From dev-return-9194-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 01:28:16 2014
Return-Path: <dev-return-9194-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0DFE011C15
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 01:28:16 +0000 (UTC)
Received: (qmail 80463 invoked by uid 500); 1 Sep 2014 01:28:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80395 invoked by uid 500); 1 Sep 2014 01:28:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80375 invoked by uid 99); 1 Sep 2014 01:28:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 01:28:14 +0000
X-ASF-Spam-Status: No, hits=-3.7 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hao.cheng@intel.com designates 192.55.52.115 as permitted sender)
Received: from [192.55.52.115] (HELO mga14.intel.com) (192.55.52.115)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 01:27:49 +0000
Received: from fmsmga003.fm.intel.com ([10.253.24.29])
  by fmsmga103.fm.intel.com with ESMTP; 31 Aug 2014 18:19:35 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.97,862,1389772800"; 
   d="scan'208";a="379572001"
Received: from fmsmsx106.amr.corp.intel.com ([10.18.124.204])
  by FMSMGA003.fm.intel.com with ESMTP; 31 Aug 2014 18:23:18 -0700
Received: from fmsmsx103.amr.corp.intel.com (10.19.9.34) by
 FMSMSX106.amr.corp.intel.com (10.18.124.204) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Sun, 31 Aug 2014 18:27:46 -0700
Received: from shsmsx104.ccr.corp.intel.com (10.239.4.70) by
 FMSMSX103.amr.corp.intel.com (10.19.9.34) with Microsoft SMTP Server (TLS) id
 14.3.195.1; Sun, 31 Aug 2014 18:27:46 -0700
Received: from shsmsx102.ccr.corp.intel.com ([169.254.2.246]) by
 SHSMSX104.ccr.corp.intel.com ([169.254.5.17]) with mapi id 14.03.0195.001;
 Mon, 1 Sep 2014 09:27:44 +0800
From: "Cheng, Hao" <hao.cheng@intel.com>
To: chutium <teng.qiu@gmail.com>, "dev@spark.incubator.apache.org"
	<dev@spark.incubator.apache.org>
Subject: RE: HiveContext, schemaRDD.printSchema get different dataTypes,
 feature or a bug? really strange and surprised...
Thread-Topic: HiveContext, schemaRDD.printSchema get different dataTypes,
 feature or a bug? really strange and surprised...
Thread-Index: AQHPwT3B7Xg9KUJTtkalEHNX2kdMI5vifIcAgAIIBYCABg27gIAA8XDA
Date: Mon, 1 Sep 2014 01:27:43 +0000
Message-ID: <80833ADD533E324CA05C160E41B636610273112B@shsmsx102.ccr.corp.intel.com>
References: <1409064875366-8035.post@n3.nabble.com>
 <1409066984856-8039.post@n3.nabble.com>
 <CAA_qdLp9FWi-ot6PzV-HWkP9bsZfbjHE48C7kjo15XLtCgKEyA@mail.gmail.com>
 <1409511459144-8157.post@n3.nabble.com>
In-Reply-To: <1409511459144-8157.post@n3.nabble.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, the root cause for that is the output ObjectInspector in SerDe impleme=
ntation doesn't reflect the real typeinfo.

Hive actually provides the API like TypeInfoUtils.getStandardJavaObjectInsp=
ectorFromTypeInfo(TypeInfo) for the mapping.

You probably need to update the code at https://github.com/ogrodnek/csv-ser=
de/blob/master/src/main/java/com/bizo/hive/serde/csv/CSVSerde.java#L60.

-----Original Message-----
From: chutium [mailto:teng.qiu@gmail.com]=20
Sent: Monday, September 01, 2014 2:58 AM
To: dev@spark.incubator.apache.org
Subject: Re: HiveContext, schemaRDD.printSchema get different dataTypes, fe=
ature or a bug? really strange and surprised...

Hi Cheng, thank you very much for helping me to finally find out the secret=
 of this magic...

actually we defined this external table with
    SID STRING
    REQUEST_ID STRING
    TIMES_DQ TIMESTAMP
    TOTAL_PRICE FLOAT
    ...

using "desc table ext_fullorders" it is only shown as
[# col_name             data_type               comment             ]
...
[times_dq               string                  from deserializer   ]
[total_price            string                  from deserializer   ]
...
because, as you said, CSVSerde sets all field object inspectors to javaStri=
ngObjectInspector and therefore there are comments "from deserializer"

but in StorageDescriptor, are the real user defined types, using "desc exte=
nded table ext_fullorders" we can see his sd:StorageDescriptor
is:
FieldSchema(name:times_dq, type:timestamp, comment:null), FieldSchema(name:=
total_price, type:float, comment:null)

and Spark HiveContext reads the schema info from this StorageDescriptor
https://github.com/apache/spark/blob/7e191fe29bb09a8560cd75d453c4f7f662dff4=
06/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.s=
cala#L316

so, in the SchemaRDD, the fields in Row were filled with strings (via fillO=
bject, all of values were retrieved from CSVSerDe with
javaStringObjectInspector)

but Spark considers that some of them are float or timestamp (schema info w=
ere got from sd:StorageDescriptor)

crazy...

and sorry for update on the weekend...

a little more about how i fand this problem and why it is a trouble for us.

we use the new spark thrift server, to query normal managed hive table, it =
works fine

but when we try to access the external tables with custom SerDe such as thi=
s CSVSerDe, then we will get this ClassCastException, such as:
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.=
Float

the reason is
https://github.com/apache/spark/blob/d94a44d7caaf3fe7559d9ad7b10872fa16cf81=
ca/sql/hive-thriftserver/src/main/scala/org/apache/spark/sql/hive/thriftser=
ver/server/SparkSQLOperationManager.scala#L104-L105

here Spark's thrift server try to get a float value from SparkRow, because =
in the schema info (sd:StorageDescriptor) this column is float, but actuall=
y in SparkRow, this field was filled with string value...



--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/HiveContext-schemaRDD-printSchema-get-different-dataTypes-feat=
ure-or-a-bug-really-strange-and-surpri-tp8035p8157.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional com=
mands, e-mail: dev-help@spark.apache.org


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9195-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 02:04:45 2014
Return-Path: <dev-return-9195-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90F3611C78
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 02:04:45 +0000 (UTC)
Received: (qmail 42637 invoked by uid 500); 1 Sep 2014 02:04:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42571 invoked by uid 500); 1 Sep 2014 02:04:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42559 invoked by uid 99); 1 Sep 2014 02:04:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 02:04:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 02:04:17 +0000
Received: by mail-we0-f169.google.com with SMTP id k48so4725476wev.28
        for <dev@spark.incubator.apache.org>; Sun, 31 Aug 2014 19:04:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=2WmI80bmcR1YgECxB2B5pLvG3iJK1nlupnVjfiErgJ8=;
        b=rGRpz1SabaarAqoiH8/1JgarmeL1CekHGeFDW771XrMcgSCwg6oZC0p3oTt6Dy/fZH
         46uPx9Gk7l0r3AXtg0JtDXBOp5Ctxy+pne12iLhLsaOeiG8EAopnYfcDBPEA+rpoxol3
         LoU0P7d9WTAP7oqAnKLmhkadXbtZkmPE6hn+lK1A3wPXdDjYNL+MxPoVxwPlfsxbZycV
         s6+niyUmQL0aj+6qOSLzy8Wojvtn2wXpCHimqttkAJKIjs+2rkoNy6bBUcix+BxUuC8Z
         Ci+URqDAB0JaugeX85JJhvRYJZrpyNiJske3BCqtTbv/V/Rmt5fyTy7+iJ4K8jA0QzdP
         OcWw==
X-Received: by 10.194.174.4 with SMTP id bo4mr5155691wjc.84.1409537057162;
 Sun, 31 Aug 2014 19:04:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sun, 31 Aug 2014 19:03:37 -0700 (PDT)
In-Reply-To: <1409524686697-8159.post@n3.nabble.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com>
 <1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com>
 <CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
 <CABPQxstJVGRBJev90xEaydUrzhxtO0Jxj6rPuE6cS105a6HEQw@mail.gmail.com> <1409524686697-8159.post@n3.nabble.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 31 Aug 2014 22:03:37 -0400
Message-ID: <CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
To: chutium <teng.qiu@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e013d0c7a970b230501f76b08
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d0c7a970b230501f76b08
Content-Type: text/plain; charset=UTF-8

On Sun, Aug 31, 2014 at 6:38 PM, chutium <teng.qiu@gmail.com> wrote:

> has anyone tried to build it on hadoop.version=2.0.0-mr1-cdh4.3.0 or
> hadoop.version=1.0.3-mapr-3.0.3 ?
>

Is the behavior you're seeing a regression from 1.0.2, or does 1.0.2 have
this same problem?

Nick

--089e013d0c7a970b230501f76b08--

From dev-return-9196-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 03:28:17 2014
Return-Path: <dev-return-9196-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 22F6711DE0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 03:28:16 +0000 (UTC)
Received: (qmail 26149 invoked by uid 500); 1 Sep 2014 03:28:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26067 invoked by uid 500); 1 Sep 2014 03:28:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26049 invoked by uid 99); 1 Sep 2014 03:28:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 03:28:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ianoconnell@gmail.com designates 209.85.223.171 as permitted sender)
Received: from [209.85.223.171] (HELO mail-ie0-f171.google.com) (209.85.223.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 03:28:08 +0000
Received: by mail-ie0-f171.google.com with SMTP id rp18so5510316iec.30
        for <dev@spark.apache.org>; Sun, 31 Aug 2014 20:27:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=2vYMd8/aMcxsUNyZ+ihcDLb8jdbmWB0exIM9w/ugzC8=;
        b=fKMfzYPzJFtuRDHQmydsRmlujb9l62Pfa9qqsT5WDzqhrRtoYp1xkxS99X8HTxShiA
         g4O3qQ/H0NJ31gEQ54/MFaI+zjomYwfDk0z6x58hliCAhuEtbBMqKtrVnOWAKP5reGdd
         c14h3YKVQJyMcde21I/tUHqkKE+NRyAtaRGtLxB5q9ax1lKjg5L30q0XMO4kY8ib8W6m
         BBFjCt6jvnbHg18vMQ5bzC8euDGfQkGOeJjTM/uvlvwBVhoMmG8HZT3mbE9iFpF3mLau
         w9ojZ+QDsetdBtmfTtoHVl1TTy5yEnflKAQcVi+Yb2msGYQp0dIHRibNdzqHtqaLtBqS
         b0nQ==
X-Received: by 10.50.122.99 with SMTP id lr3mr18434196igb.10.1409542067859;
 Sun, 31 Aug 2014 20:27:47 -0700 (PDT)
MIME-Version: 1.0
Sender: ianoconnell@gmail.com
Received: by 10.64.9.8 with HTTP; Sun, 31 Aug 2014 20:27:27 -0700 (PDT)
In-Reply-To: <CAN6Vra0xEZV7XYpCqWYgJABC2CHLtau423yc69_=WVwPXAMV3A@mail.gmail.com>
References: <CAN6Vra27gzyifyrVVTnoGddRmysN-rnfCHBTDCT1KuX-ZcOjPw@mail.gmail.com>
 <CAAswR-43krAdVUDZ3ZLod1qFWYzAsZhQBv87s17vuD2Sc4A6WA@mail.gmail.com>
 <CAN6Vra0oSCPAr14mO3RfuPz5D1WnB1C8xFEcUmCuoqSiLzrGHw@mail.gmail.com>
 <CAAswR-60n8cj5WU47TNw-AvmVBAmdveb7XEu4YmjyTjqbR=hCg@mail.gmail.com> <CAN6Vra0xEZV7XYpCqWYgJABC2CHLtau423yc69_=WVwPXAMV3A@mail.gmail.com>
From: "Ian O'Connell" <ian@ianoconnell.com>
Date: Sun, 31 Aug 2014 20:27:27 -0700
X-Google-Sender-Auth: gCgYmFhCfSYz-GSs7VskiWm3D2w
Message-ID: <CAMDxJTFfbrXH7bdupOfNPhwqEMgEShg4OoWUzZa6UvyJS9D96w@mail.gmail.com>
Subject: Re: [Spark SQL] off-heap columnar store
To: Evan Chan <velvia.github@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0153835a4038f70501f8966d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0153835a4038f70501f8966d
Content-Type: text/plain; charset=UTF-8

I'm not sure what you mean here? Parquet is at its core just a format, you
could store that data anywhere.

Though it sounds like you saying, correct me if i'm wrong: you basically
want a columnar abstraction layer where you can provide a different backing
implementation to keep the columns rather than parquet-mr?

I.e. you want to be able to produce a schema RDD from something like
vertica, where updates should act as a write through cache back to vertica
itself?

I'm sorry it just sounds like its worth clearly defining what your key
requirement/goal is.


On Thu, Aug 28, 2014 at 11:31 PM, Evan Chan <velvia.github@gmail.com> wrote:

> >
> >> The reason I'm asking about the columnar compressed format is that
> >> there are some problems for which Parquet is not practical.
> >
> >
> > Can you elaborate?
>
> Sure.
>
> - Organization or co has no Hadoop, but significant investment in some
> other NoSQL store.
> - Need to efficiently add a new column to existing data
> - Need to mark some existing rows as deleted or replace small bits of
> existing data
>
> For these use cases, it would be much more efficient and practical if
> we didn't have to take the origin of the data from the datastore,
> convert it to Parquet first.  Doing so loses significant latency and
> causes Ops headaches in having to maintain HDFS.     It would be great
> to be able to load data directly into the columnar format, into the
> InMemoryColumnarCache.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0153835a4038f70501f8966d--

From dev-return-9197-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 13:36:41 2014
Return-Path: <dev-return-9197-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BAD7611E8C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 13:36:41 +0000 (UTC)
Received: (qmail 12360 invoked by uid 500); 1 Sep 2014 13:36:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12297 invoked by uid 500); 1 Sep 2014 13:36:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12286 invoked by uid 99); 1 Sep 2014 13:36:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 13:36:40 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of teng.qiu@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 13:36:14 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <teng.qiu@gmail.com>)
	id 1XORmG-0004XZ-IE
	for dev@spark.incubator.apache.org; Mon, 01 Sep 2014 06:36:12 -0700
Date: Mon, 1 Sep 2014 06:36:12 -0700 (PDT)
From: chutium <teng.qiu@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409578572550-8163.post@n3.nabble.com>
In-Reply-To: <CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com> <CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com> <1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com> <CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com> <CABPQxstJVGRBJev90xEaydUrzhxtO0Jxj6rPuE6cS105a6HEQw@mail.gmail.com> <1409524686697-8159.post@n3.nabble.com> <CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

i didn't tried with 1.0.2

it takes always too long to build spark assembly jars... more than 20min

[info] Packaging
/mnt/some-nfs/common/spark/assembly/target/scala-2.10/spark-assembly-1.1.0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
...
[info] Packaging
/mnt/some-nfs/common/spark/examples/target/scala-2.10/spark-examples-1.1.0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
...
[info] Done packaging.
[info] Done packaging.
[success] Total time: 1582 s, completed Sep 1, 2014 1:39:21 PM

is there some easily way to exclude some modules such as spark/examples or
spark/external ?



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC3-tp8147p8163.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9198-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 15:10:39 2014
Return-Path: <dev-return-9198-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04A8511181
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 15:10:39 +0000 (UTC)
Received: (qmail 82277 invoked by uid 500); 1 Sep 2014 15:10:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82220 invoked by uid 500); 1 Sep 2014 15:10:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82208 invoked by uid 99); 1 Sep 2014 15:10:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 15:10:37 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.169 as permitted sender)
Received: from [209.85.212.169] (HELO mail-wi0-f169.google.com) (209.85.212.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 15:10:10 +0000
Received: by mail-wi0-f169.google.com with SMTP id n3so2773922wiv.0
        for <dev@spark.incubator.apache.org>; Mon, 01 Sep 2014 08:10:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=GTiYeofQTL4BKm/qoCIsCEzyRVcteLsZ3CrZz0mJ3B0=;
        b=PWqmoCeuTCmd8ktI1tuLpq1gKj4CM/gnMhuwAPtUyDa6zimemg/z0AprZpDGFaXbDd
         106umPoyBtDmG1cTiMDLMwQ8JzafzlOmPCor3PgkVryIBqOTFfU9MxVlZcMv8/S9RksR
         zXDtLJjADxFAlcPcq+6VyuOevty5v6WW9e0q0YXf/b9No1h64v36kOJc63TXWVipQKcU
         FPOVfobyRQHe76e3LYXywEjdgtzZm/vsPzoChfSS5Wg9TjCXUNXdAwCTAgdU3rh6708x
         G0SgHUDnegd6OcptpqROjpK6ZFmQKwPlyq6fGMchhZP1DzfGUJEuUa613g8Uu7hwhLE4
         XiaA==
MIME-Version: 1.0
X-Received: by 10.180.149.197 with SMTP id uc5mr21734949wib.75.1409584209038;
 Mon, 01 Sep 2014 08:10:09 -0700 (PDT)
Received: by 10.180.92.232 with HTTP; Mon, 1 Sep 2014 08:10:08 -0700 (PDT)
In-Reply-To: <1409578572550-8163.post@n3.nabble.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
	<CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com>
	<1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com>
	<CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
	<CABPQxstJVGRBJev90xEaydUrzhxtO0Jxj6rPuE6cS105a6HEQw@mail.gmail.com>
	<1409524686697-8159.post@n3.nabble.com>
	<CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
	<1409578572550-8163.post@n3.nabble.com>
Date: Mon, 1 Sep 2014 11:10:08 -0400
Message-ID: <CAOhmDzf1D40yr=WVfJJO4OEkQigfmV+X+6RR_A-WJ4-BogU5AQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: chutium <teng.qiu@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c381140f92400502026621
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c381140f92400502026621
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

If this is not a confirmed regression from 1.0.2, I think it's better to
report it in a separate thread or JIRA.

I believe serious regressions are generally the only reason to block a new
release. Otherwise, if this is an old issue, it should be handled
separately.

2014=EB=85=84 9=EC=9B=94 1=EC=9D=BC =EC=9B=94=EC=9A=94=EC=9D=BC, chutium<te=
ng.qiu@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =EB=A9=94=
=EC=8B=9C=EC=A7=80:

> i didn't tried with 1.0.2
>
> it takes always too long to build spark assembly jars... more than 20min
>
> [info] Packaging
>
> /mnt/some-nfs/common/spark/assembly/target/scala-2.10/spark-assembly-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> ...
> [info] Packaging
>
> /mnt/some-nfs/common/spark/examples/target/scala-2.10/spark-examples-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> ...
> [info] Done packaging.
> [info] Done packaging.
> [success] Total time: 1582 s, completed Sep 1, 2014 1:39:21 PM
>
> is there some easily way to exclude some modules such as spark/examples o=
r
> spark/external ?
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Ap=
ache-Spark-1-1-0-RC3-tp8147p8163.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: dev-help@spark.apache.org <javascript:;>
>
>

--001a11c381140f92400502026621--

From dev-return-9199-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 16:28:21 2014
Return-Path: <dev-return-9199-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0B3721140B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 16:28:21 +0000 (UTC)
Received: (qmail 65800 invoked by uid 500); 1 Sep 2014 16:28:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65733 invoked by uid 500); 1 Sep 2014 16:28:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65714 invoked by uid 99); 1 Sep 2014 16:28:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 16:28:19 +0000
X-ASF-Spam-Status: No, hits=3.8 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 209.85.220.171 as permitted sender)
Received: from [209.85.220.171] (HELO mail-vc0-f171.google.com) (209.85.220.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 16:27:52 +0000
Received: by mail-vc0-f171.google.com with SMTP id id10so5743717vcb.30
        for <dev@spark.incubator.apache.org>; Mon, 01 Sep 2014 09:27:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=jyuvFESSatJ7/9bt8pf+eI45O+nccdXW6JeTdk27pvM=;
        b=ZhWGE9OOdTUOlTgFW2P3TcTOtlYrBvPSR5wZ0QEWa/LkOB+FB72W5Qwvr2c0c4U7NE
         H4uHKn2k8U97NaV1iy4FaWmI0KT5/OcggiCsEM8pNbu31+BL/PyeiWdZTAt6WVSj0UVI
         ZTMfwzuE9zwFmBxOvoB/CvduGLbtJCADXSilS3C9g3yasjcPgjXniHAHbrHH0US5mhFz
         Yrfm0/krni+zy9IS2BJ9sWVLYLa9fhyh++w+tKKAzZu53cHo+85j33uOSpWgKu51oaVM
         Eabzemnho1uq5H23WA7lQ91Rb+yUU0/CsPUQzjnectk+iwTXQ9LxiizkSgljs7qnY4bh
         qASw==
X-Received: by 10.52.248.42 with SMTP id yj10mr1090273vdc.50.1409588871468;
 Mon, 01 Sep 2014 09:27:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.220.211 with HTTP; Mon, 1 Sep 2014 09:27:31 -0700 (PDT)
In-Reply-To: <CAOhmDzf1D40yr=WVfJJO4OEkQigfmV+X+6RR_A-WJ4-BogU5AQ@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com>
 <1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com>
 <CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
 <CABPQxstJVGRBJev90xEaydUrzhxtO0Jxj6rPuE6cS105a6HEQw@mail.gmail.com>
 <1409524686697-8159.post@n3.nabble.com> <CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
 <1409578572550-8163.post@n3.nabble.com> <CAOhmDzf1D40yr=WVfJJO4OEkQigfmV+X+6RR_A-WJ4-BogU5AQ@mail.gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Mon, 1 Sep 2014 21:57:31 +0530
Message-ID: <CAOYDGoCSRWU1YQagrpf_fq9U=9JvXPDxs=V+Y9sdAC9Oi4oR6g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: chutium <teng.qiu@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a1135f962f6a09e0502037b02
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135f962f6a09e0502037b02
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Easy or quicker way to build spark is

sbt/sbt assembly/assembly

Prashant Sharma




On Mon, Sep 1, 2014 at 8:40 PM, Nicholas Chammas <nicholas.chammas@gmail.co=
m
> wrote:

> If this is not a confirmed regression from 1.0.2, I think it's better to
> report it in a separate thread or JIRA.
>
> I believe serious regressions are generally the only reason to block a ne=
w
> release. Otherwise, if this is an old issue, it should be handled
> separately.
>
> 2014=EB=85=84 9=EC=9B=94 1=EC=9D=BC =EC=9B=94=EC=9A=94=EC=9D=BC, chutium<=
teng.qiu@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =EB=A9=94=
=EC=8B=9C=EC=A7=80:
>
> > i didn't tried with 1.0.2
> >
> > it takes always too long to build spark assembly jars... more than 20mi=
n
> >
> > [info] Packaging
> >
> >
> /mnt/some-nfs/common/spark/assembly/target/scala-2.10/spark-assembly-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> > ...
> > [info] Packaging
> >
> >
> /mnt/some-nfs/common/spark/examples/target/scala-2.10/spark-examples-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> > ...
> > [info] Done packaging.
> > [info] Done packaging.
> > [success] Total time: 1582 s, completed Sep 1, 2014 1:39:21 PM
> >
> > is there some easily way to exclude some modules such as spark/examples
> or
> > spark/external ?
> >
> >
> >
> > --
> > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Ap=
ache-Spark-1-1-0-RC3-tp8147p8163.html
> > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> > For additional commands, e-mail: dev-help@spark.apache.org
> <javascript:;>
> >
> >
>

--001a1135f962f6a09e0502037b02--

From dev-return-9200-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 16:43:34 2014
Return-Path: <dev-return-9200-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9D39C11463
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 16:43:34 +0000 (UTC)
Received: (qmail 165 invoked by uid 500); 1 Sep 2014 16:43:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 102 invoked by uid 500); 1 Sep 2014 16:43:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99990 invoked by uid 99); 1 Sep 2014 16:43:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 16:43:33 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of teng.qiu@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 16:43:29 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <teng.qiu@gmail.com>)
	id 1XOUhA-0007Ns-SE
	for dev@spark.incubator.apache.org; Mon, 01 Sep 2014 09:43:08 -0700
Date: Mon, 1 Sep 2014 09:43:08 -0700 (PDT)
From: chutium <teng.qiu@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409589788865-8166.post@n3.nabble.com>
In-Reply-To: <80833ADD533E324CA05C160E41B636610273112B@shsmsx102.ccr.corp.intel.com>
References: <1409064875366-8035.post@n3.nabble.com> <1409066984856-8039.post@n3.nabble.com> <CAA_qdLp9FWi-ot6PzV-HWkP9bsZfbjHE48C7kjo15XLtCgKEyA@mail.gmail.com> <1409511459144-8157.post@n3.nabble.com> <80833ADD533E324CA05C160E41B636610273112B@shsmsx102.ccr.corp.intel.com>
Subject: RE: HiveContext, schemaRDD.printSchema get different dataTypes,
 feature or a bug? really strange and surprised...
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

thanks a lot, Hao, finally solved this problem, changes of CSVSerDe are here:
https://github.com/chutium/csv-serde/commit/22c667c003e705613c202355a8791978d790591e

btw, "add jar" in spark hive or hive-thriftserver always doesn't work, we
build the spark with libraryDependencies += "csv-serde" ...

or maybe should try to add it to SPARK_CLASSPATH ?



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/HiveContext-schemaRDD-printSchema-get-different-dataTypes-feature-or-a-bug-really-strange-and-surpri-tp8035p8166.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9201-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  1 19:40:33 2014
Return-Path: <dev-return-9201-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 426C611837
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  1 Sep 2014 19:40:33 +0000 (UTC)
Received: (qmail 45853 invoked by uid 500); 1 Sep 2014 19:40:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45783 invoked by uid 500); 1 Sep 2014 19:40:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45769 invoked by uid 99); 1 Sep 2014 19:40:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 19:40:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 01 Sep 2014 19:40:25 +0000
Received: by mail-qc0-f178.google.com with SMTP id x13so5755967qcv.37
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 12:40:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=lg1z9koNDLARfFN7Ii6Nqys1WsPrNbB1MxP3mAAFqks=;
        b=Y5aWgc/aLTgW+FOuz4I9+9C2pJixR5lghebhr0DtTjOGzbTlBKF49LQuM/kI69adYl
         PQQYjhH6swSwhDSQOe0pJgFsSBdIAPdn617vjUnov/rDU18VqJDyJLobAEd3rJ09ciLU
         Ui1QBdrzNkP9b/3zHaY5n8mNQgjK4+UowAg29zMjocDWacfL28PdgjBrU3VbVSJDthvu
         baYgRm+Gjb7YK1bCPyTOvReZECC6L3ESzA0Ov8mnpFrjGRechcRZ3LStu6ZS73T74nGX
         Z5O5jKZimGABAZzzCf+4g/e8HhwjLIXg6Dnag2VJcoZdkN5suxb02sxIyesnnp1NsM2G
         hFNw==
X-Received: by 10.224.46.8 with SMTP id h8mr48777731qaf.6.1409600404505;
        Mon, 01 Sep 2014 12:40:04 -0700 (PDT)
Received: from joshs-mbp.att.net (108-221-16-177.lightspeed.sntcca.sbcglobal.net. [108.221.16.177])
        by mx.google.com with ESMTPSA id o6sm4161739qag.40.2014.09.01.12.40.02
        for <dev@spark.apache.org>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Mon, 01 Sep 2014 12:40:03 -0700 (PDT)
Date: Mon, 1 Sep 2014 12:40:01 -0700
From: Josh Rosen <rosenville@gmail.com>
To: dev@spark.apache.org
Message-ID: <etPan.5404cb91.79e2a9e3.cf9@joshs-mbp.att.net>
In-Reply-To: <etPan.5400b2f1.8edbdab.104@joshs-mbp>
References: <CAF7WS+qAKzzDshDqNy=jrRQWvHVVcupEL3zBtE69CRuuZh2izw@mail.gmail.com>
 <etPan.53ffb3b8.2443a858.104@joshs-mbp>
 <19E8DB9B-E581-4B8A-938B-ED55B78FD016@yahoo.com>
 <etPan.5400b2f1.8edbdab.104@joshs-mbp>
Subject: Re: Jira tickets for starter tasks
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5404cb91_7545e146_cf9"
X-Virus-Checked: Checked by ClamAV on apache.org

--5404cb91_7545e146_cf9
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

A number of folks have emailed me to add them, but I=E2=80=99ve been unab=
le to find their usernanmes in the Apache JIRA. =C2=A0Note that you need =
to have an account at issues.apache.org, which may or may not have the sa=
me email / username as your accounts on any other Apache systems, includi=
ng CWiki. =C2=A0Even if you are an Apache committer, you might not have a=
n account on the JIRA unless you=E2=80=99ve created one.

Therefore, if you want to be added to the =E2=80=9CContributors=E2=80=9D =
group, I=E2=80=99ll need your actual JIRA username, which you can find at=
=C2=A0https://issues.apache.org/jira/secure/ViewProfile.jspa=C2=A0when si=
gned in to JIRA.

Note that you do not need to be a member of the contributors group in ode=
r to open issues. =C2=A0If you want to be assigned an issue, you can also=
 just comment in the issue itself and a JIRA administrator should be able=
 to assign it to you.

On August 29, 2014 at 10:05:54 AM, Josh Rosen (rosenville=40gmail.com) wr=
ote:
Added you; you should be set=21

If anyone else wants me to add them, please email me off-list so that we =
don=E2=80=99t end up flooding the dev list with replies. Thanks=21


On August 29, 2014 at 10:03:41 AM, Ron's Yahoo=21 (zlgonzalez=40yahoo.com=
) wrote:

Hi Josh,
Can you add me as well=3F

Thanks,
Ron

On Aug 28, 2014, at 3:56 PM, Josh Rosen <rosenville=40gmail.com> wrote:

> A JIRA admin needs to add you to the =E2=80=98=E2=80=99Contributors=E2=80=
=9D role group in order to allow you to assign issues to yourself. I=E2=80=
=99ve added this email address to that group, so you should be set=21
>
> - Josh
>
>
> On August 28, 2014 at 3:52:57 PM, Bill Bejeck (bbejeck=40gmail.com) wro=
te:
>
> Hi,
>
> How do I get a starter task jira ticket assigned to myself=3F Or do I j=
ust do
> the work and issue a pull request with the associated jira number=3F
>
> Thanks,
> Bill


--5404cb91_7545e146_cf9--


From dev-return-9202-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 01:36:03 2014
Return-Path: <dev-return-9202-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5262011E45
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 01:36:03 +0000 (UTC)
Received: (qmail 11946 invoked by uid 500); 2 Sep 2014 01:36:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11874 invoked by uid 500); 2 Sep 2014 01:36:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11862 invoked by uid 99); 2 Sep 2014 01:36:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 01:36:02 +0000
X-ASF-Spam-Status: No, hits=3.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 01:35:36 +0000
Received: by mail-pa0-f51.google.com with SMTP id rd3so13435386pab.38
        for <dev@spark.incubator.apache.org>; Mon, 01 Sep 2014 18:35:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=rNlQnNBRq/tad4to2h5GmMM+2Tq1kww/L+o2wN4BVLA=;
        b=iCzI97AMGCJE2wpiXXg0eHofgAlNvKs1qXXdRe3r9dUNPFFWkHwT+jSYwEKvQI7tIZ
         uZwTYNUuvW3oeBvm/r/o8KRQZZK/owoeeZzxDpIiGAYBYI3Kg+xgbvCeYJesiRnIxMlh
         v1kpuhAcbt2Aq2jLVl8QVi4qxvDywwCndjQFSIFAwq2GI4b+ZUF4cFEWWy+oliFtX1+B
         BFZ/tz49cKLZ4dDTcjm2WHOuO+XYXXBoxgsVIALrXEhrE+N2T5TN8F4w279sOyjKhZtQ
         FRzW0yIJbxi65+ZhGkFVs+48P3ZEr2zpLKSoQLuIKVxRcdTCDw3sUkqFvI5JVe6SXn+c
         s/OQ==
X-Gm-Message-State: ALoCoQm6YtJu+5FDUZ8WnAopo6Z98T5lMDdiHBwp3VIRVMP2CLnAlj//c9fTqAoLeM7YaUSs2sGT
MIME-Version: 1.0
X-Received: by 10.70.34.235 with SMTP id c11mr8332748pdj.76.1409621734072;
 Mon, 01 Sep 2014 18:35:34 -0700 (PDT)
Received: by 10.70.41.198 with HTTP; Mon, 1 Sep 2014 18:35:33 -0700 (PDT)
In-Reply-To: <CAOYDGoCSRWU1YQagrpf_fq9U=9JvXPDxs=V+Y9sdAC9Oi4oR6g@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
	<CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com>
	<1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com>
	<CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
	<CABPQxstJVGRBJev90xEaydUrzhxtO0Jxj6rPuE6cS105a6HEQw@mail.gmail.com>
	<1409524686697-8159.post@n3.nabble.com>
	<CAOhmDzfSksnZBEh65N1o=Rt+U2oOff2ZRC6ydipJgON6TSSjuw@mail.gmail.com>
	<1409578572550-8163.post@n3.nabble.com>
	<CAOhmDzf1D40yr=WVfJJO4OEkQigfmV+X+6RR_A-WJ4-BogU5AQ@mail.gmail.com>
	<CAOYDGoCSRWU1YQagrpf_fq9U=9JvXPDxs=V+Y9sdAC9Oi4oR6g@mail.gmail.com>
Date: Mon, 1 Sep 2014 18:35:33 -0700
Message-ID: <CAMJOb8mPEUDZsSr67N4J9LE+ZzdF56dz2ZmS97zsh7--kcYGtg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
From: Andrew Or <andrew@databricks.com>
To: Prashant Sharma <scrapcodes@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, chutium <teng.qiu@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfcfb7aba40aa05020b22d2
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfcfb7aba40aa05020b22d2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

+1. Tested all the basic applications under both deploy modes (where
applicable) in the following environments:

- locally on OSX 10.9
- locally on Windows 8.1
- standalone cluster
- yarn cluster built with Hadoop 2.4

>From this front I have observed no regressions, and verified that
standalone-cluster mode is now fixed.



2014-09-01 9:27 GMT-07:00 Prashant Sharma <scrapcodes@gmail.com>:

> Easy or quicker way to build spark is
>
> sbt/sbt assembly/assembly
>
> Prashant Sharma
>
>
>
>
> On Mon, Sep 1, 2014 at 8:40 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > If this is not a confirmed regression from 1.0.2, I think it's better t=
o
> > report it in a separate thread or JIRA.
> >
> > I believe serious regressions are generally the only reason to block a
> new
> > release. Otherwise, if this is an old issue, it should be handled
> > separately.
> >
> > 2014=EB=85=84 9=EC=9B=94 1=EC=9D=BC =EC=9B=94=EC=9A=94=EC=9D=BC, chutiu=
m<teng.qiu@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =EB=A9=
=94=EC=8B=9C=EC=A7=80:
> >
> > > i didn't tried with 1.0.2
> > >
> > > it takes always too long to build spark assembly jars... more than
> 20min
> > >
> > > [info] Packaging
> > >
> > >
> >
> /mnt/some-nfs/common/spark/assembly/target/scala-2.10/spark-assembly-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> > > ...
> > > [info] Packaging
> > >
> > >
> >
> /mnt/some-nfs/common/spark/examples/target/scala-2.10/spark-examples-1.1.=
0-SNAPSHOT-hadoop1.0.3-mapr-3.0.3.jar
> > > ...
> > > [info] Done packaging.
> > > [info] Done packaging.
> > > [success] Total time: 1582 s, completed Sep 1, 2014 1:39:21 PM
> > >
> > > is there some easily way to exclude some modules such as spark/exampl=
es
> > or
> > > spark/external ?
> > >
> > >
> > >
> > > --
> > > View this message in context:
> > >
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Ap=
ache-Spark-1-1-0-RC3-tp8147p8163.html
> > > Sent from the Apache Spark Developers List mailing list archive at
> > > Nabble.com.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> <javascript:;>
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > <javascript:;>
> > >
> > >
> >
>

--047d7bfcfb7aba40aa05020b22d2--

From dev-return-9203-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 03:22:05 2014
Return-Path: <dev-return-9203-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AF4D011FF8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 03:22:05 +0000 (UTC)
Received: (qmail 27468 invoked by uid 500); 2 Sep 2014 03:22:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27392 invoked by uid 500); 2 Sep 2014 03:22:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27380 invoked by uid 99); 2 Sep 2014 03:22:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 03:22:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 03:22:00 +0000
Received: by mail-we0-f172.google.com with SMTP id q59so6259332wes.31
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 20:21:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=4TxLMHjeB2JqxaG+BlSphgyHlC47qtAZJdQD/J/jrc4=;
        b=k3SsHC59ZnHY0Socksq++CPmN2BnVoaMT/7+Fz4Bv+4MlcEGx8WMPGD6ykIgBLgmxs
         Sm6U4hCYaSwpeah4ICLSzxcMEsWb3LobilguGRL3yUHEFjivNhnXVYaMT2h/hsBvPjHo
         0AgPu5JK3iuVCuOa2C76/YaoaA5XNOxJTI3vOcUr4CUeFNSP2VvbSMIxyH7+0TLvwbyS
         ztqzyWwrj5enNrzoprGPvdOaCAVKPXmP259qQh2GT0XDaOAod5EytgCWtvbNl27b/qqF
         Ji1qEYl3m5vd2kIeHA6xF8AjDPRKcxPKHSKMs8ZJskrxiquubOBPfxpSzL2GKNOIJvU1
         HF6g==
X-Received: by 10.180.211.233 with SMTP id nf9mr24825392wic.33.1409628099122;
 Mon, 01 Sep 2014 20:21:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Mon, 1 Sep 2014 20:20:59 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 1 Sep 2014 23:20:59 -0400
Message-ID: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
Subject: Run the "Big Data Benchmark" for new releases
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c338d01d1c3e05020c9e81
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c338d01d1c3e05020c9e81
Content-Type: text/plain; charset=UTF-8

What do people think of running the Big Data Benchmark
<https://amplab.cs.berkeley.edu/benchmark/> (repo
<https://github.com/amplab/benchmark>) as part of preparing every new
release of Spark?

We'd run it just for Spark and effectively use it as another type of test
to track any performance progress or regressions from release to release.

Would doing such a thing be valuable? Do we already have a way of
benchmarking Spark performance that we use regularly?

Nick

--001a11c338d01d1c3e05020c9e81--

From dev-return-9204-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 04:29:58 2014
Return-Path: <dev-return-9204-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EE384110E3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 04:29:57 +0000 (UTC)
Received: (qmail 4572 invoked by uid 500); 2 Sep 2014 04:29:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4516 invoked by uid 500); 2 Sep 2014 04:29:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4504 invoked by uid 99); 2 Sep 2014 04:29:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 04:29:56 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.180 as permitted sender)
Received: from [209.85.192.180] (HELO mail-pd0-f180.google.com) (209.85.192.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 04:29:52 +0000
Received: by mail-pd0-f180.google.com with SMTP id p10so7509453pdj.25
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 21:29:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=uHN6aRcLn7PcrLPGQ4mR3K2ecrPUMpzyKb1vcrqTfHE=;
        b=rd+MyDS2HuGg0qDa6aDHE2C1u/LTmBcpdEQbf1ykxLBg8hOUdLsSIHFynus9LO8Xf6
         oiHgEhiE4JaJTszRWH2IDo0jRHC7llVT8ezSjcHYZFdbliC6QFbg8M8oENXE+LUwLwpo
         goUvAWjD4Vvyt+UxPFMRbiQ1+ggnZ2oZ/2Avyod4i26lmy06HM0NHDUXfdWyk9pCvb4O
         ufwRv1zqI/rrWu1LnEW0xaYaGbrG52IEyELbvWGHd1G61RTfCua2fXjY1XHOFlMtPRw1
         WNsAub1osLNMVNM9X2cFlOV1Xh449q/7JlX4WlzWM0ub+gv/mDvI8aYel84r3moWqXUR
         BUNg==
X-Received: by 10.66.66.225 with SMTP id i1mr18640786pat.56.1409632172005;
        Mon, 01 Sep 2014 21:29:32 -0700 (PDT)
Received: from mbp-3.local (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id jw6sm2475745pbc.79.2014.09.01.21.29.27
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 01 Sep 2014 21:29:28 -0700 (PDT)
Date: Mon, 1 Sep 2014 21:29:26 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>, dev
 <dev@spark.apache.org>
Message-ID: <etPan.540547a6.41b71efb.8aeb@mbp-3.local>
In-Reply-To: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
References: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
Subject: Re: Run the "Big Data Benchmark" for new releases
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540547a6_79e2a9e3_8aeb"
X-Virus-Checked: Checked by ClamAV on apache.org

--540547a6_79e2a9e3_8aeb
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi Nicholas,

At Databricks we already run=C2=A0https://github.com/databricks/spark-per=
f for each release, which is a more comprehensive performance test suite.=


Matei

On September 1, 2014 at 8:22:05 PM, Nicholas Chammas (nicholas.chammas=40=
gmail.com) wrote:

What do people think of running the Big Data Benchmark =20
<https://amplab.cs.berkeley.edu/benchmark/> (repo =20
<https://github.com/amplab/benchmark>) as part of preparing every new =20
release of Spark=3F =20

We'd run it just for Spark and effectively use it as another type of test=
 =20
to track any performance progress or regressions from release to release.=
 =20

Would doing such a thing be valuable=3F Do we already have a way of =20
benchmarking Spark performance that we use regularly=3F =20

Nick =20

--540547a6_79e2a9e3_8aeb--


From dev-return-9205-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 05:03:48 2014
Return-Path: <dev-return-9205-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5CCDE111A9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 05:03:48 +0000 (UTC)
Received: (qmail 49399 invoked by uid 500); 2 Sep 2014 05:03:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49334 invoked by uid 500); 2 Sep 2014 05:03:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49320 invoked by uid 99); 2 Sep 2014 05:03:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:03:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.181 as permitted sender)
Received: from [209.85.212.181] (HELO mail-wi0-f181.google.com) (209.85.212.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:03:21 +0000
Received: by mail-wi0-f181.google.com with SMTP id e4so7087385wiv.14
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 22:03:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=S6q9FS7aV3e8aZke5ynUr348JjUOEqMeV6hcUyIhLSk=;
        b=ysiaHKJXt2YoXLU+c5kQfoGxIOT9FlbUjfll2YK1ZkYtoxS5CbZhr4sYf0pesFWW0h
         WYocss+EnQBt5Po4SGWXTwWiXIo3f8W0++A9LCbKuxY+slIBsxUjvqL83cl+p6OiIjlR
         m3mbT/1VVo15ty//uyxxOE/FW5aZP9ZAOIDRP4zC4LaargSfwWDQ6HOr1orEMbHyH/5D
         7mgfRWUUM/luZ2OlzCq8Z6HeDQQcqJXqK0ePr6zuUAxeAWYSNoig1E9UNXZBl36kOTPt
         7Wy8Y9zGxqLxup4jqXlbgOGBIGzfHfqI09u/bIf3QQIj8egQ6C/Kg8QY8Y396upuR/MC
         sw9w==
X-Received: by 10.180.149.197 with SMTP id uc5mr25131589wib.75.1409634200843;
 Mon, 01 Sep 2014 22:03:20 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Mon, 1 Sep 2014 22:02:40 -0700 (PDT)
In-Reply-To: <etPan.540547a6.41b71efb.8aeb@mbp-3.local>
References: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
 <etPan.540547a6.41b71efb.8aeb@mbp-3.local>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 2 Sep 2014 01:02:40 -0400
Message-ID: <CAOhmDzdepHQNGShgRJvrcd9Ta_odmEQGY8qwgEwTM3TCVFN6bg@mail.gmail.com>
Subject: Re: Run the "Big Data Benchmark" for new releases
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c38114cdfab505020e09c9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c38114cdfab505020e09c9
Content-Type: text/plain; charset=UTF-8

Oh, that's sweet. So, a related question then.

Did those tests pick up the performance issue reported in SPARK-3333
<https://issues.apache.org/jira/browse/SPARK-3333>? Does it make sense to
add a new test to cover that case?


On Tue, Sep 2, 2014 at 12:29 AM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Hi Nicholas,
>
> At Databricks we already run https://github.com/databricks/spark-perf for
> each release, which is a more comprehensive performance test suite.
>
> Matei
>
> On September 1, 2014 at 8:22:05 PM, Nicholas Chammas (
> nicholas.chammas@gmail.com) wrote:
>
> What do people think of running the Big Data Benchmark
> <https://amplab.cs.berkeley.edu/benchmark/> (repo
> <https://github.com/amplab/benchmark>) as part of preparing every new
> release of Spark?
>
> We'd run it just for Spark and effectively use it as another type of test
> to track any performance progress or regressions from release to release.
>
> Would doing such a thing be valuable? Do we already have a way of
> benchmarking Spark performance that we use regularly?
>
> Nick
>
>

--001a11c38114cdfab505020e09c9--

From dev-return-9206-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 05:05:01 2014
Return-Path: <dev-return-9206-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A5F0111B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 05:05:01 +0000 (UTC)
Received: (qmail 50826 invoked by uid 500); 2 Sep 2014 05:05:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50753 invoked by uid 500); 2 Sep 2014 05:05:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50739 invoked by uid 99); 2 Sep 2014 05:05:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:05:00 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:04:34 +0000
Received: by mail-pa0-f44.google.com with SMTP id rd3so13837520pab.31
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 22:04:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=ioW4Y1uXcMhhLJNZR8j5H6Ipkfmj3avIITvpRy1fc7o=;
        b=yKK/7B3/Ue4wLYnamQZvEbx89LcM0TjMr/+6zA7IdnkIjYsga+BKDtTo/TDUS0fY+P
         P8ZWZtoHXM4DoVO1R/7sV5xWNmD/tCWB163kX4Gv9F7XuTfaVYNe6pFNKdcvr2O3PXoj
         JSClVi0VtRi7GG5gdvv3xg51X9KUW9kd7usZMjeOFcs0UYai/b71ChL1HsZxDSOS+TXc
         2YUIPaixvxVz0sVimqy1ltFiVakU+MtXtUVJn03yaTBcmcI49EP6TWHV3pNI9kNb5+gB
         TzeOkqsMWlZF9GLarcgNBnMnyx60++CtYmsIaKaGhysMUA1Sxy4IJF2dqZbV5bFtOvmG
         H/fg==
X-Received: by 10.70.48.208 with SMTP id o16mr44997534pdn.17.1409634272587;
        Mon, 01 Sep 2014 22:04:32 -0700 (PDT)
Received: from mbp-3.local (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id cx2sm2610283pbb.52.2014.09.01.22.04.31
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 01 Sep 2014 22:04:32 -0700 (PDT)
Date: Mon, 1 Sep 2014 22:04:30 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Message-ID: <etPan.54054fde.12200854.8aeb@mbp-3.local>
In-Reply-To: <CAOhmDzdepHQNGShgRJvrcd9Ta_odmEQGY8qwgEwTM3TCVFN6bg@mail.gmail.com>
References: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
 <etPan.540547a6.41b71efb.8aeb@mbp-3.local>
 <CAOhmDzdepHQNGShgRJvrcd9Ta_odmEQGY8qwgEwTM3TCVFN6bg@mail.gmail.com>
Subject: Re: Run the "Big Data Benchmark" for new releases
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54054fde_4db127f8_8aeb"
X-Virus-Checked: Checked by ClamAV on apache.org

--54054fde_4db127f8_8aeb
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Nope, actually, they didn't find that (they found some other things that =
were fixed, as well as some improvements). =46eel free to send a PR, but =
it would be good to profile the issue first to understand what slowed dow=
n. (=46or example is the map phase taking longer or is it the reduce phas=
e, is there some difference in lengths of specific tasks, etc).

Matei

On September 1, 2014 at 10:03:20 PM, Nicholas Chammas (nicholas.chammas=40=
gmail.com) wrote:

Oh, that's sweet. So, a related question then.=C2=A0

Did those tests pick up the performance issue reported in SPARK-3333=3F D=
oes it make sense to add a new test to cover that case=3F


On Tue, Sep 2, 2014 at 12:29 AM, Matei Zaharia <matei.zaharia=40gmail.com=
> wrote:
Hi Nicholas,

At Databricks we already run=C2=A0https://github.com/databricks/spark-per=
f for each release, which is a more comprehensive performance test suite.=


Matei

On September 1, 2014 at 8:22:05 PM, Nicholas Chammas (nicholas.chammas=40=
gmail.com) wrote:

What do people think of running the Big Data Benchmark
<https://amplab.cs.berkeley.edu/benchmark/> (repo
<https://github.com/amplab/benchmark>) as part of preparing every new
release of Spark=3F

We'd run it just for Spark and effectively use it as another type of test=

to track any performance progress or regressions from release to release.=


Would doing such a thing be valuable=3F Do we already have a way of
benchmarking Spark performance that we use regularly=3F

Nick


--54054fde_4db127f8_8aeb--


From dev-return-9207-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 05:07:37 2014
Return-Path: <dev-return-9207-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B8B16111BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 05:07:37 +0000 (UTC)
Received: (qmail 54879 invoked by uid 500); 2 Sep 2014 05:07:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54806 invoked by uid 500); 2 Sep 2014 05:07:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54794 invoked by uid 99); 2 Sep 2014 05:07:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:07:36 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:07:11 +0000
Received: by mail-ob0-f170.google.com with SMTP id m8so4443512obr.15
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 22:07:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=8inulKVlRpHTlhTOQjffST7YDoRL+Sf74QmYPHnRSSA=;
        b=Ew6e9/i+Fpynml0dHAUe4gAR6Ns7hot6yMVWG+6u98UTclD6uUw5zVDodwKB96vt3R
         Uv0ZrQWMK9ji9P/fcLKbt48PBQw3OdRBs+QMm3/yCouX8fyNxgUYB2QPd/AMVqKN1g1N
         pOfE1GijRi2AsUbPat00fhY3IYjpCrEYieWSfyC20fOxV8NJIIPhMMjtm/97u7cdWQcN
         aAi8iPkJOZRFxz2zh/Msk98IZb5ItqFlXuOdZ1PDuFa6yYVAj2LkL6w6YqibIMcILwzs
         DYKHQt2HtEU8fu3wRZwjvTB0u28JcLHJFKCZ3LBfjT/AsMieP8YDEVSpMyxFXW9eRLww
         HEUQ==
MIME-Version: 1.0
X-Received: by 10.182.29.200 with SMTP id m8mr29926521obh.13.1409634429888;
 Mon, 01 Sep 2014 22:07:09 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Mon, 1 Sep 2014 22:07:09 -0700 (PDT)
In-Reply-To: <etPan.54054fde.12200854.8aeb@mbp-3.local>
References: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
	<etPan.540547a6.41b71efb.8aeb@mbp-3.local>
	<CAOhmDzdepHQNGShgRJvrcd9Ta_odmEQGY8qwgEwTM3TCVFN6bg@mail.gmail.com>
	<etPan.54054fde.12200854.8aeb@mbp-3.local>
Date: Mon, 1 Sep 2014 22:07:09 -0700
Message-ID: <CABPQxsuT0kH8-4xyv4VaaMCXyPKrLRwovKFLQw=dERYbFOqXQA@mail.gmail.com>
Subject: Re: Run the "Big Data Benchmark" for new releases
From: Patrick Wendell <pwendell@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Yeah, this wasn't detected in our performance tests. We even have a
test in PySpark that I would have though might catch this (it just
schedules a bunch of really small tasks, similar to the regression
case).

https://github.com/databricks/spark-perf/blob/master/pyspark-tests/tests.py=
#L51

Anyways, Josh is trying to repro the regression to see if we can
figure out what is going on. If we find something for sure we should
add a test.

On Mon, Sep 1, 2014 at 10:04 PM, Matei Zaharia <matei.zaharia@gmail.com> wr=
ote:
> Nope, actually, they didn't find that (they found some other things that =
were fixed, as well as some improvements). Feel free to send a PR, but it w=
ould be good to profile the issue first to understand what slowed down. (Fo=
r example is the map phase taking longer or is it the reduce phase, is ther=
e some difference in lengths of specific tasks, etc).
>
> Matei
>
> On September 1, 2014 at 10:03:20 PM, Nicholas Chammas (nicholas.chammas@g=
mail.com) wrote:
>
> Oh, that's sweet. So, a related question then.
>
> Did those tests pick up the performance issue reported in SPARK-3333? Doe=
s it make sense to add a new test to cover that case?
>
>
> On Tue, Sep 2, 2014 at 12:29 AM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:
> Hi Nicholas,
>
> At Databricks we already run https://github.com/databricks/spark-perf for=
 each release, which is a more comprehensive performance test suite.
>
> Matei
>
> On September 1, 2014 at 8:22:05 PM, Nicholas Chammas (nicholas.chammas@gm=
ail.com) wrote:
>
> What do people think of running the Big Data Benchmark
> <https://amplab.cs.berkeley.edu/benchmark/> (repo
> <https://github.com/amplab/benchmark>) as part of preparing every new
> release of Spark?
>
> We'd run it just for Spark and effectively use it as another type of test
> to track any performance progress or regressions from release to release.
>
> Would doing such a thing be valuable? Do we already have a way of
> benchmarking Spark performance that we use regularly?
>
> Nick
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9208-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 05:57:49 2014
Return-Path: <dev-return-9208-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8CC8A112BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 05:57:49 +0000 (UTC)
Received: (qmail 18266 invoked by uid 500); 2 Sep 2014 05:57:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18200 invoked by uid 500); 2 Sep 2014 05:57:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18188 invoked by uid 99); 2 Sep 2014 05:57:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:57:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.47 as permitted sender)
Received: from [74.125.82.47] (HELO mail-wg0-f47.google.com) (74.125.82.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 05:57:43 +0000
Received: by mail-wg0-f47.google.com with SMTP id z12so6312584wgg.30
        for <dev@spark.apache.org>; Mon, 01 Sep 2014 22:57:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=r9o5lQJ5wbnL22pyStrO7AZzNni29FRM25WQZ2sJ9MU=;
        b=UHUlIbEvAY7th/iPdZsSc43thpaAUp4ExCsfHXSBe3UExWul8NbKzrI//ttAIVeo2W
         pXVcsyOZT091PJhPJHgogYKLI2qNO/7s36sjAwVQCdz6+lntetPild86WkARtLBjDWVj
         dCnSsyrZzK07XPXeAtGmyBU1gseuKvAsbEUwRggA516h7s8GLEXCyLTi1wvuBMjd+C9x
         kjG0biY7rENEIXyjLqTLKIho3pQGb8OhtuKQcdRaNPBKgFoMHedSkniZeSkz8dfsWkl2
         YANAzluIZ2jvSkTcYfhB8eaAY9nHkFmpjGZJ5c8RghopQSIVRtzPVnMai6hvmnWJ5qBy
         tktw==
X-Received: by 10.180.149.197 with SMTP id uc5mr25369534wib.75.1409637442548;
 Mon, 01 Sep 2014 22:57:22 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Mon, 1 Sep 2014 22:56:42 -0700 (PDT)
In-Reply-To: <CABPQxsuT0kH8-4xyv4VaaMCXyPKrLRwovKFLQw=dERYbFOqXQA@mail.gmail.com>
References: <CAOhmDzc+i26v71d3A4akG8TPqGRUip=ykAbKgLQg9bTsKrn9tw@mail.gmail.com>
 <etPan.540547a6.41b71efb.8aeb@mbp-3.local> <CAOhmDzdepHQNGShgRJvrcd9Ta_odmEQGY8qwgEwTM3TCVFN6bg@mail.gmail.com>
 <etPan.54054fde.12200854.8aeb@mbp-3.local> <CABPQxsuT0kH8-4xyv4VaaMCXyPKrLRwovKFLQw=dERYbFOqXQA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 2 Sep 2014 01:56:42 -0400
Message-ID: <CAOhmDzddkZKh1m6pfVRQLoWT6fKc99a_ktdd16sJwCnVA3YDkA@mail.gmail.com>
Subject: Re: Run the "Big Data Benchmark" for new releases
To: Patrick Wendell <pwendell@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c381140679f305020ecb6d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c381140679f305020ecb6d
Content-Type: text/plain; charset=UTF-8

Alright, sounds good! I've created databricks/spark-perf/issues/9
<https://github.com/databricks/spark-perf/issues/9> as a reminder for us to
add a new test once we've root caused SPARK-3333.


On Tue, Sep 2, 2014 at 1:07 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> Yeah, this wasn't detected in our performance tests. We even have a
> test in PySpark that I would have though might catch this (it just
> schedules a bunch of really small tasks, similar to the regression
> case).
>
>
> https://github.com/databricks/spark-perf/blob/master/pyspark-tests/tests.py#L51
>
> Anyways, Josh is trying to repro the regression to see if we can
> figure out what is going on. If we find something for sure we should
> add a test.
>
> On Mon, Sep 1, 2014 at 10:04 PM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Nope, actually, they didn't find that (they found some other things that
> were fixed, as well as some improvements). Feel free to send a PR, but it
> would be good to profile the issue first to understand what slowed down.
> (For example is the map phase taking longer or is it the reduce phase, is
> there some difference in lengths of specific tasks, etc).
> >
> > Matei
> >
> > On September 1, 2014 at 10:03:20 PM, Nicholas Chammas (
> nicholas.chammas@gmail.com) wrote:
> >
> > Oh, that's sweet. So, a related question then.
> >
> > Did those tests pick up the performance issue reported in SPARK-3333?
> Does it make sense to add a new test to cover that case?
> >
> >
> > On Tue, Sep 2, 2014 at 12:29 AM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Hi Nicholas,
> >
> > At Databricks we already run https://github.com/databricks/spark-perf
> for each release, which is a more comprehensive performance test suite.
> >
> > Matei
> >
> > On September 1, 2014 at 8:22:05 PM, Nicholas Chammas (
> nicholas.chammas@gmail.com) wrote:
> >
> > What do people think of running the Big Data Benchmark
> > <https://amplab.cs.berkeley.edu/benchmark/> (repo
> > <https://github.com/amplab/benchmark>) as part of preparing every new
> > release of Spark?
> >
> > We'd run it just for Spark and effectively use it as another type of test
> > to track any performance progress or regressions from release to release.
> >
> > Would doing such a thing be valuable? Do we already have a way of
> > benchmarking Spark performance that we use regularly?
> >
> > Nick
> >
>

--001a11c381140679f305020ecb6d--

From dev-return-9209-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 07:00:31 2014
Return-Path: <dev-return-9209-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 43F6E11425
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 07:00:31 +0000 (UTC)
Received: (qmail 22398 invoked by uid 500); 2 Sep 2014 07:00:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22325 invoked by uid 500); 2 Sep 2014 07:00:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 4547 invoked by uid 99); 2 Sep 2014 06:46:38 -0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of niranda@wso2.com designates 209.85.214.172 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=wso2.com; s=google;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=KvjL/91O6BsJ5h57qAdpWTO14J0QvT6vSOYt66cfOdU=;
        b=C7Hxsjug1UKcFLJrm9vTDutX0s22vH8Ckda6QLATmqUwRkdSlRTT82pvqpU3sNhIkX
         ZUwW41Q9Mef4ZmNPH9e4YpzKB+CeCO6biD6rj+n5U0WVafm/vWnAZfHDMTczquTXbpAE
         sXvQZWzVUCMOMU1Zs+Pa2CDeWBiEw5TLOVvf0=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=KvjL/91O6BsJ5h57qAdpWTO14J0QvT6vSOYt66cfOdU=;
        b=Co9uHa2k4ZQmrVMQZ/dKQ9qE6tI8Ag28I/FIDTbspcZ7F/rzfOuwJTX/+iIm1jy8XW
         MLe/r17mPcnlfKFsxK6XrzilHzPIRYmBBiCVLAnSRqRaxGtey0JtDltglRXa8W2y/BVm
         wIH8DyE0PmsYKrww9I+JbAQyhCcPKFO/q7cGyeETAnYBqRL3DIPMJOLzuxrHRRF5KOXk
         YZ0VWag6DYh1/QbbsqViXJ+kNjz38uy620YCpBK2PDuPsHmhjpQJ95mWrBqsq9qnCJnp
         uvuB+wfdyoq0E86ZDAujnIs8HS5kflGHGmMjeACSDTdkqni73ugTYoxUwRgZAWfEn5vQ
         hJTQ==
X-Gm-Message-State: ALoCoQnv8G8q7PseUFzWnbLRdY7U0dHareokmNLtRG8DXjhFucjJyg1aSIwQSvigVp+NEq/7GIb/
X-Received: by 10.182.24.101 with SMTP id t5mr29419383obf.31.1409640369758;
 Mon, 01 Sep 2014 23:46:09 -0700 (PDT)
MIME-Version: 1.0
From: Niranda Perera <niranda@wso2.com>
Date: Tue, 2 Sep 2014 12:15:49 +0530
Message-ID: <CADz3zK3OY2tXrcKVXgNtad2oSNUJ0=y0a2k+A-2GVC9mK3D9og@mail.gmail.com>
Subject: Getting the execution times of spark job
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2a1d48033a205020f7978
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2a1d48033a205020f7978
Content-Type: text/plain; charset=UTF-8

Hi,

I have been playing around with spark for a couple of days. I am
using spark-1.0.1-bin-hadoop1 and the Java API. The main idea of the
implementation is to run Hive queries on Spark. I used JavaHiveContext to
achieve this (As per the examples).

I have 2 questions.
1. I am wondering how I could get the execution times of a spark job? Does
Spark provide monitoring facilities in the form of an API?

2. I used a laymen way to get the execution times by enclosing a
JavaHiveContext.hql method with System.nanoTime() as follows

long start, end;
JavaHiveContext hiveCtx;
JavaSchemaRDD hiveResult;

start = System.nanoTime();
hiveResult = hiveCtx.hql(query);
end = System.nanoTime();
System.out.println(start-end);

But the result I got is drastically different from the execution times
recorded in SparkUI. Can you please explain this disparity?

Look forward to hearing from you.

rgds

-- 
*Niranda Perera*
Software Engineer, WSO2 Inc.
Mobile: +94-71-554-8430
Twitter: @n1r44 <https://twitter.com/N1R44>

--001a11c2a1d48033a205020f7978--

From dev-return-9210-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 07:09:43 2014
Return-Path: <dev-return-9210-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8EA1F11461
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 07:09:43 +0000 (UTC)
Received: (qmail 41737 invoked by uid 500); 2 Sep 2014 07:09:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41675 invoked by uid 500); 2 Sep 2014 07:09:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41663 invoked by uid 99); 2 Sep 2014 07:09:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 07:09:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of concretevitamin@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 07:09:11 +0000
Received: by mail-wg0-f45.google.com with SMTP id k14so6266186wgh.28
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 00:09:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=bDEzeTIC/UKHcHPjDPEbnQbWlddSjySEvd+diUb6SAA=;
        b=xTj8jz2PMjU6FnmTixb7gMLLPLJ+SDzDiBACkmKKbQVsbX2UaraCgOVbyRdlA60Mpi
         80V92xq7DJPGKggk9k7JGVf4LsnREFNHpZjfOGdaKbOOLrVJyh/ds2KeaVzwejTeebKO
         lju1injVOsRFQMJipVVMzAN1F6vzH2rT+h/1CZ2q9kNxxmnd+cHjCN5aZtpGXA0IQy+F
         rs8SnA349NC/5oYdCcyvtezSdSBg0WwH5yx8n2eoEcnOQlG25ge5uP//YhZyybh31V/U
         yG/beqb0EEFcBt5Q3jkXGDdNRprrYt+qumVoKndj4fYqCjl1eNAZFyypCit5Q/VrR9pu
         lqcA==
MIME-Version: 1.0
X-Received: by 10.180.24.35 with SMTP id r3mr25930457wif.71.1409641751187;
 Tue, 02 Sep 2014 00:09:11 -0700 (PDT)
Sender: concretevitamin@gmail.com
Received: by 10.216.62.129 with HTTP; Tue, 2 Sep 2014 00:09:11 -0700 (PDT)
In-Reply-To: <CADz3zK3OY2tXrcKVXgNtad2oSNUJ0=y0a2k+A-2GVC9mK3D9og@mail.gmail.com>
References: <CADz3zK3OY2tXrcKVXgNtad2oSNUJ0=y0a2k+A-2GVC9mK3D9og@mail.gmail.com>
Date: Tue, 2 Sep 2014 00:09:11 -0700
X-Google-Sender-Auth: ad8x7cKn0cBZUlhM06lyy9HCUio
Message-ID: <CAG2+eoicqyoy=soJYy7cv1Y2ibQurv5CuoXjtpVc_+MsKzXw8A@mail.gmail.com>
Subject: Re: Getting the execution times of spark job
From: Zongheng Yang <zongheng.y@gmail.com>
To: Niranda Perera <niranda@wso2.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

For your second question: hql() (as well as sql()) does not launch a
Spark job immediately; instead, it fires off the Spark SQL
parser/optimizer/planner pipeline first, and a Spark job will be
started after the a physical execution plan is selected. Therefore,
your hand-rolled end-to-end measurement includes the time to go
through the Spark SQL code path, and the times reported inside the UI
are the execution times of the Spark job(s) only.

On Mon, Sep 1, 2014 at 11:45 PM, Niranda Perera <niranda@wso2.com> wrote:
> Hi,
>
> I have been playing around with spark for a couple of days. I am
> using spark-1.0.1-bin-hadoop1 and the Java API. The main idea of the
> implementation is to run Hive queries on Spark. I used JavaHiveContext to
> achieve this (As per the examples).
>
> I have 2 questions.
> 1. I am wondering how I could get the execution times of a spark job? Does
> Spark provide monitoring facilities in the form of an API?
>
> 2. I used a laymen way to get the execution times by enclosing a
> JavaHiveContext.hql method with System.nanoTime() as follows
>
> long start, end;
> JavaHiveContext hiveCtx;
> JavaSchemaRDD hiveResult;
>
> start = System.nanoTime();
> hiveResult = hiveCtx.hql(query);
> end = System.nanoTime();
> System.out.println(start-end);
>
> But the result I got is drastically different from the execution times
> recorded in SparkUI. Can you please explain this disparity?
>
> Look forward to hearing from you.
>
> rgds
>
> --
> *Niranda Perera*
> Software Engineer, WSO2 Inc.
> Mobile: +94-71-554-8430
> Twitter: @n1r44 <https://twitter.com/N1R44>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9211-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 07:59:59 2014
Return-Path: <dev-return-9211-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9C4E011597
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 07:59:59 +0000 (UTC)
Received: (qmail 60663 invoked by uid 500); 2 Sep 2014 07:59:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60591 invoked by uid 500); 2 Sep 2014 07:59:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60577 invoked by uid 99); 2 Sep 2014 07:59:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 07:59:56 +0000
X-ASF-Spam-Status: No, hits=4.4 required=10.0
	tests=HK_RANDOM_ENVFROM,HK_RANDOM_FROM,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of huaiyin.thu@gmail.com designates 209.85.217.178 as permitted sender)
Received: from [209.85.217.178] (HELO mail-lb0-f178.google.com) (209.85.217.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 07:59:52 +0000
Received: by mail-lb0-f178.google.com with SMTP id v6so7142907lbi.9
        for <dev@spark.incubator.apache.org>; Tue, 02 Sep 2014 00:59:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=/Et/oKgyy2V2yET0dSXNLwCktf2twvhiGootQme95Lw=;
        b=KxvVZZPo/zBWVELzzzcs8xHgBCBTsH+veaj8LQkKhHVj27tBZvs6z59tcGyrimVijR
         XXS2GlWsYY5gcaLDaDo9PQi5uc1KUiwdp2vLdARrZSkaPrx7baFxV091NFBMppNOt8ln
         1wIEzAiijWkepYoia5TDWSPVC7lKVRVRyz+gPJK8PYKlWLrzG/hmDEG01qArMw8i7HME
         cAith9T1/Qgyk/SgVpGeJqsgbj49/QNiUf8/zpsYXtshpdiuk7DiZ4crArN/1mHKOMPz
         E2U+Ky/GsPAAS5SidZDWk+LHgl95Lwm1350muWP5n3glGx23YwhpDEHECa+cfQq58fsW
         tAdQ==
X-Received: by 10.112.24.104 with SMTP id t8mr26729870lbf.46.1409644770965;
 Tue, 02 Sep 2014 00:59:30 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.7.166 with HTTP; Tue, 2 Sep 2014 00:59:10 -0700 (PDT)
In-Reply-To: <1408712873055-7955.post@n3.nabble.com>
References: <1408467214979-7914.post@n3.nabble.com> <1408620901005-7937.post@n3.nabble.com>
 <C434A3773D08A842B26FED6A1BA2E6546D155857@SJCEML702-CHM.china.huawei.com> <1408712873055-7955.post@n3.nabble.com>
From: Yin Huai <huaiyin.thu@gmail.com>
Date: Tue, 2 Sep 2014 15:59:10 +0800
Message-ID: <CAOSFW12YnGCe9kBUGZ4VdeH2wNpVBJiDGQ5ZZJsbHka37G49Jg@mail.gmail.com>
Subject: Re: Spark SQL Query and join different data sources.
To: chutium <teng.qiu@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11344544d540870502107fa8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11344544d540870502107fa8
Content-Type: text/plain; charset=UTF-8

Actually, with HiveContext, you can join hive tables with registered
temporary tables.


On Fri, Aug 22, 2014 at 9:07 PM, chutium <teng.qiu@gmail.com> wrote:

> oops, thanks Yan, you are right, i got
>
> scala> sqlContext.sql("select * from a join b").take(10)
> java.lang.RuntimeException: Table Not Found: b
>         at scala.sys.package$.error(package.scala:27)
>         at
>
> org.apache.spark.sql.catalyst.analysis.SimpleCatalog$$anonfun$1.apply(Catalog.scala:90)
>         at
>
> org.apache.spark.sql.catalyst.analysis.SimpleCatalog$$anonfun$1.apply(Catalog.scala:90)
>         at scala.Option.getOrElse(Option.scala:120)
>         at
>
> org.apache.spark.sql.catalyst.analysis.SimpleCatalog.lookupRelation(Catalog.scala:90)
>
> and with hql
>
> scala> hiveContext.hql("select * from a join b").take(10)
> warning: there were 1 deprecation warning(s); re-run with -deprecation for
> details
> 14/08/22 14:48:45 INFO parse.ParseDriver: Parsing command: select * from a
> join b
> 14/08/22 14:48:45 INFO parse.ParseDriver: Parse Completed
> 14/08/22 14:48:45 ERROR metadata.Hive:
> NoSuchObjectException(message:default.a table not found)
>         at
>
> org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_result$get_table_resultStandardScheme.read(ThriftHiveMetastore.java:27129)
>         at
>
> org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_result$get_table_resultStandardScheme.read(ThriftHiveMetastore.java:27097)
>         at
>
> org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_result.read(ThriftHiveMetastore.java:27028)
>         at
> org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
>         at
>
> org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table(ThriftHiveMetastore.java:936)
>         at
>
> org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table(ThriftHiveMetastore.java:922)
>         at
>
> org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:854)
>         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>         at
>
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
>         at
>
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
>         at java.lang.reflect.Method.invoke(Method.java:601)
>         at
>
> org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)
>         at com.sun.proxy.$Proxy17.getTable(Unknown Source)
>         at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:950)
>         at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:924)
>         at
>
> org.apache.spark.sql.hive.HiveMetastoreCatalog.lookupRelation(HiveMetastoreCatalog.scala:59)
>
>
> so sqlContext is looking up table from
> org.apache.spark.sql.catalyst.analysis.SimpleCatalog, Catalog.scala
> hiveContext looking up from org.apache.spark.sql.hive.HiveMetastoreCatalog,
> HiveMetastoreCatalog.scala
>
> maybe we can do something in sqlContext to register a hive table as
> Spark-SQL-Table, need to read column info, partition info, location, SerDe,
> Input/OutputFormat and maybe StorageHandler also, from the hive
> metastore...
>
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-Query-and-join-different-data-sources-tp7914p7955.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11344544d540870502107fa8--

From dev-return-9212-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 08:39:46 2014
Return-Path: <dev-return-9212-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8D40B1167A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 08:39:46 +0000 (UTC)
Received: (qmail 12169 invoked by uid 500); 2 Sep 2014 08:39:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12099 invoked by uid 500); 2 Sep 2014 08:39:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12084 invoked by uid 99); 2 Sep 2014 08:39:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 08:39:45 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wangfei1@huawei.com designates 119.145.14.64 as permitted sender)
Received: from [119.145.14.64] (HELO szxga01-in.huawei.com) (119.145.14.64)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 08:39:39 +0000
Received: from 172.24.2.119 (EHLO szxeml461-hub.china.huawei.com) ([172.24.2.119])
	by szxrg01-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id CBD15257;
	Tue, 02 Sep 2014 16:39:17 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml461-hub.china.huawei.com
 (10.82.67.204) with Microsoft SMTP Server id 14.3.158.1; Tue, 2 Sep 2014
 16:39:12 +0800
Message-ID: <54058224.3030909@huawei.com>
Date: Tue, 2 Sep 2014 16:39:00 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: about spark assembly jar
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

hi, all
   I suggest spark not use assembly jar as default run-time dependency(spark-submit/spark-class depend on assembly jar),use a library of all 3rd dependency jar like hadoop/hive/hbase more reasonable.

   1 assembly jar packaged all 3rd jars into a big one, so we need rebuild this jar if we want to update the version of some component(such as hadoop)
   2 in our practice with spark, sometimes we meet jar compatibility issue, it is hard to diagnose compatibility issue with assembly jar







---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9213-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 08:46:11 2014
Return-Path: <dev-return-9213-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 41B97116AB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 08:46:11 +0000 (UTC)
Received: (qmail 18378 invoked by uid 500); 2 Sep 2014 08:46:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18303 invoked by uid 500); 2 Sep 2014 08:46:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18292 invoked by uid 99); 2 Sep 2014 08:46:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 08:46:09 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 08:45:44 +0000
Received: by mail-ie0-f180.google.com with SMTP id rl12so7314376iec.11
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 01:45:42 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=NsXTLypLWZJ37sBFl6EEwHVzL6ayldvSAGQn4irri7E=;
        b=RerGSz1jBeqgGsgdtnv2NGum4CG92Uu95vALu0F94MQiVWI1f3kF037fuXVbvHy1az
         xHjjs23MMxtN2ESm7txLFLB043oEjIV65BqXfsVG/gVp+rRzYuITLhzY4PVjNOkoWP3q
         UKwINyJ2oXxIA+J+oUOnD8Lfax29KD1qI/df+CzOI0+510q4HlkD/TAyNzA+UL7F0qw8
         VfMywFTXiQOT8TILvS+MFmKHJOTtopHH0XQ/vfdGIOHNtN6KIQV6cPmam9l7cgToDhGW
         8ztWUxCYt0h2nJLhtBfuTvW5TLkv9di/svx/nuK4B/ng5VCYR87KoGKaQX8NVP/ZMgIM
         y9zQ==
X-Gm-Message-State: ALoCoQlFHvosmOYkeV3OUaBPG4iYwfv6elFXuL1Y+Ty6lzFoyJJm7JgQ0r5s6x1ySIj7i5x1hwkR
X-Received: by 10.50.108.103 with SMTP id hj7mr26541598igb.5.1409647542461;
 Tue, 02 Sep 2014 01:45:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Tue, 2 Sep 2014 01:45:22 -0700 (PDT)
In-Reply-To: <54058224.3030909@huawei.com>
References: <54058224.3030909@huawei.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 2 Sep 2014 09:45:22 +0100
Message-ID: <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
Subject: Re: about spark assembly jar
To: scwf <wangfei1@huawei.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hm, are you suggesting that the Spark distribution be a bag of 100
JARs? It doesn't quite seem reasonable. It does not remove version
conflicts, just pushes them to run-time, which isn't good. The
assembly is also necessary because that's where shading happens. In
development, you want to run against exactly what will be used in a
real Spark distro.

On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
> hi, all
>   I suggest spark not use assembly jar as default run-time
> dependency(spark-submit/spark-class depend on assembly jar),use a library of
> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
>
>   1 assembly jar packaged all 3rd jars into a big one, so we need rebuild
> this jar if we want to update the version of some component(such as hadoop)
>   2 in our practice with spark, sometimes we meet jar compatibility issue,
> it is hard to diagnose compatibility issue with assembly jar
>
>
>
>
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9214-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 09:03:05 2014
Return-Path: <dev-return-9214-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F1F5116FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 09:03:05 +0000 (UTC)
Received: (qmail 41232 invoked by uid 500); 2 Sep 2014 09:02:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41164 invoked by uid 500); 2 Sep 2014 09:02:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41153 invoked by uid 99); 2 Sep 2014 09:02:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:02:57 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wangfei1@huawei.com designates 119.145.14.65 as permitted sender)
Received: from [119.145.14.65] (HELO szxga02-in.huawei.com) (119.145.14.65)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:02:32 +0000
Received: from 172.24.2.119 (EHLO szxeml406-hub.china.huawei.com) ([172.24.2.119])
	by szxrg02-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id BYY18399;
	Tue, 02 Sep 2014 17:01:43 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml406-hub.china.huawei.com
 (10.82.67.93) with Microsoft SMTP Server id 14.3.158.1; Tue, 2 Sep 2014
 17:01:41 +0800
Message-ID: <54058774.4070005@huawei.com>
Date: Tue, 2 Sep 2014 17:01:40 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: Sean Owen <sowen@cloudera.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: about spark assembly jar
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
In-Reply-To: <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

yes, i am not sure what happens when building assembly jar and in my understanding it just package all the dependency jars to a big one.

On 2014/9/2 16:45, Sean Owen wrote:
> Hm, are you suggesting that the Spark distribution be a bag of 100
> JARs? It doesn't quite seem reasonable. It does not remove version
> conflicts, just pushes them to run-time, which isn't good. The
> assembly is also necessary because that's where shading happens. In
> development, you want to run against exactly what will be used in a
> real Spark distro.
>
> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
>> hi, all
>>    I suggest spark not use assembly jar as default run-time
>> dependency(spark-submit/spark-class depend on assembly jar),use a library of
>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
>>
>>    1 assembly jar packaged all 3rd jars into a big one, so we need rebuild
>> this jar if we want to update the version of some component(such as hadoop)
>>    2 in our practice with spark, sometimes we meet jar compatibility issue,
>> it is hard to diagnose compatibility issue with assembly jar
>>
>>
>>
>>
>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
>



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9215-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 09:09:50 2014
Return-Path: <dev-return-9215-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0BB561171A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 09:09:50 +0000 (UTC)
Received: (qmail 57447 invoked by uid 500); 2 Sep 2014 09:09:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57369 invoked by uid 500); 2 Sep 2014 09:09:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57357 invoked by uid 99); 2 Sep 2014 09:09:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:09:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of advancedxy@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:09:44 +0000
Received: by mail-pa0-f44.google.com with SMTP id rd3so14374625pab.31
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 02:09:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=CIliPI2+X075G9hRMHXtDilK1E6vbmpXijWjmCtztQY=;
        b=rTj6XjC2zq1iqkejE8D906lGwUeUyaHMCUBNIVN57NrBT/N8Cu/S7BtbtaUmJpatkO
         UZ3iu6s51Ryio1LQzzchuVwRJ98QlX/LEypClG3zL/kiduBDjfva6rHa34bKrs3EUXrS
         nZE9MJlFpajQEVkNO4tBQ9U6YE/KJmMXnwxE2utDqwPPfhhb18xskynwOH1KIFNeqF0I
         MnPqHik6ybj+rNewjeMtuGerFCeTh+SRhxa6f6MMV5X7h4VM4ipPh26CxwxK27DC7v/X
         laLob7uknFwjoYbtZl2TxRN6B6TwWKkHKdX86/CUutxsJ3NhGt8JMc85oWvrr9YaLfvO
         2LgQ==
X-Received: by 10.66.102.68 with SMTP id fm4mr46081158pab.46.1409648962525;
        Tue, 02 Sep 2014 02:09:22 -0700 (PDT)
Received: from [172.16.100.191] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id ty8sm9846474pab.26.2014.09.02.02.09.17
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 02 Sep 2014 02:09:21 -0700 (PDT)
Date: Tue, 2 Sep 2014 17:09:10 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev@spark.apache.org
Message-ID: <98646434E693400B84D080F3CA10AF7C@gmail.com>
In-Reply-To: <CAMAsSdJpT8r93Uzw8Sj4i2s8+2gT4MeuMhmqP+01Vws10G6z6A@mail.gmail.com>
References: <54058224.3030909@huawei.com>
 <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
 <56C78C34497A47A6B846714787EBE5CE@gmail.com>
 <CAMAsSdJpT8r93Uzw8Sj4i2s8+2gT4MeuMhmqP+01Vws10G6z6A@mail.gmail.com>
Subject: Re: about spark assembly jar
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54058936_8edbdab_e9"
X-Virus-Checked: Checked by ClamAV on apache.org

--54058936_8edbdab_e9
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Sorry, The quick reply didn't cc the dev list.

Sean, sometimes I have to use the spark-shell to confirm some behavior change. In that case, I have to reassembly the whole project.  is there another way around, not use the the big jar in development? For the original question, I have no comments. 

-- 
Ye Xianjin
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)


On Tuesday, September 2, 2014 at 4:58 PM, Sean Owen wrote:

> No, usually you unit-test your changes during development. That
> doesn't require the assembly. Eventually you may wish to test some
> change against the complete assembly.
> 
> But that's a different question; I thought you were suggesting that
> the assembly JAR should never be created.
> 
> On Tue, Sep 2, 2014 at 9:53 AM, Ye Xianjin <advancedxy@gmail.com (mailto:advancedxy@gmail.com)> wrote:
> > Hi, Sean:
> > In development, do I really need to reassembly the whole project even if I
> > only change a line or two code in one component?
> > I used to that but found time-consuming.
> > 
> > --
> > Ye Xianjin
> > Sent with Sparrow
> > 
> > On Tuesday, September 2, 2014 at 4:45 PM, Sean Owen wrote:
> > 
> > Hm, are you suggesting that the Spark distribution be a bag of 100
> > JARs? It doesn't quite seem reasonable. It does not remove version
> > conflicts, just pushes them to run-time, which isn't good. The
> > assembly is also necessary because that's where shading happens. In
> > development, you want to run against exactly what will be used in a
> > real Spark distro.
> > 
> > On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com (mailto:wangfei1@huawei.com)> wrote:
> > 
> > hi, all
> > I suggest spark not use assembly jar as default run-time
> > dependency(spark-submit/spark-class depend on assembly jar),use a library of
> > all 3rd dependency jar like hadoop/hive/hbase more reasonable.
> > 
> > 1 assembly jar packaged all 3rd jars into a big one, so we need rebuild
> > this jar if we want to update the version of some component(such as hadoop)
> > 2 in our practice with spark, sometimes we meet jar compatibility issue,
> > it is hard to diagnose compatibility issue with assembly jar
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
> > For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
> > 
> > 
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
> > For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
> > 
> 
> 
> 



--54058936_8edbdab_e9--


From dev-return-9216-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 09:12:46 2014
Return-Path: <dev-return-9216-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1B94D11735
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 09:12:46 +0000 (UTC)
Received: (qmail 62824 invoked by uid 500); 2 Sep 2014 09:12:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62755 invoked by uid 500); 2 Sep 2014 09:12:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62744 invoked by uid 99); 2 Sep 2014 09:12:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:12:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wangfei1@huawei.com designates 119.145.14.65 as permitted sender)
Received: from [119.145.14.65] (HELO szxga02-in.huawei.com) (119.145.14.65)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 09:12:18 +0000
Received: from 172.24.2.119 (EHLO szxeml457-hub.china.huawei.com) ([172.24.2.119])
	by szxrg02-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id BYY19972;
	Tue, 02 Sep 2014 17:12:15 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml457-hub.china.huawei.com
 (10.82.67.200) with Microsoft SMTP Server id 14.3.158.1; Tue, 2 Sep 2014
 17:12:09 +0800
Message-ID: <540589E8.8020107@huawei.com>
Date: Tue, 2 Sep 2014 17:12:08 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: Sean Owen <sowen@cloudera.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: about spark assembly jar
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
In-Reply-To: <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

Hi sean owen,
here are some problems when i used assembly jar
1 i put spark-assembly-*.jar to the lib directory of my application, it throw compile error

Error:scalac: Error: class scala.reflect.BeanInfo not found.
scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanInfo not found.

	at scala.tools.nsc.symtab.Definitions$definitions$.getModuleOrClass(Definitions.scala:655)

	at scala.tools.nsc.symtab.Definitions$definitions$.getClass(Definitions.scala:608)

	at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<init>(GenJVM.scala:127)

	at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.scala:85)

	at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)

	at scala.tools.nsc.Global$Run.compile(Global.scala:1041)

	at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)

	at xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)

	at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)

	at xsbt.CompilerInterface.run(CompilerInterface.scala:27)

	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)

	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)

	at java.lang.reflect.Method.invoke(Method.java:597)

	at sbt.compiler.AnalyzingCompiler.call(AnalyzingCompiler.scala:102)

	at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:48)

	at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:41)

	at org.jetbrains.jps.incremental.scala.local.IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)

	at org.jetbrains.jps.incremental.scala.local.LocalServer.compile(LocalServer.scala:25)

	at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.scala:58)

	at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(Main.scala:21)

	at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(Main.scala)

	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)

	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)

	at java.lang.reflect.Method.invoke(Method.java:597)

	at com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
2 i test my branch which updated hive version to org.apache.hive 0.13.1
   it run successfully when use a bag of 3rd jars as dependency but throw error using assembly jar, it seems assembly jar lead to conflict
   ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
         at org.apache.hadoop.hive.ql.io.parquet.serde.ArrayWritableObjectInspector.getObjectInspector(ArrayWritableObjectInspector.java:66)
         at org.apache.hadoop.hive.ql.io.parquet.serde.ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
         at org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
         at org.apache.hadoop.hive.metastore.MetaStoreUtils.getDeserializer(MetaStoreUtils.java:339)
         at org.apache.hadoop.hive.ql.metadata.Table.getDeserializerFromMetaStore(Table.java:283)
         at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(Table.java:189)
         at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:597)
         at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4194)
         at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:281)
         at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
         at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)




On 2014/9/2 16:45, Sean Owen wrote:
> Hm, are you suggesting that the Spark distribution be a bag of 100
> JARs? It doesn't quite seem reasonable. It does not remove version
> conflicts, just pushes them to run-time, which isn't good. The
> assembly is also necessary because that's where shading happens. In
> development, you want to run against exactly what will be used in a
> real Spark distro.
>
> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
>> hi, all
>>    I suggest spark not use assembly jar as default run-time
>> dependency(spark-submit/spark-class depend on assembly jar),use a library of
>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
>>
>>    1 assembly jar packaged all 3rd jars into a big one, so we need rebuild
>> this jar if we want to update the version of some component(such as hadoop)
>>    2 in our practice with spark, sometimes we meet jar compatibility issue,
>> it is hard to diagnose compatibility issue with assembly jar
>>
>>
>>
>>
>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
>



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9217-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 15:09:03 2014
Return-Path: <dev-return-9217-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C71A61122B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 15:09:03 +0000 (UTC)
Received: (qmail 28027 invoked by uid 500); 2 Sep 2014 15:09:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27961 invoked by uid 500); 2 Sep 2014 15:09:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27945 invoked by uid 99); 2 Sep 2014 15:09:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 15:09:02 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wibenton@redhat.com designates 209.132.183.24 as permitted sender)
Received: from [209.132.183.24] (HELO mx3-phx2.redhat.com) (209.132.183.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 15:08:58 +0000
Received: from zmail14.collab.prod.int.phx2.redhat.com (zmail14.collab.prod.int.phx2.redhat.com [10.5.83.16])
	by mx3-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s82F8Zij017548;
	Tue, 2 Sep 2014 11:08:35 -0400
Date: Tue, 2 Sep 2014 11:08:33 -0400 (EDT)
From: Will Benton <willb@redhat.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, dev@spark.apache.org
Message-ID: <2114029789.49829460.1409670513127.JavaMail.zimbra@redhat.com>
In-Reply-To: <CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com> <CAMAsSdKpzGdGTYOyzKxnTq-U=hStDPPSGhXxvrhSBAvp2XrgFQ@mail.gmail.com> <1549011493.48644371.1409505081207.JavaMail.zimbra@redhat.com> <CAMAsSdL732rYb1ARy=anxUQRJoFBAndKD1otkW69RRDLXYDZwQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.6]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - FF31 (Mac)/8.0.6_GA_5922)
Thread-Topic: Release Apache Spark 1.1.0 (RC3)
Thread-Index: guEfZJ4yjBY7aE/OyR6kpf1ROByB7Q==
X-Virus-Checked: Checked by ClamAV on apache.org

Zongheng pointed out in my SPARK-3329 PR (https://github.com/apache/spark/pull/2220) that Aaron had already fixed this issue but that it had gotten inadvertently clobbered by another patch.  I don't know how the project handles this kind of problem, but I've rewritten my SPARK-3329 branch to cherry-pick Aaron's fix (also fixing a merge conflict and handling a test case that it didn't).

The other weird spurious testsuite failures related to orderings I've seen were in "DESCRIBE FUNCTION EXTENDED" for functions with lists of synonyms (e.g. STDDEV).  I can't reproduce those now but will take another look later this week.



best,
wb

----- Original Message -----
> From: "Sean Owen" <sowen@cloudera.com>
> To: "Will Benton" <willb@redhat.com>
> Cc: "Patrick Wendell" <pwendell@gmail.com>, dev@spark.apache.org
> Sent: Sunday, August 31, 2014 12:18:42 PM
> Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
> 
> Fantastic. As it happens, I just fixed up Mahout's tests for Java 8
> and observed a lot of the same type of failure.
> 
> I'm about to submit PRs for the two issues I identified. AFAICT these
> 3 then cover the failures I mentioned:
> 
> https://issues.apache.org/jira/browse/SPARK-3329
> https://issues.apache.org/jira/browse/SPARK-3330
> https://issues.apache.org/jira/browse/SPARK-3331
> 
> I'd argue that none necessarily block a release, since they just
> represent a problem with test-only code in Java 8, with the test-only
> context of Jenkins and multiple profiles, and with a trivial
> configuration in a style check for Python. Should be fixed but none
> indicate a bug in the release.
> 
> On Sun, Aug 31, 2014 at 6:11 PM, Will Benton <willb@redhat.com> wrote:
> > ----- Original Message -----
> >
> >> dev/run-tests fails two tests (1 Hive, 1 Kafka Streaming) for me
> >> locally on 1.1.0-rc3. Does anyone else see that? It may be my env.
> >> Although I still see the Hive failure on Debian too:
> >>
> >> [info] - SET commands semantics for a HiveContext *** FAILED ***
> >> [info]   Expected Array("spark.sql.key.usedfortestonly=test.val.0",
> >> "spark.sql.key.usedfortestonlyspark.sql.key.usedfortestonly=test.val.0test.val.0"),
> >> but got
> >> Array("spark.sql.key.usedfortestonlyspark.sql.key.usedfortestonly=test.val.0test.val.0",
> >> "spark.sql.key.usedfortestonly=test.val.0") (HiveQuerySuite.scala:541)
> >
> > I've seen this error before.  (In particular, I've seen it on my OS X
> > machine using Oracle JDK 8 but not on Fedora using OpenJDK.)  I've also
> > seen similar errors in topic branches (but not on master) that seem to
> > indicate that tests depend on sets of pairs arriving from Hive in a
> > particular order; it seems that this isn't a safe assumption.
> >
> > I just submitted a (trivial) PR to fix this spurious failure:
> > https://github.com/apache/spark/pull/2220
> >
> >
> > best,
> > wb
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9218-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 16:10:45 2014
Return-Path: <dev-return-9218-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7794811461
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 16:10:45 +0000 (UTC)
Received: (qmail 80191 invoked by uid 500); 2 Sep 2014 16:10:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80124 invoked by uid 500); 2 Sep 2014 16:10:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80113 invoked by uid 99); 2 Sep 2014 16:10:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 16:10:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.192.54 as permitted sender)
Received: from [209.85.192.54] (HELO mail-qg0-f54.google.com) (209.85.192.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 16:10:18 +0000
Received: by mail-qg0-f54.google.com with SMTP id q107so6841256qgd.13
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 09:10:16 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=S+JFtrFLZdPVDFYc/Tb4VVNeLMWjAUKVPVX6zEx2gY4=;
        b=aFGslKsqc33SpDgWWPyYHL0DKt7rMni8FCWslEYF22qZLb2C4nZPZjeXX+yKzqf20I
         yHP2zDJIyjp+rCzoBHAGppo0TxhlKhzeVh6+nH25xhZ7jxkfKDnecJ1BD3+kuYUAl5cM
         4I3megSzUkPx1fccxD92nTB4yJW4yclWZX/EyHUWL14qISOBQ/psmMxUwWfU9Kl/5e5C
         FenxhaqOzqj8YVH0wejskptbdj0tANARi1vBwcBx+k0bsoJpRzTrFoiGhWeFnd6Rhqs0
         GxjWl4aF+rUssdbkpSE1wMObTn4ZHTd4oc74G0S3/GG6qBaFEuh2H5gJ0b9GXDciJOSb
         JKVw==
X-Gm-Message-State: ALoCoQl34cXa3DOoox9szW7W3hG3b6+xCkBoUIVFJ8mYNLi/wemMPQl+1YDD7cXNGwReFgF0SGcM
MIME-Version: 1.0
X-Received: by 10.140.19.100 with SMTP id 91mr8334624qgg.32.1409674216737;
 Tue, 02 Sep 2014 09:10:16 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Tue, 2 Sep 2014 09:10:16 -0700 (PDT)
In-Reply-To: <540589E8.8020107@huawei.com>
References: <54058224.3030909@huawei.com>
	<CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
	<540589E8.8020107@huawei.com>
Date: Tue, 2 Sep 2014 09:10:16 -0700
Message-ID: <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
Subject: Re: about spark assembly jar
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: scwf <wangfei1@huawei.com>
Cc: Sean Owen <sowen@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1135637ef02ca70502175aba
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135637ef02ca70502175aba
Content-Type: text/plain; charset=UTF-8

This doesn't help for every dependency, but Spark provides an option to
build the assembly jar without Hadoop and its dependencies.  We make use of
this in CDH packaging.

-Sandy


On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1@huawei.com> wrote:

> Hi sean owen,
> here are some problems when i used assembly jar
> 1 i put spark-assembly-*.jar to the lib directory of my application, it
> throw compile error
>
> Error:scalac: Error: class scala.reflect.BeanInfo not found.
> scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanInfo not
> found.
>
>         at scala.tools.nsc.symtab.Definitions$definitions$.
> getModuleOrClass(Definitions.scala:655)
>
>         at scala.tools.nsc.symtab.Definitions$definitions$.
> getClass(Definitions.scala:608)
>
>         at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<
> init>(GenJVM.scala:127)
>
>         at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.
> scala:85)
>
>         at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
>
>         at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
>
>         at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)
>
>         at xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)
>
>         at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)
>
>         at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
>
>         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>
>         at sun.reflect.NativeMethodAccessorImpl.invoke(
> NativeMethodAccessorImpl.java:39)
>
>         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> DelegatingMethodAccessorImpl.java:25)
>
>         at java.lang.reflect.Method.invoke(Method.java:597)
>
>         at sbt.compiler.AnalyzingCompiler.call(
> AnalyzingCompiler.scala:102)
>
>         at sbt.compiler.AnalyzingCompiler.compile(
> AnalyzingCompiler.scala:48)
>
>         at sbt.compiler.AnalyzingCompiler.compile(
> AnalyzingCompiler.scala:41)
>
>         at org.jetbrains.jps.incremental.scala.local.
> IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)
>
>         at org.jetbrains.jps.incremental.scala.local.LocalServer.
> compile(LocalServer.scala:25)
>
>         at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.
> scala:58)
>
>         at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(
> Main.scala:21)
>
>         at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(
> Main.scala)
>
>         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>
>         at sun.reflect.NativeMethodAccessorImpl.invoke(
> NativeMethodAccessorImpl.java:39)
>
>         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> DelegatingMethodAccessorImpl.java:25)
>
>         at java.lang.reflect.Method.invoke(Method.java:597)
>
>         at com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
> 2 i test my branch which updated hive version to org.apache.hive 0.13.1
>   it run successfully when use a bag of 3rd jars as dependency but throw
> error using assembly jar, it seems assembly jar lead to conflict
>   ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
>         at org.apache.hadoop.hive.ql.io.parquet.serde.
> ArrayWritableObjectInspector.getObjectInspector(
> ArrayWritableObjectInspector.java:66)
>         at org.apache.hadoop.hive.ql.io.parquet.serde.
> ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
>         at org.apache.hadoop.hive.ql.io.parquet.serde.
> ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
>         at org.apache.hadoop.hive.metastore.MetaStoreUtils.
> getDeserializer(MetaStoreUtils.java:339)
>         at org.apache.hadoop.hive.ql.metadata.Table.
> getDeserializerFromMetaStore(Table.java:283)
>         at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(
> Table.java:189)
>         at org.apache.hadoop.hive.ql.metadata.Hive.createTable(
> Hive.java:597)
>         at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(
> DDLTask.java:4194)
>         at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.
> java:281)
>         at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
>         at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(
> TaskRunner.java:85)
>
>
>
>
>
> On 2014/9/2 16:45, Sean Owen wrote:
>
>> Hm, are you suggesting that the Spark distribution be a bag of 100
>> JARs? It doesn't quite seem reasonable. It does not remove version
>> conflicts, just pushes them to run-time, which isn't good. The
>> assembly is also necessary because that's where shading happens. In
>> development, you want to run against exactly what will be used in a
>> real Spark distro.
>>
>> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
>>
>>> hi, all
>>>    I suggest spark not use assembly jar as default run-time
>>> dependency(spark-submit/spark-class depend on assembly jar),use a
>>> library of
>>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
>>>
>>>    1 assembly jar packaged all 3rd jars into a big one, so we need
>>> rebuild
>>> this jar if we want to update the version of some component(such as
>>> hadoop)
>>>    2 in our practice with spark, sometimes we meet jar compatibility
>>> issue,
>>> it is hard to diagnose compatibility issue with assembly jar
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>>
>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1135637ef02ca70502175aba--

From dev-return-9219-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 16:32:56 2014
Return-Path: <dev-return-9219-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F387F11536
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 16:32:55 +0000 (UTC)
Received: (qmail 45714 invoked by uid 500); 2 Sep 2014 16:32:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45645 invoked by uid 500); 2 Sep 2014 16:32:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45634 invoked by uid 99); 2 Sep 2014 16:32:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 16:32:54 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of teng.qiu@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 16:32:29 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <teng.qiu@gmail.com>)
	id 1XOr0L-0008FJ-Ty
	for dev@spark.incubator.apache.org; Tue, 02 Sep 2014 09:32:25 -0700
Date: Tue, 2 Sep 2014 09:32:25 -0700 (PDT)
From: chutium <teng.qiu@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409675545891-8186.post@n3.nabble.com>
Subject: hive client.getAllPartitions in lookupRelation can take a very long
 time
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

in our hive warehouse there are many tables with a lot of partitions, such as
scala> hiveContext.sql("use db_external")
scala> val result = hiveContext.sql("show partitions et_fullorders").count
result: Long = 5879

i noticed that this part of code:
https://github.com/apache/spark/blob/9d006c97371ddf357e0b821d5c6d1535d9b6fe41/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L55-L56

reads the whole partitions info at the beginning of plan phase, i added a
logInfo around this val partitions = ...

it shows:

scala> val result = hiveContext.sql("select * from db_external.et_fullorders
limit 5")
14/09/02 16:15:56 INFO ParseDriver: Parsing command: select * from
db_external.et_fullorders limit 5
14/09/02 16:15:56 INFO ParseDriver: Parse Completed
14/09/02 16:15:56 INFO HiveContext$$anon$1: getAllPartitionsForPruner
started
14/09/02 16:17:35 INFO HiveContext$$anon$1: getAllPartitionsForPruner
finished

it took about 2min to get all partitions...

is there any possible way to avoid this operation? such as only fetch the
requested partition somehow?

Thanks



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/hive-client-getAllPartitions-in-lookupRelation-can-take-a-very-long-time-tp8186.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9220-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 17:36:27 2014
Return-Path: <dev-return-9220-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7BF03117B8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 17:36:27 +0000 (UTC)
Received: (qmail 26120 invoked by uid 500); 2 Sep 2014 17:36:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26055 invoked by uid 500); 2 Sep 2014 17:36:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26043 invoked by uid 99); 2 Sep 2014 17:36:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:36:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:36:21 +0000
Received: by mail-lb0-f177.google.com with SMTP id z11so7971485lbi.22
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 10:35:59 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=OwT49bjUOlUuKWD9hqKDbYPO9cIxLG9Hz89pPzZDvjE=;
        b=QznIxN6Y3BP+5xgOQ9ONnv2sTN4LrcFw5oRTnVyVt/dC7rKvMv+6hu9jw5LIFoOoUy
         VfbLXfqZ8VOydxjHPNXQjWx1/slYW8Waid68xKjPLt1OXDbiq8hGdaWHC//DfayQ86TC
         fVtg2azBx66Vizx4+XtsjyBTLZL/PPqpQEK0BKyYjdQNygrQgR1zFfl144vmNSAGujig
         NueTQ2c+V2vzSw4Ib3nZfa5ZHqp2+GGq1mKas9fhRAkSdFoX68sA8IKYav8xtiuDwYOc
         +9N4trObr3klmh+0uxAaRU6Voi5an0ciGFQOJLXOQHxiYD4XIyeNRBQYO9Qtdu9SmB6V
         fwWA==
X-Gm-Message-State: ALoCoQkNMo/Du7rWakXPzKWR7V8cY/ov1aV/63tOsrrvENL6OyqHaMos4YZd/AqYtNOADO0FVgp+
X-Received: by 10.112.217.2 with SMTP id ou2mr3636678lbc.101.1409679359581;
 Tue, 02 Sep 2014 10:35:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Tue, 2 Sep 2014 10:35:39 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 2 Sep 2014 10:35:39 -0700
Message-ID: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
Subject: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134840879bb0c0502188d0b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134840879bb0c0502188d0b
Content-Type: text/plain; charset=UTF-8

so, i had a meeting w/the databricks guys on friday and they recommended i
send an email out to the list to say 'hi' and give you guys a quick intro.
 :)

hi!  i'm shane knapp, the new AMPLab devops engineer, and will be spending
time getting the jenkins build infrastructure up to production quality.
 much of this will be 'under the covers' work, like better system level
auth, backups, etc, but some will definitely be user facing:  timely
jenkins updates, debugging broken build infrastructure and some plugin
support.

i've been working in the bay area now since 1997 at many different
companies, and my last 10 years has been split between google and palantir.
 i'm a huge proponent of OSS, and am really happy to be able to help with
the work you guys are doing!

if anyone has any requests/questions/comments, feel free to drop me a line!

shane

--001a1134840879bb0c0502188d0b--

From dev-return-9221-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 17:47:00 2014
Return-Path: <dev-return-9221-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1AEDE1180B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 17:47:00 +0000 (UTC)
Received: (qmail 53624 invoked by uid 500); 2 Sep 2014 17:46:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53550 invoked by uid 500); 2 Sep 2014 17:46:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53538 invoked by uid 99); 2 Sep 2014 17:46:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:46:59 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:46:55 +0000
Received: by mail-qc0-f173.google.com with SMTP id w7so7284550qcr.32
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 10:46:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=mhoDIoPZWVh+XmCZ5fIlzvDsqmdob48q68d/H4rj2L8=;
        b=ULbPu0UasnnON6vq+08ShhsKtMJ8nraOybgXrkp/4+tr4sVs6To3o790RiOmKFWH/z
         vB2XoohK0G4pPKWT1xCj+3Zpq7Bef6jHBCHxuCcx15giqvGNapU9MNe673oTHs0uhPZJ
         6DnEzY8jlpQA+cqlG9Iexdd5P0e1RkVJrVhNicX8LfYx9XTB9JU1easNYjKcQwNkWfLC
         V3DjKX1YDmnUF+lzx0EYTK6/1RuS1jV2qepP5+rg+pIY/Bdq5wfBrmg0UYGG03DKxxxr
         58aG10AConap6T4/YoWtWei0RczFDe99K7LewqP13FM9z1jDuOqK58lIbm2rl0gOyGcr
         p6fg==
X-Gm-Message-State: ALoCoQkeoceH5VbkmwqekM81bmVAETNKDoQp5wxCXH7GK8Dfv9B6NTxEfoMmxDIUlOR+IsNfdC5M
MIME-Version: 1.0
X-Received: by 10.224.114.136 with SMTP id e8mr18167566qaq.67.1409679993745;
 Tue, 02 Sep 2014 10:46:33 -0700 (PDT)
Received: by 10.96.41.34 with HTTP; Tue, 2 Sep 2014 10:46:33 -0700 (PDT)
In-Reply-To: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
Date: Tue, 2 Sep 2014 10:46:33 -0700
Message-ID: <CAPh_B=Z==byxtryWqQnT2OBBPSSZEe69aaq+kddtc6AVbPqMPA@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
From: Reynold Xin <rxin@databricks.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bea3b74464f96050218b3fd
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea3b74464f96050218b3fd
Content-Type: text/plain; charset=UTF-8

Welcome, Shane!

On Tuesday, September 2, 2014, shane knapp <sknapp@berkeley.edu> wrote:

> so, i had a meeting w/the databricks guys on friday and they recommended i
> send an email out to the list to say 'hi' and give you guys a quick intro.
>  :)
>
> hi!  i'm shane knapp, the new AMPLab devops engineer, and will be spending
> time getting the jenkins build infrastructure up to production quality.
>  much of this will be 'under the covers' work, like better system level
> auth, backups, etc, but some will definitely be user facing:  timely
> jenkins updates, debugging broken build infrastructure and some plugin
> support.
>
> i've been working in the bay area now since 1997 at many different
> companies, and my last 10 years has been split between google and palantir.
>  i'm a huge proponent of OSS, and am really happy to be able to help with
> the work you guys are doing!
>
> if anyone has any requests/questions/comments, feel free to drop me a line!
>
> shane
>

--047d7bea3b74464f96050218b3fd--

From dev-return-9222-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 17:49:02 2014
Return-Path: <dev-return-9222-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9558411826
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 17:49:02 +0000 (UTC)
Received: (qmail 61537 invoked by uid 500); 2 Sep 2014 17:49:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61475 invoked by uid 500); 2 Sep 2014 17:49:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61463 invoked by uid 99); 2 Sep 2014 17:49:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:49:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:48:57 +0000
Received: by mail-wg0-f46.google.com with SMTP id x13so7268489wgg.5
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 10:48:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=5cCm33SOgV8X4sppM2Le/6URCx/QNkqmGan25+xEHyo=;
        b=T8wCxtJjs46drsGgIfaO5pCGr6k8CMp0fwXZmDH82TpyB7orEmn+/ppVC1xq7Nnm/W
         m0MCo6pO6Z1x49/7h8ghARAv2661Ap4sbO6sZxhqiJ+wxkT5UMFLPRmYZKC8BlAR/6af
         fmGvtV01qp29DSqazg7WheWIJRCQH5w1hN+wSKQLsYoqWsHXD7Qwp1HeojfPIPzTgN/N
         w7RT3hddIIIW5iz8M37K8rpmdh1fP2qT5oNFryYYoPb9+kYPksKKlU4w/RvQXpLUatQL
         p6Wwqp1ReS1UO+BbCyNkxkwVfDIBzo8QuCNirJys5AveogJ9yrUsIuGCUrsCq5c1Iv1k
         5JGQ==
X-Received: by 10.180.91.40 with SMTP id cb8mr30185799wib.45.1409680116213;
 Tue, 02 Sep 2014 10:48:36 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Tue, 2 Sep 2014 10:47:56 -0700 (PDT)
In-Reply-To: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 2 Sep 2014 13:47:56 -0400
Message-ID: <CAOhmDzfVZzOHXDDT02A6BbB_sOcK0r9L3X8HxZd595T8a8bstQ@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
To: shane knapp <sknapp@berkeley.edu>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c7e7892f071050218bafd
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c7e7892f071050218bafd
Content-Type: text/plain; charset=UTF-8

Hi Shane!

Thank you for doing the Jenkins upgrade last week. It's nice to know that
infrastructure is gonna get some dedicated TLC going forward.

Welcome aboard!

Nick


On Tue, Sep 2, 2014 at 1:35 PM, shane knapp <sknapp@berkeley.edu> wrote:

> so, i had a meeting w/the databricks guys on friday and they recommended i
> send an email out to the list to say 'hi' and give you guys a quick intro.
>  :)
>
> hi!  i'm shane knapp, the new AMPLab devops engineer, and will be spending
> time getting the jenkins build infrastructure up to production quality.
>  much of this will be 'under the covers' work, like better system level
> auth, backups, etc, but some will definitely be user facing:  timely
> jenkins updates, debugging broken build infrastructure and some plugin
> support.
>
> i've been working in the bay area now since 1997 at many different
> companies, and my last 10 years has been split between google and palantir.
>  i'm a huge proponent of OSS, and am really happy to be able to help with
> the work you guys are doing!
>
> if anyone has any requests/questions/comments, feel free to drop me a line!
>
> shane
>

--f46d043c7e7892f071050218bafd--

From dev-return-9223-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 17:54:48 2014
Return-Path: <dev-return-9223-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A135611862
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 17:54:48 +0000 (UTC)
Received: (qmail 80854 invoked by uid 500); 2 Sep 2014 17:54:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80777 invoked by uid 500); 2 Sep 2014 17:54:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80766 invoked by uid 99); 2 Sep 2014 17:54:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:54:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:54:43 +0000
Received: by mail-qc0-f178.google.com with SMTP id x13so7415375qcv.9
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 10:54:22 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=LEiIeDuLbVp6LnO6N22pVEmZYncZBfHG39MyVfJvUPs=;
        b=FrFYP6DNd3YE81LvLYSjPhJocqSjt0aBGtuDNqXpWGF0GgT6cnE3hdKXSqES4KpgEt
         /UDhC2FUZ72QIvTSz+LDd1N4ChkJDFLImtwYaNcOsQoE1MpWu3SScjR69Oh+qlXPgJ0N
         DctySA81Ygzr2WiZNbAFd4EIbblXfIMEY6AvIIjLERzOFjozzxlZUOLyHY3WE1vxykGT
         wD7hIyZVIenFrjQWTkCXkg/K6cbpcMdB+DtHZuqQlmQmfHP1lsydFpoI1M1SXz2ok+MR
         Q4U9aZpdllYUoAfRQ6UaT9Bde/3nuWY+FUcV9WJnRPhDSCeo6ddkqEVTBbHGLFVNU2VB
         H1eQ==
X-Gm-Message-State: ALoCoQm3YdI+UPvz37A6UMcQPjIQI876lMWsoAGU+0qR6txmt1G341w1IWjmgapmWzKVjsSXoN3Q
X-Received: by 10.224.166.195 with SMTP id n3mr37005145qay.22.1409680462086;
 Tue, 02 Sep 2014 10:54:22 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Tue, 2 Sep 2014 10:54:01 -0700 (PDT)
In-Reply-To: <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
 <540589E8.8020107@huawei.com> <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 2 Sep 2014 10:54:01 -0700
Message-ID: <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com>
Subject: Re: about spark assembly jar
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: scwf <wangfei1@huawei.com>, Sean Owen <sowen@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01538110309da8050218cf8c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01538110309da8050218cf8c
Content-Type: text/plain; charset=UTF-8

Having a SSD help tremendously with assembly time.

Without that, you can do the following in order for Spark to pick up the
compiled classes before assembly at runtime.

export SPARK_PREPEND_CLASSES=true


On Tue, Sep 2, 2014 at 9:10 AM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> This doesn't help for every dependency, but Spark provides an option to
> build the assembly jar without Hadoop and its dependencies.  We make use of
> this in CDH packaging.
>
> -Sandy
>
>
> On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1@huawei.com> wrote:
>
> > Hi sean owen,
> > here are some problems when i used assembly jar
> > 1 i put spark-assembly-*.jar to the lib directory of my application, it
> > throw compile error
> >
> > Error:scalac: Error: class scala.reflect.BeanInfo not found.
> > scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanInfo not
> > found.
> >
> >         at scala.tools.nsc.symtab.Definitions$definitions$.
> > getModuleOrClass(Definitions.scala:655)
> >
> >         at scala.tools.nsc.symtab.Definitions$definitions$.
> > getClass(Definitions.scala:608)
> >
> >         at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<
> > init>(GenJVM.scala:127)
> >
> >         at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.
> > scala:85)
> >
> >         at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
> >
> >         at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
> >
> >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)
> >
> >         at
> xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)
> >
> >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)
> >
> >         at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
> >
> >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >
> >         at sun.reflect.NativeMethodAccessorImpl.invoke(
> > NativeMethodAccessorImpl.java:39)
> >
> >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > DelegatingMethodAccessorImpl.java:25)
> >
> >         at java.lang.reflect.Method.invoke(Method.java:597)
> >
> >         at sbt.compiler.AnalyzingCompiler.call(
> > AnalyzingCompiler.scala:102)
> >
> >         at sbt.compiler.AnalyzingCompiler.compile(
> > AnalyzingCompiler.scala:48)
> >
> >         at sbt.compiler.AnalyzingCompiler.compile(
> > AnalyzingCompiler.scala:41)
> >
> >         at org.jetbrains.jps.incremental.scala.local.
> > IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)
> >
> >         at org.jetbrains.jps.incremental.scala.local.LocalServer.
> > compile(LocalServer.scala:25)
> >
> >         at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.
> > scala:58)
> >
> >         at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(
> > Main.scala:21)
> >
> >         at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(
> > Main.scala)
> >
> >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> >
> >         at sun.reflect.NativeMethodAccessorImpl.invoke(
> > NativeMethodAccessorImpl.java:39)
> >
> >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > DelegatingMethodAccessorImpl.java:25)
> >
> >         at java.lang.reflect.Method.invoke(Method.java:597)
> >
> >         at com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
> > 2 i test my branch which updated hive version to org.apache.hive 0.13.1
> >   it run successfully when use a bag of 3rd jars as dependency but throw
> > error using assembly jar, it seems assembly jar lead to conflict
> >   ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
> >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > ArrayWritableObjectInspector.getObjectInspector(
> > ArrayWritableObjectInspector.java:66)
> >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
> >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
> >         at org.apache.hadoop.hive.metastore.MetaStoreUtils.
> > getDeserializer(MetaStoreUtils.java:339)
> >         at org.apache.hadoop.hive.ql.metadata.Table.
> > getDeserializerFromMetaStore(Table.java:283)
> >         at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(
> > Table.java:189)
> >         at org.apache.hadoop.hive.ql.metadata.Hive.createTable(
> > Hive.java:597)
> >         at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(
> > DDLTask.java:4194)
> >         at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.
> > java:281)
> >         at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
> >         at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(
> > TaskRunner.java:85)
> >
> >
> >
> >
> >
> > On 2014/9/2 16:45, Sean Owen wrote:
> >
> >> Hm, are you suggesting that the Spark distribution be a bag of 100
> >> JARs? It doesn't quite seem reasonable. It does not remove version
> >> conflicts, just pushes them to run-time, which isn't good. The
> >> assembly is also necessary because that's where shading happens. In
> >> development, you want to run against exactly what will be used in a
> >> real Spark distro.
> >>
> >> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
> >>
> >>> hi, all
> >>>    I suggest spark not use assembly jar as default run-time
> >>> dependency(spark-submit/spark-class depend on assembly jar),use a
> >>> library of
> >>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
> >>>
> >>>    1 assembly jar packaged all 3rd jars into a big one, so we need
> >>> rebuild
> >>> this jar if we want to update the version of some component(such as
> >>> hadoop)
> >>>    2 in our practice with spark, sometimes we meet jar compatibility
> >>> issue,
> >>> it is hard to diagnose compatibility issue with assembly jar
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>> For additional commands, e-mail: dev-help@spark.apache.org
> >>>
> >>>
> >>
> >>
> >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--089e01538110309da8050218cf8c--

From dev-return-9224-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:00:16 2014
Return-Path: <dev-return-9224-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2FA5F1188A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:00:16 +0000 (UTC)
Received: (qmail 92111 invoked by uid 500); 2 Sep 2014 18:00:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92043 invoked by uid 500); 2 Sep 2014 18:00:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92030 invoked by uid 99); 2 Sep 2014 18:00:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:00:14 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 17:59:48 +0000
Received: by mail-ob0-f179.google.com with SMTP id uz6so5184194obc.24
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 10:59:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=A8IFb6ZOXE7oLgfkVxN9PgyWFNwjq20zzw03+khUCcQ=;
        b=YNoMIOnuwvGXdLQ5dFA9AW+JgGtpuPZC0AB3yKMcIztVhJG9EvfngwKn1dDgqB9B0C
         iNqukhVTT2G9R6hqhvLYns9XrMeZRKUM1Er+cWTiOvfShVE8gzCVrHYuAYM+G9YBIpfS
         EEZD1aE7MHbYcbpayEjR/dREUvEK8aARuDpIXij09J/M+IcWXC+Kdjo+iAZIXL5Vv8nt
         UwTvulHRbTVZXjKIMK1DBxIXBskIkbDAEd02eI/mhr9bu2wFjzOUUarYnimVAPSTGpYy
         AhpmOf/KHtDJ9e72jNmMiHt7XMRd0GaGiBEb44SzsbmuSRoWaH5N0P8SBBt32Fqkei/L
         urGA==
MIME-Version: 1.0
X-Received: by 10.60.63.201 with SMTP id i9mr6493769oes.52.1409680787559; Tue,
 02 Sep 2014 10:59:47 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 2 Sep 2014 10:59:47 -0700 (PDT)
In-Reply-To: <CAOhmDzfVZzOHXDDT02A6BbB_sOcK0r9L3X8HxZd595T8a8bstQ@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
	<CAOhmDzfVZzOHXDDT02A6BbB_sOcK0r9L3X8HxZd595T8a8bstQ@mail.gmail.com>
Date: Tue, 2 Sep 2014 10:59:47 -0700
Message-ID: <CABPQxsuX2RmK5b7iW6SpvcEcgJwL=ozKTH=ZKvt_N1-PSEu+tg@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Shane,

Thanks for your work so far and I'm really happy to see investment in
this infrastructure. This is a key productivity tool for us and
something we'd love to expand over time to improve the development
process of Spark.

- Patrick

On Tue, Sep 2, 2014 at 10:47 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> Hi Shane!
>
> Thank you for doing the Jenkins upgrade last week. It's nice to know that
> infrastructure is gonna get some dedicated TLC going forward.
>
> Welcome aboard!
>
> Nick
>
>
> On Tue, Sep 2, 2014 at 1:35 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> so, i had a meeting w/the databricks guys on friday and they recommended i
>> send an email out to the list to say 'hi' and give you guys a quick intro.
>>  :)
>>
>> hi!  i'm shane knapp, the new AMPLab devops engineer, and will be spending
>> time getting the jenkins build infrastructure up to production quality.
>>  much of this will be 'under the covers' work, like better system level
>> auth, backups, etc, but some will definitely be user facing:  timely
>> jenkins updates, debugging broken build infrastructure and some plugin
>> support.
>>
>> i've been working in the bay area now since 1997 at many different
>> companies, and my last 10 years has been split between google and palantir.
>>  i'm a huge proponent of OSS, and am really happy to be able to help with
>> the work you guys are doing!
>>
>> if anyone has any requests/questions/comments, feel free to drop me a line!
>>
>> shane
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9225-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:10:23 2014
Return-Path: <dev-return-9225-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CCEB71190A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:10:23 +0000 (UTC)
Received: (qmail 26825 invoked by uid 500); 2 Sep 2014 18:10:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26756 invoked by uid 500); 2 Sep 2014 18:10:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26744 invoked by uid 99); 2 Sep 2014 18:10:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:10:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ctn@adatao.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:10:08 +0000
Received: by mail-ig0-f174.google.com with SMTP id a13so5436854igq.1
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 11:09:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=fYsOWER+R6Q2U/DMCHLtUikGPX+aoza/5SBsBuwhH/M=;
        b=KWAKh7ChH4R7nSc3guITM/Qbez40WaNgBVmjfltOLNcMhOcLw5T8OPUlf1XqyW4pcE
         wUwHjU3x/kcsuWZKZkBJW6htNlVN8lKcp9XpCuV31wsS5+SFQdbCl6TdSYAvtDKEP5jm
         T/NQVd+ouXaXncp/aTgVYycZHA2TiA6GAXd/E=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=fYsOWER+R6Q2U/DMCHLtUikGPX+aoza/5SBsBuwhH/M=;
        b=KNOvUtejC9v2B0gWG6uH6cMiZP3TrUJme5cLb0H8GGtgM+10LS7wSDCFeoXMxZ0gbg
         uZnYs1Hq+GBTbjHELUBtMvAENEnTG1Q/0i1YPvOML1X+3pN4RKSgU3HlAxp5+YaJTGXG
         HxKLskpE877JkMFBHa/4UWvCLcCO0Hu1wf0sIUFqpvrdUtxAoGj7ficBJZkbgGajbNEW
         4FUQn3m2AD67y9nvxp0nl1+W63h/Ie8zJvyKvVkBlAnWZXX1fJTSiiq4PtUwmXmJh5Y8
         gwJD+uKFqfYthXVXyd4xK9ebxtyWfCv1No0HL158bF6rlbTf7aG2m5U9F+t/BVTcrj6G
         HwGA==
X-Gm-Message-State: ALoCoQkiVcwU9u2EYtyaIANwRuyVoE+MQ7/c5OO1pYbZ9E/YaXGnQJ3Zi0zxk7AbdvSj+krSc+jc
MIME-Version: 1.0
X-Received: by 10.50.80.45 with SMTP id o13mr30413443igx.7.1409681385657; Tue,
 02 Sep 2014 11:09:45 -0700 (PDT)
Received: by 10.64.13.83 with HTTP; Tue, 2 Sep 2014 11:09:45 -0700 (PDT)
X-Originating-IP: [70.197.5.118]
Received: by 10.64.13.83 with HTTP; Tue, 2 Sep 2014 11:09:45 -0700 (PDT)
In-Reply-To: <CABPQxsuX2RmK5b7iW6SpvcEcgJwL=ozKTH=ZKvt_N1-PSEu+tg@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
	<CAOhmDzfVZzOHXDDT02A6BbB_sOcK0r9L3X8HxZd595T8a8bstQ@mail.gmail.com>
	<CABPQxsuX2RmK5b7iW6SpvcEcgJwL=ozKTH=ZKvt_N1-PSEu+tg@mail.gmail.com>
Date: Tue, 2 Sep 2014 11:09:45 -0700
Message-ID: <CAGh_TuPP_GTZ9=DevO6x3fF1xSd60oVEvitSqAE9X3rXCwt+dg@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
From: Christopher Nguyen <ctn@adatao.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, dev@spark.apache.org, 
	Nicholas Chammas <nicholas.chammas@gmail.com>
Content-Type: multipart/alternative; boundary=089e0153668a3d3376050219065b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0153668a3d3376050219065b
Content-Type: text/plain; charset=UTF-8

Welcome, Shane. As a former prof and eng dir at Google, I've been expecting
this to be a first-class engineering college subject. I just didn't expect
it to come through this route :-)

So congrats, and I hope you represent the beginning of a great new trend at
universities.

Sent while mobile. Please excuse typos etc.
On Sep 2, 2014 11:00 AM, "Patrick Wendell" <pwendell@gmail.com> wrote:

> Hey Shane,
>
> Thanks for your work so far and I'm really happy to see investment in
> this infrastructure. This is a key productivity tool for us and
> something we'd love to expand over time to improve the development
> process of Spark.
>
> - Patrick
>
> On Tue, Sep 2, 2014 at 10:47 AM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > Hi Shane!
> >
> > Thank you for doing the Jenkins upgrade last week. It's nice to know that
> > infrastructure is gonna get some dedicated TLC going forward.
> >
> > Welcome aboard!
> >
> > Nick
> >
> >
> > On Tue, Sep 2, 2014 at 1:35 PM, shane knapp <sknapp@berkeley.edu> wrote:
> >
> >> so, i had a meeting w/the databricks guys on friday and they
> recommended i
> >> send an email out to the list to say 'hi' and give you guys a quick
> intro.
> >>  :)
> >>
> >> hi!  i'm shane knapp, the new AMPLab devops engineer, and will be
> spending
> >> time getting the jenkins build infrastructure up to production quality.
> >>  much of this will be 'under the covers' work, like better system level
> >> auth, backups, etc, but some will definitely be user facing:  timely
> >> jenkins updates, debugging broken build infrastructure and some plugin
> >> support.
> >>
> >> i've been working in the bay area now since 1997 at many different
> >> companies, and my last 10 years has been split between google and
> palantir.
> >>  i'm a huge proponent of OSS, and am really happy to be able to help
> with
> >> the work you guys are doing!
> >>
> >> if anyone has any requests/questions/comments, feel free to drop me a
> line!
> >>
> >> shane
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0153668a3d3376050219065b--

From dev-return-9226-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:19:28 2014
Return-Path: <dev-return-9226-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9517411967
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:19:28 +0000 (UTC)
Received: (qmail 52092 invoked by uid 500); 2 Sep 2014 18:19:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52032 invoked by uid 500); 2 Sep 2014 18:19:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 49496 invoked by uid 99); 2 Sep 2014 15:17:08 -0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of kartheek.mbms@gmail.com designates 209.85.212.177 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=QfQ58E1t/06NJ6zhULTyYONSw+XsINVqq8Po8e3smfU=;
        b=sF2rr3YmKddSdEUHWFdlxlVYCKtJsSAW1ojAzFJI/49FFcp0diby6kfB9Kn/jvQ0SG
         kLVG+xT6BSVxirSMtp21MoyffdGv3++EKVslksSDSIswfdzxE2T2g0SE0Ict0PhKGEl8
         gwkf/wHxGdoBhF6qgd0QSYiqcy8+0sChiL5Nn5LAU+HCK9DSb7ufZwkmM1GNhTM/g0fA
         0FxxMvpQyp4s5u9Df12BdOS0BguYpgKgaU213FrBXX1qm/bnZKo6CwebuuAjEi/2s/r0
         fo1OKX9RBZGr/79riAd8A6ybDjxAjOxduG6QMpAZXxZbE5FHkvzK6YrpMSM/qP9ZKW44
         ysPA==
MIME-Version: 1.0
X-Received: by 10.180.223.4 with SMTP id qq4mr29359789wic.47.1409671001956;
 Tue, 02 Sep 2014 08:16:41 -0700 (PDT)
Date: Tue, 2 Sep 2014 20:46:41 +0530
Message-ID: <CAAbaoBDaryCs+NTMe8EPG1xOQUK5SbskyahDOM2DpGsYPHQYLw@mail.gmail.com>
Subject: Resource allocation
From: rapelly kartheek <kartheek.mbms@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11361c065267e90502169b1b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11361c065267e90502169b1b
Content-Type: text/plain; charset=UTF-8

Hi,

I want to incorporate some intelligence while choosing the resources for
rdd replication. I thought, if we replicate rdd on specially chosen nodes
based on the capabilities, the next application that requires this rdd can
be executed more efficiently. But, I found that an rdd creatd by an
appplication is owned by only that application and nobody else can access
it.

Can someone tell me what kind of operations can be done on a replicated
rdd. Or to put it other way, what are the benefits of a replicated rdd or
what operations can be performed on a replicated rdd.  I just want to know
how effective is my work going to be.

I'll be happy if some other ideas in the similar line of thought are
suggested.

Thank you!!
Karthik

--001a11361c065267e90502169b1b--

From dev-return-9227-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:53:50 2014
Return-Path: <dev-return-9227-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 070E411B5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:53:50 +0000 (UTC)
Received: (qmail 76808 invoked by uid 500); 2 Sep 2014 18:53:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76740 invoked by uid 500); 2 Sep 2014 18:53:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76727 invoked by uid 99); 2 Sep 2014 18:53:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:53:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.216.47 as permitted sender)
Received: from [209.85.216.47] (HELO mail-qa0-f47.google.com) (209.85.216.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:53:45 +0000
Received: by mail-qa0-f47.google.com with SMTP id x12so6660308qac.6
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 11:53:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=VilTrb4/PZGsG8tIx5qT2ey9/DgWgk/IwfqLcf3rLY4=;
        b=ZRzpPzPnA943yKNlNeKbn0Mm2QpiDLnsJzSTXwOk7zJwPi6h6z6iY0+TXtUekLuIHH
         Lr5bWj4/lcl8cZ90wTsv9aPuYY6yqm76oLfvvC/ex9EA5LZormeyN2EDX1BtHn1n4zXt
         EV/mnKiN0+g32lm5F7gw9dvNP4+9Rsi7lg1ZzWAB4BY8SntSsJeukyass23m1LSqejw8
         +lRboKMeBfqcLdagy4YbkOZIGjPpf/QqrqpVBQ2x0a2321mMLNKeeSSkB4DpNVEiHgYU
         bLLOgyXTKB7evX6jvISKLxti20LksyxxEKCAKG04Qe7qcELmejReyhXs1DBATPhZt3ns
         Si3w==
X-Received: by 10.224.137.6 with SMTP id u6mr57828465qat.91.1409684004257;
 Tue, 02 Sep 2014 11:53:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.92.210 with HTTP; Tue, 2 Sep 2014 11:53:04 -0700 (PDT)
In-Reply-To: <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com>
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
 <540589E8.8020107@huawei.com> <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
 <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 2 Sep 2014 11:53:04 -0700
Message-ID: <CAA_qdLpVTEZ2Vd1a9JTbFnssiCjZFwYbnE2sBRsZ5sQZgqWphg@mail.gmail.com>
Subject: Re: about spark assembly jar
To: Reynold Xin <rxin@databricks.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, scwf <wangfei1@huawei.com>, 
	Sean Owen <sowen@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2a3ec51ca49050219a213
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2a3ec51ca49050219a213
Content-Type: text/plain; charset=UTF-8

Yea, SSD + SPARK_PREPEND_CLASSES totally changed my life :)

Maybe we should add a "developer notes" page to document all these useful
black magic.


On Tue, Sep 2, 2014 at 10:54 AM, Reynold Xin <rxin@databricks.com> wrote:

> Having a SSD help tremendously with assembly time.
>
> Without that, you can do the following in order for Spark to pick up the
> compiled classes before assembly at runtime.
>
> export SPARK_PREPEND_CLASSES=true
>
>
> On Tue, Sep 2, 2014 at 9:10 AM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
> > This doesn't help for every dependency, but Spark provides an option to
> > build the assembly jar without Hadoop and its dependencies.  We make use
> of
> > this in CDH packaging.
> >
> > -Sandy
> >
> >
> > On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1@huawei.com> wrote:
> >
> > > Hi sean owen,
> > > here are some problems when i used assembly jar
> > > 1 i put spark-assembly-*.jar to the lib directory of my application, it
> > > throw compile error
> > >
> > > Error:scalac: Error: class scala.reflect.BeanInfo not found.
> > > scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanInfo
> not
> > > found.
> > >
> > >         at scala.tools.nsc.symtab.Definitions$definitions$.
> > > getModuleOrClass(Definitions.scala:655)
> > >
> > >         at scala.tools.nsc.symtab.Definitions$definitions$.
> > > getClass(Definitions.scala:608)
> > >
> > >         at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<
> > > init>(GenJVM.scala:127)
> > >
> > >         at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.
> > > scala:85)
> > >
> > >         at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
> > >
> > >         at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
> > >
> > >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)
> > >
> > >         at
> > xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)
> > >
> > >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)
> > >
> > >         at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
> > >
> > >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >
> > >         at sun.reflect.NativeMethodAccessorImpl.invoke(
> > > NativeMethodAccessorImpl.java:39)
> > >
> > >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > > DelegatingMethodAccessorImpl.java:25)
> > >
> > >         at java.lang.reflect.Method.invoke(Method.java:597)
> > >
> > >         at sbt.compiler.AnalyzingCompiler.call(
> > > AnalyzingCompiler.scala:102)
> > >
> > >         at sbt.compiler.AnalyzingCompiler.compile(
> > > AnalyzingCompiler.scala:48)
> > >
> > >         at sbt.compiler.AnalyzingCompiler.compile(
> > > AnalyzingCompiler.scala:41)
> > >
> > >         at org.jetbrains.jps.incremental.scala.local.
> > > IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)
> > >
> > >         at org.jetbrains.jps.incremental.scala.local.LocalServer.
> > > compile(LocalServer.scala:25)
> > >
> > >         at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.
> > > scala:58)
> > >
> > >         at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(
> > > Main.scala:21)
> > >
> > >         at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(
> > > Main.scala)
> > >
> > >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > >
> > >         at sun.reflect.NativeMethodAccessorImpl.invoke(
> > > NativeMethodAccessorImpl.java:39)
> > >
> > >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > > DelegatingMethodAccessorImpl.java:25)
> > >
> > >         at java.lang.reflect.Method.invoke(Method.java:597)
> > >
> > >         at
> com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
> > > 2 i test my branch which updated hive version to org.apache.hive 0.13.1
> > >   it run successfully when use a bag of 3rd jars as dependency but
> throw
> > > error using assembly jar, it seems assembly jar lead to conflict
> > >   ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
> > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > > ArrayWritableObjectInspector.getObjectInspector(
> > > ArrayWritableObjectInspector.java:66)
> > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > >
> ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
> > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
> > > ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
> > >         at org.apache.hadoop.hive.metastore.MetaStoreUtils.
> > > getDeserializer(MetaStoreUtils.java:339)
> > >         at org.apache.hadoop.hive.ql.metadata.Table.
> > > getDeserializerFromMetaStore(Table.java:283)
> > >         at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(
> > > Table.java:189)
> > >         at org.apache.hadoop.hive.ql.metadata.Hive.createTable(
> > > Hive.java:597)
> > >         at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(
> > > DDLTask.java:4194)
> > >         at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.
> > > java:281)
> > >         at
> org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
> > >         at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(
> > > TaskRunner.java:85)
> > >
> > >
> > >
> > >
> > >
> > > On 2014/9/2 16:45, Sean Owen wrote:
> > >
> > >> Hm, are you suggesting that the Spark distribution be a bag of 100
> > >> JARs? It doesn't quite seem reasonable. It does not remove version
> > >> conflicts, just pushes them to run-time, which isn't good. The
> > >> assembly is also necessary because that's where shading happens. In
> > >> development, you want to run against exactly what will be used in a
> > >> real Spark distro.
> > >>
> > >> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
> > >>
> > >>> hi, all
> > >>>    I suggest spark not use assembly jar as default run-time
> > >>> dependency(spark-submit/spark-class depend on assembly jar),use a
> > >>> library of
> > >>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
> > >>>
> > >>>    1 assembly jar packaged all 3rd jars into a big one, so we need
> > >>> rebuild
> > >>> this jar if we want to update the version of some component(such as
> > >>> hadoop)
> > >>>    2 in our practice with spark, sometimes we meet jar compatibility
> > >>> issue,
> > >>> it is hard to diagnose compatibility issue with assembly jar
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>
> > >>> ---------------------------------------------------------------------
> > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >>> For additional commands, e-mail: dev-help@spark.apache.org
> > >>>
> > >>>
> > >>
> > >>
> > >
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--001a11c2a3ec51ca49050219a213--

From dev-return-9228-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:56:10 2014
Return-Path: <dev-return-9228-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4CD2011B9D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:56:10 +0000 (UTC)
Received: (qmail 93463 invoked by uid 500); 2 Sep 2014 18:56:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93400 invoked by uid 500); 2 Sep 2014 18:56:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93383 invoked by uid 99); 2 Sep 2014 18:56:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:56:09 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.192.176 as permitted sender)
Received: from [209.85.192.176] (HELO mail-pd0-f176.google.com) (209.85.192.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:56:04 +0000
Received: by mail-pd0-f176.google.com with SMTP id g10so9172896pdj.7
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 11:55:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=OgZB7P3+dByL91PGWy64rpfb7JRkLaqprGw8ARLdhfU=;
        b=KMDex6gbyVkB6KiRYJUB3IdAkJv2RmQNYMNBdFvqwQ1VH6ENV/M/SQa7ietoDIvP7u
         2QCjD5Hmx+bII1jHpjVPgBOic2cGBZdwIzOWf99NRF1HUXvyj5AkifxAU+v0pZXLZSwa
         LYnfnrUoXm7kpNJoqFBx14DoAYV6GHQaEuzpTbpPjdt2/hecaAEJS9sz7DNdGKTP0tUX
         9cMqg1kOBEDKSxwbjoVRBlpDLC/p0xK/1+4CVqr5uCO8ctKUfNPRUt8LVQ/Ah9GdOPQ7
         COTale+5eJFMj/PJldEtAovpxVjQH8VO3dACfdwpA68ZQrXvaeFT/T2gJm+kfS9GUiU2
         Qc3w==
X-Received: by 10.68.171.33 with SMTP id ar1mr7338904pbc.148.1409684144429;
        Tue, 02 Sep 2014 11:55:44 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id o2sm6522031pde.30.2014.09.02.11.55.42
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Tue, 02 Sep 2014 11:55:43 -0700 (PDT)
Date: Tue, 2 Sep 2014 11:55:42 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>, Reynold Xin
 <rxin@databricks.com>
Cc: Sean Owen <sowen@cloudera.com>, Sandy Ryza
 <sandy.ryza@cloudera.com>, "=?utf-8?Q?dev=40spark.apache.org?="
 <dev@spark.apache.org>, scwf <wangfei1@huawei.com>
Message-ID: <etPan.540612ae.628c895d.cf9@joshs-mbp>
In-Reply-To: <CAA_qdLpVTEZ2Vd1a9JTbFnssiCjZFwYbnE2sBRsZ5sQZgqWphg@mail.gmail.com>
References: <54058224.3030909@huawei.com>
 <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
 <540589E8.8020107@huawei.com>
 <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
 <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com>
 <CAA_qdLpVTEZ2Vd1a9JTbFnssiCjZFwYbnE2sBRsZ5sQZgqWphg@mail.gmail.com>
Subject: Re: about spark assembly jar
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540612ae_333ab105_cf9"
X-Virus-Checked: Checked by ClamAV on apache.org

--540612ae_333ab105_cf9
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

SPARK=5FPREPEND=5FCLASSES is documented on the Spark Wiki (which could pr=
obably be easier to find):=C2=A0https://cwiki.apache.org/confluence/displ=
ay/SPARK/Useful+Developer+Tools


On September 2, 2014 at 11:53:49 AM, Cheng Lian (lian.cs.zju=40gmail.com)=
 wrote:

Yea, SSD + SPARK=5FPREPEND=5FCLASSES totally changed my life :) =20

Maybe we should add a =22developer notes=22 page to document all these us=
eful =20
black magic. =20


On Tue, Sep 2, 2014 at 10:54 AM, Reynold Xin <rxin=40databricks.com> wrot=
e: =20

> Having a SSD help tremendously with assembly time. =20
> =20
> Without that, you can do the following in order for Spark to pick up th=
e =20
> compiled classes before assembly at runtime. =20
> =20
> export SPARK=5FPREPEND=5FCLASSES=3Dtrue =20
> =20
> =20
> On Tue, Sep 2, 2014 at 9:10 AM, Sandy Ryza <sandy.ryza=40cloudera.com> =
=20
> wrote: =20
> =20
> > This doesn't help for every dependency, but Spark provides an option =
to =20
> > build the assembly jar without Hadoop and its dependencies. We make u=
se =20
> of =20
> > this in CDH packaging. =20
> > =20
> > -Sandy =20
> > =20
> > =20
> > On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1=40huawei.com> wrote: =20
> > =20
> > > Hi sean owen, =20
> > > here are some problems when i used assembly jar =20
> > > 1 i put spark-assembly-*.jar to the lib directory of my application=
, it =20
> > > throw compile error =20
> > > =20
> > > Error:scalac: Error: class scala.reflect.BeanInfo not found. =20
> > > scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanIn=
fo =20
> not =20
> > > found. =20
> > > =20
> > > at scala.tools.nsc.symtab.Definitions=24definitions=24. =20
> > > getModuleOrClass(Definitions.scala:655) =20
> > > =20
> > > at scala.tools.nsc.symtab.Definitions=24definitions=24. =20
> > > getClass(Definitions.scala:608) =20
> > > =20
> > > at scala.tools.nsc.backend.jvm.GenJVM=24BytecodeGenerator.< =20
> > > init>(GenJVM.scala:127) =20
> > > =20
> > > at scala.tools.nsc.backend.jvm.GenJVM=24JvmPhase.run(GenJVM. =20
> > > scala:85) =20
> > > =20
> > > at scala.tools.nsc.Global=24Run.compileSources(Global.scala:953) =20
> > > =20
> > > at scala.tools.nsc.Global=24Run.compile(Global.scala:1041) =20
> > > =20
> > > at xsbt.CachedCompiler0.run(CompilerInterface.scala:126) =20
> > > =20
> > > at =20
> > xsbt.CachedCompiler0.liftedTree1=241(CompilerInterface.scala:102) =20
> > > =20
> > > at xsbt.CachedCompiler0.run(CompilerInterface.scala:102) =20
> > > =20
> > > at xsbt.CompilerInterface.run(CompilerInterface.scala:27) =20
> > > =20
> > > at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) =20
> > > =20
> > > at sun.reflect.NativeMethodAccessorImpl.invoke( =20
> > > NativeMethodAccessorImpl.java:39) =20
> > > =20
> > > at sun.reflect.DelegatingMethodAccessorImpl.invoke( =20
> > > DelegatingMethodAccessorImpl.java:25) =20
> > > =20
> > > at java.lang.reflect.Method.invoke(Method.java:597) =20
> > > =20
> > > at sbt.compiler.AnalyzingCompiler.call( =20
> > > AnalyzingCompiler.scala:102) =20
> > > =20
> > > at sbt.compiler.AnalyzingCompiler.compile( =20
> > > AnalyzingCompiler.scala:48) =20
> > > =20
> > > at sbt.compiler.AnalyzingCompiler.compile( =20
> > > AnalyzingCompiler.scala:41) =20
> > > =20
> > > at org.jetbrains.jps.incremental.scala.local. =20
> > > IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28) =20
> > > =20
> > > at org.jetbrains.jps.incremental.scala.local.LocalServer. =20
> > > compile(LocalServer.scala:25) =20
> > > =20
> > > at org.jetbrains.jps.incremental.scala.remote.Main=24.make(Main. =20
> > > scala:58) =20
> > > =20
> > > at org.jetbrains.jps.incremental.scala.remote.Main=24.nailMain( =20
> > > Main.scala:21) =20
> > > =20
> > > at org.jetbrains.jps.incremental.scala.remote.Main.nailMain( =20
> > > Main.scala) =20
> > > =20
> > > at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) =20
> > > =20
> > > at sun.reflect.NativeMethodAccessorImpl.invoke( =20
> > > NativeMethodAccessorImpl.java:39) =20
> > > =20
> > > at sun.reflect.DelegatingMethodAccessorImpl.invoke( =20
> > > DelegatingMethodAccessorImpl.java:25) =20
> > > =20
> > > at java.lang.reflect.Method.invoke(Method.java:597) =20
> > > =20
> > > at =20
> com.martiansoftware.nailgun.NGSession.run(NGSession.java:319) =20
> > > 2 i test my branch which updated hive version to org.apache.hive 0.=
13.1 =20
> > > it run successfully when use a bag of 3rd jars as dependency but =20
> throw =20
> > > error using assembly jar, it seems assembly jar lead to conflict =20
> > > ERROR DDLTask: java.lang.NoSuch=46ieldError: doubleTypeInfo =20
> > > at org.apache.hadoop.hive.ql.io.parquet.serde. =20
> > > ArrayWritableObjectInspector.getObjectInspector( =20
> > > ArrayWritableObjectInspector.java:66) =20
> > > at org.apache.hadoop.hive.ql.io.parquet.serde. =20
> > > =20
> ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:5=
9) =20
> > > at org.apache.hadoop.hive.ql.io.parquet.serde. =20
> > > ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113) =20
> > > at org.apache.hadoop.hive.metastore.MetaStoreUtils. =20
> > > getDeserializer(MetaStoreUtils.java:339) =20
> > > at org.apache.hadoop.hive.ql.metadata.Table. =20
> > > getDeserializer=46romMetaStore(Table.java:283) =20
> > > at org.apache.hadoop.hive.ql.metadata.Table.checkValidity( =20
> > > Table.java:189) =20
> > > at org.apache.hadoop.hive.ql.metadata.Hive.createTable( =20
> > > Hive.java:597) =20
> > > at org.apache.hadoop.hive.ql.exec.DDLTask.createTable( =20
> > > DDLTask.java:4194) =20
> > > at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask. =20
> > > java:281) =20
> > > at =20
> org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153) =20
> > > at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential( =20
> > > TaskRunner.java:85) =20
> > > =20
> > > =20
> > > =20
> > > =20
> > > =20
> > > On 2014/9/2 16:45, Sean Owen wrote: =20
> > > =20
> > >> Hm, are you suggesting that the Spark distribution be a bag of 100=
 =20
> > >> JARs=3F It doesn't quite seem reasonable. It does not remove versi=
on =20
> > >> conflicts, just pushes them to run-time, which isn't good. The =20
> > >> assembly is also necessary because that's where shading happens. I=
n =20
> > >> development, you want to run against exactly what will be used in =
a =20
> > >> real Spark distro. =20
> > >> =20
> > >> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1=40huawei.com> wrote=
: =20
> > >> =20
> > >>> hi, all =20
> > >>> I suggest spark not use assembly jar as default run-time =20
> > >>> dependency(spark-submit/spark-class depend on assembly jar),use a=
 =20
> > >>> library of =20
> > >>> all 3rd dependency jar like hadoop/hive/hbase more reasonable. =20
> > >>> =20
> > >>> 1 assembly jar packaged all 3rd jars into a big one, so we need =20
> > >>> rebuild =20
> > >>> this jar if we want to update the version of some component(such =
as =20
> > >>> hadoop) =20
> > >>> 2 in our practice with spark, sometimes we meet jar compatibility=
 =20
> > >>> issue, =20
> > >>> it is hard to diagnose compatibility issue with assembly jar =20
> > >>> =20
> > >>> =20
> > >>> =20
> > >>> =20
> > >>> =20
> > >>> =20
> > >>> =20
> > >>> -----------------------------------------------------------------=
---- =20
> > >>> To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > >>> =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> > >>> =20
> > >>> =20
> > >> =20
> > >> =20
> > > =20
> > > =20
> > > -------------------------------------------------------------------=
-- =20
> > > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > > =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> > > =20
> > > =20
> > =20
> =20

--540612ae_333ab105_cf9--


From dev-return-9229-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 18:57:47 2014
Return-Path: <dev-return-9229-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A171C11BB8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 18:57:47 +0000 (UTC)
Received: (qmail 97881 invoked by uid 500); 2 Sep 2014 18:57:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97808 invoked by uid 500); 2 Sep 2014 18:57:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97795 invoked by uid 99); 2 Sep 2014 18:57:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:57:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.48 as permitted sender)
Received: from [209.85.192.48] (HELO mail-qg0-f48.google.com) (209.85.192.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 18:57:42 +0000
Received: by mail-qg0-f48.google.com with SMTP id z107so6922291qgd.7
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 11:57:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=XzLu1R19rK4mG/71mTS0lX84hwmpkaI5LB4fzvwovaM=;
        b=NsGxUThmOkVAbHQ3a7ZoUULb9rIxh0zlaBbU8H28H5jdGbweShC+aQp3Y1HQ7gc9p8
         n6GgFzbJZmhA3xaNUKO7s7V6kNC3Sb00T7D2sQ477OkJLPJhgHyLwReurD6LzhO8w5Pg
         5rETwrB4knfn808zQaJWapVp8WWc1yi1D7yCYMK7NrpM30XJouONwsaX2GfRJdVRnjL9
         FpvpVQ4AmD3WQF1wITDcOAWMtKm2KyMilB8uXDHvNypS9sDDm+AMJWMM4HriUwTSRY1p
         mZ8xWIxskfFsUIuR4csitTycypm9Cf5DkgGTG/uRN0AtzSaCjPKH+RtLiSeF7G3agdsV
         2UtQ==
X-Received: by 10.224.62.8 with SMTP id v8mr58996089qah.9.1409684241316; Tue,
 02 Sep 2014 11:57:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.92.210 with HTTP; Tue, 2 Sep 2014 11:57:01 -0700 (PDT)
In-Reply-To: <etPan.540612ae.628c895d.cf9@joshs-mbp>
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com>
 <540589E8.8020107@huawei.com> <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com>
 <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com>
 <CAA_qdLpVTEZ2Vd1a9JTbFnssiCjZFwYbnE2sBRsZ5sQZgqWphg@mail.gmail.com> <etPan.540612ae.628c895d.cf9@joshs-mbp>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 2 Sep 2014 11:57:01 -0700
Message-ID: <CAA_qdLoqMO==zsg9mCUDPxejiYcQsYDV=1j2nP_O6vjj+r+_Yw@mail.gmail.com>
Subject: Re: about spark assembly jar
To: Josh Rosen <rosenville@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, Sean Owen <sowen@cloudera.com>, 
	Sandy Ryza <sandy.ryza@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	scwf <wangfei1@huawei.com>
Content-Type: multipart/alternative; boundary=089e0149cb7073035b050219b026
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149cb7073035b050219b026
Content-Type: text/plain; charset=UTF-8

Cool, didn't notice that, thanks Josh!


On Tue, Sep 2, 2014 at 11:55 AM, Josh Rosen <rosenville@gmail.com> wrote:

> SPARK_PREPEND_CLASSES is documented on the Spark Wiki (which could
> probably be easier to find):
> https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools
>
>
> On September 2, 2014 at 11:53:49 AM, Cheng Lian (lian.cs.zju@gmail.com)
> wrote:
>
> Yea, SSD + SPARK_PREPEND_CLASSES totally changed my life :)
>
> Maybe we should add a "developer notes" page to document all these useful
> black magic.
>
>
> On Tue, Sep 2, 2014 at 10:54 AM, Reynold Xin <rxin@databricks.com> wrote:
>
> > Having a SSD help tremendously with assembly time.
> >
> > Without that, you can do the following in order for Spark to pick up the
> > compiled classes before assembly at runtime.
> >
> > export SPARK_PREPEND_CLASSES=true
> >
> >
> > On Tue, Sep 2, 2014 at 9:10 AM, Sandy Ryza <sandy.ryza@cloudera.com>
> > wrote:
> >
> > > This doesn't help for every dependency, but Spark provides an option
> to
> > > build the assembly jar without Hadoop and its dependencies. We make
> use
> > of
> > > this in CDH packaging.
> > >
> > > -Sandy
> > >
> > >
> > > On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1@huawei.com> wrote:
> > >
> > > > Hi sean owen,
> > > > here are some problems when i used assembly jar
> > > > 1 i put spark-assembly-*.jar to the lib directory of my application,
> it
> > > > throw compile error
> > > >
> > > > Error:scalac: Error: class scala.reflect.BeanInfo not found.
> > > > scala.tools.nsc.MissingRequirementError: class
> scala.reflect.BeanInfo
> > not
> > > > found.
> > > >
> > > > at scala.tools.nsc.symtab.Definitions$definitions$.
> > > > getModuleOrClass(Definitions.scala:655)
> > > >
> > > > at scala.tools.nsc.symtab.Definitions$definitions$.
> > > > getClass(Definitions.scala:608)
> > > >
> > > > at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<
> > > > init>(GenJVM.scala:127)
> > > >
> > > > at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.
> > > > scala:85)
> > > >
> > > > at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
> > > >
> > > > at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
> > > >
> > > > at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)
> > > >
> > > > at
> > > xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)
> > > >
> > > > at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)
> > > >
> > > > at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
> > > >
> > > > at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >
> > > > at sun.reflect.NativeMethodAccessorImpl.invoke(
> > > > NativeMethodAccessorImpl.java:39)
> > > >
> > > > at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > > > DelegatingMethodAccessorImpl.java:25)
> > > >
> > > > at java.lang.reflect.Method.invoke(Method.java:597)
> > > >
> > > > at sbt.compiler.AnalyzingCompiler.call(
> > > > AnalyzingCompiler.scala:102)
> > > >
> > > > at sbt.compiler.AnalyzingCompiler.compile(
> > > > AnalyzingCompiler.scala:48)
> > > >
> > > > at sbt.compiler.AnalyzingCompiler.compile(
> > > > AnalyzingCompiler.scala:41)
> > > >
> > > > at org.jetbrains.jps.incremental.scala.local.
> > > > IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)
> > > >
> > > > at org.jetbrains.jps.incremental.scala.local.LocalServer.
> > > > compile(LocalServer.scala:25)
> > > >
> > > > at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.
> > > > scala:58)
> > > >
> > > > at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(
> > > > Main.scala:21)
> > > >
> > > > at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(
> > > > Main.scala)
> > > >
> > > > at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > > >
> > > > at sun.reflect.NativeMethodAccessorImpl.invoke(
> > > > NativeMethodAccessorImpl.java:39)
> > > >
> > > > at sun.reflect.DelegatingMethodAccessorImpl.invoke(
> > > > DelegatingMethodAccessorImpl.java:25)
> > > >
> > > > at java.lang.reflect.Method.invoke(Method.java:597)
> > > >
> > > > at
> > com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
> > > > 2 i test my branch which updated hive version to org.apache.hive
> 0.13.1
> > > > it run successfully when use a bag of 3rd jars as dependency but
> > throw
> > > > error using assembly jar, it seems assembly jar lead to conflict
> > > > ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
> > > > at org.apache.hadoop.hive.ql.io.parquet.serde.
> > > > ArrayWritableObjectInspector.getObjectInspector(
> > > > ArrayWritableObjectInspector.java:66)
> > > > at org.apache.hadoop.hive.ql.io.parquet.serde.
> > > >
> >
> ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
> > > > at org.apache.hadoop.hive.ql.io.parquet.serde.
> > > > ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
> > > > at org.apache.hadoop.hive.metastore.MetaStoreUtils.
> > > > getDeserializer(MetaStoreUtils.java:339)
> > > > at org.apache.hadoop.hive.ql.metadata.Table.
> > > > getDeserializerFromMetaStore(Table.java:283)
> > > > at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(
> > > > Table.java:189)
> > > > at org.apache.hadoop.hive.ql.metadata.Hive.createTable(
> > > > Hive.java:597)
> > > > at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(
> > > > DDLTask.java:4194)
> > > > at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.
> > > > java:281)
> > > > at
> > org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
> > > > at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(
> > > > TaskRunner.java:85)
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > On 2014/9/2 16:45, Sean Owen wrote:
> > > >
> > > >> Hm, are you suggesting that the Spark distribution be a bag of 100
> > > >> JARs? It doesn't quite seem reasonable. It does not remove version
> > > >> conflicts, just pushes them to run-time, which isn't good. The
> > > >> assembly is also necessary because that's where shading happens. In
> > > >> development, you want to run against exactly what will be used in a
> > > >> real Spark distro.
> > > >>
> > > >> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com> wrote:
> > > >>
> > > >>> hi, all
> > > >>> I suggest spark not use assembly jar as default run-time
> > > >>> dependency(spark-submit/spark-class depend on assembly jar),use a
> > > >>> library of
> > > >>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
> > > >>>
> > > >>> 1 assembly jar packaged all 3rd jars into a big one, so we need
> > > >>> rebuild
> > > >>> this jar if we want to update the version of some component(such
> as
> > > >>> hadoop)
> > > >>> 2 in our practice with spark, sometimes we meet jar compatibility
> > > >>> issue,
> > > >>> it is hard to diagnose compatibility issue with assembly jar
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> ---------------------------------------------------------------------
> > > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > >>> For additional commands, e-mail: dev-help@spark.apache.org
> > > >>>
> > > >>>
> > > >>
> > > >>
> > > >
> > > >
> > > >
> ---------------------------------------------------------------------
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > > >
> > >
> >
>
>

--089e0149cb7073035b050219b026--

From dev-return-9230-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 19:44:42 2014
Return-Path: <dev-return-9230-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4E11C11E7D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 19:44:42 +0000 (UTC)
Received: (qmail 60077 invoked by uid 500); 2 Sep 2014 19:44:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60009 invoked by uid 500); 2 Sep 2014 19:44:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59993 invoked by uid 99); 2 Sep 2014 19:44:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 19:44:41 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 209.85.215.44 as permitted sender)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 19:44:37 +0000
Received: by mail-la0-f44.google.com with SMTP id hz20so8506089lab.31
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 12:44:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IJ5ugRdlKn9T4chQ1u5acTmq5YctYVyh8V/ObqXOlyY=;
        b=BZQYujhowsAkbKQ/SsYogImXzHuvi9sWSkMhBcyZNgRIF9BQtrHj2RfZVcUFO0K9yy
         +GWJtWqGU1l4xxBTNQRW/v1f0e9ERv8SFfEJbPoQ7fzECITxRHwBIj2rjecjekftzU7v
         X6FcOCxPEGur2xpulhyjv/uTWJlHHvFFk2ngR6hIRPMmlzTibacb2GPFPmAtLmRgH5Nq
         j/qTH7L8OBDs3YiHtY1v6ss62iFf8d8RKye2q/PjLvNzxKasqH+YctLR6oSYKZ4Ca8P+
         tdC3465HRZPa5TIbQPQawSfIiVf9IomuJ4Vl7lrPIcKtwpI3i9BxPWpmabSh38l/XrFK
         2mbA==
MIME-Version: 1.0
X-Received: by 10.112.114.227 with SMTP id jj3mr35014407lbb.39.1409687055785;
 Tue, 02 Sep 2014 12:44:15 -0700 (PDT)
Received: by 10.25.205.204 with HTTP; Tue, 2 Sep 2014 12:44:15 -0700 (PDT)
In-Reply-To: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
Date: Tue, 2 Sep 2014 12:44:15 -0700
Message-ID: <CALuGr6arxV0wrY9GsUzOZkkf0eb8mKPE=7Cv99VzyBDTqbFTpg@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
From: Henry Saputra <henry.saputra@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Welcome Shane =)


- Henry

On Tue, Sep 2, 2014 at 10:35 AM, shane knapp <sknapp@berkeley.edu> wrote:
> so, i had a meeting w/the databricks guys on friday and they recommended i
> send an email out to the list to say 'hi' and give you guys a quick intro.
>  :)
>
> hi!  i'm shane knapp, the new AMPLab devops engineer, and will be spending
> time getting the jenkins build infrastructure up to production quality.
>  much of this will be 'under the covers' work, like better system level
> auth, backups, etc, but some will definitely be user facing:  timely
> jenkins updates, debugging broken build infrastructure and some plugin
> support.
>
> i've been working in the bay area now since 1997 at many different
> companies, and my last 10 years has been split between google and palantir.
>  i'm a huge proponent of OSS, and am really happy to be able to help with
> the work you guys are doing!
>
> if anyone has any requests/questions/comments, feel free to drop me a line!
>
> shane

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9231-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 20:08:17 2014
Return-Path: <dev-return-9231-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2FD0311FDB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 20:08:17 +0000 (UTC)
Received: (qmail 36094 invoked by uid 500); 2 Sep 2014 20:08:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36035 invoked by uid 500); 2 Sep 2014 20:08:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36023 invoked by uid 99); 2 Sep 2014 20:08:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 20:08:16 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=HTML_MESSAGE,MISSING_HEADERS,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.216.53 as permitted sender)
Received: from [209.85.216.53] (HELO mail-qa0-f53.google.com) (209.85.216.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 20:07:48 +0000
Received: by mail-qa0-f53.google.com with SMTP id w8so6752552qac.40
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 13:07:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:cc
         :content-type;
        bh=SpWXFb40wRAnkWJp7YYD6diimrPte93eoFd13+GkL+o=;
        b=IeMfCRrGE4qTRnPF+8FNbI7WNHXCyg+T5Qr5nqOf3BdqADi1cXCQrmj8lGQprlf9Ht
         I01pd2iUjGz9giU2cfL+hDPj0ecq7NbTUnuDbHZtPqr4zhBUUWPdexz8wsALZlXWKKsb
         aC64MnwD5BOFxL1AYhGlPgrvAmThKvYBZsdPkhIb1iP5j4MAZOukXZ9sSycvlhxvlup8
         NuvNGxu4XFQGc9t8y9GBSJdWv5muOrQMnr+BEtipYA5q4+mvUOOOXkN+Pk2tvchn1ITr
         PV5xt6fBav1oL8E6igtt6FCWhh3vi3jEs7bRtXHcAeZvn1A0yQh7T8AnSYHCcuLU6uou
         c3IQ==
X-Received: by 10.224.37.134 with SMTP id x6mt50715423qad.39.1409688467588;
 Tue, 02 Sep 2014 13:07:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.92.210 with HTTP; Tue, 2 Sep 2014 13:07:27 -0700 (PDT)
In-Reply-To: <CALuGr6arxV0wrY9GsUzOZkkf0eb8mKPE=7Cv99VzyBDTqbFTpg@mail.gmail.com>
References: <CACdU-dRB6BvuN7YeN8aJ3fVa5E4NKNvMxSdx8+UzxyT5_eMFjA@mail.gmail.com>
 <CALuGr6arxV0wrY9GsUzOZkkf0eb8mKPE=7Cv99VzyBDTqbFTpg@mail.gmail.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 2 Sep 2014 13:07:27 -0700
Message-ID: <CAA_qdLrwjmruydgH1txEG2YXFXm3Sn4PUgab=AzQHwP3yY3U4Q@mail.gmail.com>
Subject: Re: hey spark developers! intro from shane knapp, devops engineer @ AMPLab
Cc: shane knapp <sknapp@berkeley.edu>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1f4a25b1f1305021aac27
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1f4a25b1f1305021aac27
Content-Type: text/plain; charset=UTF-8

Welcome Shane! Glad to see that finally a hero jumping out to tame Jenkins
:)


On Tue, Sep 2, 2014 at 12:44 PM, Henry Saputra <henry.saputra@gmail.com>
wrote:

> Welcome Shane =)
>
>
> - Henry
>
> On Tue, Sep 2, 2014 at 10:35 AM, shane knapp <sknapp@berkeley.edu> wrote:
> > so, i had a meeting w/the databricks guys on friday and they recommended
> i
> > send an email out to the list to say 'hi' and give you guys a quick
> intro.
> >  :)
> >
> > hi!  i'm shane knapp, the new AMPLab devops engineer, and will be
> spending
> > time getting the jenkins build infrastructure up to production quality.
> >  much of this will be 'under the covers' work, like better system level
> > auth, backups, etc, but some will definitely be user facing:  timely
> > jenkins updates, debugging broken build infrastructure and some plugin
> > support.
> >
> > i've been working in the bay area now since 1997 at many different
> > companies, and my last 10 years has been split between google and
> palantir.
> >  i'm a huge proponent of OSS, and am really happy to be able to help with
> > the work you guys are doing!
> >
> > if anyone has any requests/questions/comments, feel free to drop me a
> line!
> >
> > shane
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c1f4a25b1f1305021aac27--

From dev-return-9232-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 21:30:47 2014
Return-Path: <dev-return-9232-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D5A6B11400
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 21:30:47 +0000 (UTC)
Received: (qmail 43396 invoked by uid 500); 2 Sep 2014 21:30:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43332 invoked by uid 500); 2 Sep 2014 21:30:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43321 invoked by uid 99); 2 Sep 2014 21:30:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 21:30:46 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wibenton@redhat.com designates 209.132.183.25 as permitted sender)
Received: from [209.132.183.25] (HELO mx4-phx2.redhat.com) (209.132.183.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 21:30:41 +0000
Received: from zmail14.collab.prod.int.phx2.redhat.com (zmail14.collab.prod.int.phx2.redhat.com [10.5.83.16])
	by mx4-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s82LUIqt023314;
	Tue, 2 Sep 2014 17:30:18 -0400
Date: Tue, 2 Sep 2014 17:30:18 -0400 (EDT)
From: Will Benton <willb@redhat.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: dev@spark.apache.org
Message-ID: <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
In-Reply-To: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.6]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - FF31 (Mac)/8.0.6_GA_5922)
Thread-Topic: Release Apache Spark 1.1.0 (RC3)
Thread-Index: WzZk92GnvvgzHDv44fjF9LiA9ep1lg==
X-Virus-Checked: Checked by ClamAV on apache.org

+1

Tested Scala/MLlib apps on Fedora 20 (OpenJDK 7) and OS X 10.9 (Oracle JDK 8).


best,
wb


----- Original Message -----
> From: "Patrick Wendell" <pwendell@gmail.com>
> To: dev@spark.apache.org
> Sent: Saturday, August 30, 2014 5:07:52 PM
> Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)
> 
> Please vote on releasing the following candidate as Apache Spark version
> 1.1.0!
> 
> The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b2d0493b223c5f98a593bb6d7372706cc02bebad
> 
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc3/
> 
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
> 
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1030/
> 
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
> 
> Please vote on releasing this package as Apache Spark 1.1.0!
> 
> The vote is open until Tuesday, September 02, at 23:07 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
> 
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
> 
> To learn more about Apache Spark, please see
> http://spark.apache.org/
> 
> == Regressions fixed since RC1 ==
> - Build issue for SQL support:
> https://issues.apache.org/jira/browse/SPARK-3234
> - EC2 script version bump to 1.1.0.
> 
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
> 
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
> 
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9233-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 22:09:33 2014
Return-Path: <dev-return-9233-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4826611578
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 22:09:33 +0000 (UTC)
Received: (qmail 36583 invoked by uid 500); 2 Sep 2014 22:09:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36520 invoked by uid 500); 2 Sep 2014 22:09:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36508 invoked by uid 99); 2 Sep 2014 22:09:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:09:32 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=HTML_MESSAGE,MISSING_HEADERS,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.43 as permitted sender)
Received: from [209.85.192.43] (HELO mail-qg0-f43.google.com) (209.85.192.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:09:27 +0000
Received: by mail-qg0-f43.google.com with SMTP id f51so7308097qge.16
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 15:09:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:cc
         :content-type;
        bh=hcYZD04dVJX6E6WivGt54Hqp/MhcBv39TKHQjRVK5Pg=;
        b=CreBsyln/Pwgc5btXmKquWUDABZ8x1nYSk5hqboIkNM6TncD3YKJ20ydAoxczy3Ir+
         V1G0lXIhWOEvccXC7hTaOQm9z3JyzZrmFXOiNbZGEAnNUdC3E+C287LOBfjkxBvyupSZ
         9Oo3tbXBOwVEHgLogjacqFV0oRNNdJuG+tyCkJxqdhL1jHx2bCNcl2OKf3TH5Wl24qho
         mV3u7Mnq/Rg9vsMu9tuOzbGJlyjOMIuu3MuaeI3KxUHhzoIKDZjfDMfmuuGDHanM734Q
         NGP5mlzpCyxaj/95V34spdLqfKpLf6HbHRd2UKP+pHNfXPJg7kJSzWpxtdWAYT3bsUZz
         QdJA==
X-Received: by 10.224.62.8 with SMTP id v8mt51354884qah.9.1409695746527; Tue,
 02 Sep 2014 15:09:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.92.210 with HTTP; Tue, 2 Sep 2014 15:08:46 -0700 (PDT)
In-Reply-To: <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 2 Sep 2014 15:08:46 -0700
Message-ID: <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0149cb70370d7605021c5ecf
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149cb70370d7605021c5ecf
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

+1

   - Tested Thrift server and SQL CLI locally on OSX 10.9.
   - Checked datanucleus dependencies in distribution tarball built by
   make-distribution.sh without SPARK_HIVE defined.

=E2=80=8B


On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb@redhat.com> wrote:

> +1
>
> Tested Scala/MLlib apps on Fedora 20 (OpenJDK 7) and OS X 10.9 (Oracle JD=
K
> 8).
>
>
> best,
> wb
>
>
> ----- Original Message -----
> > From: "Patrick Wendell" <pwendell@gmail.com>
> > To: dev@spark.apache.org
> > Sent: Saturday, August 30, 2014 5:07:52 PM
> > Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)
> >
> > Please vote on releasing the following candidate as Apache Spark versio=
n
> > 1.1.0!
> >
> > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db2d0=
493b223c5f98a593bb6d7372706cc02bebad
> >
> > The release files, including signatures, digests, etc. can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc3/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-1030/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
> >
> > Please vote on releasing this package as Apache Spark 1.1.0!
> >
> > The vote is open until Tuesday, September 02, at 23:07 UTC and passes i=
f
> > a majority of at least 3 +1 PMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 1.1.0
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.apache.org/
> >
> > =3D=3D Regressions fixed since RC1 =3D=3D
> > - Build issue for SQL support:
> > https://issues.apache.org/jira/browse/SPARK-3234
> > - EC2 script version bump to 1.1.0.
> >
> > =3D=3D What justifies a -1 vote for this release? =3D=3D
> > This vote is happening very late into the QA period compared with
> > previous votes, so -1 votes should only occur for significant
> > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > this release.
> >
> > =3D=3D What default changes should I be aware of? =3D=3D
> > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > --> Old behavior can be restored by switching to "lzf"
> >
> > 2. PySpark now performs external spilling during aggregations.
> > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> "false".
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0149cb70370d7605021c5ecf--

From dev-return-9234-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 22:14:26 2014
Return-Path: <dev-return-9234-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 560BE11594
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 22:14:26 +0000 (UTC)
Received: (qmail 46666 invoked by uid 500); 2 Sep 2014 22:14:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46606 invoked by uid 500); 2 Sep 2014 22:14:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46595 invoked by uid 99); 2 Sep 2014 22:14:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:14:25 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:14:18 +0000
Received: by mail-qg0-f52.google.com with SMTP id z60so7207690qgd.25
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 15:13:57 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:from:content-type:subject:message-id:date:to
         :mime-version;
        bh=yoAW6qFGVx/uht0RkpJ/Eh3ehP7hBX3D/JtMaM3YMck=;
        b=JVk+bp5OGq9yFBcwekVB99tLx9HzpBL5mmSxavmaeJALm8Q9Em5SjtuKpLmWiUWaej
         lbjV6/pN1eql57LFSLFO37PIW77oSW0PD56t860r/edusrLIWjCGqHEjdEAR+9McK9tN
         n5Bw6gimkgOcC6+8x7Dga0iB3hyVX/Y7SrBDt7EQUEsRP20G00avSrClWT2oWsPXcGmT
         K9Il/kIneXNI64EpFXZoldU2Nb5GTBO0ttEGWZSBkMpw8v5/UzL4q+btbj6xYZAmLFVt
         mMLM/I8wbHlhXRRwiO52I42uIYDtJ6KNkp9oD8ig2A+rWxrY2Ag6lhd3gEmxpy89ERWa
         at3w==
X-Gm-Message-State: ALoCoQkI/0IPuNF88qoBpoNwriSwRlOmk/umjq6S04RWC+euLHSiik2YM+uZN2h+ERzj54G8DVSF
X-Received: by 10.229.229.135 with SMTP id ji7mr60105217qcb.15.1409696037401;
        Tue, 02 Sep 2014 15:13:57 -0700 (PDT)
Received: from 187.corp01.nym1.placeiq.net ([38.125.17.226])
        by mx.google.com with ESMTPSA id u95sm6598004qgu.35.2014.09.02.15.13.56
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 02 Sep 2014 15:13:56 -0700 (PDT)
From: Jeffrey Picard <jpicard@placeiq.com>
Content-Type: multipart/signed; boundary="Apple-Mail=_71AF9905-0855-41BF-AE8E-C5A9964EE691"; protocol="application/pgp-signature"; micalg=pgp-sha512
Subject: Checkpointing Pregel
Message-Id: <F4739FA2-DE87-4E86-A439-D4C8B439CE2A@placeiq.com>
Date: Tue, 2 Sep 2014 18:13:55 -0400
To: dev <dev@spark.apache.org>
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_71AF9905-0855-41BF-AE8E-C5A9964EE691
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

Hey guys,

I=92m trying to run connected components on graphs that end up running =
for a fairly large number of iterations (25-30) and take 5-6 hours. I =
find more than half the time I end up getting fetch failures and losing =
an executor after a number of iterations. Then it has to go back and =
recompute pieces that it lost, which don=92t seem to be getting =
persisted at the same level as the graph so those iterations take =
exponentially longer and I have to kill the job because it=92s not worth =
waiting for it to finish.

The approach I=92m currently trying is checkpointing the vertices and =
edges (and maybe the messages?) in Pregel. What I=92ve been testing with =
so far is the below patch, which seems to be working (actually I haven=92t=
 had any failures since I added this change, so I don=92t know if I did =
get one if it would recompute from the start or not) but I=92m also =
seeing things like 5 instances of VertexRDDs being persisted all at the =
same time and =93reduce at VertexRDD.scala:111=94 runs twice each time. =
I was wondering if this is the proper / most efficient way of doing this =
checkpointing, and if not what would work better?

diff --git a/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala =
b/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala
index 5e55620..5be40c3 100644
--- a/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala
+++ b/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala
@@ -134,6 +134,11 @@ object Pregel extends Logging {
       g =3D g.outerJoinVertices(newVerts) { (vid, old, newOpt) =3D> =
newOpt.getOrElse(old) }
       g.cache()

+      g.vertices.checkpoint()
+      g.vertices.count()
+      g.edges.checkpoint()
+      g.edges.count()
+
       val oldMessages =3D messages
       // Send new messages. Vertices that didn't get any messages don't =
appear in newVerts, so don't
       // get to send messages. We must cache messages so it can be =
materialized on the next line,
@@ -142,6 +147,7 @@ object Pregel extends Logging {
       // The call to count() materializes `messages`, `newVerts`, and =
the vertices of `g`. This
       // hides oldMessages (depended on by newVerts), newVerts =
(depended on by messages), and the
       // vertices of prevG (depended on by newVerts, oldMessages, and =
the vertices of g).
+         messages.checkpoint()
       activeMessages =3D messages.count()

       logInfo("Pregel finished iteration " + i)

Best Regards,

Jeffrey Picard

--Apple-Mail=_71AF9905-0855-41BF-AE8E-C5A9964EE691
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
	filename=signature.asc
Content-Type: application/pgp-signature;
	name=signature.asc
Content-Description: Message signed with OpenPGP using GPGMail

-----BEGIN PGP SIGNATURE-----
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJUBkEjAAoJEC0tCmi2+GvE2TEP/jHarF8RZ63TETwZGEyc4iiN
MNLFuMlHnU4GImTAQwzR6uc+b/9eJ/SIjVx+ke55fa4iMXmzhDhgmyC4hDldixpb
sSqEK/g1+5sRg0rGkuB1Ui27LgncSk4tn7p6K1Zy404GC/STd9waou4Mtab5oBZL
irAvAJK/tMwpVrVOwfEBRmMQEXWMwKdYhTNunhiUcZRq18IHpgesky8glUDm/NZG
+NvKJjUL2P5q2t6sG6mrtVyytx5fBuk+mxDHHfdDa7Fzk+3p69vqwOcB3sBOhaVq
6472FcRrGjdfCnGEdjo5Gm5j4vdpeBc3tWnVvyaABYungNeTOH7CN2DHok09p54X
8HfITNWboaXB2tNDhTAab1X9Zhm2TWTQMikSN7TtftueUtZaos7kGXcHUMCuDexq
JMPtZYvXpvv0oRLjZfK3ZRrIC9cmfIwknbO9ArbIyQcPHqUVEMsejhuUPbaYjUdJ
nKGdl/+wVOkPj5F0PEqwNJpPmdWVyYdrI0TXV3bSp3zlURJqWeXLMzVZ9wcZqjsN
pCEhvSg7RbeFhiMwq1Ift+AuQPIdimW7en/OnCTlP1lk9l2WctEEPPRCLS+OebBR
rXTLuCaIlH+VZaTecYsUcRUw1/hij2Lj3/T7ibgtEqltUOwMJcaWnQbQyrD/KDci
6LZHuo6qNZ1Gn2fapjd9
=8pr9
-----END PGP SIGNATURE-----

--Apple-Mail=_71AF9905-0855-41BF-AE8E-C5A9964EE691--

From dev-return-9235-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 22:31:34 2014
Return-Path: <dev-return-9235-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E45E51163C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 22:31:33 +0000 (UTC)
Received: (qmail 90200 invoked by uid 500); 2 Sep 2014 22:31:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90136 invoked by uid 500); 2 Sep 2014 22:31:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90124 invoked by uid 99); 2 Sep 2014 22:31:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:31:32 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_IMAGE_ONLY_28,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of phoenixlee1@gmail.com designates 209.85.216.175 as permitted sender)
Received: from [209.85.216.175] (HELO mail-qc0-f175.google.com) (209.85.216.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:31:26 +0000
Received: by mail-qc0-f175.google.com with SMTP id c9so7623405qcz.20
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 15:31:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=9wd8nln471pdHEpP1zyzAi4PWMqZhxntcrTnROgteRg=;
        b=Kx+keqkCr9CIeXf2a4+D1oxGs+gR1iQOmgsT5I1jdiSPh0EogCydBJ2SdGvwGYNaH7
         lpXfU+Z0v88kDzRzxjUu3/FYOptEJ8rfcASUrgOkyLUqLxHVNUi4r0Tp09OtfTODWCWo
         gqFidH2cNDWhhUT45aoIK5kNL3J5BK1jYbpkqPQUBiQubFNj5FcO+LfjHciRs49gVHF5
         VYTnz1zSy+xQqBnmErhPTH6prS1rxYRs41TpFFiqNm0B8fm5mo5tAgL08XLFb0sOkLaw
         S23baF08JCnYvnZIK1yNHsGd5ukwI2kkqm+tkU7twycD35wMq4oDeKK++t1veH1Oc6Ri
         wHoA==
MIME-Version: 1.0
X-Received: by 10.224.120.138 with SMTP id d10mr350232qar.8.1409697066148;
 Tue, 02 Sep 2014 15:31:06 -0700 (PDT)
Received: by 10.229.223.198 with HTTP; Tue, 2 Sep 2014 15:31:06 -0700 (PDT)
Date: Wed, 3 Sep 2014 07:31:06 +0900
Message-ID: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com>
Subject: Ask something about spark
From: Sanghoon Lee <phoenixlee1@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2eea0de6d1705021caca7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2eea0de6d1705021caca7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi, I am phoenixlee and a Spark programmer in Korea.

And be a good chance this time, it tries to teach college students and
office workers to Spark.
This course will be done with the support of the government. Can I use the
data(pictures, samples, etc.) in the spark homepage for this course? Of
course, I will put the comments in thanks and webpage URL. It would be a
good opportunity, even though the findings were that there is no teaching
materials "Spark" and education (or community) still in Korea.

Thanks.
=E1=90=A7

--001a11c2eea0de6d1705021caca7--

From dev-return-9236-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 22:33:33 2014
Return-Path: <dev-return-9236-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E9A7711644
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 22:33:32 +0000 (UTC)
Received: (qmail 92259 invoked by uid 500); 2 Sep 2014 22:33:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92192 invoked by uid 500); 2 Sep 2014 22:33:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92181 invoked by uid 99); 2 Sep 2014 22:33:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:33:30 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.182] (HELO mail-qc0-f182.google.com) (209.85.216.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 22:33:04 +0000
Received: by mail-qc0-f182.google.com with SMTP id m20so7882512qcx.27
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 15:33:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=jepiCHngPIGFvaTD6O81VxtLjUKWtKohftU/GnHqRmk=;
        b=SaWMFm2EKYxtHyejsUIcNaWd/M5h1NOQjzRUZl8OvGsUQ+L8pmkpBl1GMmOygzWDc5
         X0p+ywetvVx41EOwsWdmlqLd5r1g1+XCGWlMc03sEVn//Vs3f+YM4aae+2SL18WBArdT
         Y+4PQmZ0bHEybZH6rBFlidHYqqZtU1ATX3ot8NnNZh9LQWpw8OaJgrcdAIywaRYwc+Ww
         q3ccZPQLb5G1BeZPVau/Vmt5CcwFV4O3yBWUJDZy8/5Ty0EpZ0sTLEZKeOG5xS0oO0/A
         EbY2plQRpffNQyyAphmWW4CtzNJzUn0YlmR0vRzwEc9IrXixjpfsyWwbUtqS17zWVwME
         y7zw==
X-Gm-Message-State: ALoCoQliLFBQlcXp/+HrA6pKULBMh/2sYmFw0TQGfGirkCsNA5EI1SIJtewTSF03nhaV3i/T0eWU
X-Received: by 10.140.96.85 with SMTP id j79mr58263764qge.5.1409697182637;
 Tue, 02 Sep 2014 15:33:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Tue, 2 Sep 2014 15:32:41 -0700 (PDT)
In-Reply-To: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com>
References: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 2 Sep 2014 15:32:41 -0700
Message-ID: <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com>
Subject: Re: Ask something about spark
To: Sanghoon Lee <phoenixlee1@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113ac468d0332705021cb3f7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ac468d0332705021cb3f7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I think in general that is fine. It would be great if your slides come with
proper attribution.


On Tue, Sep 2, 2014 at 3:31 PM, Sanghoon Lee <phoenixlee1@gmail.com> wrote:

> Hi, I am phoenixlee and a Spark programmer in Korea.
>
> And be a good chance this time, it tries to teach college students and
> office workers to Spark.
> This course will be done with the support of the government. Can I use th=
e
> data(pictures, samples, etc.) in the spark homepage for this course? Of
> course, I will put the comments in thanks and webpage URL. It would be a
> good opportunity, even though the findings were that there is no teaching
> materials "Spark" and education (or community) still in Korea.
>
> Thanks.
> =E1=90=A7
>

--001a113ac468d0332705021cb3f7--

From dev-return-9237-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  2 23:11:10 2014
Return-Path: <dev-return-9237-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 589EE117A9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  2 Sep 2014 23:11:10 +0000 (UTC)
Received: (qmail 93972 invoked by uid 500); 2 Sep 2014 23:11:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93905 invoked by uid 500); 2 Sep 2014 23:11:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93894 invoked by uid 99); 2 Sep 2014 23:11:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 23:11:09 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 02 Sep 2014 23:10:43 +0000
Received: by mail-qg0-f45.google.com with SMTP id e89so7320777qgf.4
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 16:10:41 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=4qitqSrjquI09RSPPbDIR1P3YFrKe3DT3xY7MZNBYU0=;
        b=WUifVVfnOYck+jl2ktneYF3LzDT5Hx8iq5v9CoCuAwwPUQUXd1FDReWT+oC3GPqDPJ
         F8vk7cb16cIA2XLYMyjIehPkO6Q8sRntCVodQXo2Y8aYGcfoewuu4HFmPyGd+SdFA72f
         PjK92Js6ybNaO2QvQkJvWugoxWNwd4keoIxtLoRNXEcOg9c0ihOavwodcOFD4Ssy3AaH
         XIECW8gA+5fVcxZSdlzMhHW8FcVDbdezfdHdtihmu0pNqPpOviuckBYJYRvb19FCTxU/
         lTLcgxnK9PR1Rw6QRjzFwlJ/d+W+lLGyT0Bs2Ko7hbm3QaI1O95bdC49sm7tQaMxA23F
         Z/wA==
X-Gm-Message-State: ALoCoQlBtF2Tmf5d/wH1M3XvmiG0IFBhuK9WGb3YUpN6Lb3g9y1DLBW6GnfWSxasNgDPJe6WKjDw
X-Received: by 10.224.114.136 with SMTP id e8mr20728069qaq.67.1409699441493;
 Tue, 02 Sep 2014 16:10:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Tue, 2 Sep 2014 16:10:21 -0700 (PDT)
In-Reply-To: <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com> <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 2 Sep 2014 16:10:21 -0700
Message-ID: <CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bea3b7473b6be05021d3aa0
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea3b7473b6be05021d3aa0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

+1


On Tue, Sep 2, 2014 at 3:08 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:

> +1
>
>    - Tested Thrift server and SQL CLI locally on OSX 10.9.
>    - Checked datanucleus dependencies in distribution tarball built by
>    make-distribution.sh without SPARK_HIVE defined.
>
> =E2=80=8B
>
>
> On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb@redhat.com> wrote:
>
> > +1
> >
> > Tested Scala/MLlib apps on Fedora 20 (OpenJDK 7) and OS X 10.9 (Oracle
> JDK
> > 8).
> >
> >
> > best,
> > wb
> >
> >
> > ----- Original Message -----
> > > From: "Patrick Wendell" <pwendell@gmail.com>
> > > To: dev@spark.apache.org
> > > Sent: Saturday, August 30, 2014 5:07:52 PM
> > > Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)
> > >
> > > Please vote on releasing the following candidate as Apache Spark
> version
> > > 1.1.0!
> > >
> > > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db2d0=
493b223c5f98a593bb6d7372706cc02bebad
> > >
> > > The release files, including signatures, digests, etc. can be found a=
t:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc3/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1030/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
> > >
> > > Please vote on releasing this package as Apache Spark 1.1.0!
> > >
> > > The vote is open until Tuesday, September 02, at 23:07 UTC and passes
> if
> > > a majority of at least 3 +1 PMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.apache.org/
> > >
> > > =3D=3D Regressions fixed since RC1 =3D=3D
> > > - Build issue for SQL support:
> > > https://issues.apache.org/jira/browse/SPARK-3234
> > > - EC2 script version bump to 1.1.0.
> > >
> > > =3D=3D What justifies a -1 vote for this release? =3D=3D
> > > This vote is happening very late into the QA period compared with
> > > previous votes, so -1 votes should only occur for significant
> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > > this release.
> > >
> > > =3D=3D What default changes should I be aware of? =3D=3D
> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > > --> Old behavior can be restored by switching to "lzf"
> > >
> > > 2. PySpark now performs external spilling during aggregations.
> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> > "false".
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--047d7bea3b7473b6be05021d3aa0--

From dev-return-9238-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:03:19 2014
Return-Path: <dev-return-9238-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6E89F11949
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:03:19 +0000 (UTC)
Received: (qmail 7617 invoked by uid 500); 3 Sep 2014 00:03:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7552 invoked by uid 500); 3 Sep 2014 00:03:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7540 invoked by uid 99); 3 Sep 2014 00:03:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:03:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kanzhangemail@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:02:52 +0000
Received: by mail-ie0-f175.google.com with SMTP id y20so8690405ier.20
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:02:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:reply-to:sender:in-reply-to:references:date:message-id
         :subject:from:to:cc:content-type;
        bh=apeEvZerrBdahkULfwYmNCActuqmrTFguP2M8HIEKCE=;
        b=jRyHi2l3OHF9XR1DbYyJdpczZYacR9OE8dhcWhTyW/OYnM8zunfssL+pwKD4Tnll9/
         /Ex+ls4rFyth+TZq5iRO/VKoUUzV0K5YP+0c+E6pvSOUARlKrSNEqynTCkkMG2CKXkDU
         9WyDWULvUaVmuD4HAL0lR26xC0+9Q79Ja4uN7Qqc8HIS+ykDy010MFSz+NOj1Qo8qQbQ
         GDlkpQdHCnDJ2u9Ssxx7VdJ240pEjDKUrfuf4GqCfA2gs21raUNmo7UBXUfMw6yfrIXD
         5Cfbz7Y4ZnoCofycrH1wyycEeg3YlrdW3EM9RpBPl9PJhI0S1C67ON8C6dACJD7fhuGX
         7e0Q==
MIME-Version: 1.0
X-Received: by 10.50.115.73 with SMTP id jm9mr31877337igb.3.1409702570944;
 Tue, 02 Sep 2014 17:02:50 -0700 (PDT)
Reply-To: kzhang@apache.org
Sender: kanzhangemail@gmail.com
Received: by 10.64.68.163 with HTTP; Tue, 2 Sep 2014 17:02:50 -0700 (PDT)
In-Reply-To: <CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
	<717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
	<CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
	<CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
Date: Tue, 2 Sep 2014 17:02:50 -0700
X-Google-Sender-Auth: vJCXnAK9QrnAY-A3Scu20CzGOFg
Message-ID: <CALRHqP9FFSsD5SC+6z1nieoYs=+QjBMp1pLCEFbTRtCTRpmoXw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
From: Kan Zhang <kzhang@apache.org>
To: Reynold Xin <rxin@databricks.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122a230faef8305021df42d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a230faef8305021df42d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

+1

Verified PySpark InputFormat/OutputFormat examples.


On Tue, Sep 2, 2014 at 4:10 PM, Reynold Xin <rxin@databricks.com> wrote:

> +1
>
>
> On Tue, Sep 2, 2014 at 3:08 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>
> > +1
> >
> >    - Tested Thrift server and SQL CLI locally on OSX 10.9.
> >    - Checked datanucleus dependencies in distribution tarball built by
> >    make-distribution.sh without SPARK_HIVE defined.
> >
> > =E2=80=8B
> >
> >
> > On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb@redhat.com> wrote:
> >
> > > +1
> > >
> > > Tested Scala/MLlib apps on Fedora 20 (OpenJDK 7) and OS X 10.9 (Oracl=
e
> > JDK
> > > 8).
> > >
> > >
> > > best,
> > > wb
> > >
> > >
> > > ----- Original Message -----
> > > > From: "Patrick Wendell" <pwendell@gmail.com>
> > > > To: dev@spark.apache.org
> > > > Sent: Saturday, August 30, 2014 5:07:52 PM
> > > > Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)
> > > >
> > > > Please vote on releasing the following candidate as Apache Spark
> > version
> > > > 1.1.0!
> > > >
> > > > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
> > > >
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db2d0=
493b223c5f98a593bb6d7372706cc02bebad
> > > >
> > > > The release files, including signatures, digests, etc. can be found
> at:
> > > > http://people.apache.org/~pwendell/spark-1.1.0-rc3/
> > > >
> > > > Release artifacts are signed with the following key:
> > > > https://people.apache.org/keys/committer/pwendell.asc
> > > >
> > > > The staging repository for this release can be found at:
> > > >
> > https://repository.apache.org/content/repositories/orgapachespark-1030/
> > > >
> > > > The documentation corresponding to this release can be found at:
> > > > http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
> > > >
> > > > Please vote on releasing this package as Apache Spark 1.1.0!
> > > >
> > > > The vote is open until Tuesday, September 02, at 23:07 UTC and pass=
es
> > if
> > > > a majority of at least 3 +1 PMC votes are cast.
> > > >
> > > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > > [ ] -1 Do not release this package because ...
> > > >
> > > > To learn more about Apache Spark, please see
> > > > http://spark.apache.org/
> > > >
> > > > =3D=3D Regressions fixed since RC1 =3D=3D
> > > > - Build issue for SQL support:
> > > > https://issues.apache.org/jira/browse/SPARK-3234
> > > > - EC2 script version bump to 1.1.0.
> > > >
> > > > =3D=3D What justifies a -1 vote for this release? =3D=3D
> > > > This vote is happening very late into the QA period compared with
> > > > previous votes, so -1 votes should only occur for significant
> > > > regressions from 1.0.2. Bugs already present in 1.0.X will not bloc=
k
> > > > this release.
> > > >
> > > > =3D=3D What default changes should I be aware of? =3D=3D
> > > > 1. The default value of "spark.io.compression.codec" is now "snappy=
"
> > > > --> Old behavior can be restored by switching to "lzf"
> > > >
> > > > 2. PySpark now performs external spilling during aggregations.
> > > > --> Old behavior can be restored by setting "spark.shuffle.spill" t=
o
> > > "false".
> > > >
> > > > -------------------------------------------------------------------=
--
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > > >
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--089e0122a230faef8305021df42d--

From dev-return-9239-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:08:37 2014
Return-Path: <dev-return-9239-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 902E41196E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:08:37 +0000 (UTC)
Received: (qmail 20628 invoked by uid 500); 3 Sep 2014 00:08:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20562 invoked by uid 500); 3 Sep 2014 00:08:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20551 invoked by uid 99); 3 Sep 2014 00:08:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:08:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.174 as permitted sender)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:08:10 +0000
Received: by mail-lb0-f174.google.com with SMTP id p9so8470711lbv.5
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:08:09 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=kHq+Ttty64P9t6VFCc0Ri+/QD33qkqpt2XJJfcRa6tE=;
        b=AfrVQZf5HSci33QURChcUb4Dpzwj41kIv9C4RHJwQCTGTrZpNU7yy74lAUZTlYiDkM
         3VyUopm7DpssfzlHt6VHjAfzmBdbb+U1pntMjjEBa+G90aLctgg1kE8aQgUSoyEIqqTW
         6JJTJgpgJO5MbH6p848ZAfFkn/fFgQ6hQ997jP6EUskUR7mb8cLjvLKyNWlofk8X+je7
         97J+jHA4y1fJRoCV7LAdUqoFeOx/ZQui2mEz3liRscXOnwQMBQs1Al3Ea4CL9v3tlT7R
         BwCYhimhaB7k3DON8uhVP4h3gpcAnPnHL6udSXJusolzWvj7Y/54l+6MLXdGBTgQ7QlK
         XJzA==
X-Gm-Message-State: ALoCoQkEIWX54CvGGQAnqXMslad8vBxcPEqnpZECjyiPW+5LeCs1gFED0Dng7Fe99EDSh1HJEMqF
X-Received: by 10.112.134.169 with SMTP id pl9mr17140483lbb.75.1409702888849;
 Tue, 02 Sep 2014 17:08:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Tue, 2 Sep 2014 17:07:48 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 2 Sep 2014 17:07:48 -0700
Message-ID: <CACdU-dRYXsumR0-uqyDC4TGUL6gkRoQhCM1OX2PnNwKjtQXA5A@mail.gmail.com>
Subject: quick jenkins restart
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011767e9ee456305021e078c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011767e9ee456305021e078c
Content-Type: text/plain; charset=UTF-8

since our queue is really short, i'm waiting for a couple of builds to
finish and will be restarting jenkins to install/update some plugins.  the
github pull request builder looks like it has some fixes to reduce spammy
github calls, and reduce any potential rate limiting.

i'll let everyone know when it's back up...  this should be super quick
(~15 mins for tests to finish, ~2 mins for jenkins to restart).

thanks in advance!

shane

--089e011767e9ee456305021e078c--

From dev-return-9240-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:19:02 2014
Return-Path: <dev-return-9240-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4AC33119EF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:19:02 +0000 (UTC)
Received: (qmail 45711 invoked by uid 500); 3 Sep 2014 00:19:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45640 invoked by uid 500); 3 Sep 2014 00:19:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45625 invoked by uid 99); 3 Sep 2014 00:19:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:19:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:18:56 +0000
Received: by mail-pd0-f169.google.com with SMTP id y10so394021pdj.0
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:18:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=VQKQvf7tgdcU+eJqlQg0xX/q69vOQc5UFY3ddzcLboo=;
        b=X3KYy9UY51NHrdCRYZVXe7MFMTv3CdS9rR9NfSvpnvpqZY6Xt1UU/Q0Rk7sY6BVBpL
         oChNEzr3P3iBNj8+BDccLNhaKzoqTHMmU4aeXnl4SLBOpz4KaDcCUD8dOtJIO4wDQG+n
         4U1XR+kDVwJmHa4BjsbLIgDp+o/pZydMNJ3TfhKi0ySvf6hq9F7+hrJxh43d4WDJIJmx
         1GWmCl6FN9E+AoY7ce9+x9JU1XmkDKjkT07en+7kfaOO3UfKscpPaGOpog+lSt2Zj32j
         vttQKNuGSUSNVTJG9JyNL7uPa6DFMwPY6zaWYs8u+tWkNmdLgW82VLYkAmS0A83bWCT5
         2PlQ==
X-Received: by 10.66.120.99 with SMTP id lb3mr7378507pab.152.1409703516012;
        Tue, 02 Sep 2014 17:18:36 -0700 (PDT)
Received: from mbp-3 (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id qc3sm13467962pab.48.2014.09.02.17.18.30
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 02 Sep 2014 17:18:31 -0700 (PDT)
Date: Tue, 2 Sep 2014 17:18:30 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Reynold Xin <rxin@databricks.com>, kzhang@apache.org
Cc: Cheng Lian <lian.cs.zju@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Patrick
 Wendell <pwendell@gmail.com>
Message-ID: <etPan.54065e56.71f32454.8aeb@mbp-3>
In-Reply-To: <CALRHqP9FFSsD5SC+6z1nieoYs=+QjBMp1pLCEFbTRtCTRpmoXw@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
 <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
 <CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
 <CALRHqP9FFSsD5SC+6z1nieoYs=+QjBMp1pLCEFbTRtCTRpmoXw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54065e56_2ca88611_8aeb"
X-Virus-Checked: Checked by ClamAV on apache.org

--54065e56_2ca88611_8aeb
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

+1

Tested on Mac OS X.

Matei

On September 2, 2014 at 5:03:19 PM, Kan Zhang (kzhang=40apache.org) wrote=
:

+1 =20

Verified PySpark Input=46ormat/Output=46ormat examples. =20


On Tue, Sep 2, 2014 at 4:10 PM, Reynold Xin <rxin=40databricks.com> wrote=
: =20

> +1 =20
> =20
> =20
> On Tue, Sep 2, 2014 at 3:08 PM, Cheng Lian <lian.cs.zju=40gmail.com> wr=
ote: =20
> =20
> > +1 =20
> > =20
> > - Tested Thrift server and SQL CLI locally on OSX 10.9. =20
> > - Checked datanucleus dependencies in distribution tarball built by =20
> > make-distribution.sh without SPARK=5FHIVE defined. =20
> > =20
> > =E2=80=8B =20
> > =20
> > =20
> > On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb=40redhat.com> wrot=
e: =20
> > =20
> > > +1 =20
> > > =20
> > > Tested Scala/MLlib apps on =46edora 20 (OpenJDK 7) and OS X 10.9 (O=
racle =20
> > JDK =20
> > > 8). =20
> > > =20
> > > =20
> > > best, =20
> > > wb =20
> > > =20
> > > =20
> > > ----- Original Message ----- =20
> > > > =46rom: =22Patrick Wendell=22 <pwendell=40gmail.com> =20
> > > > To: dev=40spark.apache.org =20
> > > > Sent: Saturday, August 30, 2014 5:07:52 PM =20
> > > > Subject: =5BVOTE=5D Release Apache Spark 1.1.0 (RC3) =20
> > > > =20
> > > > Please vote on releasing the following candidate as Apache Spark =
=20
> > version =20
> > > > 1.1.0=21 =20
> > > > =20
> > > > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b): =20
> > > > =20
> > > =20
> > =20
> https://git-wip-us.apache.org/repos/asf=3Fp=3Dspark.git;a=3Dcommit;h=3D=
b2d0493b223c5f98a593bb6d7372706cc02bebad =20
> > > > =20
> > > > The release files, including signatures, digests, etc. can be fou=
nd =20
> at: =20
> > > > http://people.apache.org/=7Epwendell/spark-1.1.0-rc3/ =20
> > > > =20
> > > > Release artifacts are signed with the following key: =20
> > > > https://people.apache.org/keys/committer/pwendell.asc =20
> > > > =20
> > > > The staging repository for this release can be found at: =20
> > > > =20
> > https://repository.apache.org/content/repositories/orgapachespark-103=
0/ =20
> > > > =20
> > > > The documentation corresponding to this release can be found at: =
=20
> > > > http://people.apache.org/=7Epwendell/spark-1.1.0-rc3-docs/ =20
> > > > =20
> > > > Please vote on releasing this package as Apache Spark 1.1.0=21 =20
> > > > =20
> > > > The vote is open until Tuesday, September 02, at 23:07 UTC and pa=
sses =20
> > if =20
> > > > a majority of at least 3 +1 PMC votes are cast. =20
> > > > =20
> > > > =5B =5D +1 Release this package as Apache Spark 1.1.0 =20
> > > > =5B =5D -1 Do not release this package because ... =20
> > > > =20
> > > > To learn more about Apache Spark, please see =20
> > > > http://spark.apache.org/ =20
> > > > =20
> > > > =3D=3D Regressions fixed since RC1 =3D=3D =20
> > > > - Build issue for SQL support: =20
> > > > https://issues.apache.org/jira/browse/SPARK-3234 =20
> > > > - EC2 script version bump to 1.1.0. =20
> > > > =20
> > > > =3D=3D What justifies a -1 vote for this release=3F =3D=3D =20
> > > > This vote is happening very late into the QA period compared with=
 =20
> > > > previous votes, so -1 votes should only occur for significant =20
> > > > regressions from 1.0.2. Bugs already present in 1.0.X will not bl=
ock =20
> > > > this release. =20
> > > > =20
> > > > =3D=3D What default changes should I be aware of=3F =3D=3D =20
> > > > 1. The default value of =22spark.io.compression.codec=22 is now =22=
snappy=22 =20
> > > > --> Old behavior can be restored by switching to =22lzf=22 =20
> > > > =20
> > > > 2. PySpark now performs external spilling during aggregations. =20
> > > > --> Old behavior can be restored by setting =22spark.shuffle.spil=
l=22 to =20
> > > =22false=22. =20
> > > > =20
> > > > -----------------------------------------------------------------=
---- =20
> > > > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > > > =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> > > > =20
> > > > =20
> > > =20
> > > -------------------------------------------------------------------=
-- =20
> > > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > > =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> > > =20
> > > =20
> > =20
> =20

--54065e56_2ca88611_8aeb--


From dev-return-9241-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:29:30 2014
Return-Path: <dev-return-9241-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04BE511A71
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:29:30 +0000 (UTC)
Received: (qmail 76543 invoked by uid 500); 3 Sep 2014 00:29:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76480 invoked by uid 500); 3 Sep 2014 00:29:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76464 invoked by uid 99); 3 Sep 2014 00:29:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:29:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:29:24 +0000
Received: by mail-lb0-f180.google.com with SMTP id w7so8447594lbi.25
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:29:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=dZ2DaKD1EYYYl0mPXKSzfemS2lTaDPzBH092rhpjMX4=;
        b=TjXTn3/yC4dLZY8N37OGAmgxI7SXkd/US6476YxiaWtaTQUTRrmymYUxes3k0X1CnR
         JxN3lBoAX0k+9pGQe5nAmzL/nIinr2r1rTwOatoAXJr/vPM/1Ig6hZAU478EXThbWGsE
         mlyJW0ak5l2m9f3AoCWR4HgTa0Eapuq+kFt2PITG4N4lX+iCyMBiNa0bW3ldxBrfLmzG
         RiC7ZFyfZVxNcnX9LZECPops9Uw9Hax7pBj9G0FxLP73ZpINmV3PFfOZnqTwPV1ANz3r
         OdjEwy8SuKLkrw8ODVrwvzYA8k+zkUtmMkuFZVo5pANmgkegyNhCzAIoq6GVi5h5F2G5
         N5BA==
X-Gm-Message-State: ALoCoQlt0KMQ3MBGoMbVGklqNEoIKKVE6jW7axoHsRLF61dMDzbGrDBNMaTl5ePlrPYHdJB32hSF
X-Received: by 10.152.23.6 with SMTP id i6mr38031051laf.39.1409704142330; Tue,
 02 Sep 2014 17:29:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Tue, 2 Sep 2014 17:28:42 -0700 (PDT)
In-Reply-To: <etPan.54065e56.71f32454.8aeb@mbp-3>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
 <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
 <CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
 <CALRHqP9FFSsD5SC+6z1nieoYs=+QjBMp1pLCEFbTRtCTRpmoXw@mail.gmail.com> <etPan.54065e56.71f32454.8aeb@mbp-3>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 2 Sep 2014 17:28:42 -0700
Message-ID: <CAAswR-6O=FZgJw4_g82OCO-pyfNq2vwRuvmSztvrCBctA2cw1g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160bbeea47bcb05021e5275
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160bbeea47bcb05021e5275
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

+1


On Tue, Sep 2, 2014 at 5:18 PM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> +1
>
> Tested on Mac OS X.
>
> Matei
>
> On September 2, 2014 at 5:03:19 PM, Kan Zhang (kzhang@apache.org) wrote:
>
> +1
>
> Verified PySpark InputFormat/OutputFormat examples.
>
>
> On Tue, Sep 2, 2014 at 4:10 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > +1
> >
> >
> > On Tue, Sep 2, 2014 at 3:08 PM, Cheng Lian <lian.cs.zju@gmail.com>
> wrote:
> >
> > > +1
> > >
> > > - Tested Thrift server and SQL CLI locally on OSX 10.9.
> > > - Checked datanucleus dependencies in distribution tarball built by
> > > make-distribution.sh without SPARK_HIVE defined.
> > >
> > > =E2=80=8B
> > >
> > >
> > > On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb@redhat.com> wrote:
> > >
> > > > +1
> > > >
> > > > Tested Scala/MLlib apps on Fedora 20 (OpenJDK 7) and OS X 10.9
> (Oracle
> > > JDK
> > > > 8).
> > > >
> > > >
> > > > best,
> > > > wb
> > > >
> > > >
> > > > ----- Original Message -----
> > > > > From: "Patrick Wendell" <pwendell@gmail.com>
> > > > > To: dev@spark.apache.org
> > > > > Sent: Saturday, August 30, 2014 5:07:52 PM
> > > > > Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)
> > > > >
> > > > > Please vote on releasing the following candidate as Apache Spark
> > > version
> > > > > 1.1.0!
> > > > >
> > > > > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
> > > > >
> > > >
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db2d0=
493b223c5f98a593bb6d7372706cc02bebad
> > > > >
> > > > > The release files, including signatures, digests, etc. can be fou=
nd
> > at:
> > > > > http://people.apache.org/~pwendell/spark-1.1.0-rc3/
> > > > >
> > > > > Release artifacts are signed with the following key:
> > > > > https://people.apache.org/keys/committer/pwendell.asc
> > > > >
> > > > > The staging repository for this release can be found at:
> > > > >
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1030/
> > > > >
> > > > > The documentation corresponding to this release can be found at:
> > > > > http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
> > > > >
> > > > > Please vote on releasing this package as Apache Spark 1.1.0!
> > > > >
> > > > > The vote is open until Tuesday, September 02, at 23:07 UTC and
> passes
> > > if
> > > > > a majority of at least 3 +1 PMC votes are cast.
> > > > >
> > > > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > > > [ ] -1 Do not release this package because ...
> > > > >
> > > > > To learn more about Apache Spark, please see
> > > > > http://spark.apache.org/
> > > > >
> > > > > =3D=3D Regressions fixed since RC1 =3D=3D
> > > > > - Build issue for SQL support:
> > > > > https://issues.apache.org/jira/browse/SPARK-3234
> > > > > - EC2 script version bump to 1.1.0.
> > > > >
> > > > > =3D=3D What justifies a -1 vote for this release? =3D=3D
> > > > > This vote is happening very late into the QA period compared with
> > > > > previous votes, so -1 votes should only occur for significant
> > > > > regressions from 1.0.2. Bugs already present in 1.0.X will not
> block
> > > > > this release.
> > > > >
> > > > > =3D=3D What default changes should I be aware of? =3D=3D
> > > > > 1. The default value of "spark.io.compression.codec" is now
> "snappy"
> > > > > --> Old behavior can be restored by switching to "lzf"
> > > > >
> > > > > 2. PySpark now performs external spilling during aggregations.
> > > > > --> Old behavior can be restored by setting "spark.shuffle.spill"
> to
> > > > "false".
> > > > >
> > > > >
> ---------------------------------------------------------------------
> > > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > > >
> > > > >
> > > >
> > > > -------------------------------------------------------------------=
--
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > > >
> > >
> >
>

--089e0160bbeea47bcb05021e5275--

From dev-return-9242-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:31:07 2014
Return-Path: <dev-return-9242-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2DA6F11A78
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:31:07 +0000 (UTC)
Received: (qmail 80952 invoked by uid 500); 3 Sep 2014 00:31:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80889 invoked by uid 500); 3 Sep 2014 00:31:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80875 invoked by uid 99); 3 Sep 2014 00:31:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:31:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:31:01 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so15964342pad.35
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:30:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=KDmmyJ8QIgt3asJxML+3heKPtvpFemeGevWwX80huAo=;
        b=nQ530LneYupZMlf8CsaLu5taVt+C8N/G2R1xztKVMW74zMt3OwS0MPYCQOJSrKCR17
         UPofmA17jZoDTZDnV/OVeie/jd+3QIQDToeEAxTVXVHWqS7xxz6RxNtdse5fONoJqTy6
         k22BzzfRgT1BhlZVe1FWH0sKuCawn1mC1BRwddmrrkOAT6/pkVIzykUDF5V9q6mR4byp
         a/tpQP3lyxrhbT6CYAe4iURmTeaIITy6gX1vfH8QNcVfFGkIVi1waa76gp1Cz83ZbK2l
         0SMURreDXfG1D4fPUKJhOmIvwWd9x1dT5V6Adt8vhbRDadv9eX6lKZSlzBqZ5CtGTeZ1
         drnA==
X-Received: by 10.66.66.198 with SMTP id h6mr51010920pat.72.1409704240166;
        Tue, 02 Sep 2014 17:30:40 -0700 (PDT)
Received: from gallifrey.local ([2601:8:9880:5e8:6546:659b:ba1b:d1f0])
        by mx.google.com with ESMTPSA id im1sm5168185pbb.29.2014.09.02.17.30.39
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Tue, 02 Sep 2014 17:30:39 -0700 (PDT)
Date: Tue, 2 Sep 2014 17:30:39 -0700
From: Denny Lee <denny.g.lee@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Michael
 Armbrust <michael@databricks.com>
Message-ID: <etPan.5406612f.6b8b4567.521@gallifrey.local>
In-Reply-To: <CAAswR-6O=FZgJw4_g82OCO-pyfNq2vwRuvmSztvrCBctA2cw1g@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <717463417.50035269.1409693418085.JavaMail.zimbra@redhat.com>
 <CAA_qdLoKpJm8XxAGj-y30dintp6__Lveu7gUb29i0j=DCgMpPQ@mail.gmail.com>
 <CAPh_B=b+vzncFUuLiKOQuir5qWUSyVF=EDW8Lshqb7JECrm_3Q@mail.gmail.com>
 <CALRHqP9FFSsD5SC+6z1nieoYs=+QjBMp1pLCEFbTRtCTRpmoXw@mail.gmail.com>
 <etPan.54065e56.71f32454.8aeb@mbp-3>
 <CAAswR-6O=FZgJw4_g82OCO-pyfNq2vwRuvmSztvrCBctA2cw1g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5406612f_327b23c6_521"
X-Virus-Checked: Checked by ClamAV on apache.org

--5406612f_327b23c6_521
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

+1 =C2=A0Tested on Mac OSX, Thrift Server, SparkSQL


On September 2, 2014 at 17:29:29, Michael Armbrust (michael=40databricks.=
com) wrote:

+1 =20


On Tue, Sep 2, 2014 at 5:18 PM, Matei Zaharia <matei.zaharia=40gmail.com>=
 =20
wrote: =20

> +1 =20
> =20
> Tested on Mac OS X. =20
> =20
> Matei =20
> =20
> On September 2, 2014 at 5:03:19 PM, Kan Zhang (kzhang=40apache.org) wro=
te: =20
> =20
> +1 =20
> =20
> Verified PySpark Input=46ormat/Output=46ormat examples. =20
> =20
> =20
> On Tue, Sep 2, 2014 at 4:10 PM, Reynold Xin <rxin=40databricks.com> wro=
te: =20
> =20
> > +1 =20
> > =20
> > =20
> > On Tue, Sep 2, 2014 at 3:08 PM, Cheng Lian <lian.cs.zju=40gmail.com> =
=20
> wrote: =20
> > =20
> > > +1 =20
> > > =20
> > > - Tested Thrift server and SQL CLI locally on OSX 10.9. =20
> > > - Checked datanucleus dependencies in distribution tarball built by=
 =20
> > > make-distribution.sh without SPARK=5FHIVE defined. =20
> > > =20
> > > =E2=80=8B =20
> > > =20
> > > =20
> > > On Tue, Sep 2, 2014 at 2:30 PM, Will Benton <willb=40redhat.com> wr=
ote: =20
> > > =20
> > > > +1 =20
> > > > =20
> > > > Tested Scala/MLlib apps on =46edora 20 (OpenJDK 7) and OS X 10.9 =
=20
> (Oracle =20
> > > JDK =20
> > > > 8). =20
> > > > =20
> > > > =20
> > > > best, =20
> > > > wb =20
> > > > =20
> > > > =20
> > > > ----- Original Message ----- =20
> > > > > =46rom: =22Patrick Wendell=22 <pwendell=40gmail.com> =20
> > > > > To: dev=40spark.apache.org =20
> > > > > Sent: Saturday, August 30, 2014 5:07:52 PM =20
> > > > > Subject: =5BVOTE=5D Release Apache Spark 1.1.0 (RC3) =20
> > > > > =20
> > > > > Please vote on releasing the following candidate as Apache Spar=
k =20
> > > version =20
> > > > > 1.1.0=21 =20
> > > > > =20
> > > > > The tag to be voted on is v1.1.0-rc3 (commit b2d0493b): =20
> > > > > =20
> > > > =20
> > > =20
> > =20
> https://git-wip-us.apache.org/repos/asf=3Fp=3Dspark.git;a=3Dcommit;h=3D=
b2d0493b223c5f98a593bb6d7372706cc02bebad =20
> > > > > =20
> > > > > The release files, including signatures, digests, etc. can be f=
ound =20
> > at: =20
> > > > > http://people.apache.org/=7Epwendell/spark-1.1.0-rc3/ =20
> > > > > =20
> > > > > Release artifacts are signed with the following key: =20
> > > > > https://people.apache.org/keys/committer/pwendell.asc =20
> > > > > =20
> > > > > The staging repository for this release can be found at: =20
> > > > > =20
> > > =20
> https://repository.apache.org/content/repositories/orgapachespark-1030/=
 =20
> > > > > =20
> > > > > The documentation corresponding to this release can be found at=
: =20
> > > > > http://people.apache.org/=7Epwendell/spark-1.1.0-rc3-docs/ =20
> > > > > =20
> > > > > Please vote on releasing this package as Apache Spark 1.1.0=21 =
=20
> > > > > =20
> > > > > The vote is open until Tuesday, September 02, at 23:07 UTC and =
=20
> passes =20
> > > if =20
> > > > > a majority of at least 3 +1 PMC votes are cast. =20
> > > > > =20
> > > > > =5B =5D +1 Release this package as Apache Spark 1.1.0 =20
> > > > > =5B =5D -1 Do not release this package because ... =20
> > > > > =20
> > > > > To learn more about Apache Spark, please see =20
> > > > > http://spark.apache.org/ =20
> > > > > =20
> > > > > =3D=3D Regressions fixed since RC1 =3D=3D =20
> > > > > - Build issue for SQL support: =20
> > > > > https://issues.apache.org/jira/browse/SPARK-3234 =20
> > > > > - EC2 script version bump to 1.1.0. =20
> > > > > =20
> > > > > =3D=3D What justifies a -1 vote for this release=3F =3D=3D =20
> > > > > This vote is happening very late into the QA period compared wi=
th =20
> > > > > previous votes, so -1 votes should only occur for significant =20
> > > > > regressions from 1.0.2. Bugs already present in 1.0.X will not =
=20
> block =20
> > > > > this release. =20
> > > > > =20
> > > > > =3D=3D What default changes should I be aware of=3F =3D=3D =20
> > > > > 1. The default value of =22spark.io.compression.codec=22 is now=
 =20
> =22snappy=22 =20
> > > > > --> Old behavior can be restored by switching to =22lzf=22 =20
> > > > > =20
> > > > > 2. PySpark now performs external spilling during aggregations. =
=20
> > > > > --> Old behavior can be restored by setting =22spark.shuffle.sp=
ill=22 =20
> to =20
> > > > =22false=22. =20
> > > > > =20
> > > > > =20
> --------------------------------------------------------------------- =20
> > > > > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > > > > =46or additional commands, e-mail: dev-help=40spark.apache.org =
=20
> > > > > =20
> > > > > =20
> > > > =20
> > > > -----------------------------------------------------------------=
---- =20
> > > > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> > > > =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> > > > =20
> > > > =20
> > > =20
> > =20
> =20

--5406612f_327b23c6_521--


From dev-return-9243-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:31:31 2014
Return-Path: <dev-return-9243-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CF03211A7B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:31:31 +0000 (UTC)
Received: (qmail 82401 invoked by uid 500); 3 Sep 2014 00:31:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82330 invoked by uid 500); 3 Sep 2014 00:31:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82311 invoked by uid 99); 3 Sep 2014 00:31:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:31:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of Sean.McNamara@webtrends.com designates 216.64.169.22 as permitted sender)
Received: from [216.64.169.22] (HELO pdxmta01.webtrends.com) (216.64.169.22)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:31:04 +0000
Received: from pdxex2.webtrends.corp (Not Verified[10.61.2.221]) by pdxmta01.webtrends.com with MailMarshal (v7,2,3,6978) (using TLS: SSLv23)
	id <B540661210000>; Wed, 03 Sep 2014 00:30:25 +0000
Received: from PDXEX1.WebTrends.corp ([172.27.5.220]) by pdxex2.webtrends.corp
 ([172.27.3.221]) with mapi id 14.03.0181.006; Wed, 3 Sep 2014 00:30:52 +0000
From: Sean McNamara <Sean.McNamara@Webtrends.com>
To: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: [VOTE] Release Apache Spark 1.1.0 (RC3)
Thread-Topic: [VOTE] Release Apache Spark 1.1.0 (RC3)
Thread-Index: AQHPxJ7pyhyzl828xkm4P1obeRJdwpvuk1Vs
Date: Wed, 3 Sep 2014 00:30:52 +0000
Message-ID: <012039977044474D9CFA6A36A4D1FF661F527FAC@pdxex1.webtrends.corp>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
In-Reply-To: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.61.2.4]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

+1=0A=
________________________________________=0A=
From: Patrick Wendell [pwendell@gmail.com]=0A=
Sent: Saturday, August 30, 2014 4:08 PM=0A=
To: dev@spark.apache.org=0A=
Subject: [VOTE] Release Apache Spark 1.1.0 (RC3)=0A=
=0A=
Please vote on releasing the following candidate as Apache Spark version 1.=
1.0!=0A=
=0A=
The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):=0A=
https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db2d049=
3b223c5f98a593bb6d7372706cc02bebad=0A=
=0A=
The release files, including signatures, digests, etc. can be found at:=0A=
http://people.apache.org/~pwendell/spark-1.1.0-rc3/=0A=
=0A=
Release artifacts are signed with the following key:=0A=
https://people.apache.org/keys/committer/pwendell.asc=0A=
=0A=
The staging repository for this release can be found at:=0A=
https://repository.apache.org/content/repositories/orgapachespark-1030/=0A=
=0A=
The documentation corresponding to this release can be found at:=0A=
http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/=0A=
=0A=
Please vote on releasing this package as Apache Spark 1.1.0!=0A=
=0A=
The vote is open until Tuesday, September 02, at 23:07 UTC and passes if=0A=
a majority of at least 3 +1 PMC votes are cast.=0A=
=0A=
[ ] +1 Release this package as Apache Spark 1.1.0=0A=
[ ] -1 Do not release this package because ...=0A=
=0A=
To learn more about Apache Spark, please see=0A=
http://spark.apache.org/=0A=
=0A=
=3D=3D Regressions fixed since RC1 =3D=3D=0A=
- Build issue for SQL support: https://issues.apache.org/jira/browse/SPARK-=
3234=0A=
- EC2 script version bump to 1.1.0.=0A=
=0A=
=3D=3D What justifies a -1 vote for this release? =3D=3D=0A=
This vote is happening very late into the QA period compared with=0A=
previous votes, so -1 votes should only occur for significant=0A=
regressions from 1.0.2. Bugs already present in 1.0.X will not block=0A=
this release.=0A=
=0A=
=3D=3D What default changes should I be aware of? =3D=3D=0A=
1. The default value of "spark.io.compression.codec" is now "snappy"=0A=
--> Old behavior can be restored by switching to "lzf"=0A=
=0A=
2. PySpark now performs external spilling during aggregations.=0A=
--> Old behavior can be restored by setting "spark.shuffle.spill" to "false=
".=0A=
=0A=
---------------------------------------------------------------------=0A=
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org=0A=
For additional commands, e-mail: dev-help@spark.apache.org=0A=
=0A=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9244-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:34:32 2014
Return-Path: <dev-return-9244-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEEFB11A8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:34:32 +0000 (UTC)
Received: (qmail 88199 invoked by uid 500); 3 Sep 2014 00:34:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88142 invoked by uid 500); 3 Sep 2014 00:34:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88131 invoked by uid 99); 3 Sep 2014 00:34:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:34:31 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of freeman.jeremy@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:34:27 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <freeman.jeremy@gmail.com>)
	id 1XOyWU-0006P3-CP
	for dev@spark.incubator.apache.org; Tue, 02 Sep 2014 17:34:06 -0700
Date: Tue, 2 Sep 2014 17:34:06 -0700 (PDT)
From: Jeremy Freeman <freeman.jeremy@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409704446371-8211.post@n3.nabble.com>
In-Reply-To: <012039977044474D9CFA6A36A4D1FF661F527FAC@pdxex1.webtrends.corp>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com> <012039977044474D9CFA6A36A4D1FF661F527FAC@pdxex1.webtrends.corp>
Subject: RE: [VOTE] Release Apache Spark 1.1.0 (RC3)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

+1



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC3-tp8147p8211.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9245-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:37:47 2014
Return-Path: <dev-return-9245-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4038911AA9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:37:47 +0000 (UTC)
Received: (qmail 94515 invoked by uid 500); 3 Sep 2014 00:37:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94442 invoked by uid 500); 3 Sep 2014 00:37:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94420 invoked by uid 99); 3 Sep 2014 00:37:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:37:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:37:21 +0000
Received: by mail-la0-f52.google.com with SMTP id ty20so8927223lab.11
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 17:37:20 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=GUVnXc2HQxetJ6TCWPxVLYv1g1Rj8DhYUgSA/PNQoJ0=;
        b=aoh2FFQ7IEguHDAU+vEbWFi7WKWBWCj/AdIp1lrFfz4ZblqgylvrejRxvG2a4cnWhG
         IJB0jCQt0EZi4uQ7+y1g588X8Z5OnZMTR3jFOPGhs/E8Bayc378bYiavh78S6M/Sd5Nv
         TtUTWiwzPOSk4RmqWBh6KpnkY5lregePnr2IrDl4UWsQWbJ0+t1eNBMAiDMXUwXV8DVx
         QDcWAIRb5+9EIXSWprFzm/8S8B1RfQIW0H0SUWb7w3z3O6EpNwmJgHENd+o7I+RDzuWj
         VG8jxT93mbvFtJgU6eqbxcuzcl/0QCDFFJky68OvwO5YTosZ2DQsyKnGgoXy07UvoWJq
         bnBw==
X-Gm-Message-State: ALoCoQm1ZVzoFy0+lC8gCp6MGn/dDeLhZjco9oyjjuxNcV+TEQLkOfNZ9MN/ug0esjzsYTv2Giml
X-Received: by 10.112.158.199 with SMTP id ww7mr36200152lbb.71.1409704640130;
 Tue, 02 Sep 2014 17:37:20 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Tue, 2 Sep 2014 17:37:00 -0700 (PDT)
In-Reply-To: <CACdU-dRYXsumR0-uqyDC4TGUL6gkRoQhCM1OX2PnNwKjtQXA5A@mail.gmail.com>
References: <CACdU-dRYXsumR0-uqyDC4TGUL6gkRoQhCM1OX2PnNwKjtQXA5A@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 2 Sep 2014 17:37:00 -0700
Message-ID: <CACdU-dRa6Hj1Ljw0HzmQU_b3LctmXJi0Z_5VR=9zGk3yoJeEAA@mail.gmail.com>
Subject: Re: quick jenkins restart
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c33aa8503d6705021e70f6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c33aa8503d6705021e70f6
Content-Type: text/plain; charset=UTF-8

and we're back and building!


On Tue, Sep 2, 2014 at 5:07 PM, shane knapp <sknapp@berkeley.edu> wrote:

> since our queue is really short, i'm waiting for a couple of builds to
> finish and will be restarting jenkins to install/update some plugins.  the
> github pull request builder looks like it has some fixes to reduce spammy
> github calls, and reduce any potential rate limiting.
>
> i'll let everyone know when it's back up...  this should be super quick
> (~15 mins for tests to finish, ~2 mins for jenkins to restart).
>
> thanks in advance!
>
> shane
>

--001a11c33aa8503d6705021e70f6--

From dev-return-9246-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 00:37:50 2014
Return-Path: <dev-return-9246-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A742411AAA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 00:37:50 +0000 (UTC)
Received: (qmail 95629 invoked by uid 500); 3 Sep 2014 00:37:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95561 invoked by uid 500); 3 Sep 2014 00:37:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95550 invoked by uid 99); 3 Sep 2014 00:37:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:37:49 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_HELO_PASS,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of paolo.platter@agilelab.it designates 213.199.154.83 as permitted sender)
Received: from [213.199.154.83] (HELO emea01-db3-obe.outbound.protection.outlook.com) (213.199.154.83)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 00:37:44 +0000
Received: from AMSPR05MB177.eurprd05.prod.outlook.com (10.242.86.15) by
 AMSPR05MB179.eurprd05.prod.outlook.com (10.242.86.21) with Microsoft SMTP
 Server (TLS) id 15.0.1019.16; Wed, 3 Sep 2014 00:37:21 +0000
Received: from AMSPR05MB177.eurprd05.prod.outlook.com ([169.254.5.42]) by
 AMSPR05MB177.eurprd05.prod.outlook.com ([169.254.5.42]) with mapi id
 15.00.1019.015; Wed, 3 Sep 2014 00:37:21 +0000
From: Paolo Platter <paolo.platter@agilelab.it>
To: Jeremy Freeman <freeman.jeremy@gmail.com>,
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
Thread-Topic: [VOTE] Release Apache Spark 1.1.0 (RC3)
Thread-Index: AQHPxJ7qjjrP7ULOZkCMQGzoCfmV0Jvuk2QAgAAA5wCAAADokg==
Date: Wed, 3 Sep 2014 00:37:21 +0000
Message-ID: <6536eb51d9014d0eb78e14d55b86fcdd@agilelab.it>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <012039977044474D9CFA6A36A4D1FF661F527FAC@pdxex1.webtrends.corp>,<1409704446371-8211.post@n3.nabble.com>
In-Reply-To: <1409704446371-8211.post@n3.nabble.com>
Accept-Language: it-IT, en-US
Content-Language: it-IT
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [93.38.170.157]
x-microsoft-antispam: BCL:0;PCL:0;RULEID:;UriScan:;
x-forefront-prvs: 032334F434
x-forefront-antispam-report: SFV:NSPM;SFS:(252514010)(189002)(199003)(33646002)(90102001)(86362001)(54356999)(76176999)(74662001)(74502001)(74482001)(31966008)(83322001)(99396002)(50986999)(19580405001)(19580395003)(92566001)(2656002)(4396001)(2501002)(87936001)(85852003)(81342001)(64706001)(85306004)(66066001)(80022001)(79102001)(36756003)(76482001)(105586002)(106116001)(83072002)(81542001)(20776003)(95666004)(21056001)(15975445006)(101416001)(15202345003)(108616004)(77982001)(19625215002)(46102001)(106356001)(77096002)(107046002)(107886001)(16236675004)(24736002)(19607625011);DIR:OUT;SFP:;SCL:1;SRVR:AMSPR05MB179;H:AMSPR05MB177.eurprd05.prod.outlook.com;FPR:;MLV:sfv;PTR:InfoNoRecords;MX:1;A:1;LANG:en;
Content-Type: multipart/alternative;
	boundary="_000_6536eb51d9014d0eb78e14d55b86fcddagilelabit_"
MIME-Version: 1.0
X-OriginatorOrg: agilelab.it
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_6536eb51d9014d0eb78e14d55b86fcddagilelabit_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

+1
Tested on HDP 2.1 Sandbox, Thrift Server with Simba Shark ODBC

Paolo

Da: Jeremy Freeman<mailto:freeman.jeremy@gmail.com>
Data invio: ?mercoled?? ?3? ?settembre? ?2014 ?02?:?34
A: dev@spark.incubator.apache.org<mailto:dev@spark.incubator.apache.org>

+1



--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC3-tp8147p8211.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


--_000_6536eb51d9014d0eb78e14d55b86fcddagilelabit_--

From dev-return-9247-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 01:56:19 2014
Return-Path: <dev-return-9247-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8FF4411D78
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 01:56:19 +0000 (UTC)
Received: (qmail 32947 invoked by uid 500); 3 Sep 2014 01:56:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32878 invoked by uid 500); 3 Sep 2014 01:56:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32864 invoked by uid 99); 3 Sep 2014 01:56:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 01:56:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 01:55:49 +0000
Received: by mail-wg0-f51.google.com with SMTP id l18so7711110wgh.10
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 18:55:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=e46JaGncN59jQPoxKPvGv2YVnocXiy67MZ3JsA79hZc=;
        b=pZRUntlcSFo3QboaWrzh0qUykKnlnLrmq01R6b+OxC2Umfv7DhF8u2BIpn2exZGU4b
         ORbdV9waIdpIQyPzGsFryPOauddzqVqF6U1bLaTEgxtaICFepuRDrmWXXwauT9h34yLL
         K3Wp9u+UBbPWYHuqsCTwaXdVk9CDNKL3U5izExJ1ZdaNFsggyIg2u5GLpaVUlyArXE1M
         ll8VxlOQFZEU3WsgV+xF6XEFmTtUIdjVdpt6hLntI+8lEVqNxR/xyPd7L0a9CUsVAWq8
         zXaVCVzVn73tiWRZF2dtgDONd2rACg3Ds6p0+X6zJDeMikg7Ck23lv/DzQ/dXAabTN/y
         zJjQ==
X-Received: by 10.180.91.40 with SMTP id cb8mr205588wib.45.1409709349203; Tue,
 02 Sep 2014 18:55:49 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Tue, 2 Sep 2014 18:55:09 -0700 (PDT)
In-Reply-To: <CAOhmDzcoPjs3byXpuUf585VQSu4xs5rYAXcqy6zh=wBpENsnLg@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
 <CAOhmDzcoPjs3byXpuUf585VQSu4xs5rYAXcqy6zh=wBpENsnLg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 2 Sep 2014 21:55:09 -0400
Message-ID: <CAOhmDzcBAFGx3DG-18G5pWiT5Kit6ZgBt482R-cAXHGLPK2FFQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c7e78fef5e605021f88d7
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c7e78fef5e605021f88d7
Content-Type: text/plain; charset=UTF-8

In light of the discussion on SPARK-3333, I'll revoke my "-1" vote. The
issue does not appear to be serious.


On Sun, Aug 31, 2014 at 5:14 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> -1: I believe I've found a regression from 1.0.2. The report is captured
> in SPARK-3333 <https://issues.apache.org/jira/browse/SPARK-3333>.
>
>
> On Sat, Aug 30, 2014 at 6:07 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
>> Please vote on releasing the following candidate as Apache Spark version
>> 1.1.0!
>>
>> The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
>>
>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b2d0493b223c5f98a593bb6d7372706cc02bebad
>>
>> The release files, including signatures, digests, etc. can be found at:
>> http://people.apache.org/~pwendell/spark-1.1.0-rc3/
>>
>> Release artifacts are signed with the following key:
>> https://people.apache.org/keys/committer/pwendell.asc
>>
>> The staging repository for this release can be found at:
>> https://repository.apache.org/content/repositories/orgapachespark-1030/
>>
>> The documentation corresponding to this release can be found at:
>> http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
>>
>> Please vote on releasing this package as Apache Spark 1.1.0!
>>
>> The vote is open until Tuesday, September 02, at 23:07 UTC and passes if
>> a majority of at least 3 +1 PMC votes are cast.
>>
>> [ ] +1 Release this package as Apache Spark 1.1.0
>> [ ] -1 Do not release this package because ...
>>
>> To learn more about Apache Spark, please see
>> http://spark.apache.org/
>>
>> == Regressions fixed since RC1 ==
>> - Build issue for SQL support:
>> https://issues.apache.org/jira/browse/SPARK-3234
>> - EC2 script version bump to 1.1.0.
>>
>> == What justifies a -1 vote for this release? ==
>> This vote is happening very late into the QA period compared with
>> previous votes, so -1 votes should only occur for significant
>> regressions from 1.0.2. Bugs already present in 1.0.X will not block
>> this release.
>>
>> == What default changes should I be aware of? ==
>> 1. The default value of "spark.io.compression.codec" is now "snappy"
>> --> Old behavior can be restored by switching to "lzf"
>>
>> 2. PySpark now performs external spilling during aggregations.
>> --> Old behavior can be restored by setting "spark.shuffle.spill" to
>> "false".
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--f46d043c7e78fef5e605021f88d7--

From dev-return-9248-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 01:57:30 2014
Return-Path: <dev-return-9248-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9E8211D89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 01:57:30 +0000 (UTC)
Received: (qmail 35605 invoked by uid 500); 3 Sep 2014 01:57:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35533 invoked by uid 500); 3 Sep 2014 01:57:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35522 invoked by uid 99); 3 Sep 2014 01:57:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 01:57:29 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wangfei1@huawei.com designates 119.145.14.64 as permitted sender)
Received: from [119.145.14.64] (HELO szxga01-in.huawei.com) (119.145.14.64)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 01:57:04 +0000
Received: from 172.24.2.119 (EHLO szxeml405-hub.china.huawei.com) ([172.24.2.119])
	by szxrg01-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id CBD90847;
	Wed, 03 Sep 2014 09:56:56 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml405-hub.china.huawei.com
 (10.82.67.60) with Microsoft SMTP Server id 14.3.158.1; Wed, 3 Sep 2014
 09:56:54 +0800
Message-ID: <54067563.3020504@huawei.com>
Date: Wed, 3 Sep 2014 09:56:51 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: Cheng Lian <lian.cs.zju@gmail.com>
CC: Josh Rosen <rosenville@gmail.com>, Reynold Xin <rxin@databricks.com>,
        "Sean Owen" <sowen@cloudera.com>, Sandy Ryza <sandy.ryza@cloudera.com>,
        "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: about spark assembly jar
References: <54058224.3030909@huawei.com> <CAMAsSd+6q=kJS5=Di8svkJLq7Dw6Q9kxLa81=o2wQ-5HwiYbww@mail.gmail.com> <540589E8.8020107@huawei.com> <CACBYxKK93uDzYs8Y_FgX8FMrvzAmxMDvLGRfja4B6V-YjX+vVA@mail.gmail.com> <CAPh_B=YPOD4ikHUzN6MZMwof0XdfhQAko4CL84KsM6WBpob-AA@mail.gmail.com> <CAA_qdLpVTEZ2Vd1a9JTbFnssiCjZFwYbnE2sBRsZ5sQZgqWphg@mail.gmail.com> <etPan.540612ae.628c895d.cf9@joshs-mbp> <CAA_qdLoqMO==zsg9mCUDPxejiYcQsYDV=1j2nP_O6vjj+r+_Yw@mail.gmail.com>
In-Reply-To: <CAA_qdLoqMO==zsg9mCUDPxejiYcQsYDV=1j2nP_O6vjj+r+_Yw@mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

Yea, SSD + SPARK_PREPEND_CLASSES is great for iterative development!

Then why it is ok with a bag of 3rd jars but throw error with assembly jar, any one have idea?

On 2014/9/3 2:57, Cheng Lian wrote:
> Cool, didn't notice that, thanks Josh!
>
>
> On Tue, Sep 2, 2014 at 11:55 AM, Josh Rosen <rosenville@gmail.com <mailto:rosenville@gmail.com>> wrote:
>
>     SPARK_PREPEND_CLASSES is documented on the Spark Wiki (which could probably be easier to find): https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools
>
>
>     On September 2, 2014 at 11:53:49 AM, Cheng Lian (lian.cs.zju@gmail.com <mailto:lian.cs.zju@gmail.com>) wrote:
>
>>     Yea, SSD + SPARK_PREPEND_CLASSES totally changed my life :)
>>
>>     Maybe we should add a "developer notes" page to document all these useful
>>     black magic.
>>
>>
>>     On Tue, Sep 2, 2014 at 10:54 AM, Reynold Xin <rxin@databricks.com <mailto:rxin@databricks.com>> wrote:
>>
>>     > Having a SSD help tremendously with assembly time.
>>     >
>>     > Without that, you can do the following in order for Spark to pick up the
>>     > compiled classes before assembly at runtime.
>>     >
>>     > export SPARK_PREPEND_CLASSES=true
>>     >
>>     >
>>     > On Tue, Sep 2, 2014 at 9:10 AM, Sandy Ryza <sandy.ryza@cloudera.com <mailto:sandy.ryza@cloudera.com>>
>>     > wrote:
>>     >
>>     > > This doesn't help for every dependency, but Spark provides an option to
>>     > > build the assembly jar without Hadoop and its dependencies.  We make use
>>     > of
>>     > > this in CDH packaging.
>>     > >
>>     > > -Sandy
>>     > >
>>     > >
>>     > > On Tue, Sep 2, 2014 at 2:12 AM, scwf <wangfei1@huawei.com <mailto:wangfei1@huawei.com>> wrote:
>>     > >
>>     > > > Hi sean owen,
>>     > > > here are some problems when i used assembly jar
>>     > > > 1 i put spark-assembly-*.jar to the lib directory of my application, it
>>     > > > throw compile error
>>     > > >
>>     > > > Error:scalac: Error: class scala.reflect.BeanInfo not found.
>>     > > > scala.tools.nsc.MissingRequirementError: class scala.reflect.BeanInfo
>>     > not
>>     > > > found.
>>     > > >
>>     > > >         at scala.tools.nsc.symtab.Definitions$definitions$.
>>     > > > getModuleOrClass(Definitions.scala:655)
>>     > > >
>>     > > >         at scala.tools.nsc.symtab.Definitions$definitions$.
>>     > > > getClass(Definitions.scala:608)
>>     > > >
>>     > > >         at scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.<
>>     > > > init>(GenJVM.scala:127)
>>     > > >
>>     > > >         at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.
>>     > > > scala:85)
>>     > > >
>>     > > >         at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
>>     > > >
>>     > > >         at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
>>     > > >
>>     > > >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:126)
>>     > > >
>>     > > >         at
>>     > > xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:102)
>>     > > >
>>     > > >         at xsbt.CachedCompiler0.run(CompilerInterface.scala:102)
>>     > > >
>>     > > >         at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
>>     > > >
>>     > > >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>>     > > >
>>     > > >         at sun.reflect.NativeMethodAccessorImpl.invoke(
>>     > > > NativeMethodAccessorImpl.java:39)
>>     > > >
>>     > > >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
>>     > > > DelegatingMethodAccessorImpl.java:25)
>>     > > >
>>     > > >         at java.lang.reflect.Method.invoke(Method.java:597)
>>     > > >
>>     > > >         at sbt.compiler.AnalyzingCompiler.call(
>>     > > > AnalyzingCompiler.scala:102)
>>     > > >
>>     > > >         at sbt.compiler.AnalyzingCompiler.compile(
>>     > > > AnalyzingCompiler.scala:48)
>>     > > >
>>     > > >         at sbt.compiler.AnalyzingCompiler.compile(
>>     > > > AnalyzingCompiler.scala:41)
>>     > > >
>>     > > >         at org.jetbrains.jps.incremental.scala.local.
>>     > > > IdeaIncrementalCompiler.compile(IdeaIncrementalCompiler.scala:28)
>>     > > >
>>     > > >         at org.jetbrains.jps.incremental.scala.local.LocalServer.
>>     > > > compile(LocalServer.scala:25)
>>     > > >
>>     > > >         at org.jetbrains.jps.incremental.scala.remote.Main$.make(Main.
>>     > > > scala:58)
>>     > > >
>>     > > >         at org.jetbrains.jps.incremental.scala.remote.Main$.nailMain(
>>     > > > Main.scala:21)
>>     > > >
>>     > > >         at org.jetbrains.jps.incremental.scala.remote.Main.nailMain(
>>     > > > Main.scala)
>>     > > >
>>     > > >         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>>     > > >
>>     > > >         at sun.reflect.NativeMethodAccessorImpl.invoke(
>>     > > > NativeMethodAccessorImpl.java:39)
>>     > > >
>>     > > >         at sun.reflect.DelegatingMethodAccessorImpl.invoke(
>>     > > > DelegatingMethodAccessorImpl.java:25)
>>     > > >
>>     > > >         at java.lang.reflect.Method.invoke(Method.java:597)
>>     > > >
>>     > > >         at
>>     > com.martiansoftware.nailgun.NGSession.run(NGSession.java:319)
>>     > > > 2 i test my branch which updated hive version to org.apache.hive 0.13.1
>>     > > >   it run successfully when use a bag of 3rd jars as dependency but
>>     > throw
>>     > > > error using assembly jar, it seems assembly jar lead to conflict
>>     > > >   ERROR DDLTask: java.lang.NoSuchFieldError: doubleTypeInfo
>>     > > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
>>     > > > ArrayWritableObjectInspector.getObjectInspector(
>>     > > > ArrayWritableObjectInspector.java:66)
>>     > > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
>>     > > >
>>     > ArrayWritableObjectInspector.<init>(ArrayWritableObjectInspector.java:59)
>>     > > >         at org.apache.hadoop.hive.ql.io.parquet.serde.
>>     > > > ParquetHiveSerDe.initialize(ParquetHiveSerDe.java:113)
>>     > > >         at org.apache.hadoop.hive.metastore.MetaStoreUtils.
>>     > > > getDeserializer(MetaStoreUtils.java:339)
>>     > > >         at org.apache.hadoop.hive.ql.metadata.Table.
>>     > > > getDeserializerFromMetaStore(Table.java:283)
>>     > > >         at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(
>>     > > > Table.java:189)
>>     > > >         at org.apache.hadoop.hive.ql.metadata.Hive.createTable(
>>     > > > Hive.java:597)
>>     > > >         at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(
>>     > > > DDLTask.java:4194)
>>     > > >         at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.
>>     > > > java:281)
>>     > > >         at
>>     > org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
>>     > > >         at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(
>>     > > > TaskRunner.java:85)
>>     > > >
>>     > > >
>>     > > >
>>     > > >
>>     > > >
>>     > > > On 2014/9/2 16:45, Sean Owen wrote:
>>     > > >
>>     > > >> Hm, are you suggesting that the Spark distribution be a bag of 100
>>     > > >> JARs? It doesn't quite seem reasonable. It does not remove version
>>     > > >> conflicts, just pushes them to run-time, which isn't good. The
>>     > > >> assembly is also necessary because that's where shading happens. In
>>     > > >> development, you want to run against exactly what will be used in a
>>     > > >> real Spark distro.
>>     > > >>
>>     > > >> On Tue, Sep 2, 2014 at 9:39 AM, scwf <wangfei1@huawei.com <mailto:wangfei1@huawei.com>> wrote:
>>     > > >>
>>     > > >>> hi, all
>>     > > >>>    I suggest spark not use assembly jar as default run-time
>>     > > >>> dependency(spark-submit/spark-class depend on assembly jar),use a
>>     > > >>> library of
>>     > > >>> all 3rd dependency jar like hadoop/hive/hbase more reasonable.
>>     > > >>>
>>     > > >>>    1 assembly jar packaged all 3rd jars into a big one, so we need
>>     > > >>> rebuild
>>     > > >>> this jar if we want to update the version of some component(such as
>>     > > >>> hadoop)
>>     > > >>>    2 in our practice with spark, sometimes we meet jar compatibility
>>     > > >>> issue,
>>     > > >>> it is hard to diagnose compatibility issue with assembly jar
>>     > > >>>
>>     > > >>>
>>     > > >>>
>>     > > >>>
>>     > > >>>
>>     > > >>>
>>     > > >>>
>>     > > >>> ---------------------------------------------------------------------
>>     > > >>> To unsubscribe, e-mail:dev-unsubscribe@spark.apache.org <mailto:dev-unsubscribe@spark.apache.org>
>>     > > >>> For additional commands, e-mail:dev-help@spark.apache.org <mailto:dev-help@spark.apache.org>
>>     > > >>>
>>     > > >>>
>>     > > >>
>>     > > >>
>>     > > >
>>     > > >
>>     > > > ---------------------------------------------------------------------
>>     > > > To unsubscribe, e-mail:dev-unsubscribe@spark.apache.org <mailto:dev-unsubscribe@spark.apache.org>
>>     > > > For additional commands, e-mail:dev-help@spark.apache.org <mailto:dev-help@spark.apache.org>
>>     > > >
>>     > > >
>>     > >
>>     >
>
>



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9249-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 04:56:28 2014
Return-Path: <dev-return-9249-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2AA3011275
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 04:56:28 +0000 (UTC)
Received: (qmail 96753 invoked by uid 500); 3 Sep 2014 04:56:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96691 invoked by uid 500); 3 Sep 2014 04:56:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96679 invoked by uid 99); 3 Sep 2014 04:56:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 04:56:27 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 04:56:00 +0000
Received: by mail-ob0-f172.google.com with SMTP id wo20so5704289obc.17
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 21:55:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=KiN/Hu4QzxlTNdfAK4BkhInIowohBr36gWMd3lrPqF4=;
        b=lxWJgBYBsLqjhVP4hul41zBDdKptvga4vtb4MrzjEMXo+ZDkRwXpfak/T5VB55M6oz
         v7OX59mgUYu3pPfR/s2hMogIGmwMqqTa/sJtHXh6ViPt58/zJnwg6q+5kmDjXgWEaXd+
         xsNhLGtzXL7uj8OfWkal5rNyIpOT/dw944oqxeu1yddMNlz0YD0hUUOUXlOmeR/Av74b
         zdPOjeZJckBnFWmFJleTevnOBUrx64X1bVRKtXGO+XpV/Vqkqe1+pkLUjkft47b4R1Pc
         fo+96aS6T21s17o1gHar/bR2vI7OyACsX4dL2PlGf/JZcGBO+iaNYEany+4PzMmnn4Ii
         HpDw==
MIME-Version: 1.0
X-Received: by 10.60.146.176 with SMTP id td16mr36488569oeb.28.1409720158971;
 Tue, 02 Sep 2014 21:55:58 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 2 Sep 2014 21:55:58 -0700 (PDT)
In-Reply-To: <CAOhmDzcBAFGx3DG-18G5pWiT5Kit6ZgBt482R-cAXHGLPK2FFQ@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
	<CAOhmDzcoPjs3byXpuUf585VQSu4xs5rYAXcqy6zh=wBpENsnLg@mail.gmail.com>
	<CAOhmDzcBAFGx3DG-18G5pWiT5Kit6ZgBt482R-cAXHGLPK2FFQ@mail.gmail.com>
Date: Tue, 2 Sep 2014 21:55:58 -0700
Message-ID: <CABPQxstYCz6=nLXhMKRib+BanpWOi6i=ok3mNZ0=9fJD_hi9PQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks everyone for voting on this. There were two minor issues (one a
blocker) were found that warrant cutting a new RC. For those who voted
+1 on this release, I'd encourage you to +1 rc4 when it comes out
unless you have been testing issues specific to the EC2 scripts. This
will move the release process along.

SPARK-3332 - Issue with tagging in EC2 scripts
SPARK-3358 - Issue with regression for m3.XX instances

- Patrick

On Tue, Sep 2, 2014 at 6:55 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> In light of the discussion on SPARK-3333, I'll revoke my "-1" vote. The
> issue does not appear to be serious.
>
>
> On Sun, Aug 31, 2014 at 5:14 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
>>
>> -1: I believe I've found a regression from 1.0.2. The report is captured
>> in SPARK-3333.
>>
>>
>> On Sat, Aug 30, 2014 at 6:07 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>>
>>> Please vote on releasing the following candidate as Apache Spark version
>>> 1.1.0!
>>>
>>> The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
>>>
>>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b2d0493b223c5f98a593bb6d7372706cc02bebad
>>>
>>> The release files, including signatures, digests, etc. can be found at:
>>> http://people.apache.org/~pwendell/spark-1.1.0-rc3/
>>>
>>> Release artifacts are signed with the following key:
>>> https://people.apache.org/keys/committer/pwendell.asc
>>>
>>> The staging repository for this release can be found at:
>>> https://repository.apache.org/content/repositories/orgapachespark-1030/
>>>
>>> The documentation corresponding to this release can be found at:
>>> http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
>>>
>>> Please vote on releasing this package as Apache Spark 1.1.0!
>>>
>>> The vote is open until Tuesday, September 02, at 23:07 UTC and passes if
>>> a majority of at least 3 +1 PMC votes are cast.
>>>
>>> [ ] +1 Release this package as Apache Spark 1.1.0
>>> [ ] -1 Do not release this package because ...
>>>
>>> To learn more about Apache Spark, please see
>>> http://spark.apache.org/
>>>
>>> == Regressions fixed since RC1 ==
>>> - Build issue for SQL support:
>>> https://issues.apache.org/jira/browse/SPARK-3234
>>> - EC2 script version bump to 1.1.0.
>>>
>>> == What justifies a -1 vote for this release? ==
>>> This vote is happening very late into the QA period compared with
>>> previous votes, so -1 votes should only occur for significant
>>> regressions from 1.0.2. Bugs already present in 1.0.X will not block
>>> this release.
>>>
>>> == What default changes should I be aware of? ==
>>> 1. The default value of "spark.io.compression.codec" is now "snappy"
>>> --> Old behavior can be restored by switching to "lzf"
>>>
>>> 2. PySpark now performs external spilling during aggregations.
>>> --> Old behavior can be restored by setting "spark.shuffle.spill" to
>>> "false".
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9250-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 05:25:36 2014
Return-Path: <dev-return-9250-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 10EA411373
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 05:25:36 +0000 (UTC)
Received: (qmail 55791 invoked by uid 500); 3 Sep 2014 05:25:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55726 invoked by uid 500); 3 Sep 2014 05:25:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55714 invoked by uid 99); 3 Sep 2014 05:25:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 05:25:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of velvia.github@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 05:25:30 +0000
Received: by mail-wg0-f46.google.com with SMTP id x13so7886631wgg.5
        for <dev@spark.apache.org>; Tue, 02 Sep 2014 22:25:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=J7cS4UtL87cwNlarhZwQ0pHi2qkIyRAIvkTqZKxErNE=;
        b=DOPbBtNouoC+WsPWeOon1PkTgCVAA0zQaQdxBHV1foxOZdMHOj7Q/TEPin1VVIY4ax
         KAWdvEI3KeVT7d2RuUlfeB2J8cvZacKVWe5aiTwu3ETEhGy83Cr1Qx6i4y2wfw7PxH5Q
         qU6vk7ugZLFNwxadoB1sL7yv4tnYeoiusytM1xf67/gEp8mpmE4ews4Y+evFEJT4z7Cr
         AJ3YVy7UBRWDZpsXTSlyYIuw7QcXJBmMpJn/gdQo8yulX5CSs8847X48AbqmAzKrFKR+
         ShgYDU7Jy+uh1rmdAeJBya6eKuadaun1oMa497XE60JXJp7X2ejk+uYEkKGzYbZx76B9
         h65w==
MIME-Version: 1.0
X-Received: by 10.194.200.137 with SMTP id js9mr14581293wjc.90.1409721908998;
 Tue, 02 Sep 2014 22:25:08 -0700 (PDT)
Received: by 10.216.33.10 with HTTP; Tue, 2 Sep 2014 22:25:08 -0700 (PDT)
In-Reply-To: <CAMDxJTFfbrXH7bdupOfNPhwqEMgEShg4OoWUzZa6UvyJS9D96w@mail.gmail.com>
References: <CAN6Vra27gzyifyrVVTnoGddRmysN-rnfCHBTDCT1KuX-ZcOjPw@mail.gmail.com>
	<CAAswR-43krAdVUDZ3ZLod1qFWYzAsZhQBv87s17vuD2Sc4A6WA@mail.gmail.com>
	<CAN6Vra0oSCPAr14mO3RfuPz5D1WnB1C8xFEcUmCuoqSiLzrGHw@mail.gmail.com>
	<CAAswR-60n8cj5WU47TNw-AvmVBAmdveb7XEu4YmjyTjqbR=hCg@mail.gmail.com>
	<CAN6Vra0xEZV7XYpCqWYgJABC2CHLtau423yc69_=WVwPXAMV3A@mail.gmail.com>
	<CAMDxJTFfbrXH7bdupOfNPhwqEMgEShg4OoWUzZa6UvyJS9D96w@mail.gmail.com>
Date: Tue, 2 Sep 2014 22:25:08 -0700
Message-ID: <CAN6Vra1Jnwh2qWebLStMcL4=9=OWpXLTvzERBMuf+_S_p6krYQ@mail.gmail.com>
Subject: Re: [Spark SQL] off-heap columnar store
From: Evan Chan <velvia.github@gmail.com>
To: "Ian O'Connell" <ian@ianoconnell.com>
Cc: Michael Armbrust <michael@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Sun, Aug 31, 2014 at 8:27 PM, Ian O'Connell <ian@ianoconnell.com> wrote:
> I'm not sure what you mean here? Parquet is at its core just a format, you
> could store that data anywhere.
>
> Though it sounds like you saying, correct me if i'm wrong: you basically
> want a columnar abstraction layer where you can provide a different backing
> implementation to keep the columns rather than parquet-mr?
>
> I.e. you want to be able to produce a schema RDD from something like
> vertica, where updates should act as a write through cache back to vertica
> itself?

Something like that.

I'd like,

1)  An API to produce a schema RDD from an RDD of columns, not rows.
  However, an RDD[Column] would not make sense, since it would be
spread out across partitions.  Perhaps what is needed is a
Seq[RDD[ColumnSegment]].    The idea is that each RDD would hold the
segments for one column.  The segments represent a range of rows.
This would then read from something like Vertica or Cassandra.

2)  A variant of 1) where you could read this data from Tachyon.
Tachyon is supposed to support a columnar representation of data, it
did for Shark 0.9.x.

The goal is basically to load columnar data from something like
Cassandra into Tachyon, with the compression ratio of columnar
storage, and the speed of InMemoryColumnarTableScan.   If data is
appended into the Tachyon representation, be able to cache it back.
The write back is not as high a priority though.

A workaround would be to read data from Cassandra/Vertica/etc. and
write back into Parquet, but this would take a long time and incur
huge I/O overhead.

>
> I'm sorry it just sounds like its worth clearly defining what your key
> requirement/goal is.
>
>
> On Thu, Aug 28, 2014 at 11:31 PM, Evan Chan <velvia.github@gmail.com> wrote:
>>
>> >
>> >> The reason I'm asking about the columnar compressed format is that
>> >> there are some problems for which Parquet is not practical.
>> >
>> >
>> > Can you elaborate?
>>
>> Sure.
>>
>> - Organization or co has no Hadoop, but significant investment in some
>> other NoSQL store.
>> - Need to efficiently add a new column to existing data
>> - Need to mark some existing rows as deleted or replace small bits of
>> existing data
>>
>> For these use cases, it would be much more efficient and practical if
>> we didn't have to take the origin of the data from the datastore,
>> convert it to Parquet first.  Doing so loses significant latency and
>> causes Ops headaches in having to maintain HDFS.     It would be great
>> to be able to load data directly into the columnar format, into the
>> InMemoryColumnarCache.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9251-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 07:03:04 2014
Return-Path: <dev-return-9251-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C4FB71167A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 07:03:04 +0000 (UTC)
Received: (qmail 53121 invoked by uid 500); 3 Sep 2014 07:03:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53051 invoked by uid 500); 3 Sep 2014 07:03:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53033 invoked by uid 99); 3 Sep 2014 07:03:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:03:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:02:57 +0000
Received: by mail-ob0-f171.google.com with SMTP id wn1so5816454obc.30
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 00:02:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=k0DB3P8VM1A8tDcyPCSUTDlCHTKcq0r00i8twaPHkaI=;
        b=vwvtlSlnAFVRS8JNuvKBkL1R6XvKZPjW6+pka3nziM1z2xPcMaw/PPKdZ7nA2jAFHt
         3zNr2WuVVwhvJxPfj5+R2k/JaR8QKRQPr5kQE2Ctf9Fpnfmk+nftQyW/FWaOu/GaHIlI
         0AX8b23xH+HSeDroa8Nayvr60D9sCK5pUBZ98X/yO5oHFDf9kdxdqDxrte7xR5yXrkZ5
         cu67epY5q/BqQ+HNMWW2khUx94nrFvPXWBjuTqjWPy2FtRsRdkA5/k/1LN5ml7RlShr6
         ByLNQQOrprvSCKdie+7HubeaFiePLInWbaIrJgKvEf8EioAaVE2pjlnzrVSJhAiT0/Bx
         k/7w==
MIME-Version: 1.0
X-Received: by 10.60.92.168 with SMTP id cn8mr212660oeb.83.1409727756605; Wed,
 03 Sep 2014 00:02:36 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 3 Sep 2014 00:02:36 -0700 (PDT)
In-Reply-To: <CABPQxstYCz6=nLXhMKRib+BanpWOi6i=ok3mNZ0=9fJD_hi9PQ@mail.gmail.com>
References: <CABPQxstG4PmQ1hKF2T3d_0GCZWqw15_gx9A2yh4utt9X=cPgZg@mail.gmail.com>
	<CAOhmDzcoPjs3byXpuUf585VQSu4xs5rYAXcqy6zh=wBpENsnLg@mail.gmail.com>
	<CAOhmDzcBAFGx3DG-18G5pWiT5Kit6ZgBt482R-cAXHGLPK2FFQ@mail.gmail.com>
	<CABPQxstYCz6=nLXhMKRib+BanpWOi6i=ok3mNZ0=9fJD_hi9PQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 00:02:36 -0700
Message-ID: <CABPQxstipcCFqbr+mjDy=nU6od+UtryaJL-CytChx2+HiaQdEQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC3)
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'm cancelling this release in favor of RC4. Happy voting!

On Tue, Sep 2, 2014 at 9:55 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Thanks everyone for voting on this. There were two minor issues (one a
> blocker) were found that warrant cutting a new RC. For those who voted
> +1 on this release, I'd encourage you to +1 rc4 when it comes out
> unless you have been testing issues specific to the EC2 scripts. This
> will move the release process along.
>
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> - Patrick
>
> On Tue, Sep 2, 2014 at 6:55 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
>> In light of the discussion on SPARK-3333, I'll revoke my "-1" vote. The
>> issue does not appear to be serious.
>>
>>
>> On Sun, Aug 31, 2014 at 5:14 PM, Nicholas Chammas
>> <nicholas.chammas@gmail.com> wrote:
>>>
>>> -1: I believe I've found a regression from 1.0.2. The report is captured
>>> in SPARK-3333.
>>>
>>>
>>> On Sat, Aug 30, 2014 at 6:07 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>>
>>>> Please vote on releasing the following candidate as Apache Spark version
>>>> 1.1.0!
>>>>
>>>> The tag to be voted on is v1.1.0-rc3 (commit b2d0493b):
>>>>
>>>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b2d0493b223c5f98a593bb6d7372706cc02bebad
>>>>
>>>> The release files, including signatures, digests, etc. can be found at:
>>>> http://people.apache.org/~pwendell/spark-1.1.0-rc3/
>>>>
>>>> Release artifacts are signed with the following key:
>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>>
>>>> The staging repository for this release can be found at:
>>>> https://repository.apache.org/content/repositories/orgapachespark-1030/
>>>>
>>>> The documentation corresponding to this release can be found at:
>>>> http://people.apache.org/~pwendell/spark-1.1.0-rc3-docs/
>>>>
>>>> Please vote on releasing this package as Apache Spark 1.1.0!
>>>>
>>>> The vote is open until Tuesday, September 02, at 23:07 UTC and passes if
>>>> a majority of at least 3 +1 PMC votes are cast.
>>>>
>>>> [ ] +1 Release this package as Apache Spark 1.1.0
>>>> [ ] -1 Do not release this package because ...
>>>>
>>>> To learn more about Apache Spark, please see
>>>> http://spark.apache.org/
>>>>
>>>> == Regressions fixed since RC1 ==
>>>> - Build issue for SQL support:
>>>> https://issues.apache.org/jira/browse/SPARK-3234
>>>> - EC2 script version bump to 1.1.0.
>>>>
>>>> == What justifies a -1 vote for this release? ==
>>>> This vote is happening very late into the QA period compared with
>>>> previous votes, so -1 votes should only occur for significant
>>>> regressions from 1.0.2. Bugs already present in 1.0.X will not block
>>>> this release.
>>>>
>>>> == What default changes should I be aware of? ==
>>>> 1. The default value of "spark.io.compression.codec" is now "snappy"
>>>> --> Old behavior can be restored by switching to "lzf"
>>>>
>>>> 2. PySpark now performs external spilling during aggregations.
>>>> --> Old behavior can be restored by setting "spark.shuffle.spill" to
>>>> "false".
>>>>
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9252-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 07:25:14 2014
Return-Path: <dev-return-9252-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D1773116FB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 07:25:14 +0000 (UTC)
Received: (qmail 95265 invoked by uid 500); 3 Sep 2014 07:25:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95202 invoked by uid 500); 3 Sep 2014 07:25:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95185 invoked by uid 99); 3 Sep 2014 07:25:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:25:09 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:25:04 +0000
Received: by mail-ob0-f176.google.com with SMTP id wn1so5679830obc.21
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 00:24:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=LXFzjQ+mddDb83/I4jHJG9EdFHPOBAzDKhVweKLBCb0=;
        b=xlNwiIpEUaxOwMXAAJa5aYlYxwe4YS53R++K0ffYkH3iYqs7lIHuZDlQwePJhs+a5s
         hET6kKq6qhX1ChvZNssM4PBaTUqtLZsv3dP4acZJRd/xv7SPQy244vpo/xFM9i8FZOkU
         3l2/tnRc3mbZElEHnbYQuCkxL1mZHPGznW9K3nzLE82F3Zgz4qjwnFiuxtlyB8+ESkM2
         rOG0BIPUti16DbVphrN8HlCiZ9EAm48JGYZ7GkNT6xxsDwX0McFs54XFPjlfRqOo+DJs
         EZkVeAM8ANjmhliVGghe5H4ZdtdriS1+BFPQjwovAf6FO0UlGekUqQPLxhQ1aiL/x/vJ
         wG3g==
MIME-Version: 1.0
X-Received: by 10.60.102.100 with SMTP id fn4mr36937027oeb.30.1409729083600;
 Wed, 03 Sep 2014 00:24:43 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 3 Sep 2014 00:24:43 -0700 (PDT)
Date: Wed, 3 Sep 2014 00:24:43 -0700
Message-ID: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Please vote on releasing the following candidate as Apache Spark version 1.1.0!

The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.1.0-rc4/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1031/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/

Please vote on releasing this package as Apache Spark 1.1.0!

The vote is open until Saturday, September 06, at 08:30 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.1.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

== Regressions fixed since RC3 ==
SPARK-3332 - Issue with tagging in EC2 scripts
SPARK-3358 - Issue with regression for m3.XX instances

== What justifies a -1 vote for this release? ==
This vote is happening very late into the QA period compared with
previous votes, so -1 votes should only occur for significant
regressions from 1.0.2. Bugs already present in 1.0.X will not block
this release.

== What default changes should I be aware of? ==
1. The default value of "spark.io.compression.codec" is now "snappy"
--> Old behavior can be restored by switching to "lzf"

2. PySpark now performs external spilling during aggregations.
--> Old behavior can be restored by setting "spark.shuffle.spill" to "false".

3. PySpark uses a new heuristic for determining the parallelism of
shuffle operations.
--> Old behavior can be restored by setting
"spark.default.parallelism" to the number of cores in the cluster.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9253-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 07:25:33 2014
Return-Path: <dev-return-9253-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA78F116FE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 07:25:33 +0000 (UTC)
Received: (qmail 96454 invoked by uid 500); 3 Sep 2014 07:25:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96391 invoked by uid 500); 3 Sep 2014 07:25:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96368 invoked by uid 99); 3 Sep 2014 07:25:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:25:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.42 as permitted sender)
Received: from [209.85.219.42] (HELO mail-oa0-f42.google.com) (209.85.219.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:24:55 +0000
Received: by mail-oa0-f42.google.com with SMTP id m1so5701843oag.29
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 00:24:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=uGTTSlb8QF9arstC9zvnP9x7hCNkTkbv6zvOolSkYdo=;
        b=OcaAu1E9u3nGbVgxjqtxRG7AYVuPOEmEtJZA90szmhEjrQCxU4aHkNHBgxTAJhNbTM
         VVR+kfqJ9JkFMpfFJAr+zWvpke2NP9OFanjb1+buKN7MXSr7sOS7mgckk4CBs4k18TLV
         hiai1rB2jKMqwH4HZ8pQozlZf7bx2KIKo5JdjpAkNyId5FVQC0CvEWc71b5po3h3oXDR
         wS0hof1E0DtV9OgJhtADQzMGamoBQQbvIKD7qinCsY/BZ05OUgdCiIrViwxq8j0XprmW
         yAjlz4tdeHeSOSV6lJuZw6GLfQj9ELZLCJmIYHR6R7aQN/j/ROptS1vf3mxquX0hCw79
         aHrQ==
MIME-Version: 1.0
X-Received: by 10.60.147.130 with SMTP id tk2mr6815682oeb.68.1409729093777;
 Wed, 03 Sep 2014 00:24:53 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 3 Sep 2014 00:24:53 -0700 (PDT)
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 00:24:53 -0700
Message-ID: <CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'll kick it off with a +1

On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.1.0!
>
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1031/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>
> Please vote on releasing this package as Apache Spark 1.1.0!
>
> The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == Regressions fixed since RC3 ==
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
>
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9254-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 07:30:35 2014
Return-Path: <dev-return-9254-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E8BD011722
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 07:30:34 +0000 (UTC)
Received: (qmail 9247 invoked by uid 500); 3 Sep 2014 07:30:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9187 invoked by uid 500); 3 Sep 2014 07:30:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9173 invoked by uid 99); 3 Sep 2014 07:30:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:30:20 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:29:52 +0000
Received: by mail-qg0-f41.google.com with SMTP id i50so7929628qgf.14
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 00:29:51 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=0D6fXQ3auzFamJL9Nu2Zw17c0GYiB1bZR35oShe0Nig=;
        b=GTuf57Ukira/xRl8Ugc5YPM2LsrgXgL0qL7a8roBzEkAg+DRaRwydgcxVDodbW6wM1
         S+4nSvpPbQduR1P1ts6A6Y+3pubkqXZRk2P4XWexL8XkE8mXHbI2Gt2SwYG5uEImlEfC
         4C2XA10EIO/EFQ5vOxEN0s91fvhuDXFvjuM0ERA5DzQf/NCoxwqTt3TE+/EjRJ9ZmPjx
         hJeNegRxGiQb/xNF0l+HmNmI7aP1U+Jo3hqVYMfS02afS7L6uRuBB89g1uLnqoDkFKEF
         PnxgTvu1T+yLRrRrQSw14TaOYmB8AAwODO+WHmCobI6UPYmvjzpODIufT6MHq+jGTQcu
         Yihg==
X-Gm-Message-State: ALoCoQkavBA+Sv1Qah5wFdu9K3zIi0JElY0ZXRGgO/kFRmlmk2vyFWdiZ5+u34yJKvEpnyw1CYx8
X-Received: by 10.224.30.139 with SMTP id u11mr63908080qac.77.1409729391349;
 Wed, 03 Sep 2014 00:29:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Wed, 3 Sep 2014 00:29:31 -0700 (PDT)
In-Reply-To: <CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 3 Sep 2014 00:29:31 -0700
Message-ID: <CAPh_B=bQ57Qp+zfHQfhRDL3v6xH0fhee2b-7wDhLmcwRxHGecw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bea2dd899ebfb0502243332
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea2dd899ebfb0502243332
Content-Type: text/plain; charset=UTF-8

+1

Tested locally on Mac OS X with local-cluster mode.




On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> I'll kick it off with a +1
>
> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Please vote on releasing the following candidate as Apache Spark version
> 1.1.0!
> >
> > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> >
> > The release files, including signatures, digests, etc. can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-1031/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> >
> > Please vote on releasing this package as Apache Spark 1.1.0!
> >
> > The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> > a majority of at least 3 +1 PMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 1.1.0
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.apache.org/
> >
> > == Regressions fixed since RC3 ==
> > SPARK-3332 - Issue with tagging in EC2 scripts
> > SPARK-3358 - Issue with regression for m3.XX instances
> >
> > == What justifies a -1 vote for this release? ==
> > This vote is happening very late into the QA period compared with
> > previous votes, so -1 votes should only occur for significant
> > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > this release.
> >
> > == What default changes should I be aware of? ==
> > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > --> Old behavior can be restored by switching to "lzf"
> >
> > 2. PySpark now performs external spilling during aggregations.
> > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> "false".
> >
> > 3. PySpark uses a new heuristic for determining the parallelism of
> > shuffle operations.
> > --> Old behavior can be restored by setting
> > "spark.default.parallelism" to the number of cores in the cluster.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7bea2dd899ebfb0502243332--

From dev-return-9255-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 07:35:51 2014
Return-Path: <dev-return-9255-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D92E611742
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 07:35:51 +0000 (UTC)
Received: (qmail 17629 invoked by uid 500); 3 Sep 2014 07:35:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17555 invoked by uid 500); 3 Sep 2014 07:35:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17544 invoked by uid 99); 3 Sep 2014 07:35:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:35:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 07:34:50 +0000
Received: by mail-lb0-f177.google.com with SMTP id z11so8820545lbi.8
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 00:34:49 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=wq29e1LI0HDm8VpdkJmq+A1JyJJMN3OrTVIkbvZgtAk=;
        b=LVeT+Y12BxJP0zhNFVY9q9HPG4NlQI7r1Tkw7TYGSRKCDQV70rAikzY8WydDJRK5o5
         BRw9gNBxAtuCawHiS1K6Y//YnGgfDVJcJfcYwxvVl40phv0Y7ksp+/O8bbO4MjJ6pFS8
         dMAa9T+gC/RmYbm2ilwgSo0HIOF7gONjraSOItdhFGRZsXSmcqNNLBWf7Wkki77x+f2s
         E418MDRfq0JDmC6CnajMMSL0do9n1qFYPGE2Zwh+lJFiE0AUHXKveE72NrgzTWZWMJ10
         i9WJydp9udyBSTAC6iM1DEssZI4iSDOVawxFKkkEIWbDvIn2vE2eb7cvelQpI7et/diL
         d3yw==
X-Gm-Message-State: ALoCoQmiwF5CXZHz+npo5Q3/FQpoLoZihWqM2paepy6U75IG1hozh0EDGyx/8NuSsd5jIPEFId/U
X-Received: by 10.152.87.82 with SMTP id v18mr7441521laz.83.1409729689349;
 Wed, 03 Sep 2014 00:34:49 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Wed, 3 Sep 2014 00:34:29 -0700 (PDT)
In-Reply-To: <CAPh_B=bQ57Qp+zfHQfhRDL3v6xH0fhee2b-7wDhLmcwRxHGecw@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com> <CAPh_B=bQ57Qp+zfHQfhRDL3v6xH0fhee2b-7wDhLmcwRxHGecw@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 3 Sep 2014 00:34:29 -0700
Message-ID: <CAAswR-5Q7HxSwo4naCUTCxnw+L5FphmoQwSvH2fxxsj0EmcdzA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Reynold Xin <rxin@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2ae8c5d02a00502244540
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2ae8c5d02a00502244540
Content-Type: text/plain; charset=UTF-8

+1


On Wed, Sep 3, 2014 at 12:29 AM, Reynold Xin <rxin@databricks.com> wrote:

> +1
>
> Tested locally on Mac OS X with local-cluster mode.
>
>
>
>
> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > I'll kick it off with a +1
> >
> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > > Please vote on releasing the following candidate as Apache Spark
> version
> > 1.1.0!
> > >
> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> > >
> > > The release files, including signatures, digests, etc. can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1031/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> > >
> > > Please vote on releasing this package as Apache Spark 1.1.0!
> > >
> > > The vote is open until Saturday, September 06, at 08:30 UTC and passes
> if
> > > a majority of at least 3 +1 PMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.apache.org/
> > >
> > > == Regressions fixed since RC3 ==
> > > SPARK-3332 - Issue with tagging in EC2 scripts
> > > SPARK-3358 - Issue with regression for m3.XX instances
> > >
> > > == What justifies a -1 vote for this release? ==
> > > This vote is happening very late into the QA period compared with
> > > previous votes, so -1 votes should only occur for significant
> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > > this release.
> > >
> > > == What default changes should I be aware of? ==
> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > > --> Old behavior can be restored by switching to "lzf"
> > >
> > > 2. PySpark now performs external spilling during aggregations.
> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> > "false".
> > >
> > > 3. PySpark uses a new heuristic for determining the parallelism of
> > > shuffle operations.
> > > --> Old behavior can be restored by setting
> > > "spark.default.parallelism" to the number of cores in the cluster.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a11c2ae8c5d02a00502244540--

From dev-return-9256-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 08:26:43 2014
Return-Path: <dev-return-9256-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA21911883
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 08:26:43 +0000 (UTC)
Received: (qmail 18594 invoked by uid 500); 3 Sep 2014 08:26:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18525 invoked by uid 500); 3 Sep 2014 08:26:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18513 invoked by uid 99); 3 Sep 2014 08:26:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 08:26:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 08:25:54 +0000
Received: by mail-ig0-f177.google.com with SMTP id r10so8679816igi.10
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 01:25:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Hlc4cRsymsss9jrDlag/0Z50Wb55N/cuPivShx0/BTM=;
        b=kjW20SueW+txhzLcaTiaea4cYKptnksB0hHaZiAqNcIGIRSqiq6rxkAV3nyEXn7NUr
         TVixFKsrrZtL9hYwIlBiji0+7hPC5OtVN0EKuwQdtpdKT2yeGYiFih3PC32TQ6b5r1zc
         kp+2I+MdL5ZXERtHp+J4Bt7pj8nZg1A+QQrIqvHn2CuXrhNMhrt5wGgzT445KjpCoNMd
         kP5kbMSKi+5Ro6XSOT2Q5kb798PWk2bYiU8D5YlxRyJniSUIKDEYUT+o1cjO+LlONNwH
         amBxIHI4fjbIZLHuhgaVJGct2ETTaGjgn/rjAbdJlRDEob+7zY4B1YFY4CJMLriw9Bbh
         75Gw==
MIME-Version: 1.0
X-Received: by 10.42.84.9 with SMTP id j9mr7669636icl.60.1409732753308; Wed,
 03 Sep 2014 01:25:53 -0700 (PDT)
Received: by 10.107.152.196 with HTTP; Wed, 3 Sep 2014 01:25:53 -0700 (PDT)
In-Reply-To: <CAAswR-5Q7HxSwo4naCUTCxnw+L5FphmoQwSvH2fxxsj0EmcdzA@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com>
	<CAPh_B=bQ57Qp+zfHQfhRDL3v6xH0fhee2b-7wDhLmcwRxHGecw@mail.gmail.com>
	<CAAswR-5Q7HxSwo4naCUTCxnw+L5FphmoQwSvH2fxxsj0EmcdzA@mail.gmail.com>
Date: Wed, 3 Sep 2014 01:25:53 -0700
Message-ID: <CAJgQjQ-bx_e-7g5U9xgj38trKUkN3nE372OT4wNaNqWyS=65YQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Xiangrui Meng <mengxr@gmail.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Reynold Xin <rxin@databricks.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1. Tested some MLlib example code.

For default changes, maybe it is useful to mention the default
broadcast factory changed to torrent.

On Wed, Sep 3, 2014 at 12:34 AM, Michael Armbrust
<michael@databricks.com> wrote:
> +1
>
>
> On Wed, Sep 3, 2014 at 12:29 AM, Reynold Xin <rxin@databricks.com> wrote:
>
>> +1
>>
>> Tested locally on Mac OS X with local-cluster mode.
>>
>>
>>
>>
>> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > I'll kick it off with a +1
>> >
>> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
>> > wrote:
>> > > Please vote on releasing the following candidate as Apache Spark
>> version
>> > 1.1.0!
>> > >
>> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
>> > >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>> > >
>> > > The release files, including signatures, digests, etc. can be found at:
>> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>> > >
>> > > Release artifacts are signed with the following key:
>> > > https://people.apache.org/keys/committer/pwendell.asc
>> > >
>> > > The staging repository for this release can be found at:
>> > >
>> https://repository.apache.org/content/repositories/orgapachespark-1031/
>> > >
>> > > The documentation corresponding to this release can be found at:
>> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>> > >
>> > > Please vote on releasing this package as Apache Spark 1.1.0!
>> > >
>> > > The vote is open until Saturday, September 06, at 08:30 UTC and passes
>> if
>> > > a majority of at least 3 +1 PMC votes are cast.
>> > >
>> > > [ ] +1 Release this package as Apache Spark 1.1.0
>> > > [ ] -1 Do not release this package because ...
>> > >
>> > > To learn more about Apache Spark, please see
>> > > http://spark.apache.org/
>> > >
>> > > == Regressions fixed since RC3 ==
>> > > SPARK-3332 - Issue with tagging in EC2 scripts
>> > > SPARK-3358 - Issue with regression for m3.XX instances
>> > >
>> > > == What justifies a -1 vote for this release? ==
>> > > This vote is happening very late into the QA period compared with
>> > > previous votes, so -1 votes should only occur for significant
>> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
>> > > this release.
>> > >
>> > > == What default changes should I be aware of? ==
>> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
>> > > --> Old behavior can be restored by switching to "lzf"
>> > >
>> > > 2. PySpark now performs external spilling during aggregations.
>> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
>> > "false".
>> > >
>> > > 3. PySpark uses a new heuristic for determining the parallelism of
>> > > shuffle operations.
>> > > --> Old behavior can be restored by setting
>> > > "spark.default.parallelism" to the number of cores in the cluster.
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9257-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 09:01:04 2014
Return-Path: <dev-return-9257-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3E10411985
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 09:01:04 +0000 (UTC)
Received: (qmail 85088 invoked by uid 500); 3 Sep 2014 09:00:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85030 invoked by uid 500); 3 Sep 2014 09:00:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85019 invoked by uid 99); 3 Sep 2014 09:00:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 09:00:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 09:00:32 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so16820817pad.7
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 02:00:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=LjHG3T8RzASNaH+/dGdBpCKQLA5t6EFyWGreZX1GiEA=;
        b=gWxHLrs4hLYt9lvsZh1TfupxBS5xNaNXced/eQLCBqKsvJtXqHCaE/STF0WZNZ+PBp
         jfCKf+QlSgeHWRcFe7K9zAjEguYZDdqHXdSk+P/g9n+0BQSNirzXUqWH5RKJSS1nrq8E
         XUChCCLOYaLpCxYZJn1GY4AE7S7njmL4G7oHVgYRgNe3K18pWG7k1ugyZt/nU7a4xB4j
         flCEk3bMkoR9yfZukQ/9GK07QzBQHobW206r2f/sUqycD5AXfXiAz0KfGaScsRBytVKS
         KY29XmFBYHj2WiieYTGfJiaw3gdl7ezTIaCCTRnLLI4QdnW+KC98TCBULXEl9lNJx6I8
         cn0w==
X-Gm-Message-State: ALoCoQlfwzF2lb4mOKvxawRV1TFtBU3nU/FIz9Ie0pjdU48p4up5bPJBqx6sJfdwxNq8KfCCo4il
MIME-Version: 1.0
X-Received: by 10.66.231.10 with SMTP id tc10mr27643125pac.121.1409734485108;
 Wed, 03 Sep 2014 01:54:45 -0700 (PDT)
Received: by 10.70.41.198 with HTTP; Wed, 3 Sep 2014 01:54:45 -0700 (PDT)
In-Reply-To: <CAJgQjQ-bx_e-7g5U9xgj38trKUkN3nE372OT4wNaNqWyS=65YQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CABPQxstH86BMvF-B7xxz0VB4H6SeeXUShn=cM_VCP3Y48c6Bqg@mail.gmail.com>
	<CAPh_B=bQ57Qp+zfHQfhRDL3v6xH0fhee2b-7wDhLmcwRxHGecw@mail.gmail.com>
	<CAAswR-5Q7HxSwo4naCUTCxnw+L5FphmoQwSvH2fxxsj0EmcdzA@mail.gmail.com>
	<CAJgQjQ-bx_e-7g5U9xgj38trKUkN3nE372OT4wNaNqWyS=65YQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 01:54:45 -0700
Message-ID: <CAMJOb8mf=R6KQTBQyHcXB+oo2XeyotDDdDcG7RkfNZhN0hEkwA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Andrew Or <andrew@databricks.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, Reynold Xin <rxin@databricks.com>, 
	Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b111e5d3688950502256321
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b111e5d3688950502256321
Content-Type: text/plain; charset=UTF-8

+1 Tested on Yarn and Windows. Also verified that standalone cluster mode
is now fixed.


2014-09-03 1:25 GMT-07:00 Xiangrui Meng <mengxr@gmail.com>:

> +1. Tested some MLlib example code.
>
> For default changes, maybe it is useful to mention the default
> broadcast factory changed to torrent.
>
> On Wed, Sep 3, 2014 at 12:34 AM, Michael Armbrust
> <michael@databricks.com> wrote:
> > +1
> >
> >
> > On Wed, Sep 3, 2014 at 12:29 AM, Reynold Xin <rxin@databricks.com>
> wrote:
> >
> >> +1
> >>
> >> Tested locally on Mac OS X with local-cluster mode.
> >>
> >>
> >>
> >>
> >> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >>
> >> > I'll kick it off with a +1
> >> >
> >> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> >> > wrote:
> >> > > Please vote on releasing the following candidate as Apache Spark
> >> version
> >> > 1.1.0!
> >> > >
> >> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> >> > >
> >> >
> >>
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> >> > >
> >> > > The release files, including signatures, digests, etc. can be found
> at:
> >> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> >> > >
> >> > > Release artifacts are signed with the following key:
> >> > > https://people.apache.org/keys/committer/pwendell.asc
> >> > >
> >> > > The staging repository for this release can be found at:
> >> > >
> >> https://repository.apache.org/content/repositories/orgapachespark-1031/
> >> > >
> >> > > The documentation corresponding to this release can be found at:
> >> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> >> > >
> >> > > Please vote on releasing this package as Apache Spark 1.1.0!
> >> > >
> >> > > The vote is open until Saturday, September 06, at 08:30 UTC and
> passes
> >> if
> >> > > a majority of at least 3 +1 PMC votes are cast.
> >> > >
> >> > > [ ] +1 Release this package as Apache Spark 1.1.0
> >> > > [ ] -1 Do not release this package because ...
> >> > >
> >> > > To learn more about Apache Spark, please see
> >> > > http://spark.apache.org/
> >> > >
> >> > > == Regressions fixed since RC3 ==
> >> > > SPARK-3332 - Issue with tagging in EC2 scripts
> >> > > SPARK-3358 - Issue with regression for m3.XX instances
> >> > >
> >> > > == What justifies a -1 vote for this release? ==
> >> > > This vote is happening very late into the QA period compared with
> >> > > previous votes, so -1 votes should only occur for significant
> >> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> >> > > this release.
> >> > >
> >> > > == What default changes should I be aware of? ==
> >> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> >> > > --> Old behavior can be restored by switching to "lzf"
> >> > >
> >> > > 2. PySpark now performs external spilling during aggregations.
> >> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> >> > "false".
> >> > >
> >> > > 3. PySpark uses a new heuristic for determining the parallelism of
> >> > > shuffle operations.
> >> > > --> Old behavior can be restored by setting
> >> > > "spark.default.parallelism" to the number of cores in the cluster.
> >> >
> >> > ---------------------------------------------------------------------
> >> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> > For additional commands, e-mail: dev-help@spark.apache.org
> >> >
> >> >
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b111e5d3688950502256321--

From dev-return-9258-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 11:07:40 2014
Return-Path: <dev-return-9258-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD20711DC9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 11:07:40 +0000 (UTC)
Received: (qmail 29721 invoked by uid 500); 3 Sep 2014 11:07:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29657 invoked by uid 500); 3 Sep 2014 11:07:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29646 invoked by uid 99); 3 Sep 2014 11:07:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 11:07:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 11:07:29 +0000
Received: by mail-ig0-f182.google.com with SMTP id a13so8860963igq.3
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 04:07:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=+hQ73L61Pi+ODDzlgK4qx9T+nMw9nOqJfK5HIFavpK0=;
        b=KRi9u62ei/iyIxiIFNKJ6ZIK0L5KDD4IGbznGFFBJkNfrGVNeE8ot0F/dxsjUsHMnm
         J3XK82nkfZ6HgALgesk9Vb62DtcJb45AmN9Y0jCSyeTo0XJz/rFBpL0HAD/hOCPaf1fD
         aMIyvXtoT4nP7an5BhYgxlAvawLoDGtzjo139NbQ3USHCChOOaOuDGwSKHO+6JxfjgUL
         a+shGjdHQb+Rvii0gGhxFL9ZLOucr2goUd82UXPt0C7RovxSGwchQVA2z2Gwt1uDSUgs
         4j6XUiEiKnmK5GYFwfH+DZepq7izmSvlHnME6naHCw2XC1qi9pi5Yk6Ify9miIFGpX0+
         MTGA==
X-Gm-Message-State: ALoCoQkRhe5Y9HmJrB1zZg5LlQ3E65LRrVJiaGvD38RFjKAynepAF2lL28pVD8Ll6H7MITIHhbNA
X-Received: by 10.50.80.76 with SMTP id p12mr35911846igx.34.1409742428573;
 Wed, 03 Sep 2014 04:07:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Wed, 3 Sep 2014 04:06:48 -0700 (PDT)
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 3 Sep 2014 12:06:48 +0100
Message-ID: <CAMAsSdJs0fMsdc-K-4orgBhBfz2VvrMM0HFyifEeaL-SpFtPKQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1 signatures still fine, tests still pass. On Mac OS X I get the
following failure but I think it's spurious. Only mentioning it to see
if anyone else sees it. It doesn't happen on Linux.

[error] Test org.apache.spark.streaming.kafka.JavaKafkaStreamSuite.testKafkaStream
failed: junit.framework.AssertionFailedError: expected:<3> but was:<0>
[error]     at junit.framework.Assert.fail(Assert.java:50)
[error]     at junit.framework.Assert.failNotEquals(Assert.java:287)
[error]     at junit.framework.Assert.assertEquals(Assert.java:67)
[error]     at junit.framework.Assert.assertEquals(Assert.java:199)
[error]     at junit.framework.Assert.assertEquals(Assert.java:205)
[error]     at org.apache.spark.streaming.kafka.JavaKafkaStreamSuite.testKafkaStream(JavaKafkaStreamSuite.java:129)
[error]

On Wed, Sep 3, 2014 at 8:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.1.0!
>
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1031/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>
> Please vote on releasing this package as Apache Spark 1.1.0!
>
> The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == Regressions fixed since RC3 ==
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
>
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9260-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 14:56:22 2014
Return-Path: <dev-return-9260-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3FBB3110E9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 14:56:22 +0000 (UTC)
Received: (qmail 45975 invoked by uid 500); 3 Sep 2014 14:25:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31093 invoked by uid 500); 3 Sep 2014 14:25:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91824 invoked by uid 99); 3 Sep 2014 12:37:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 12:37:15 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 12:37:10 +0000
Received: from int-mx10.intmail.prod.int.phx2.redhat.com (int-mx10.intmail.prod.int.phx2.redhat.com [10.5.11.23])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s83CakVK010518
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Wed, 3 Sep 2014 08:36:47 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx10.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s83Cajo1008466;
	Wed, 3 Sep 2014 08:36:46 -0400
Message-ID: <54070B5D.8000000@redhat.com>
Date: Wed, 03 Sep 2014 08:36:45 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: Patrick Wendell <pwendell@gmail.com>,
        "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.23
X-Virus-Checked: Checked by ClamAV on apache.org

+1

built from sha w/ make-distribution.sh
tested basic examples (0 data) w/ local on fedora 20 (openjdk 1.7, 
python 2.7.5)
tested detection and log processing (25GB data) w/ mesos (0.19.0) & nfs 
on rhel 7 (openjdk 1.7, python 2.7.5)

On 09/03/2014 03:24 AM, Patrick Wendell wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.1.0!
>
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1031/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>
> Please vote on releasing this package as Apache Spark 1.1.0!
>
> The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == Regressions fixed since RC3 ==
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
>
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9259-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 14:56:22 2014
Return-Path: <dev-return-9259-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 544AC110EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 14:56:22 +0000 (UTC)
Received: (qmail 42493 invoked by uid 500); 3 Sep 2014 14:25:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24378 invoked by uid 500); 3 Sep 2014 14:25:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7233 invoked by uid 99); 3 Sep 2014 14:24:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 14:24:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.174 as permitted sender)
Received: from [74.125.82.174] (HELO mail-we0-f174.google.com) (74.125.82.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 14:24:18 +0000
Received: by mail-we0-f174.google.com with SMTP id u57so8717836wes.33
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 07:23:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=BhgcxnhAg8iRA+E/RtPfvFYXHdz+x/FZ9NKyYzFOnfA=;
        b=W7qVgjYBkF7IRRu4B6Mb7lN4Ea4E5E42gVGRXON7tx8D0lO2zM8KtoC8Sdqu7nRug7
         3ECcU2qO3CVVEGt9EL0sueWNKMQUWZA6SYudsXK0840W0HFyufsclM1iI/38Xrck+8M3
         b+cZk9I6muypfuMrcCEqLkJPgHHVRA3TP3+WcEb+A0vY/ZFW2J1KZ2eGNAGQV7w0MQ7I
         yd+UZdQvwXFo+pigFmS8XrGewOkjsW1fb/skSbVhpBsLo2W00oRlxis4d+uDEDeKWurI
         i4ELXDsKOGkWIm/XQfD477pxB6TKzgTzS24LLtX5X992QtCQ6x8P83WXO1koKSQuBbYz
         5yhQ==
X-Received: by 10.194.59.18 with SMTP id v18mr7511391wjq.64.1409754237759;
 Wed, 03 Sep 2014 07:23:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Wed, 3 Sep 2014 07:23:17 -0700 (PDT)
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 3 Sep 2014 10:23:17 -0400
Message-ID: <CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bacb0a6906fee050229fc72
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bacb0a6906fee050229fc72
Content-Type: text/plain; charset=UTF-8

On Wed, Sep 3, 2014 at 3:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to
> "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.
>

Will these changes be called out in the release notes or somewhere in the
docs?

That last one (which I believe is what we discovered as the result of
SPARK-3333 <https://issues.apache.org/jira/browse/SPARK-3333>) could have a
large impact on PySpark users.

Nick

--047d7bacb0a6906fee050229fc72--

From dev-return-9261-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 16:37:07 2014
Return-Path: <dev-return-9261-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A2BED118CE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 16:37:07 +0000 (UTC)
Received: (qmail 26946 invoked by uid 500); 3 Sep 2014 16:37:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26862 invoked by uid 500); 3 Sep 2014 16:37:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26849 invoked by uid 99); 3 Sep 2014 16:37:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 16:37:06 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 16:36:39 +0000
Received: by mail-ob0-f179.google.com with SMTP id uz6so6402472obc.10
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 09:36:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Lm/IINBkjVlQtHb7DXTpIIGQ+81rozuU4mX/HWqeu68=;
        b=MdgBtCSCgcqAGG2SUm4lYpDx9XWskhbsUXbkme9VyJV/IeimpYT3cgzmMyxwcApsUu
         VXP/Er2OBSvqtv47iYTg5pRNmVuW9dt+fTQJbt4iXVfDRhf216muRSa7NEoEZ8zloE7N
         8eEFSWsIX//XJV4kNpBr4yPlV7FGlEjarZoJ9vhP/3umQRp7rOAFM8qTkxMtQXXlAS2+
         iyFHBZcs8p+D1iyB7azmX14LchxcDDEpjzKNndjGaWO68dV9yL+ULe6OFhV4EuIbhEei
         VZfab4oN2X4TnSN8nOGfJ75cTieMabWHX0AbBSB1D097k5SnM7W9wc+wKFFi1E2RynPA
         Kjzg==
MIME-Version: 1.0
X-Received: by 10.182.191.39 with SMTP id gv7mr39004212obc.14.1409762198487;
 Wed, 03 Sep 2014 09:36:38 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 3 Sep 2014 09:36:38 -0700 (PDT)
In-Reply-To: <CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 09:36:38 -0700
Message-ID: <CABPQxstZPPoFUa_D-3QxogPzqqWEckm3HLNLx0KSz0tBJ7JjTg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Nick,

Yeah we'll put those in the release notes.

On Wed, Sep 3, 2014 at 7:23 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> On Wed, Sep 3, 2014 at 3:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> == What default changes should I be aware of? ==
>> 1. The default value of "spark.io.compression.codec" is now "snappy"
>> --> Old behavior can be restored by switching to "lzf"
>>
>> 2. PySpark now performs external spilling during aggregations.
>> --> Old behavior can be restored by setting "spark.shuffle.spill" to
>> "false".
>>
>> 3. PySpark uses a new heuristic for determining the parallelism of
>> shuffle operations.
>> --> Old behavior can be restored by setting
>> "spark.default.parallelism" to the number of cores in the cluster.
>
>
> Will these changes be called out in the release notes or somewhere in the
> docs?
>
> That last one (which I believe is what we discovered as the result of
> SPARK-3333) could have a large impact on PySpark users.
>
> Nick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9262-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:07:20 2014
Return-Path: <dev-return-9262-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2C0EA11A28
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:07:20 +0000 (UTC)
Received: (qmail 99805 invoked by uid 500); 3 Sep 2014 17:07:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99725 invoked by uid 500); 3 Sep 2014 17:07:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99710 invoked by uid 99); 3 Sep 2014 17:07:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:07:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.169 as permitted sender)
Received: from [209.85.212.169] (HELO mail-wi0-f169.google.com) (209.85.212.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:07:14 +0000
Received: by mail-wi0-f169.google.com with SMTP id n3so6244596wiv.0
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 10:06:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=6yr54IrEWBICv3sm4Y95UuPB+k6qBZH+TP83hU3Qi+w=;
        b=Dw4RMTFcEcgaW5ii5kDGnvf4du6pathwm1HwBjWKtdsCZGm2a3wmFfOfTb+BKUj3tn
         eRkjQT6hMVr7TXlQCQeVnd4zTIdk/YA8i1x1vmzPtNV962NwHF+kB8CqNjGEn8uj4JPj
         9rywZspzXdwHAONhTE5aKsdFVtKj8R4Pj9pPkJTf1P11UtMzV37EQvnKMi67Yv2wUjcm
         fxMrVMZuspxRadABYY5q5H85Fn3mnZcKWOvZllbEtHAzOVjKYyujVEdkEd7GcxQah6yB
         nfBBR84tnJ9MopFNvuAW5ktpWu7rj2O7ge4Klka9ZMyPBJSs3yY3aN4HnkWtEuePZ07+
         KGqg==
X-Received: by 10.180.149.197 with SMTP id uc5mr36176480wib.75.1409764013595;
 Wed, 03 Sep 2014 10:06:53 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Wed, 3 Sep 2014 10:06:13 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 3 Sep 2014 13:06:13 -0400
Message-ID: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com>
Subject: spark-ec2 depends on stuff in the Mesos repo
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c381143f623205022c4375
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c381143f623205022c4375
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Spawned by this discussion
<https://github.com/apache/spark/pull/1120#issuecomment-54305831>.

See these 2 lines in spark_ec2.py:

   - spark_ec2 L42
   <https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d5=
13115c/ec2/spark_ec2.py#L42>
   - spark_ec2 L566
   <https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d5=
13115c/ec2/spark_ec2.py#L566>

Why does the spark-ec2 script depend on stuff in the Mesos repo? Should
they be moved to the Spark repo?

Nick
=E2=80=8B

--001a11c381143f623205022c4375--

From dev-return-9263-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:17:45 2014
Return-Path: <dev-return-9263-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DBA9811A87
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:17:44 +0000 (UTC)
Received: (qmail 27113 invoked by uid 500); 3 Sep 2014 17:17:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27058 invoked by uid 500); 3 Sep 2014 17:17:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27045 invoked by uid 99); 3 Sep 2014 17:17:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:17:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of shivaram@berkeley.edu designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:17:15 +0000
Received: by mail-wg0-f50.google.com with SMTP id x12so8807308wgg.33
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 10:17:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=AYroC/bUPrEtJWIfq2LYX50JWoGxnONYTq5ShfDFkVY=;
        b=WZ/bGW8dBMIz2+5Lk2Tkgo0CiuBtW98s4hP04oc1H2wKzN7Mav68yJqzhGka9tvtWA
         dADEQE7lk5h4cjFJlaeZKmWnzPvXAUqaQrrThpO72KBZmwOMgbFIN+k3W23JJr/6yPqT
         i0Qvuo0HEX6AjVnMpA5du64ff1Bm7vGe/m1tH+Hcc6yxQQa67iGLleDHqd3Zh74fRtkj
         tdA/auMS3HO/s7I8S3bKDMHA7f6nxDkrNU0er/XJB0f5iaoef52UvL3YtgtWXytKgPdp
         CT/X/wvy0hun8NzOQEzKysUvsH14LEVIUikdvqyYr8f4Ix97bwAhXfyOzyh+dm2BOlib
         I3mg==
X-Gm-Message-State: ALoCoQluF+90l/bwczjiDSHizyObSkqu4JRnmWMvgHO3wnWFlDvRKB+/gQAfEJtLQx0XuozY+v1d
MIME-Version: 1.0
X-Received: by 10.180.37.16 with SMTP id u16mr37826448wij.72.1409764634311;
 Wed, 03 Sep 2014 10:17:14 -0700 (PDT)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.216.108.198 with HTTP; Wed, 3 Sep 2014 10:17:14 -0700 (PDT)
In-Reply-To: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com>
References: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com>
Date: Wed, 3 Sep 2014 10:17:14 -0700
Message-ID: <CAKx7Bf_M2Q-kx4_R_LRCsf09f9zd79r2CQnhyU2hWwy=LOJd1w@mail.gmail.com>
Subject: Re: spark-ec2 depends on stuff in the Mesos repo
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f646ff53ecd6605022c686d
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f646ff53ecd6605022c686d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

The spark-ec2 repository isn't a part of Mesos. Back in the days, Spark
used to be hosted in the Mesos github organization as well and so we put
scripts that were used by Spark under the same organization.

FWIW I don't think these scripts belong in the Spark repository. They are
helper scripts that setup EC2 clusters with different components like HDFS,
Spark, Tachyon etc. Also one of the motivations for creating this
repository was the ability to change these scripts without requiring a new
Spark release or a new AMI etc.

We can move the repository to a different github organization like AMPLab
if that'll make sense.

Thanks
Shivaram


On Wed, Sep 3, 2014 at 10:06 AM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Spawned by this discussion
> <https://github.com/apache/spark/pull/1120#issuecomment-54305831>.
>
> See these 2 lines in spark_ec2.py:
>
>    - spark_ec2 L42
>    <
> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513=
115c/ec2/spark_ec2.py#L42
> >
>    - spark_ec2 L566
>    <
> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513=
115c/ec2/spark_ec2.py#L566
> >
>
> Why does the spark-ec2 script depend on stuff in the Mesos repo? Should
> they be moved to the Spark repo?
>
> Nick
> =E2=80=8B
>

--e89a8f646ff53ecd6605022c686d--

From dev-return-9264-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:22:52 2014
Return-Path: <dev-return-9264-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4C5BF11AC5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:22:52 +0000 (UTC)
Received: (qmail 43787 invoked by uid 500); 3 Sep 2014 17:22:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43722 invoked by uid 500); 3 Sep 2014 17:22:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43703 invoked by uid 99); 3 Sep 2014 17:22:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:22:51 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:22:46 +0000
Received: from int-mx11.intmail.prod.int.phx2.redhat.com (int-mx11.intmail.prod.int.phx2.redhat.com [10.5.11.24])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s83HMIHT006821
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Wed, 3 Sep 2014 13:22:19 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx11.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s83HMHxc003363;
	Wed, 3 Sep 2014 13:22:17 -0400
Message-ID: <54074E49.3060303@redhat.com>
Date: Wed, 03 Sep 2014 13:22:17 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: shivaram@eecs.berkeley.edu, Nicholas Chammas <nicholas.chammas@gmail.com>
CC: dev <dev@spark.apache.org>
Subject: Re: spark-ec2 depends on stuff in the Mesos repo
References: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com> <CAKx7Bf_M2Q-kx4_R_LRCsf09f9zd79r2CQnhyU2hWwy=LOJd1w@mail.gmail.com>
In-Reply-To: <CAKx7Bf_M2Q-kx4_R_LRCsf09f9zd79r2CQnhyU2hWwy=LOJd1w@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.24
X-Virus-Checked: Checked by ClamAV on apache.org

that's not a bad idea. it would also break the circular dep in versions 
that results in spark X's ec2 script installing spark X-1 by default.

best,


matt

On 09/03/2014 01:17 PM, Shivaram Venkataraman wrote:
> The spark-ec2 repository isn't a part of Mesos. Back in the days, Spark
> used to be hosted in the Mesos github organization as well and so we put
> scripts that were used by Spark under the same organization.
>
> FWIW I don't think these scripts belong in the Spark repository. They are
> helper scripts that setup EC2 clusters with different components like HDFS,
> Spark, Tachyon etc. Also one of the motivations for creating this
> repository was the ability to change these scripts without requiring a new
> Spark release or a new AMI etc.
>
> We can move the repository to a different github organization like AMPLab
> if that'll make sense.
>
> Thanks
> Shivaram
>
>
> On Wed, Sep 3, 2014 at 10:06 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Spawned by this discussion
>> <https://github.com/apache/spark/pull/1120#issuecomment-54305831>.
>>
>> See these 2 lines in spark_ec2.py:
>>
>>     - spark_ec2 L42
>>     <
>> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513115c/ec2/spark_ec2.py#L42
>>>
>>     - spark_ec2 L566
>>     <
>> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513115c/ec2/spark_ec2.py#L566
>>>
>>
>> Why does the spark-ec2 script depend on stuff in the Mesos repo? Should
>> they be moved to the Spark repo?
>>
>> Nick
>> 
>>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9265-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:28:21 2014
Return-Path: <dev-return-9265-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4FCAE11B01
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:28:21 +0000 (UTC)
Received: (qmail 57634 invoked by uid 500); 3 Sep 2014 17:28:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57569 invoked by uid 500); 3 Sep 2014 17:28:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57548 invoked by uid 99); 3 Sep 2014 17:28:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:28:20 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.55] (HELO g4t3427.houston.hp.com) (15.201.208.55)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:28:12 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3427.houston.hp.com (Postfix) with ESMTPS id 3502024B
	for <dev@spark.apache.org>; Wed,  3 Sep 2014 17:27:52 +0000 (UTC)
Received: from G4W6303.americas.hpqcorp.net (16.210.26.228) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Wed, 3 Sep 2014 17:26:56 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.222]) by
 G4W6303.americas.hpqcorp.net ([16.210.26.228]) with mapi id 14.03.0169.001;
 Wed, 3 Sep 2014 17:26:56 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "<dev@spark.apache.org>" <dev@spark.apache.org>
Subject: Is breeze thread safe in Spark?
Thread-Topic: Is breeze thread safe in Spark?
Thread-Index: Ac/HnEHIpnke8IkPRvauFqDTM2ZjuA==
Date: Wed, 3 Sep 2014 17:26:54 +0000
Message-ID: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
Accept-Language: en-US
Content-Language: ru-RU
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
Content-Type: text/plain; charset="us-ascii"
Content-ID: <DA58B6241D266E48926213B6E24BD4B0@Compaq.com>
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

Is breeze library called thread safe from Spark mllib code in case when nat=
ive libs for blas and lapack are used? Might it be an issue when running Sp=
ark locally?

Best regards, Alexander=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9266-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:30:34 2014
Return-Path: <dev-return-9266-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DC9D211B18
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:30:33 +0000 (UTC)
Received: (qmail 67415 invoked by uid 500); 3 Sep 2014 17:30:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67351 invoked by uid 500); 3 Sep 2014 17:30:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67339 invoked by uid 99); 3 Sep 2014 17:30:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:30:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of shivaram@berkeley.edu designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:30:27 +0000
Received: by mail-wg0-f41.google.com with SMTP id l18so8861843wgh.12
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 10:30:06 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=hJZTQJhFCA8g32fgQPMORpIn3X34KM2iOe53QmJgmkg=;
        b=dP89OkHMaHvLp71gqidBUvsEYpKMK5t5AwBI2jf8V3gKuS78WTV8Wc7gA/laqr5At1
         oHPLQwgIpeV10xoUZz2DreX8u0KM0oOcSXGw8OwUWqlCH3xLI5YE7sjBh244dUj9iWKD
         ltx6XreEZiGG5IQx8u2eGtTVxzpNs9479kKF8e0dreOoIrzZ2XMUPeLhbXJxYqSuoUtP
         S9v8Qxa4cVS8NMITvHkKfnj9snbfUlIGrNsPFFKZHb1Sr/TDjROk/kqidsaJqUDU8Sec
         0v4acreeEzkAIGxhA4txJxMRjCYBC34INk15GuMMYIMsE+3M1356+O7K9E6E42NTF7Fx
         WfXw==
X-Gm-Message-State: ALoCoQkG5geQ5GCnm2jKrP+VnzMgM7IdZF8htxsY/dy6WRr/YS3yZRCylDVEBMQUrA5zuwzHJ/C/
MIME-Version: 1.0
X-Received: by 10.194.77.212 with SMTP id u20mr49476782wjw.27.1409765406144;
 Wed, 03 Sep 2014 10:30:06 -0700 (PDT)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.216.108.198 with HTTP; Wed, 3 Sep 2014 10:30:06 -0700 (PDT)
In-Reply-To: <54074E49.3060303@redhat.com>
References: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com>
	<CAKx7Bf_M2Q-kx4_R_LRCsf09f9zd79r2CQnhyU2hWwy=LOJd1w@mail.gmail.com>
	<54074E49.3060303@redhat.com>
Date: Wed, 3 Sep 2014 10:30:06 -0700
Message-ID: <CAKx7Bf_-_OVJnZKHEAmbwOMFBZCg3KNjoT1-7grk_ZEiZB07Rg@mail.gmail.com>
Subject: Re: spark-ec2 depends on stuff in the Mesos repo
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Matthew Farrellee <matt@redhat.com>
Cc: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfcf85840097a05022c96c9
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfcf85840097a05022c96c9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Actually the circular dependency doesn't depend on the spark-ec2 scripts --
The scripts contain download links to many Spark versions and you can
configure which one should be used.

Shivaram


On Wed, Sep 3, 2014 at 10:22 AM, Matthew Farrellee <matt@redhat.com> wrote:

> that's not a bad idea. it would also break the circular dep in versions
> that results in spark X's ec2 script installing spark X-1 by default.
>
> best,
>
>
> matt
>
>
> On 09/03/2014 01:17 PM, Shivaram Venkataraman wrote:
>
>> The spark-ec2 repository isn't a part of Mesos. Back in the days, Spark
>> used to be hosted in the Mesos github organization as well and so we put
>> scripts that were used by Spark under the same organization.
>>
>> FWIW I don't think these scripts belong in the Spark repository. They ar=
e
>> helper scripts that setup EC2 clusters with different components like
>> HDFS,
>> Spark, Tachyon etc. Also one of the motivations for creating this
>> repository was the ability to change these scripts without requiring a n=
ew
>> Spark release or a new AMI etc.
>>
>> We can move the repository to a different github organization like AMPLa=
b
>> if that'll make sense.
>>
>> Thanks
>> Shivaram
>>
>>
>> On Wed, Sep 3, 2014 at 10:06 AM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>  Spawned by this discussion
>>> <https://github.com/apache/spark/pull/1120#issuecomment-54305831>.
>>>
>>> See these 2 lines in spark_ec2.py:
>>>
>>>     - spark_ec2 L42
>>>     <
>>> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818b
>>> c7d513115c/ec2/spark_ec2.py#L42
>>>
>>>>
>>>>      - spark_ec2 L566
>>>     <
>>> https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818b
>>> c7d513115c/ec2/spark_ec2.py#L566
>>>
>>>>
>>>>
>>> Why does the spark-ec2 script depend on stuff in the Mesos repo? Should
>>> they be moved to the Spark repo?
>>>
>>> Nick
>>> =E2=80=8B
>>>
>>>
>>
>

--047d7bfcf85840097a05022c96c9--

From dev-return-9267-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:33:45 2014
Return-Path: <dev-return-9267-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9BE5F11B41
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:33:45 +0000 (UTC)
Received: (qmail 82214 invoked by uid 500); 3 Sep 2014 17:33:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82152 invoked by uid 500); 3 Sep 2014 17:33:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82137 invoked by uid 99); 3 Sep 2014 17:33:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:33:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:33:39 +0000
Received: by mail-qa0-f46.google.com with SMTP id w8so8071228qac.5
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 10:33:18 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=NzP7bFn20RpMl3zruuq+MbOBfpa7p8vn4wp2kI5JmNw=;
        b=RrjRj63CAybAGMsbjyId8sfr1oGIpLEH1WewpPUAgTxnCcKyRGfRpm3AI+AQ8N7tIM
         J6TfK4VMUwUO/TKL3e7ycyPN5pG8kKVM8AoMw9E1iNXTTk8B4S7Zv5jRtIohbjRfkD8C
         lHyFblmZ4uDExRdVclaGf4SdsncCU8MmXRnoXEdwFQrKW2OIxyHjh0iy3prRbyMmi6UR
         hJknn/INZsk1jRoEB12uDSipArvOrxYLx2T2JVPin+FxCo476TlI/eLkuzth02l06jVI
         he4m1aX6fq7EoCm7TXD3n79aHOhw3sftdU2jRRsbIYQFcoNIV9k1Q93rNSfYdZQQXMa3
         Y1FA==
X-Gm-Message-State: ALoCoQm6yJFCxKZJ+Vw/GtC0lkdwUZu9qB9cwiU2LUzL7T3+VXMmbyjfbEYiVxyamUgjw0Kfa2AQ
MIME-Version: 1.0
X-Received: by 10.140.109.75 with SMTP id k69mr45624035qgf.96.1409765597081;
 Wed, 03 Sep 2014 10:33:17 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Wed, 3 Sep 2014 10:33:16 -0700 (PDT)
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 10:33:16 -0700
Message-ID: <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Marcelo Vanzin <vanzin@cloudera.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1 (non-binding)

- checked checksums of a few packages
- ran few jobs against yarn client/cluster using hadoop2.3 package
- played with spark-shell in yarn-client mode

On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.1.0!
>
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1031/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>
> Please vote on releasing this package as Apache Spark 1.1.0!
>
> The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == Regressions fixed since RC3 ==
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
>
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9268-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:40:52 2014
Return-Path: <dev-return-9268-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0531F11B93
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:40:52 +0000 (UTC)
Received: (qmail 13306 invoked by uid 500); 3 Sep 2014 17:40:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13246 invoked by uid 500); 3 Sep 2014 17:40:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13221 invoked by uid 99); 3 Sep 2014 17:40:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:40:47 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:40:21 +0000
Received: from int-mx11.intmail.prod.int.phx2.redhat.com (int-mx11.intmail.prod.int.phx2.redhat.com [10.5.11.24])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s83HeFdS012149
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Wed, 3 Sep 2014 13:40:15 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx11.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s83HeDDU012124;
	Wed, 3 Sep 2014 13:40:14 -0400
Message-ID: <5407527D.1010806@redhat.com>
Date: Wed, 03 Sep 2014 13:40:13 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: shivaram@eecs.berkeley.edu
CC: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Subject: Re: spark-ec2 depends on stuff in the Mesos repo
References: <CAOhmDzeTR84s8N84qB7JoOE3np8SJ+ao0YTVszrTKXBVVF79HA@mail.gmail.com>	<CAKx7Bf_M2Q-kx4_R_LRCsf09f9zd79r2CQnhyU2hWwy=LOJd1w@mail.gmail.com>	<54074E49.3060303@redhat.com> <CAKx7Bf_-_OVJnZKHEAmbwOMFBZCg3KNjoT1-7grk_ZEiZB07Rg@mail.gmail.com>
In-Reply-To: <CAKx7Bf_-_OVJnZKHEAmbwOMFBZCg3KNjoT1-7grk_ZEiZB07Rg@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.24
X-Virus-Checked: Checked by ClamAV on apache.org

oh, i see pwendell is did a patch to the release branch to make the 
release version == --spark-version default

best,


matt

On 09/03/2014 01:30 PM, Shivaram Venkataraman wrote:
> Actually the circular dependency doesn't depend on the spark-ec2 scripts
> -- The scripts contain download links to many Spark versions and you can
> configure which one should be used.
>
> Shivaram
>
>
> On Wed, Sep 3, 2014 at 10:22 AM, Matthew Farrellee <matt@redhat.com
> <mailto:matt@redhat.com>> wrote:
>
>     that's not a bad idea. it would also break the circular dep in
>     versions that results in spark X's ec2 script installing spark X-1
>     by default.
>
>     best,
>
>
>     matt
>
>
>     On 09/03/2014 01:17 PM, Shivaram Venkataraman wrote:
>
>         The spark-ec2 repository isn't a part of Mesos. Back in the
>         days, Spark
>         used to be hosted in the Mesos github organization as well and
>         so we put
>         scripts that were used by Spark under the same organization.
>
>         FWIW I don't think these scripts belong in the Spark repository.
>         They are
>         helper scripts that setup EC2 clusters with different components
>         like HDFS,
>         Spark, Tachyon etc. Also one of the motivations for creating this
>         repository was the ability to change these scripts without
>         requiring a new
>         Spark release or a new AMI etc.
>
>         We can move the repository to a different github organization
>         like AMPLab
>         if that'll make sense.
>
>         Thanks
>         Shivaram
>
>
>         On Wed, Sep 3, 2014 at 10:06 AM, Nicholas Chammas <
>         nicholas.chammas@gmail.com <mailto:nicholas.chammas@gmail.com>>
>         wrote:
>
>             Spawned by this discussion
>             <https://github.com/apache/__spark/pull/1120#issuecomment-__54305831
>             <https://github.com/apache/spark/pull/1120#issuecomment-54305831>>.
>
>             See these 2 lines in spark_ec2.py:
>
>                  - spark_ec2 L42
>                  <
>             https://github.com/apache/__spark/blob/__6a72a36940311fcb3429bd34c8818b__c7d513115c/ec2/spark_ec2.py#__L42
>             <https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513115c/ec2/spark_ec2.py#L42>
>
>
>                  - spark_ec2 L566
>                  <
>             https://github.com/apache/__spark/blob/__6a72a36940311fcb3429bd34c8818b__c7d513115c/ec2/spark_ec2.py#__L566
>             <https://github.com/apache/spark/blob/6a72a36940311fcb3429bd34c8818bc7d513115c/ec2/spark_ec2.py#L566>
>
>
>
>             Why does the spark-ec2 script depend on stuff in the Mesos
>             repo? Should
>             they be moved to the Spark repo?
>
>             Nick
>             
>
>
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9269-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 17:41:50 2014
Return-Path: <dev-return-9269-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F7FF11B99
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 17:41:50 +0000 (UTC)
Received: (qmail 17693 invoked by uid 500); 3 Sep 2014 17:41:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17628 invoked by uid 500); 3 Sep 2014 17:41:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17616 invoked by uid 99); 3 Sep 2014 17:41:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:41:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rnowling@gmail.com designates 74.125.82.177 as permitted sender)
Received: from [74.125.82.177] (HELO mail-we0-f177.google.com) (74.125.82.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 17:41:43 +0000
Received: by mail-we0-f177.google.com with SMTP id u56so8956471wes.36
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 10:41:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=URCFSW7KB14aq8CIk4EXLaKYxsF0mwhrwdsWJ5RwhcI=;
        b=pFrn6tK2sxBAHlTO0AOx029eeMY4sQ/5dE/G0Fb5xkQvSMcs/izXAmx423/3ysle0m
         +/Jupd+ZwaywEs9G5weC1Gl8qu/LDPycZ28D4cQ5I9hDsP1JJwVSaGI9NZEKcAhxlj4S
         h25Wwr+PDU74DeqQ9D6FGBziqvuORw+WXY11Rz9OwF7LKiRkGwdFQiH/El6XXzOu+2sU
         qI+8nsCYqgiHX9k0e93BrXyVMDJjtyzRcnVRKY0APo7KPJJj3fHYpKuIIp2ZkTCuW3YQ
         Q3sPzIvQuw1tZmcHs8Gc2+svjhuO2Y9k77+4EQv2db9/s83N2KzZNkrigbchSNlNneo5
         4oPw==
MIME-Version: 1.0
X-Received: by 10.194.170.227 with SMTP id ap3mr48897034wjc.30.1409766081514;
 Wed, 03 Sep 2014 10:41:21 -0700 (PDT)
Received: by 10.194.14.137 with HTTP; Wed, 3 Sep 2014 10:41:21 -0700 (PDT)
In-Reply-To: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
Date: Wed, 3 Sep 2014 13:41:21 -0400
Message-ID: <CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: RJ Nowling <rnowling@gmail.com>
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: "<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122e92281569905022cbec3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122e92281569905022cbec3
Content-Type: text/plain; charset=UTF-8

No, it's not in all cases.   Since Breeze uses lapack under the hood,
changes to memory between different threads is bad.

There's actually a potential bug in the KMeans code where it uses +=
instead of +.


On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

> Hi,
>
> Is breeze library called thread safe from Spark mllib code in case when
> native libs for blas and lapack are used? Might it be an issue when running
> Spark locally?
>
> Best regards, Alexander
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--089e0122e92281569905022cbec3--

From dev-return-9270-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:16:41 2014
Return-Path: <dev-return-9270-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 213C511D5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:16:41 +0000 (UTC)
Received: (qmail 32494 invoked by uid 500); 3 Sep 2014 18:16:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32432 invoked by uid 500); 3 Sep 2014 18:16:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32421 invoked by uid 99); 3 Sep 2014 18:16:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:16:39 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:16:08 +0000
Received: from int-mx14.intmail.prod.int.phx2.redhat.com (int-mx14.intmail.prod.int.phx2.redhat.com [10.5.11.27])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s83IFqJa012257
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Wed, 3 Sep 2014 14:15:52 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx14.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s83IFoMh024520;
	Wed, 3 Sep 2014 14:15:51 -0400
Message-ID: <54075AD6.8090803@redhat.com>
Date: Wed, 03 Sep 2014 14:15:50 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: Reynold Xin <rxin@databricks.com>, Sanghoon Lee <phoenixlee1@gmail.com>
CC: dev <dev@spark.apache.org>
Subject: Re: Ask something about spark
References: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com> <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com>
In-Reply-To: <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.27
X-Virus-Checked: Checked by ClamAV on apache.org

reynold,

would you folks be willing to put some creative commons license 
information on the site and its content?

best,


matt

On 09/02/2014 06:32 PM, Reynold Xin wrote:
> I think in general that is fine. It would be great if your slides come with
> proper attribution.
>
>
> On Tue, Sep 2, 2014 at 3:31 PM, Sanghoon Lee <phoenixlee1@gmail.com> wrote:
>
>> Hi, I am phoenixlee and a Spark programmer in Korea.
>>
>> And be a good chance this time, it tries to teach college students and
>> office workers to Spark.
>> This course will be done with the support of the government. Can I use the
>> data(pictures, samples, etc.) in the spark homepage for this course? Of
>> course, I will put the comments in thanks and webpage URL. It would be a
>> good opportunity, even though the findings were that there is no teaching
>> materials "Spark" and education (or community) still in Korea.
>>
>> Thanks.
>> 
>>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9271-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:24:04 2014
Return-Path: <dev-return-9271-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CFCA111DDA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:24:04 +0000 (UTC)
Received: (qmail 50168 invoked by uid 500); 3 Sep 2014 18:24:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50103 invoked by uid 500); 3 Sep 2014 18:24:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50092 invoked by uid 99); 3 Sep 2014 18:24:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:24:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.44] (HELO mail-qa0-f44.google.com) (209.85.216.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:23:57 +0000
Received: by mail-qa0-f44.google.com with SMTP id j7so8130750qaq.17
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 11:23:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ILuwmU8ak1eJPYI2mkcfOrc0bdafP4uvZTLR8x8dDm4=;
        b=UkiYE/TOjyblGbrdpzWkInjb0QoIeIVO/4QE+3gltY9RIy2RRnijWJhrCGSFPFy33V
         ugZEkKCPEmEX1R5hpm5Vx9I9OZek05RN11SqZB3TjUHZiUClKVWhZFjpd5mCZN45wban
         USXNc8WVK2cJOgyfTGFd1154qnJ34oqpfX0Fsmg6djNolhJ9fUxqi06YNXGViofj0965
         mzcisyPP0rIrCIudqNN8pYBp6ZAjAiQM+LyapiMiRkg6W/grqpy+ZT7y23xQdGshmVLk
         mEc/PTP97ZM0tN85kThEDQlFhSMefB4Z52Tw1i+e4cHWX7pA9D9+ko6Lege6ODrXM2hE
         yLRw==
X-Gm-Message-State: ALoCoQk0HGYSTr31hCDrDp8QfcvNJ+oRg7PhtYuDRBlYkqufHKYnm+d9hDUQjU8Tcc1Xh9QfrMMC
X-Received: by 10.224.79.13 with SMTP id n13mr69460117qak.79.1409768615563;
 Wed, 03 Sep 2014 11:23:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Wed, 3 Sep 2014 11:23:15 -0700 (PDT)
In-Reply-To: <54075AD6.8090803@redhat.com>
References: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com>
 <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com> <54075AD6.8090803@redhat.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 3 Sep 2014 11:23:15 -0700
Message-ID: <CAPh_B=aCY6QaE302+cuxhrz5MJC2AJkedM5PQFQxBKo0Yj3rVQ@mail.gmail.com>
Subject: Re: Ask something about spark
To: Matthew Farrellee <matt@redhat.com>
Cc: Sanghoon Lee <phoenixlee1@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc80168c6be205022d55c2
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc80168c6be205022d55c2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I am not sure if I can just go ahead and update the website with a creative
common license.

IIRC, ASF websites are also Apache 2.0 license. Might need somebody from
legal to chime in.


On Wed, Sep 3, 2014 at 11:15 AM, Matthew Farrellee <matt@redhat.com> wrote:

> reynold,
>
> would you folks be willing to put some creative commons license
> information on the site and its content?
>
> best,
>
>
> matt
>
>
> On 09/02/2014 06:32 PM, Reynold Xin wrote:
>
>> I think in general that is fine. It would be great if your slides come
>> with
>> proper attribution.
>>
>>
>> On Tue, Sep 2, 2014 at 3:31 PM, Sanghoon Lee <phoenixlee1@gmail.com>
>> wrote:
>>
>>  Hi, I am phoenixlee and a Spark programmer in Korea.
>>>
>>> And be a good chance this time, it tries to teach college students and
>>> office workers to Spark.
>>> This course will be done with the support of the government. Can I use
>>> the
>>> data(pictures, samples, etc.) in the spark homepage for this course? Of
>>> course, I will put the comments in thanks and webpage URL. It would be =
a
>>> good opportunity, even though the findings were that there is no teachi=
ng
>>> materials "Spark" and education (or community) still in Korea.
>>>
>>> Thanks.
>>> =E1=90=A7
>>>
>>>
>>
>

--047d7bdc80168c6be205022d55c2--

From dev-return-9272-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:26:03 2014
Return-Path: <dev-return-9272-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31B8011DEE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:26:03 +0000 (UTC)
Received: (qmail 59929 invoked by uid 500); 3 Sep 2014 18:26:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59863 invoked by uid 500); 3 Sep 2014 18:26:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59850 invoked by uid 99); 3 Sep 2014 18:26:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:26:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.220.53 as permitted sender)
Received: from [209.85.220.53] (HELO mail-pa0-f53.google.com) (209.85.220.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:25:35 +0000
Received: by mail-pa0-f53.google.com with SMTP id fa1so17668678pad.26
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 11:25:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=lyr8uaKT3p5ZInDlHirzfYgYiIflmquQM7e1V69GXcA=;
        b=jtCouOhB+VXpgiU554h7wjTtmYlQkHerDHCuOe5iD/hDb9NmVftwtWWJKNKkRdiyR7
         mI58MoE/iR3nHMTwG8Owik7c52znWfb/QZUMG6hlxbdcTa9fgQeV7NXMUkjIw6kKF/gg
         DPTwemVBVd6oAZoM7YiDqdQqRQNvAeoji/nozX6LWRUtN5YF0eSoKXQ/koAo/gGiUyPb
         OYkS/A4ua4rH4KiTDOxujoUohRAi/fj4IuhB+oSeN5IA2f+OW8oTM9sjhk0aWMdKVbjM
         P4Pc7q8Aqk+7+kqangPXkhmu9WH9N84FxZoblTHmPqUDq7lYrY9X/hIDvEPfH2BdRdEk
         j2eQ==
X-Received: by 10.66.141.142 with SMTP id ro14mr1352617pab.104.1409768728949;
        Wed, 03 Sep 2014 11:25:28 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id rg9sm1553951pdb.39.2014.09.03.11.25.28
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Wed, 03 Sep 2014 11:25:28 -0700 (PDT)
Date: Wed, 3 Sep 2014 11:25:27 -0700
From: Josh Rosen <rosenville@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Marcelo
 Vanzin <vanzin@cloudera.com>
Message-ID: <etPan.54075d17.643c9869.5a82@joshs-mbp>
In-Reply-To: <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54075d17_66334873_5a82"
X-Virus-Checked: Checked by ClamAV on apache.org

--54075d17_66334873_5a82
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

+1. =C2=A0Tested on Windows and EC2. =C2=A0Confirmed that the EC2 pvm->hv=
m switch fixed the SPARK-3358 regression.


On September 3, 2014 at 10:33:45 AM, Marcelo Vanzin (vanzin=40cloudera.co=
m) wrote:

+1 (non-binding) =20

- checked checksums of a few packages =20
- ran few jobs against yarn client/cluster using hadoop2.3 package =20
- played with spark-shell in yarn-client mode =20

On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell=40gmail.com> w=
rote: =20
> Please vote on releasing the following candidate as Apache Spark versio=
n 1.1.0=21 =20
> =20
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd): =20
> https://git-wip-us.apache.org/repos/asf=3Fp=3Dspark.git;a=3Dcommit;h=3D=
2f9b2bd7844ee8393dc9c319f4fefedf95f5e460 =20
> =20
> The release files, including signatures, digests, etc. can be found at:=
 =20
> http://people.apache.org/=7Epwendell/spark-1.1.0-rc4/ =20
> =20
> Release artifacts are signed with the following key: =20
> https://people.apache.org/keys/committer/pwendell.asc =20
> =20
> The staging repository for this release can be found at: =20
> https://repository.apache.org/content/repositories/orgapachespark-1031/=
 =20
> =20
> The documentation corresponding to this release can be found at: =20
> http://people.apache.org/=7Epwendell/spark-1.1.0-rc4-docs/ =20
> =20
> Please vote on releasing this package as Apache Spark 1.1.0=21 =20
> =20
> The vote is open until Saturday, September 06, at 08:30 UTC and passes =
if =20
> a majority of at least 3 +1 PMC votes are cast. =20
> =20
> =5B =5D +1 Release this package as Apache Spark 1.1.0 =20
> =5B =5D -1 Do not release this package because ... =20
> =20
> To learn more about Apache Spark, please see =20
> http://spark.apache.org/ =20
> =20
> =3D=3D Regressions fixed since RC3 =3D=3D =20
> SPARK-3332 - Issue with tagging in EC2 scripts =20
> SPARK-3358 - Issue with regression for m3.XX instances =20
> =20
> =3D=3D What justifies a -1 vote for this release=3F =3D=3D =20
> This vote is happening very late into the QA period compared with =20
> previous votes, so -1 votes should only occur for significant =20
> regressions from 1.0.2. Bugs already present in 1.0.X will not block =20
> this release. =20
> =20
> =3D=3D What default changes should I be aware of=3F =3D=3D =20
> 1. The default value of =22spark.io.compression.codec=22 is now =22snap=
py=22 =20
> --> Old behavior can be restored by switching to =22lzf=22 =20
> =20
> 2. PySpark now performs external spilling during aggregations. =20
> --> Old behavior can be restored by setting =22spark.shuffle.spill=22 t=
o =22false=22. =20
> =20
> 3. PySpark uses a new heuristic for determining the parallelism of =20
> shuffle operations. =20
> --> Old behavior can be restored by setting =20
> =22spark.default.parallelism=22 to the number of cores in the cluster. =
=20
> =20
> --------------------------------------------------------------------- =20
> To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> =20



-- =20
Marcelo =20

--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--54075d17_66334873_5a82--


From dev-return-9273-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:26:27 2014
Return-Path: <dev-return-9273-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8DED811DF6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:26:27 +0000 (UTC)
Received: (qmail 62783 invoked by uid 500); 3 Sep 2014 18:26:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62728 invoked by uid 500); 3 Sep 2014 18:26:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62604 invoked by uid 99); 3 Sep 2014 18:26:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:26:08 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:25:41 +0000
Received: from int-mx11.intmail.prod.int.phx2.redhat.com (int-mx11.intmail.prod.int.phx2.redhat.com [10.5.11.24])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s83IPQ9m030279
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Wed, 3 Sep 2014 14:25:26 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx11.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s83IPPYv005421;
	Wed, 3 Sep 2014 14:25:25 -0400
Message-ID: <54075D15.6060901@redhat.com>
Date: Wed, 03 Sep 2014 14:25:25 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: Reynold Xin <rxin@databricks.com>
CC: Sanghoon Lee <phoenixlee1@gmail.com>, dev <dev@spark.apache.org>
Subject: Re: Ask something about spark
References: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com> <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com> <54075AD6.8090803@redhat.com> <CAPh_B=aCY6QaE302+cuxhrz5MJC2AJkedM5PQFQxBKo0Yj3rVQ@mail.gmail.com>
In-Reply-To: <CAPh_B=aCY6QaE302+cuxhrz5MJC2AJkedM5PQFQxBKo0Yj3rVQ@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.24
X-Virus-Checked: Checked by ClamAV on apache.org

CC or Apache, it'd be helpful to have it listed in the footer of pages

best,


matt

On 09/03/2014 02:23 PM, Reynold Xin wrote:
> I am not sure if I can just go ahead and update the website with a
> creative common license.
>
> IIRC, ASF websites are also Apache 2.0 license. Might need somebody from
> legal to chime in.
>
>
> On Wed, Sep 3, 2014 at 11:15 AM, Matthew Farrellee <matt@redhat.com
> <mailto:matt@redhat.com>> wrote:
>
>     reynold,
>
>     would you folks be willing to put some creative commons license
>     information on the site and its content?
>
>     best,
>
>
>     matt
>
>
>     On 09/02/2014 06:32 PM, Reynold Xin wrote:
>
>         I think in general that is fine. It would be great if your
>         slides come with
>         proper attribution.
>
>
>         On Tue, Sep 2, 2014 at 3:31 PM, Sanghoon Lee
>         <phoenixlee1@gmail.com <mailto:phoenixlee1@gmail.com>> wrote:
>
>             Hi, I am phoenixlee and a Spark programmer in Korea.
>
>             And be a good chance this time, it tries to teach college
>             students and
>             office workers to Spark.
>             This course will be done with the support of the government.
>             Can I use the
>             data(pictures, samples, etc.) in the spark homepage for this
>             course? Of
>             course, I will put the comments in thanks and webpage URL.
>             It would be a
>             good opportunity, even though the findings were that there
>             is no teaching
>             materials "Spark" and education (or community) still in Korea.
>
>             Thanks.
>             
>
>
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9274-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:51:00 2014
Return-Path: <dev-return-9274-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C80911F24
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:51:00 +0000 (UTC)
Received: (qmail 52251 invoked by uid 500); 3 Sep 2014 18:50:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52185 invoked by uid 500); 3 Sep 2014 18:50:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52154 invoked by uid 99); 3 Sep 2014 18:50:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:50:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of david.lw.hall@gmail.com designates 209.85.223.170 as permitted sender)
Received: from [209.85.223.170] (HELO mail-ie0-f170.google.com) (209.85.223.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:50:52 +0000
Received: by mail-ie0-f170.google.com with SMTP id rl12so10266816iec.15
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 11:50:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=+ULy6cACh9c7ohQlipLmuEBSyP6BPJMRLyPHotYFMYU=;
        b=bIl0a2+0sA6AQECgvBjxGRy4OJBKDRrx65CEGquXjmUTsNb3q17kIUUY1MyhJ4EuSB
         y7SoA9+MYwIli3BfjnEf4eSbjNgC+WFeQT7pOO11GJmwYI5wJq9EwAm3e/aTDD8bzW/h
         X+kQhWRFGpUhFEroejdokjZ/6rwwlfGuN0VZRmCx140XeAjhVdhev4A6k+NZfyTe4Sjj
         oKKj7ohT4WxR3jqxort+3N5Tp9+KVwsWkaHKdZgqfYKW/Rz0GT/cI8IKnIv4/aR8rF/W
         QxupWUPDqZzY2OvGpdgtEAGR1BSmi1B4C7ZxFRFDbhvpbaIBQ+fpC2/+NNoSlkPOqs41
         q//g==
MIME-Version: 1.0
X-Received: by 10.50.111.80 with SMTP id ig16mr492601igb.43.1409770231409;
 Wed, 03 Sep 2014 11:50:31 -0700 (PDT)
Sender: david.lw.hall@gmail.com
Received: by 10.107.36.78 with HTTP; Wed, 3 Sep 2014 11:50:31 -0700 (PDT)
In-Reply-To: <CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
Date: Wed, 3 Sep 2014 11:50:31 -0700
X-Google-Sender-Auth: Z2EyyrwPC28Bt0bTtqQKaX4LwyM
Message-ID: <CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: David Hall <dlwh@cs.berkeley.edu>
To: RJ Nowling <rnowling@gmail.com>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e014944a4dbb29405022db572
X-Virus-Checked: Checked by ClamAV on apache.org

--089e014944a4dbb29405022db572
Content-Type: text/plain; charset=UTF-8

In general, in Breeze we allocate separate work arrays for each call to
lapack, so it should be fine. In general concurrent modification isn't
thread safe of course, but things that "ought" to be thread safe really
should be.


On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:

> No, it's not in all cases.   Since Breeze uses lapack under the hood,
> changes to memory between different threads is bad.
>
> There's actually a potential bug in the KMeans code where it uses +=
> instead of +.
>
>
> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <alexander.ulanov@hp.com
> >
> wrote:
>
> > Hi,
> >
> > Is breeze library called thread safe from Spark mllib code in case when
> > native libs for blas and lapack are used? Might it be an issue when
> running
> > Spark locally?
> >
> > Best regards, Alexander
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314
>

--089e014944a4dbb29405022db572--

From dev-return-9275-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:58:46 2014
Return-Path: <dev-return-9275-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8CFF111F8E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:58:46 +0000 (UTC)
Received: (qmail 87405 invoked by uid 500); 3 Sep 2014 18:58:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87340 invoked by uid 500); 3 Sep 2014 18:58:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87327 invoked by uid 99); 3 Sep 2014 18:58:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:58:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rnowling@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:58:40 +0000
Received: by mail-wi0-f173.google.com with SMTP id cc10so1520284wib.0
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 11:58:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=aYthFErHNs+Tou57ZMCntcn8LlP9UHYTiH+eK6dArvs=;
        b=K5H9HnRidsAaZOqrKqkNpgWF0brdu0SXMFhgIrql+GIKRWnIK6qq/E9pLER7S9Pt/Q
         C0ewV9O34d0x1ep3Pl6AInoEM/YuQWNuDXMt0GMJzUT3AG9WzkU08zXKkiX6XdVJco/T
         bRf59/KEmr4w3dJsHH8U7mv7TZ0Fcf8yb2uI2ApnnxkQKPxI3G3pEuYV4h9feQOBk2Zw
         eV6LpcQg6usP60cUe7fxjPpDAFiY3przDxiplEX10m6hjGsb0QrAWHaFN0j/7dhK1HF5
         r/foYUSUl6FKKtTkyJ3xuCpQLgFmI9eigHc88diOOQBkTNdok7XJ7bG7s99CrX4RIbAD
         rn/g==
MIME-Version: 1.0
X-Received: by 10.180.38.114 with SMTP id f18mr667544wik.24.1409770699450;
 Wed, 03 Sep 2014 11:58:19 -0700 (PDT)
Received: by 10.194.14.137 with HTTP; Wed, 3 Sep 2014 11:58:19 -0700 (PDT)
In-Reply-To: <CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
Date: Wed, 3 Sep 2014 14:58:19 -0400
Message-ID: <CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: RJ Nowling <rnowling@gmail.com>
To: David Hall <dlwh@cs.berkeley.edu>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f6439c6c16f6905022dd189
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f6439c6c16f6905022dd189
Content-Type: text/plain; charset=UTF-8

David,

Can you confirm that += is not thread safe but + is?  I'm assuming +
allocates a new object for the write, while += doesn't.

Thanks!
RJ


On Wed, Sep 3, 2014 at 2:50 PM, David Hall <dlwh@cs.berkeley.edu> wrote:

> In general, in Breeze we allocate separate work arrays for each call to
> lapack, so it should be fine. In general concurrent modification isn't
> thread safe of course, but things that "ought" to be thread safe really
> should be.
>
>
> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>
>> No, it's not in all cases.   Since Breeze uses lapack under the hood,
>> changes to memory between different threads is bad.
>>
>> There's actually a potential bug in the KMeans code where it uses +=
>> instead of +.
>>
>>
>> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com>
>> wrote:
>>
>> > Hi,
>> >
>> > Is breeze library called thread safe from Spark mllib code in case when
>> > native libs for blas and lapack are used? Might it be an issue when
>> running
>> > Spark locally?
>> >
>> > Best regards, Alexander
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>
>>
>> --
>> em rnowling@gmail.com
>> c 954.496.2314
>>
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--e89a8f6439c6c16f6905022dd189--

From dev-return-9276-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 18:59:03 2014
Return-Path: <dev-return-9276-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DACFF11F8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 18:59:03 +0000 (UTC)
Received: (qmail 88581 invoked by uid 500); 3 Sep 2014 18:59:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88512 invoked by uid 500); 3 Sep 2014 18:59:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88499 invoked by uid 99); 3 Sep 2014 18:59:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:59:02 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.176 as permitted sender)
Received: from [209.85.220.176] (HELO mail-vc0-f176.google.com) (209.85.220.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 18:58:58 +0000
Received: by mail-vc0-f176.google.com with SMTP id ik5so9386173vcb.35
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 11:58:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=Qy5NYBlMV0dZBp3h8GE+SoTMbPKW3WMBiNufZ+eWdOQ=;
        b=QhdsYxHI3ilRnBI4j79D+VNvHfGLtH6/g1nO9UaCGm3IquWJ4A8gTo98ozM2dKZvFS
         13dKBPcj8QEJIMR9mPlUGmk04zZr84YVR761Q8qH36qDgo/vLUZWYIa+hC4AycP4B2nN
         wMP3zuuPBWrWdSTMgdML8g4kwI3o5mCyDlF2rDpnRMv0H/P8/GYXMUf/9INYQauTrEdw
         wTtICWN2BBepwrQUaNpS8zrucYt55SadVF0KFq5j68nIUqtcmEZK3RBMJtq2EsYFEQck
         rN814O8ysngNVV4KzK1jXg3kJDAhUIxwEXDXWgws6ejPfMBcj9cJlMpHTa0hkBgvLaK9
         meig==
X-Received: by 10.52.245.66 with SMTP id xm2mr6697310vdc.36.1409770718027;
 Wed, 03 Sep 2014 11:58:38 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.52.32.225 with HTTP; Wed, 3 Sep 2014 11:58:17 -0700 (PDT)
In-Reply-To: <CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com> <CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
 <CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Wed, 3 Sep 2014 11:58:17 -0700
Message-ID: <CABjXkq7WSdx32LW7UvOLOW0m53UH-bgHQNOhUN4BnUDOhvCmmQ@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
To: David Hall <dlwh@cs.berkeley.edu>
Cc: RJ Nowling <rnowling@gmail.com>, "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c257aadce62505022dd25a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c257aadce62505022dd25a
Content-Type: text/plain; charset=UTF-8

Additionally, at the higher level, MLlib allocates separate Breeze
Vectors/Matrices on a Per-executor basis. The only place I can think of
where data structures might be over-written concurrently is in a
.aggregate() call, and these calls happen sequentially.

RJ - Do you have a JIRA reference for that bug?

Thanks!


On Wed, Sep 3, 2014 at 11:50 AM, David Hall <dlwh@cs.berkeley.edu> wrote:

> In general, in Breeze we allocate separate work arrays for each call to
> lapack, so it should be fine. In general concurrent modification isn't
> thread safe of course, but things that "ought" to be thread safe really
> should be.
>
>
> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>
> > No, it's not in all cases.   Since Breeze uses lapack under the hood,
> > changes to memory between different threads is bad.
> >
> > There's actually a potential bug in the KMeans code where it uses +=
> > instead of +.
> >
> >
> > On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
> alexander.ulanov@hp.com
> > >
> > wrote:
> >
> > > Hi,
> > >
> > > Is breeze library called thread safe from Spark mllib code in case when
> > > native libs for blas and lapack are used? Might it be an issue when
> > running
> > > Spark locally?
> > >
> > > Best regards, Alexander
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
> >
> > --
> > em rnowling@gmail.com
> > c 954.496.2314
> >
>

--001a11c257aadce62505022dd25a--

From dev-return-9277-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:02:32 2014
Return-Path: <dev-return-9277-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D6AB811FB1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:02:32 +0000 (UTC)
Received: (qmail 97230 invoked by uid 500); 3 Sep 2014 19:02:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97154 invoked by uid 500); 3 Sep 2014 19:02:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97142 invoked by uid 99); 3 Sep 2014 19:02:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:02:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rnowling@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:02:06 +0000
Received: by mail-wi0-f173.google.com with SMTP id cc10so1526739wib.0
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 12:02:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=0qCOzRfg6WjEK3cfMSEmDRgmJOXTZ1UzY4YW5yg2UJI=;
        b=lTEsOmU4yr7d5GuxtGGZPRi1KuYgWYdZ5C8hGsgMg6VY6/KBUVx+fDR8AWBOZKnZRP
         PVgbA1IV6KXocwXTef+85gKE+E9HRHXzPl3Sb72kd6Rvwx1Q3RYzGiaVXRfBN6qWSfFX
         1jyTcCwqo+qscspii1SlPtkcFiVobdgfDJN6vn2ZYA6LujhndnYMivFtZMVEE1Q4cFue
         h2/SsRF1Mnnzej0o30NbPBPnQGeuzJTLbXHO7MIfliVcGayft+MpTbXLTPXIuao3kEhi
         AscQIzJWY7T5CIB9PdH9yE8eh+9ggUsx/EMd1EjjZSU7BgmluP4OPWHv5M81zUar/+vS
         9dCA==
MIME-Version: 1.0
X-Received: by 10.194.170.227 with SMTP id ap3mr49471161wjc.30.1409770925469;
 Wed, 03 Sep 2014 12:02:05 -0700 (PDT)
Received: by 10.194.14.137 with HTTP; Wed, 3 Sep 2014 12:02:05 -0700 (PDT)
In-Reply-To: <CABjXkq7WSdx32LW7UvOLOW0m53UH-bgHQNOhUN4BnUDOhvCmmQ@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CABjXkq7WSdx32LW7UvOLOW0m53UH-bgHQNOhUN4BnUDOhvCmmQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 15:02:05 -0400
Message-ID: <CADtDQQ+8fXrO8fVpLg7oOKEOgKtOOJWdcCUbtR92BvFVUntbqg@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: RJ Nowling <rnowling@gmail.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
Cc: David Hall <dlwh@cs.berkeley.edu>, "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122e9223a3a6a05022ddfd7
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122e9223a3a6a05022ddfd7
Content-Type: text/plain; charset=UTF-8

Never filed a JIRA -- I actually forgot about it.  Let me file one now.



On Wed, Sep 3, 2014 at 2:58 PM, Evan R. Sparks <evan.sparks@gmail.com>
wrote:

> Additionally, at the higher level, MLlib allocates separate Breeze
> Vectors/Matrices on a Per-executor basis. The only place I can think of
> where data structures might be over-written concurrently is in a
> .aggregate() call, and these calls happen sequentially.
>
> RJ - Do you have a JIRA reference for that bug?
>
> Thanks!
>
>
> On Wed, Sep 3, 2014 at 11:50 AM, David Hall <dlwh@cs.berkeley.edu> wrote:
>
>> In general, in Breeze we allocate separate work arrays for each call to
>> lapack, so it should be fine. In general concurrent modification isn't
>> thread safe of course, but things that "ought" to be thread safe really
>> should be.
>>
>>
>> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>
>> > No, it's not in all cases.   Since Breeze uses lapack under the hood,
>> > changes to memory between different threads is bad.
>> >
>> > There's actually a potential bug in the KMeans code where it uses +=
>> > instead of +.
>> >
>> >
>> > On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com
>> > >
>> > wrote:
>> >
>> > > Hi,
>> > >
>> > > Is breeze library called thread safe from Spark mllib code in case
>> when
>> > > native libs for blas and lapack are used? Might it be an issue when
>> > running
>> > > Spark locally?
>> > >
>> > > Best regards, Alexander
>> > > ---------------------------------------------------------------------
>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > For additional commands, e-mail: dev-help@spark.apache.org
>> > >
>> > >
>> >
>> >
>> > --
>> > em rnowling@gmail.com
>> > c 954.496.2314
>> >
>>
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--089e0122e9223a3a6a05022ddfd7--

From dev-return-9278-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:02:59 2014
Return-Path: <dev-return-9278-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA74D11FB7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:02:59 +0000 (UTC)
Received: (qmail 1472 invoked by uid 500); 3 Sep 2014 19:02:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1406 invoked by uid 500); 3 Sep 2014 19:02:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1394 invoked by uid 99); 3 Sep 2014 19:02:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:02:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of david.lw.hall@gmail.com designates 209.85.213.179 as permitted sender)
Received: from [209.85.213.179] (HELO mail-ig0-f179.google.com) (209.85.213.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:02:54 +0000
Received: by mail-ig0-f179.google.com with SMTP id r2so9666145igi.6
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 12:02:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=NL6xe66fDkgHJx9QBCDrzwL93dfg8ppdE/TCOS0015M=;
        b=IklUyOsvajQV1x2Q0C+W5bjzzo5r45VbO0WKtzdsJ5erilk3/dK2/m20OV40bXDi8j
         xYCjxJpkxWpLWYPxZKcxaA7Kaep1aEa3Cg0PFSKdCF5XRtFPcmvRr6l5dmYtSy8VqWvW
         p/Ek3bqo8UnIO1qdowxTtNv5temuR6IDOxLmbJSn7PUcff2VcQmy21BsQ7wpfSxrBuBd
         YKmvjzYC4PyaKWZXhGoTrgEIK7/W5Cun0j4STRkAhRFZ/UX6wJudZgtmioEOi5LfWt8B
         tfmH7bVXYi9Hb7nPhAF68OFRRfnhVj8+VcvzKUg9Qy6UU+sm2u1eWAdk93JhWnrM3smF
         K36g==
MIME-Version: 1.0
X-Received: by 10.50.111.80 with SMTP id ig16mr593979igb.43.1409770953478;
 Wed, 03 Sep 2014 12:02:33 -0700 (PDT)
Sender: david.lw.hall@gmail.com
Received: by 10.107.36.78 with HTTP; Wed, 3 Sep 2014 12:02:33 -0700 (PDT)
In-Reply-To: <CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
Date: Wed, 3 Sep 2014 12:02:33 -0700
X-Google-Sender-Auth: 19wx0RxwEoWyJe1VOoT8geREjSc
Message-ID: <CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: David Hall <dlwh@cs.berkeley.edu>
To: RJ Nowling <rnowling@gmail.com>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e014944a4e5f2e005022de0b2
X-Virus-Checked: Checked by ClamAV on apache.org

--089e014944a4e5f2e005022de0b2
Content-Type: text/plain; charset=UTF-8

mutating operations are not thread safe. Operations that don't mutate
should be thread safe. I can't speak to what Evan said, but I would guess
that the way they're using += should be safe.


On Wed, Sep 3, 2014 at 11:58 AM, RJ Nowling <rnowling@gmail.com> wrote:

> David,
>
> Can you confirm that += is not thread safe but + is?  I'm assuming +
> allocates a new object for the write, while += doesn't.
>
> Thanks!
> RJ
>
>
> On Wed, Sep 3, 2014 at 2:50 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>
>> In general, in Breeze we allocate separate work arrays for each call to
>> lapack, so it should be fine. In general concurrent modification isn't
>> thread safe of course, but things that "ought" to be thread safe really
>> should be.
>>
>>
>> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>
>>> No, it's not in all cases.   Since Breeze uses lapack under the hood,
>>> changes to memory between different threads is bad.
>>>
>>> There's actually a potential bug in the KMeans code where it uses +=
>>> instead of +.
>>>
>>>
>>> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com>
>>> wrote:
>>>
>>> > Hi,
>>> >
>>> > Is breeze library called thread safe from Spark mllib code in case when
>>> > native libs for blas and lapack are used? Might it be an issue when
>>> running
>>> > Spark locally?
>>> >
>>> > Best regards, Alexander
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>> >
>>>
>>>
>>> --
>>> em rnowling@gmail.com
>>> c 954.496.2314
>>>
>>
>>
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314
>

--089e014944a4e5f2e005022de0b2--

From dev-return-9279-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:07:44 2014
Return-Path: <dev-return-9279-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CB98211FDA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:07:44 +0000 (UTC)
Received: (qmail 9792 invoked by uid 500); 3 Sep 2014 19:07:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9725 invoked by uid 500); 3 Sep 2014 19:07:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9713 invoked by uid 99); 3 Sep 2014 19:07:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:07:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rnowling@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:07:39 +0000
Received: by mail-wg0-f51.google.com with SMTP id l18so9010629wgh.22
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 12:07:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=wH/bTMwLSXLfDx0ExxCTi2luBdzFbTlOOG3h0ux+zxw=;
        b=fOWY6JyYdrXOYkNgmy7REl+sssRLzPgGRi47WvgKGaaBhsRiYiVDwerHTKUpx2SvsQ
         k6jVEX+zCA/2BDmQesy3KpXxaJZszh6/8I3LFZS4WnhSUpCGqgVngQomiXMFJzoGLMC6
         wqyyCxJP0Igl5nvdVC0PjqVsjKzougHD1+/cyyNUbINr9Mov2oCOHI9nuOoqfbdGexFs
         M8iuzrx/0tQmqr0cuvhQtqjnvMKLi7tHJopI0PITDfxB2Mqi5MkmTBfy1dg5MBQVRR3K
         5yh17Liy/p/T/qp0utoxi9fHeGW+aLIxZk/+dWmuNviaJeBKtbkYQRxxw+huItQqzy3F
         /AcA==
MIME-Version: 1.0
X-Received: by 10.180.207.105 with SMTP id lv9mr513260wic.23.1409771238418;
 Wed, 03 Sep 2014 12:07:18 -0700 (PDT)
Received: by 10.194.14.137 with HTTP; Wed, 3 Sep 2014 12:07:18 -0700 (PDT)
In-Reply-To: <CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
	<CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
Date: Wed, 3 Sep 2014 15:07:18 -0400
Message-ID: <CADtDQQJd5n_9JN-nB+JQTRgND3UHe9dPKmp0Mm_QQNqh9jhM_w@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: RJ Nowling <rnowling@gmail.com>
To: David Hall <dlwh@cs.berkeley.edu>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3f956e16f9105022df19e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f956e16f9105022df19e
Content-Type: text/plain; charset=UTF-8

Here's the JIRA:

https://issues.apache.org/jira/browse/SPARK-3384

Even if the current implementation uses += in a thread safe manner, it can
be easy to make the mistake of accidentally using += in a parallelized
context.  I suggest changing all instances of += to +.

I would encourage others to reproduce and validate this issue, though.


On Wed, Sep 3, 2014 at 3:02 PM, David Hall <dlwh@cs.berkeley.edu> wrote:

> mutating operations are not thread safe. Operations that don't mutate
> should be thread safe. I can't speak to what Evan said, but I would guess
> that the way they're using += should be safe.
>
>
> On Wed, Sep 3, 2014 at 11:58 AM, RJ Nowling <rnowling@gmail.com> wrote:
>
>> David,
>>
>> Can you confirm that += is not thread safe but + is?  I'm assuming +
>> allocates a new object for the write, while += doesn't.
>>
>> Thanks!
>> RJ
>>
>>
>> On Wed, Sep 3, 2014 at 2:50 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>>
>>> In general, in Breeze we allocate separate work arrays for each call to
>>> lapack, so it should be fine. In general concurrent modification isn't
>>> thread safe of course, but things that "ought" to be thread safe really
>>> should be.
>>>
>>>
>>> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>>
>>>> No, it's not in all cases.   Since Breeze uses lapack under the hood,
>>>> changes to memory between different threads is bad.
>>>>
>>>> There's actually a potential bug in the KMeans code where it uses +=
>>>> instead of +.
>>>>
>>>>
>>>> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com>
>>>> wrote:
>>>>
>>>> > Hi,
>>>> >
>>>> > Is breeze library called thread safe from Spark mllib code in case
>>>> when
>>>> > native libs for blas and lapack are used? Might it be an issue when
>>>> running
>>>> > Spark locally?
>>>> >
>>>> > Best regards, Alexander
>>>> > ---------------------------------------------------------------------
>>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>>> >
>>>> >
>>>>
>>>>
>>>> --
>>>> em rnowling@gmail.com
>>>> c 954.496.2314
>>>>
>>>
>>>
>>
>>
>> --
>> em rnowling@gmail.com
>> c 954.496.2314
>>
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--001a11c3f956e16f9105022df19e--

From dev-return-9280-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:18:16 2014
Return-Path: <dev-return-9280-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 866EB11068
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:18:16 +0000 (UTC)
Received: (qmail 45031 invoked by uid 500); 3 Sep 2014 19:18:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44969 invoked by uid 500); 3 Sep 2014 19:18:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44957 invoked by uid 99); 3 Sep 2014 19:18:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:18:15 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:18:11 +0000
Received: by mail-ie0-f180.google.com with SMTP id rl12so9971541iec.25
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 12:17:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=YirGA0gDiU2LzeLGYuZWnXrQayux1x+32tM9/uoaQ/c=;
        b=ThQeYHBQ+45kvGCdM1oYLbyw1m5IY9TLRb8YW8UdFicqaoYtaT7kQhud1kSfn6R/+n
         pn7zeuGlhdD2ZN6RujJCZv/H4OF5EZq6twK+zSrBxA3F3OHtoOj4WV81xf0FLkjMFwmV
         AullQx+2XK78JCcZDbEJuuexegp/H1JZadw1y3fF1FGh9hEY3MIzi+41eYkoBomQIbNK
         AkaLk340Fj9auvVHlt8ynkkeXR+7vOyO0bQeYonVz92x0rU5bTblrTaU3gCrgt4PJWMY
         0K6whQMhgUaGw8Fmq3JBsKkdRTDwTAjWwTrydLa4ukEWhRXZ4Ytli0jA9aVGX8CTbm9v
         9R2Q==
MIME-Version: 1.0
X-Received: by 10.50.142.68 with SMTP id ru4mr1098365igb.18.1409771871032;
 Wed, 03 Sep 2014 12:17:51 -0700 (PDT)
Received: by 10.107.152.196 with HTTP; Wed, 3 Sep 2014 12:17:50 -0700 (PDT)
In-Reply-To: <CADtDQQJd5n_9JN-nB+JQTRgND3UHe9dPKmp0Mm_QQNqh9jhM_w@mail.gmail.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
	<CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
	<CADtDQQJd5n_9JN-nB+JQTRgND3UHe9dPKmp0Mm_QQNqh9jhM_w@mail.gmail.com>
Date: Wed, 3 Sep 2014 12:17:50 -0700
Message-ID: <CAJgQjQ81u=1dZb1M6+adSv+Zvj2DdmJLMcNjQfuW5A3oPqwnGg@mail.gmail.com>
Subject: Re: Is breeze thread safe in Spark?
From: Xiangrui Meng <mengxr@gmail.com>
To: RJ Nowling <rnowling@gmail.com>
Cc: David Hall <dlwh@cs.berkeley.edu>, "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

RJ, could you provide a code example that can re-produce the bug you
observed in local testing? Breeze's += is not thread-safe. But in a
Spark job, calls to a resultHandler is synchronized:
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/JobWaiter.scala#L52
. Let's move our discussion to the JIRA page. -Xiangrui

On Wed, Sep 3, 2014 at 12:07 PM, RJ Nowling <rnowling@gmail.com> wrote:
> Here's the JIRA:
>
> https://issues.apache.org/jira/browse/SPARK-3384
>
> Even if the current implementation uses += in a thread safe manner, it can
> be easy to make the mistake of accidentally using += in a parallelized
> context.  I suggest changing all instances of += to +.
>
> I would encourage others to reproduce and validate this issue, though.
>
>
> On Wed, Sep 3, 2014 at 3:02 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>
>> mutating operations are not thread safe. Operations that don't mutate
>> should be thread safe. I can't speak to what Evan said, but I would guess
>> that the way they're using += should be safe.
>>
>>
>> On Wed, Sep 3, 2014 at 11:58 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>
>>> David,
>>>
>>> Can you confirm that += is not thread safe but + is?  I'm assuming +
>>> allocates a new object for the write, while += doesn't.
>>>
>>> Thanks!
>>> RJ
>>>
>>>
>>> On Wed, Sep 3, 2014 at 2:50 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>>>
>>>> In general, in Breeze we allocate separate work arrays for each call to
>>>> lapack, so it should be fine. In general concurrent modification isn't
>>>> thread safe of course, but things that "ought" to be thread safe really
>>>> should be.
>>>>
>>>>
>>>> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>>>
>>>>> No, it's not in all cases.   Since Breeze uses lapack under the hood,
>>>>> changes to memory between different threads is bad.
>>>>>
>>>>> There's actually a potential bug in the KMeans code where it uses +=
>>>>> instead of +.
>>>>>
>>>>>
>>>>> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com>
>>>>> wrote:
>>>>>
>>>>> > Hi,
>>>>> >
>>>>> > Is breeze library called thread safe from Spark mllib code in case
>>>>> when
>>>>> > native libs for blas and lapack are used? Might it be an issue when
>>>>> running
>>>>> > Spark locally?
>>>>> >
>>>>> > Best regards, Alexander
>>>>> > ---------------------------------------------------------------------
>>>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>>>> >
>>>>> >
>>>>>
>>>>>
>>>>> --
>>>>> em rnowling@gmail.com
>>>>> c 954.496.2314
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> em rnowling@gmail.com
>>> c 954.496.2314
>>>
>>
>>
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9281-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:24:31 2014
Return-Path: <dev-return-9281-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DCAA6110A5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:24:31 +0000 (UTC)
Received: (qmail 65315 invoked by uid 500); 3 Sep 2014 19:24:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65250 invoked by uid 500); 3 Sep 2014 19:24:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65238 invoked by uid 99); 3 Sep 2014 19:24:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:24:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.216.47 as permitted sender)
Received: from [209.85.216.47] (HELO mail-qa0-f47.google.com) (209.85.216.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:24:04 +0000
Received: by mail-qa0-f47.google.com with SMTP id x12so8241518qac.6
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 12:24:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=JZTBwiz3nTxXK/vme9s8gI7NN81fO/eKz/0nFBLc5tY=;
        b=BfevbwupowQZvIQbv7uWXb9iF2SKDfA2mPQr5BhRV0cVbCjWHnZYEL6snQArW+t42L
         n3wAe7+nKIm/VEYnaEX4t9etHw1TCpBF1bOcgPNDUxctxkyUZnHKUBNjS2pRTR/6H6/M
         drEX3DkrjA1Zo91iSYwIKYwbBouQ4zPMnWUjVw7qH4E2d2K2f3NAwStNNvHfNQBv45XB
         Ouz6jJpk/4tLgCyHQmVQWrDii5LcyU6Tb1iFSWbSFhXHyic0Tuws3QHjtDUYz/xQFymk
         ZurS4O0J/iE/w1BnSEKjraBxuMWnBdJrYI4mXA6k0CzEheWEFyW35gNz1Eit6uqFi7xD
         m2sw==
X-Received: by 10.140.51.166 with SMTP id u35mr65430534qga.68.1409772243087;
 Wed, 03 Sep 2014 12:24:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.92.210 with HTTP; Wed, 3 Sep 2014 12:23:42 -0700 (PDT)
In-Reply-To: <etPan.54075d17.643c9869.5a82@joshs-mbp>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com> <etPan.54075d17.643c9869.5a82@joshs-mbp>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Wed, 3 Sep 2014 12:23:42 -0700
Message-ID: <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Josh Rosen <rosenville@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Marcelo Vanzin <vanzin@cloudera.com>
Content-Type: multipart/alternative; boundary=001a1135306cc37a5c05022e2d09
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135306cc37a5c05022e2d09
Content-Type: text/plain; charset=UTF-8

+1.

Tested locally on OSX 10.9, built with Hadoop 2.4.1

- Checked Datanucleus jar files
- Tested Spark SQL Thrift server and CLI under local mode and standalone
cluster against MySQL backed metastore



On Wed, Sep 3, 2014 at 11:25 AM, Josh Rosen <rosenville@gmail.com> wrote:

> +1.  Tested on Windows and EC2.  Confirmed that the EC2 pvm->hvm switch
> fixed the SPARK-3358 regression.
>
>
> On September 3, 2014 at 10:33:45 AM, Marcelo Vanzin (vanzin@cloudera.com)
> wrote:
>
> +1 (non-binding)
>
> - checked checksums of a few packages
> - ran few jobs against yarn client/cluster using hadoop2.3 package
> - played with spark-shell in yarn-client mode
>
> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Please vote on releasing the following candidate as Apache Spark version
> 1.1.0!
> >
> > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> >
> > The release files, including signatures, digests, etc. can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-1031/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> >
> > Please vote on releasing this package as Apache Spark 1.1.0!
> >
> > The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> > a majority of at least 3 +1 PMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 1.1.0
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.apache.org/
> >
> > == Regressions fixed since RC3 ==
> > SPARK-3332 - Issue with tagging in EC2 scripts
> > SPARK-3358 - Issue with regression for m3.XX instances
> >
> > == What justifies a -1 vote for this release? ==
> > This vote is happening very late into the QA period compared with
> > previous votes, so -1 votes should only occur for significant
> > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > this release.
> >
> > == What default changes should I be aware of? ==
> > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > --> Old behavior can be restored by switching to "lzf"
> >
> > 2. PySpark now performs external spilling during aggregations.
> > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> "false".
> >
> > 3. PySpark uses a new heuristic for determining the parallelism of
> > shuffle operations.
> > --> Old behavior can be restored by setting
> > "spark.default.parallelism" to the number of cores in the cluster.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1135306cc37a5c05022e2d09--

From dev-return-9282-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 19:32:42 2014
Return-Path: <dev-return-9282-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9CDFF110ED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 19:32:42 +0000 (UTC)
Received: (qmail 87402 invoked by uid 500); 3 Sep 2014 19:32:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87337 invoked by uid 500); 3 Sep 2014 19:32:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87326 invoked by uid 99); 3 Sep 2014 19:32:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:32:41 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.55] (HELO g4t3427.houston.hp.com) (15.201.208.55)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 19:32:15 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3427.houston.hp.com (Postfix) with ESMTPS id D5F4A22B;
	Wed,  3 Sep 2014 19:32:12 +0000 (UTC)
Received: from G4W6305.americas.hpqcorp.net (16.210.26.230) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Wed, 3 Sep 2014 19:30:55 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.222]) by
 G4W6305.americas.hpqcorp.net ([16.210.26.230]) with mapi id 14.03.0169.001;
 Wed, 3 Sep 2014 19:30:55 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: Xiangrui Meng <mengxr@gmail.com>
CC: RJ Nowling <rnowling@gmail.com>, David Hall <dlwh@cs.berkeley.edu>,
	"<dev@spark.apache.org>" <dev@spark.apache.org>
Subject: Re: Is breeze thread safe in Spark?
Thread-Topic: Is breeze thread safe in Spark?
Thread-Index: Ac/HnEHIpnke8IkPRvauFqDTM2ZjuAAAgQ2AAAJqZoAAAEW8gAAAJdqAAAAqeAAAAF4tAAAAdPqL
Date: Wed, 3 Sep 2014 19:30:54 +0000
Message-ID: <6F306B65-1C09-45F6-A6E2-10876C7A3403@hp.com>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
	<CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
	<CADtDQQJd5n_9JN-nB+JQTRgND3UHe9dPKmp0Mm_QQNqh9jhM_w@mail.gmail.com>,<CAJgQjQ81u=1dZb1M6+adSv+Zvj2DdmJLMcNjQfuW5A3oPqwnGg@mail.gmail.com>
In-Reply-To: <CAJgQjQ81u=1dZb1M6+adSv+Zvj2DdmJLMcNjQfuW5A3oPqwnGg@mail.gmail.com>
Accept-Language: en-US
Content-Language: ru-RU
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
Content-Type: text/plain; charset="koi8-r"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

What about the allocation of a new breeze vector? Can it happen unsafe with=
in Spark (in several threads)?

Best regards, Alexander

03.09.2014, =D7 23:17, "Xiangrui Meng" <mengxr@gmail.com> =CE=C1=D0=C9=D3=
=C1=CC(=C1):

> RJ, could you provide a code example that can re-produce the bug you
> observed in local testing? Breeze's +=3D is not thread-safe. But in a
> Spark job, calls to a resultHandler is synchronized:
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apach=
e/spark/scheduler/JobWaiter.scala#L52
> . Let's move our discussion to the JIRA page. -Xiangrui
>=20
> On Wed, Sep 3, 2014 at 12:07 PM, RJ Nowling <rnowling@gmail.com> wrote:
>> Here's the JIRA:
>>=20
>> https://issues.apache.org/jira/browse/SPARK-3384
>>=20
>> Even if the current implementation uses +=3D in a thread safe manner, it=
 can
>> be easy to make the mistake of accidentally using +=3D in a parallelized
>> context.  I suggest changing all instances of +=3D to +.
>>=20
>> I would encourage others to reproduce and validate this issue, though.
>>=20
>>=20
>> On Wed, Sep 3, 2014 at 3:02 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>>=20
>>> mutating operations are not thread safe. Operations that don't mutate
>>> should be thread safe. I can't speak to what Evan said, but I would gue=
ss
>>> that the way they're using +=3D should be safe.
>>>=20
>>>=20
>>> On Wed, Sep 3, 2014 at 11:58 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>>=20
>>>> David,
>>>>=20
>>>> Can you confirm that +=3D is not thread safe but + is?  I'm assuming +
>>>> allocates a new object for the write, while +=3D doesn't.
>>>>=20
>>>> Thanks!
>>>> RJ
>>>>=20
>>>>=20
>>>> On Wed, Sep 3, 2014 at 2:50 PM, David Hall <dlwh@cs.berkeley.edu> wrot=
e:
>>>>=20
>>>>> In general, in Breeze we allocate separate work arrays for each call =
to
>>>>> lapack, so it should be fine. In general concurrent modification isn'=
t
>>>>> thread safe of course, but things that "ought" to be thread safe real=
ly
>>>>> should be.
>>>>>=20
>>>>>=20
>>>>> On Wed, Sep 3, 2014 at 10:41 AM, RJ Nowling <rnowling@gmail.com> wrot=
e:
>>>>>=20
>>>>>> No, it's not in all cases.   Since Breeze uses lapack under the hood=
,
>>>>>> changes to memory between different threads is bad.
>>>>>>=20
>>>>>> There's actually a potential bug in the KMeans code where it uses +=
=3D
>>>>>> instead of +.
>>>>>>=20
>>>>>>=20
>>>>>> On Wed, Sep 3, 2014 at 1:26 PM, Ulanov, Alexander <
>>>>>> alexander.ulanov@hp.com>
>>>>>> wrote:
>>>>>>=20
>>>>>>> Hi,
>>>>>>>=20
>>>>>>> Is breeze library called thread safe from Spark mllib code in case
>>>>>> when
>>>>>>> native libs for blas and lapack are used? Might it be an issue when
>>>>>> running
>>>>>>> Spark locally?
>>>>>>>=20
>>>>>>> Best regards, Alexander
>>>>>>> -------------------------------------------------------------------=
--
>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>>=20
>>>>>>=20
>>>>>> --
>>>>>> em rnowling@gmail.com
>>>>>> c 954.496.2314
>>>>=20
>>>>=20
>>>> --
>>>> em rnowling@gmail.com
>>>> c 954.496.2314
>>=20
>>=20
>> --
>> em rnowling@gmail.com
>> c 954.496.2314

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9283-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 20:43:47 2014
Return-Path: <dev-return-9283-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0FF0A113C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 20:43:47 +0000 (UTC)
Received: (qmail 14983 invoked by uid 500); 3 Sep 2014 20:43:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14917 invoked by uid 500); 3 Sep 2014 20:43:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14861 invoked by uid 99); 3 Sep 2014 20:43:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:43:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of spark.devuser@gmail.com designates 209.85.220.182 as permitted sender)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:43:41 +0000
Received: by mail-vc0-f182.google.com with SMTP id im17so9441989vcb.41
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 13:43:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HnNe7QSok4ya8uDyf7G6M0EmoDWOo5YxUOMHgoEnOZc=;
        b=FpRquOLZE2aYIK3TTRZ723LxSc1jVK3D5NnZb5bALI5LT45jJR+LQwE+b5bCXGkBtC
         n0sgyjC5T2hCPevzE9QV2L8zXq7+uv32nAbmmPrgnwGCCZni976r73Mjcvk1vZmQ1EIE
         aOUxj7usdRJ4fIVJezVNKdBPruAl27dB8Zi1C28OBu0xoax35TqXmDgDquQcEKFUNfJQ
         PzalPdEEn+4D8M2QeEsQiKxfDwkat8w6Jp5llInUxefNJFH5PyxnW4EINL9pACGZ3oIM
         rB0I0oONwYmzgCbltR6T1G1LLVmSErI6kXnqUWVkP6g6sAfHUu7OsYu0+wyugpw21xmj
         tWoA==
MIME-Version: 1.0
X-Received: by 10.52.28.198 with SMTP id d6mr33098vdh.68.1409777000926; Wed,
 03 Sep 2014 13:43:20 -0700 (PDT)
Received: by 10.221.23.74 with HTTP; Wed, 3 Sep 2014 13:43:20 -0700 (PDT)
In-Reply-To: <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
	<etPan.54075d17.643c9869.5a82@joshs-mbp>
	<CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 13:43:20 -0700
Message-ID: <CAPV_Hnw93KbkH-7e7rvrVabXJatDO6GsGbOd4F7Y0Skz1RySWQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Mubarak Seyed <spark.devuser@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Marcelo Vanzin <vanzin@cloudera.com>
Content-Type: multipart/alternative; boundary=20cf307ca3c45a541205022f49df
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf307ca3c45a541205022f49df
Content-Type: text/plain; charset=UTF-8

+1 (non-binding)

Tested locally on Mac OS X with local-cluster mode.


On Wed, Sep 3, 2014 at 12:23 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:

> +1.
>
> Tested locally on OSX 10.9, built with Hadoop 2.4.1
>
> - Checked Datanucleus jar files
> - Tested Spark SQL Thrift server and CLI under local mode and standalone
> cluster against MySQL backed metastore
>
>
>
> On Wed, Sep 3, 2014 at 11:25 AM, Josh Rosen <rosenville@gmail.com> wrote:
>
> > +1.  Tested on Windows and EC2.  Confirmed that the EC2 pvm->hvm switch
> > fixed the SPARK-3358 regression.
> >
> >
> > On September 3, 2014 at 10:33:45 AM, Marcelo Vanzin (vanzin@cloudera.com
> )
> > wrote:
> >
> > +1 (non-binding)
> >
> > - checked checksums of a few packages
> > - ran few jobs against yarn client/cluster using hadoop2.3 package
> > - played with spark-shell in yarn-client mode
> >
> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > > Please vote on releasing the following candidate as Apache Spark
> version
> > 1.1.0!
> > >
> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> > >
> > > The release files, including signatures, digests, etc. can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1031/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> > >
> > > Please vote on releasing this package as Apache Spark 1.1.0!
> > >
> > > The vote is open until Saturday, September 06, at 08:30 UTC and passes
> if
> > > a majority of at least 3 +1 PMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.apache.org/
> > >
> > > == Regressions fixed since RC3 ==
> > > SPARK-3332 - Issue with tagging in EC2 scripts
> > > SPARK-3358 - Issue with regression for m3.XX instances
> > >
> > > == What justifies a -1 vote for this release? ==
> > > This vote is happening very late into the QA period compared with
> > > previous votes, so -1 votes should only occur for significant
> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > > this release.
> > >
> > > == What default changes should I be aware of? ==
> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > > --> Old behavior can be restored by switching to "lzf"
> > >
> > > 2. PySpark now performs external spilling during aggregations.
> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> > "false".
> > >
> > > 3. PySpark uses a new heuristic for determining the parallelism of
> > > shuffle operations.
> > > --> Old behavior can be restored by setting
> > > "spark.default.parallelism" to the number of cores in the cluster.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
> >
> >
> > --
> > Marcelo
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--20cf307ca3c45a541205022f49df--

From dev-return-9284-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 20:44:24 2014
Return-Path: <dev-return-9284-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 88712113C9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 20:44:24 +0000 (UTC)
Received: (qmail 18997 invoked by uid 500); 3 Sep 2014 20:44:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18936 invoked by uid 500); 3 Sep 2014 20:44:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18924 invoked by uid 99); 3 Sep 2014 20:44:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:44:23 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.45 as permitted sender)
Received: from [209.85.220.45] (HELO mail-pa0-f45.google.com) (209.85.220.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:43:56 +0000
Received: by mail-pa0-f45.google.com with SMTP id bj1so18237046pad.18
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 13:43:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=ZQ3mwMHb/EEgyfpW8YeYayps41GJ6sxOhChp4vLNtaw=;
        b=oRK8grVaKbk4nWkmgbi5K3otMlisfTL1SsXEgdySxYBy83SJAVFvTLdi0PhM7ObKqg
         XKmoZsfUJEMZ+MJi2RCd9sqQsJN1C5r4qWOrdKb6+npDK0zVMCpMkCRzaY0qVTNp1IhO
         8dKatCIMz3AijOuXnApbCDrX3mjKAU9KOg0NOxefcFhTBa5xudRy+Mg80GDviTmyt5+2
         Ns61V/XF8P2ZpqIBnicT32KVebSSXY/uc8XYtzjMaleUhJQ7zxvurmAo/VDuu8ZN3VcF
         s34EPH1h7yWrNd8F1ihvwqjqH/EZgD6F6wHuyq4ntzF28rLILkvkLEdDtgo61vhO1vCX
         qTqw==
X-Received: by 10.70.140.163 with SMTP id rh3mr114784pdb.53.1409777035282;
        Wed, 03 Sep 2014 13:43:55 -0700 (PDT)
Received: from mbp-3 (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id uf6sm20036046pac.16.2014.09.03.13.43.52
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 03 Sep 2014 13:43:54 -0700 (PDT)
Date: Wed, 3 Sep 2014 13:43:49 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.54077d85.580bd78f.8aeb@mbp-3>
In-Reply-To: <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
 <etPan.54075d17.643c9869.5a82@joshs-mbp>
 <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54077d85_153ea438_8aeb"
X-Virus-Checked: Checked by ClamAV on apache.org

--54077d85_153ea438_8aeb
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

+1

Matei

On September 3, 2014 at 12:24:32 PM, Cheng Lian (lian.cs.zju@gmail.com) wrote:

+1. 

Tested locally on OSX 10.9, built with Hadoop 2.4.1 

- Checked Datanucleus jar files 
- Tested Spark SQL Thrift server and CLI under local mode and standalone 
cluster against MySQL backed metastore 



On Wed, Sep 3, 2014 at 11:25 AM, Josh Rosen <rosenville@gmail.com> wrote: 

> +1. Tested on Windows and EC2. Confirmed that the EC2 pvm->hvm switch 
> fixed the SPARK-3358 regression. 
> 
> 
> On September 3, 2014 at 10:33:45 AM, Marcelo Vanzin (vanzin@cloudera.com) 
> wrote: 
> 
> +1 (non-binding) 
> 
> - checked checksums of a few packages 
> - ran few jobs against yarn client/cluster using hadoop2.3 package 
> - played with spark-shell in yarn-client mode 
> 
> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com> 
> wrote: 
> > Please vote on releasing the following candidate as Apache Spark version 
> 1.1.0! 
> > 
> > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd): 
> > 
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460 
> > 
> > The release files, including signatures, digests, etc. can be found at: 
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4/ 
> > 
> > Release artifacts are signed with the following key: 
> > https://people.apache.org/keys/committer/pwendell.asc 
> > 
> > The staging repository for this release can be found at: 
> > https://repository.apache.org/content/repositories/orgapachespark-1031/ 
> > 
> > The documentation corresponding to this release can be found at: 
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/ 
> > 
> > Please vote on releasing this package as Apache Spark 1.1.0! 
> > 
> > The vote is open until Saturday, September 06, at 08:30 UTC and passes if 
> > a majority of at least 3 +1 PMC votes are cast. 
> > 
> > [ ] +1 Release this package as Apache Spark 1.1.0 
> > [ ] -1 Do not release this package because ... 
> > 
> > To learn more about Apache Spark, please see 
> > http://spark.apache.org/ 
> > 
> > == Regressions fixed since RC3 == 
> > SPARK-3332 - Issue with tagging in EC2 scripts 
> > SPARK-3358 - Issue with regression for m3.XX instances 
> > 
> > == What justifies a -1 vote for this release? == 
> > This vote is happening very late into the QA period compared with 
> > previous votes, so -1 votes should only occur for significant 
> > regressions from 1.0.2. Bugs already present in 1.0.X will not block 
> > this release. 
> > 
> > == What default changes should I be aware of? == 
> > 1. The default value of "spark.io.compression.codec" is now "snappy" 
> > --> Old behavior can be restored by switching to "lzf" 
> > 
> > 2. PySpark now performs external spilling during aggregations. 
> > --> Old behavior can be restored by setting "spark.shuffle.spill" to 
> "false". 
> > 
> > 3. PySpark uses a new heuristic for determining the parallelism of 
> > shuffle operations. 
> > --> Old behavior can be restored by setting 
> > "spark.default.parallelism" to the number of cores in the cluster. 
> > 
> > --------------------------------------------------------------------- 
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org 
> > For additional commands, e-mail: dev-help@spark.apache.org 
> > 
> 
> 
> 
> -- 
> Marcelo 
> 
> --------------------------------------------------------------------- 
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org 
> For additional commands, e-mail: dev-help@spark.apache.org 
> 
> 

--54077d85_153ea438_8aeb--


From dev-return-9285-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 20:46:11 2014
Return-Path: <dev-return-9285-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA61E113D7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 20:46:11 +0000 (UTC)
Received: (qmail 24435 invoked by uid 500); 3 Sep 2014 20:46:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24369 invoked by uid 500); 3 Sep 2014 20:46:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24357 invoked by uid 99); 3 Sep 2014 20:46:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:46:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.170 as permitted sender)
Received: from [209.85.223.170] (HELO mail-ie0-f170.google.com) (209.85.223.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:45:43 +0000
Received: by mail-ie0-f170.google.com with SMTP id rl12so10471521iec.29
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 13:45:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=H8+f3NYnJbO1Jdy0Jqyr7TO+bwjRSimdgM9yLcm0+18=;
        b=ZWZV/cQkv+FsG1ClKtp6vbt4kYmeIZD095/etTT7nPQ3fiKMFEkTCJOAcSH5MtB5ju
         7fp7taiIBfn23rJnSg3jI0vn3aBQEqfWnBmNKpB350pBmzcszb2/3My3Ae2wT1flkF45
         eQIW3XzaJ1CfaZlBOXUpWm0NiZ5bTnc0Doc1io//2dMxz2I9v68MbSJAWG0BxiE/U7Mk
         qN14CbDZhJfSb11HHcWDBbRsTxQcAjJuJMj/nb4wpXrOMDz3/0f5qTlbYR32h15dWbfb
         fLOTWJKCqFxbQSVsehAqRvFbDDgPWIuCG3obG6Pupr29jnF+Lw/rrfh/JbkEth8M4gbp
         2ceA==
X-Received: by 10.43.53.198 with SMTP id vr6mr105148icb.74.1409777142205;
        Wed, 03 Sep 2014 13:45:42 -0700 (PDT)
Received: from [142.157.43.33] (wpa043033.Wireless.McGill.CA. [142.157.43.33])
        by mx.google.com with ESMTPSA id hg4sm6441172igb.15.2014.09.03.13.45.41
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 03 Sep 2014 13:45:41 -0700 (PDT)
Date: Wed, 3 Sep 2014 16:59:08 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <1E9F7A2DD2D6408BA9F29BC2A0170697@gmail.com>
In-Reply-To: <etPan.54077d85.580bd78f.8aeb@mbp-3>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
 <etPan.54075d17.643c9869.5a82@joshs-mbp>
 <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
 <etPan.54077d85.580bd78f.8aeb@mbp-3>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5407811c_238e1f29_3447"
X-Virus-Checked: Checked by ClamAV on apache.org

--5407811c_238e1f29_3447
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

+1 tested thrift server with our in-house application, everything works fine 

-- 
Nan Zhu


On Wednesday, September 3, 2014 at 4:43 PM, Matei Zaharia wrote:

> +1
> 
> Matei
> 
> On September 3, 2014 at 12:24:32 PM, Cheng Lian (lian.cs.zju@gmail.com (mailto:lian.cs.zju@gmail.com)) wrote:
> 
> +1. 
> 
> Tested locally on OSX 10.9, built with Hadoop 2.4.1 
> 
> - Checked Datanucleus jar files 
> - Tested Spark SQL Thrift server and CLI under local mode and standalone 
> cluster against MySQL backed metastore 
> 
> 
> 
> On Wed, Sep 3, 2014 at 11:25 AM, Josh Rosen <rosenville@gmail.com (mailto:rosenville@gmail.com)> wrote: 
> 
> > +1. Tested on Windows and EC2. Confirmed that the EC2 pvm->hvm switch 
> > fixed the SPARK-3358 regression. 
> > 
> > 
> > On September 3, 2014 at 10:33:45 AM, Marcelo Vanzin (vanzin@cloudera.com (mailto:vanzin@cloudera.com)) 
> > wrote: 
> > 
> > +1 (non-binding) 
> > 
> > - checked checksums of a few packages 
> > - ran few jobs against yarn client/cluster using hadoop2.3 package 
> > - played with spark-shell in yarn-client mode 
> > 
> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com (mailto:pwendell@gmail.com)> 
> > wrote: 
> > > Please vote on releasing the following candidate as Apache Spark version 
> > 
> > 1.1.0! 
> > > 
> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd): 
> > https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460 
> > > 
> > > The release files, including signatures, digests, etc. can be found at: 
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/ 
> > > 
> > > Release artifacts are signed with the following key: 
> > > https://people.apache.org/keys/committer/pwendell.asc 
> > > 
> > > The staging repository for this release can be found at: 
> > > https://repository.apache.org/content/repositories/orgapachespark-1031/ 
> > > 
> > > The documentation corresponding to this release can be found at: 
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/ 
> > > 
> > > Please vote on releasing this package as Apache Spark 1.1.0! 
> > > 
> > > The vote is open until Saturday, September 06, at 08:30 UTC and passes if 
> > > a majority of at least 3 +1 PMC votes are cast. 
> > > 
> > > [ ] +1 Release this package as Apache Spark 1.1.0 
> > > [ ] -1 Do not release this package because ... 
> > > 
> > > To learn more about Apache Spark, please see 
> > > http://spark.apache.org/ 
> > > 
> > > == Regressions fixed since RC3 == 
> > > SPARK-3332 - Issue with tagging in EC2 scripts 
> > > SPARK-3358 - Issue with regression for m3.XX instances 
> > > 
> > > == What justifies a -1 vote for this release? == 
> > > This vote is happening very late into the QA period compared with 
> > > previous votes, so -1 votes should only occur for significant 
> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block 
> > > this release. 
> > > 
> > > == What default changes should I be aware of? == 
> > > 1. The default value of "spark.io.compression.codec" is now "snappy" 
> > > --> Old behavior can be restored by switching to "lzf" 
> > > 
> > > 2. PySpark now performs external spilling during aggregations. 
> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to 
> > > 
> > 
> > "false". 
> > > 
> > > 3. PySpark uses a new heuristic for determining the parallelism of 
> > > shuffle operations. 
> > > --> Old behavior can be restored by setting 
> > > "spark.default.parallelism" to the number of cores in the cluster. 
> > > 
> > > --------------------------------------------------------------------- 
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org) 
> > > For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org) 
> > > 
> > 
> > 
> > 
> > 
> > -- 
> > Marcelo 
> > 
> > --------------------------------------------------------------------- 
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org) 
> > For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org) 
> > 
> 
> 
> 



--5407811c_238e1f29_3447--


From dev-return-9286-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 20:46:22 2014
Return-Path: <dev-return-9286-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A29B3113D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 20:46:22 +0000 (UTC)
Received: (qmail 26056 invoked by uid 500); 3 Sep 2014 20:46:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25994 invoked by uid 500); 3 Sep 2014 20:46:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25981 invoked by uid 99); 3 Sep 2014 20:46:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:46:21 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.47 as permitted sender)
Received: from [209.85.220.47] (HELO mail-pa0-f47.google.com) (209.85.220.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 20:45:53 +0000
Received: by mail-pa0-f47.google.com with SMTP id hz1so18288503pad.6
        for <dev@spark.apache.org>; Wed, 03 Sep 2014 13:45:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=0LKb3a+lcib5OVkIJYDFdyaju+tl5Xo2BOs0AgfeJ5Y=;
        b=RXOiSayUMxKh90iCOrzxG74R8DnTGVA5GCPtU43h5CVbCctQRd/FljBGai3eVQsaVi
         SR088kAtLU7hnQlrtqPkCOu1Zl0aGuNk4YoVMvdi+Zy0qoiLQj7WyIzGgnD9kZEtv1+q
         iIms9xe18LczaVCAHOP1Lt9I6YxmoMmoedcUdgats6pzTwAdvHlPV+ffNKfLXsRRFmQ4
         MX1xP1/3+KcmR/PTo3hFz4E2tkxTNHpuIaVe64wIoq/OgZIi2sr8jVfvevhnz7mN7Ndp
         /WKUiSfA/72YSXA+vEi/jBqUPjB9u7+W4NKTReWvY4GJ72cM8BE8MDJBpghAdu1IUEA/
         2Rqw==
X-Received: by 10.66.121.200 with SMTP id lm8mr121462pab.1.1409777149671;
        Wed, 03 Sep 2014 13:45:49 -0700 (PDT)
Received: from mbp-3 (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id sf1sm7728334pbb.0.2014.09.03.13.45.48
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 03 Sep 2014 13:45:49 -0700 (PDT)
Date: Wed, 3 Sep 2014 13:45:46 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Matthew Farrellee <matt@redhat.com>, Reynold Xin
 <rxin@databricks.com>
Cc: Sanghoon Lee <phoenixlee1@gmail.com>, dev <dev@spark.apache.org>
Message-ID: <etPan.54077dfa.3855585c.8aeb@mbp-3>
In-Reply-To: <54075D15.6060901@redhat.com>
References: <CAMdi-keSUiYt+Yc5QQPF+B0Aq7q+f+K8+hs0o6Q4qTrD7_OC5g@mail.gmail.com>
 <CAPh_B=b5o8HoAqmp1PMw-tbP80QSEp7MjSkZ6e=b6_3b5vqu0w@mail.gmail.com>
 <54075AD6.8090803@redhat.com>
 <CAPh_B=aCY6QaE302+cuxhrz5MJC2AJkedM5PQFQxBKo0Yj3rVQ@mail.gmail.com>
 <54075D15.6060901@redhat.com>
Subject: Re: Ask something about spark
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54077dfa_70a64e2a_8aeb"
X-Virus-Checked: Checked by ClamAV on apache.org

--54077dfa_70a64e2a_8aeb
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I think it has to be Apache actually, it can't be CC.

Matei

On September 3, 2014 at 11:26:32 AM, Matthew =46arrellee (matt=40redhat.c=
om) wrote:

CC or Apache, it'd be helpful to have it listed in the footer of pages =20

best, =20


matt =20

On 09/03/2014 02:23 PM, Reynold Xin wrote: =20
> I am not sure if I can just go ahead and update the website with a =20
> creative common license. =20
> =20
> IIRC, AS=46 websites are also Apache 2.0 license. Might need somebody f=
rom =20
> legal to chime in. =20
> =20
> =20
> On Wed, Sep 3, 2014 at 11:15 AM, Matthew =46arrellee <matt=40redhat.com=
 =20
> <mailto:matt=40redhat.com>> wrote: =20
> =20
> reynold, =20
> =20
> would you folks be willing to put some creative commons license =20
> information on the site and its content=3F =20
> =20
> best, =20
> =20
> =20
> matt =20
> =20
> =20
> On 09/02/2014 06:32 PM, Reynold Xin wrote: =20
> =20
> I think in general that is fine. It would be great if your =20
> slides come with =20
> proper attribution. =20
> =20
> =20
> On Tue, Sep 2, 2014 at 3:31 PM, Sanghoon Lee =20
> <phoenixlee1=40gmail.com <mailto:phoenixlee1=40gmail.com>> wrote: =20
> =20
> Hi, I am phoenixlee and a Spark programmer in Korea. =20
> =20
> And be a good chance this time, it tries to teach college =20
> students and =20
> office workers to Spark. =20
> This course will be done with the support of the government. =20
> Can I use the =20
> data(pictures, samples, etc.) in the spark homepage for this =20
> course=3F Of =20
> course, I will put the comments in thanks and webpage URL. =20
> It would be a =20
> good opportunity, even though the findings were that there =20
> is no teaching =20
> materials =22Spark=22 and education (or community) still in Korea. =20
> =20
> Thanks. =20
> =E1=90=A7 =20
> =20
> =20
> =20
> =20


--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--54077dfa_70a64e2a_8aeb--


From dev-return-9287-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep  3 23:03:06 2014
Return-Path: <dev-return-9287-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A5C111AAB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  3 Sep 2014 23:03:06 +0000 (UTC)
Received: (qmail 11248 invoked by uid 500); 3 Sep 2014 23:03:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11174 invoked by uid 500); 3 Sep 2014 23:03:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11163 invoked by uid 99); 3 Sep 2014 23:03:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 23:03:05 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of freeman.jeremy@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 03 Sep 2014 23:02:39 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <freeman.jeremy@gmail.com>)
	id 1XPJZW-0008NX-2f
	for dev@spark.incubator.apache.org; Wed, 03 Sep 2014 16:02:38 -0700
Date: Wed, 3 Sep 2014 16:02:38 -0700 (PDT)
From: Jeremy Freeman <freeman.jeremy@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409785358073-8254.post@n3.nabble.com>
In-Reply-To: <1E9F7A2DD2D6408BA9F29BC2A0170697@gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com> <CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com> <etPan.54075d17.643c9869.5a82@joshs-mbp> <CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com> <etPan.54077d85.580bd78f.8aeb@mbp-3> <1E9F7A2DD2D6408BA9F29BC2A0170697@gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

+1



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC4-tp8219p8254.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9288-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 02:13:34 2014
Return-Path: <dev-return-9288-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 709E811123
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 02:13:34 +0000 (UTC)
Received: (qmail 31168 invoked by uid 500); 4 Sep 2014 02:13:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31102 invoked by uid 500); 4 Sep 2014 02:13:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31047 invoked by uid 99); 4 Sep 2014 02:13:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 02:13:33 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 02:13:28 +0000
Received: by mail-ig0-f172.google.com with SMTP id h15so303016igd.11
        for <dev@spark.incubator.apache.org>; Wed, 03 Sep 2014 19:13:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=DixKpIV+a/8fj1we8yd0l/fJcL50gI+RdL+MqxKN8Es=;
        b=liBrqa7aU/BOUCIAzJztFB3iVZLXv0+tH/ZgibeBIyUTgu/2S4g05ozUpy3PuRpd/b
         Rd+s/+gqaW1p/yafu+J/1TU5xKkb4WegYqdmMWCkI2sO1zuKxzz1fWNam4PnN5HR19+/
         1081hyiqkeffry4h2V/khgXPMC0NpzOOhK8s7zKKheHrQoNfRqgGbWCOe6e1bCaaNegC
         2qVXqgIK1eq7WtXbxhR2Q+I275Wocuj9q9mnQ9TcL+T5Mha9qpKvEFFUOlH3PXzjZ0EQ
         D0V9saXH+1AzVeRIsHHG0axAULWiR+ulqnSaNyTnGeSf/QFWO1Yml0agrXZ6jmlhva9K
         zWnQ==
MIME-Version: 1.0
X-Received: by 10.50.79.165 with SMTP id k5mr1712180igx.16.1409796787799; Wed,
 03 Sep 2014 19:13:07 -0700 (PDT)
Received: by 10.107.148.66 with HTTP; Wed, 3 Sep 2014 19:13:07 -0700 (PDT)
In-Reply-To: <1409785358073-8254.post@n3.nabble.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CAAOnQ7v7QiGbL+w8JutgXaKCrPFPfnmjYdvsx2gZP-7A8BjNSQ@mail.gmail.com>
	<etPan.54075d17.643c9869.5a82@joshs-mbp>
	<CAA_qdLoTLv7fommuSKaybaf192F02_eDzdg-MEtEGvKVRyYFrQ@mail.gmail.com>
	<etPan.54077d85.580bd78f.8aeb@mbp-3>
	<1E9F7A2DD2D6408BA9F29BC2A0170697@gmail.com>
	<1409785358073-8254.post@n3.nabble.com>
Date: Wed, 3 Sep 2014 19:13:07 -0700
Message-ID: <CABjYQ3_uvdjmL1YajPWXeP=6waEEUx6TOm_1PgLyerQqMAfj2A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Denny Lee <denny.g.lee@gmail.com>
To: Jeremy Freeman <freeman.jeremy@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013a032ebe703c050233e4de
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013a032ebe703c050233e4de
Content-Type: text/plain; charset=UTF-8

+1

on OSX Yosemite, built with Hadoop 2.4.1, Hive 0.12 testing SparkSQL,
Thrift, MySQL metastore



On Wed, Sep 3, 2014 at 4:02 PM, Jeremy Freeman <freeman.jeremy@gmail.com>
wrote:

> +1
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC4-tp8219p8254.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e013a032ebe703c050233e4de--

From dev-return-9289-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 03:13:28 2014
Return-Path: <dev-return-9289-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 32A7D112D6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 03:13:28 +0000 (UTC)
Received: (qmail 38364 invoked by uid 500); 4 Sep 2014 03:13:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38291 invoked by uid 500); 4 Sep 2014 03:13:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38256 invoked by uid 99); 4 Sep 2014 03:13:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 03:13:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nzjemail@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 03:13:21 +0000
Received: by mail-wg0-f44.google.com with SMTP id m15so9306864wgh.3
        for <multiple recipients>; Wed, 03 Sep 2014 20:13:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=EMmt3YzPPoflm87ld5C7e1282qHT6dJyFy9nbehuCiM=;
        b=YSNCj3sdU0jlXmBrGvDzrjrM+4zlDYJ/1bp03sTENw/+uiHYqwRUjiVepNoBV91B8F
         knR44s1+QJZX+x2Ntb0Z09Qp2pDUwgFRS5mSEsCBVPbms7ZZ/yinEtSnoFJjs5q2V9u8
         LsPm4cM4CVovEzt/lW6350K+YweaK8YgkAVkAUjwWxjxdlpyhdbC9baSee5DL6YwIqOV
         Qdw/ky/49spicppN0t3BeStH/+eIxh5BSJ5e1sLbkBECvOKA32cdRlO8psfq94krxDXC
         2KJzt4Lg4wH5xtKBtHhlqgVhM/N64J00kxaSk7RyGHRfZtcOeoCx7l15GvFAisEWndOv
         /pzw==
MIME-Version: 1.0
X-Received: by 10.180.103.234 with SMTP id fz10mr1925917wib.76.1409800380337;
 Wed, 03 Sep 2014 20:13:00 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Wed, 3 Sep 2014 20:13:00 -0700 (PDT)
Date: Thu, 4 Sep 2014 11:13:00 +0800
Message-ID: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
Subject: memory size for caching RDD
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: user@spark.apache.org, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=f46d04428f16dfd512050234ba95
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04428f16dfd512050234ba95
Content-Type: text/plain; charset=UTF-8

Dear all:

Spark uses memory to cache RDD and the memory size is specified by
"spark.storage.memoryFraction".

One the Executor starts, does Spark support adjusting/resizing memory size
of this part dynamically?

Thanks.

-- 
*Regards,*
*Zhaojie*

--f46d04428f16dfd512050234ba95--

From dev-return-9290-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 05:46:12 2014
Return-Path: <dev-return-9290-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 84112115F1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 05:46:12 +0000 (UTC)
Received: (qmail 40954 invoked by uid 500); 4 Sep 2014 05:45:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40912 invoked by uid 500); 4 Sep 2014 05:45:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40247 invoked by uid 99); 4 Sep 2014 05:45:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 05:45:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.169 as permitted sender)
Received: from [209.85.214.169] (HELO mail-ob0-f169.google.com) (209.85.214.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 05:45:25 +0000
Received: by mail-ob0-f169.google.com with SMTP id wp4so6995592obc.28
        for <multiple recipients>; Wed, 03 Sep 2014 22:45:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=xQ9yZeS+1PrRUjvI7ho4Y/DhIO319DZtosgapewDyf4=;
        b=qJ6Wj8N/Si0op3AKYZ4Bul1IOP9IAMgqnK2dZyVsngxbr8NlTwPGtVkEhNZXgEdLIW
         yVFhB6szzxhPZ65d/M/gx/BRFaPdnoHdnjTcn5p+V7qXx9kLnHZComukDW5CafdCZjh+
         drII+7mgudRIjy73TAGZLBYFUIpNDKE4mWmEQ/DS3TOYDF9Z8Onratc+TphPtTKvsGxt
         dSl3SYtJty14hlQ7p+cZXFN2yUF08cFbDfimlm89L5KoR2BuoJ+c5mgM4yg8rIyFTe6x
         AAMJjFpBsM14Yw6RIVOHfTFID7zL1X4lAgYMxGIYsifjy3RYBJO/HtdVyQyC7fTKHSAh
         DnGw==
MIME-Version: 1.0
X-Received: by 10.60.92.168 with SMTP id cn8mr2054644oeb.83.1409809524551;
 Wed, 03 Sep 2014 22:45:24 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 3 Sep 2014 22:45:24 -0700 (PDT)
In-Reply-To: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
Date: Wed, 3 Sep 2014 22:45:24 -0700
Message-ID: <CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
Subject: Re: memory size for caching RDD
From: Patrick Wendell <pwendell@gmail.com>
To: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Changing this is not supported, it si immutable similar to other spark
configuration settings.

On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gmail=
.com> wrote:
> Dear all:
>
> Spark uses memory to cache RDD and the memory size is specified by
> "spark.storage.memoryFraction".
>
> One the Executor starts, does Spark support adjusting/resizing memory siz=
e
> of this part dynamically?
>
> Thanks.
>
> --
> *Regards,*
> *Zhaojie*

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9291-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 06:27:48 2014
Return-Path: <dev-return-9291-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 91EE9116B7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 06:27:48 +0000 (UTC)
Received: (qmail 91604 invoked by uid 500); 4 Sep 2014 06:27:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91498 invoked by uid 500); 4 Sep 2014 06:27:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90498 invoked by uid 99); 4 Sep 2014 06:27:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:27:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nzjemail@gmail.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:27:36 +0000
Received: by mail-we0-f172.google.com with SMTP id q59so9671074wes.31
        for <multiple recipients>; Wed, 03 Sep 2014 23:27:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=f91y23RbkB+nD1I6LQ1p8PkebDCYre87QtTTZy50YqI=;
        b=CiMNsXPOG40IDl8fwHf29OJzoxY76DJ5W1aLYbUKNN6h7WaW+e7ugaDVDmgsv7QCd4
         P+6Z9Wg/XYQKZU2NTIl3cFknQd8MoXktH2pl2SDPy/XQyEXkM0MlZ3SLazaBjKqSlxdB
         pf2AMv6o5eWbvBhhPghHm6yp7fgKUGfidf6kznmmkjc0cIRv2XHYrHBzs0Yc/GZbqNSY
         f97M8qO5srK+jA3n1eN9wqRdVZPS5Hc/sOshJ6DxNn4INwa9e4GXfJ87aZdEXmNUSRdc
         0QFNnrc7f/tKg30Cd6mIBOoqexALg3eFWHwW3DOP1J3XP8WPMZPVPBhzzG7WCBV7U6Hg
         H5vA==
MIME-Version: 1.0
X-Received: by 10.180.91.101 with SMTP id cd5mr2901500wib.41.1409812035118;
 Wed, 03 Sep 2014 23:27:15 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Wed, 3 Sep 2014 23:27:15 -0700 (PDT)
In-Reply-To: <CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
Date: Thu, 4 Sep 2014 14:27:15 +0800
Message-ID: <CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
Subject: Re: memory size for caching RDD
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=14dae9cc96408dad2a0502377172
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae9cc96408dad2a0502377172
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

But is it possible to make t resizable? When we don't have many RDD to
cache, we can give some memory to others.


2014-09-04 13:45 GMT+08:00 Patrick Wendell <pwendell@gmail.com>:

> Changing this is not supported, it si immutable similar to other spark
> configuration settings.
>
> On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gma=
il.com> wrote:
> > Dear all:
> >
> > Spark uses memory to cache RDD and the memory size is specified by
> > "spark.storage.memoryFraction".
> >
> > One the Executor starts, does Spark support adjusting/resizing memory
> size
> > of this part dynamically?
> >
> > Thanks.
> >
> > --
> > *Regards,*
> > *Zhaojie*
>



--=20
*Regards,*
*Zhaojie*

--14dae9cc96408dad2a0502377172--

From dev-return-9293-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 06:35:32 2014
Return-Path: <dev-return-9293-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 76324116E9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 06:35:32 +0000 (UTC)
Received: (qmail 6692 invoked by uid 500); 4 Sep 2014 06:35:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6330 invoked by uid 500); 4 Sep 2014 06:35:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4361 invoked by uid 99); 4 Sep 2014 06:32:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:32:19 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=HTML_IMAGE_ONLY_24,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nzjemail@gmail.com designates 74.125.82.180 as permitted sender)
Received: from [74.125.82.180] (HELO mail-we0-f180.google.com) (74.125.82.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:32:13 +0000
Received: by mail-we0-f180.google.com with SMTP id w61so9718164wes.39
        for <multiple recipients>; Wed, 03 Sep 2014 23:31:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=hmZRMztzRXK3iRR5fbV7Ta4cbwfh7rcO/LhPUerUIcM=;
        b=AVefcXFzdoy59PqddlTqsbDhQ0ELZjkEdTC277OP1AmDt2uSLu744SBCdz9pTf1YEw
         PVODfOOlYIQRBXnb32W9x8C7JNcVlScv1U+O/GVe3aT+YffhbpicUpvDe2Fz2bOevHqw
         afibkwoXLg0ZQgDxCKbQdriURLUbjsLfmcvv+1ZEh75kJ+mnhyFlqctW5mlfByQv4H+C
         SgY+x1X7A2VoH7ZlQwvbf5fSq0bLBnoOHwb7iPTtreRfIaEVeCMkEXaFVrRfSEdxQ0F0
         wS1+HNt+JG2PUqsmE5atX8yvge4BmJISDLMNiLzg02XiAk9OZLcqSKqdbjFjYZlE6n76
         n3Vg==
MIME-Version: 1.0
X-Received: by 10.194.203.105 with SMTP id kp9mr3141473wjc.41.1409812312300;
 Wed, 03 Sep 2014 23:31:52 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Wed, 3 Sep 2014 23:31:51 -0700 (PDT)
In-Reply-To: <CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
	<CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
X-Goomoji-Body: true
Date: Thu, 4 Sep 2014 14:31:51 +0800
Message-ID: <CAHc8ag2C1GszvkmNjK9oGAkRxdbbvHfO_0NmxHj2rLxgakgmRA@mail.gmail.com>
Subject: Re: memory size for caching RDD
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: raymond.liu@intel.com
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/related; boundary=047d7b6d87641322820502378229
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6d87641322820502378229
Content-Type: multipart/alternative; boundary=047d7b6d876413227f0502378228

--047d7b6d876413227f0502378228
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks raymond.

I duplicated the question. Please see the reply here. [?]


2014-09-04 14:27 GMT+08:00 =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gmail.com>=
:

> But is it possible to make t resizable? When we don't have many RDD to
> cache, we can give some memory to others.
>
>
> 2014-09-04 13:45 GMT+08:00 Patrick Wendell <pwendell@gmail.com>:
>
> Changing this is not supported, it si immutable similar to other spark
>> configuration settings.
>>
>> On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gm=
ail.com> wrote:
>> > Dear all:
>> >
>> > Spark uses memory to cache RDD and the memory size is specified by
>> > "spark.storage.memoryFraction".
>> >
>> > One the Executor starts, does Spark support adjusting/resizing memory
>> size
>> > of this part dynamically?
>> >
>> > Thanks.
>> >
>> > --
>> > *Regards,*
>> > *Zhaojie*
>>
>
>
>
> --
> *Regards,*
> *Zhaojie*
>
>


--=20
*Regards,*
*Zhaojie*

--047d7b6d876413227f0502378228
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Thanks raymond.</div><div><br></div><div>I duplicated=
=C2=A0the question.=C2=A0Please see the reply here.=C2=A0<img style=3D"marg=
in: 0px 0.2ex; vertical-align: middle;" src=3D"cid:330@goomoji.gmail" goomo=
ji=3D"330"></div></div>
<div class=3D"gmail_extra"><br><br><div class=3D"gmail_quote">2014-09-04 14=
:27 GMT+08:00 =E7=89=9B=E5=85=86=E6=8D=B7 <span dir=3D"ltr">&lt;<a href=3D"=
mailto:nzjemail@gmail.com" target=3D"_blank">nzjemail@gmail.com</a>&gt;</sp=
an>:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border=
-left:1px #ccc solid;padding-left:1ex">
<div dir=3D"ltr">But is it possible to make t resizable? When we don&#39;t =
have many RDD to cache, we can give some memory to others.</div><div class=
=3D"gmail_extra"><br><br><div class=3D"gmail_quote">2014-09-04 13:45 GMT+08=
:00 Patrick Wendell <span dir=3D"ltr">&lt;<a href=3D"mailto:pwendell@gmail.=
com" target=3D"_blank">pwendell@gmail.com</a>&gt;</span>:<div>
<div class=3D"h5"><br>
<blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;padding=
-left:1ex;border-left-color:rgb(204,204,204);border-left-width:1px;border-l=
eft-style:solid">Changing this is not supported, it si immutable similar to=
 other spark<br>

configuration settings.<br>
<div><div><br>
On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 &lt;<a href=3D"=
mailto:nzjemail@gmail.com" target=3D"_blank">nzjemail@gmail.com</a>&gt; wro=
te:<br>
&gt; Dear all:<br>
&gt;<br>
&gt; Spark uses memory to cache RDD and the memory size is specified by<br>
&gt; &quot;spark.storage.memoryFraction&quot;.<br>
&gt;<br>
&gt; One the Executor starts, does Spark support adjusting/resizing memory =
size<br>
&gt; of this part dynamically?<br>
&gt;<br>
&gt; Thanks.<br>
&gt;<br>
&gt; --<br>
</div></div>&gt; *Regards,*<br>
&gt; *Zhaojie*<br>
</blockquote></div></div></div><span class=3D"HOEnZb"><font color=3D"#88888=
8"><br><br clear=3D"all"><br>-- <br><div dir=3D"ltr"><b>Regards,</b><div><b=
>Zhaojie</b></div><div><div><b><br></b></div></div></div>
</font></span></div>
</blockquote></div><br><br clear=3D"all"><br>-- <br><div dir=3D"ltr"><b>Reg=
ards,</b><div><b>Zhaojie</b></div><div><div><b><br></b></div></div></div>
</div>

--047d7b6d876413227f0502378228--
--047d7b6d87641322820502378229--

From dev-return-9292-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 06:35:53 2014
Return-Path: <dev-return-9292-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C820E116EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 06:35:53 +0000 (UTC)
Received: (qmail 6441 invoked by uid 500); 4 Sep 2014 06:35:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6255 invoked by uid 500); 4 Sep 2014 06:35:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4533 invoked by uid 99); 4 Sep 2014 06:34:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:34:36 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of raymond.liu@intel.com designates 192.55.52.88 as permitted sender)
Received: from [192.55.52.88] (HELO mga01.intel.com) (192.55.52.88)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:34:31 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by fmsmga101.fm.intel.com with ESMTP; 03 Sep 2014 23:34:10 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.04,464,1406617200"; 
   d="scan'208,217";a="586063711"
Received: from fmsmsx107.amr.corp.intel.com ([10.18.124.205])
  by fmsmga001.fm.intel.com with ESMTP; 03 Sep 2014 23:32:57 -0700
Received: from fmsmsx111.amr.corp.intel.com (10.18.116.5) by
 fmsmsx107.amr.corp.intel.com (10.18.124.205) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Wed, 3 Sep 2014 23:32:57 -0700
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 fmsmsx111.amr.corp.intel.com (10.18.116.5) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Wed, 3 Sep 2014 23:32:57 -0700
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.198]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.174]) with mapi id 14.03.0195.001;
 Thu, 4 Sep 2014 14:32:55 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: =?utf-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>, Patrick Wendell
	<pwendell@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: memory size for caching RDD
Thread-Topic: memory size for caching RDD
Thread-Index: AQHPyAl63cXsncrreUCDCuauIY9xyJvwgwzA
Date: Thu, 4 Sep 2014 06:32:55 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
 <CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
In-Reply-To: <CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: multipart/alternative;
	boundary="_000_391D65D0EBFC9B4B95E117F72A360F1A0E9AE375SHSMSX101ccrcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_391D65D0EBFC9B4B95E117F72A360F1A0E9AE375SHSMSX101ccrcor_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64

WW91IGRvbuKAmXQgbmVlZCB0by4gSXQgaXMgbm90IHN0YXRpYyBhbGxvY2F0ZWQgdG8gUkREIGNh
Y2hlLCBpdCBpcyBqdXN0IGFuIHVwIGxpbWl0Lg0KSWYgeW91IGRvbuKAmXQgdXNlIHVwIHRoZSBt
ZW1vcnkgYnkgUkREIGNhY2hlLCBpdCBpcyBhbHdheXMgYXZhaWxhYmxlIGZvciBvdGhlciB1c2Fn
ZS4gZXhjZXB0IHRob3NlIG9uZSBhbHNvIGNvbnRyb2xsZWQgYnkgc29tZSBtZW1vcnlGcmFjdGlv
biBjb25mLiBlLmcuIHNwYXJrLnNodWZmbGUubWVtb3J5RnJhY3Rpb24gd2hpY2ggeW91IGFsc28g
c2V0IHRoZSB1cCBsaW1pdC4NCg0KQmVzdCBSZWdhcmRzLA0KUmF5bW9uZCBMaXUNCg0KRnJvbTog
54mb5YWG5o23IFttYWlsdG86bnpqZW1haWxAZ21haWwuY29tXQ0KU2VudDogVGh1cnNkYXksIFNl
cHRlbWJlciAwNCwgMjAxNCAyOjI3IFBNDQpUbzogUGF0cmljayBXZW5kZWxsDQpDYzogdXNlckBz
cGFyay5hcGFjaGUub3JnOyBkZXZAc3BhcmsuYXBhY2hlLm9yZw0KU3ViamVjdDogUmU6IG1lbW9y
eSBzaXplIGZvciBjYWNoaW5nIFJERA0KDQpCdXQgaXMgaXQgcG9zc2libGUgdG8gbWFrZSB0IHJl
c2l6YWJsZT8gV2hlbiB3ZSBkb24ndCBoYXZlIG1hbnkgUkREIHRvIGNhY2hlLCB3ZSBjYW4gZ2l2
ZSBzb21lIG1lbW9yeSB0byBvdGhlcnMuDQoNCjIwMTQtMDktMDQgMTM6NDUgR01UKzA4OjAwIFBh
dHJpY2sgV2VuZGVsbCA8cHdlbmRlbGxAZ21haWwuY29tPG1haWx0bzpwd2VuZGVsbEBnbWFpbC5j
b20+PjoNCkNoYW5naW5nIHRoaXMgaXMgbm90IHN1cHBvcnRlZCwgaXQgc2kgaW1tdXRhYmxlIHNp
bWlsYXIgdG8gb3RoZXIgc3BhcmsNCmNvbmZpZ3VyYXRpb24gc2V0dGluZ3MuDQoNCk9uIFdlZCwg
U2VwIDMsIDIwMTQgYXQgODoxMyBQTSwg54mb5YWG5o23IDxuemplbWFpbEBnbWFpbC5jb208bWFp
bHRvOm56amVtYWlsQGdtYWlsLmNvbT4+IHdyb3RlOg0KPiBEZWFyIGFsbDoNCj4NCj4gU3Bhcmsg
dXNlcyBtZW1vcnkgdG8gY2FjaGUgUkREIGFuZCB0aGUgbWVtb3J5IHNpemUgaXMgc3BlY2lmaWVk
IGJ5DQo+ICJzcGFyay5zdG9yYWdlLm1lbW9yeUZyYWN0aW9uIi4NCj4NCj4gT25lIHRoZSBFeGVj
dXRvciBzdGFydHMsIGRvZXMgU3Bhcmsgc3VwcG9ydCBhZGp1c3RpbmcvcmVzaXppbmcgbWVtb3J5
IHNpemUNCj4gb2YgdGhpcyBwYXJ0IGR5bmFtaWNhbGx5Pw0KPg0KPiBUaGFua3MuDQo+DQo+IC0t
DQo+ICpSZWdhcmRzLCoNCj4gKlpoYW9qaWUqDQoNCg0KDQotLQ0KUmVnYXJkcywNClpoYW9qaWUN
Cg0K

--_000_391D65D0EBFC9B4B95E117F72A360F1A0E9AE375SHSMSX101ccrcor_--

From dev-return-9294-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 06:58:00 2014
Return-Path: <dev-return-9294-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0E96211793
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 06:58:00 +0000 (UTC)
Received: (qmail 68003 invoked by uid 500); 4 Sep 2014 06:57:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67895 invoked by uid 500); 4 Sep 2014 06:57:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66863 invoked by uid 99); 4 Sep 2014 06:57:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:57:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nzjemail@gmail.com designates 74.125.82.176 as permitted sender)
Received: from [74.125.82.176] (HELO mail-we0-f176.google.com) (74.125.82.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 06:57:44 +0000
Received: by mail-we0-f176.google.com with SMTP id q59so9712694wes.35
        for <multiple recipients>; Wed, 03 Sep 2014 23:57:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=r+9imQ4w5ECoIZvO2Lczz9E3Lf4igkc8xTOz79/xN6s=;
        b=L948jJp2mLA5ZwFLjf2G7gtCLXt0B9C91bG/46DapMZpVmnslWmPjcoDCVUeWEMAIE
         4na2J0+DjnqVQ4Ggz28CDrWVJOW28WzGYVyMs93CA5G0Lk7e4zNf10y4g4fYwxmhO0Ym
         1atBPy9kV9UP/f6XZhlHQoxyaxKdtoLh71AkqXYFBlOcP7+0VVbDfeFOt9V21mN3PInJ
         Al9m5B/ID7toJHKMyBbYCm0VPuJl6JO4wiAGs/OxvoKoW5/24UbCa2YiBBGUov39Az3j
         FYGGoOZYfdG1ch7bFRqCtI/euKccfyQGMceLd7KXhHqN53CCo1KVYbBRDWNxt+MasUVE
         Mvjw==
MIME-Version: 1.0
X-Received: by 10.180.103.234 with SMTP id fz10mr3169254wib.76.1409813842672;
 Wed, 03 Sep 2014 23:57:22 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Wed, 3 Sep 2014 23:57:22 -0700 (PDT)
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
	<CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com>
Date: Thu, 4 Sep 2014 14:57:22 +0800
Message-ID: <CAHc8ag24FUwgRZ=KKv=q+H00LMOZDp9t2Zp1f8fBD8QrUCqh-Q@mail.gmail.com>
Subject: Re: memory size for caching RDD
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: "Liu, Raymond" <raymond.liu@intel.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "user@spark.apache.org" <user@spark.apache.org>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d04428f164ac66d050237dd6b
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04428f164ac66d050237dd6b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Oh I see.

I want to implement something like this: sometimes I need to release some
memory for other usage even when they are occupied by some RDDs (can be
recomputed with the help of lineage when they are needed),  does spark
provide interfaces to force it to release some memory ?


2014-09-04 14:32 GMT+08:00 Liu, Raymond <raymond.liu@intel.com>:

>  You don=E2=80=99t need to. It is not static allocated to RDD cache, it i=
s just
> an up limit.
>
> If you don=E2=80=99t use up the memory by RDD cache, it is always availab=
le for
> other usage. except those one also controlled by some memoryFraction conf=
.
> e.g. spark.shuffle.memoryFraction which you also set the up limit.
>
>
>
> Best Regards,
>
> *Raymond Liu*
>
>
>
> *From:* =E7=89=9B=E5=85=86=E6=8D=B7 [mailto:nzjemail@gmail.com]
> *Sent:* Thursday, September 04, 2014 2:27 PM
> *To:* Patrick Wendell
> *Cc:* user@spark.apache.org; dev@spark.apache.org
> *Subject:* Re: memory size for caching RDD
>
>
>
> But is it possible to make t resizable? When we don't have many RDD to
> cache, we can give some memory to others.
>
>
>
> 2014-09-04 13:45 GMT+08:00 Patrick Wendell <pwendell@gmail.com>:
>
> Changing this is not supported, it si immutable similar to other spark
> configuration settings.
>
>
> On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gma=
il.com> wrote:
> > Dear all:
> >
> > Spark uses memory to cache RDD and the memory size is specified by
> > "spark.storage.memoryFraction".
> >
> > One the Executor starts, does Spark support adjusting/resizing memory
> size
> > of this part dynamically?
> >
> > Thanks.
> >
> > --
>
> > *Regards,*
> > *Zhaojie*
>
>
>
>
> --
>
> *Regards,*
>
> *Zhaojie*
>
>
>



--=20
*Regards,*
*Zhaojie*

--f46d04428f164ac66d050237dd6b--

From dev-return-9295-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 07:06:16 2014
Return-Path: <dev-return-9295-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 15C7E117C2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 07:06:16 +0000 (UTC)
Received: (qmail 90378 invoked by uid 500); 4 Sep 2014 07:06:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90335 invoked by uid 500); 4 Sep 2014 07:06:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90251 invoked by uid 99); 4 Sep 2014 07:06:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 07:06:00 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of raymond.liu@intel.com designates 192.55.52.93 as permitted sender)
Received: from [192.55.52.93] (HELO mga11.intel.com) (192.55.52.93)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 07:05:34 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by fmsmga102.fm.intel.com with ESMTP; 04 Sep 2014 00:05:32 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.04,464,1406617200"; 
   d="scan'208";a="586073488"
Received: from fmsmsx107.amr.corp.intel.com ([10.18.124.205])
  by fmsmga001.fm.intel.com with ESMTP; 04 Sep 2014 00:05:19 -0700
Received: from fmsmsx120.amr.corp.intel.com (10.18.124.208) by
 fmsmsx107.amr.corp.intel.com (10.18.124.205) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Thu, 4 Sep 2014 00:05:18 -0700
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 fmsmsx120.amr.corp.intel.com (10.18.124.208) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Thu, 4 Sep 2014 00:05:18 -0700
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.198]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.174]) with mapi id 14.03.0195.001;
 Thu, 4 Sep 2014 15:05:16 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: =?utf-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: memory size for caching RDD
Thread-Topic: memory size for caching RDD
Thread-Index: AQHPyAl63cXsncrreUCDCuauIY9xyJvwgwzA//+BuACAAIbYIA==
Date: Thu, 4 Sep 2014 07:05:16 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A0E9AE454@SHSMSX101.ccr.corp.intel.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
	<CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com>
 <CAHc8ag24FUwgRZ=KKv=q+H00LMOZDp9t2Zp1f8fBD8QrUCqh-Q@mail.gmail.com>
In-Reply-To: <CAHc8ag24FUwgRZ=KKv=q+H00LMOZDp9t2Zp1f8fBD8QrUCqh-Q@mail.gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9296-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 07:18:53 2014
Return-Path: <dev-return-9296-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 599DF1180C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 07:18:53 +0000 (UTC)
Received: (qmail 15691 invoked by uid 500); 4 Sep 2014 07:18:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15598 invoked by uid 500); 4 Sep 2014 07:18:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14652 invoked by uid 99); 4 Sep 2014 07:18:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 07:18:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nzjemail@gmail.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 07:18:09 +0000
Received: by mail-wi0-f180.google.com with SMTP id ex7so499113wid.13
        for <multiple recipients>; Thu, 04 Sep 2014 00:18:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=o/PQKXz4cLh/5iv6uYuZmrX+he1/HtxCX+Lt+pZlDYo=;
        b=hcilXLMWjnpf73JuajeNHFWOU0TEBoJWDU5ZYIRnDcMeb1TKnk0nQtP4pxG3QudXyl
         b3bYStbiCex49VWKpMAB1Cw4P9y4AEuxqOXeWWdhMkRpT9X2LS/bZsjfODuHKj7g1jh2
         cTGlzftIyqsFFqqkXKCRCenpb5taw4I95kDyBQYNyR1ltlTOktrf90doRflZWwnIXntn
         jfLuwS5C3laXzs8PjmTAeGIXtZy8rCtly0saBP6/IZcxHd5hpLQHCF3/T9f0ohD+3ucs
         Q6cJyReLZyrUa9Z6EXqG9dfKgGFotgAIDWkKkPtcuDU+z+QB/jBnpCq9ZqB4Su0pB8+1
         QHlQ==
MIME-Version: 1.0
X-Received: by 10.194.203.105 with SMTP id kp9mr3456305wjc.41.1409815088121;
 Thu, 04 Sep 2014 00:18:08 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Thu, 4 Sep 2014 00:18:08 -0700 (PDT)
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A0E9AE454@SHSMSX101.ccr.corp.intel.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com>
	<CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com>
	<CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com>
	<CAHc8ag24FUwgRZ=KKv=q+H00LMOZDp9t2Zp1f8fBD8QrUCqh-Q@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A0E9AE454@SHSMSX101.ccr.corp.intel.com>
Date: Thu, 4 Sep 2014 15:18:08 +0800
Message-ID: <CAHc8ag3Vdr845dg9iDwiY9PFVHaLBRp+E5NSdrfU0MJSb8-LoQ@mail.gmail.com>
Subject: Re: memory size for caching RDD
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: "Liu, Raymond" <raymond.liu@intel.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b6d876486cf0e05023827b6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6d876486cf0e05023827b6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

ok. So can I use the similar logic as the block manager does when space
fills up ?


2014-09-04 15:05 GMT+08:00 Liu, Raymond <raymond.liu@intel.com>:

> I think there is no public API available to do this. In this case, the
> best you can do might be unpersist some RDDs manually. The problem is tha=
t
> this is done by RDD unit, not by block unit. And then, if the storage lev=
el
> including disk level, the data on the disk will be removed too.
>
> Best Regards,
> Raymond Liu
>
> From: =E7=89=9B=E5=85=86=E6=8D=B7 [mailto:nzjemail@gmail.com]
> Sent: Thursday, September 04, 2014 2:57 PM
> To: Liu, Raymond
> Cc: Patrick Wendell; user@spark.apache.org; dev@spark.apache.org
> Subject: Re: memory size for caching RDD
>
> Oh I see.
>
> I want to implement something like this: sometimes I need to release some
> memory for other usage even when they are occupied by some RDDs (can be
> recomputed with the help of lineage when they are needed),  does spark
> provide interfaces to force it to release some memory ?
>
> 2014-09-04 14:32 GMT+08:00 Liu, Raymond <raymond.liu@intel.com>:
> You don=E2=80=99t need to. It is not static allocated to RDD cache, it is=
 just an
> up limit.
> If you don=E2=80=99t use up the memory by RDD cache, it is always availab=
le for
> other usage. except those one also controlled by some memoryFraction conf=
.
> e.g. spark.shuffle.memoryFraction which you also set the up limit.
>
> Best Regards,
> Raymond Liu
>
> From: =E7=89=9B=E5=85=86=E6=8D=B7 [mailto:nzjemail@gmail.com]
> Sent: Thursday, September 04, 2014 2:27 PM
> To: Patrick Wendell
> Cc: user@spark.apache.org; dev@spark.apache.org
> Subject: Re: memory size for caching RDD
>
> But is it possible to make t resizable? When we don't have many RDD to
> cache, we can give some memory to others.
>
> 2014-09-04 13:45 GMT+08:00 Patrick Wendell <pwendell@gmail.com>:
> Changing this is not supported, it si immutable similar to other spark
> configuration settings.
>
> On Wed, Sep 3, 2014 at 8:13 PM, =E7=89=9B=E5=85=86=E6=8D=B7 <nzjemail@gma=
il.com> wrote:
> > Dear all:
> >
> > Spark uses memory to cache RDD and the memory size is specified by
> > "spark.storage.memoryFraction".
> >
> > One the Executor starts, does Spark support adjusting/resizing memory
> size
> > of this part dynamically?
> >
> > Thanks.
> >
> > --
> > *Regards,*
> > *Zhaojie*
>
>
>
> --
> Regards,
> Zhaojie
>
>
>
>
> --
> Regards,
> Zhaojie
>
>


--=20
*Regards,*
*Zhaojie*

--047d7b6d876486cf0e05023827b6--

From dev-return-9297-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 10:36:00 2014
Return-Path: <dev-return-9297-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1494311ED0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 10:36:00 +0000 (UTC)
Received: (qmail 19956 invoked by uid 500); 4 Sep 2014 10:35:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19890 invoked by uid 500); 4 Sep 2014 10:35:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19878 invoked by uid 99); 4 Sep 2014 10:35:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 10:35:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.215.46 as permitted sender)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 10:35:53 +0000
Received: by mail-la0-f46.google.com with SMTP id pv20so11619155lab.33
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 03:35:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=BZi4txV0CaP/39rfdwAj84S2FzPDfYQ+ted/t4J2pB4=;
        b=arb0u0dsHDqQ3QP/sm4BiUzMbHYXnWA1O6gKxf9rGFSj9X3PPDtgsfZ6+By2O5ZZ/C
         KWrLI/bLY9muA1laqg/QgXQs4klD+X9u3XaC558wAxGwZf20vjsix1/OpsfgTPmOw/Y9
         1x20XkJgHa1ZvujF+nK7pxYPR2DL71b55uAt/nwSCSBBEIV58QPy8Vif4TtNvZs/Wf36
         +5BH2z9OTMTjvuS/9aCdeeENMo4p1Y44nGl1tJ3sJCYBoHhy3OI/sJKEVFYd4Xxqe9UF
         XD2yu0EaICtvfos4/v9EY0OXNpafRwN8zSb3cfM8B6ktldNcPNNICGsG7kwAqwrPlLhZ
         mgqg==
MIME-Version: 1.0
X-Received: by 10.112.34.78 with SMTP id x14mr3606952lbi.38.1409826931831;
 Thu, 04 Sep 2014 03:35:31 -0700 (PDT)
Received: by 10.152.37.231 with HTTP; Thu, 4 Sep 2014 03:35:31 -0700 (PDT)
Date: Thu, 4 Sep 2014 16:05:31 +0530
Message-ID: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
Subject: Dependency hell in Spark applications
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=bcaec5554fb2777bb705023ae98f
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec5554fb2777bb705023ae98f
Content-Type: text/plain; charset=UTF-8

I am trying to use Kinesis as source to Spark Streaming and have run into a
dependency issue that can't be resolved without making my own custom Spark
build. The issue is that Spark is transitively dependent
on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because of
libfb303 coming from hbase and hive-serde) whereas AWS SDK is dependent
on org.apache.httpcomponents:httpclient:jar:4.2. When I package and run
Spark Streaming application, I get the following:

Caused by: java.lang.NoSuchMethodError:
org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
        at
org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
        at
org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
        at
org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
        at
com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
        at
com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
        at
com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
        at
com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
        at
com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
        at
com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
        at
com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
        at
com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)

I can create a custom Spark build with
org.apache.httpcomponents:httpclient:jar:4.2 included in the assembly but I
was wondering if this is something Spark devs have noticed and are looking
to resolve in near releases. Here are my thoughts on this issue:

Containers that allow running custom user code have to often resolve
dependency issues in case of conflicts between framework's and user code's
dependency. Here is how I have seen some frameworks resolve the issue:
1. Provide a child-first class loader: Some JEE containers provided a
child-first class loader that allowed for loading classes from user code
first. I don't think this approach completely solves the problem as the
framework is then susceptible to class mismatch errors.
2. Fold in all dependencies in a sub-package: This approach involves
folding all dependencies in a project specific sub-package (like
spark.dependencies). This approach is tedious because it involves building
custom version of all dependencies (and their transitive dependencies)
3. Use something like OSGi: Some frameworks has successfully used OSGi to
manage dependencies between the modules. The challenge in this approach is
to OSGify the framework and hide OSGi complexities from end user.

My personal preference is OSGi (or atleast some support for OSGi) but I
would love to hear what Spark devs are thinking in terms of resolving the
problem.

Thanks,
Aniket

--bcaec5554fb2777bb705023ae98f--

From dev-return-9298-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 10:44:28 2014
Return-Path: <dev-return-9298-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7C96611EFB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 10:44:28 +0000 (UTC)
Received: (qmail 45029 invoked by uid 500); 4 Sep 2014 10:44:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44972 invoked by uid 500); 4 Sep 2014 10:44:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44961 invoked by uid 99); 4 Sep 2014 10:44:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 10:44:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 10:44:21 +0000
Received: by mail-ie0-f176.google.com with SMTP id x19so11430300ier.21
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 03:44:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=wVwYtWoPiKO5VDSNyJNSpdj88EyDLhOWm43uvEBnFdg=;
        b=YrT2AN5ReOkhCiodVmwypyHZ+t01Aa9tPpChrmIENJ4WKtRU8T27I/u/kdu8qtZF/T
         6dCxPHJeZRM9B5F6fFHMBgcYrETTjPRWxv4EaLiyR8L5oHq0SKrxQdfUwQxWYTyqZtiV
         0ibBCHa8xbL88OzDGXHDneRkzA421F2EYHruiVlB0oBfMdgdw9MEcgpCVa8ihkArhIFT
         5Rx48RbyCuUwTqBjnqqaEDGlHTUG50QUlrts0bszx20B+MOrh/8z3cdvKFC5ihNFJWDI
         WNZR2khSipZ14P56JxhX4yQOepTVyVNPGPvhAwgFdXMieZo8wWXCojlXJPrGskrw1ad0
         L2mg==
X-Gm-Message-State: ALoCoQkYfpdXzNYQpYoCWEMRLOteeKGSCS9NmOOSmhr2AbIAmVH9GnIaBom7ojTxgyJiPtiQuYhl
X-Received: by 10.50.108.103 with SMTP id hj7mr5470505igb.5.1409827441089;
 Thu, 04 Sep 2014 03:44:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Thu, 4 Sep 2014 03:43:41 -0700 (PDT)
In-Reply-To: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 4 Sep 2014 11:43:41 +0100
Message-ID: <CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
To: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Dumb question -- are you using a Spark build that includes the Kinesis
dependency? that build would have resolved conflicts like this for
you. Your app would need to use the same version of the Kinesis client
SDK, ideally.

All of these ideas are well-known, yes. In cases of super-common
dependencies like Guava, they are already shaded. This is a
less-common source of conflicts so I don't think http-client is
shaded, especially since it is not used directly by Spark. I think
this is a case of your app conflicting with a third-party dependency?

I think OSGi is deemed too over the top for things like this.

On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
<aniket.bhatnagar@gmail.com> wrote:
> I am trying to use Kinesis as source to Spark Streaming and have run into a
> dependency issue that can't be resolved without making my own custom Spark
> build. The issue is that Spark is transitively dependent
> on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because of
> libfb303 coming from hbase and hive-serde) whereas AWS SDK is dependent
> on org.apache.httpcomponents:httpclient:jar:4.2. When I package and run
> Spark Streaming application, I get the following:
>
> Caused by: java.lang.NoSuchMethodError:
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
>         at
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
>         at
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
>         at
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
>         at
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
>         at
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
>         at
> com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
>         at
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
>         at
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
>         at
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
>         at
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
>         at
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
>
> I can create a custom Spark build with
> org.apache.httpcomponents:httpclient:jar:4.2 included in the assembly but I
> was wondering if this is something Spark devs have noticed and are looking
> to resolve in near releases. Here are my thoughts on this issue:
>
> Containers that allow running custom user code have to often resolve
> dependency issues in case of conflicts between framework's and user code's
> dependency. Here is how I have seen some frameworks resolve the issue:
> 1. Provide a child-first class loader: Some JEE containers provided a
> child-first class loader that allowed for loading classes from user code
> first. I don't think this approach completely solves the problem as the
> framework is then susceptible to class mismatch errors.
> 2. Fold in all dependencies in a sub-package: This approach involves
> folding all dependencies in a project specific sub-package (like
> spark.dependencies). This approach is tedious because it involves building
> custom version of all dependencies (and their transitive dependencies)
> 3. Use something like OSGi: Some frameworks has successfully used OSGi to
> manage dependencies between the modules. The challenge in this approach is
> to OSGify the framework and hide OSGi complexities from end user.
>
> My personal preference is OSGi (or atleast some support for OSGi) but I
> would love to hear what Spark devs are thinking in terms of resolving the
> problem.
>
> Thanks,
> Aniket

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9299-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 13:01:12 2014
Return-Path: <dev-return-9299-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B0AC6112C7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 13:01:12 +0000 (UTC)
Received: (qmail 12259 invoked by uid 500); 4 Sep 2014 13:01:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12200 invoked by uid 500); 4 Sep 2014 13:01:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12184 invoked by uid 99); 4 Sep 2014 13:01:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 13:01:06 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED
X-Spam-Check-By: apache.org
Received-SPF: unknown (athena.apache.org: error in processing during lookup of fborrego@gilt.com)
Received: from [74.125.149.155] (HELO na3sys009aog126.obsmtp.com) (74.125.149.155)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 13:01:01 +0000
Received: from mail-qc0-f176.google.com ([209.85.216.176]) (using TLSv1) by na3sys009aob126.postini.com ([74.125.148.12]) with SMTP
	ID DSNKVAhieHmIdQtjxaVe7t1pigWzzkB3VGkA@postini.com; Thu, 04 Sep 2014 06:00:41 PDT
Received: by mail-qc0-f176.google.com with SMTP id m20so10312992qcx.21
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 06:00:40 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=5Y7rvfkQkxeYnHw6YDiDlLoPLMS9EhP3x1gXagJP5SA=;
        b=PQe3ZYe0IgN59H+dP4xxlzNtUpbImVYjQkg2ibwXkJBmQ3DOigDyJsZrpn7Mg1C0sq
         5GSedxV881Dei1r60ntS/mLPBVVYhmy9oXi13TDp9qSSTnI82qM59TGWL4ZkqOFl5kYr
         5UD1SYz5rfMnmFqqpdKC1bak4ZvWR21RNSnjnISiK+qwRBRZolLETycb2cdu3YwaFu37
         Zmt2wnHXcRGKMCUkQd3A8j7Zo7DTL12CUtyZatnzsmpp2oRkww3Kyo+moWBs811A2Rnt
         Kvyy9aE09zkeBm5zQJClx4EHhOPOBSxTZaAccD1wQjRubWLfz3QsbxhB/ZrqTx8u7wKo
         AlGQ==
X-Gm-Message-State: ALoCoQm3AecC9eC73hj/M6uxLVpd3INp6VzuVrzpcnJw++uHUQlNA/FomL2U5/bx4HOPG+uzE3xSFRFWjKS4cwoGA38Q2PqmVjmVaLI6/dqBhQeyctJQBBQJG7590XR+t9HfyQB1nl5gn8JHBO/kSNt8S19SJrxB6Q==
X-Received: by 10.140.40.84 with SMTP id w78mr6330012qgw.87.1409835640074;
        Thu, 04 Sep 2014 06:00:40 -0700 (PDT)
X-Received: by 10.140.40.84 with SMTP id w78mr6329979qgw.87.1409835639907;
 Thu, 04 Sep 2014 06:00:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.229.15.5 with HTTP; Thu, 4 Sep 2014 06:00:19 -0700 (PDT)
In-Reply-To: <CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
 <CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
From: Felix Garcia Borrego <fborrego@gilt.com>
Date: Thu, 4 Sep 2014 14:00:19 +0100
Message-ID: <CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
To: Sean Owen <sowen@cloudera.com>
Cc: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c122ba82524a05023cf0fa
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c122ba82524a05023cf0fa
Content-Type: text/plain; charset=UTF-8

Hi,
I run into the same issue and apart from the ideas Aniket said, I only
could find a nasty workaround. Add my custom PoolingClientConnectionManager
to my classpath.

http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955



On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com> wrote:

> Dumb question -- are you using a Spark build that includes the Kinesis
> dependency? that build would have resolved conflicts like this for
> you. Your app would need to use the same version of the Kinesis client
> SDK, ideally.
>
> All of these ideas are well-known, yes. In cases of super-common
> dependencies like Guava, they are already shaded. This is a
> less-common source of conflicts so I don't think http-client is
> shaded, especially since it is not used directly by Spark. I think
> this is a case of your app conflicting with a third-party dependency?
>
> I think OSGi is deemed too over the top for things like this.
>
> On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
> <aniket.bhatnagar@gmail.com> wrote:
> > I am trying to use Kinesis as source to Spark Streaming and have run
> into a
> > dependency issue that can't be resolved without making my own custom
> Spark
> > build. The issue is that Spark is transitively dependent
> > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because of
> > libfb303 coming from hbase and hive-serde) whereas AWS SDK is dependent
> > on org.apache.httpcomponents:httpclient:jar:4.2. When I package and run
> > Spark Streaming application, I get the following:
> >
> > Caused by: java.lang.NoSuchMethodError:
> >
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
> >         at
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
> >         at
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
> >         at
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
> >         at
> >
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
> >         at
> >
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
> >         at
> > com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
> >         at
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
> >         at
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
> >         at
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
> >         at
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
> >         at
> >
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
> >
> > I can create a custom Spark build with
> > org.apache.httpcomponents:httpclient:jar:4.2 included in the assembly
> but I
> > was wondering if this is something Spark devs have noticed and are
> looking
> > to resolve in near releases. Here are my thoughts on this issue:
> >
> > Containers that allow running custom user code have to often resolve
> > dependency issues in case of conflicts between framework's and user
> code's
> > dependency. Here is how I have seen some frameworks resolve the issue:
> > 1. Provide a child-first class loader: Some JEE containers provided a
> > child-first class loader that allowed for loading classes from user code
> > first. I don't think this approach completely solves the problem as the
> > framework is then susceptible to class mismatch errors.
> > 2. Fold in all dependencies in a sub-package: This approach involves
> > folding all dependencies in a project specific sub-package (like
> > spark.dependencies). This approach is tedious because it involves
> building
> > custom version of all dependencies (and their transitive dependencies)
> > 3. Use something like OSGi: Some frameworks has successfully used OSGi to
> > manage dependencies between the modules. The challenge in this approach
> is
> > to OSGify the framework and hide OSGi complexities from end user.
> >
> > My personal preference is OSGi (or atleast some support for OSGi) but I
> > would love to hear what Spark devs are thinking in terms of resolving the
> > problem.
> >
> > Thanks,
> > Aniket
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c122ba82524a05023cf0fa--

From dev-return-9300-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 13:43:14 2014
Return-Path: <dev-return-9300-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0176111447
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 13:43:14 +0000 (UTC)
Received: (qmail 8400 invoked by uid 500); 4 Sep 2014 13:43:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8333 invoked by uid 500); 4 Sep 2014 13:43:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8320 invoked by uid 99); 4 Sep 2014 13:43:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 13:43:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 13:42:44 +0000
Received: by mail-wg0-f51.google.com with SMTP id l18so10169035wgh.22
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 06:42:43 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=fj3Fg5/z2SC0EMXM5+DC/7BvqX/e4eZvVXQaKppdZSM=;
        b=DR12+teaceePSZ6ZrnBEYSXC+rGGdRC+ymY/P/1ZeuB0bP9VRW5ZxEHEMrxtooNCkW
         7ePPLE5QXVnipMmVGm5LGnyaCZBp0RoAROcl2MuqqbTGB+DtpU9QtXpPC85HYZY6sfoN
         kWWanQUKjwIJ9MRSXbX9SMDcfIiHlGsycKOVX5+LD0wa7iLC0O9USFb0V3BVxzAn6d1d
         ZfHCopGxeL1cByqMohOmRyhmQ98lJDEpA0oQlQC10SQrpXPsqRRDmOXqSbsR+2P8oMkm
         +ANBpvqnhu/4dqjNY2c7+s6N3V7nPPpkFaNHPs+0+Bm/6ysompVFzw993/2OTeq20yEO
         6/Og==
X-Gm-Message-State: ALoCoQncS0ozokD8xTeQe6l/JkyrUIHxgZujNX0OhPiXx76YrtpVZ1WPr288V3fGJrzLWepqCk1B
MIME-Version: 1.0
X-Received: by 10.194.249.164 with SMTP id yv4mr6475585wjc.34.1409838163250;
 Thu, 04 Sep 2014 06:42:43 -0700 (PDT)
Received: by 10.216.174.197 with HTTP; Thu, 4 Sep 2014 06:42:43 -0700 (PDT)
X-Originating-IP: [172.56.34.241]
Received: by 10.216.174.197 with HTTP; Thu, 4 Sep 2014 06:42:43 -0700 (PDT)
In-Reply-To: <CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
	<CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
	<CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
Date: Thu, 4 Sep 2014 09:42:43 -0400
Message-ID: <CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
From: Koert Kuipers <koert@tresata.com>
To: Felix Garcia Borrego <fborrego@gilt.com>
Cc: Sean Owen <sowen@cloudera.com>, Aniket Bhatnagar <aniket.bhatnagar@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1b90ae968f105023d864d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1b90ae968f105023d864d
Content-Type: text/plain; charset=UTF-8

custom spark builds should not be the answer. at least not if spark ever
wants to have a vibrant community for spark apps.

spark does support a user-classpath-first option, which would deal with
some of these issues, but I don't think it works.
On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com> wrote:

> Hi,
> I run into the same issue and apart from the ideas Aniket said, I only
> could find a nasty workaround. Add my custom PoolingClientConnectionManager
> to my classpath.
>
>
> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
>
>
>
> On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com> wrote:
>
> > Dumb question -- are you using a Spark build that includes the Kinesis
> > dependency? that build would have resolved conflicts like this for
> > you. Your app would need to use the same version of the Kinesis client
> > SDK, ideally.
> >
> > All of these ideas are well-known, yes. In cases of super-common
> > dependencies like Guava, they are already shaded. This is a
> > less-common source of conflicts so I don't think http-client is
> > shaded, especially since it is not used directly by Spark. I think
> > this is a case of your app conflicting with a third-party dependency?
> >
> > I think OSGi is deemed too over the top for things like this.
> >
> > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
> > <aniket.bhatnagar@gmail.com> wrote:
> > > I am trying to use Kinesis as source to Spark Streaming and have run
> > into a
> > > dependency issue that can't be resolved without making my own custom
> > Spark
> > > build. The issue is that Spark is transitively dependent
> > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because of
> > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is dependent
> > > on org.apache.httpcomponents:httpclient:jar:4.2. When I package and run
> > > Spark Streaming application, I get the following:
> > >
> > > Caused by: java.lang.NoSuchMethodError:
> > >
> >
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
> > >         at
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
> > >         at
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
> > >         at
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
> > >         at
> > >
> >
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
> > >         at
> > >
> >
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
> > >         at
> > > com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
> > >         at
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
> > >         at
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
> > >         at
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
> > >         at
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
> > >         at
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
> > >
> > > I can create a custom Spark build with
> > > org.apache.httpcomponents:httpclient:jar:4.2 included in the assembly
> > but I
> > > was wondering if this is something Spark devs have noticed and are
> > looking
> > > to resolve in near releases. Here are my thoughts on this issue:
> > >
> > > Containers that allow running custom user code have to often resolve
> > > dependency issues in case of conflicts between framework's and user
> > code's
> > > dependency. Here is how I have seen some frameworks resolve the issue:
> > > 1. Provide a child-first class loader: Some JEE containers provided a
> > > child-first class loader that allowed for loading classes from user
> code
> > > first. I don't think this approach completely solves the problem as the
> > > framework is then susceptible to class mismatch errors.
> > > 2. Fold in all dependencies in a sub-package: This approach involves
> > > folding all dependencies in a project specific sub-package (like
> > > spark.dependencies). This approach is tedious because it involves
> > building
> > > custom version of all dependencies (and their transitive dependencies)
> > > 3. Use something like OSGi: Some frameworks has successfully used OSGi
> to
> > > manage dependencies between the modules. The challenge in this approach
> > is
> > > to OSGify the framework and hide OSGi complexities from end user.
> > >
> > > My personal preference is OSGi (or atleast some support for OSGi) but I
> > > would love to hear what Spark devs are thinking in terms of resolving
> the
> > > problem.
> > >
> > > Thanks,
> > > Aniket
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a11c1b90ae968f105023d864d--

From dev-return-9301-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 15:54:52 2014
Return-Path: <dev-return-9301-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C6EC611895
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 15:54:52 +0000 (UTC)
Received: (qmail 49985 invoked by uid 500); 4 Sep 2014 15:54:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49895 invoked by uid 500); 4 Sep 2014 15:54:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49852 invoked by uid 99); 4 Sep 2014 15:54:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 15:54:51 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 15:54:25 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id 5C51810A;
	Thu,  4 Sep 2014 15:54:23 +0000 (UTC)
Received: from G4W6301.americas.hpqcorp.net (16.210.26.226) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Thu, 4 Sep 2014 15:53:27 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.222]) by
 G4W6301.americas.hpqcorp.net ([16.210.26.226]) with mapi id 14.03.0169.001;
 Thu, 4 Sep 2014 15:53:27 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: Xiangrui Meng <mengxr@gmail.com>, RJ Nowling <rnowling@gmail.com>
CC: David Hall <dlwh@cs.berkeley.edu>, "<dev@spark.apache.org>"
	<dev@spark.apache.org>
Subject: RE: Is breeze thread safe in Spark?
Thread-Topic: Is breeze thread safe in Spark?
Thread-Index: Ac/HnEHIpnke8IkPRvauFqDTM2ZjuAAAgQ2AAAJqZoAAAEW8gAAAJdqAAAAqeAAAAF4tAAAqxZAw
Date: Thu, 4 Sep 2014 15:53:25 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FD01780@G4W3292.americas.hpqcorp.net>
References: <2DD1C869-6BDE-4276-B5C3-99A67FB9A713@hp.com>
	<CADtDQQJNT71SmOHAHK1PWG4PRhzsVMZJ5tc5Ur8bqPBFXbygtg@mail.gmail.com>
	<CALW2ey21AaXdJ9-DRkZGWmdg5Zv6wOLwuXoGd7OS+0pAct4CKA@mail.gmail.com>
	<CADtDQQJ7YZb2rOzBhUT6wCpfTCdxPDZGi9f2etqk_vg_zRP2=Q@mail.gmail.com>
	<CALW2ey1rjn9TT-DvYAEbqztRChS8hPGGkW3DqLaYKNaSJg89-A@mail.gmail.com>
	<CADtDQQJd5n_9JN-nB+JQTRgND3UHe9dPKmp0Mm_QQNqh9jhM_w@mail.gmail.com>
 <CAJgQjQ81u=1dZb1M6+adSv+Zvj2DdmJLMcNjQfuW5A3oPqwnGg@mail.gmail.com>
In-Reply-To: <CAJgQjQ81u=1dZb1M6+adSv+Zvj2DdmJLMcNjQfuW5A3oPqwnGg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [15.201.58.18]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9302-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 17:51:14 2014
Return-Path: <dev-return-9302-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 835F311DB8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 17:51:14 +0000 (UTC)
Received: (qmail 96757 invoked by uid 500); 4 Sep 2014 17:51:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96695 invoked by uid 500); 4 Sep 2014 17:51:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96683 invoked by uid 99); 4 Sep 2014 17:51:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 17:51:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tgraves_cs@yahoo.com designates 98.139.212.160 as permitted sender)
Received: from [98.139.212.160] (HELO nm1.bullet.mail.bf1.yahoo.com) (98.139.212.160)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 17:51:05 +0000
Received: from [98.139.215.143] by nm1.bullet.mail.bf1.yahoo.com with NNFMP; 04 Sep 2014 17:50:44 -0000
Received: from [98.139.212.193] by tm14.bullet.mail.bf1.yahoo.com with NNFMP; 04 Sep 2014 17:50:43 -0000
Received: from [127.0.0.1] by omp1002.mail.bf1.yahoo.com with NNFMP; 04 Sep 2014 17:50:43 -0000
X-Yahoo-Newman-Property: ymail-5
X-Yahoo-Newman-Id: 923543.21663.bm@omp1002.mail.bf1.yahoo.com
Received: (qmail 4185 invoked by uid 60001); 4 Sep 2014 17:50:43 -0000
X-YMail-OSG: Nob84QsVM1mWiacciZ_dv6OH3G8srXX_p_fqIACI_Bdcphw
 nHjuByHAvJGXWcr_HEVW_0Sa9wSZ9_z601Z9UFnLrMC1OFgUcimPVKJ9Z7qK
 milTmd4b0Jx4AszuK4ahX4Ega5T892mSLlnsH7hWTjqshMU5DDayDOsl28Gn
 5qTvd3GTwT7eUAt8LbSzcnLnqrIyI20ey48EvV6Pyw91vSZM8bFklgPC.IrS
 1vHtZonEwtYpEd2YlWWYHILEQO6tlzTRxGbghhJW4i0VLK5GLzks_Ajllnuw
 hs9nfzXg9dnTtLcF3WjPfQjf4coCm9jdazde8vJLFKd6J59HQuNWjwRzxu9r
 QP6.NS0tenMBfAU9cIeS9.NtvZeU9opLlPHx0v77zgvcRiDG3hqulFMf1G5D
 3J2FjmRKGoO2k6mtdcu7CLsNFzvPOyS80FBhjJu34Z2JAQqTTQXB80L.D3zL
 YMyCYUGeLyDKEMxCL2hbvo5vhu_prQdR9WAmrXIHUyRe7fcrmH2YxKgdOPnl
 BOCR.lcqEeHC.EEMRAgPWxiG39N.jWy0MEUFCjSWyYPV9KIa1UNKTrQ79PBn
 qh.TQN6Vd3a0s8lKswXfpU9vzhWK9x0qO9T35EpYfk8MCNKTP2qhspEFuDm0
 w3ro-
Received: from [209.131.52.50] by web140101.mail.bf1.yahoo.com via HTTP; Thu, 04 Sep 2014 10:50:43 PDT
X-Rocket-MIMEInfo: 002.001,KzEuIFJhbiBzcGFyayBvbiB5YXJuIG9uIGhhZG9vcCAwLjIzIGFuZCAyLnguCgpUb20KCgpPbiBXZWRuZXNkYXksIFNlcHRlbWJlciAzLCAyMDE0IDI6MjUgQU0sIFBhdHJpY2sgV2VuZGVsbCA8cHdlbmRlbGxAZ21haWwuY29tPiB3cm90ZToKIAoKClBsZWFzZSB2b3RlIG9uIHJlbGVhc2luZyB0aGUgZm9sbG93aW5nIGNhbmRpZGF0ZSBhcyBBcGFjaGUgU3BhcmsgdmVyc2lvbiAxLjEuMCEKClRoZSB0YWcgdG8gYmUgdm90ZWQgb24gaXMgdjEuMS4wLXJjNCAoY29tbWl0IDJmOWIyYmQpOgpodHRwczovL2dpdC0BMAEBAQE-
X-Mailer: YahooMailWebService/0.8.201.700
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com> 
Message-ID: <1409853043.87709.YahooMailNeo@web140101.mail.bf1.yahoo.com>
Date: Thu, 4 Sep 2014 10:50:43 -0700
From: Tom Graves <tgraves_cs@yahoo.com.INVALID>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Patrick Wendell <pwendell@gmail.com>,
  "dev@spark.apache.org" <dev@spark.apache.org>
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="584511794-1860976142-1409853043=:87709"
X-Virus-Checked: Checked by ClamAV on apache.org

--584511794-1860976142-1409853043=:87709
Content-Type: text/plain; charset=us-ascii

+1. Ran spark on yarn on hadoop 0.23 and 2.x.

Tom


On Wednesday, September 3, 2014 2:25 AM, Patrick Wendell <pwendell@gmail.com> wrote:
 


Please vote on releasing the following candidate as Apache Spark version 1.1.0!

The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.1.0-rc4/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1031/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/

Please vote on releasing this package as Apache Spark 1.1.0!

The vote is open until Saturday, September 06, at 08:30 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.1.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

== Regressions fixed since RC3 ==
SPARK-3332 - Issue with tagging in EC2 scripts
SPARK-3358 - Issue with regression for m3.XX instances

== What justifies a -1 vote for this release? ==
This vote is happening very late into the QA period compared with
previous votes, so -1 votes should only occur for significant
regressions from 1.0.2. Bugs already present in 1.0.X will not block
this release.

== What
 default changes should I be aware of? ==
1. The default value of "spark.io.compression.codec" is now "snappy"
--> Old behavior can be restored by switching to "lzf"

2. PySpark now performs external spilling during aggregations.
--> Old behavior can be restored by setting "spark.shuffle.spill" to "false".

3. PySpark uses a new heuristic for determining the parallelism of
shuffle operations.
--> Old behavior can be restored by setting
"spark.default.parallelism" to the number of cores in the cluster.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--584511794-1860976142-1409853043=:87709--

From dev-return-9303-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 17:51:17 2014
Return-Path: <dev-return-9303-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA4CB11DB9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 17:51:17 +0000 (UTC)
Received: (qmail 97986 invoked by uid 500); 4 Sep 2014 17:51:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97921 invoked by uid 500); 4 Sep 2014 17:51:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97895 invoked by uid 99); 4 Sep 2014 17:51:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 17:51:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gurvinder.singh@uninett.no designates 158.38.180.100 as permitted sender)
Received: from [158.38.180.100] (HELO epost.uninett.no) (158.38.180.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 17:50:46 +0000
Received: from [192.168.0.100] (141.12.189.109.customer.cdi.no [109.189.12.141])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by epost.uninett.no (Postfix) with ESMTPSA id CF1453363F8
	for <dev@spark.apache.org>; Thu,  4 Sep 2014 19:50:45 +0200 (CEST)
Message-ID: <5408A675.4030400@uninett.no>
Date: Thu, 04 Sep 2014 19:50:45 +0200
From: Gurvinder Singh <gurvinder.singh@uninett.no>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.6.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com> <CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com>
In-Reply-To: <CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On 09/03/2014 04:23 PM, Nicholas Chammas wrote:
> On Wed, Sep 3, 2014 at 3:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> 
>> == What default changes should I be aware of? ==
>> 1. The default value of "spark.io.compression.codec" is now "snappy"
>> --> Old behavior can be restored by switching to "lzf"
>>
>> 2. PySpark now performs external spilling during aggregations.
>> --> Old behavior can be restored by setting "spark.shuffle.spill" to
>> "false".
>>
>> 3. PySpark uses a new heuristic for determining the parallelism of
>> shuffle operations.
>> --> Old behavior can be restored by setting
>> "spark.default.parallelism" to the number of cores in the cluster.
>>
> 
> Will these changes be called out in the release notes or somewhere in the
> docs?
> 
> That last one (which I believe is what we discovered as the result of
> SPARK-3333 <https://issues.apache.org/jira/browse/SPARK-3333>) could have a
> large impact on PySpark users.

Just wanted to add, it might be related to this issue or different.
There is a regression when using pyspark to read data
from HDFS. its performance during map tasks has gone down approx 1 ->
0.5x. I have tested the 1.0.2 and the performance was fine, but the 1.1
release candidate has this issue. I tested by setting the following
properties to make sure it was not due to these.

set("spark.io.compression.codec","lzf").set("spark.shuffle.spill","false")

in conf object.

Regards,
Gurvinder
> 
> Nick
> 


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9304-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 18:22:35 2014
Return-Path: <dev-return-9304-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 11E4F11F5C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 18:22:35 +0000 (UTC)
Received: (qmail 26576 invoked by uid 500); 4 Sep 2014 18:22:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26515 invoked by uid 500); 4 Sep 2014 18:22:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26503 invoked by uid 99); 4 Sep 2014 18:22:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 18:22:33 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 18:22:27 +0000
Received: by mail-la0-f50.google.com with SMTP id mc6so12362073lab.37
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 11:22:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=WXtf9eHyh9JJfSHDMnZUNvnUwgSENA+Q2PU17SKjJac=;
        b=ufsp3wBkVLWho6hYC51i7JPMwED0xHG7o5q9Cyrremosn2TxAgmhYZMCechWcziVki
         il0PbO0VKNFUKgpThS+UOp3rpGfNHSK1IXgsGBHEutE7EIm+Tu+xyXDs1cybIfkauDRk
         dYmSui1mSKaXrSDckhzK+HolUI2qC5z2ZbRg8sOgcASOLfUUo1CTXQjAkWmmyccZXXM3
         Hi6JIm5duImxTyhanB0h98GRlnbTajnUX4wpklupxFa0TGo3f/ebMFxDI/IhSGnGcklm
         Ikw+HspO4N9PS1vUK9eSma6O/UbdKChfwMqTcC0sb5kpcA8PaQc+CTtk+FzaOcZ2HRTi
         Atow==
MIME-Version: 1.0
X-Received: by 10.112.98.198 with SMTP id ek6mr6165693lbb.22.1409854926434;
 Thu, 04 Sep 2014 11:22:06 -0700 (PDT)
Received: by 10.25.205.204 with HTTP; Thu, 4 Sep 2014 11:22:06 -0700 (PDT)
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Date: Thu, 4 Sep 2014 11:22:06 -0700
Message-ID: <CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

LICENSE and NOTICE files are good
Hash files are good
Signature files are good
No 3rd parties executables
Source compiled
Run local and standalone tests
Test persist off heap with Tachyon looks good

+1

- Henry

On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.1.0!
>
> The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1031/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
>
> Please vote on releasing this package as Apache Spark 1.1.0!
>
> The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.1.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == Regressions fixed since RC3 ==
> SPARK-3332 - Issue with tagging in EC2 scripts
> SPARK-3358 - Issue with regression for m3.XX instances
>
> == What justifies a -1 vote for this release? ==
> This vote is happening very late into the QA period compared with
> previous votes, so -1 votes should only occur for significant
> regressions from 1.0.2. Bugs already present in 1.0.X will not block
> this release.
>
> == What default changes should I be aware of? ==
> 1. The default value of "spark.io.compression.codec" is now "snappy"
> --> Old behavior can be restored by switching to "lzf"
>
> 2. PySpark now performs external spilling during aggregations.
> --> Old behavior can be restored by setting "spark.shuffle.spill" to "false".
>
> 3. PySpark uses a new heuristic for determining the parallelism of
> shuffle operations.
> --> Old behavior can be restored by setting
> "spark.default.parallelism" to the number of cores in the cluster.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9305-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 19:25:49 2014
Return-Path: <dev-return-9305-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3E3F6111C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 19:25:49 +0000 (UTC)
Received: (qmail 97107 invoked by uid 500); 4 Sep 2014 19:25:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97047 invoked by uid 500); 4 Sep 2014 19:25:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97036 invoked by uid 99); 4 Sep 2014 19:25:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 19:25:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 19:25:42 +0000
Received: by mail-lb0-f177.google.com with SMTP id z11so12271588lbi.36
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 12:25:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=Abu6Q+DCOeZDbf/igzsyWHEmCO8SWkk/pocAhr49T1Q=;
        b=NtJWGmcn7M/tjL1rQhk5gXGnUmHuFR5XgV27ktqruYY8ynExf78Obt6pvAzCcffNVi
         Nfx/BaepWLLFdOKoW+1NaPKE71bIl4Y9I0v1hMsxu82aWIXFw0fztE0SOLH58OtUpFcs
         7mQNTNmBKu2mxWzpvBF8yh6TYjnKCsWDeK6yIWegSLZ1PnIX9MK61Gv+wGAMNXN1FSD+
         ncFKtIPgGY4LnIl2H06naSDsnOYGmE12HkSn3jNHTJjm0Ol2vM7TwWJEnFYCJ1ae2n5T
         edUPpdCXo80vUwt61DPMCaVYLUao5/8+0Y8MN2EOfJradNHnRFcEHtVTluctAC+ZbLmN
         XQEA==
X-Gm-Message-State: ALoCoQmn+xa+xWZJB9RQv/2dLF9/t5J8wdl1BFUOTcgHc3Lc0PI1aKG1Jbu2Tvyljmd64mVgCjX0
X-Received: by 10.152.115.232 with SMTP id jr8mr6745630lab.69.1409858720558;
 Thu, 04 Sep 2014 12:25:20 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 12:25:00 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 12:25:00 -0700
Message-ID: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
Subject: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c34e6838fcc405024250c9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34e6838fcc405024250c9
Content-Type: text/plain; charset=UTF-8

i am trying to get things up and running, but it looks like either the
firewall gateway or jenkins server itself is down.  i'll update as soon as
i know more.

--001a11c34e6838fcc405024250c9--

From dev-return-9306-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 19:28:45 2014
Return-Path: <dev-return-9306-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 285F6111D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 19:28:45 +0000 (UTC)
Received: (qmail 2815 invoked by uid 500); 4 Sep 2014 19:28:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2751 invoked by uid 500); 4 Sep 2014 19:28:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2739 invoked by uid 99); 4 Sep 2014 19:28:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 19:28:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.53 as permitted sender)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 19:28:18 +0000
Received: by mail-la0-f53.google.com with SMTP id q1so3873800lam.40
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 12:28:17 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=KtUI+LFJOpKh3fm0bvN4YrRs33n89lSj/A80k2eMQeE=;
        b=Cb6OI1okwUF0Ha9xT49BOMCsTboc+yO6PTysm4gFQRVUyoJz/tupCgV5R6jn6zzUvv
         IBwSj2h5jr+GDkg/lkpVxaxMjNO8QlOZkkxKZwgJG08H3tt/nKV28sYPSUPv40TpRERV
         ogKz958HAbl6ttlo2V2ObNFXkVzePy9L1UJYG0ox7/KxKd7sVWjYRcDjp1OFEmGjRotu
         dvKgpmecaXqUuz+1GbO8C2tqB8jiz+h09LlLpfPscP3xOJpW94WV/Bgiw/kooQGHf+28
         CCM+fzxCMS2RrrtqgsFtRgwH1tm70nJhWDbnhLSyPcnxl2bhAzsZ9pXlHDSaspdQd9SI
         XGmw==
X-Gm-Message-State: ALoCoQkUotQ62CQc5I42NtsHq90YLbqyGL2CiPjCLZjW7CygT6snKdaolU58ybJedstGrBTOIzpc
X-Received: by 10.112.184.161 with SMTP id ev1mr6256004lbc.82.1409858897393;
 Thu, 04 Sep 2014 12:28:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 12:27:57 -0700 (PDT)
In-Reply-To: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 12:27:57 -0700
Message-ID: <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c31d0ec351750502425a2d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c31d0ec351750502425a2d
Content-Type: text/plain; charset=UTF-8

looks like a power outage in soda hall.  more updates as they happen.


On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i am trying to get things up and running, but it looks like either the
> firewall gateway or jenkins server itself is down.  i'll update as soon as
> i know more.
>

--001a11c31d0ec351750502425a2d--

From dev-return-9307-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 20:11:06 2014
Return-Path: <dev-return-9307-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B08AC113B9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 20:11:06 +0000 (UTC)
Received: (qmail 7000 invoked by uid 500); 4 Sep 2014 20:11:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6935 invoked by uid 500); 4 Sep 2014 20:11:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6918 invoked by uid 99); 4 Sep 2014 20:11:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:11:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.42 as permitted sender)
Received: from [209.85.216.42] (HELO mail-qa0-f42.google.com) (209.85.216.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:10:37 +0000
Received: by mail-qa0-f42.google.com with SMTP id dc16so6004707qab.1
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 13:10:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=O9fLKTpmJGS/zMxg4vsGDnsL3oAYA/q2TSj0/bf5RYc=;
        b=Q7BKq7Q9xvhTlCq9SODuf1j8ks5WxgSfcBzL7VUGzPyuKVTtl1sw+baS3kK8C9s/1N
         +ZnEI2pbXhIECvvE1LFkFim1GubDeUDQscOy2/V0nkRHNEfyi87Vgi+rV+Ra91Akwi5S
         RPMC6+ODKhb+/FIAHzrMwX7QTPaM1U5DA176HLgq0dxBGLniz1p7yIV8Kv+pC2bX6uvh
         +a4m39o67wR8mmFQLJ99Ef5MVu51dQTq4B2Yt2xGRxr7jXRLZ4zsYGruNEtjL3obVbxj
         feiX1Y/UkGeLdAZT1VsfL1uNE6pYSBRfIRwkwOY8kOS6zXdeiWWUSC+8jGsgYrFQcUtS
         VJDA==
MIME-Version: 1.0
X-Received: by 10.140.97.131 with SMTP id m3mr10357207qge.80.1409861435527;
 Thu, 04 Sep 2014 13:10:35 -0700 (PDT)
Received: by 10.140.32.197 with HTTP; Thu, 4 Sep 2014 13:10:35 -0700 (PDT)
In-Reply-To: <CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
Date: Fri, 5 Sep 2014 00:10:35 +0400
Message-ID: <CAMrx5DxVwNZo4DajGgbQh3fuQmyDFBDLTo5a64on9QaoB=XUZQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Henry Saputra <henry.saputra@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a99060cd2fd050242f288
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a99060cd2fd050242f288
Content-Type: text/plain; charset=UTF-8

+1

Compiled, ran on yarn-hadoop-2.3 simple job.


2014-09-04 22:22 GMT+04:00 Henry Saputra <henry.saputra@gmail.com>:

> LICENSE and NOTICE files are good
> Hash files are good
> Signature files are good
> No 3rd parties executables
> Source compiled
> Run local and standalone tests
> Test persist off heap with Tachyon looks good
>
> +1
>
> - Henry
>
> On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Please vote on releasing the following candidate as Apache Spark version
> 1.1.0!
> >
> > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> >
> > The release files, including signatures, digests, etc. can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-1031/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> >
> > Please vote on releasing this package as Apache Spark 1.1.0!
> >
> > The vote is open until Saturday, September 06, at 08:30 UTC and passes if
> > a majority of at least 3 +1 PMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 1.1.0
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.apache.org/
> >
> > == Regressions fixed since RC3 ==
> > SPARK-3332 - Issue with tagging in EC2 scripts
> > SPARK-3358 - Issue with regression for m3.XX instances
> >
> > == What justifies a -1 vote for this release? ==
> > This vote is happening very late into the QA period compared with
> > previous votes, so -1 votes should only occur for significant
> > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > this release.
> >
> > == What default changes should I be aware of? ==
> > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > --> Old behavior can be restored by switching to "lzf"
> >
> > 2. PySpark now performs external spilling during aggregations.
> > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> "false".
> >
> > 3. PySpark uses a new heuristic for determining the parallelism of
> > shuffle operations.
> > --> Old behavior can be restored by setting
> > "spark.default.parallelism" to the number of cores in the cluster.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a113a99060cd2fd050242f288--

From dev-return-9308-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 20:20:10 2014
Return-Path: <dev-return-9308-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9DB9511400
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 20:20:10 +0000 (UTC)
Received: (qmail 37548 invoked by uid 500); 4 Sep 2014 20:20:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37475 invoked by uid 500); 4 Sep 2014 20:20:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37464 invoked by uid 99); 4 Sep 2014 20:20:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:20:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:19:44 +0000
Received: by mail-lb0-f172.google.com with SMTP id c11so4044707lbj.3
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 13:19:43 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=Etn/RTGym1uTZhapOpCOVrjMaKOCUlN4xLF/CeSbRR8=;
        b=a+ia8j5nX2dgBUmkc+ODoSrCMZNL88h7U4g/k0CEuorTS0OpUJrsqj+uqiG3Tw/WFf
         W0FzorOcvtltOJkiQFWMN3O9HwPhNrdIH37D220ZCnaQdLK9b5KcduFTSo54b8+NOsUj
         j5Qg+Ngyz48X5CyFTS5IqQyaZHK/fyCZS0Odm5yw+psYUVMsg+vQy7uQlWdH1u+OEFUG
         BX7VLblZQc5DZgrsUiXT4n/JfT5VUuVsGSB/ypdeZu9xFZXvBWv+inuIgae/EqyXQQdZ
         2Ah1w2a9lAkzhJdXpPErTzTlFms4kylmGb0WSh5BGzh5Jgw+y/VIKSjSk0n5IKsAkUnn
         vsSQ==
X-Gm-Message-State: ALoCoQk7+ZNGokF3rafrlpTlcu1/cWb/iGuyCJcoPrY+a0SGk9u3rqN5opDGID3y8tXu0l11LrCp
X-Received: by 10.112.160.163 with SMTP id xl3mr6669073lbb.80.1409861982929;
 Thu, 04 Sep 2014 13:19:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 13:19:22 -0700 (PDT)
In-Reply-To: <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 13:19:22 -0700
Message-ID: <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c34262acd21205024312d1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34262acd21205024312d1
Content-Type: text/plain; charset=UTF-8

looks like some hardware failed, and we're swapping in a replacement.  i
don't have more specific information yet -- including *what* failed, as our
sysadmin is super busy ATM.  the root cause was an incorrect circuit being
switched off during building maintenance.

on a side note, this incident will be accelerating our plan to move the
entire jenkins infrastructure in to a managed datacenter environment.  this
will be our major push over the next couple of weeks.  more details about
this, also, as soon as i get them.

i'm very sorry about the downtime, we'll get everything up and running ASAP.


On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu> wrote:

> looks like a power outage in soda hall.  more updates as they happen.
>
>
> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i am trying to get things up and running, but it looks like either the
>> firewall gateway or jenkins server itself is down.  i'll update as soon as
>> i know more.
>>
>
>

--001a11c34262acd21205024312d1--

From dev-return-9309-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 20:28:07 2014
Return-Path: <dev-return-9309-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED40E11462
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 20:28:06 +0000 (UTC)
Received: (qmail 67384 invoked by uid 500); 4 Sep 2014 20:28:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67316 invoked by uid 500); 4 Sep 2014 20:28:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67304 invoked by uid 99); 4 Sep 2014 20:28:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:28:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:27:40 +0000
Received: by mail-lb0-f172.google.com with SMTP id c11so3990358lbj.17
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 13:27:39 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=Qc2sRZUgC0JFBwcbu3OHIfIDjVVzYB1LHLlgZWLDcfs=;
        b=U+Mgtn0bDMQHCYjDymj8ncY/uH94BGC3Uf5xbrWSzFqvw4J6Z8HtG7O/eLD7RDG3+B
         rtOFfIt4cM0QrOyPJfLReSFDRzE7zSCHIzqtOd9Y8lcGqP4+8ls/QkShhrlxCU0Y+5hR
         G+CTE0qqQM4Hmq9H1rkNtI41O0bvF7sFhQUADq6xAe17Et13YXsPPAggS0x4pk3Lqu/I
         iECMzl7ZqLnVMi6WTCDbfaNxG6PEIBuyjeMJHUzaXdhX8sg0gFxE651BSGV/OcibZ6UL
         4566B3wjZlc7uiZtqaiZWY/P5AjcmXsZr0c/Q0K6CIyYYHNmTY6VIR60zSVr6Q7IE0fT
         e9sw==
X-Gm-Message-State: ALoCoQnXrONQkDRc8BI9BMoT5WmvJmX3gSr7fgpGHUfdqASWpO3Nlxje8b2d50r80TeLahlKm+za
X-Received: by 10.152.4.9 with SMTP id g9mr7268117lag.14.1409862459739; Thu,
 04 Sep 2014 13:27:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 13:27:19 -0700 (PDT)
In-Reply-To: <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com> <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 13:27:19 -0700
Message-ID: <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=089e013d1708185cc10502432f7f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d1708185cc10502432f7f
Content-Type: text/plain; charset=UTF-8

it's a faulty power switch on the firewall, which has been swapped out.
 we're about to reboot and be good to go.


On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu> wrote:

> looks like some hardware failed, and we're swapping in a replacement.  i
> don't have more specific information yet -- including *what* failed, as our
> sysadmin is super busy ATM.  the root cause was an incorrect circuit being
> switched off during building maintenance.
>
> on a side note, this incident will be accelerating our plan to move the
> entire jenkins infrastructure in to a managed datacenter environment.  this
> will be our major push over the next couple of weeks.  more details about
> this, also, as soon as i get them.
>
> i'm very sorry about the downtime, we'll get everything up and running
> ASAP.
>
>
> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> looks like a power outage in soda hall.  more updates as they happen.
>>
>>
>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> i am trying to get things up and running, but it looks like either the
>>> firewall gateway or jenkins server itself is down.  i'll update as soon as
>>> i know more.
>>>
>>
>>
>

--089e013d1708185cc10502432f7f--

From dev-return-9310-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 20:28:45 2014
Return-Path: <dev-return-9310-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CAE0D11465
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 20:28:45 +0000 (UTC)
Received: (qmail 68959 invoked by uid 500); 4 Sep 2014 20:28:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68896 invoked by uid 500); 4 Sep 2014 20:28:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68884 invoked by uid 99); 4 Sep 2014 20:28:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:28:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.173 as permitted sender)
Received: from [74.125.82.173] (HELO mail-we0-f173.google.com) (74.125.82.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 20:28:19 +0000
Received: by mail-we0-f173.google.com with SMTP id t60so10791930wes.32
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 13:28:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=LAFJpWMxsfN/E1gFcxeyRyDsu2NIWuprdKBQBzkOyvU=;
        b=cNfN7J+M4tk6Fgc6Am9lWVBuPGYDpLJUzGJy2mkfqJ4EIb0hJMUfRYoZ6pPdxn6zTB
         //AX69S/kF3e/yboAjbJgdMM6/qQzl9jBOJ+Z3wbt+2hkfZ3qfj9xkVJJXrpb2yPPlAn
         DWwNI85uRIxJXgdeTqBLwr7VjW55MEqTaRQw/bOHokSjj0aTAKDqglW7i6i2XrLytsp9
         lBAUIptZMd4sNt6M6cEuLV+3QzFE7m/QgGWH0ZHmXEsuenzZft2PasdgeLXZjs4ZN57s
         I7enUMHxmFfShhC9XsYEwZUXZ+4YefcQYl7w2aoqp4t3tGuorGieYpDhbFcoJMEgtRq1
         4Rjw==
X-Received: by 10.194.59.18 with SMTP id v18mr9480566wjq.64.1409862497077;
 Thu, 04 Sep 2014 13:28:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Thu, 4 Sep 2014 13:27:37 -0700 (PDT)
In-Reply-To: <5408A675.4030400@uninett.no>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CAOhmDzdS36wtZZk2xNyaGDXRuyeiOW3t0Yic1hdnziaKjQcRgQ@mail.gmail.com> <5408A675.4030400@uninett.no>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 4 Sep 2014 16:27:37 -0400
Message-ID: <CAOhmDzfuqSQ5rmX7rszJQPnPjLUYof5_7TUF1AnWud5PUhxW0Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bacb0a652121e0502433150
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bacb0a652121e0502433150
Content-Type: text/plain; charset=UTF-8

On Thu, Sep 4, 2014 at 1:50 PM, Gurvinder Singh <gurvinder.singh@uninett.no>
wrote:

> There is a regression when using pyspark to read data
> from HDFS.
>

Could you open a JIRA <http://issues.apache.org/jira/> with a brief repro?
We'll look into it.

(You could also provide a repro in a separate thread.)

Nick

--047d7bacb0a652121e0502433150--

From dev-return-9311-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 21:15:02 2014
Return-Path: <dev-return-9311-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8930C115C3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 21:15:02 +0000 (UTC)
Received: (qmail 74564 invoked by uid 500); 4 Sep 2014 21:15:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74501 invoked by uid 500); 4 Sep 2014 21:15:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74490 invoked by uid 99); 4 Sep 2014 21:15:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:15:01 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of talktorohit54@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:14:56 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <talktorohit54@gmail.com>)
	id 1XPeMW-00046I-Dn
	for dev@spark.incubator.apache.org; Thu, 04 Sep 2014 14:14:36 -0700
Date: Thu, 4 Sep 2014 14:14:36 -0700 (PDT)
From: randomuser54 <talktorohit54@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409865276418-8278.post@n3.nabble.com>
In-Reply-To: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

+1



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-1-0-RC4-tp8219p8278.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9312-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 21:17:41 2014
Return-Path: <dev-return-9312-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A75B6115E2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 21:17:41 +0000 (UTC)
Received: (qmail 84815 invoked by uid 500); 4 Sep 2014 21:17:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84751 invoked by uid 500); 4 Sep 2014 21:17:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84740 invoked by uid 99); 4 Sep 2014 21:17:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:17:40 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of talktorohit54@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:17:35 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <talktorohit54@gmail.com>)
	id 1XPeP5-0004Uj-5z
	for dev@spark.incubator.apache.org; Thu, 04 Sep 2014 14:17:15 -0700
Date: Thu, 4 Sep 2014 14:17:15 -0700 (PDT)
From: randomuser54 <talktorohit54@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409865435175-8279.post@n3.nabble.com>
Subject: How to kill a Spark job running in local mode programmatically ?
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I have a java class which calls SparkSubmit.scala with all the arguments to
run a spark job in a thread. I am running them in local mode for now but
also want to run them in yarn-cluster mode later.

Now, I want to kill the running spark job (which can be in local or
yarn-cluster mode) programmatically.

I know that SparkContext has a stop() method but from the thread from which
I am calling the SparkSubmit I don=E2=80=99t have access to it. Can someone=
 suggest
me how to do this properly ?

Thanks.




--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/How-to-kill-a-Spark-job-running-in-local-mode-programmatically=
-tp8279.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9313-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 21:37:56 2014
Return-Path: <dev-return-9313-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D92291169C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 21:37:56 +0000 (UTC)
Received: (qmail 40517 invoked by uid 500); 4 Sep 2014 21:37:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40438 invoked by uid 500); 4 Sep 2014 21:37:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40427 invoked by uid 99); 4 Sep 2014 21:37:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:37:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.178 as permitted sender)
Received: from [209.85.217.178] (HELO mail-lb0-f178.google.com) (209.85.217.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:37:51 +0000
Received: by mail-lb0-f178.google.com with SMTP id v6so12320444lbi.37
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 14:37:30 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=D8r7bYxtz4hBVYTYAFJWpr8FwL2S1HwzvXe78rLXUxs=;
        b=X+MEfCW+0vU5rh1KhVpWz6m/45ZRzwlMpPjGXhAjKMT9OvK7QTY3J6hij0snv3BrOP
         lG8OccKx7EmywxiPdUs696d/YHaGyP/m0ZTsudtt4mxKHUlghHQrz9oaxFJg8OCuYJ4X
         /HlBUG4WcAqxylx60hn3DaNxWALZHSdYBi6PZ9+ny0agMbMSNW1iKA7zcsYaSfCf3WKr
         PQeo1kQ/YNfCnJSnPXrJUrt40XxdXe5XvTz0al6CVGc9NwmFlC/Rk5Eh/PxoTPvv9UPe
         G8HARVOE4qgpV4uXDV67VErSN5JjgZzc00eOgbGQ0vVbl8M/ea6NEYMkyJQVR8k/bRv0
         euPQ==
X-Gm-Message-State: ALoCoQkOMLP2HWRGedwQDQwXyAIERcWoHq+Lk4/T0Ga6RgMPFSOIDr6Vg3h4H3CCh+nAZf4PpHK8
X-Received: by 10.112.4.70 with SMTP id i6mr7135559lbi.54.1409866650094; Thu,
 04 Sep 2014 14:37:30 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 14:37:09 -0700 (PDT)
In-Reply-To: <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com> <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 14:37:09 -0700
Message-ID: <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=14dae94ed6cddc1bf0050244282d
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae94ed6cddc1bf0050244282d
Content-Type: text/plain; charset=UTF-8

AND WE'RE UP!

sorry that this took so long...  i'll send out a more detailed explanation
of what happened soon.

now, off to back up jenkins.

shane


On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu> wrote:

> it's a faulty power switch on the firewall, which has been swapped out.
>  we're about to reboot and be good to go.
>
>
> On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> looks like some hardware failed, and we're swapping in a replacement.  i
>> don't have more specific information yet -- including *what* failed, as our
>> sysadmin is super busy ATM.  the root cause was an incorrect circuit being
>> switched off during building maintenance.
>>
>> on a side note, this incident will be accelerating our plan to move the
>> entire jenkins infrastructure in to a managed datacenter environment.  this
>> will be our major push over the next couple of weeks.  more details about
>> this, also, as soon as i get them.
>>
>> i'm very sorry about the downtime, we'll get everything up and running
>> ASAP.
>>
>>
>> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> looks like a power outage in soda hall.  more updates as they happen.
>>>
>>>
>>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>> i am trying to get things up and running, but it looks like either the
>>>> firewall gateway or jenkins server itself is down.  i'll update as soon as
>>>> i know more.
>>>>
>>>
>>>
>>
>

--14dae94ed6cddc1bf0050244282d--

From dev-return-9314-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 21:46:08 2014
Return-Path: <dev-return-9314-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 98FC8116D6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 21:46:08 +0000 (UTC)
Received: (qmail 56594 invoked by uid 500); 4 Sep 2014 21:46:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56530 invoked by uid 500); 4 Sep 2014 21:46:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56513 invoked by uid 99); 4 Sep 2014 21:46:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:46:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:45:41 +0000
Received: by mail-la0-f47.google.com with SMTP id el20so4094489lab.6
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 14:45:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=0VLaCEVVTwjpqIvh87gviOFmYf2c2Tx/kgxYFmBVeZg=;
        b=Qpo1zT9pnTq6O2yCfA0rVptLzdh8XstLG+32uj4ITTmdNfePUAKHwVfu094waeGODu
         JLwWw78KV2uavj0Q9UhCkFdzLHwXELBV7Z2z5zIP7PPsdBL/ZCwKylDnjSPglG5dW2I+
         py3ith++ZkNec1mQ40/APGVWqit1lj0yy3sHRicdp+IerC3KmfsFx67NIKL52muntBb1
         F++SFZ/b6Kj7zH7HUQRC+zVhr6i8cLe2rdZiS7hloSqH3uO14wLblIGU7wd+LezGHvfN
         HGp8kL1hhpxzpxTg1wXQve2/7Eaa54B8qur7MAdFNBj23REvWqjAEAPklLtTpGVVdYZq
         4EMQ==
X-Received: by 10.112.202.69 with SMTP id kg5mr7034532lbc.33.1409867141120;
 Thu, 04 Sep 2014 14:45:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.7.166 with HTTP; Thu, 4 Sep 2014 14:45:01 -0700 (PDT)
In-Reply-To: <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com> <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 4 Sep 2014 17:45:01 -0400
Message-ID: <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c3712e2088200502444647
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3712e2088200502444647
Content-Type: text/plain; charset=UTF-8

Woohoo! Thanks Shane.

Do you know if queued PR builds will automatically be picked up? Or do we
have to ping the Jenkinmensch manually from each PR?

Nick


On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu> wrote:

> AND WE'RE UP!
>
> sorry that this took so long...  i'll send out a more detailed explanation
> of what happened soon.
>
> now, off to back up jenkins.
>
> shane
>
>
> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
> > it's a faulty power switch on the firewall, which has been swapped out.
> >  we're about to reboot and be good to go.
> >
> >
> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu> wrote:
> >
> >> looks like some hardware failed, and we're swapping in a replacement.  i
> >> don't have more specific information yet -- including *what* failed, as
> our
> >> sysadmin is super busy ATM.  the root cause was an incorrect circuit
> being
> >> switched off during building maintenance.
> >>
> >> on a side note, this incident will be accelerating our plan to move the
> >> entire jenkins infrastructure in to a managed datacenter environment.
> this
> >> will be our major push over the next couple of weeks.  more details
> about
> >> this, also, as soon as i get them.
> >>
> >> i'm very sorry about the downtime, we'll get everything up and running
> >> ASAP.
> >>
> >>
> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>
> >>> looks like a power outage in soda hall.  more updates as they happen.
> >>>
> >>>
> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
> >>> wrote:
> >>>
> >>>> i am trying to get things up and running, but it looks like either the
> >>>> firewall gateway or jenkins server itself is down.  i'll update as
> soon as
> >>>> i know more.
> >>>>
> >>>
> >>>
> >>
> >
>

--001a11c3712e2088200502444647--

From dev-return-9315-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 21:50:46 2014
Return-Path: <dev-return-9315-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 30D971170D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 21:50:46 +0000 (UTC)
Received: (qmail 68811 invoked by uid 500); 4 Sep 2014 21:50:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68745 invoked by uid 500); 4 Sep 2014 21:50:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68734 invoked by uid 99); 4 Sep 2014 21:50:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:50:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 21:50:18 +0000
Received: by mail-la0-f50.google.com with SMTP id mc6so12694970lab.37
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 14:50:17 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=zCin7UvaI9dVcGwn/c67lB9F5H8NIBKr/1JhoAUlayQ=;
        b=cqdMpDhSaK+77a7JRbhTKlEdB7qryxKy2u4YgTtHCcsaKZ19cyJZcxQ6qgJRcGFyQT
         Ny7cKwGa1qPpZrHlTj4gNGu5DGKd0b8PxkRywTsS7HZwaChPy0QO0pEk3F8BgLcbSxkX
         JbzV8a1zGBQWBoudiI6GZRHwkMG5dvyRK8v6rGFm+ebEbBWi9S08m7vmmBgVO1Z2zCQS
         nHNdQIFOwA4T0RcUjnsuqLyxcm01CTalh1Pj+WxM6isBdhIp9Vk6f2EqQhCSATdYzfEb
         EpnRWWU24j1RaFWZ9hfxGALwdGoYwXX+xSIIRJnUCqZz/k97cIadQk47dB/+r5uJgyLj
         +tzQ==
X-Gm-Message-State: ALoCoQmP9gQunDYejGy5Bmgs+xqdykKa6MLj+uo4Cm4RCU21nn62N9xmJcdryGDsREn8r7tyrbt3
X-Received: by 10.112.55.238 with SMTP id v14mr6827471lbp.93.1409867417428;
 Thu, 04 Sep 2014 14:50:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 14:49:57 -0700 (PDT)
In-Reply-To: <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com> <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 14:49:57 -0700
Message-ID: <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: amp-infra <amp-infra@googlegroups.com>
Cc: dev <dev@spark.apache.org>, Mike Patterson <mike@databricks.com>, 
	Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a1133c96698b1420502445671
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133c96698b1420502445671
Content-Type: text/plain; charset=UTF-8

i'd ping the Jenkinsmench...  the master was completely offline, so any new
jobs wouldn't have reached it.  any jobs that were queued when power was
lost probably started up, but jobs that were running would fail.


On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Woohoo! Thanks Shane.
>
> Do you know if queued PR builds will automatically be picked up? Or do we
> have to ping the Jenkinmensch manually from each PR?
>
> Nick
>
>
> On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> AND WE'RE UP!
>>
>> sorry that this took so long...  i'll send out a more detailed explanation
>> of what happened soon.
>>
>> now, off to back up jenkins.
>>
>> shane
>>
>>
>> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>> > it's a faulty power switch on the firewall, which has been swapped out.
>> >  we're about to reboot and be good to go.
>> >
>> >
>> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >
>> >> looks like some hardware failed, and we're swapping in a replacement.
>> i
>> >> don't have more specific information yet -- including *what* failed,
>> as our
>> >> sysadmin is super busy ATM.  the root cause was an incorrect circuit
>> being
>> >> switched off during building maintenance.
>> >>
>> >> on a side note, this incident will be accelerating our plan to move the
>> >> entire jenkins infrastructure in to a managed datacenter environment.
>> this
>> >> will be our major push over the next couple of weeks.  more details
>> about
>> >> this, also, as soon as i get them.
>> >>
>> >> i'm very sorry about the downtime, we'll get everything up and running
>> >> ASAP.
>> >>
>> >>
>> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >>
>> >>> looks like a power outage in soda hall.  more updates as they happen.
>> >>>
>> >>>
>> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
>> >>> wrote:
>> >>>
>> >>>> i am trying to get things up and running, but it looks like either
>> the
>> >>>> firewall gateway or jenkins server itself is down.  i'll update as
>> soon as
>> >>>> i know more.
>> >>>>
>> >>>
>> >>>
>> >>
>> >
>>
>
>  --
> You received this message because you are subscribed to the Google Groups
> "amp-infra" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to amp-infra+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.
>

--001a1133c96698b1420502445671--

From dev-return-9316-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 23:22:22 2014
Return-Path: <dev-return-9316-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6DBA911A46
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 23:22:22 +0000 (UTC)
Received: (qmail 82742 invoked by uid 500); 4 Sep 2014 23:22:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82664 invoked by uid 500); 4 Sep 2014 23:22:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82647 invoked by uid 99); 4 Sep 2014 23:22:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:22:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:21:55 +0000
Received: by mail-wg0-f48.google.com with SMTP id a1so121295wgh.31
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 16:21:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=llqfkkKdDUeoMvi2q3+KDHXEwlv2Pi3L5p+xZy7NqbE=;
        b=JtHpiKL8c7/9UPwKpIR6rfL9rXDaET6utCCjN+00gFR0reHK6LaFpzRb8zXKehxr/P
         /vLCkYy/KtkK28/Np9g4xxeXC5pEd07R79eG1w2cbT/MKjr1AR0+yiThseGDPgrdJmZW
         VvGnCjaAeV2iof/kAr9XW20ZyZiD/nY+rRSJsLyMICiBDSXk8voocbFELACjyNllvBh+
         lhG/qE11/T8oNCEo3npiYRzgAA1+xPS4MqYdmy8MubXoV/hLb49UFaJHmG8RtzxeD/aW
         O/LtKXlNoSbB7Xw5RgslrV0E3HkLUNQ6ZXPTiNoXfSW2RRCFrsjGShFT9CzCJO3z5Siz
         JSxA==
X-Received: by 10.180.211.233 with SMTP id nf9mr9305355wic.33.1409872914874;
 Thu, 04 Sep 2014 16:21:54 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Thu, 4 Sep 2014 16:21:14 -0700 (PDT)
In-Reply-To: <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com> <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 4 Sep 2014 19:21:14 -0400
Message-ID: <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c338d04508b40502459e10
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c338d04508b40502459e10
Content-Type: text/plain; charset=UTF-8

It appears that our main man is having trouble
<https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
 hearing new requests
<https://github.com/apache/spark/pull/2277#issuecomment-54549106>.

Do we need some smelling salts?


On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i'd ping the Jenkinsmench...  the master was completely offline, so any new
> jobs wouldn't have reached it.  any jobs that were queued when power was
> lost probably started up, but jobs that were running would fail.
>
>
> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > Woohoo! Thanks Shane.
> >
> > Do you know if queued PR builds will automatically be picked up? Or do we
> > have to ping the Jenkinmensch manually from each PR?
> >
> > Nick
> >
> >
> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu> wrote:
> >
> >> AND WE'RE UP!
> >>
> >> sorry that this took so long...  i'll send out a more detailed
> explanation
> >> of what happened soon.
> >>
> >> now, off to back up jenkins.
> >>
> >> shane
> >>
> >>
> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>
> >> > it's a faulty power switch on the firewall, which has been swapped
> out.
> >> >  we're about to reboot and be good to go.
> >> >
> >> >
> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
> >> wrote:
> >> >
> >> >> looks like some hardware failed, and we're swapping in a replacement.
> >> i
> >> >> don't have more specific information yet -- including *what* failed,
> >> as our
> >> >> sysadmin is super busy ATM.  the root cause was an incorrect circuit
> >> being
> >> >> switched off during building maintenance.
> >> >>
> >> >> on a side note, this incident will be accelerating our plan to move
> the
> >> >> entire jenkins infrastructure in to a managed datacenter environment.
> >> this
> >> >> will be our major push over the next couple of weeks.  more details
> >> about
> >> >> this, also, as soon as i get them.
> >> >>
> >> >> i'm very sorry about the downtime, we'll get everything up and
> running
> >> >> ASAP.
> >> >>
> >> >>
> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
> >> wrote:
> >> >>
> >> >>> looks like a power outage in soda hall.  more updates as they
> happen.
> >> >>>
> >> >>>
> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
> >> >>> wrote:
> >> >>>
> >> >>>> i am trying to get things up and running, but it looks like either
> >> the
> >> >>>> firewall gateway or jenkins server itself is down.  i'll update as
> >> soon as
> >> >>>> i know more.
> >> >>>>
> >> >>>
> >> >>>
> >> >>
> >> >
> >>
> >
> >  --
> > You received this message because you are subscribed to the Google Groups
> > "amp-infra" group.
> > To unsubscribe from this group and stop receiving emails from it, send an
> > email to amp-infra+unsubscribe@googlegroups.com.
> > For more options, visit https://groups.google.com/d/optout.
> >
>

--001a11c338d04508b40502459e10--

From dev-return-9317-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 23:30:33 2014
Return-Path: <dev-return-9317-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E594211A66
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 23:30:32 +0000 (UTC)
Received: (qmail 97360 invoked by uid 500); 4 Sep 2014 23:30:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97294 invoked by uid 500); 4 Sep 2014 23:30:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97277 invoked by uid 99); 4 Sep 2014 23:30:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:30:31 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.182 as permitted sender)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:30:06 +0000
Received: by mail-ob0-f182.google.com with SMTP id va2so7965245obc.13
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 16:30:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=KtIdRuu9vN6mEsSC7VYwMbLNtmvhBOknfhC5EvzKfMU=;
        b=IR1YLSu4MNyzC69yA3YxkVWv4xMF91fMtU4ED1NaQ3cZMb/cdhT4wPdUiIuieqg0Yd
         o+Ae0XZJrYqGCNdryXshGZdlxKHuF5J1enweNcZn0Belm5dizeRTqK/7oM0+N4VCayJU
         eHIppMdu7qxZpWGQVaJ3XhvmvR1AjO5tDdXPrOOrP7sRwpGCjYrPBK5ragMr8PCc/iRn
         qb3yAQpFb1/wbhutZwIx4qt7Q2j6xMlTN2kqYhJFIdfVKPcWgKQveON+thE2q8PpWPzg
         L9blbkmnDJqXKXBxZBTHV75Ubg51eBapOxO2rM44lN0K/zP2tNvoibGOUxNINM8ZwzTo
         4uPw==
MIME-Version: 1.0
X-Received: by 10.60.161.49 with SMTP id xp17mr9507119oeb.18.1409873405115;
 Thu, 04 Sep 2014 16:30:05 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Thu, 4 Sep 2014 16:30:05 -0700 (PDT)
In-Reply-To: <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
	<CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
	<CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
	<CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
	<CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
	<CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
	<CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
	<CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
Date: Thu, 4 Sep 2014 16:30:05 -0700
Message-ID: <CABPQxsup7R1AgprbDfSc_gCoLvv5LBLZyD4k9RPM7Pi3pT6tMA@mail.gmail.com>
Subject: Re: amplab jenkins is down
From: Patrick Wendell <pwendell@gmail.com>
To: amp-infra@googlegroups.com
Cc: shane knapp <sknapp@berkeley.edu>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hm yeah it seems that it hasn't been polling since 3:45.

On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> It appears that our main man is having trouble hearing new requests.
>
> Do we need some smelling salts?
>
>
> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>> i'd ping the Jenkinsmench...  the master was completely offline, so any
>> new
>> jobs wouldn't have reached it.  any jobs that were queued when power was
>> lost probably started up, but jobs that were running would fail.
>>
>>
>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas
>> <nicholas.chammas@gmail.com
>> > wrote:
>>
>> > Woohoo! Thanks Shane.
>> >
>> > Do you know if queued PR builds will automatically be picked up? Or do
>> > we
>> > have to ping the Jenkinmensch manually from each PR?
>> >
>> > Nick
>> >
>> >
>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu> wrote:
>> >
>> >> AND WE'RE UP!
>> >>
>> >> sorry that this took so long...  i'll send out a more detailed
>> >> explanation
>> >> of what happened soon.
>> >>
>> >> now, off to back up jenkins.
>> >>
>> >> shane
>> >>
>> >>
>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>> >> wrote:
>> >>
>> >> > it's a faulty power switch on the firewall, which has been swapped
>> >> > out.
>> >> >  we're about to reboot and be good to go.
>> >> >
>> >> >
>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>> >> wrote:
>> >> >
>> >> >> looks like some hardware failed, and we're swapping in a
>> >> >> replacement.
>> >> i
>> >> >> don't have more specific information yet -- including *what* failed,
>> >> as our
>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect circuit
>> >> being
>> >> >> switched off during building maintenance.
>> >> >>
>> >> >> on a side note, this incident will be accelerating our plan to move
>> >> >> the
>> >> >> entire jenkins infrastructure in to a managed datacenter
>> >> >> environment.
>> >> this
>> >> >> will be our major push over the next couple of weeks.  more details
>> >> about
>> >> >> this, also, as soon as i get them.
>> >> >>
>> >> >> i'm very sorry about the downtime, we'll get everything up and
>> >> >> running
>> >> >> ASAP.
>> >> >>
>> >> >>
>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
>> >> wrote:
>> >> >>
>> >> >>> looks like a power outage in soda hall.  more updates as they
>> >> >>> happen.
>> >> >>>
>> >> >>>
>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
>> >> >>> wrote:
>> >> >>>
>> >> >>>> i am trying to get things up and running, but it looks like either
>> >> the
>> >> >>>> firewall gateway or jenkins server itself is down.  i'll update as
>> >> soon as
>> >> >>>> i know more.
>> >> >>>>
>> >> >>>
>> >> >>>
>> >> >>
>> >> >
>> >>
>> >
>> >  --
>> > You received this message because you are subscribed to the Google
>> > Groups
>> > "amp-infra" group.
>> > To unsubscribe from this group and stop receiving emails from it, send
>> > an
>> > email to amp-infra+unsubscribe@googlegroups.com.
>> > For more options, visit https://groups.google.com/d/optout.
>> >
>
>
> --
> You received this message because you are subscribed to the Google Groups
> "amp-infra" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to amp-infra+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9318-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 23:56:59 2014
Return-Path: <dev-return-9318-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7FAE211AE8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 23:56:59 +0000 (UTC)
Received: (qmail 35064 invoked by uid 500); 4 Sep 2014 23:56:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35002 invoked by uid 500); 4 Sep 2014 23:56:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34989 invoked by uid 99); 4 Sep 2014 23:56:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:56:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:56:33 +0000
Received: by mail-la0-f50.google.com with SMTP id mc6so12834027lab.37
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 16:56:32 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=963N5Tx4LO/mjezMoQJUPzhyqcUjjq7yzAxWu+cSiJA=;
        b=KjLvpDxnzKV4qEVt0pwwjOBJCF3sHOMHbwacuPapsbsa/xKc5j5AcnSyFhl+MTXpA8
         EEJGHOcVWNC60GlhZmSQVsUlE+0lNHBKShwnqVTa8V3ZJBQcDwYH8aS7LiGYQQoxSOs8
         w2BsWqTif9K0JmnBIcXtmtkCgSfFWr+8GXdkDWS5In7t5QrokFePe6WMH3IL9qsE6Ue3
         B3xsvb6E28mJw7ThlERAQyZjWgbzGPelgghHbL05KSC9MRa181wlB4Z5D5LP7gM3Uv/L
         Y43bbm2J+UU/sJo5woq6oZbjhHlalO2dH9v/em0HrvSqotcCaiFmX8wi47f8g9hAsVUd
         3atw==
X-Gm-Message-State: ALoCoQmS1xaPRy5LfrfhfGup1JfH0re7FISwRRKxuyJZByX6A+KPe/vZ2TF0KlluAfSoLhHXsrP8
X-Received: by 10.152.42.136 with SMTP id o8mr8019303lal.76.1409874992051;
 Thu, 04 Sep 2014 16:56:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 16:56:12 -0700 (PDT)
In-Reply-To: <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com> <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 16:56:12 -0700
Message-ID: <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c34e8414415d0502461a4b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34e8414415d0502461a4b
Content-Type: text/plain; charset=UTF-8

looking


On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> It appears that our main man is having trouble
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>  hearing new requests
> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>
> Do we need some smelling salts?
>
>
> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i'd ping the Jenkinsmench...  the master was completely offline, so any
>> new
>> jobs wouldn't have reached it.  any jobs that were queued when power was
>> lost probably started up, but jobs that were running would fail.
>>
>>
>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com
>> > wrote:
>>
>> > Woohoo! Thanks Shane.
>> >
>> > Do you know if queued PR builds will automatically be picked up? Or do
>> we
>> > have to ping the Jenkinmensch manually from each PR?
>> >
>> > Nick
>> >
>> >
>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >
>> >> AND WE'RE UP!
>> >>
>> >> sorry that this took so long...  i'll send out a more detailed
>> explanation
>> >> of what happened soon.
>> >>
>> >> now, off to back up jenkins.
>> >>
>> >> shane
>> >>
>> >>
>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >>
>> >> > it's a faulty power switch on the firewall, which has been swapped
>> out.
>> >> >  we're about to reboot and be good to go.
>> >> >
>> >> >
>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>> >> wrote:
>> >> >
>> >> >> looks like some hardware failed, and we're swapping in a
>> replacement.
>> >> i
>> >> >> don't have more specific information yet -- including *what* failed,
>> >> as our
>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect circuit
>> >> being
>> >> >> switched off during building maintenance.
>> >> >>
>> >> >> on a side note, this incident will be accelerating our plan to move
>> the
>> >> >> entire jenkins infrastructure in to a managed datacenter
>> environment.
>> >> this
>> >> >> will be our major push over the next couple of weeks.  more details
>> >> about
>> >> >> this, also, as soon as i get them.
>> >> >>
>> >> >> i'm very sorry about the downtime, we'll get everything up and
>> running
>> >> >> ASAP.
>> >> >>
>> >> >>
>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
>> >> wrote:
>> >> >>
>> >> >>> looks like a power outage in soda hall.  more updates as they
>> happen.
>> >> >>>
>> >> >>>
>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu>
>> >> >>> wrote:
>> >> >>>
>> >> >>>> i am trying to get things up and running, but it looks like either
>> >> the
>> >> >>>> firewall gateway or jenkins server itself is down.  i'll update as
>> >> soon as
>> >> >>>> i know more.
>> >> >>>>
>> >> >>>
>> >> >>>
>> >> >>
>> >> >
>> >>
>> >
>> >  --
>> > You received this message because you are subscribed to the Google
>> Groups
>> > "amp-infra" group.
>> > To unsubscribe from this group and stop receiving emails from it, send
>> an
>> > email to amp-infra+unsubscribe@googlegroups.com.
>> > For more options, visit https://groups.google.com/d/optout.
>> >
>>
>
>

--001a11c34e8414415d0502461a4b--

From dev-return-9319-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep  4 23:59:40 2014
Return-Path: <dev-return-9319-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 02BFC11B00
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  4 Sep 2014 23:59:40 +0000 (UTC)
Received: (qmail 42405 invoked by uid 500); 4 Sep 2014 23:59:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42337 invoked by uid 500); 4 Sep 2014 23:59:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42326 invoked by uid 99); 4 Sep 2014 23:59:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:59:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 04 Sep 2014 23:59:13 +0000
Received: by mail-la0-f45.google.com with SMTP id pn19so12815015lab.4
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 16:59:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=QOjmnOY8N7lZx7jQYXj/xhiUz1FYZzp0qdLA5wbH5PE=;
        b=VJjd2WI6Iu+lr/ZlnoKYtjE6FjyrRWZuKUl1GlnqFMU2pRgNsgo1DXASpi27L+dMm2
         W4NjJw/UIZj26Cx7sDKycc3H2S0UoW1fJB5+1IyA3y4L9ddgq4peXAQh+FgN5cY2mJzC
         XhHawpOh8w9BL2OTNqGJlEC+r0wkqOIaA0b0pDEeeQ33uWgSK6l9Jmv45veCNPy5g4nZ
         cv+Jj8nNIyn9yJUE/bK2n4fGwPaDaNHHVC29yzUrzqiYMa9d7zFLdgW79iORZDNuCsge
         HAo4emDfpK7L1pwbZOrfy7RZbiDZOVek0wJp2U57IUGnWTvdzinsCRYIJDdv6XIzLsJA
         i1gA==
X-Gm-Message-State: ALoCoQmg27qyikTxzjYsjBBOy8yYkpHSyBPB0kAdsqHBJ35DSStxdzl67cUOo1F2Y8DH2cMWrOB/
X-Received: by 10.152.115.232 with SMTP id jr8mr7921030lab.69.1409875152791;
 Thu, 04 Sep 2014 16:59:12 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 16:58:52 -0700 (PDT)
In-Reply-To: <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com> <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 16:58:52 -0700
Message-ID: <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c34e68a8fa570502462325
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34e68a8fa570502462325
Content-Type: text/plain; charset=UTF-8

i'm going to restart jenkins and see if that fixes things.


On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu> wrote:

> looking
>
>
> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> It appears that our main man is having trouble
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>  hearing new requests
>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>
>> Do we need some smelling salts?
>>
>>
>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> i'd ping the Jenkinsmench...  the master was completely offline, so any
>>> new
>>> jobs wouldn't have reached it.  any jobs that were queued when power was
>>> lost probably started up, but jobs that were running would fail.
>>>
>>>
>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com
>>> > wrote:
>>>
>>> > Woohoo! Thanks Shane.
>>> >
>>> > Do you know if queued PR builds will automatically be picked up? Or do
>>> we
>>> > have to ping the Jenkinmensch manually from each PR?
>>> >
>>> > Nick
>>> >
>>> >
>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>> >
>>> >> AND WE'RE UP!
>>> >>
>>> >> sorry that this took so long...  i'll send out a more detailed
>>> explanation
>>> >> of what happened soon.
>>> >>
>>> >> now, off to back up jenkins.
>>> >>
>>> >> shane
>>> >>
>>> >>
>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>> >>
>>> >> > it's a faulty power switch on the firewall, which has been swapped
>>> out.
>>> >> >  we're about to reboot and be good to go.
>>> >> >
>>> >> >
>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>>> >> wrote:
>>> >> >
>>> >> >> looks like some hardware failed, and we're swapping in a
>>> replacement.
>>> >> i
>>> >> >> don't have more specific information yet -- including *what*
>>> failed,
>>> >> as our
>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>> circuit
>>> >> being
>>> >> >> switched off during building maintenance.
>>> >> >>
>>> >> >> on a side note, this incident will be accelerating our plan to
>>> move the
>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>> environment.
>>> >> this
>>> >> >> will be our major push over the next couple of weeks.  more details
>>> >> about
>>> >> >> this, also, as soon as i get them.
>>> >> >>
>>> >> >> i'm very sorry about the downtime, we'll get everything up and
>>> running
>>> >> >> ASAP.
>>> >> >>
>>> >> >>
>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu>
>>> >> wrote:
>>> >> >>
>>> >> >>> looks like a power outage in soda hall.  more updates as they
>>> happen.
>>> >> >>>
>>> >> >>>
>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <sknapp@berkeley.edu
>>> >
>>> >> >>> wrote:
>>> >> >>>
>>> >> >>>> i am trying to get things up and running, but it looks like
>>> either
>>> >> the
>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll update
>>> as
>>> >> soon as
>>> >> >>>> i know more.
>>> >> >>>>
>>> >> >>>
>>> >> >>>
>>> >> >>
>>> >> >
>>> >>
>>> >
>>> >  --
>>> > You received this message because you are subscribed to the Google
>>> Groups
>>> > "amp-infra" group.
>>> > To unsubscribe from this group and stop receiving emails from it, send
>>> an
>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>> > For more options, visit https://groups.google.com/d/optout.
>>> >
>>>
>>
>>
>

--001a11c34e68a8fa570502462325--

From dev-return-9320-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 01:09:05 2014
Return-Path: <dev-return-9320-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B8F3D11CB0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 01:09:04 +0000 (UTC)
Received: (qmail 60142 invoked by uid 500); 5 Sep 2014 01:09:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60075 invoked by uid 500); 5 Sep 2014 01:09:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60058 invoked by uid 99); 5 Sep 2014 01:09:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 01:09:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kanzhangemail@gmail.com designates 209.85.223.181 as permitted sender)
Received: from [209.85.223.181] (HELO mail-ie0-f181.google.com) (209.85.223.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 01:08:33 +0000
Received: by mail-ie0-f181.google.com with SMTP id rp18so12352177iec.26
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 18:08:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:reply-to:sender:in-reply-to:references:date:message-id
         :subject:from:to:content-type;
        bh=hvZTCnI0+teEVsAT4F9Spm7O191ihHq5PNzkUYgv2co=;
        b=jgh59evWDPpEwrtBXiza6MVXWR8SHFcoWP1TN5al/ehD3dG9l7cbaBAQ3H6LlVi+za
         bWLAChOE65+R1/LMetr84FK/N+dK/lR9sHi5qMZKxXNRMRVht0l/JXsCTd8+HUK5lSLr
         eJwI+p7Izil3Y1+qg75ZOFUnsjEwZkz2K9qESkrGB2Z1wuJAX488MGHbl2/AUdhPwRPc
         XVW05G1kaK6PyjxeBwnMq6OrOm8rrQ+vvm17ramzXATeqntoGZMHEf0dxLg/8bhPH8Eh
         qoELNKirnIIf+Xu13b3001I+WkoBaJpUNNXDHNzu4W1UGLgyZNDg1IT4kLZEHvY7/waY
         1WYg==
MIME-Version: 1.0
X-Received: by 10.42.82.6 with SMTP id b6mr10191721icl.51.1409879312144; Thu,
 04 Sep 2014 18:08:32 -0700 (PDT)
Reply-To: kzhang@apache.org
Sender: kanzhangemail@gmail.com
Received: by 10.64.68.163 with HTTP; Thu, 4 Sep 2014 18:08:32 -0700 (PDT)
In-Reply-To: <CAMrx5DxVwNZo4DajGgbQh3fuQmyDFBDLTo5a64on9QaoB=XUZQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
	<CAMrx5DxVwNZo4DajGgbQh3fuQmyDFBDLTo5a64on9QaoB=XUZQ@mail.gmail.com>
Date: Thu, 4 Sep 2014 18:08:32 -0700
X-Google-Sender-Auth: -Mb4U_FfsxKniaV4Je1pVfrnnuM
Message-ID: <CALRHqP9reGgcc03paDWXkvf6qNWgP6YtB7j=RctrEpiUP-=dCg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Kan Zhang <kzhang@apache.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=485b397dd701939cf20502471bd1
X-Virus-Checked: Checked by ClamAV on apache.org

--485b397dd701939cf20502471bd1
Content-Type: text/plain; charset=UTF-8

+1

Compiled, ran newly-introduced PySpark Hadoop input/output examples.


On Thu, Sep 4, 2014 at 1:10 PM, Egor Pahomov <pahomov.egor@gmail.com> wrote:

> +1
>
> Compiled, ran on yarn-hadoop-2.3 simple job.
>
>
> 2014-09-04 22:22 GMT+04:00 Henry Saputra <henry.saputra@gmail.com>:
>
> > LICENSE and NOTICE files are good
> > Hash files are good
> > Signature files are good
> > No 3rd parties executables
> > Source compiled
> > Run local and standalone tests
> > Test persist off heap with Tachyon looks good
> >
> > +1
> >
> > - Henry
> >
> > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > > Please vote on releasing the following candidate as Apache Spark
> version
> > 1.1.0!
> > >
> > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> > >
> > > The release files, including signatures, digests, etc. can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1031/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> > >
> > > Please vote on releasing this package as Apache Spark 1.1.0!
> > >
> > > The vote is open until Saturday, September 06, at 08:30 UTC and passes
> if
> > > a majority of at least 3 +1 PMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.apache.org/
> > >
> > > == Regressions fixed since RC3 ==
> > > SPARK-3332 - Issue with tagging in EC2 scripts
> > > SPARK-3358 - Issue with regression for m3.XX instances
> > >
> > > == What justifies a -1 vote for this release? ==
> > > This vote is happening very late into the QA period compared with
> > > previous votes, so -1 votes should only occur for significant
> > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > > this release.
> > >
> > > == What default changes should I be aware of? ==
> > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > > --> Old behavior can be restored by switching to "lzf"
> > >
> > > 2. PySpark now performs external spilling during aggregations.
> > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> > "false".
> > >
> > > 3. PySpark uses a new heuristic for determining the parallelism of
> > > shuffle operations.
> > > --> Old behavior can be restored by setting
> > > "spark.default.parallelism" to the number of cores in the cluster.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--485b397dd701939cf20502471bd1--

From dev-return-9321-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 02:11:26 2014
Return-Path: <dev-return-9321-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8535B11E31
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 02:11:26 +0000 (UTC)
Received: (qmail 58355 invoked by uid 500); 5 Sep 2014 02:11:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58293 invoked by uid 500); 5 Sep 2014 02:11:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57943 invoked by uid 99); 5 Sep 2014 02:11:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 02:11:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.174 as permitted sender)
Received: from [74.125.82.174] (HELO mail-we0-f174.google.com) (74.125.82.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 02:11:21 +0000
Received: by mail-we0-f174.google.com with SMTP id u57so11075755wes.5
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 19:11:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=LBiLU++/oz5XEksY2r7qao4V7Cg/7O/c9q0MIAEsXYY=;
        b=NhSYzkVnDdD09EZtABmWxz7Xmkfic0YaxMN0MqOAx7CeWHZ1JIypN31S1MaqmH4MGc
         kNyoVrI6WXFbOZard4be6PwKEHg8miYvPoVAAN04aUCD2ys0CytH6LkkmTLiHakWcfiV
         dKqNu2kOq7jpd5ENlfer2tBNNtpyEliAdcA5LPQdi6eJ/7zpzeRPcnHABm8EYJQhrepe
         qNnttIbx28DQERbzP1wZ7hXB8to8WCcrZNjWZg1L9O9cCMLYvIHftehPl7yeWPBzsVt2
         igVjNN+PbvwmM5sPsB7WHbu6wUbaWhwyEOx67rAUE3dJLw24Euf8EtFWUyghEOZQePAT
         uKZw==
X-Received: by 10.180.187.144 with SMTP id fs16mr9951005wic.75.1409883060229;
 Thu, 04 Sep 2014 19:11:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Thu, 4 Sep 2014 19:10:20 -0700 (PDT)
In-Reply-To: <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com> <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 4 Sep 2014 22:10:20 -0400
Message-ID: <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c266a8fade13050247faba
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c266a8fade13050247faba
Content-Type: text/plain; charset=UTF-8

Looks like during the last build
<https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
Jenkins was unable to execute a git fetch?


On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i'm going to restart jenkins and see if that fixes things.
>
>
> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> looking
>>
>>
>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> It appears that our main man is having trouble
>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>  hearing new requests
>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>
>>> Do we need some smelling salts?
>>>
>>>
>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>>> i'd ping the Jenkinsmench...  the master was completely offline, so any
>>>> new
>>>> jobs wouldn't have reached it.  any jobs that were queued when power was
>>>> lost probably started up, but jobs that were running would fail.
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com
>>>> > wrote:
>>>>
>>>> > Woohoo! Thanks Shane.
>>>> >
>>>> > Do you know if queued PR builds will automatically be picked up? Or
>>>> do we
>>>> > have to ping the Jenkinmensch manually from each PR?
>>>> >
>>>> > Nick
>>>> >
>>>> >
>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>> >
>>>> >> AND WE'RE UP!
>>>> >>
>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>> explanation
>>>> >> of what happened soon.
>>>> >>
>>>> >> now, off to back up jenkins.
>>>> >>
>>>> >> shane
>>>> >>
>>>> >>
>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>> >>
>>>> >> > it's a faulty power switch on the firewall, which has been swapped
>>>> out.
>>>> >> >  we're about to reboot and be good to go.
>>>> >> >
>>>> >> >
>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>>>> >> wrote:
>>>> >> >
>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>> replacement.
>>>> >> i
>>>> >> >> don't have more specific information yet -- including *what*
>>>> failed,
>>>> >> as our
>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>> circuit
>>>> >> being
>>>> >> >> switched off during building maintenance.
>>>> >> >>
>>>> >> >> on a side note, this incident will be accelerating our plan to
>>>> move the
>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>> environment.
>>>> >> this
>>>> >> >> will be our major push over the next couple of weeks.  more
>>>> details
>>>> >> about
>>>> >> >> this, also, as soon as i get them.
>>>> >> >>
>>>> >> >> i'm very sorry about the downtime, we'll get everything up and
>>>> running
>>>> >> >> ASAP.
>>>> >> >>
>>>> >> >>
>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <sknapp@berkeley.edu
>>>> >
>>>> >> wrote:
>>>> >> >>
>>>> >> >>> looks like a power outage in soda hall.  more updates as they
>>>> happen.
>>>> >> >>>
>>>> >> >>>
>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>> sknapp@berkeley.edu>
>>>> >> >>> wrote:
>>>> >> >>>
>>>> >> >>>> i am trying to get things up and running, but it looks like
>>>> either
>>>> >> the
>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll update
>>>> as
>>>> >> soon as
>>>> >> >>>> i know more.
>>>> >> >>>>
>>>> >> >>>
>>>> >> >>>
>>>> >> >>
>>>> >> >
>>>> >>
>>>> >
>>>> >  --
>>>> > You received this message because you are subscribed to the Google
>>>> Groups
>>>> > "amp-infra" group.
>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>> send an
>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>> > For more options, visit https://groups.google.com/d/optout.
>>>> >
>>>>
>>>
>>>
>>
>

--001a11c266a8fade13050247faba--

From dev-return-9322-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 05:03:42 2014
Return-Path: <dev-return-9322-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C132711291
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 05:03:42 +0000 (UTC)
Received: (qmail 80473 invoked by uid 500); 5 Sep 2014 05:03:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80400 invoked by uid 500); 5 Sep 2014 05:03:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80384 invoked by uid 99); 5 Sep 2014 05:03:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 05:03:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 05:03:37 +0000
Received: by mail-la0-f54.google.com with SMTP id b17so13343973lan.27
        for <dev@spark.apache.org>; Thu, 04 Sep 2014 22:03:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=zam6fn1bC0drxVwa7ljpsLDfNCUzL6WTvw3DfR12/8Y=;
        b=U5PEL+VKco49tjQuAR6n0wKLOBpHVTjL3hPI16cAC/bCKyPFUEf397oh7lJ2R0HiGL
         iyGyw1OlJviXfoXDct03+0hEqsFTIOS4I5yUbF3zSgMNMMjVWSmz7zuKxnDt58tRu7m1
         uM5UKEPVbd/aHbFDOMH+bn91fZ7zuA80P2u0E0px84Ako3DblgMFeFpWKHOmGwhvEm7G
         yttlEg6S/MhX6B8AmgdDI6bGYX1afZQpOIoKRb8AGBsiBQrXz4pLtey/nk1FxDzU3tTT
         iceNSW/0XaUF06Sk2VJ+jb0z75L7LUWPT1z6zDF96W5/noaWN/4WmsfS5ICgqV/xaMFX
         sCGA==
X-Gm-Message-State: ALoCoQkqIECk/NMg4UiY95wwqMxBzY0wo2p7ZfWYy0I8fIx35W8nSWaClcI58/5gb1rP0/gczW8F
X-Received: by 10.152.4.9 with SMTP id g9mr9255706lag.14.1409893395318; Thu,
 04 Sep 2014 22:03:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Thu, 4 Sep 2014 22:02:55 -0700 (PDT)
In-Reply-To: <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com> <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 4 Sep 2014 22:02:55 -0700
Message-ID: <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=089e013d1708ffd78005024a6263
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d1708ffd78005024a6263
Content-Type: text/plain; charset=UTF-8

yep.  that's exactly the behavior i saw earlier, and will be figuring out
first thing tomorrow morning.  i bet it's an environment issues on the
slaves.


On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Looks like during the last build
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
> Jenkins was unable to execute a git fetch?
>
>
> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i'm going to restart jenkins and see if that fixes things.
>>
>>
>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> looking
>>>
>>>
>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> It appears that our main man is having trouble
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>  hearing new requests
>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>
>>>> Do we need some smelling salts?
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>>> i'd ping the Jenkinsmench...  the master was completely offline, so
>>>>> any new
>>>>> jobs wouldn't have reached it.  any jobs that were queued when power
>>>>> was
>>>>> lost probably started up, but jobs that were running would fail.
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com
>>>>> > wrote:
>>>>>
>>>>> > Woohoo! Thanks Shane.
>>>>> >
>>>>> > Do you know if queued PR builds will automatically be picked up? Or
>>>>> do we
>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>> >
>>>>> > Nick
>>>>> >
>>>>> >
>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>> >
>>>>> >> AND WE'RE UP!
>>>>> >>
>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>> explanation
>>>>> >> of what happened soon.
>>>>> >>
>>>>> >> now, off to back up jenkins.
>>>>> >>
>>>>> >> shane
>>>>> >>
>>>>> >>
>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>> >>
>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>> swapped out.
>>>>> >> >  we're about to reboot and be good to go.
>>>>> >> >
>>>>> >> >
>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu>
>>>>> >> wrote:
>>>>> >> >
>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>> replacement.
>>>>> >> i
>>>>> >> >> don't have more specific information yet -- including *what*
>>>>> failed,
>>>>> >> as our
>>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>>> circuit
>>>>> >> being
>>>>> >> >> switched off during building maintenance.
>>>>> >> >>
>>>>> >> >> on a side note, this incident will be accelerating our plan to
>>>>> move the
>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>> environment.
>>>>> >> this
>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>> details
>>>>> >> about
>>>>> >> >> this, also, as soon as i get them.
>>>>> >> >>
>>>>> >> >> i'm very sorry about the downtime, we'll get everything up and
>>>>> running
>>>>> >> >> ASAP.
>>>>> >> >>
>>>>> >> >>
>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>> sknapp@berkeley.edu>
>>>>> >> wrote:
>>>>> >> >>
>>>>> >> >>> looks like a power outage in soda hall.  more updates as they
>>>>> happen.
>>>>> >> >>>
>>>>> >> >>>
>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>> sknapp@berkeley.edu>
>>>>> >> >>> wrote:
>>>>> >> >>>
>>>>> >> >>>> i am trying to get things up and running, but it looks like
>>>>> either
>>>>> >> the
>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>> update as
>>>>> >> soon as
>>>>> >> >>>> i know more.
>>>>> >> >>>>
>>>>> >> >>>
>>>>> >> >>>
>>>>> >> >>
>>>>> >> >
>>>>> >>
>>>>> >
>>>>> >  --
>>>>> > You received this message because you are subscribed to the Google
>>>>> Groups
>>>>> > "amp-infra" group.
>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>> send an
>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>> >
>>>>>
>>>>
>>>>
>>>
>>
>

--089e013d1708ffd78005024a6263--

From dev-return-9323-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 09:27:28 2014
Return-Path: <dev-return-9323-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0B5D311886
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 09:27:28 +0000 (UTC)
Received: (qmail 94029 invoked by uid 500); 5 Sep 2014 09:27:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93959 invoked by uid 500); 5 Sep 2014 09:27:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93948 invoked by uid 99); 5 Sep 2014 09:27:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 09:27:26 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 09:27:00 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XPpnH-00077h-Pz
	for dev@spark.incubator.apache.org; Fri, 05 Sep 2014 02:26:59 -0700
Date: Fri, 5 Sep 2014 02:26:59 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409909219731-8291.post@n3.nabble.com>
Subject: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all, 

It seems that there is a method to multiply a RowMatrix and a (local)
Matrix. 
However, there is not a method to multiply a large scale matrix and another
one in Spark.
It would be helpful. Does anyone have a plan to add multiplying large scale
matrices? 
Or shouldn't  we support it in Spark?

thanks,



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9324-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 15:05:51 2014
Return-Path: <dev-return-9324-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DB59E112CA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 15:05:50 +0000 (UTC)
Received: (qmail 26680 invoked by uid 500); 5 Sep 2014 15:05:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26606 invoked by uid 500); 5 Sep 2014 15:05:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26594 invoked by uid 99); 5 Sep 2014 15:05:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:05:49 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rnowling@gmail.com designates 209.85.212.172 as permitted sender)
Received: from [209.85.212.172] (HELO mail-wi0-f172.google.com) (209.85.212.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:05:23 +0000
Received: by mail-wi0-f172.google.com with SMTP id n3so989329wiv.17
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 08:05:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IQgweBWoHQg2PlpOjOvYMMl3TgnhkRN4oCVzx6b1dKU=;
        b=Ah9OSG1YYM+wYubvd6VLFhW0QTzS0gYLWxM5pZJKVCqhjWuWZIDsZd3eFAFRsTtI1Z
         Drk/6ktS+hA+cNxi6quU1wKkVrJ6gA34VjzWUAOSIZFIxcqnIHWBuYSVj8A+2aY8Bsa+
         ftJt56u5cwwTa50hb+dP0xgr+lXFmvRNfNcWVSQ5F+pU8rAUaoqZMEEewjPOzlTcQ/MD
         swsXbzeIr4x5JwNuUE8X60sSc9dVcjGw4wwxzXpKBWjyGwUQCGSn0esp6lTImGR1bnZ6
         ZTiI+ygA09Sm5e4avZABD4z/rXiqZKyaBGDrXNlipjIHfpI4GZCvUzfYIexp7pwGUkSR
         q8Wg==
MIME-Version: 1.0
X-Received: by 10.194.78.100 with SMTP id a4mr15253316wjx.106.1409929518485;
 Fri, 05 Sep 2014 08:05:18 -0700 (PDT)
Received: by 10.194.14.137 with HTTP; Fri, 5 Sep 2014 08:05:18 -0700 (PDT)
In-Reply-To: <1409909219731-8291.post@n3.nabble.com>
References: <1409909219731-8291.post@n3.nabble.com>
Date: Fri, 5 Sep 2014 11:05:18 -0400
Message-ID: <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: RJ Nowling <rnowling@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bfd05821b9760050252cc47
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfd05821b9760050252cc47
Content-Type: text/plain; charset=UTF-8

I think it would be interesting to have a variety of matrix operations
(multiplication, addition / subtraction, powers, scalar multiply, etc.)
available in Spark.

Diagonalization may be more difficult but iterative approximation
approaches may be quite amenable.


On Fri, Sep 5, 2014 at 5:26 AM, Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
wrote:

> Hi all,
>
> It seems that there is a method to multiply a RowMatrix and a (local)
> Matrix.
> However, there is not a method to multiply a large scale matrix and another
> one in Spark.
> It would be helpful. Does anyone have a plan to add multiplying large scale
> matrices?
> Or shouldn't  we support it in Spark?
>
> thanks,
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--047d7bfd05821b9760050252cc47--

From dev-return-9325-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 15:18:28 2014
Return-Path: <dev-return-9325-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7516211313
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 15:18:28 +0000 (UTC)
Received: (qmail 43724 invoked by uid 500); 5 Sep 2014 15:18:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43658 invoked by uid 500); 5 Sep 2014 15:18:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43647 invoked by uid 99); 5 Sep 2014 15:18:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:18:27 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:18:01 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XPvGy-0002WS-Bh
	for dev@spark.incubator.apache.org; Fri, 05 Sep 2014 08:18:00 -0700
Date: Fri, 5 Sep 2014 08:18:00 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409930280353-8293.post@n3.nabble.com>
In-Reply-To: <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi RJ,

Thank you for your comment. I am interested in to have other matrix
operations too.
I will create a JIRA issue in the first place.

thanks,



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8293.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9326-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 15:19:12 2014
Return-Path: <dev-return-9326-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8881E1132D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 15:19:12 +0000 (UTC)
Received: (qmail 49924 invoked by uid 500); 5 Sep 2014 15:19:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49858 invoked by uid 500); 5 Sep 2014 15:19:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49843 invoked by uid 99); 5 Sep 2014 15:19:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:19:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.179 as permitted sender)
Received: from [74.125.82.179] (HELO mail-we0-f179.google.com) (74.125.82.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 15:19:06 +0000
Received: by mail-we0-f179.google.com with SMTP id t60so11825486wes.24
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 08:18:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=EkXi7I+MOb2mflButPhlx7gM08iiYvqvGjFO0zBoPjc=;
        b=kn5zdScczIL6ziu4ryMdff6OTfKoaWghqHEhgBr0X+KwTjFI7FdXpVE1UM+dGg35Qs
         9OJKwvjjlrRt8oknMka1ZRKTPtINkfWnNPszTfVuBd8wODGhcU+IypiQN8mdGVGniyi3
         EcSZW2C2E+Al2kZR0F6t5E5PYSnY3JsnwYqqSYCwJ5GozL/jOELZ/ANV+AvobuOchxG3
         Yzytu97K+WJCfrclpz3e8YjwGnZBPpoGsdDUMvrf5Ik+u47W11zHArkpOEmfRHYw3xdq
         MVQdAZdzEt2EQihdw/Iy+xj6bPcgjIiFJ0VS7ajRWkNCBIBw41sPxIIoJ4vclbU4JZMh
         hw/Q==
X-Received: by 10.195.11.200 with SMTP id ek8mr15908057wjd.85.1409930320987;
 Fri, 05 Sep 2014 08:18:40 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Fri, 5 Sep 2014 08:18:00 -0700 (PDT)
In-Reply-To: <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com> <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 5 Sep 2014 11:18:00 -0400
Message-ID: <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=047d7b873762f0cde0050252fb6a
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b873762f0cde0050252fb6a
Content-Type: text/plain; charset=UTF-8

Hmm, looks like at least some builds
<https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19804/consoleFull>
are working now, though this last one was from ~5 hours ago.


On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu> wrote:

> yep.  that's exactly the behavior i saw earlier, and will be figuring out
> first thing tomorrow morning.  i bet it's an environment issues on the
> slaves.
>
>
> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Looks like during the last build
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
>> Jenkins was unable to execute a git fetch?
>>
>>
>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> i'm going to restart jenkins and see if that fixes things.
>>>
>>>
>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>>> looking
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> It appears that our main man is having trouble
>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>>  hearing new requests
>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>>
>>>>> Do we need some smelling salts?
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>>
>>>>>> i'd ping the Jenkinsmench...  the master was completely offline, so
>>>>>> any new
>>>>>> jobs wouldn't have reached it.  any jobs that were queued when power
>>>>>> was
>>>>>> lost probably started up, but jobs that were running would fail.
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>> nicholas.chammas@gmail.com
>>>>>> > wrote:
>>>>>>
>>>>>> > Woohoo! Thanks Shane.
>>>>>> >
>>>>>> > Do you know if queued PR builds will automatically be picked up? Or
>>>>>> do we
>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>>> >
>>>>>> > Nick
>>>>>> >
>>>>>> >
>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>> >
>>>>>> >> AND WE'RE UP!
>>>>>> >>
>>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>>> explanation
>>>>>> >> of what happened soon.
>>>>>> >>
>>>>>> >> now, off to back up jenkins.
>>>>>> >>
>>>>>> >> shane
>>>>>> >>
>>>>>> >>
>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>> >>
>>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>>> swapped out.
>>>>>> >> >  we're about to reboot and be good to go.
>>>>>> >> >
>>>>>> >> >
>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <sknapp@berkeley.edu
>>>>>> >
>>>>>> >> wrote:
>>>>>> >> >
>>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>>> replacement.
>>>>>> >> i
>>>>>> >> >> don't have more specific information yet -- including *what*
>>>>>> failed,
>>>>>> >> as our
>>>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>>>> circuit
>>>>>> >> being
>>>>>> >> >> switched off during building maintenance.
>>>>>> >> >>
>>>>>> >> >> on a side note, this incident will be accelerating our plan to
>>>>>> move the
>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>>> environment.
>>>>>> >> this
>>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>>> details
>>>>>> >> about
>>>>>> >> >> this, also, as soon as i get them.
>>>>>> >> >>
>>>>>> >> >> i'm very sorry about the downtime, we'll get everything up and
>>>>>> running
>>>>>> >> >> ASAP.
>>>>>> >> >>
>>>>>> >> >>
>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>> sknapp@berkeley.edu>
>>>>>> >> wrote:
>>>>>> >> >>
>>>>>> >> >>> looks like a power outage in soda hall.  more updates as they
>>>>>> happen.
>>>>>> >> >>>
>>>>>> >> >>>
>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>> sknapp@berkeley.edu>
>>>>>> >> >>> wrote:
>>>>>> >> >>>
>>>>>> >> >>>> i am trying to get things up and running, but it looks like
>>>>>> either
>>>>>> >> the
>>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>>> update as
>>>>>> >> soon as
>>>>>> >> >>>> i know more.
>>>>>> >> >>>>
>>>>>> >> >>>
>>>>>> >> >>>
>>>>>> >> >>
>>>>>> >> >
>>>>>> >>
>>>>>> >
>>>>>> >  --
>>>>>> > You received this message because you are subscribed to the Google
>>>>>> Groups
>>>>>> > "amp-infra" group.
>>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an
>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>>> >
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

--047d7b873762f0cde0050252fb6a--

From dev-return-9327-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 16:13:08 2014
Return-Path: <dev-return-9327-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 839B7115A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 16:13:08 +0000 (UTC)
Received: (qmail 84389 invoked by uid 500); 5 Sep 2014 16:13:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84320 invoked by uid 500); 5 Sep 2014 16:13:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84308 invoked by uid 99); 5 Sep 2014 16:13:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:13:07 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.182 as permitted sender)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:12:41 +0000
Received: by mail-vc0-f182.google.com with SMTP id im17so12441306vcb.41
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 09:12:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=YoYx94Nt6tPrHH3nUrOE7aQuMKW09R4awW3i5Mu17vI=;
        b=rtgpiOObSLKTFyNabysuqt3YYUTS2cZG8+3vVcUdl7eMTrhHP6engm8ESnSiUGXXc2
         XAD6l3p0oOJtiFTn7fVtNDTxjmeb4ZgcivjeIPFG6R/gIqXqbB0+a3wqpWydhHbO8xFV
         GZl+wzTJfBKe43N6ZkA412P98QAStwVbeaCcwFu24DoJ0c+W4qNRB8aJuMmpaVREJ6SY
         mbLHH0oF1yunrIr36EbgKhx6dx9A+BlcWQIFEcbZ6neSq65CFwg3nx9+7wN/hhjPKYIq
         BMfuoXKR1mvuQEvJVGPJXeBm7QskK+Y9nsVBAXBM4MhCuoVxInqlYthclzBAMIpI/SrO
         KJZw==
X-Received: by 10.53.2.10 with SMTP id bk10mr1772270vdd.48.1409933560281; Fri,
 05 Sep 2014 09:12:40 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.52.32.225 with HTTP; Fri, 5 Sep 2014 09:12:20 -0700 (PDT)
In-Reply-To: <1409930280353-8293.post@n3.nabble.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
 <1409930280353-8293.post@n3.nabble.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Fri, 5 Sep 2014 09:12:20 -0700
Message-ID: <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a1133ba78048148050253bd88
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133ba78048148050253bd88
Content-Type: text/plain; charset=UTF-8

There's some work on this going on in the AMP Lab. Create a ticket and we
can update with our progress so that we don't duplicate effort.


On Fri, Sep 5, 2014 at 8:18 AM, Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
wrote:

> Hi RJ,
>
> Thank you for your comment. I am interested in to have other matrix
> operations too.
> I will create a JIRA issue in the first place.
>
> thanks,
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8293.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1133ba78048148050253bd88--

From dev-return-9328-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 16:18:52 2014
Return-Path: <dev-return-9328-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A30A3115CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 16:18:52 +0000 (UTC)
Received: (qmail 96340 invoked by uid 500); 5 Sep 2014 16:18:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96266 invoked by uid 500); 5 Sep 2014 16:18:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96254 invoked by uid 99); 5 Sep 2014 16:18:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:18:50 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:18:25 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XPwDP-0005LS-Rh
	for dev@spark.incubator.apache.org; Fri, 05 Sep 2014 09:18:23 -0700
Date: Fri, 5 Sep 2014 09:18:23 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409933903848-8296.post@n3.nabble.com>
In-Reply-To: <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com> <1409930280353-8293.post@n3.nabble.com> <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Evan, 

That's sounds interesting. 

Here is the ticket which I created.
https://issues.apache.org/jira/browse/SPARK-3416

thanks,



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8296.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9329-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 16:23:31 2014
Return-Path: <dev-return-9329-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 52C2A115F4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 16:23:31 +0000 (UTC)
Received: (qmail 9808 invoked by uid 500); 5 Sep 2014 16:23:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9742 invoked by uid 500); 5 Sep 2014 16:23:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9728 invoked by uid 99); 5 Sep 2014 16:23:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:23:29 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of shivaram@berkeley.edu designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:23:25 +0000
Received: by mail-wg0-f46.google.com with SMTP id n12so1061964wgh.29
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 09:23:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=ggkGZ4i3XaxnQ+fp3n/VjzT/B2uJN899XY4b+H8XbW0=;
        b=fGyWXzSNm7iVt0FFsxvbnhCVACXESwBdAn3ZajB1yaqUYA3NDWQ/W9h9KaDKcWmhKc
         dSl7EB+Lbz2YC9sDpoKVmP0X2Yv0hfm6BD9Vz7QJmH5zh0+Euv+PuMdDEA2DvHi3reOk
         NMODTvE9M4sF98xEL8qs4dls0mm/ovL6IOgwc+7Kxcz154aYJ94Zx4DsEaWW4lWs8MqE
         4QYrQMyPvVwCUTAXslLk4bsP2gDzHqajj+JSmY6PGX2g/Wh8/clmXCDgDPQgKMzm8t7s
         rBUbSKKNvFJ52jSPwRGhSDEZaX+BQJclr8NZZu0h2cVe+vyxjH55+oLa1VrAMbdVsbWt
         drAQ==
X-Gm-Message-State: ALoCoQllVzBYHEavrrauRDoySRslrWFEBmRPr+e6DasqlThVGybagvrZDsA2XU7xZRV+tSTRRb4e
MIME-Version: 1.0
X-Received: by 10.180.73.142 with SMTP id l14mr4953180wiv.83.1409934183942;
 Fri, 05 Sep 2014 09:23:03 -0700 (PDT)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.216.108.198 with HTTP; Fri, 5 Sep 2014 09:23:03 -0700 (PDT)
In-Reply-To: <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com>
	<CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
	<1409930280353-8293.post@n3.nabble.com>
	<CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
Date: Fri, 5 Sep 2014 09:23:03 -0700
Message-ID: <CAKx7Bf_CWpZNWq3LEDrfgXuCCuf9cGKBVQTG21AZFzY6vqX3RA@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
Cc: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

FWIW matrix multiplication is extremely communication intensive when
you have two row partitioned matrices and there are often other ways
to solve problems. Regardless, it would be good to have a more
complete matrix library and it would be good to contribute some of the
stuff we have done in the AMPLab to MLLib.

Shivaram

On Fri, Sep 5, 2014 at 9:12 AM, Evan R. Sparks <evan.sparks@gmail.com> wrote:
> There's some work on this going on in the AMP Lab. Create a ticket and we
> can update with our progress so that we don't duplicate effort.
>
>
> On Fri, Sep 5, 2014 at 8:18 AM, Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
> wrote:
>
>> Hi RJ,
>>
>> Thank you for your comment. I am interested in to have other matrix
>> operations too.
>> I will create a JIRA issue in the first place.
>>
>> thanks,
>>
>>
>>
>> --
>> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8293.html
>> Sent from the Apache Spark Developers List mailing list archive at
>> Nabble.com.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9330-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 16:23:48 2014
Return-Path: <dev-return-9330-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C109D115F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 16:23:48 +0000 (UTC)
Received: (qmail 11008 invoked by uid 500); 5 Sep 2014 16:23:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10943 invoked by uid 500); 5 Sep 2014 16:23:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10931 invoked by uid 99); 5 Sep 2014 16:23:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:23:47 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:23:43 +0000
Received: by mail-ob0-f174.google.com with SMTP id uz6so8780308obc.5
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 09:23:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HA3/qx/gDS7Vfi8hV1ispwasIMGukNi6XpIJi7aqv7U=;
        b=apmN4qFX13P6UVJUuFdqskN15Jix+B77kW5i0o/34DyrqfQwJK2kLryZ91r61ayz5L
         ldJwrfn9f3hkSYDpAi3Cg4SP3T0rhxw1ZakihbhlUpZ+BcHZSu9PoOshna0dF9kOkpRD
         ufzbYaFAtygutKMEyJt8CrY5sAZNJuzGDaz6NcSDuMMv/GW3WbyrEJtyeLzMp5lg+h8x
         a/QEqtK6XR6DrsSUUXJia7JlJxJeKtrxydB3Q4SSrnAtkuDQys1viJNuJpE7MO02hmYZ
         3azN4HgKbJvGmVsnsq+6Dyw0qoXeGzTYBQ9PlX5apmqgN21ZDIx4z4X5EZeGDtCPb/hu
         +Kfg==
MIME-Version: 1.0
X-Received: by 10.182.112.134 with SMTP id iq6mr15001645obb.34.1409934202854;
 Fri, 05 Sep 2014 09:23:22 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Fri, 5 Sep 2014 09:23:22 -0700 (PDT)
In-Reply-To: <1409933903848-8296.post@n3.nabble.com>
References: <1409909219731-8291.post@n3.nabble.com>
	<CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
	<1409930280353-8293.post@n3.nabble.com>
	<CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
	<1409933903848-8296.post@n3.nabble.com>
Date: Fri, 5 Sep 2014 09:23:22 -0700
Message-ID: <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: Patrick Wendell <pwendell@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey There,

I believe this is on the roadmap for the 1.2 next release. But
Xiangrui can comment on this.

- Patrick

On Fri, Sep 5, 2014 at 9:18 AM, Yu Ishikawa
<yuu.ishikawa+spark@gmail.com> wrote:
> Hi Evan,
>
> That's sounds interesting.
>
> Here is the ticket which I created.
> https://issues.apache.org/jira/browse/SPARK-3416
>
> thanks,
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8296.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9331-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 16:52:23 2014
Return-Path: <dev-return-9331-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7118411721
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 16:52:23 +0000 (UTC)
Received: (qmail 4083 invoked by uid 500); 5 Sep 2014 16:52:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4018 invoked by uid 500); 5 Sep 2014 16:52:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4000 invoked by uid 99); 5 Sep 2014 16:52:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:52:22 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.41 as permitted sender)
Received: from [209.85.216.41] (HELO mail-qa0-f41.google.com) (209.85.216.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 16:52:17 +0000
Received: by mail-qa0-f41.google.com with SMTP id m5so11182900qaj.0
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 09:51:56 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=8K+9qIXrjzinb7WM0wJxgY+5CfQMrfSOPbWMlmdsGiQ=;
        b=cUR1vO+Q+z47VVxAOhl+ybbAp3RjW75Tht7C6sWWnLzELq5TeVDnOKN4ixLsiCzKF4
         fUEs5TJUmXu3P0q0gjErfNH4Ay9X2FpcnlDnhKSgql2ysF88YXV90w9pe1zUEftv4V4y
         JcY4EEnoXXIbrzLNjEeCP9fohfBc6pufxzUQ02r+N5yT4/TLs+td6U5FJj9fshAf9h+7
         566UEgJso0Ksdu2zDZb7sQQW2NOUscqCitec/ED4UnNZ/yXFHAipt/9mzcNlfjn1lLFg
         CaGeV7g28nO/TapdqdJhRDbKcnfQX/d312mMIpnpqz4PpCMSk/l9nJ9MOY+taqfqYRYn
         6Faw==
X-Gm-Message-State: ALoCoQl52FTJeO1CiUHPJPx3P+wZb04JUgxKXDB7SG234lZovxiErYwX0q9fBxgZdyTRicT0l7u0
MIME-Version: 1.0
X-Received: by 10.140.109.75 with SMTP id k69mr19782616qgf.96.1409935915835;
 Fri, 05 Sep 2014 09:51:55 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Fri, 5 Sep 2014 09:51:55 -0700 (PDT)
In-Reply-To: <1409865435175-8279.post@n3.nabble.com>
References: <1409865435175-8279.post@n3.nabble.com>
Date: Fri, 5 Sep 2014 09:51:55 -0700
Message-ID: <CAAOnQ7sNwrnkSJtF43STssYEWFXayeACOXLBRLX1iKTzNPvwHg@mail.gmail.com>
Subject: Re: How to kill a Spark job running in local mode programmatically ?
From: Marcelo Vanzin <vanzin@cloudera.com>
To: randomuser54 <talktorohit54@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I don't think that's possible at the moment, mainly because
SparkSubmit expects it to be run from the command line, and not
programatically, so it doesn't return anything that can be used to
control what's going on. You may try to interrupt the thread calling
into SparkSubmit, but that might not work - especially if the app
doesn't handle it correctly.

Another thing to consider is that Spark itself doesn't play well with
multiple contexts running in the same JVM, so that would have to be
fixed before having SparkSubmit support that kind of use case.

Have you thought about spawning a child process to run SparkSubmit?
Then you can kill the underlying process if you need to.


On Thu, Sep 4, 2014 at 2:17 PM, randomuser54 <talktorohit54@gmail.com> wrot=
e:
> I have a java class which calls SparkSubmit.scala with all the arguments =
to
> run a spark job in a thread. I am running them in local mode for now but
> also want to run them in yarn-cluster mode later.
>
> Now, I want to kill the running spark job (which can be in local or
> yarn-cluster mode) programmatically.
>
> I know that SparkContext has a stop() method but from the thread from whi=
ch
> I am calling the SparkSubmit I don=E2=80=99t have access to it. Can someo=
ne suggest
> me how to do this properly ?
>
> Thanks.
>
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551=
.n3.nabble.com/How-to-kill-a-Spark-job-running-in-local-mode-programmatical=
ly-tp8279.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble=
.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>



--=20
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9332-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 17:24:03 2014
Return-Path: <dev-return-9332-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A39D11829
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 17:24:03 +0000 (UTC)
Received: (qmail 71028 invoked by uid 500); 5 Sep 2014 17:24:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70960 invoked by uid 500); 5 Sep 2014 17:24:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70948 invoked by uid 99); 5 Sep 2014 17:24:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 17:24:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 17:23:36 +0000
Received: by mail-lb0-f169.google.com with SMTP id p9so3182588lbv.28
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 10:23:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=n22iGaQmor4Ehsvwxe8rAIZQyd0TB54243Y0ulHMF1E=;
        b=PwLdmjMMFrPQf3POxj1hTQt/w2ixFwBJ4CVxrW8F9VaRP28MVuWJzJX8oWRZYsgjsM
         I1cBcdw8Eh+ou5BkW5iC1WAAlYuthEGCH47Hhh3o6MVvis3pyjn/eOC9xkfFj/IY7vb0
         JfHF3ujd4QLF6RnQRE8Vuz8jk9Uq6OAJnIqjPWNpoWrXZgb/D/bnNdb+h/6aZlGGD9oY
         Rtva9VlKaN9Ds2Zbi+ALYuQ60pa2oXcCVokhzi0rlF8ixHo7XMu4K3Gw6Mri9HD/VXIm
         DgaYgsMzq/ZV6I802AtDl2IDeveUozXO7oBXD28utihKwJhabvw5Q5Y5LUCp8t+wDUb0
         72ZA==
X-Gm-Message-State: ALoCoQnCJmUTW1PykLJJPn+Zinqr0zMpxq44fxrocr+vGOgl1+S+MhtqHErH+AV4pBsu1bKHc9qB
X-Received: by 10.152.203.167 with SMTP id kr7mr13325257lac.75.1409937814571;
 Fri, 05 Sep 2014 10:23:34 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Fri, 5 Sep 2014 10:23:14 -0700 (PDT)
In-Reply-To: <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com> <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 5 Sep 2014 10:23:14 -0700
Message-ID: <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a1134652e97d775050254ba4d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134652e97d775050254ba4d
Content-Type: text/plain; charset=UTF-8

it's looking like everything except the pull request builders are working.
 i'm going to be working on getting this resolved today.


On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Hmm, looks like at least some builds
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19804/consoleFull>
> are working now, though this last one was from ~5 hours ago.
>
>
> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> yep.  that's exactly the behavior i saw earlier, and will be figuring out
>> first thing tomorrow morning.  i bet it's an environment issues on the
>> slaves.
>>
>>
>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Looks like during the last build
>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
>>> Jenkins was unable to execute a git fetch?
>>>
>>>
>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>>> i'm going to restart jenkins and see if that fixes things.
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>>> looking
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>
>>>>>> It appears that our main man is having trouble
>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>>>  hearing new requests
>>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>>>
>>>>>> Do we need some smelling salts?
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>>
>>>>>>> i'd ping the Jenkinsmench...  the master was completely offline, so
>>>>>>> any new
>>>>>>> jobs wouldn't have reached it.  any jobs that were queued when power
>>>>>>> was
>>>>>>> lost probably started up, but jobs that were running would fail.
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>> nicholas.chammas@gmail.com
>>>>>>> > wrote:
>>>>>>>
>>>>>>> > Woohoo! Thanks Shane.
>>>>>>> >
>>>>>>> > Do you know if queued PR builds will automatically be picked up?
>>>>>>> Or do we
>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>>>> >
>>>>>>> > Nick
>>>>>>> >
>>>>>>> >
>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>> wrote:
>>>>>>> >
>>>>>>> >> AND WE'RE UP!
>>>>>>> >>
>>>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>>>> explanation
>>>>>>> >> of what happened soon.
>>>>>>> >>
>>>>>>> >> now, off to back up jenkins.
>>>>>>> >>
>>>>>>> >> shane
>>>>>>> >>
>>>>>>> >>
>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>> wrote:
>>>>>>> >>
>>>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>>>> swapped out.
>>>>>>> >> >  we're about to reboot and be good to go.
>>>>>>> >> >
>>>>>>> >> >
>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>> sknapp@berkeley.edu>
>>>>>>> >> wrote:
>>>>>>> >> >
>>>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>>>> replacement.
>>>>>>> >> i
>>>>>>> >> >> don't have more specific information yet -- including *what*
>>>>>>> failed,
>>>>>>> >> as our
>>>>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>>>>> circuit
>>>>>>> >> being
>>>>>>> >> >> switched off during building maintenance.
>>>>>>> >> >>
>>>>>>> >> >> on a side note, this incident will be accelerating our plan to
>>>>>>> move the
>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>>>> environment.
>>>>>>> >> this
>>>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>>>> details
>>>>>>> >> about
>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>> >> >>
>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything up and
>>>>>>> running
>>>>>>> >> >> ASAP.
>>>>>>> >> >>
>>>>>>> >> >>
>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>> sknapp@berkeley.edu>
>>>>>>> >> wrote:
>>>>>>> >> >>
>>>>>>> >> >>> looks like a power outage in soda hall.  more updates as they
>>>>>>> happen.
>>>>>>> >> >>>
>>>>>>> >> >>>
>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>> sknapp@berkeley.edu>
>>>>>>> >> >>> wrote:
>>>>>>> >> >>>
>>>>>>> >> >>>> i am trying to get things up and running, but it looks like
>>>>>>> either
>>>>>>> >> the
>>>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>>>> update as
>>>>>>> >> soon as
>>>>>>> >> >>>> i know more.
>>>>>>> >> >>>>
>>>>>>> >> >>>
>>>>>>> >> >>>
>>>>>>> >> >>
>>>>>>> >> >
>>>>>>> >>
>>>>>>> >
>>>>>>> >  --
>>>>>>> > You received this message because you are subscribed to the Google
>>>>>>> Groups
>>>>>>> > "amp-infra" group.
>>>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an
>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>>>> >
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a1134652e97d775050254ba4d--

From dev-return-9333-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 17:29:49 2014
Return-Path: <dev-return-9333-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CC00E11859
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 17:29:49 +0000 (UTC)
Received: (qmail 89159 invoked by uid 500); 5 Sep 2014 17:29:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89088 invoked by uid 500); 5 Sep 2014 17:29:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89072 invoked by uid 99); 5 Sep 2014 17:29:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 17:29:48 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of freeman.jeremy@gmail.com designates 209.85.192.43 as permitted sender)
Received: from [209.85.192.43] (HELO mail-qg0-f43.google.com) (209.85.192.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 17:29:22 +0000
Received: by mail-qg0-f43.google.com with SMTP id a108so1209494qge.30
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 10:29:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=QU7lqBQyjnqGO1I9j/lFmB08zk/Rx9KAaR/aVXD817w=;
        b=vl1O2YDhJVItYu3pfUWr2NO5p3qnwfYzNxqIpOXqFlubymPSAs9PQ8rEBd2E+C7RLY
         /4SKf7D/ep9z9NnyYPyBUmlfordgugM2omiBoA47YOFgRjfnbTZNRAmROvWvV3UOPpkX
         X87mwaxMeUl5sfHWZDz/dXGYrRPWnNUYOmOz26i1lfMuyqaHxW8o6w2Lba7MJJ/ahHjH
         QtzvZwyykSgmSmQAbrCjk4vt4FG6Oh/rlUC/MTZ0PhSqEHQ6yPtsymXTA8pN8lbW6n2j
         OVKRsp3UhdWZRp2LIlHKR9C+j2vC4r5kzuoVNmnKDCgH6ZX7ac5tfJTmcsS1KXebqzVt
         pndw==
X-Received: by 10.224.79.13 with SMTP id n13mr20590452qak.79.1409938160733;
        Fri, 05 Sep 2014 10:29:20 -0700 (PDT)
Received: from freemanj-wm1.hhmi.org (simcoe.janelia.org. [206.241.0.254])
        by mx.google.com with ESMTPSA id y1sm1289190qaj.34.2014.09.05.10.29.19
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 05 Sep 2014 10:29:19 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_88100823-C01A-4C8E-9E5F-C4ED1E527BBA"
Mime-Version: 1.0 (Mac OS X Mail 6.6 \(1510\))
Subject: Re: [mllib] Add multiplying large scale matrices
From: Jeremy Freeman <freeman.jeremy@gmail.com>
In-Reply-To: <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
Date: Fri, 5 Sep 2014 13:29:18 -0400
Cc: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,
 "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>,
 Xiangrui Meng <mengxr@gmail.com>
Message-Id: <EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com> <1409930280353-8293.post@n3.nabble.com> <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com> <1409933903848-8296.post@n3.nabble.com> <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
X-Mailer: Apple Mail (2.1510)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_88100823-C01A-4C8E-9E5F-C4ED1E527BBA
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=iso-8859-1

Hey all,=20

Definitely agreed this would be nice! In our own work we've done =
element-wise addition, subtraction, and scalar multiplication of =
similarly partitioned matrices very efficiently with zipping. We've also =
done matrix-matrix multiplication with zipping, but that only works in =
certain circumstances, and it's otherwise very communication intensive =
(as Shivaram says). Another tricky thing with addition / subtraction is =
how to handle sparse vs. dense arrays.

Would be happy to contribute anything we did, but definitely first worth =
knowing what progress has been made from the AMPLab.

-- Jeremy

---------------------
jeremy freeman, phd
neuroscientist
@thefreemanlab

On Sep 5, 2014, at 12:23 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey There,
>=20
> I believe this is on the roadmap for the 1.2 next release. But
> Xiangrui can comment on this.
>=20
> - Patrick
>=20
> On Fri, Sep 5, 2014 at 9:18 AM, Yu Ishikawa
> <yuu.ishikawa+spark@gmail.com> wrote:
>> Hi Evan,
>>=20
>> That's sounds interesting.
>>=20
>> Here is the ticket which I created.
>> https://issues.apache.org/jira/browse/SPARK-3416
>>=20
>> thanks,
>>=20
>>=20
>>=20
>> --
>> View this message in context: =
http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multip=
lying-large-scale-matrices-tp8291p8296.html
>> Sent from the Apache Spark Developers List mailing list archive at =
Nabble.com.
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


--Apple-Mail=_88100823-C01A-4C8E-9E5F-C4ED1E527BBA--

From dev-return-9334-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 20:16:35 2014
Return-Path: <dev-return-9334-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 225E411EF6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 20:16:35 +0000 (UTC)
Received: (qmail 44272 invoked by uid 500); 5 Sep 2014 20:16:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44206 invoked by uid 500); 5 Sep 2014 20:16:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44193 invoked by uid 99); 5 Sep 2014 20:16:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 20:16:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.170 as permitted sender)
Received: from [209.85.212.170] (HELO mail-wi0-f170.google.com) (209.85.212.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 20:16:30 +0000
Received: by mail-wi0-f170.google.com with SMTP id cc10so100273wib.1
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 13:16:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=fCRxmn0w6BIbori1h+UMk4u7RbbJQcl73f/JbOOmzLM=;
        b=ttk2/haFawVGbqxVym1O5hjf7nLtXG2WhJKJPnBq6iCBQ0+4K7Trut7cc025/bRmIk
         sw2Zsb5AkNhrAF4D+F6US9tzN6a5lWV2rN6dS4IgEUMMa/PDXL5tla+OZfuCwjDhkZuD
         RtHLaOrCRYPQNfUDEr3R3vBO6C2KRwfFJR7rHg5JFDPkLnRbgzy6by6xrg1fsZXOECXo
         g647oW/odzIxCHM4JBRfweLU1/24jK24eXMUrlJ5F2QoAHzazzD2d1WbEaaB3dLgZHUE
         McXnSyrqv0X0ivJEDkpehO9p7yOXZt+rz+omb5BYcywo425BMukKtGyOlF6FEvM7eiDT
         eccw==
X-Received: by 10.180.77.193 with SMTP id u1mr6051151wiw.45.1409948168639;
 Fri, 05 Sep 2014 13:16:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Fri, 5 Sep 2014 13:15:28 -0700 (PDT)
In-Reply-To: <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com> <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 5 Sep 2014 16:15:28 -0400
Message-ID: <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=f46d043d6759be5b0005025723e0
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043d6759be5b0005025723e0
Content-Type: text/plain; charset=UTF-8

How's it going?

It looks like during the last build
<https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/lastBuild/console>
from about 30 min ago Jenkins was still having trouble fetching from
GitHub. It also looks like not all requests for testing are triggering
builds.


On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu> wrote:

> it's looking like everything except the pull request builders are working.
>  i'm going to be working on getting this resolved today.
>
>
> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Hmm, looks like at least some builds
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19804/consoleFull>
>> are working now, though this last one was from ~5 hours ago.
>>
>>
>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> yep.  that's exactly the behavior i saw earlier, and will be figuring
>>> out first thing tomorrow morning.  i bet it's an environment issues on the
>>> slaves.
>>>
>>>
>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> Looks like during the last build
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
>>>> Jenkins was unable to execute a git fetch?
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>>> i'm going to restart jenkins and see if that fixes things.
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>>
>>>>>> looking
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>
>>>>>>> It appears that our main man is having trouble
>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>>>>  hearing new requests
>>>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>>>>
>>>>>>> Do we need some smelling salts?
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> i'd ping the Jenkinsmench...  the master was completely offline, so
>>>>>>>> any new
>>>>>>>> jobs wouldn't have reached it.  any jobs that were queued when
>>>>>>>> power was
>>>>>>>> lost probably started up, but jobs that were running would fail.
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>>> nicholas.chammas@gmail.com
>>>>>>>> > wrote:
>>>>>>>>
>>>>>>>> > Woohoo! Thanks Shane.
>>>>>>>> >
>>>>>>>> > Do you know if queued PR builds will automatically be picked up?
>>>>>>>> Or do we
>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>>>>> >
>>>>>>>> > Nick
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>>> wrote:
>>>>>>>> >
>>>>>>>> >> AND WE'RE UP!
>>>>>>>> >>
>>>>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>>>>> explanation
>>>>>>>> >> of what happened soon.
>>>>>>>> >>
>>>>>>>> >> now, off to back up jenkins.
>>>>>>>> >>
>>>>>>>> >> shane
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>>> wrote:
>>>>>>>> >>
>>>>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>>>>> swapped out.
>>>>>>>> >> >  we're about to reboot and be good to go.
>>>>>>>> >> >
>>>>>>>> >> >
>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>>> sknapp@berkeley.edu>
>>>>>>>> >> wrote:
>>>>>>>> >> >
>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>>>>> replacement.
>>>>>>>> >> i
>>>>>>>> >> >> don't have more specific information yet -- including *what*
>>>>>>>> failed,
>>>>>>>> >> as our
>>>>>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>>>>>> circuit
>>>>>>>> >> being
>>>>>>>> >> >> switched off during building maintenance.
>>>>>>>> >> >>
>>>>>>>> >> >> on a side note, this incident will be accelerating our plan
>>>>>>>> to move the
>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>>>>> environment.
>>>>>>>> >> this
>>>>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>>>>> details
>>>>>>>> >> about
>>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>>> >> >>
>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything up
>>>>>>>> and running
>>>>>>>> >> >> ASAP.
>>>>>>>> >> >>
>>>>>>>> >> >>
>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>>> sknapp@berkeley.edu>
>>>>>>>> >> wrote:
>>>>>>>> >> >>
>>>>>>>> >> >>> looks like a power outage in soda hall.  more updates as
>>>>>>>> they happen.
>>>>>>>> >> >>>
>>>>>>>> >> >>>
>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>>> sknapp@berkeley.edu>
>>>>>>>> >> >>> wrote:
>>>>>>>> >> >>>
>>>>>>>> >> >>>> i am trying to get things up and running, but it looks like
>>>>>>>> either
>>>>>>>> >> the
>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>>>>> update as
>>>>>>>> >> soon as
>>>>>>>> >> >>>> i know more.
>>>>>>>> >> >>>>
>>>>>>>> >> >>>
>>>>>>>> >> >>>
>>>>>>>> >> >>
>>>>>>>> >> >
>>>>>>>> >>
>>>>>>>> >
>>>>>>>> >  --
>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>> Google Groups
>>>>>>>> > "amp-infra" group.
>>>>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an
>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>>>>> >
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--f46d043d6759be5b0005025723e0--

From dev-return-9335-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 22:15:32 2014
Return-Path: <dev-return-9335-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8549511418
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 22:15:32 +0000 (UTC)
Received: (qmail 55575 invoked by uid 500); 5 Sep 2014 22:15:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55507 invoked by uid 500); 5 Sep 2014 22:15:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55488 invoked by uid 99); 5 Sep 2014 22:15:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 22:15:31 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.223.173 as permitted sender)
Received: from [209.85.223.173] (HELO mail-ie0-f173.google.com) (209.85.223.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 22:15:27 +0000
Received: by mail-ie0-f173.google.com with SMTP id lx4so14810471iec.4
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 15:15:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=uPCo9EbvYQfqHaWVID0DFTXiVXiONmXWpjuAwaiVjPM=;
        b=LZ8M2weWqsxPdK0tflIxgtg1hzWN7QfWT8TlVgKCRyJkQ1tmOFLXkDYxn5OPWfoi53
         3P1zsf8aTmcwPw5VLqLMpbbevIC218MXQijE414xlmVsQ9w81obokA2tA3WpOtFyLtCo
         8SC/jocvnuDn3EpZgxzRIgOeRK2w7djHiSI+TjFPcG8ZprE0m/V3u/sCMSSaSQfC6WwF
         92qONOnG3cqeZuf6709VaivS6WUV/DxBzKWqeiORX9zqizPe7y87Phn2JfZMCBy8tDUi
         cnStxMNfpHoWbUVAzFnponu180taW875svfOlpEqfHnqe6TlKmo+dgGkxpqzLCSRyP6B
         UaVg==
X-Received: by 10.50.88.72 with SMTP id be8mr8554503igb.26.1409955306922; Fri,
 05 Sep 2014 15:15:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.128.161 with HTTP; Fri, 5 Sep 2014 15:14:36 -0700 (PDT)
In-Reply-To: <CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
 <CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
 <CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com> <CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Fri, 5 Sep 2014 15:14:36 -0700
Message-ID: <CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
To: Koert Kuipers <koert@tresata.com>
Cc: Felix Garcia Borrego <fborrego@gilt.com>, Sean Owen <sowen@cloudera.com>, 
	Aniket Bhatnagar <aniket.bhatnagar@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013cbeb438a95e050258cdce
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013cbeb438a95e050258cdce
Content-Type: text/plain; charset=UTF-8

If httpClient dependency is coming from Hive, you could build Spark without
Hive. Alternatively, have you tried excluding httpclient from
spark-streaming dependency in your sbt/maven project?

TD



On Thu, Sep 4, 2014 at 6:42 AM, Koert Kuipers <koert@tresata.com> wrote:

> custom spark builds should not be the answer. at least not if spark ever
> wants to have a vibrant community for spark apps.
>
> spark does support a user-classpath-first option, which would deal with
> some of these issues, but I don't think it works.
> On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com> wrote:
>
> > Hi,
> > I run into the same issue and apart from the ideas Aniket said, I only
> > could find a nasty workaround. Add my custom
> PoolingClientConnectionManager
> > to my classpath.
> >
> >
> >
> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
> >
> >
> >
> > On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com> wrote:
> >
> > > Dumb question -- are you using a Spark build that includes the Kinesis
> > > dependency? that build would have resolved conflicts like this for
> > > you. Your app would need to use the same version of the Kinesis client
> > > SDK, ideally.
> > >
> > > All of these ideas are well-known, yes. In cases of super-common
> > > dependencies like Guava, they are already shaded. This is a
> > > less-common source of conflicts so I don't think http-client is
> > > shaded, especially since it is not used directly by Spark. I think
> > > this is a case of your app conflicting with a third-party dependency?
> > >
> > > I think OSGi is deemed too over the top for things like this.
> > >
> > > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
> > > <aniket.bhatnagar@gmail.com> wrote:
> > > > I am trying to use Kinesis as source to Spark Streaming and have run
> > > into a
> > > > dependency issue that can't be resolved without making my own custom
> > > Spark
> > > > build. The issue is that Spark is transitively dependent
> > > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because of
> > > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is
> dependent
> > > > on org.apache.httpcomponents:httpclient:jar:4.2. When I package and
> run
> > > > Spark Streaming application, I get the following:
> > > >
> > > > Caused by: java.lang.NoSuchMethodError:
> > > >
> > >
> >
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
> > > >         at
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
> > > >         at
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
> > > >         at
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
> > > >         at
> > > > com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
> > > >         at
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
> > > >
> > > > I can create a custom Spark build with
> > > > org.apache.httpcomponents:httpclient:jar:4.2 included in the assembly
> > > but I
> > > > was wondering if this is something Spark devs have noticed and are
> > > looking
> > > > to resolve in near releases. Here are my thoughts on this issue:
> > > >
> > > > Containers that allow running custom user code have to often resolve
> > > > dependency issues in case of conflicts between framework's and user
> > > code's
> > > > dependency. Here is how I have seen some frameworks resolve the
> issue:
> > > > 1. Provide a child-first class loader: Some JEE containers provided a
> > > > child-first class loader that allowed for loading classes from user
> > code
> > > > first. I don't think this approach completely solves the problem as
> the
> > > > framework is then susceptible to class mismatch errors.
> > > > 2. Fold in all dependencies in a sub-package: This approach involves
> > > > folding all dependencies in a project specific sub-package (like
> > > > spark.dependencies). This approach is tedious because it involves
> > > building
> > > > custom version of all dependencies (and their transitive
> dependencies)
> > > > 3. Use something like OSGi: Some frameworks has successfully used
> OSGi
> > to
> > > > manage dependencies between the modules. The challenge in this
> approach
> > > is
> > > > to OSGify the framework and hide OSGi complexities from end user.
> > > >
> > > > My personal preference is OSGi (or atleast some support for OSGi)
> but I
> > > > would love to hear what Spark devs are thinking in terms of resolving
> > the
> > > > problem.
> > > >
> > > > Thanks,
> > > > Aniket
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--089e013cbeb438a95e050258cdce--

From dev-return-9336-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep  5 23:14:55 2014
Return-Path: <dev-return-9336-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8A183116AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  5 Sep 2014 23:14:55 +0000 (UTC)
Received: (qmail 1248 invoked by uid 500); 5 Sep 2014 23:14:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1183 invoked by uid 500); 5 Sep 2014 23:14:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1171 invoked by uid 99); 5 Sep 2014 23:14:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 23:14:53 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.53 as permitted sender)
Received: from [209.85.213.53] (HELO mail-yh0-f53.google.com) (209.85.213.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 05 Sep 2014 23:14:49 +0000
Received: by mail-yh0-f53.google.com with SMTP id a41so7805140yho.12
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 16:14:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Z9XLbC3x6IYJ0/AP5HLJOaIiiLnTbcNdviA2l11l0Ys=;
        b=a1VA0yAEyad/xDRI7tkoNQ4YRHsnmJmmhGjIgaMQK79qdEjmxnU8FlT6Ch+Y805/P9
         uMT0AIbe7LaGjX33PW/WBaJVALDUOXXERGUS4rfDbCG5XfhdGX8HXuLd0phjwd+wnc8+
         iQ6Od6Zh8G/K9NHMbCfINpgkTvAUvMRTAtA5jWAtLYBbZxNExUJk2YjRiPYJ+gUKt2E0
         Onl3/SPa/svjb8ALQqhi11j5Rt1/1CXS4p3OQcvz2MvDnTFM2OIIIWgT7tlUA5JHsuQM
         Q+e9toT0Q9yk5WtilaPZxCUbiGBX5EbVdFcmY8D3Bi9LyJKryxKBTDJsRmCKnu0lqP52
         AIjA==
MIME-Version: 1.0
X-Received: by 10.236.87.100 with SMTP id x64mr19020691yhe.47.1409958868941;
 Fri, 05 Sep 2014 16:14:28 -0700 (PDT)
Received: by 10.170.136.14 with HTTP; Fri, 5 Sep 2014 16:14:28 -0700 (PDT)
In-Reply-To: <CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
	<CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
	<CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
	<CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
	<CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
Date: Fri, 5 Sep 2014 16:14:28 -0700
Message-ID: <CALte62yLoTaw4u2M7=G=zLXkaXAMNEs8zOJB9ogs6+1hyRQZtQ@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
From: Ted Yu <yuzhihong@gmail.com>
To: Tathagata Das <tathagata.das1565@gmail.com>
Cc: Koert Kuipers <koert@tresata.com>, Felix Garcia Borrego <fborrego@gilt.com>, Sean Owen <sowen@cloudera.com>, 
	Aniket Bhatnagar <aniket.bhatnagar@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf300fb4f9880147050259a168
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf300fb4f9880147050259a168
Content-Type: text/plain; charset=UTF-8

>From output of dependency:tree:

[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @
spark-streaming_2.10 ---
[INFO] org.apache.spark:spark-streaming_2.10:jar:1.1.0-SNAPSHOT
INFO] +- org.apache.spark:spark-core_2.10:jar:1.1.0-SNAPSHOT:compile
[INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.4.0:compile
...
[INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile
[INFO] |  |  +- commons-codec:commons-codec:jar:1.5:compile
[INFO] |  |  +- org.apache.httpcomponents:httpclient:jar:4.1.2:compile
[INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.1.2:compile

bq. excluding httpclient from spark-streaming dependency in your sbt/maven
project

This should work.


On Fri, Sep 5, 2014 at 3:14 PM, Tathagata Das <tathagata.das1565@gmail.com>
wrote:

> If httpClient dependency is coming from Hive, you could build Spark without
> Hive. Alternatively, have you tried excluding httpclient from
> spark-streaming dependency in your sbt/maven project?
>
> TD
>
>
>
> On Thu, Sep 4, 2014 at 6:42 AM, Koert Kuipers <koert@tresata.com> wrote:
>
> > custom spark builds should not be the answer. at least not if spark ever
> > wants to have a vibrant community for spark apps.
> >
> > spark does support a user-classpath-first option, which would deal with
> > some of these issues, but I don't think it works.
> > On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com>
> wrote:
> >
> > > Hi,
> > > I run into the same issue and apart from the ideas Aniket said, I only
> > > could find a nasty workaround. Add my custom
> > PoolingClientConnectionManager
> > > to my classpath.
> > >
> > >
> > >
> >
> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
> > >
> > >
> > >
> > > On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com> wrote:
> > >
> > > > Dumb question -- are you using a Spark build that includes the
> Kinesis
> > > > dependency? that build would have resolved conflicts like this for
> > > > you. Your app would need to use the same version of the Kinesis
> client
> > > > SDK, ideally.
> > > >
> > > > All of these ideas are well-known, yes. In cases of super-common
> > > > dependencies like Guava, they are already shaded. This is a
> > > > less-common source of conflicts so I don't think http-client is
> > > > shaded, especially since it is not used directly by Spark. I think
> > > > this is a case of your app conflicting with a third-party dependency?
> > > >
> > > > I think OSGi is deemed too over the top for things like this.
> > > >
> > > > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
> > > > <aniket.bhatnagar@gmail.com> wrote:
> > > > > I am trying to use Kinesis as source to Spark Streaming and have
> run
> > > > into a
> > > > > dependency issue that can't be resolved without making my own
> custom
> > > > Spark
> > > > > build. The issue is that Spark is transitively dependent
> > > > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think because
> of
> > > > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is
> > dependent
> > > > > on org.apache.httpcomponents:httpclient:jar:4.2. When I package and
> > run
> > > > > Spark Streaming application, I get the following:
> > > > >
> > > > > Caused by: java.lang.NoSuchMethodError:
> > > > >
> > > >
> > >
> >
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
> > > > >         at
> > > > >
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
> > > > >         at
> > > > >
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
> > > > >         at
> > > > >
> > > >
> > >
> >
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
> > > > >         at
> > > > >
> com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
> > > > >         at
> > > > >
> > > >
> > >
> >
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
> > > > >
> > > > > I can create a custom Spark build with
> > > > > org.apache.httpcomponents:httpclient:jar:4.2 included in the
> assembly
> > > > but I
> > > > > was wondering if this is something Spark devs have noticed and are
> > > > looking
> > > > > to resolve in near releases. Here are my thoughts on this issue:
> > > > >
> > > > > Containers that allow running custom user code have to often
> resolve
> > > > > dependency issues in case of conflicts between framework's and user
> > > > code's
> > > > > dependency. Here is how I have seen some frameworks resolve the
> > issue:
> > > > > 1. Provide a child-first class loader: Some JEE containers
> provided a
> > > > > child-first class loader that allowed for loading classes from user
> > > code
> > > > > first. I don't think this approach completely solves the problem as
> > the
> > > > > framework is then susceptible to class mismatch errors.
> > > > > 2. Fold in all dependencies in a sub-package: This approach
> involves
> > > > > folding all dependencies in a project specific sub-package (like
> > > > > spark.dependencies). This approach is tedious because it involves
> > > > building
> > > > > custom version of all dependencies (and their transitive
> > dependencies)
> > > > > 3. Use something like OSGi: Some frameworks has successfully used
> > OSGi
> > > to
> > > > > manage dependencies between the modules. The challenge in this
> > approach
> > > > is
> > > > > to OSGify the framework and hide OSGi complexities from end user.
> > > > >
> > > > > My personal preference is OSGi (or atleast some support for OSGi)
> > but I
> > > > > would love to hear what Spark devs are thinking in terms of
> resolving
> > > the
> > > > > problem.
> > > > >
> > > > > Thanks,
> > > > > Aniket
> > > >
> > > > ---------------------------------------------------------------------
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > > >
> > >
> >
>

--20cf300fb4f9880147050259a168--

From dev-return-9337-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 00:34:10 2014
Return-Path: <dev-return-9337-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90D2911B9D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 00:34:10 +0000 (UTC)
Received: (qmail 84012 invoked by uid 500); 6 Sep 2014 00:34:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83945 invoked by uid 500); 6 Sep 2014 00:34:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83924 invoked by uid 99); 6 Sep 2014 00:34:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:34:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:34:03 +0000
Received: by mail-wi0-f177.google.com with SMTP id cc10so177876wib.10
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 17:33:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=CVgHvHgmAcgCP9loAsFvfX4N0oMd3CuJkysha+Hb/3k=;
        b=DOW38AoX7qe4xkAI65+UJlUpSzFT3rIOcb32JaXXnIyaK1bN8/OU/23K58DenzXFux
         rOVYzln5iRVy3CMsThiH5PB1RfeOFnALiLKZFCIL2FMWjkiiOh+z3HsZwRCJMGYyVUBy
         cH2/88KgTAhdq2LVgo6gwybENl9oBgQwFwXvGSuOMuNVwev0r1gdY6phhZmYkOQAtHKa
         O3KvQ2Kis57iDVlnCIKv01Vh6p6MMFAj/BMsKJuGOwHbmuGWGDSXBkEhqCa5BGd2rfEt
         IlML8t6qdd5rsK5VLGEx0EU6Sn9Jdve2BDkME3cR/NNpaRQL9+ImBGcGZ4nOilyUYT+V
         qp+w==
X-Received: by 10.180.77.193 with SMTP id u1mr7012624wiw.45.1409963622233;
 Fri, 05 Sep 2014 17:33:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Fri, 5 Sep 2014 17:33:02 -0700 (PDT)
In-Reply-To: <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com> <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 5 Sep 2014 20:33:02 -0400
Message-ID: <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=f46d043d6759d97b3805025abc38
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043d6759d97b3805025abc38
Content-Type: text/plain; charset=UTF-8

Looks like Jenkins is back!

lol The poor guy has like a million builds
<https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
to catch up on.


On Fri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> How's it going?
>
> It looks like during the last build
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/lastBuild/console>
> from about 30 min ago Jenkins was still having trouble fetching from
> GitHub. It also looks like not all requests for testing are triggering
> builds.
>
>
> On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> it's looking like everything except the pull request builders are
>> working.  i'm going to be working on getting this resolved today.
>>
>>
>> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Hmm, looks like at least some builds
>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19804/consoleFull>
>>> are working now, though this last one was from ~5 hours ago.
>>>
>>>
>>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>>> yep.  that's exactly the behavior i saw earlier, and will be figuring
>>>> out first thing tomorrow morning.  i bet it's an environment issues on the
>>>> slaves.
>>>>
>>>>
>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> Looks like during the last build
>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
>>>>> Jenkins was unable to execute a git fetch?
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>>
>>>>>> i'm going to restart jenkins and see if that fixes things.
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>>
>>>>>>> looking
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>>
>>>>>>>> It appears that our main man is having trouble
>>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>>>>>  hearing new requests
>>>>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>>>>>
>>>>>>>> Do we need some smelling salts?
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> i'd ping the Jenkinsmench...  the master was completely offline,
>>>>>>>>> so any new
>>>>>>>>> jobs wouldn't have reached it.  any jobs that were queued when
>>>>>>>>> power was
>>>>>>>>> lost probably started up, but jobs that were running would fail.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>>>> nicholas.chammas@gmail.com
>>>>>>>>> > wrote:
>>>>>>>>>
>>>>>>>>> > Woohoo! Thanks Shane.
>>>>>>>>> >
>>>>>>>>> > Do you know if queued PR builds will automatically be picked up?
>>>>>>>>> Or do we
>>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>>>>>> >
>>>>>>>>> > Nick
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>>>> wrote:
>>>>>>>>> >
>>>>>>>>> >> AND WE'RE UP!
>>>>>>>>> >>
>>>>>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>>>>>> explanation
>>>>>>>>> >> of what happened soon.
>>>>>>>>> >>
>>>>>>>>> >> now, off to back up jenkins.
>>>>>>>>> >>
>>>>>>>>> >> shane
>>>>>>>>> >>
>>>>>>>>> >>
>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>>>>>>>>> sknapp@berkeley.edu> wrote:
>>>>>>>>> >>
>>>>>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>>>>>> swapped out.
>>>>>>>>> >> >  we're about to reboot and be good to go.
>>>>>>>>> >> >
>>>>>>>>> >> >
>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>> >> wrote:
>>>>>>>>> >> >
>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>>>>>> replacement.
>>>>>>>>> >> i
>>>>>>>>> >> >> don't have more specific information yet -- including *what*
>>>>>>>>> failed,
>>>>>>>>> >> as our
>>>>>>>>> >> >> sysadmin is super busy ATM.  the root cause was an incorrect
>>>>>>>>> circuit
>>>>>>>>> >> being
>>>>>>>>> >> >> switched off during building maintenance.
>>>>>>>>> >> >>
>>>>>>>>> >> >> on a side note, this incident will be accelerating our plan
>>>>>>>>> to move the
>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>>>>>> environment.
>>>>>>>>> >> this
>>>>>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>>>>>> details
>>>>>>>>> >> about
>>>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>>>> >> >>
>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything up
>>>>>>>>> and running
>>>>>>>>> >> >> ASAP.
>>>>>>>>> >> >>
>>>>>>>>> >> >>
>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>> >> wrote:
>>>>>>>>> >> >>
>>>>>>>>> >> >>> looks like a power outage in soda hall.  more updates as
>>>>>>>>> they happen.
>>>>>>>>> >> >>>
>>>>>>>>> >> >>>
>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>> >> >>> wrote:
>>>>>>>>> >> >>>
>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks
>>>>>>>>> like either
>>>>>>>>> >> the
>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>>>>>> update as
>>>>>>>>> >> soon as
>>>>>>>>> >> >>>> i know more.
>>>>>>>>> >> >>>>
>>>>>>>>> >> >>>
>>>>>>>>> >> >>>
>>>>>>>>> >> >>
>>>>>>>>> >> >
>>>>>>>>> >>
>>>>>>>>> >
>>>>>>>>> >  --
>>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>>> Google Groups
>>>>>>>>> > "amp-infra" group.
>>>>>>>>> > To unsubscribe from this group and stop receiving emails from
>>>>>>>>> it, send an
>>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>>>>>> >
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--f46d043d6759d97b3805025abc38--

From dev-return-9338-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 00:36:30 2014
Return-Path: <dev-return-9338-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6BAA611BAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 00:36:30 +0000 (UTC)
Received: (qmail 89531 invoked by uid 500); 6 Sep 2014 00:36:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89466 invoked by uid 500); 6 Sep 2014 00:36:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89455 invoked by uid 99); 6 Sep 2014 00:36:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:36:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:36:03 +0000
Received: by mail-la0-f49.google.com with SMTP id b17so14515262lan.8
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 17:36:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=StlQJmw4PdF0YExGlpm0nQ4etkFt+l+3BppndKmTlso=;
        b=kiOCwjEnZHS5Y6cyX60ACR3oB3bEZeLA7kUkElDR//6hup18fxbUVwaeK9rBf8HYxt
         njzXoCTVvomn7ttMwixxy7tIXc/THYojcSxJsEHhzAfsYoZS1DVLzf4dgSKJaKF2Qk8x
         WRSr0NF89buQiti6h2z+jiX+lH1KE2swUrmFA/r0S6H7vzPlO+mlYn0GM5mBu13nztCi
         tryURjNMiUD+gbxd1MNcIrcMsP1ua8B225/fQKtZPc8fuwTSrCvvAIUtKNrZ/24M/Yex
         cjSpiqYiRwBHSM5g2Z5s9KB/HjrX7NlGODhLoiLSC1V6uw83A8dao1ZCYJmjaQsRNNlK
         9rSA==
X-Gm-Message-State: ALoCoQmdwJELyqskogknyncFpfDkI0SFIW647i4ciDo1xhaJiNBI4ZsstWnva/mIBxpnHVWJxLzQ
X-Received: by 10.112.55.238 with SMTP id v14mr8969lbp.93.1409963761179; Fri,
 05 Sep 2014 17:36:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Fri, 5 Sep 2014 17:35:41 -0700 (PDT)
In-Reply-To: <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com> <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 5 Sep 2014 17:35:41 -0700
Message-ID: <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a1133c96621b4cb05025ac534
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133c96621b4cb05025ac534
Content-Type: text/plain; charset=UTF-8

yeah, it was a problem w/the PRB's OAuth key.  josh rosen added a new key,
and magique!

we're about to clear the queue of all builds as most aren't wanted/needed.


On Fri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Looks like Jenkins is back!
>
> lol The poor guy has like a million builds
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
> to catch up on.
>
>
> On Fri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> How's it going?
>>
>> It looks like during the last build
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/lastBuild/console>
>> from about 30 min ago Jenkins was still having trouble fetching from
>> GitHub. It also looks like not all requests for testing are triggering
>> builds.
>>
>>
>> On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> it's looking like everything except the pull request builders are
>>> working.  i'm going to be working on getting this resolved today.
>>>
>>>
>>> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> Hmm, looks like at least some builds
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19804/consoleFull>
>>>> are working now, though this last one was from ~5 hours ago.
>>>>
>>>>
>>>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>>> yep.  that's exactly the behavior i saw earlier, and will be figuring
>>>>> out first thing tomorrow morning.  i bet it's an environment issues on the
>>>>> slaves.
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>
>>>>>> Looks like during the last build
>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/19797/console>
>>>>>> Jenkins was unable to execute a git fetch?
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>>
>>>>>>> i'm going to restart jenkins and see if that fixes things.
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> looking
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>>>
>>>>>>>>> It appears that our main man is having trouble
>>>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job/SparkPullRequestBuilder/>
>>>>>>>>>  hearing new requests
>>>>>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>>>>>>>>
>>>>>>>>> Do we need some smelling salts?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>>> i'd ping the Jenkinsmench...  the master was completely offline,
>>>>>>>>>> so any new
>>>>>>>>>> jobs wouldn't have reached it.  any jobs that were queued when
>>>>>>>>>> power was
>>>>>>>>>> lost probably started up, but jobs that were running would fail.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>>>>> nicholas.chammas@gmail.com
>>>>>>>>>> > wrote:
>>>>>>>>>>
>>>>>>>>>> > Woohoo! Thanks Shane.
>>>>>>>>>> >
>>>>>>>>>> > Do you know if queued PR builds will automatically be picked
>>>>>>>>>> up? Or do we
>>>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>>>>>>>>> >
>>>>>>>>>> > Nick
>>>>>>>>>> >
>>>>>>>>>> >
>>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
>>>>>>>>>> sknapp@berkeley.edu> wrote:
>>>>>>>>>> >
>>>>>>>>>> >> AND WE'RE UP!
>>>>>>>>>> >>
>>>>>>>>>> >> sorry that this took so long...  i'll send out a more detailed
>>>>>>>>>> explanation
>>>>>>>>>> >> of what happened soon.
>>>>>>>>>> >>
>>>>>>>>>> >> now, off to back up jenkins.
>>>>>>>>>> >>
>>>>>>>>>> >> shane
>>>>>>>>>> >>
>>>>>>>>>> >>
>>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>>>>>>>>>> sknapp@berkeley.edu> wrote:
>>>>>>>>>> >>
>>>>>>>>>> >> > it's a faulty power switch on the firewall, which has been
>>>>>>>>>> swapped out.
>>>>>>>>>> >> >  we're about to reboot and be good to go.
>>>>>>>>>> >> >
>>>>>>>>>> >> >
>>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >
>>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a
>>>>>>>>>> replacement.
>>>>>>>>>> >> i
>>>>>>>>>> >> >> don't have more specific information yet -- including
>>>>>>>>>> *what* failed,
>>>>>>>>>> >> as our
>>>>>>>>>> >> >> sysadmin is super busy ATM.  the root cause was an
>>>>>>>>>> incorrect circuit
>>>>>>>>>> >> being
>>>>>>>>>> >> >> switched off during building maintenance.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> on a side note, this incident will be accelerating our plan
>>>>>>>>>> to move the
>>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
>>>>>>>>>> environment.
>>>>>>>>>> >> this
>>>>>>>>>> >> >> will be our major push over the next couple of weeks.  more
>>>>>>>>>> details
>>>>>>>>>> >> about
>>>>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything up
>>>>>>>>>> and running
>>>>>>>>>> >> >> ASAP.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>> looks like a power outage in soda hall.  more updates as
>>>>>>>>>> they happen.
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>>>>> sknapp@berkeley.edu>
>>>>>>>>>> >> >>> wrote:
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks
>>>>>>>>>> like either
>>>>>>>>>> >> the
>>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down.  i'll
>>>>>>>>>> update as
>>>>>>>>>> >> soon as
>>>>>>>>>> >> >>>> i know more.
>>>>>>>>>> >> >>>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >
>>>>>>>>>> >>
>>>>>>>>>> >
>>>>>>>>>> >  --
>>>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>>>> Google Groups
>>>>>>>>>> > "amp-infra" group.
>>>>>>>>>> > To unsubscribe from this group and stop receiving emails from
>>>>>>>>>> it, send an
>>>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>>>>>>>>> > For more options, visit https://groups.google.com/d/optout.
>>>>>>>>>> >
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a1133c96621b4cb05025ac534--

From dev-return-9339-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 00:50:02 2014
Return-Path: <dev-return-9339-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9D25811C08
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 00:50:02 +0000 (UTC)
Received: (qmail 4528 invoked by uid 500); 6 Sep 2014 00:50:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4463 invoked by uid 500); 6 Sep 2014 00:50:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4451 invoked by uid 99); 6 Sep 2014 00:50:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:50:01 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.174 as permitted sender)
Received: from [209.85.192.174] (HELO mail-pd0-f174.google.com) (209.85.192.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 00:49:34 +0000
Received: by mail-pd0-f174.google.com with SMTP id v10so3096025pde.33
        for <dev@spark.apache.org>; Fri, 05 Sep 2014 17:49:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=AwKqF9M+6Ky35Y5ct/5TEi6ebK42HGWc6CmU5Jys+ZQ=;
        b=XrBdR30kCDuPMKNe13aVo/gpnTBzWp3nxJNr0//LTt2v6SPtuReFZ24UmTTnofPf05
         N2vJHtzLw0sGc0PBcvZ5m5E6gPE+5lZQvLGZc6dl8toZnHt08op808KG7zJP8ovrgED1
         KsXNSGFGcPs9QmHTkSn6OhQYndEQDslZWWdrA+7F4nDk+sf/3RgfBulx2fg+sZvfOt3a
         WBgw6ueMMObvIG05/PTUIQMyqcQ6xo+Jhh2LZkc8NV30WC9sCf1Az0L+h44LIL/QYcJK
         nzMCfhmBbuo4oHmLoqBn46rgalnUfZAXnj2qm11SCJSpX+B92Y32jyyumrZfg1qBhpFX
         HgiQ==
X-Received: by 10.68.222.168 with SMTP id qn8mr618962pbc.114.1409964573039;
        Fri, 05 Sep 2014 17:49:33 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id pp2sm2698656pbc.66.2014.09.05.17.49.32
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 05 Sep 2014 17:49:32 -0700 (PDT)
Date: Fri, 5 Sep 2014 17:49:31 -0700
From: Josh Rosen <rosenville@gmail.com>
To: shane knapp <sknapp@berkeley.edu>, Nicholas Chammas
 <nicholas.chammas@gmail.com>
Cc: Matthew L Massie <massie@cs.berkeley.edu>, Mike Patterson
 <mike@databricks.com>, dev <dev@spark.apache.org>, amp-infra
 <amp-infra@googlegroups.com>
Message-ID: <etPan.540a5a1b.238e1f29.112@joshs-mbp>
In-Reply-To: <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
 <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
 <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
Subject: Re: amplab jenkins is down
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540a5a1b_46e87ccd_112"
X-Virus-Checked: Checked by ClamAV on apache.org

--540a5a1b_46e87ccd_112
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

We have successfully purged Jenkins=E2=80=99 build queue. =C2=A0If you wa=
nt a PR to be re-tested, please ask Jenkins again.

On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp=40berkeley.edu) w=
rote:

yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new key,=
 =20
and magique=21 =20

we're about to clear the queue of all builds as most aren't wanted/needed=
. =20


On =46ri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <nicholas.chammas=40gm=
ail.com =20
> wrote: =20

> Looks like Jenkins is back=21 =20
> =20
> lol The poor guy has like a million builds =20
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/=
job/SparkPullRequestBuilder/> =20
> to catch up on. =20
> =20
> =20
> On =46ri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas < =20
> nicholas.chammas=40gmail.com> wrote: =20
> =20
>> How's it going=3F =20
>> =20
>> It looks like during the last build =20
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders=
/job/SparkPullRequestBuilder/lastBuild/console> =20
>> from about 30 min ago Jenkins was still having trouble fetching from =20
>> GitHub. It also looks like not all requests for testing are triggering=
 =20
>> builds. =20
>> =20
>> =20
>> On =46ri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp=40berkeley.edu> =
wrote: =20
>> =20
>>> it's looking like everything except the pull request builders are =20
>>> working. i'm going to be working on getting this resolved today. =20
>>> =20
>>> =20
>>> On =46ri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas < =20
>>> nicholas.chammas=40gmail.com> wrote: =20
>>> =20
>>>> Hmm, looks like at least some builds =20
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builde=
rs/job/SparkPullRequestBuilder/19804/console=46ull> =20
>>>> are working now, though this last one was from =7E5 hours ago. =20
>>>> =20
>>>> =20
>>>> On =46ri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp=40berkeley.edu=
> =20
>>>> wrote: =20
>>>> =20
>>>>> yep. that's exactly the behavior i saw earlier, and will be figurin=
g =20
>>>>> out first thing tomorrow morning. i bet it's an environment issues =
on the =20
>>>>> slaves. =20
>>>>> =20
>>>>> =20
>>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas < =20
>>>>> nicholas.chammas=40gmail.com> wrote: =20
>>>>> =20
>>>>>> Looks like during the last build =20
>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Buil=
ders/job/SparkPullRequestBuilder/19797/console> =20
>>>>>> Jenkins was unable to execute a git fetch=3F =20
>>>>>> =20
>>>>>> =20
>>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp=40berkeley.edu=
> =20
>>>>>> wrote: =20
>>>>>> =20
>>>>>>> i'm going to restart jenkins and see if that fixes things. =20
>>>>>>> =20
>>>>>>> =20
>>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp=40berkeley.ed=
u> =20
>>>>>>> wrote: =20
>>>>>>> =20
>>>>>>>> looking =20
>>>>>>>> =20
>>>>>>>> =20
>>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas < =20
>>>>>>>> nicholas.chammas=40gmail.com> wrote: =20
>>>>>>>> =20
>>>>>>>>> It appears that our main man is having trouble =20
>>>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20B=
uilders/job/SparkPullRequestBuilder/> =20
>>>>>>>>> hearing new requests =20
>>>>>>>>> <https://github.com/apache/spark/pull/2277=23issuecomment-54549=
106>. =20
>>>>>>>>> =20
>>>>>>>>> Do we need some smelling salts=3F =20
>>>>>>>>> =20
>>>>>>>>> =20
>>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp=40berkeley.=
edu> =20
>>>>>>>>> wrote: =20
>>>>>>>>> =20
>>>>>>>>>> i'd ping the Jenkinsmench... the master was completely offline=
, =20
>>>>>>>>>> so any new =20
>>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued when =
=20
>>>>>>>>>> power was =20
>>>>>>>>>> lost probably started up, but jobs that were running would fai=
l. =20
>>>>>>>>>> =20
>>>>>>>>>> =20
>>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas < =20
>>>>>>>>>> nicholas.chammas=40gmail.com =20
>>>>>>>>>> > wrote: =20
>>>>>>>>>> =20
>>>>>>>>>> > Woohoo=21 Thanks Shane. =20
>>>>>>>>>> > =20
>>>>>>>>>> > Do you know if queued PR builds will automatically be picked=
 =20
>>>>>>>>>> up=3F Or do we =20
>>>>>>>>>> > have to ping the Jenkinmensch manually from each PR=3F =20
>>>>>>>>>> > =20
>>>>>>>>>> > Nick =20
>>>>>>>>>> > =20
>>>>>>>>>> > =20
>>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp < =20
>>>>>>>>>> sknapp=40berkeley.edu> wrote: =20
>>>>>>>>>> > =20
>>>>>>>>>> >> AND WE'RE UP=21 =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> sorry that this took so long... i'll send out a more detail=
ed =20
>>>>>>>>>> explanation =20
>>>>>>>>>> >> of what happened soon. =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> now, off to back up jenkins. =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> shane =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp < =20
>>>>>>>>>> sknapp=40berkeley.edu> wrote: =20
>>>>>>>>>> >> =20
>>>>>>>>>> >> > it's a faulty power switch on the firewall, which has bee=
n =20
>>>>>>>>>> swapped out. =20
>>>>>>>>>> >> > we're about to reboot and be good to go. =20
>>>>>>>>>> >> > =20
>>>>>>>>>> >> > =20
>>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp < =20
>>>>>>>>>> sknapp=40berkeley.edu> =20
>>>>>>>>>> >> wrote: =20
>>>>>>>>>> >> > =20
>>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a=
 =20
>>>>>>>>>> replacement. =20
>>>>>>>>>> >> i =20
>>>>>>>>>> >> >> don't have more specific information yet -- including =20
>>>>>>>>>> *what* failed, =20
>>>>>>>>>> >> as our =20
>>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an =20
>>>>>>>>>> incorrect circuit =20
>>>>>>>>>> >> being =20
>>>>>>>>>> >> >> switched off during building maintenance. =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> >> on a side note, this incident will be accelerating our p=
lan =20
>>>>>>>>>> to move the =20
>>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter=
 =20
>>>>>>>>>> environment. =20
>>>>>>>>>> >> this =20
>>>>>>>>>> >> >> will be our major push over the next couple of weeks. mo=
re =20
>>>>>>>>>> details =20
>>>>>>>>>> >> about =20
>>>>>>>>>> >> >> this, also, as soon as i get them. =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything =
up =20
>>>>>>>>>> and running =20
>>>>>>>>>> >> >> ASAP. =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp < =20
>>>>>>>>>> sknapp=40berkeley.edu> =20
>>>>>>>>>> >> wrote: =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates as=
 =20
>>>>>>>>>> they happen. =20
>>>>>>>>>> >> >>> =20
>>>>>>>>>> >> >>> =20
>>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp < =20
>>>>>>>>>> sknapp=40berkeley.edu> =20
>>>>>>>>>> >> >>> wrote: =20
>>>>>>>>>> >> >>> =20
>>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks=
 =20
>>>>>>>>>> like either =20
>>>>>>>>>> >> the =20
>>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down. i'l=
l =20
>>>>>>>>>> update as =20
>>>>>>>>>> >> soon as =20
>>>>>>>>>> >> >>>> i know more. =20
>>>>>>>>>> >> >>>> =20
>>>>>>>>>> >> >>> =20
>>>>>>>>>> >> >>> =20
>>>>>>>>>> >> >> =20
>>>>>>>>>> >> > =20
>>>>>>>>>> >> =20
>>>>>>>>>> > =20
>>>>>>>>>> > -- =20
>>>>>>>>>> > You received this message because you are subscribed to the =
=20
>>>>>>>>>> Google Groups =20
>>>>>>>>>> > =22amp-infra=22 group. =20
>>>>>>>>>> > To unsubscribe from this group and stop receiving emails fro=
m =20
>>>>>>>>>> it, send an =20
>>>>>>>>>> > email to amp-infra+unsubscribe=40googlegroups.com. =20
>>>>>>>>>> > =46or more options, visit https://groups.google.com/d/optout=
. =20
>>>>>>>>>> > =20
>>>>>>>>>> =20
>>>>>>>>> =20
>>>>>>>>> =20
>>>>>>>> =20
>>>>>>> =20
>>>>>> =20
>>>>> =20
>>>> =20
>>> =20
>> =20
> =20

--540a5a1b_46e87ccd_112--


From dev-return-9340-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 03:25:20 2014
Return-Path: <dev-return-9340-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9E9B311EA4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 03:25:19 +0000 (UTC)
Received: (qmail 46014 invoked by uid 500); 6 Sep 2014 03:25:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45968 invoked by uid 500); 6 Sep 2014 03:25:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45956 invoked by uid 99); 6 Sep 2014 03:25:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 03:25:16 +0000
X-ASF-Spam-Status: No, hits=3.8 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of gurongwalker@gmail.com designates 209.85.216.180 as permitted sender)
Received: from [209.85.216.180] (HELO mail-qc0-f180.google.com) (209.85.216.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 03:25:12 +0000
Received: by mail-qc0-f180.google.com with SMTP id c9so13034600qcz.25
        for <dev@spark.incubator.apache.org>; Fri, 05 Sep 2014 20:24:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=3vRVT36fkC0sEmXfj8bVqQPrVtKX8KVdjeEfjSfzQYA=;
        b=kARB/y7n2RnuOaJnPXNUlzIfkQx7PPP5C0SfPselGzK/tw4xfqk8OYlYFala6DNT/j
         78sJCGlV52p67O0jAuAPJM1ZNYbXjYhwCcvT3g6urf9wg3HjW9ZotZUIYH63GcqzNJqo
         xD79zTk817zfAZi8AKrQRGcuwtVi8DNsi81874apnBmTvu3W3BC1EDL7T2oIPIriyKzj
         ukTBlpOkZTwuSOdLSCOxahg2w7DEXbJUF8qEDfWYcgBzOoiWO7q/Z2XgFQPfAeB7cZkM
         AKU2bL5hMnVX3nRD2OAmN0yX7OCPq1oeNEssZqxCEH8WkXHmg+7hZ+y5AFaxmXlVH1Lo
         JyYA==
MIME-Version: 1.0
X-Received: by 10.229.219.138 with SMTP id hu10mr24314924qcb.5.1409973891972;
 Fri, 05 Sep 2014 20:24:51 -0700 (PDT)
Received: by 10.140.49.135 with HTTP; Fri, 5 Sep 2014 20:24:51 -0700 (PDT)
In-Reply-To: <CAEJ05AFo5xmMoHA-6K0=jMbqmWeD2Lj_6QJSmLiD45ov96AgFw@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com>
	<CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
	<1409930280353-8293.post@n3.nabble.com>
	<CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
	<1409933903848-8296.post@n3.nabble.com>
	<CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
	<EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
	<CAEJ05AFo5xmMoHA-6K0=jMbqmWeD2Lj_6QJSmLiD45ov96AgFw@mail.gmail.com>
Date: Sat, 6 Sep 2014 11:24:51 +0800
Message-ID: <CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: =?UTF-8?B?6aG+6I2j?= <gurongwalker@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>, Xiangrui Meng <mengxr@gmail.com>, 
	Haoyuan Li <haoyuan.li@gmail.com>, =?UTF-8?B?5bC557uq5qOu?= <yinxusen@gmail.com>, 
	Reynold Xin <rxin@databricks.com>
Cc: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>, Freeman <freeman.jeremy@gmail.com>, 
	dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11344af2f94d8c05025d2051
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11344af2f94d8c05025d2051
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Missed the dev-list last email. Resent it again. Please ignore the
duplicated one.

2014-09-06 11:22 GMT+08:00 =E9=A1=BE=E8=8D=A3 <gurongwalker@gmail.com>:

> Hi All,
>
> This is RongGu from PasaLab at Nanjing Universtiy,China. Actually, we hav=
e
> been working on a distributed matrix operations library on Spark this
> summer. It is a Summer Code project hosted by CSDN and Intel Lab (
> http://code.csdn.net/os_camp/8/proposals/26). Previously, the codebase of
> the project is hosted on CSDN's code platform(
> https://code.csdn.net/u014252240/sparkmatrixlib) and we have been writing
> weekly reports on the blog(http://blog.csdn.net/u014252240).
>
> Now, the project comes to end now. I have moved the project to github
> these days. *Please see the link here *https://github.com/PasaLab/saury .
> We name the project Saury and provide documents to help people know  it
> better.
>
> Technically, we implement the matrix manipulation on Spark with block
> matrix parallel algorithms to distribute large scale matrix computation
> among cluster nodes. Also, we take advantage of the native linear algebra
> library=EF=BC=88e.g BLAS=EF=BC=89on each worker node to accelerate the co=
mputing process.
> That really makes a difference! See the preliminary performance evaluatio=
n
> report at
> https://github.com/PasaLab/saury/wiki/Performance-comparison-on-matrices-=
multiply
>
> Currently, we are working on adding more advanced matrix manipulation
> algorithms into Saury, such as matrix factorization and diagonalization
> algorithms. In fact, Saury contains an alpha version distributed LU
> factorization implementation now. Also, we are trying to use Tachyon to
> hold and share the matrix data across the cluster with faster speed.
>
> Best,
> Rong
>
> --
> ------------------
> Rong Gu
> Department of Computer Science and Technology
> State Key Laboratory for Novel Software Technology
> Nanjing University
> Email: gurongwalker@gmail.com
> Homepage: http://pasa-bigdata.nju.edu.cn/people/ronggu/
>
>
> 2014-09-06 1:29 GMT+08:00 Jeremy Freeman <freeman.jeremy@gmail.com>:
>
>> Hey all,
>>
>> Definitely agreed this would be nice! In our own work we've done
>> element-wise addition, subtraction, and scalar multiplication of similar=
ly
>> partitioned matrices very efficiently with zipping. We've also done
>> matrix-matrix multiplication with zipping, but that only works in certai=
n
>> circumstances, and it's otherwise very communication intensive (as Shiva=
ram
>> says). Another tricky thing with addition / subtraction is how to handle
>> sparse vs. dense arrays.
>>
>> Would be happy to contribute anything we did, but definitely first worth
>> knowing what progress has been made from the AMPLab.
>>
>> -- Jeremy
>>
>> ---------------------
>> jeremy freeman, phd
>> neuroscientist
>> @thefreemanlab
>>
>> On Sep 5, 2014, at 12:23 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> > Hey There,
>> >
>> > I believe this is on the roadmap for the 1.2 next release. But
>> > Xiangrui can comment on this.
>> >
>> > - Patrick
>> >
>> > On Fri, Sep 5, 2014 at 9:18 AM, Yu Ishikawa
>> > <yuu.ishikawa+spark@gmail.com> wrote:
>> >> Hi Evan,
>> >>
>> >> That's sounds interesting.
>> >>
>> >> Here is the ticket which I created.
>> >> https://issues.apache.org/jira/browse/SPARK-3416
>> >>
>> >> thanks,
>> >>
>> >>
>> >>
>> >> --
>> >> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-mult=
iplying-large-scale-matrices-tp8291p8296.html
>> >> Sent from the Apache Spark Developers List mailing list archive at
>> Nabble.com.
>> >>
>> >> ---------------------------------------------------------------------
>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>>
>>
>
>
> --
> ------------------
> Rong Gu
> Department of Computer Science and Technology
> State Key Laboratory for Novel Software Technology
> Nanjing University
> Phone: +86 15850682791
> Email: gurongwalker@gmail.com
> Homepage: http://pasa-bigdata.nju.edu.cn/people/ronggu/
>



--=20
------------------
Rong Gu
Department of Computer Science and Technology
State Key Laboratory for Novel Software Technology
Nanjing University
Phone: +86 15850682791
Email: gurongwalker@gmail.com
Homepage: http://pasa-bigdata.nju.edu.cn/people/ronggu/

--001a11344af2f94d8c05025d2051--

From dev-return-9341-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 08:17:38 2014
Return-Path: <dev-return-9341-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6CC6A112F0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 08:17:37 +0000 (UTC)
Received: (qmail 66788 invoked by uid 500); 6 Sep 2014 08:17:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66716 invoked by uid 500); 6 Sep 2014 08:17:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66704 invoked by uid 99); 6 Sep 2014 08:17:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 08:17:34 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 08:17:09 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XQBBD-0006a6-Vr
	for dev@spark.incubator.apache.org; Sat, 06 Sep 2014 01:17:07 -0700
Date: Sat, 6 Sep 2014 01:17:07 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409991427964-8309.post@n3.nabble.com>
In-Reply-To: <EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com> <1409930280353-8293.post@n3.nabble.com> <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com> <1409933903848-8296.post@n3.nabble.com> <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com> <EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi  Jeremy, 

Great work!

I'm interested in your work. If there is your code on github, could you let
me know?

-- Yu Ishikawa



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8309.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9342-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 08:28:32 2014
Return-Path: <dev-return-9342-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9919011311
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 08:28:32 +0000 (UTC)
Received: (qmail 71330 invoked by uid 500); 6 Sep 2014 08:28:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71262 invoked by uid 500); 6 Sep 2014 08:28:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71249 invoked by uid 99); 6 Sep 2014 08:28:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 08:28:31 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 08:28:26 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XQBLq-0000HP-Go
	for dev@spark.incubator.apache.org; Sat, 06 Sep 2014 01:28:06 -0700
Date: Sat, 6 Sep 2014 01:28:06 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1409992086513-8310.post@n3.nabble.com>
In-Reply-To: <CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com> <1409930280353-8293.post@n3.nabble.com> <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com> <1409933903848-8296.post@n3.nabble.com> <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com> <EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com> <CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Rong, 

Great job! Thank you for let me know your work.
I will read the source code of saury later.

Although AMPLab is working to implement them, would you like to merge it
into Spark?

Best,

-- Yu Ishikawa




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8310.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9343-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 10:33:45 2014
Return-Path: <dev-return-9343-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A12D1144F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 10:33:45 +0000 (UTC)
Received: (qmail 39744 invoked by uid 500); 6 Sep 2014 10:33:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39677 invoked by uid 500); 6 Sep 2014 10:33:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39662 invoked by uid 99); 6 Sep 2014 10:33:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 10:33:43 +0000
X-ASF-Spam-Status: No, hits=7.1 required=10.0
	tests=ASF_LIST_OPS,DCC_CHECK,HTML_MESSAGE,HTML_OBFUSCATE_10_20,MIME_QP_LONG_LINE,MPART_ALT_DIFF,RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of aaron.babcock@gmail.com does not designate 64.202.189.130 as permitted sender)
Received: from [64.202.189.130] (HELO m1plded01-06.prod.mesa1.secureserver.net) (64.202.189.130)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 10:33:16 +0000
Received: from ip-72-167-99-64.ip.secureserver.net ([72.167.99.64])
	by m1plded01-06.prod.mesa1.secureserver.net with : DED :
	id nmZE1o01r1PMFlC01mZEbF; Sat, 06 Sep 2014 03:33:15 -0700
x-originating-ip: 72.167.99.64
x_spam_cmae: v=2.1 cv=e6qISMZ/ c=1 sm=1 tr=0 p=t1IW4pc9AAAA:8
 a=G4crXpZ63kyE4FfcQsuYtQ==:117 a=pR6c/5rvinXhHXQ0jCWW+Q==:17 a=TZb1taSUAAAA:8
 a=y00fCCxsyUoA:10 a=ipGM3iMKwmMA:10 a=nDghuxUhq_wA:10 a=pGLkceISAAAA:8
 a=l-OSC41ZAAAA:8 a=4H7XXO3fAAAA:8 a=r77TgQKjGQsHNAKrUKIA:9 a=9iDbn-4jx3cA:10
 a=cKsnjEOsciEA:10 a=1MKa3Ojb5KWQA8s05uEA:9 a=wPNLvfGTeEIA:10
 a=TMUTNQqLXl0A:10 a=aGNdTnPGc_EA:10 a=QEXdDO2ut3YA:10 a=_W_S_7VecoQA:10
 a=2RVx76CAx24A:10 a=HdbAwMqyR8wA:10 a=FAc9sq5A1EMA:10
Received: (qmail 18362 invoked from network); 6 Sep 2014 03:33:14 -0700
Received: from lex.donbass.com (HELO supercheapcards.com) (92.242.108.122)
  by ip-72-167-99-64.ip.secureserver.net with ESMTPA; 6 Sep 2014 03:33:14 -0700
Message-ID: <738B79BEB5EA799D28090FDC4FD7555A@supercheapcards.com>
From: "Aaron Babcock" <aaron.babcock@gmail.com>
To: "Adan Perez" <nadazerep@gmail.com>,
 "dev help" <dev-help@spark.incubator.apache.org>,
 "Brian Maddy" <brian@brianmaddy.com>, "Aaron Yancy" <ayancy@gopro.com>,
 "Melissa Gilitzer" <melbell54@hotmail.com>,
 "Aaron Kardell" <aaron@mobilerealtyapps.com>,
 "Eric Caron" <eric@idea-ignition.com>,
 "dev" <dev@spark.incubator.apache.org>
Subject: Your Weekly GPGold Offer Is Waiting Inside
Date: Fri, 6 Sep 2014 11:33:09 +0000
MIME-Version: 1.0
Content-Type: multipart/alternative;
 boundary="----=_NextPart_000_9FED_2BF2BB8B.006E6714"
X-Priority: 3
X-MSMail-Priority: Normal
Importance: Normal
X-Mailer: Microsoft Windows Live Mail 16.4.3522.110
X-MIMEOLE: Produced By Microsoft MimeOLE V16.4.3522.110
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_000_9FED_2BF2BB8B.006E6714
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

http://maxigas.rrzconsulting.com/ssnfxezj/fpxihvkqhbkjlwgz.upbuevikyiirz
------=_NextPart_000_9FED_2BF2BB8B.006E6714--

From dev-return-9344-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 15:13:45 2014
Return-Path: <dev-return-9344-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 73CB211B38
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 15:13:45 +0000 (UTC)
Received: (qmail 9065 invoked by uid 500); 6 Sep 2014 15:13:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8995 invoked by uid 500); 6 Sep 2014 15:13:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8982 invoked by uid 99); 6 Sep 2014 15:13:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 15:13:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.171 as permitted sender)
Received: from [74.125.82.171] (HELO mail-we0-f171.google.com) (74.125.82.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 15:13:40 +0000
Received: by mail-we0-f171.google.com with SMTP id x48so133806wes.16
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 08:13:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=PZ56Hj/+qwdxqdrmfO41YIwvMNY9w9g+2xa1aQYA3W4=;
        b=wRjQOqVIpuN5/6CgMiQEgjMcPv/SppPv7vuiZR5paTVac551UvIwEf4/NC/BiZ+PqP
         8zWgbGRF+iIf/rxWuniLTt27gDLhiQbQRco3RH9mTcNSmxJY7RJZ3/FXhXMqdkaWRK1w
         GuaCytjEgXwaz8zbP7BscNTQ2111rBlE2Bwgs7do6SMHeLoHX2DhcKtP0kYiEr1apu8Y
         jZs2JLOBKdfrJqjTqp1WZL51CjbAcQtuqlMeCtdnTjqDxH+8dS8CxF68irgI3GrihFU2
         YpR00P1Wgilrenk7d0M7sWODWFDSdHYAJhMbeeTArPIRs43l3xkvfX3azcz20C2mY8gZ
         JeFA==
X-Received: by 10.180.187.144 with SMTP id fs16mr10270037wic.75.1410016399304;
 Sat, 06 Sep 2014 08:13:19 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sat, 6 Sep 2014 08:12:39 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sat, 6 Sep 2014 11:12:39 -0400
Message-ID: <CAOhmDzcH95Daw2yt6X04717sOo1xO7iTNXj+7OeYERf1KCve2w@mail.gmail.com>
Subject: trimming unnecessary test output
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c266a89bab3f05026706d7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c266a89bab3f05026706d7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Continuing the discussion started here
<https://github.com/apache/spark/pull/2279>, I=E2=80=99m wondering if peopl=
e
already know that certain test output is unnecessary and should be trimmed.

For example
<https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19917/c=
onsoleFull>,
I see a bunch of lines like this:

14/09/06 07:54:13 INFO GenerateProjection: Code generated expression
List(IS NOT NULL 1) in 128.33733 ms

Can/should this type of output be suppressed? Is there any other test
output that is obviously more noise than signal?

Nick
=E2=80=8B

--001a11c266a89bab3f05026706d7--

From dev-return-9345-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 15:27:53 2014
Return-Path: <dev-return-9345-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BAD7711B69
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 15:27:53 +0000 (UTC)
Received: (qmail 19639 invoked by uid 500); 6 Sep 2014 15:27:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19585 invoked by uid 500); 6 Sep 2014 15:27:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19574 invoked by uid 99); 6 Sep 2014 15:27:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 15:27:52 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of eerlands@redhat.com designates 209.132.183.25 as permitted sender)
Received: from [209.132.183.25] (HELO mx4-phx2.redhat.com) (209.132.183.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 15:27:27 +0000
Received: from zmail12.collab.prod.int.phx2.redhat.com (zmail12.collab.prod.int.phx2.redhat.com [10.5.83.14])
	by mx4-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s86FROjS004753
	for <dev@spark.apache.org>; Sat, 6 Sep 2014 11:27:24 -0400
Date: Sat, 6 Sep 2014 11:27:23 -0400 (EDT)
From: Erik Erlandson <eje@redhat.com>
Reply-To: Erik Erlandson <eje@redhat.com>
To: dev <dev@spark.apache.org>
Message-ID: <492403270.18096969.1410017243818.JavaMail.zimbra@redhat.com>
In-Reply-To: <651684514.18096142.1410016399575.JavaMail.zimbra@redhat.com>
Subject: PSA: SI-8835 (Iterator 'drop' method has a complexity bug causing
 quadratic behavior)
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.7]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - GC36 (Linux)/8.0.6_GA_5922)
Thread-Topic: SI-8835 (Iterator 'drop' method has a complexity bug causing quadratic behavior)
Thread-Index: 8D1hIK4kpMNLXHmTBCj8Z7hOWi+mvw==
X-Virus-Checked: Checked by ClamAV on apache.org

I tripped over this recently while preparing a solution for SPARK-3250 (efficient sampling):

Iterator 'drop' method has a complexity bug causing quadratic behavior
https://issues.scala-lang.org/browse/SI-8835

It's something of a corner case, as the impact is serious only if one is repeatedly invoking 'drop' on Iterator[T], and it doesn't apply to all iterator subclasses (e.g. Array().iterator).   It's actually a bug in 'slice', and so invocations of 'drop', 'take' and 'slice' are potential vulnerabilities.

Not something I'd expect to show up frequently, but it seemed worth mentioning, as RDD partitions are ubiquitously presented as Iterator[T] in the compute model, and if it does happen it turns a linear algorithm into something having quadratic behavior.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9346-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 16:16:04 2014
Return-Path: <dev-return-9346-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AF5DE11CDE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 16:16:04 +0000 (UTC)
Received: (qmail 68592 invoked by uid 500); 6 Sep 2014 16:16:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68523 invoked by uid 500); 6 Sep 2014 16:16:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68511 invoked by uid 99); 6 Sep 2014 16:16:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 16:16:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 16:15:38 +0000
Received: by mail-wi0-f177.google.com with SMTP id cc10so744493wib.16
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 09:15:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=OwVVLaLvu96KjEdNaGeQTG+1IT2xgdJUAmjEj0DTe88=;
        b=eQuV+GaTaC254mMH46wlGCzILGF1bz1w8pAKOrcQTIjH7wKlrWUdWYwpl9tORdjUr7
         VXv2JedkCorlmZmrjIYUoHSiH+P6f8b/xnFffGj1biOKB2nL0hrTp4Kpvxm07orn1cWG
         WunoF/Or2ij1RktvacZMWbBVBgZiPDANOYVDofpXCbxy7ueZv3Y/wdEQiiwcdCOSMJZ4
         DHfH30v5BltZ2T2TnQtsgMlaJgPaZP5yYiGQ60b5a7EPFp2irWJlOyr7/nfmgtRzZkgx
         FvFzsu0RUQcnLowAX1pQ5TEJD+phhXVbHPBnzua7f9aDSF8NulQpUB7Y/uzYQjlxloZc
         9rCA==
X-Received: by 10.195.11.200 with SMTP id ek8mr22656103wjd.85.1410020137632;
 Sat, 06 Sep 2014 09:15:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sat, 6 Sep 2014 09:14:57 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sat, 6 Sep 2014 12:14:57 -0400
Message-ID: <CAOhmDzc1SacTjPP24CrVNXiNN1M=Ey5oMaV_z_Yq5jcWCHuLrg@mail.gmail.com>
Subject: Scala's Jenkins setup looks neat
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b8737626e0934050267e50b
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b8737626e0934050267e50b
Content-Type: text/plain; charset=UTF-8

After reading Erik's email, I found this Scala PR
<https://github.com/scala/scala/pull/3963> and immediately noticed a few
cool things:

   - Jenkins is hooked directly into GitHub somehow, so you get the "All is
   well" message in the merge status window, presumably based on the last test
   status
   - Jenkins is also tagging the PR based on its test status or need for
   review
   - Jenkins is also tagging the PR for a specific milestone

Do any of these things make sense to add to our setup? Or perhaps something
inspired by these features?

Nick

--047d7b8737626e0934050267e50b--

From dev-return-9347-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 17:11:23 2014
Return-Path: <dev-return-9347-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7440B11DE2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 17:11:23 +0000 (UTC)
Received: (qmail 22224 invoked by uid 500); 6 Sep 2014 17:11:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22147 invoked by uid 500); 6 Sep 2014 17:11:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22136 invoked by uid 99); 6 Sep 2014 17:11:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 17:11:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.47] (HELO mail-qg0-f47.google.com) (209.85.192.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 17:11:18 +0000
Received: by mail-qg0-f47.google.com with SMTP id z60so13275447qgd.34
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 10:10:56 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=aZTfZAIHGWPMleI4JFQc0irHxvXLRwWr4nJ1dXTuAW8=;
        b=ALf7aDh0kWPjFQIlW9QeF1cTrBh/n2TZimtSjNX7Al7kNPY9ziBSMqN/jSe0eX5oYA
         ctQtFiHHHPY/YyfUm+ksCMAYsf01AIsY9AdY8KzzGTfABqGQU2agGT8l37D4SdvTboXV
         lHOZ33XTde3ePNgwmi2ePWmKT/KSbjgRVHBYaDjrv8M5XpAcK5Eel0D3GLW7u9WlgROf
         nZfq7YcdhljZnRr5z+JqNoiC/tiOgwsyWY5gz2E96p/T1Fq86riRGLS8d71PvVsAkQI6
         0sbgcve9/+TdrqgYo8tpnvQac8DESJL+PVkKYUkidDkpD+8nNYyPUNhLzKGZLAvwaOdd
         wpwg==
X-Gm-Message-State: ALoCoQmK3eeH12GLU43bXu1WZpbElqHb3I6AI1jOXiwfaG+xfT2WdFyoJZFbsZlf4+Y4y9tmcqe4
MIME-Version: 1.0
X-Received: by 10.140.47.129 with SMTP id m1mr3459922qga.95.1410023456247;
 Sat, 06 Sep 2014 10:10:56 -0700 (PDT)
Received: by 10.96.41.34 with HTTP; Sat, 6 Sep 2014 10:10:56 -0700 (PDT)
In-Reply-To: <CAOhmDzc1SacTjPP24CrVNXiNN1M=Ey5oMaV_z_Yq5jcWCHuLrg@mail.gmail.com>
References: <CAOhmDzc1SacTjPP24CrVNXiNN1M=Ey5oMaV_z_Yq5jcWCHuLrg@mail.gmail.com>
Date: Sat, 6 Sep 2014 10:10:56 -0700
Message-ID: <CAPh_B=bTeRfcHch8TEbcpZMKmRqLwBKHWno4MphU4pZUarKSdg@mail.gmail.com>
Subject: Re: Scala's Jenkins setup looks neat
From: Reynold Xin <rxin@databricks.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16b7e3c8692050268ab5f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16b7e3c8692050268ab5f
Content-Type: text/plain; charset=UTF-8

that would require github hooks permission and unfortunately asf infra
wouldn't allow that.

Maybe they will change their mind one day, but so far we asked about this
and the answer has been no for security reasons.

On Saturday, September 6, 2014, Nicholas Chammas <nicholas.chammas@gmail.com>
wrote:

> After reading Erik's email, I found this Scala PR
> <https://github.com/scala/scala/pull/3963> and immediately noticed a few
> cool things:
>
>    - Jenkins is hooked directly into GitHub somehow, so you get the "All is
>    well" message in the merge status window, presumably based on the last
> test
>    status
>    - Jenkins is also tagging the PR based on its test status or need for
>    review
>    - Jenkins is also tagging the PR for a specific milestone
>
> Do any of these things make sense to add to our setup? Or perhaps something
> inspired by these features?
>
> Nick
>

--001a11c16b7e3c8692050268ab5f--

From dev-return-9348-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 17:31:00 2014
Return-Path: <dev-return-9348-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B25AA11EAC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 17:31:00 +0000 (UTC)
Received: (qmail 48279 invoked by uid 500); 6 Sep 2014 17:31:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48221 invoked by uid 500); 6 Sep 2014 17:31:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48209 invoked by uid 99); 6 Sep 2014 17:30:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 17:30:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 17:30:34 +0000
Received: by mail-wg0-f44.google.com with SMTP id k14so232510wgh.27
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 10:30:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=p2PcAzmoic0MLfc743gRBXbrutyG7ph/HBIsZow5tbA=;
        b=qyI2y5E2T4flShZgBkMjitIxGJc47D5nwy3LWuZwpvVPBWRuas+K4qSL4j5ElcMuIA
         qM6+0iLf4+GM678SnKk4sa2Wt8IlR9fxTgOK24C+v0Oox6+NBd0ukUIRvGRJ7ltfYqNE
         7oDvVZ5j/zNGU50BGSNYsSwp28+RyClQTEtCY07JIQR56iBXsodmHjixEk1HlJ/vq7Xr
         zCCZWrVRBNkW/8SVZqQf0zPpiQa/hg9uoiYMtZSXXMe7pqPp8EChZkdUafRmv/aBckxZ
         dnSxFio13QHa8lUGfC9sYqCybM3zBitn/1JGe7RTa6MAp0D+6fa8aXGTnvXgaAVgEDRY
         eVyg==
X-Received: by 10.195.11.200 with SMTP id ek8mr23031653wjd.85.1410024633898;
 Sat, 06 Sep 2014 10:30:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sat, 6 Sep 2014 10:29:53 -0700 (PDT)
In-Reply-To: <CAPh_B=bTeRfcHch8TEbcpZMKmRqLwBKHWno4MphU4pZUarKSdg@mail.gmail.com>
References: <CAOhmDzc1SacTjPP24CrVNXiNN1M=Ey5oMaV_z_Yq5jcWCHuLrg@mail.gmail.com>
 <CAPh_B=bTeRfcHch8TEbcpZMKmRqLwBKHWno4MphU4pZUarKSdg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sat, 6 Sep 2014 13:29:53 -0400
Message-ID: <CAOhmDze9wQwvfAzPBD=76KxDEm+ZzBM4ToWeYKsU4GKU_bRhkw@mail.gmail.com>
Subject: Re: Scala's Jenkins setup looks neat
To: Reynold Xin <rxin@databricks.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b8737626d9c64050268f147
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b8737626d9c64050268f147
Content-Type: text/plain; charset=UTF-8

Aww, that's a bummer...


On Sat, Sep 6, 2014 at 1:10 PM, Reynold Xin <rxin@databricks.com> wrote:

> that would require github hooks permission and unfortunately asf infra
> wouldn't allow that.
>
> Maybe they will change their mind one day, but so far we asked about this
> and the answer has been no for security reasons.
>
> On Saturday, September 6, 2014, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> After reading Erik's email, I found this Scala PR
>> <https://github.com/scala/scala/pull/3963> and immediately noticed a few
>> cool things:
>>
>>    - Jenkins is hooked directly into GitHub somehow, so you get the "All
>> is
>>    well" message in the merge status window, presumably based on the last
>> test
>>    status
>>    - Jenkins is also tagging the PR based on its test status or need for
>>    review
>>    - Jenkins is also tagging the PR for a specific milestone
>>
>> Do any of these things make sense to add to our setup? Or perhaps
>> something
>> inspired by these features?
>>
>> Nick
>>
>

--047d7b8737626d9c64050268f147--

From dev-return-9349-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 19:48:57 2014
Return-Path: <dev-return-9349-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 27E94111C2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 19:48:57 +0000 (UTC)
Received: (qmail 93047 invoked by uid 500); 6 Sep 2014 19:48:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92977 invoked by uid 500); 6 Sep 2014 19:48:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92965 invoked by uid 99); 6 Sep 2014 19:48:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 19:48:55 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.178 as permitted sender)
Received: from [209.85.192.178] (HELO mail-pd0-f178.google.com) (209.85.192.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 19:48:29 +0000
Received: by mail-pd0-f178.google.com with SMTP id p10so1255275pdj.37
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 12:48:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=NnBZP/mHEXB5MNDb5olWq1swdgqILQUbf9V3m3H0c88=;
        b=v0YFV3fEUkQkyxdfNTiW9AY0YybbUnzyrmbIAIO0T3Bknxcon8G2VppY/Re3913cGx
         Duq+3BYuudHs87Q4Z/2osTj3vpLrg0RfR9ieq7Qx9v1FO05VpJNAlQLGh4j2C2ORiPRZ
         Gyg6fAER6bggIq3YC6VGc7ak1lt11n3PQObkori4cGIXxQT86vKJDDPfQoz6gBck7NCv
         iBkS8jPvqSuGVMtCTHM/GkXetuU9bEXwJBHMcXUV6bfepEviSsN5s7ZPHBXEf6M88tq6
         Q2sWRAuds5UA+S/FW+KWMOcmKpU6ea8BYp1yaqxNO1hdf23+LaHDgTYWynA6Sa+Q51uM
         LW4g==
X-Received: by 10.66.157.233 with SMTP id wp9mr33244831pab.11.1410032907756;
        Sat, 06 Sep 2014 12:48:27 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-104.hsd1.ca.comcast.net. [67.164.94.104])
        by mx.google.com with ESMTPSA id p8sm5060217pdj.12.2014.09.06.12.48.26
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Sat, 06 Sep 2014 12:48:27 -0700 (PDT)
Date: Sat, 6 Sep 2014 12:48:25 -0700
From: Josh Rosen <rosenville@gmail.com>
To: shane knapp <sknapp@berkeley.edu>, Nicholas Chammas
 <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, Mike Patterson
 <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>, dev
 <dev@spark.apache.org>
Message-ID: <etPan.540b6509.3d1b58ba.112@joshs-mbp>
In-Reply-To: <etPan.540a5a1b.238e1f29.112@joshs-mbp>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
 <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
 <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
 <etPan.540a5a1b.238e1f29.112@joshs-mbp>
Subject: Re: amplab jenkins is down
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540b6509_507ed7ab_112"
X-Virus-Checked: Checked by ClamAV on apache.org

--540b6509_507ed7ab_112
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

It looks like Jenkins is up and running, but there seems to be a delay in=
 responding to requests to re-test patches. =C2=A0It seems like Jenkins i=
s promptly testing new PRs, or new commits as they=E2=80=99re added to ex=
isting PRs, but taking a very=C2=A0long time to respond to requests to re=
-test PRs.

I=E2=80=99m going to continue monitoring this today. =C2=A0I=E2=80=99m co=
nsidering creating my own fork of the Jenkins pull request builder plugin=
 so that we can add extra logging in order to diagnose what=E2=80=99s cau=
sing this lag.

- Josh
On September 5, 2014 at 5:49:32 PM, Josh Rosen (rosenville=40gmail.com) w=
rote:

We have successfully purged Jenkins=E2=80=99 build queue. =C2=A0If you wa=
nt a PR to be re-tested, please ask Jenkins again.

On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp=40berkeley.edu) w=
rote:

yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new key,=

and magique=21

we're about to clear the queue of all builds as most aren't wanted/needed=
.


On =46ri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <nicholas.chammas=40gm=
ail.com
> wrote:

> Looks like Jenkins is back=21
>
> lol The poor guy has like a million builds
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/=
job/SparkPullRequestBuilder/>
> to catch up on.
>
>
> On =46ri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
> nicholas.chammas=40gmail.com> wrote:
>
>> How's it going=3F
>>
>> It looks like during the last build
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders=
/job/SparkPullRequestBuilder/lastBuild/console>
>> from about 30 min ago Jenkins was still having trouble fetching from
>> GitHub. It also looks like not all requests for testing are triggering=

>> builds.
>>
>>
>> On =46ri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp=40berkeley.edu> =
wrote:
>>
>>> it's looking like everything except the pull request builders are
>>> working. i'm going to be working on getting this resolved today.
>>>
>>>
>>> On =46ri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>>> nicholas.chammas=40gmail.com> wrote:
>>>
>>>> Hmm, looks like at least some builds
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builde=
rs/job/SparkPullRequestBuilder/19804/console=46ull>
>>>> are working now, though this last one was from =7E5 hours ago.
>>>>
>>>>
>>>> On =46ri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp=40berkeley.edu=
>
>>>> wrote:
>>>>
>>>>> yep. that's exactly the behavior i saw earlier, and will be figurin=
g
>>>>> out first thing tomorrow morning. i bet it's an environment issues =
on the
>>>>> slaves.
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>>>> nicholas.chammas=40gmail.com> wrote:
>>>>>
>>>>>> Looks like during the last build
>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Buil=
ders/job/SparkPullRequestBuilder/19797/console>
>>>>>> Jenkins was unable to execute a git fetch=3F
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp=40berkeley.edu=
>
>>>>>> wrote:
>>>>>>
>>>>>>> i'm going to restart jenkins and see if that fixes things.
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp=40berkeley.ed=
u>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> looking
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>>>>> nicholas.chammas=40gmail.com> wrote:
>>>>>>>>
>>>>>>>>> It appears that our main man is having trouble
>>>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20B=
uilders/job/SparkPullRequestBuilder/>
>>>>>>>>> hearing new requests
>>>>>>>>> <https://github.com/apache/spark/pull/2277=23issuecomment-54549=
106>.
>>>>>>>>>
>>>>>>>>> Do we need some smelling salts=3F
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp=40berkeley.=
edu>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>>> i'd ping the Jenkinsmench... the master was completely offline=
,
>>>>>>>>>> so any new
>>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued when
>>>>>>>>>> power was
>>>>>>>>>> lost probably started up, but jobs that were running would fai=
l.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>>>>> nicholas.chammas=40gmail.com
>>>>>>>>>> > wrote:
>>>>>>>>>>
>>>>>>>>>> > Woohoo=21 Thanks Shane.
>>>>>>>>>> >
>>>>>>>>>> > Do you know if queued PR builds will automatically be picked=

>>>>>>>>>> up=3F Or do we
>>>>>>>>>> > have to ping the Jenkinmensch manually from each PR=3F
>>>>>>>>>> >
>>>>>>>>>> > Nick
>>>>>>>>>> >
>>>>>>>>>> >
>>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu> wrote:
>>>>>>>>>> >
>>>>>>>>>> >> AND WE'RE UP=21
>>>>>>>>>> >>
>>>>>>>>>> >> sorry that this took so long... i'll send out a more detail=
ed
>>>>>>>>>> explanation
>>>>>>>>>> >> of what happened soon.
>>>>>>>>>> >>
>>>>>>>>>> >> now, off to back up jenkins.
>>>>>>>>>> >>
>>>>>>>>>> >> shane
>>>>>>>>>> >>
>>>>>>>>>> >>
>>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu> wrote:
>>>>>>>>>> >>
>>>>>>>>>> >> > it's a faulty power switch on the firewall, which has bee=
n
>>>>>>>>>> swapped out.
>>>>>>>>>> >> > we're about to reboot and be good to go.
>>>>>>>>>> >> >
>>>>>>>>>> >> >
>>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >
>>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a=

>>>>>>>>>> replacement.
>>>>>>>>>> >> i
>>>>>>>>>> >> >> don't have more specific information yet -- including
>>>>>>>>>> *what* failed,
>>>>>>>>>> >> as our
>>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an
>>>>>>>>>> incorrect circuit
>>>>>>>>>> >> being
>>>>>>>>>> >> >> switched off during building maintenance.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> on a side note, this incident will be accelerating our p=
lan
>>>>>>>>>> to move the
>>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter=

>>>>>>>>>> environment.
>>>>>>>>>> >> this
>>>>>>>>>> >> >> will be our major push over the next couple of weeks. mo=
re
>>>>>>>>>> details
>>>>>>>>>> >> about
>>>>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything =
up
>>>>>>>>>> and running
>>>>>>>>>> >> >> ASAP.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates as=

>>>>>>>>>> they happen.
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> >>> wrote:
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks=

>>>>>>>>>> like either
>>>>>>>>>> >> the
>>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down. i'l=
l
>>>>>>>>>> update as
>>>>>>>>>> >> soon as
>>>>>>>>>> >> >>>> i know more.
>>>>>>>>>> >> >>>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >
>>>>>>>>>> >>
>>>>>>>>>> >
>>>>>>>>>> > --
>>>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>>>> Google Groups
>>>>>>>>>> > =22amp-infra=22 group.
>>>>>>>>>> > To unsubscribe from this group and stop receiving emails fro=
m
>>>>>>>>>> it, send an
>>>>>>>>>> > email to amp-infra+unsubscribe=40googlegroups.com.
>>>>>>>>>> > =46or more options, visit https://groups.google.com/d/optout=
.
>>>>>>>>>> >
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--540b6509_507ed7ab_112--


From dev-return-9350-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 21:36:40 2014
Return-Path: <dev-return-9350-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 987A11156D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 21:36:40 +0000 (UTC)
Received: (qmail 19423 invoked by uid 500); 6 Sep 2014 21:36:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19356 invoked by uid 500); 6 Sep 2014 21:36:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19344 invoked by uid 99); 6 Sep 2014 21:36:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 21:36:39 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.213.178 as permitted sender)
Received: from [209.85.213.178] (HELO mail-ig0-f178.google.com) (209.85.213.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 21:36:34 +0000
Received: by mail-ig0-f178.google.com with SMTP id hn18so1027258igb.17
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 14:36:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=kMRiYC6vW7Caj0fk9hzP0KC8t55gmdFbmWlTy0k23WM=;
        b=xl8X2i0BW4HO3z/jPEIVkOsJSaEm3vta8trFhbOC72mMwvnNPrYYN7jwjMVZ4pdLWX
         bndMVrS9UPNa0KtG8pv2DHOOA+jX5PpzfokPIYOPijarqQB9RemNA1oTm5kBR31SUxyY
         /0+zgFN7cM15sVQRhN4UOpk+UMRGlpEFg6ldVhumszG+UVsHzpShHZ1pniUVZqoBp7kl
         R1wwza1SPd0/N77WaDj3OWUN/z8f6ac53KM6pOgeUL9+Tqf4z+ifIH6791meijMgG7pD
         qWw+JIL3g7JLrh7rpB7XpbAaTO+LK0WsSiH7Gr28J6kR1LXV8JnQr/6pg9Km4xIjSRn3
         E6Yg==
X-Received: by 10.50.44.68 with SMTP id c4mr14087099igm.1.1410039373996; Sat,
 06 Sep 2014 14:36:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.128.161 with HTTP; Sat, 6 Sep 2014 14:35:43 -0700 (PDT)
In-Reply-To: <CALRHqP9reGgcc03paDWXkvf6qNWgP6YtB7j=RctrEpiUP-=dCg@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
 <CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
 <CAMrx5DxVwNZo4DajGgbQh3fuQmyDFBDLTo5a64on9QaoB=XUZQ@mail.gmail.com> <CALRHqP9reGgcc03paDWXkvf6qNWgP6YtB7j=RctrEpiUP-=dCg@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Sat, 6 Sep 2014 14:35:43 -0700
Message-ID: <CAMwrk0===_kYOhOryamEBmjC-Oi_5VPkTtpVbf=BbwnUywvYcQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f8393bf01abfa05026c602b
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f8393bf01abfa05026c602b
Content-Type: text/plain; charset=UTF-8

+1

Tested streaming integration with flume on a local test bed.


On Thu, Sep 4, 2014 at 6:08 PM, Kan Zhang <kzhang@apache.org> wrote:

> +1
>
> Compiled, ran newly-introduced PySpark Hadoop input/output examples.
>
>
> On Thu, Sep 4, 2014 at 1:10 PM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>
> > +1
> >
> > Compiled, ran on yarn-hadoop-2.3 simple job.
> >
> >
> > 2014-09-04 22:22 GMT+04:00 Henry Saputra <henry.saputra@gmail.com>:
> >
> > > LICENSE and NOTICE files are good
> > > Hash files are good
> > > Signature files are good
> > > No 3rd parties executables
> > > Source compiled
> > > Run local and standalone tests
> > > Test persist off heap with Tachyon looks good
> > >
> > > +1
> > >
> > > - Henry
> > >
> > > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com>
> > > wrote:
> > > > Please vote on releasing the following candidate as Apache Spark
> > version
> > > 1.1.0!
> > > >
> > > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> > > >
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> > > >
> > > > The release files, including signatures, digests, etc. can be found
> at:
> > > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> > > >
> > > > Release artifacts are signed with the following key:
> > > > https://people.apache.org/keys/committer/pwendell.asc
> > > >
> > > > The staging repository for this release can be found at:
> > > >
> > https://repository.apache.org/content/repositories/orgapachespark-1031/
> > > >
> > > > The documentation corresponding to this release can be found at:
> > > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> > > >
> > > > Please vote on releasing this package as Apache Spark 1.1.0!
> > > >
> > > > The vote is open until Saturday, September 06, at 08:30 UTC and
> passes
> > if
> > > > a majority of at least 3 +1 PMC votes are cast.
> > > >
> > > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > > [ ] -1 Do not release this package because ...
> > > >
> > > > To learn more about Apache Spark, please see
> > > > http://spark.apache.org/
> > > >
> > > > == Regressions fixed since RC3 ==
> > > > SPARK-3332 - Issue with tagging in EC2 scripts
> > > > SPARK-3358 - Issue with regression for m3.XX instances
> > > >
> > > > == What justifies a -1 vote for this release? ==
> > > > This vote is happening very late into the QA period compared with
> > > > previous votes, so -1 votes should only occur for significant
> > > > regressions from 1.0.2. Bugs already present in 1.0.X will not block
> > > > this release.
> > > >
> > > > == What default changes should I be aware of? ==
> > > > 1. The default value of "spark.io.compression.codec" is now "snappy"
> > > > --> Old behavior can be restored by switching to "lzf"
> > > >
> > > > 2. PySpark now performs external spilling during aggregations.
> > > > --> Old behavior can be restored by setting "spark.shuffle.spill" to
> > > "false".
> > > >
> > > > 3. PySpark uses a new heuristic for determining the parallelism of
> > > > shuffle operations.
> > > > --> Old behavior can be restored by setting
> > > > "spark.default.parallelism" to the number of cores in the cluster.
> > > >
> > > > ---------------------------------------------------------------------
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
> >
> > --
> >
> >
> >
> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >
>

--e89a8f8393bf01abfa05026c602b--

From dev-return-9351-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep  6 21:50:32 2014
Return-Path: <dev-return-9351-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A820A115A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  6 Sep 2014 21:50:32 +0000 (UTC)
Received: (qmail 34863 invoked by uid 500); 6 Sep 2014 21:50:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34787 invoked by uid 500); 6 Sep 2014 21:50:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34776 invoked by uid 99); 6 Sep 2014 21:50:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 21:50:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.171 as permitted sender)
Received: from [209.85.223.171] (HELO mail-ie0-f171.google.com) (209.85.223.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 06 Sep 2014 21:50:06 +0000
Received: by mail-ie0-f171.google.com with SMTP id rp18so15887038iec.16
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 14:50:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=Df5oUUCL/jaj+gTeqvT2NcRcy/Wv+2sCa8rlWkmr7as=;
        b=k9LcdhOqGeAtpAShpKG8eQ1N7sszhAuhL5rU+JVLrP+6mAXDY3beb4i7WyQAtwgNjz
         1fyDQI/OcAlkHez/3dqFeqbRofGhzwt93k69MrNk2LOFe4ga+Nz3wnWYQ3nDq3w++ikV
         Wl5b9iejC4apEEkkNaXfj3nN+jag64tMUnSfKO3bB/dgGzgJUsRBvHRDDu1V8ECzCtRe
         8BxvQyu2bh54gWLGf8aqa08PfRF7UcDrhApBNydKOE4firXelkQrtbjVTE894tU4H4lI
         aAZMcxGNGof+bI9U9afiqrRDAJmkP40RPH6LkYkrTiFJKfL829rJqhwotJxB/QiksOQ3
         N55g==
X-Gm-Message-State: ALoCoQlNJ3bmB5wnENKs+9ElinO7vhhovDX/z2Uof11BkGJVoN/bAhT05gfWXZqYb4iFt9tkyEpk
MIME-Version: 1.0
X-Received: by 10.50.66.197 with SMTP id h5mr14156758igt.34.1410040205103;
 Sat, 06 Sep 2014 14:50:05 -0700 (PDT)
Received: by 10.107.40.72 with HTTP; Sat, 6 Sep 2014 14:50:05 -0700 (PDT)
Received: by 10.107.40.72 with HTTP; Sat, 6 Sep 2014 14:50:05 -0700 (PDT)
In-Reply-To: <CAOhmDzcH95Daw2yt6X04717sOo1xO7iTNXj+7OeYERf1KCve2w@mail.gmail.com>
References: <CAOhmDzcH95Daw2yt6X04717sOo1xO7iTNXj+7OeYERf1KCve2w@mail.gmail.com>
Date: Sat, 6 Sep 2014 22:50:05 +0100
Message-ID: <CAMAsSdJfgcq1YKd-AkLtfKkZCa35FEbfrm9Ed+9xnzdqtzUc9A@mail.gmail.com>
Subject: Re: trimming unnecessary test output
From: Sean Owen <sowen@cloudera.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bd6be0e8bf08d05026c91a6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd6be0e8bf08d05026c91a6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

This is just a line logging that one test succeeded right? I don't find
that noise. Recently I wanted to search test run logs for a test case
success and it was important that the individual test case was logged.
On Sep 6, 2014 4:13 PM, "Nicholas Chammas" <nicholas.chammas@gmail.com>
wrote:

> Continuing the discussion started here
> <https://github.com/apache/spark/pull/2279>, I=E2=80=99m wondering if peo=
ple
> already know that certain test output is unnecessary and should be trimme=
d.
>
> For example
> <
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19917/=
consoleFull
> >,
> I see a bunch of lines like this:
>
> 14/09/06 07:54:13 INFO GenerateProjection: Code generated expression
> List(IS NOT NULL 1) in 128.33733 ms
>
> Can/should this type of output be suppressed? Is there any other test
> output that is obviously more noise than signal?
>
> Nick
> =E2=80=8B
>

--047d7bd6be0e8bf08d05026c91a6--

From dev-return-9352-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 00:13:16 2014
Return-Path: <dev-return-9352-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 15E3E117F8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 00:13:16 +0000 (UTC)
Received: (qmail 52149 invoked by uid 500); 7 Sep 2014 00:13:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52058 invoked by uid 500); 7 Sep 2014 00:13:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52047 invoked by uid 99); 7 Sep 2014 00:13:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 00:13:15 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 00:12:48 +0000
Received: by mail-ie0-f182.google.com with SMTP id rd18so15885200iec.41
        for <dev@spark.apache.org>; Sat, 06 Sep 2014 17:12:47 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=DVOiZScPbWC9+ueYRB2WMV4XsnYNZxJSPGt/lN/qmBo=;
        b=TsH4Xpdydbey4H7w5axduFjBGrmuvCh13MtBt/T1EdUd6P2oeT/ev1uJ6nKntxY3Ik
         4PyU9M8LUvu41WgKdIC/n/eY6rc6rg8FRrnONoQe2T2PrE4g7O+y/bRHklv/dnasom3F
         qa+krE9pYEPT3CJBj2r3oSmXRu0L60ro8xceYO/dR/2Nm2M3e8xLJ7O0gOCAvgY29iv9
         X8EQjqecbkdGLbslI09nlrjSwqZieNlG8/goJ2+GtBvz5B1Wg0K2Ikp76jvcFiTqfRG/
         AAfg4u2Ln8eGK97+YFxK1uiY+2JLhzWThxWVYsSkdysjeSHvXt328ADwjSCyehqyz69H
         pJow==
X-Gm-Message-State: ALoCoQmvaX7Y6OGIU7mxzNHPqz68bQC20VS+sD2VTbBqDLd2a11t2uaY/kUqxukiSBHNSeO99tVf
MIME-Version: 1.0
X-Received: by 10.50.164.167 with SMTP id yr7mr14335453igb.37.1410048767113;
 Sat, 06 Sep 2014 17:12:47 -0700 (PDT)
Received: by 10.107.3.201 with HTTP; Sat, 6 Sep 2014 17:12:47 -0700 (PDT)
In-Reply-To: <CAMwrk0===_kYOhOryamEBmjC-Oi_5VPkTtpVbf=BbwnUywvYcQ@mail.gmail.com>
References: <CABPQxst8N_Kw0H7sv6Q3f+jgCM5scpbG7t8h8GXt+bMDXAmUBQ@mail.gmail.com>
	<CALuGr6aeNw--+PNx8CAd1E=0qCYh4-BEcUrPiWMLY3hHOb2R7Q@mail.gmail.com>
	<CAMrx5DxVwNZo4DajGgbQh3fuQmyDFBDLTo5a64on9QaoB=XUZQ@mail.gmail.com>
	<CALRHqP9reGgcc03paDWXkvf6qNWgP6YtB7j=RctrEpiUP-=dCg@mail.gmail.com>
	<CAMwrk0===_kYOhOryamEBmjC-Oi_5VPkTtpVbf=BbwnUywvYcQ@mail.gmail.com>
Date: Sat, 6 Sep 2014 17:12:47 -0700
Message-ID: <CAHuE29aJg_GS3KDkh5xexqZ=MnK1LkjOu0PZfGVddB-q=tGuOQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Reza Zadeh <reza@databricks.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122a7fce15a3705026e8f6c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a7fce15a3705026e8f6c
Content-Type: text/plain; charset=UTF-8

+1
Tested recently merged mllib matrix multiplication bugfix
<https://github.com/apache/spark/pull/2224>


On Sat, Sep 6, 2014 at 2:35 PM, Tathagata Das <tathagata.das1565@gmail.com>
wrote:

> +1
>
> Tested streaming integration with flume on a local test bed.
>
>
> On Thu, Sep 4, 2014 at 6:08 PM, Kan Zhang <kzhang@apache.org> wrote:
>
> > +1
> >
> > Compiled, ran newly-introduced PySpark Hadoop input/output examples.
> >
> >
> > On Thu, Sep 4, 2014 at 1:10 PM, Egor Pahomov <pahomov.egor@gmail.com>
> > wrote:
> >
> > > +1
> > >
> > > Compiled, ran on yarn-hadoop-2.3 simple job.
> > >
> > >
> > > 2014-09-04 22:22 GMT+04:00 Henry Saputra <henry.saputra@gmail.com>:
> > >
> > > > LICENSE and NOTICE files are good
> > > > Hash files are good
> > > > Signature files are good
> > > > No 3rd parties executables
> > > > Source compiled
> > > > Run local and standalone tests
> > > > Test persist off heap with Tachyon looks good
> > > >
> > > > +1
> > > >
> > > > - Henry
> > > >
> > > > On Wed, Sep 3, 2014 at 12:24 AM, Patrick Wendell <pwendell@gmail.com
> >
> > > > wrote:
> > > > > Please vote on releasing the following candidate as Apache Spark
> > > version
> > > > 1.1.0!
> > > > >
> > > > > The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd):
> > > > >
> > > >
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460
> > > > >
> > > > > The release files, including signatures, digests, etc. can be found
> > at:
> > > > > http://people.apache.org/~pwendell/spark-1.1.0-rc4/
> > > > >
> > > > > Release artifacts are signed with the following key:
> > > > > https://people.apache.org/keys/committer/pwendell.asc
> > > > >
> > > > > The staging repository for this release can be found at:
> > > > >
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1031/
> > > > >
> > > > > The documentation corresponding to this release can be found at:
> > > > > http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/
> > > > >
> > > > > Please vote on releasing this package as Apache Spark 1.1.0!
> > > > >
> > > > > The vote is open until Saturday, September 06, at 08:30 UTC and
> > passes
> > > if
> > > > > a majority of at least 3 +1 PMC votes are cast.
> > > > >
> > > > > [ ] +1 Release this package as Apache Spark 1.1.0
> > > > > [ ] -1 Do not release this package because ...
> > > > >
> > > > > To learn more about Apache Spark, please see
> > > > > http://spark.apache.org/
> > > > >
> > > > > == Regressions fixed since RC3 ==
> > > > > SPARK-3332 - Issue with tagging in EC2 scripts
> > > > > SPARK-3358 - Issue with regression for m3.XX instances
> > > > >
> > > > > == What justifies a -1 vote for this release? ==
> > > > > This vote is happening very late into the QA period compared with
> > > > > previous votes, so -1 votes should only occur for significant
> > > > > regressions from 1.0.2. Bugs already present in 1.0.X will not
> block
> > > > > this release.
> > > > >
> > > > > == What default changes should I be aware of? ==
> > > > > 1. The default value of "spark.io.compression.codec" is now
> "snappy"
> > > > > --> Old behavior can be restored by switching to "lzf"
> > > > >
> > > > > 2. PySpark now performs external spilling during aggregations.
> > > > > --> Old behavior can be restored by setting "spark.shuffle.spill"
> to
> > > > "false".
> > > > >
> > > > > 3. PySpark uses a new heuristic for determining the parallelism of
> > > > > shuffle operations.
> > > > > --> Old behavior can be restored by setting
> > > > > "spark.default.parallelism" to the number of cores in the cluster.
> > > > >
> > > > >
> ---------------------------------------------------------------------
> > > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > > >
> > > >
> > > > ---------------------------------------------------------------------
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > > >
> > >
> > >
> > > --
> > >
> > >
> > >
> > > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> > >
> >
>

--089e0122a7fce15a3705026e8f6c--

From dev-return-9353-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 19:26:29 2014
Return-Path: <dev-return-9353-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2574711593
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 19:26:29 +0000 (UTC)
Received: (qmail 15125 invoked by uid 500); 7 Sep 2014 19:26:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15051 invoked by uid 500); 7 Sep 2014 19:26:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15039 invoked by uid 99); 7 Sep 2014 19:26:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 19:26:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 19:26:23 +0000
Received: by mail-ie0-f176.google.com with SMTP id x19so16106210ier.7
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 12:26:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:subject:mime-version:content-type;
        bh=q8A+E4MSh6sVGqRpaJrss4Dbh31XVJHS4Duo9JkqYfY=;
        b=zEYzyz/JrhQkpQYTl9exm/LKWCDc05akuPmSodsCl7O2LPuqXOWRfjSGzIBkB0ncb8
         uZ9ZDorIdtYPO8hdUFOrFAcUGqc5+kKlhe2juqmhmxROF4yKCbDi5sI9Bj6NzScbVVtA
         jlBHQE+jKdO8QoDZ57fRPI7My3KF95Gj7tLIBSZVEPOt18Omfpz6/j4d7QDYzFpvixEP
         DoVK5RQzTsNdIczXtI0YIVDeb/k0zHAZYHrxDJPKcI5ZjX6twjwtXCaOTZ79MJE8nd3o
         HrAE3bkZK/y60QmSd1r5A1rIH4BYkaVBFDRiRLD8TNdh2Kb+hP+CrbkwMQ7I2wAGuPmN
         nZeg==
X-Received: by 10.50.147.38 with SMTP id th6mr19148295igb.31.1410117962780;
        Sun, 07 Sep 2014 12:26:02 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id an1sm9158358igc.8.2014.09.07.12.26.02
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sun, 07 Sep 2014 12:26:02 -0700 (PDT)
Date: Sun, 7 Sep 2014 15:39:42 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: dev@spark.apache.org
Message-ID: <ECE032890BB14031BBA489DAA6B82702@gmail.com>
Subject: jenkins failed all tests?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540cb47e_23f9c13c_69b7"
X-Virus-Checked: Checked by ClamAV on apache.org

--540cb47e_23f9c13c_69b7
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Hi, all 

I just modified some document, 

but still failed to pass tests?

https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19950/consoleFull

Anyone can look at the problem?

Best, 

-- 
Nan Zhu


--540cb47e_23f9c13c_69b7--


From dev-return-9354-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 20:30:37 2014
Return-Path: <dev-return-9354-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD7A111712
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 20:30:37 +0000 (UTC)
Received: (qmail 75025 invoked by uid 500); 7 Sep 2014 20:30:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74960 invoked by uid 500); 7 Sep 2014 20:30:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74948 invoked by uid 99); 7 Sep 2014 20:30:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:30:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:30:32 +0000
Received: by mail-la0-f44.google.com with SMTP id mc6so1277334lab.17
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 13:30:10 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ev3apybk1C2zvvZCaHlwZp3J220wwfKPlaUIwlkrZiQ=;
        b=d9Mayytb/aS7EGjMor6NoQTQK1k+u7o7Qru1bnqWhfmJ1UML/AjKc6sEgKs32mVadI
         hB699JXx+k/ACBVcWIsrr0GwPHDPaPkV8dcTO9uIq1b33NCFvAV7oDuLhPZ73vyUkNq4
         80V6n8vtX9Rpbil6aPR4yoHHevbHzAo7HEWchJpt4oas6+VFECLCebMS5MJoKxP4XwfO
         uR0dsZRytdyn6Gk6RoAfU3JLsdpW1Cm1HTT9uNB/i/48L0Z/xyTjV5pFswLH8HYBB7gU
         a3PdbvHQk4qaZ622OLjjGqSldV4IBMHQmZIJtuacHc2gnUn36U2bQdjJ+g5cWWe0qVaF
         uPnA==
X-Gm-Message-State: ALoCoQmi9fmb3KPZ1TfENyw4uiM9uSdvt2UV2pV/2xu8fkAlV7RwVwzNURNXFofaX+oMT9kGEHby
X-Received: by 10.152.10.74 with SMTP id g10mr24901975lab.41.1410121810502;
 Sun, 07 Sep 2014 13:30:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Sun, 7 Sep 2014 13:29:50 -0700 (PDT)
In-Reply-To: <CAMAsSdJfgcq1YKd-AkLtfKkZCa35FEbfrm9Ed+9xnzdqtzUc9A@mail.gmail.com>
References: <CAOhmDzcH95Daw2yt6X04717sOo1xO7iTNXj+7OeYERf1KCve2w@mail.gmail.com>
 <CAMAsSdJfgcq1YKd-AkLtfKkZCa35FEbfrm9Ed+9xnzdqtzUc9A@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Sun, 7 Sep 2014 13:29:50 -0700
Message-ID: <CAAswR-6SN5ac32YN0HaWPLZeSY_hSA=9Jj615t1M4=k_xhR39g@mail.gmail.com>
Subject: Re: trimming unnecessary test output
To: Sean Owen <sowen@cloudera.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1132f1709afeb705027f917c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1132f1709afeb705027f917c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Feel free to submit a PR to add a log4j.properies file to
sql/catalyst/src/test/resources similar to what we do in core/hive.


On Sat, Sep 6, 2014 at 2:50 PM, Sean Owen <sowen@cloudera.com> wrote:

> This is just a line logging that one test succeeded right? I don't find
> that noise. Recently I wanted to search test run logs for a test case
> success and it was important that the individual test case was logged.
> On Sep 6, 2014 4:13 PM, "Nicholas Chammas" <nicholas.chammas@gmail.com>
> wrote:
>
> > Continuing the discussion started here
> > <https://github.com/apache/spark/pull/2279>, I=E2=80=99m wondering if p=
eople
> > already know that certain test output is unnecessary and should be
> trimmed.
> >
> > For example
> > <
> >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19917/=
consoleFull
> > >,
> > I see a bunch of lines like this:
> >
> > 14/09/06 07:54:13 INFO GenerateProjection: Code generated expression
> > List(IS NOT NULL 1) in 128.33733 ms
> >
> > Can/should this type of output be suppressed? Is there any other test
> > output that is obviously more noise than signal?
> >
> > Nick
> > =E2=80=8B
> >
>

--001a1132f1709afeb705027f917c--

From dev-return-9355-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 20:31:29 2014
Return-Path: <dev-return-9355-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 14A6D11713
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 20:31:29 +0000 (UTC)
Received: (qmail 76285 invoked by uid 500); 7 Sep 2014 20:31:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76210 invoked by uid 500); 7 Sep 2014 20:31:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76198 invoked by uid 99); 7 Sep 2014 20:31:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:31:27 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:31:23 +0000
Received: by mail-ig0-f170.google.com with SMTP id h3so1856454igd.5
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 13:31:03 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=raxkwG+qDK51EgVr1ScN+npWEosvl+crpzjEKzkgp7g=;
        b=jpADINtpoN3MBMPjpehq4y0ejP1IuK60RJohq6xXinCKS0mhQOEujl2kRoIrB3dFNw
         04TKd+CQVPE06fgPtqS+r1gz5MUFP0i3sG2TS0qfWcOJylXh5AimeOFnA2f05ubDg01X
         jLDQ+fQR/DO7+1hYykj+NKUe0s1rTX9o4Zy0xOtARFqbn6QpL27KbmFH0566FpZizwAJ
         LeTRTVchBV5XLT2fMPBVNByPPH6ZwURi/n5t+dFkz5jW+81XDwO6p25Y8NsOLs69g+rO
         P/p+G+3gLlt1SYftFIvmPNS8Bsr9TwiYtHCx1P+KRZVZ9IQp8jKadtWxUHYPBeLEUEFk
         WTjA==
X-Gm-Message-State: ALoCoQnij0dr/7TLhEmPmgQtebEm9VL5pdmGa8HFy+xohoaB3azzSpMoeBHXo7iqSbpqG3+kwLEB
X-Received: by 10.50.108.103 with SMTP id hj7mr19084775igb.5.1410121863215;
 Sun, 07 Sep 2014 13:31:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Sun, 7 Sep 2014 13:30:43 -0700 (PDT)
In-Reply-To: <ECE032890BB14031BBA489DAA6B82702@gmail.com>
References: <ECE032890BB14031BBA489DAA6B82702@gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Sun, 7 Sep 2014 21:30:43 +0100
Message-ID: <CAMAsSdL_zXsqiUvvBN_yiGAXRD8+p7HOidnVW37SGL7vvF6TEQ@mail.gmail.com>
Subject: Re: jenkins failed all tests?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

It would help to point to your change. Are you sure it was only docs
and are you sure you're rebased, submitting against the right branch?
Jenkins is saying you are changing public APIs; it's not reporting
test failures. But it could well be a test/Jenkins problem.

On Sun, Sep 7, 2014 at 8:39 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
> Hi, all
>
> I just modified some document,
>
> but still failed to pass tests?
>
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19950/consoleFull
>
> Anyone can look at the problem?
>
> Best,
>
> --
> Nan Zhu
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9356-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 20:39:37 2014
Return-Path: <dev-return-9356-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A84B11735
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 20:39:37 +0000 (UTC)
Received: (qmail 92668 invoked by uid 500); 7 Sep 2014 20:39:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92594 invoked by uid 500); 7 Sep 2014 20:39:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92579 invoked by uid 99); 7 Sep 2014 20:39:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:39:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.182 as permitted sender)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:39:31 +0000
Received: by mail-ie0-f182.google.com with SMTP id tr6so353512ieb.41
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 13:39:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=difQN7UK262iYpb3B86KpaCBNMbkua8E6mkbEF4/OnQ=;
        b=RjKzwUR/dc8uY3HFikri7Iip9yFJJ8jOF2Bb+QHWmINMW8AFuhNX8NR7tXTwmFNsIh
         b8x7p99n1pQsVWwe9M92Gnfjo7mK7aqaKkEZ6ocq97e3mxgvuEtLotVBEFe774bZKjXY
         CaOsZnx5MQVG1zOqnUSY4kls0sxeUlHZMM+mw19a3t8pOxpnemqqA86paGwFCxANB9bB
         Z7J3Inwm9ll6IeyKcj/kmg/hdHwYCBxJ3B8R2/abQ72FDoJxNajWIegLbo/EHbcjhrMI
         dU2SIt8ruRallIvQhH8QZGdr77z51ML4jYe0T9cucSglGmnXFpWQL7C+oGd3BGvI50v6
         ZgGA==
X-Received: by 10.50.80.39 with SMTP id o7mr19321384igx.0.1410122351198;
        Sun, 07 Sep 2014 13:39:11 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id a4sm7254235igv.1.2014.09.07.13.39.10
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sun, 07 Sep 2014 13:39:10 -0700 (PDT)
Date: Sun, 7 Sep 2014 16:52:50 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <E7838A1DAB1F4AE4B953B325F5B35675@gmail.com>
In-Reply-To: <CAMAsSdL_zXsqiUvvBN_yiGAXRD8+p7HOidnVW37SGL7vvF6TEQ@mail.gmail.com>
References: <ECE032890BB14031BBA489DAA6B82702@gmail.com>
 <CAMAsSdL_zXsqiUvvBN_yiGAXRD8+p7HOidnVW37SGL7vvF6TEQ@mail.gmail.com>
Subject: Re: jenkins failed all tests?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540cc5a2_15b5af5c_69b7"
X-Virus-Checked: Checked by ClamAV on apache.org

--540cc5a2_15b5af5c_69b7
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Hi, Sean, 

Thanks for the reply

Here are the updated files:

https://github.com/apache/spark/pull/2312/files 

just two md files...

Best, 

-- 
Nan Zhu


On Sunday, September 7, 2014 at 4:30 PM, Sean Owen wrote:

> It would help to point to your change. Are you sure it was only docs
> and are you sure you're rebased, submitting against the right branch?
> Jenkins is saying you are changing public APIs; it's not reporting
> test failures. But it could well be a test/Jenkins problem.
> 
> On Sun, Sep 7, 2014 at 8:39 PM, Nan Zhu <zhunanmcgill@gmail.com (mailto:zhunanmcgill@gmail.com)> wrote:
> > Hi, all
> > 
> > I just modified some document,
> > 
> > but still failed to pass tests?
> > 
> > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19950/consoleFull
> > 
> > Anyone can look at the problem?
> > 
> > Best,
> > 
> > --
> > Nan Zhu
> > 
> 
> 
> 



--540cc5a2_15b5af5c_69b7--


From dev-return-9357-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 20:41:02 2014
Return-Path: <dev-return-9357-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8F7A61173C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 20:41:02 +0000 (UTC)
Received: (qmail 95512 invoked by uid 500); 7 Sep 2014 20:41:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95434 invoked by uid 500); 7 Sep 2014 20:41:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95422 invoked by uid 99); 7 Sep 2014 20:41:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:41:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 20:40:56 +0000
Received: by mail-ie0-f174.google.com with SMTP id at20so16856955iec.33
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 13:40:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=r3qxr8wTzzCmgGQZDpNjYqNOyvvu3PQ/x9V9HxRSQ8w=;
        b=QuudakLjrIo5c0CIZ4nlQD6X0n4zdkw/oQnMqv5wgnC+IodwePVhhCg569obEyN56e
         8Mq3g+AkOiXDWGxESvQGPxmHB3k0X7IHusYymWjO9Ai1xJv9AYQoeW7PuAO9tFcFgJEc
         tTUcT/kIUqf+LpwLw4UHIpzFdcacdG/ykql93Db9sjfF7drYfpRpaOOIpLx7JyBmjcbH
         hyozZuf9JBgmgKnnTJrIvYQ4qA49ZQK3EGiCk5qnc8btwl9Y2iyo3FrzEOE+ILiwRGQH
         2tw1dMOeaP69+s7IOg68Oj7iRWqdf8mebg46WF2DfXf7tVNBUBEpUZKXnbOKy2WUEwQ0
         xfhg==
X-Received: by 10.50.43.138 with SMTP id w10mr18881322igl.33.1410122436515;
        Sun, 07 Sep 2014 13:40:36 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id au4sm891438igc.3.2014.09.07.13.40.36
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sun, 07 Sep 2014 13:40:36 -0700 (PDT)
Date: Sun, 7 Sep 2014 16:54:16 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <8E75500248364F6198C4566F481A5654@gmail.com>
In-Reply-To: <E7838A1DAB1F4AE4B953B325F5B35675@gmail.com>
References: <ECE032890BB14031BBA489DAA6B82702@gmail.com>
 <CAMAsSdL_zXsqiUvvBN_yiGAXRD8+p7HOidnVW37SGL7vvF6TEQ@mail.gmail.com>
 <E7838A1DAB1F4AE4B953B325F5B35675@gmail.com>
Subject: Re: jenkins failed all tests?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540cc5f8_310c50b3_69b7"
X-Virus-Checked: Checked by ClamAV on apache.org

--540cc5f8_310c50b3_69b7
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

It seems that I=E2=80=99m not the only one  =20

https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/

Best, =20

-- =20
Nan Zhu


On Sunday, September 7, 2014 at 4:52 PM, Nan Zhu wrote:

> Hi, Sean, =20
> =20
> Thanks for the reply
> =20
> Here are the updated files:
> =20
> https://github.com/apache/spark/pull/2312/files =20
> =20
> just two md files...
> =20
> Best, =20
> =20
> -- =20
> Nan Zhu
> =20
> =20
> On Sunday, September 7, 2014 at 4:30 PM, Sean Owen wrote:
> =20
> > It would help to point to your change. Are you sure it was only docs
> > and are you sure you're rebased, submitting against the right branch=3F=

> > Jenkins is saying you are changing public APIs; it's not reporting
> > test failures. But it could well be a test/Jenkins problem.
> > =20
> > On Sun, Sep 7, 2014 at 8:39 PM, Nan Zhu <zhunanmcgill=40gmail.com (ma=
ilto:zhunanmcgill=40gmail.com)> wrote:
> > > Hi, all
> > > =20
> > > I just modified some document,
> > > =20
> > > but still failed to pass tests=3F
> > > =20
> > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/=
19950/console=46ull
> > > =20
> > > Anyone can look at the problem=3F
> > > =20
> > > Best,
> > > =20
> > > --
> > > Nan Zhu
> > > =20
> > =20
> > =20
> > =20
> > =20
> =20
> =20


--540cc5f8_310c50b3_69b7--


From dev-return-9358-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 22:28:01 2014
Return-Path: <dev-return-9358-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1259011874
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 22:28:01 +0000 (UTC)
Received: (qmail 70583 invoked by uid 500); 7 Sep 2014 22:28:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70505 invoked by uid 500); 7 Sep 2014 22:28:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70493 invoked by uid 99); 7 Sep 2014 22:27:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 22:27:59 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 22:27:34 +0000
Received: by mail-wg0-f48.google.com with SMTP id m15so676766wgh.7
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 15:27:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=3gGvJ9gSwGrQtiJQcp7v4rX6HINKBPJIB0HufCup6oM=;
        b=Is58I1DuB5mQZ6jAP7p+5DCJY6c0X+yD9rBltkeeGZNYdkCVATSWJt7eAp5kwgE18h
         T3KjuEhAlq63sBrGdQDKQDJ7/7ZviSTVrlKJD1dH6j787hykt15L7qs9wa6yQAu/VHTC
         nWnEb8l05vRRsz9ydb2qGGI5dXuHGhoaXZrY9D9Yb345dJjkWcJHGPrppCO2KpnJ5mYt
         faz8N43E/RE7xm5sfS1e40vnAANfGMSEaJz9BBdZJcYUw+Udd4QV4MUvSR/bweUOwx9I
         IMBxNciFi8aEUyaQ047DBa0NDp6pP7sCP55R3vfUvhLRCiaUX8EIMZ2gWSWGE6KvDSNl
         gneQ==
X-Received: by 10.194.103.41 with SMTP id ft9mr30378794wjb.93.1410128853588;
 Sun, 07 Sep 2014 15:27:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sun, 7 Sep 2014 15:26:53 -0700 (PDT)
In-Reply-To: <8E75500248364F6198C4566F481A5654@gmail.com>
References: <ECE032890BB14031BBA489DAA6B82702@gmail.com> <CAMAsSdL_zXsqiUvvBN_yiGAXRD8+p7HOidnVW37SGL7vvF6TEQ@mail.gmail.com>
 <E7838A1DAB1F4AE4B953B325F5B35675@gmail.com> <8E75500248364F6198C4566F481A5654@gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 7 Sep 2014 18:26:53 -0400
Message-ID: <CAOhmDzeT+30DhSt3E68CxDfHQKvxmpTj60gkqvzqnM9jpYW+dA@mail.gmail.com>
Subject: Re: jenkins failed all tests?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0102d91267dfd30502813532
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0102d91267dfd30502813532
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Yeah, it feels like Jenkins has become a lot more flaky recently. Or maybe
it=E2=80=99s just our tests.

Here are some more examples:

   - https://github.com/apache/spark/pull/2310#issuecomment-54741169
   - https://github.com/apache/spark/pull/2313#issuecomment-54752766

Nick
=E2=80=8B

On Sun, Sep 7, 2014 at 4:54 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> It seems that I=E2=80=99m not the only one
>
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>
> Best,
>
> --
> Nan Zhu
>
>
> On Sunday, September 7, 2014 at 4:52 PM, Nan Zhu wrote:
>
> > Hi, Sean,
> >
> > Thanks for the reply
> >
> > Here are the updated files:
> >
> > https://github.com/apache/spark/pull/2312/files
> >
> > just two md files...
> >
> > Best,
> >
> > --
> > Nan Zhu
> >
> >
> > On Sunday, September 7, 2014 at 4:30 PM, Sean Owen wrote:
> >
> > > It would help to point to your change. Are you sure it was only docs
> > > and are you sure you're rebased, submitting against the right branch?
> > > Jenkins is saying you are changing public APIs; it's not reporting
> > > test failures. But it could well be a test/Jenkins problem.
> > >
> > > On Sun, Sep 7, 2014 at 8:39 PM, Nan Zhu <zhunanmcgill@gmail.com
> (mailto:zhunanmcgill@gmail.com)> wrote:
> > > > Hi, all
> > > >
> > > > I just modified some document,
> > > >
> > > > but still failed to pass tests?
> > > >
> > > >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19950/=
consoleFull
> > > >
> > > > Anyone can look at the problem?
> > > >
> > > > Best,
> > > >
> > > > --
> > > > Nan Zhu
> > > >
> > >
> > >
> > >
> > >
> >
> >
>
>

--089e0102d91267dfd30502813532--

From dev-return-9359-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 22:29:57 2014
Return-Path: <dev-return-9359-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3337411877
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 22:29:57 +0000 (UTC)
Received: (qmail 72077 invoked by uid 500); 7 Sep 2014 22:29:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72004 invoked by uid 500); 7 Sep 2014 22:29:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 35406 invoked by uid 99); 7 Sep 2014 21:26:02 -0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Date: Sun, 7 Sep 2014 14:25:34 -0700 (PDT)
From: cjermaine <cmj4@rice.edu>
To: dev@spark.incubator.apache.org
Message-ID: <1410125134575-8326.post@n3.nabble.com>
In-Reply-To: <CANJrAvBfzo_9d3TjKv9bQ59A82nau6m_cPrZ3cM9n2XT3YqeZw@mail.gmail.com>
References: <CANJrAvBfzo_9d3TjKv9bQ59A82nau6m_cPrZ3cM9n2XT3YqeZw@mail.gmail.com>
Subject: Re: A Comparison of Platforms for Implementing and Running Very
 Large Scale Machine Learning Algorithms
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org


I=E2=80=99m out of the authors of this paper, and I just came across this t=
hread.
I=E2=80=99m glad that Ignacio Zendejas noticed our paper!

First off, let me post link to the published version of the paper, which is
likely slightly different than the version linked above:

http://cmj4.web.rice.edu/performance.pdf
<http://cmj4.web.rice.edu/performance.pdf> =20

Next, I just want to quickly address a couple of comments made here.

rxin says:

> They only compared their own implementations of couple algorithms on=20
> different platforms rather than comparing the different platforms=20
> themselves (in the case of Spark -- PySpark). I can write two variants of=
=20
> an algorithm on Spark and make them perform drastically differently.=20

It=E2=80=99s a bit misleading to say that we just tried a =E2=80=9Ccouple=
=E2=80=9D of algorithms;
the paper describes five different algorithms, along with multiple
implementations on each; we tried a LOT of variants of each algorithm, as w=
e
detail in the paper.

Also, it is true that we did use our own implementations; the point was to
compare each platform as a programming and execution platform. The paper is
clear that the benchmark was directed towards =E2=80=9Ca user who wants to =
run a
specific ML inference algorithm over a large data set, but cannot find an
existing implementation and thus must 'roll her own' ML code.=E2=80=9D We
specifically state that we are not interested in comparing canned libraries=
,
which is a very different task. Both ease-of-use and speed were considered
as being equally important. If you read the paper, you=E2=80=99ll see that =
we
generally gave PySpark high marks as a programming platform

Several of the posts here imply that all Spark experiments were using
PySpark. This is not true. Matei Zaharia says:

> Just as a note on this paper, apart from implementing the algorithms in
> naive Python=E2=80=A6

And Ignacio Zendajas says:

> Interesting that they chose to use Python alone=E2=80=A6

In reality, the paper also describes pure Java implementations that ran on
Spark, with no Python, for two models: a Gaussian mixture model and LDA.=20

For the GMM, Java ran in 40-50% of the time compared to Python (though to b=
e
fair, a lot of that is due to the fact that GMM inference is
linear-algebra-intensive; it=E2=80=99s not easy to do linear algebra in the=
 JVM for
reasons I=E2=80=99ll not get into here=E2=80=A6 it=E2=80=99s possible someo=
ne else could do a lot
better). On LDA, Java was less than 10% of the Python time (that is, much
faster).

Matai Zaharia also says:

> they also run it in a fairly inefficient way. In particular=20
> their implementations send the model out with every task closure, which i=
s=20
> really expensive for a large model, and bring it back with collectAsMap()=
.=20

It=E2=80=99s certainly possible our implementations were sub-optimal. All I=
 can say
is that again, the goal of the paper was to chronicle our experiences using
each platform as both a programming and execution platform. While doubtless
Spark=E2=80=99s developers could have done a better job of writing code for=
 Spark, I
hope we didn=E2=80=99t do too badly! And again, evaluating ease-of-programm=
ing was
at least half of our goal.

That said, I doubt that sending out the model should be much of a bottlenec=
k
as Matai Zaharia implies=E2=80=94at least in the cases we tested.  And even=
 if it
was a bottleneck, one could argue that it probably shouldn't be. In the ver=
y
worst case (LDA) the model is 100 components X 10^4 dictionary size X 8
bytes per FP number, or 8 MB in all. Not too large. The smallest model is
the GMM @10 dimension. In this case, the model has 10 components X (10 X 10
covariance matrix + 10 dim mean vector) X 8 bytes, or roughly 10KB.  Tiny
even!

Matai Zaharia also says:

> Implementing ML algorithms well by hand is unfortunately difficult, and
> this=20
> is why we have MLlib. The hope is that you either get your desired
> algorithm=20
> out of the box or get a higher-level primitive (e.g. stochastic gradient=
=20
> descent) that you can plug some functions into, without worrying about=20
> the communication.=20

I couldn=E2=80=99t agree more. But again, the idea of our benchmark was spe=
cifically
to consider the case of an expert who is facing just such an implementation
challenge: he/she needs a model for which a canned implementation does not
exist.=20

Finally, let me say that we=E2=80=99d absolutely LOVE it if someone who is =
an active
Spark developer would take the time to implement one or more of these
algorithms and replicate our experiments (I=E2=80=99d be happy to help anyo=
ne out
who wants to do this=E2=80=94send me a message). It=E2=80=99s already been =
a year since we
did all of this, and for that reason alone the results might be quite
different.



--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/A-Comparison-of-Platforms-for-Implementing-and-Running-Very-La=
rge-Scale-Machine-Learning-Algorithms-tp7823p8326.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9360-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep  7 23:08:31 2014
Return-Path: <dev-return-9360-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4249311997
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  7 Sep 2014 23:08:31 +0000 (UTC)
Received: (qmail 1066 invoked by uid 500); 7 Sep 2014 23:08:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1001 invoked by uid 500); 7 Sep 2014 23:08:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 986 invoked by uid 99); 7 Sep 2014 23:08:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 23:08:29 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.216.41 as permitted sender)
Received: from [209.85.216.41] (HELO mail-qa0-f41.google.com) (209.85.216.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 07 Sep 2014 23:08:03 +0000
Received: by mail-qa0-f41.google.com with SMTP id m5so13487781qaj.14
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 16:08:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=4oRE7wBhAlQ8AyPodAtPy6ejgvMhFLZXHsswU9EDq/E=;
        b=kDGZhvm7ls1o8ISiCnu6KaM8vOBZ7MLgsD4Rji1FvytgtNZRMPnvQ7HMWVcZqEEKAx
         lK7v8jSVwAf7R0t9nxeKQ9ktkWFfr4SZ1nrpSfQiRlXrPDKAoGe+zLfR/e5CMi1r5DzU
         8Zux+YARHUNllcBbIuaEud90bi1mMhI/Zb3J60u0weIWtyki7ea2WLsCnijHpSWhuIT7
         ElzHvWg5s9v/TRGZFjxwDTtXSzdpNhu6zAFO2m1R3xoDGFh/5QihNHYVcP7ouIXdbe8X
         i8izVx7mMnKKiO/PZWAox6QVJPl2dUvabsrpvO4uz/oswz6DUuziQNr5bJAOPRBpULNu
         ltUw==
X-Received: by 10.140.42.17 with SMTP id b17mr24760362qga.52.1410131282483;
        Sun, 07 Sep 2014 16:08:02 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:7195:472b:6f30:6299])
        by mx.google.com with ESMTPSA id l1sm6371424qao.20.2014.09.07.16.08.00
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Sun, 07 Sep 2014 16:08:01 -0700 (PDT)
Date: Sun, 7 Sep 2014 16:07:58 -0700
From: Josh Rosen <rosenville@gmail.com>
To: shane knapp <sknapp@berkeley.edu>, Nicholas Chammas
 <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>, Mike Patterson <mike@databricks.com>, 
 Matthew L Massie <massie@cs.berkeley.edu>, amp-infra
 <amp-infra@googlegroups.com>
Message-ID: <etPan.540ce54e.79e2a9e3.112@joshs-mbp.att.net>
In-Reply-To: <etPan.540b6509.3d1b58ba.112@joshs-mbp>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
 <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
 <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
 <etPan.540a5a1b.238e1f29.112@joshs-mbp>
 <etPan.540b6509.3d1b58ba.112@joshs-mbp>
Subject: Re: amplab jenkins is down
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="540ce54e_7545e146_112"
X-Virus-Checked: Checked by ClamAV on apache.org

--540ce54e_7545e146_112
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Does anyone know why some of the MiMa tests have started failing=3F

See=C2=A0https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuild=
er/19948/console=46ull=C2=A0for an example.

On September 6, 2014 at 12:48:27 PM, Josh Rosen (rosenville=40gmail.com) =
wrote:

It looks like Jenkins is up and running, but there seems to be a delay in=
 responding to requests to re-test patches. =C2=A0It seems like Jenkins i=
s promptly testing new PRs, or new commits as they=E2=80=99re added to ex=
isting PRs, but taking a very=C2=A0long time to respond to requests to re=
-test PRs.

I=E2=80=99m going to continue monitoring this today. =C2=A0I=E2=80=99m co=
nsidering creating my own fork of the Jenkins pull request builder plugin=
 so that we can add extra logging in order to diagnose what=E2=80=99s cau=
sing this lag.

- Josh
On September 5, 2014 at 5:49:32 PM, Josh Rosen (rosenville=40gmail.com) w=
rote:

We have successfully purged Jenkins=E2=80=99 build queue. =C2=A0If you wa=
nt a PR to be re-tested, please ask Jenkins again.

On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp=40berkeley.edu) w=
rote:

yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new key,=

and magique=21

we're about to clear the queue of all builds as most aren't wanted/needed=
.


On =46ri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <nicholas.chammas=40gm=
ail.com
> wrote:

> Looks like Jenkins is back=21
>
> lol The poor guy has like a million builds
> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/=
job/SparkPullRequestBuilder/>
> to catch up on.
>
>
> On =46ri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
> nicholas.chammas=40gmail.com> wrote:
>
>> How's it going=3F
>>
>> It looks like during the last build
>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders=
/job/SparkPullRequestBuilder/lastBuild/console>
>> from about 30 min ago Jenkins was still having trouble fetching from
>> GitHub. It also looks like not all requests for testing are triggering=

>> builds.
>>
>>
>> On =46ri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp=40berkeley.edu> =
wrote:
>>
>>> it's looking like everything except the pull request builders are
>>> working. i'm going to be working on getting this resolved today.
>>>
>>>
>>> On =46ri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>>> nicholas.chammas=40gmail.com> wrote:
>>>
>>>> Hmm, looks like at least some builds
>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builde=
rs/job/SparkPullRequestBuilder/19804/console=46ull>
>>>> are working now, though this last one was from =7E5 hours ago.
>>>>
>>>>
>>>> On =46ri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp=40berkeley.edu=
>
>>>> wrote:
>>>>
>>>>> yep. that's exactly the behavior i saw earlier, and will be figurin=
g
>>>>> out first thing tomorrow morning. i bet it's an environment issues =
on the
>>>>> slaves.
>>>>>
>>>>>
>>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>>>> nicholas.chammas=40gmail.com> wrote:
>>>>>
>>>>>> Looks like during the last build
>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Buil=
ders/job/SparkPullRequestBuilder/19797/console>
>>>>>> Jenkins was unable to execute a git fetch=3F
>>>>>>
>>>>>>
>>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp=40berkeley.edu=
>
>>>>>> wrote:
>>>>>>
>>>>>>> i'm going to restart jenkins and see if that fixes things.
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp=40berkeley.ed=
u>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> looking
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>>>>>>> nicholas.chammas=40gmail.com> wrote:
>>>>>>>>
>>>>>>>>> It appears that our main man is having trouble
>>>>>>>>> <https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20B=
uilders/job/SparkPullRequestBuilder/>
>>>>>>>>> hearing new requests
>>>>>>>>> <https://github.com/apache/spark/pull/2277=23issuecomment-54549=
106>.
>>>>>>>>>
>>>>>>>>> Do we need some smelling salts=3F
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp=40berkeley.=
edu>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>>> i'd ping the Jenkinsmench... the master was completely offline=
,
>>>>>>>>>> so any new
>>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued when
>>>>>>>>>> power was
>>>>>>>>>> lost probably started up, but jobs that were running would fai=
l.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>>>>>>>>> nicholas.chammas=40gmail.com
>>>>>>>>>> > wrote:
>>>>>>>>>>
>>>>>>>>>> > Woohoo=21 Thanks Shane.
>>>>>>>>>> >
>>>>>>>>>> > Do you know if queued PR builds will automatically be picked=

>>>>>>>>>> up=3F Or do we
>>>>>>>>>> > have to ping the Jenkinmensch manually from each PR=3F
>>>>>>>>>> >
>>>>>>>>>> > Nick
>>>>>>>>>> >
>>>>>>>>>> >
>>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu> wrote:
>>>>>>>>>> >
>>>>>>>>>> >> AND WE'RE UP=21
>>>>>>>>>> >>
>>>>>>>>>> >> sorry that this took so long... i'll send out a more detail=
ed
>>>>>>>>>> explanation
>>>>>>>>>> >> of what happened soon.
>>>>>>>>>> >>
>>>>>>>>>> >> now, off to back up jenkins.
>>>>>>>>>> >>
>>>>>>>>>> >> shane
>>>>>>>>>> >>
>>>>>>>>>> >>
>>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu> wrote:
>>>>>>>>>> >>
>>>>>>>>>> >> > it's a faulty power switch on the firewall, which has bee=
n
>>>>>>>>>> swapped out.
>>>>>>>>>> >> > we're about to reboot and be good to go.
>>>>>>>>>> >> >
>>>>>>>>>> >> >
>>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >
>>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a=

>>>>>>>>>> replacement.
>>>>>>>>>> >> i
>>>>>>>>>> >> >> don't have more specific information yet -- including
>>>>>>>>>> *what* failed,
>>>>>>>>>> >> as our
>>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an
>>>>>>>>>> incorrect circuit
>>>>>>>>>> >> being
>>>>>>>>>> >> >> switched off during building maintenance.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> on a side note, this incident will be accelerating our p=
lan
>>>>>>>>>> to move the
>>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter=

>>>>>>>>>> environment.
>>>>>>>>>> >> this
>>>>>>>>>> >> >> will be our major push over the next couple of weeks. mo=
re
>>>>>>>>>> details
>>>>>>>>>> >> about
>>>>>>>>>> >> >> this, also, as soon as i get them.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything =
up
>>>>>>>>>> and running
>>>>>>>>>> >> >> ASAP.
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> wrote:
>>>>>>>>>> >> >>
>>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates as=

>>>>>>>>>> they happen.
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>>>>>>>>> sknapp=40berkeley.edu>
>>>>>>>>>> >> >>> wrote:
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks=

>>>>>>>>>> like either
>>>>>>>>>> >> the
>>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down. i'l=
l
>>>>>>>>>> update as
>>>>>>>>>> >> soon as
>>>>>>>>>> >> >>>> i know more.
>>>>>>>>>> >> >>>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>>
>>>>>>>>>> >> >>
>>>>>>>>>> >> >
>>>>>>>>>> >>
>>>>>>>>>> >
>>>>>>>>>> > --
>>>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>>>> Google Groups
>>>>>>>>>> > =22amp-infra=22 group.
>>>>>>>>>> > To unsubscribe from this group and stop receiving emails fro=
m
>>>>>>>>>> it, send an
>>>>>>>>>> > email to amp-infra+unsubscribe=40googlegroups.com.
>>>>>>>>>> > =46or more options, visit https://groups.google.com/d/optout=
.
>>>>>>>>>> >
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--540ce54e_7545e146_112--


From dev-return-9361-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 00:29:57 2014
Return-Path: <dev-return-9361-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CEB1211A74
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 00:29:57 +0000 (UTC)
Received: (qmail 46283 invoked by uid 500); 8 Sep 2014 00:29:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46203 invoked by uid 500); 8 Sep 2014 00:29:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46191 invoked by uid 99); 8 Sep 2014 00:29:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 00:29:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.175 as permitted sender)
Received: from [209.85.212.175] (HELO mail-wi0-f175.google.com) (209.85.212.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 00:29:52 +0000
Received: by mail-wi0-f175.google.com with SMTP id ex7so1637844wid.2
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 17:29:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=uTlm+IGgS1bY/1AP9KtX0JZkYeTjEYNH5LSnxnPUfdE=;
        b=I5rk+KJqFVyc2Tref74gTvE9EOXzRggp5ctnc3zG1Z8qm7WURNjYyiOSJYYTzrkQ8m
         jAURJKHSa+yug2J8URB1uGWN8nSuVmtrZ6ueO+DrUC23Xfu+1bz0FY3OfQBAxbTi7p0m
         YpxOHefSRKqE+cChIEuPerdvPjmt9TH+Zm9ehO9kAITEwfuqaAixysl2XpXOs3KVcA8U
         jJ88Xm4OSIf8mepxG3BZLQRgLAZXEoUWlseTfBob4sA6GprEe3yH7qrVj8rUe0qyKz6N
         /IDxRxw3KoskcUFdCzmGBIb3bBm9M+13AfdhOGhjAFk6SlP4FONQMdhze/NyLV/sUdq6
         2w1A==
X-Received: by 10.180.149.197 with SMTP id uc5mr18219378wib.75.1410136171370;
 Sun, 07 Sep 2014 17:29:31 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sun, 7 Sep 2014 17:28:51 -0700 (PDT)
In-Reply-To: <CAPh_B=bDCGAJXPP_CgiU0NJS1+KmhmX31But57WDqUeJ=buF+Q@mail.gmail.com>
References: <CAOhmDzfyxrC=-xicZEzJK5Sgc6YWjy-qC8ef3GRhgA4cxnVZPA@mail.gmail.com>
 <CAMAsSd+S4ivrj7fjt_SAA0QOF1H1uCs=inrpf73tt4PfYAkPRA@mail.gmail.com>
 <CALte62yeOkn8OzsmUowO8Ou5RyPcdShozGZwnGVvp8mhHyLi3w@mail.gmail.com>
 <CAPh_B=bh+JHqABK2gQVpt155Ec1zzO1qSTH1Bo76tZhQ5vhMCQ@mail.gmail.com> <CAPh_B=bDCGAJXPP_CgiU0NJS1+KmhmX31But57WDqUeJ=buF+Q@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 7 Sep 2014 20:28:51 -0400
Message-ID: <CAOhmDzdLANy8adD4y02isgh5UVDCr4tee_Wz1ecO=gTY4Mr+sw@mail.gmail.com>
Subject: Re: Unit tests in < 5 minutes
To: Reynold Xin <rxin@databricks.com>
Cc: Ted Yu <yuzhihong@gmail.com>, Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3811494603b050282e9f3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3811494603b050282e9f3
Content-Type: text/plain; charset=UTF-8

On Fri, Aug 8, 2014 at 1:12 PM, Reynold Xin <rxin@databricks.com> wrote:

> Nick,
>
> Would you like to file a ticket to track this?
>

SPARK-3431 <https://issues.apache.org/jira/browse/SPARK-3431>: Parallelize
execution of tests
> Sub-task: SPARK-3432 <https://issues.apache.org/jira/browse/SPARK-3432>:
Fix logging of unit test execution time

Nick

--001a11c3811494603b050282e9f3--

From dev-return-9362-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 00:51:23 2014
Return-Path: <dev-return-9362-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 50BC811AA2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 00:51:23 +0000 (UTC)
Received: (qmail 68718 invoked by uid 500); 8 Sep 2014 00:51:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68631 invoked by uid 500); 8 Sep 2014 00:51:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68619 invoked by uid 99); 8 Sep 2014 00:51:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 00:51:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.44 as permitted sender)
Received: from [209.85.219.44] (HELO mail-oa0-f44.google.com) (209.85.219.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 00:51:16 +0000
Received: by mail-oa0-f44.google.com with SMTP id o6so10136694oag.17
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 17:50:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=emRFHtvKl422XnPZWQmprWhoJxV00oF5XNv0ccw0L0g=;
        b=PGNm3gJhxGzo92rGgEXgAxiiGD3/VV97d9hMk+pkUEVPgpU/iaASFCKjXVukXf8Ycu
         /MMIYN/MJuGQb9ji6p1VLCQmeRU54nE6VM6AMlP8tfQKmA29W1GrNau8DxGr3uzAd7+x
         fIyA4IfeHapFDkjgiZKHpfAPW6nGbOH42CMUyp/CuTH9nfkkApogjTB0TsqkRhZw2l2x
         3x+A8ZB9I2ULCeBOeB5WNmuknwfd/g7jogc1aRbXJIbPtIaY5Auzdo0agUQ3BaPpaUyq
         E/6zRJ62/N2ObabUgPsDdcEdaNdnrkxv62aWETmz4EleKLk6Oy9y4EXEOdc+pLu3oeqN
         mBqg==
MIME-Version: 1.0
X-Received: by 10.60.94.208 with SMTP id de16mr28998895oeb.0.1410137456114;
 Sun, 07 Sep 2014 17:50:56 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Sun, 7 Sep 2014 17:50:56 -0700 (PDT)
Date: Sun, 7 Sep 2014 17:50:56 -0700
Message-ID: <CABPQxstrKkVRP5rgw0gYvW459QW1i1JeNn5dYQCCJXmD2UTiNQ@mail.gmail.com>
Subject: [RESULT] [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

This vote passes with 8 binding +1 votes and no -1 votes. I'll post
the final release in the next 48 hours... just finishing the release
notes and packaging (which now takes a long time given the number of
contributors!).

+1:
Reynold Xin*
Michael Armbrust*
Xiangrui Meng*
Andrew Or*
Sean Owen
Matthew Farrellee
Marcelo Vanzin
Josh Rosen*
Cheng Lian
Mubarak Seyed
Matei Zaharia*
Nan Zhu
Jeremy Freeman
Denny Lee
Tom Graves*
Henry Saputra
Egor Pahomov
Rohit Sinha
Kan Zhang
Tathagata Das*
Reza Zadeh

-1:

0:

* = binding

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9363-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 05:09:17 2014
Return-Path: <dev-return-9363-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A05511E69
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 05:09:16 +0000 (UTC)
Received: (qmail 60644 invoked by uid 500); 8 Sep 2014 05:09:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60564 invoked by uid 500); 8 Sep 2014 05:09:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60552 invoked by uid 99); 8 Sep 2014 05:09:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 05:09:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 209.85.220.182 as permitted sender)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 05:08:47 +0000
Received: by mail-vc0-f182.google.com with SMTP id le20so909960vcb.27
        for <dev@spark.apache.org>; Sun, 07 Sep 2014 22:08:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=75doDxtbHY2ca9przKlVmLP1sdlZ3R3hVUtL9ky4Icc=;
        b=OeyMaXfQ4ixy2kmB9xpaVwMs5FYlaQDBKSEAf1oPHUxNJOeRMo0MnCy42IYoSf5iV1
         cbBr3tbMbG6LDawbniDPFpsxDpG6GDvIRJqQnqg1SUCsdUfDwFwvHa6BJdNTPg3M5BoC
         1nSOSfjr+JCRtsYh8QjcV9x22KFrl2Adymq7qsUA9FCgqTwR6DrLLVGBQxfTDn40o3Rd
         UMUDE/gn7jv39bm394Jm/aASN83fZL18TpXr44tXmPjkTNo31buQGuX6pWyD95R+7e3C
         vk/uk5W9+gKr8XJdS5oc91Vgb7UH3dBvAGfTUh0R37JIDMICDVgfx60NW3ltidrjffkc
         TK1w==
X-Received: by 10.220.184.70 with SMTP id cj6mr23579557vcb.5.1410152925794;
 Sun, 07 Sep 2014 22:08:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.220.211 with HTTP; Sun, 7 Sep 2014 22:08:25 -0700 (PDT)
In-Reply-To: <etPan.540ce54e.79e2a9e3.112@joshs-mbp.att.net>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
 <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
 <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
 <etPan.540a5a1b.238e1f29.112@joshs-mbp> <etPan.540b6509.3d1b58ba.112@joshs-mbp>
 <etPan.540ce54e.79e2a9e3.112@joshs-mbp.att.net>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Mon, 8 Sep 2014 10:38:25 +0530
Message-ID: <CAOYDGoDLwrrJmXAjap005hRPUrDKwqwWYXs=GLoYsYS7wigNnQ@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Josh Rosen <rosenville@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, Nicholas Chammas <nicholas.chammas@gmail.com>, 
	dev <dev@spark.apache.org>, Mike Patterson <mike@databricks.com>, 
	Matthew L Massie <massie@cs.berkeley.edu>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=089e0141a4403898e0050286d05e
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0141a4403898e0050286d05e
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Looks like this is already taken care of ?

Prashant Sharma



On Mon, Sep 8, 2014 at 4:37 AM, Josh Rosen <rosenville@gmail.com> wrote:

> Does anyone know why some of the MiMa tests have started failing?
>
> See
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19948/=
consoleFull for
> an example.
>
> On September 6, 2014 at 12:48:27 PM, Josh Rosen (rosenville@gmail.com)
> wrote:
>
> It looks like Jenkins is up and running, but there seems to be a delay in
> responding to requests to re-test patches.  It seems like Jenkins is
> promptly testing new PRs, or new commits as they=E2=80=99re added to exis=
ting PRs,
> but taking a very long time to respond to requests to re-test PRs.
>
> I=E2=80=99m going to continue monitoring this today.  I=E2=80=99m conside=
ring creating my
> own fork of the Jenkins pull request builder plugin so that we can add
> extra logging in order to diagnose what=E2=80=99s causing this lag.
>
> - Josh
> On September 5, 2014 at 5:49:32 PM, Josh Rosen (rosenville@gmail.com)
> wrote:
>
> We have successfully purged Jenkins=E2=80=99 build queue.  If you want a =
PR to be
> re-tested, please ask Jenkins again.
>
> On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp@berkeley.edu)
> wrote:
>
> yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new key,
> and magique!
>
> we're about to clear the queue of all builds as most aren't wanted/needed=
.
>
>
> On Fri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > Looks like Jenkins is back!
> >
> > lol The poor guy has like a million builds
> > <
> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job=
/SparkPullRequestBuilder/
> >
> > to catch up on.
> >
> >
> > On Fri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
> > nicholas.chammas@gmail.com> wrote:
> >
> >> How's it going?
> >>
> >> It looks like during the last build
> >> <
> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job=
/SparkPullRequestBuilder/lastBuild/console
> >
> >> from about 30 min ago Jenkins was still having trouble fetching from
> >> GitHub. It also looks like not all requests for testing are triggering
> >> builds.
> >>
> >>
> >> On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>
> >>> it's looking like everything except the pull request builders are
> >>> working. i'm going to be working on getting this resolved today.
> >>>
> >>>
> >>> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
> >>> nicholas.chammas@gmail.com> wrote:
> >>>
> >>>> Hmm, looks like at least some builds
> >>>> <
> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job=
/SparkPullRequestBuilder/19804/consoleFull
> >
> >>>> are working now, though this last one was from ~5 hours ago.
> >>>>
> >>>>
> >>>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu>
> >>>> wrote:
> >>>>
> >>>>> yep. that's exactly the behavior i saw earlier, and will be figurin=
g
> >>>>> out first thing tomorrow morning. i bet it's an environment issues
> on the
> >>>>> slaves.
> >>>>>
> >>>>>
> >>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
> >>>>> nicholas.chammas@gmail.com> wrote:
> >>>>>
> >>>>>> Looks like during the last build
> >>>>>> <
> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job=
/SparkPullRequestBuilder/19797/console
> >
> >>>>>> Jenkins was unable to execute a git fetch?
> >>>>>>
> >>>>>>
> >>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> i'm going to restart jenkins and see if that fixes things.
> >>>>>>>
> >>>>>>>
> >>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> looking
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
> >>>>>>>> nicholas.chammas@gmail.com> wrote:
> >>>>>>>>
> >>>>>>>>> It appears that our main man is having trouble
> >>>>>>>>> <
> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/job=
/SparkPullRequestBuilder/
> >
> >>>>>>>>> hearing new requests
> >>>>>>>>> <https://github.com/apache/spark/pull/2277#issuecomment-5454910=
6
> >.
> >>>>>>>>>
> >>>>>>>>> Do we need some smelling salts?
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <sknapp@berkeley.ed=
u
> >
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>>> i'd ping the Jenkinsmench... the master was completely offline=
,
> >>>>>>>>>> so any new
> >>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued when
> >>>>>>>>>> power was
> >>>>>>>>>> lost probably started up, but jobs that were running would fai=
l.
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
> >>>>>>>>>> nicholas.chammas@gmail.com
> >>>>>>>>>> > wrote:
> >>>>>>>>>>
> >>>>>>>>>> > Woohoo! Thanks Shane.
> >>>>>>>>>> >
> >>>>>>>>>> > Do you know if queued PR builds will automatically be picked
> >>>>>>>>>> up? Or do we
> >>>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
> >>>>>>>>>> >
> >>>>>>>>>> > Nick
> >>>>>>>>>> >
> >>>>>>>>>> >
> >>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
> >>>>>>>>>> sknapp@berkeley.edu> wrote:
> >>>>>>>>>> >
> >>>>>>>>>> >> AND WE'RE UP!
> >>>>>>>>>> >>
> >>>>>>>>>> >> sorry that this took so long... i'll send out a more detail=
ed
> >>>>>>>>>> explanation
> >>>>>>>>>> >> of what happened soon.
> >>>>>>>>>> >>
> >>>>>>>>>> >> now, off to back up jenkins.
> >>>>>>>>>> >>
> >>>>>>>>>> >> shane
> >>>>>>>>>> >>
> >>>>>>>>>> >>
> >>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
> >>>>>>>>>> sknapp@berkeley.edu> wrote:
> >>>>>>>>>> >>
> >>>>>>>>>> >> > it's a faulty power switch on the firewall, which has bee=
n
> >>>>>>>>>> swapped out.
> >>>>>>>>>> >> > we're about to reboot and be good to go.
> >>>>>>>>>> >> >
> >>>>>>>>>> >> >
> >>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
> >>>>>>>>>> sknapp@berkeley.edu>
> >>>>>>>>>> >> wrote:
> >>>>>>>>>> >> >
> >>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in a
> >>>>>>>>>> replacement.
> >>>>>>>>>> >> i
> >>>>>>>>>> >> >> don't have more specific information yet -- including
> >>>>>>>>>> *what* failed,
> >>>>>>>>>> >> as our
> >>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an
> >>>>>>>>>> incorrect circuit
> >>>>>>>>>> >> being
> >>>>>>>>>> >> >> switched off during building maintenance.
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >> on a side note, this incident will be accelerating our
> plan
> >>>>>>>>>> to move the
> >>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacenter
> >>>>>>>>>> environment.
> >>>>>>>>>> >> this
> >>>>>>>>>> >> >> will be our major push over the next couple of weeks. mo=
re
> >>>>>>>>>> details
> >>>>>>>>>> >> about
> >>>>>>>>>> >> >> this, also, as soon as i get them.
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything =
up
> >>>>>>>>>> and running
> >>>>>>>>>> >> >> ASAP.
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
> >>>>>>>>>> sknapp@berkeley.edu>
> >>>>>>>>>> >> wrote:
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates as
> >>>>>>>>>> they happen.
> >>>>>>>>>> >> >>>
> >>>>>>>>>> >> >>>
> >>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
> >>>>>>>>>> sknapp@berkeley.edu>
> >>>>>>>>>> >> >>> wrote:
> >>>>>>>>>> >> >>>
> >>>>>>>>>> >> >>>> i am trying to get things up and running, but it looks
> >>>>>>>>>> like either
> >>>>>>>>>> >> the
> >>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down. i'l=
l
> >>>>>>>>>> update as
> >>>>>>>>>> >> soon as
> >>>>>>>>>> >> >>>> i know more.
> >>>>>>>>>> >> >>>>
> >>>>>>>>>> >> >>>
> >>>>>>>>>> >> >>>
> >>>>>>>>>> >> >>
> >>>>>>>>>> >> >
> >>>>>>>>>> >>
> >>>>>>>>>> >
> >>>>>>>>>> > --
> >>>>>>>>>> > You received this message because you are subscribed to the
> >>>>>>>>>> Google Groups
> >>>>>>>>>> > "amp-infra" group.
> >>>>>>>>>> > To unsubscribe from this group and stop receiving emails fro=
m
> >>>>>>>>>> it, send an
> >>>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
> >>>>>>>>>> > For more options, visit https://groups.google.com/d/optout.
> >>>>>>>>>> >
> >>>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>
> >>>>
> >>>
> >>
> >
>

--089e0141a4403898e0050286d05e--

From dev-return-9364-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 07:31:34 2014
Return-Path: <dev-return-9364-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3472011083
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 07:31:34 +0000 (UTC)
Received: (qmail 2994 invoked by uid 500); 8 Sep 2014 07:31:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2925 invoked by uid 500); 8 Sep 2014 07:31:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2908 invoked by uid 99); 8 Sep 2014 07:31:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 07:31:33 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.173 as permitted sender)
Received: from [209.85.213.173] (HELO mail-ig0-f173.google.com) (209.85.213.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 07:31:28 +0000
Received: by mail-ig0-f173.google.com with SMTP id h18so2279072igc.6
        for <dev@spark.incubator.apache.org>; Mon, 08 Sep 2014 00:31:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IsyFCEbmGx0qAv+5s0Y+9CYCtgR1DkstgXcZhWUQuVY=;
        b=VGpwtdSBNwnBfCwEaiPGq7ksOLardndVBPkjvN1spH7AHhkhDltJMFsfeSnhgpgLmo
         5jZ8HA2236UXnij8z4lPgsxbQUmWv2+/8G0FxeVDAXUdLkq3+RVGl+JLZn1ZNdm8zj5B
         kbBbglb81coE0j0q9+Xo18XZfuoA8ZRr+I7GuDebkkmsutqjH5rYKWyKwcc7IkkzJCKo
         lx//ChXb/a/+X36iZPJwJaEUr2wNsQ9bpgNKupUJ7TtikNMJcDrZtmMPT5Na3GCIKMse
         NWmZ1/OD1I9qrX/RwXWTgL4vsCI8F8fCXYMYezQ6tXiVZDutvG8ReSiu8iSOhDFkoPnF
         0SfQ==
MIME-Version: 1.0
X-Received: by 10.50.143.101 with SMTP id sd5mr22118127igb.18.1410161468374;
 Mon, 08 Sep 2014 00:31:08 -0700 (PDT)
Received: by 10.107.152.196 with HTTP; Mon, 8 Sep 2014 00:31:08 -0700 (PDT)
In-Reply-To: <1409992086513-8310.post@n3.nabble.com>
References: <1409909219731-8291.post@n3.nabble.com>
	<CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
	<1409930280353-8293.post@n3.nabble.com>
	<CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
	<1409933903848-8296.post@n3.nabble.com>
	<CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
	<EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
	<CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com>
	<1409992086513-8310.post@n3.nabble.com>
Date: Mon, 8 Sep 2014 00:31:08 -0700
Message-ID: <CAJgQjQ9+QGNkWMpVnetHf-Oc8T89_XqPpF0myM5whm4oNCuEAw@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: Xiangrui Meng <mengxr@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: dev <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Sorry for my late reply! I'm also very interested in the
implementation of distributed matrix multiplication. As Shivaram
mentioned, the communication is the concern here. But maybe we can
start with a reasonable implementation and then iterate on its
performance. It would be great if eventually we can implement an
algorithm close to the 2.5D algorithm
(http://www.netlib.org/lapack/lawnspdf/lawn248.pdf).

I created two JIRAs for this topic:

1. Distributed block matrix: https://issues.apache.org/jira/browse/SPARK-3434
2. Distributed matrix multiplication:
https://issues.apache.org/jira/browse/SPARK-3435

We can move our discussion there.

Rong, I'm really happy to see the Saury project. It would be great if
you can share your design and experience (maybe on the JIRA page so it
is easier to track). I will read the reports on CSDN and ping you if I
ran into problems. Thanks!

Best,
Xiangrui

On Sat, Sep 6, 2014 at 1:28 AM, Yu Ishikawa
<yuu.ishikawa+spark@gmail.com> wrote:
> Hi Rong,
>
> Great job! Thank you for let me know your work.
> I will read the source code of saury later.
>
> Although AMPLab is working to implement them, would you like to merge it
> into Spark?
>
> Best,
>
> -- Yu Ishikawa
>
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8310.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9365-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 07:42:11 2014
Return-Path: <dev-return-9365-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 41263110B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 07:42:11 +0000 (UTC)
Received: (qmail 18988 invoked by uid 500); 8 Sep 2014 07:42:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18922 invoked by uid 500); 8 Sep 2014 07:42:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18911 invoked by uid 99); 8 Sep 2014 07:42:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 07:42:10 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 07:42:05 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XQta4-0007Ca-VX
	for dev@spark.incubator.apache.org; Mon, 08 Sep 2014 00:41:44 -0700
Date: Mon, 8 Sep 2014 00:41:44 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1410162104968-8333.post@n3.nabble.com>
In-Reply-To: <CAJgQjQ9+QGNkWMpVnetHf-Oc8T89_XqPpF0myM5whm4oNCuEAw@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com> <CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com> <1409930280353-8293.post@n3.nabble.com> <CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com> <1409933903848-8296.post@n3.nabble.com> <CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com> <EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com> <CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com> <1409992086513-8310.post@n3.nabble.com> <CAJgQjQ9+QGNkWMpVnetHf-Oc8T89_XqPpF0myM5whm4oNCuEAw@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Xiangrui Meng,

Thank you for your comment and creating tickets.

The ticket which I created would be moved to your tickets.
I will close my ticket, and then will link it to yours later.

Best,
Yu Ishikawa



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8333.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9366-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 08:13:52 2014
Return-Path: <dev-return-9366-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6674D11154
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 08:13:52 +0000 (UTC)
Received: (qmail 58723 invoked by uid 500); 8 Sep 2014 08:13:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58650 invoked by uid 500); 8 Sep 2014 08:13:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58638 invoked by uid 99); 8 Sep 2014 08:13:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 08:13:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 08:13:31 +0000
Received: by mail-pd0-f169.google.com with SMTP id fp1so685572pdb.28
        for <dev@spark.apache.org>; Mon, 08 Sep 2014 01:13:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=xbgxsRQWs3otWRDN6TSl3YnPnCs5Q4Fl+YosetcX2j4=;
        b=uZ89bbwzepkQjImBCQlpnRNigt4hD5HO3dY7nPC4tmD/Tdh6cV0mWr+1TjX1FouzEI
         LyRlychcEOusi9+3uFqfY0ORzLIEq4t4Jrcon2cJtdJjnx0jISNqN+e6BOe6IWHYnkEy
         mxmgUlzbsWND6AW2gWRDLSMHtYeyKTnSyEs9pCiWyX3rcPNlgG0itbuUajsn94g22yOH
         nPugEvZUow/HFOeUOW0fEVh+sl+mfao/kW7QavOhM0TZ0N9QmaLTaBJEx8nKTBxb7NXs
         8ySyuGd8nd09S2x0mtSf3epjzzv1kpx8o3pxlHcryY/67mxNd/BDcccixcpAF2OmEYHl
         ACyw==
MIME-Version: 1.0
X-Received: by 10.68.194.66 with SMTP id hu2mr18449254pbc.19.1410163990823;
 Mon, 08 Sep 2014 01:13:10 -0700 (PDT)
Received: by 10.70.73.233 with HTTP; Mon, 8 Sep 2014 01:13:10 -0700 (PDT)
In-Reply-To: <CAOYDGoDLwrrJmXAjap005hRPUrDKwqwWYXs=GLoYsYS7wigNnQ@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
	<CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
	<CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
	<CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
	<CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
	<CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
	<CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
	<CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
	<CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
	<CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
	<CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
	<CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
	<CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
	<CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
	<CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
	<CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
	<CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
	<etPan.540a5a1b.238e1f29.112@joshs-mbp>
	<etPan.540b6509.3d1b58ba.112@joshs-mbp>
	<etPan.540ce54e.79e2a9e3.112@joshs-mbp.att.net>
	<CAOYDGoDLwrrJmXAjap005hRPUrDKwqwWYXs=GLoYsYS7wigNnQ@mail.gmail.com>
Date: Mon, 8 Sep 2014 01:13:10 -0700
Message-ID: <CAOEPXP7xsbvrZfwbpsQZgQC=CGjfa9snsb60dLQ+jZQnxyqPeg@mail.gmail.com>
Subject: Re: amplab jenkins is down
From: Josh Rosen <rosenville@gmail.com>
To: Prashant Sharma <scrapcodes@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, Nicholas Chammas <nicholas.chammas@gmail.com>, 
	dev <dev@spark.apache.org>, Mike Patterson <mike@databricks.com>, 
	Matthew L Massie <massie@cs.berkeley.edu>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7b15aa23bf8ab805028963d8
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b15aa23bf8ab805028963d8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Yeah, I think https://github.com/apache/spark/pull/2315 should have fixed
the Mima issue.  We're still seeing some intermittent failures due to
DriverSuite and SparkSubmitSuite tests failing, so I'd appreciate any help
in diagnosing that issue.

On Sun, Sep 7, 2014 at 10:08 PM, Prashant Sharma <scrapcodes@gmail.com>
wrote:

> Looks like this is already taken care of ?
>
> Prashant Sharma
>
>
>
> On Mon, Sep 8, 2014 at 4:37 AM, Josh Rosen <rosenville@gmail.com> wrote:
>
>> Does anyone know why some of the MiMa tests have started failing?
>>
>> See
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/19948=
/consoleFull for
>> an example.
>>
>> On September 6, 2014 at 12:48:27 PM, Josh Rosen (rosenville@gmail.com)
>> wrote:
>>
>> It looks like Jenkins is up and running, but there seems to be a delay i=
n
>> responding to requests to re-test patches.  It seems like Jenkins is
>> promptly testing new PRs, or new commits as they=E2=80=99re added to exi=
sting PRs,
>> but taking a very long time to respond to requests to re-test PRs.
>>
>> I=E2=80=99m going to continue monitoring this today.  I=E2=80=99m consid=
ering creating my
>> own fork of the Jenkins pull request builder plugin so that we can add
>> extra logging in order to diagnose what=E2=80=99s causing this lag.
>>
>> - Josh
>> On September 5, 2014 at 5:49:32 PM, Josh Rosen (rosenville@gmail.com)
>> wrote:
>>
>> We have successfully purged Jenkins=E2=80=99 build queue.  If you want a=
 PR to be
>> re-tested, please ask Jenkins again.
>>
>> On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp@berkeley.edu)
>> wrote:
>>
>> yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new key=
,
>> and magique!
>>
>> we're about to clear the queue of all builds as most aren't wanted/neede=
d.
>>
>>
>> On Fri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com
>> > wrote:
>>
>> > Looks like Jenkins is back!
>> >
>> > lol The poor guy has like a million builds
>> > <
>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/jo=
b/SparkPullRequestBuilder/
>> >
>> > to catch up on.
>> >
>> >
>> > On Fri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
>> > nicholas.chammas@gmail.com> wrote:
>> >
>> >> How's it going?
>> >>
>> >> It looks like during the last build
>> >> <
>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/jo=
b/SparkPullRequestBuilder/lastBuild/console
>> >
>> >> from about 30 min ago Jenkins was still having trouble fetching from
>> >> GitHub. It also looks like not all requests for testing are triggerin=
g
>> >> builds.
>> >>
>> >>
>> >> On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >>
>> >>> it's looking like everything except the pull request builders are
>> >>> working. i'm going to be working on getting this resolved today.
>> >>>
>> >>>
>> >>> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>> >>> nicholas.chammas@gmail.com> wrote:
>> >>>
>> >>>> Hmm, looks like at least some builds
>> >>>> <
>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/jo=
b/SparkPullRequestBuilder/19804/consoleFull
>> >
>> >>>> are working now, though this last one was from ~5 hours ago.
>> >>>>
>> >>>>
>> >>>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu>
>> >>>> wrote:
>> >>>>
>> >>>>> yep. that's exactly the behavior i saw earlier, and will be figuri=
ng
>> >>>>> out first thing tomorrow morning. i bet it's an environment issues
>> on the
>> >>>>> slaves.
>> >>>>>
>> >>>>>
>> >>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>> >>>>> nicholas.chammas@gmail.com> wrote:
>> >>>>>
>> >>>>>> Looks like during the last build
>> >>>>>> <
>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/jo=
b/SparkPullRequestBuilder/19797/console
>> >
>> >>>>>> Jenkins was unable to execute a git fetch?
>> >>>>>>
>> >>>>>>
>> >>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu>
>> >>>>>> wrote:
>> >>>>>>
>> >>>>>>> i'm going to restart jenkins and see if that fixes things.
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.edu=
>
>> >>>>>>> wrote:
>> >>>>>>>
>> >>>>>>>> looking
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>> >>>>>>>> nicholas.chammas@gmail.com> wrote:
>> >>>>>>>>
>> >>>>>>>>> It appears that our main man is having trouble
>> >>>>>>>>> <
>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/jo=
b/SparkPullRequestBuilder/
>> >
>> >>>>>>>>> hearing new requests
>> >>>>>>>>> <
>> https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>> >>>>>>>>>
>> >>>>>>>>> Do we need some smelling salts?
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <
>> sknapp@berkeley.edu>
>> >>>>>>>>> wrote:
>> >>>>>>>>>
>> >>>>>>>>>> i'd ping the Jenkinsmench... the master was completely offlin=
e,
>> >>>>>>>>>> so any new
>> >>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued when
>> >>>>>>>>>> power was
>> >>>>>>>>>> lost probably started up, but jobs that were running would
>> fail.
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>> >>>>>>>>>> nicholas.chammas@gmail.com
>> >>>>>>>>>> > wrote:
>> >>>>>>>>>>
>> >>>>>>>>>> > Woohoo! Thanks Shane.
>> >>>>>>>>>> >
>> >>>>>>>>>> > Do you know if queued PR builds will automatically be picke=
d
>> >>>>>>>>>> up? Or do we
>> >>>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>> >>>>>>>>>> >
>> >>>>>>>>>> > Nick
>> >>>>>>>>>> >
>> >>>>>>>>>> >
>> >>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
>> >>>>>>>>>> sknapp@berkeley.edu> wrote:
>> >>>>>>>>>> >
>> >>>>>>>>>> >> AND WE'RE UP!
>> >>>>>>>>>> >>
>> >>>>>>>>>> >> sorry that this took so long... i'll send out a more
>> detailed
>> >>>>>>>>>> explanation
>> >>>>>>>>>> >> of what happened soon.
>> >>>>>>>>>> >>
>> >>>>>>>>>> >> now, off to back up jenkins.
>> >>>>>>>>>> >>
>> >>>>>>>>>> >> shane
>> >>>>>>>>>> >>
>> >>>>>>>>>> >>
>> >>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>> >>>>>>>>>> sknapp@berkeley.edu> wrote:
>> >>>>>>>>>> >>
>> >>>>>>>>>> >> > it's a faulty power switch on the firewall, which has be=
en
>> >>>>>>>>>> swapped out.
>> >>>>>>>>>> >> > we're about to reboot and be good to go.
>> >>>>>>>>>> >> >
>> >>>>>>>>>> >> >
>> >>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>> >>>>>>>>>> sknapp@berkeley.edu>
>> >>>>>>>>>> >> wrote:
>> >>>>>>>>>> >> >
>> >>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in =
a
>> >>>>>>>>>> replacement.
>> >>>>>>>>>> >> i
>> >>>>>>>>>> >> >> don't have more specific information yet -- including
>> >>>>>>>>>> *what* failed,
>> >>>>>>>>>> >> as our
>> >>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an
>> >>>>>>>>>> incorrect circuit
>> >>>>>>>>>> >> being
>> >>>>>>>>>> >> >> switched off during building maintenance.
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >> on a side note, this incident will be accelerating our
>> plan
>> >>>>>>>>>> to move the
>> >>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacente=
r
>> >>>>>>>>>> environment.
>> >>>>>>>>>> >> this
>> >>>>>>>>>> >> >> will be our major push over the next couple of weeks.
>> more
>> >>>>>>>>>> details
>> >>>>>>>>>> >> about
>> >>>>>>>>>> >> >> this, also, as soon as i get them.
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everything
>> up
>> >>>>>>>>>> and running
>> >>>>>>>>>> >> >> ASAP.
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>> >>>>>>>>>> sknapp@berkeley.edu>
>> >>>>>>>>>> >> wrote:
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates a=
s
>> >>>>>>>>>> they happen.
>> >>>>>>>>>> >> >>>
>> >>>>>>>>>> >> >>>
>> >>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>> >>>>>>>>>> sknapp@berkeley.edu>
>> >>>>>>>>>> >> >>> wrote:
>> >>>>>>>>>> >> >>>
>> >>>>>>>>>> >> >>>> i am trying to get things up and running, but it look=
s
>> >>>>>>>>>> like either
>> >>>>>>>>>> >> the
>> >>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down. i'=
ll
>> >>>>>>>>>> update as
>> >>>>>>>>>> >> soon as
>> >>>>>>>>>> >> >>>> i know more.
>> >>>>>>>>>> >> >>>>
>> >>>>>>>>>> >> >>>
>> >>>>>>>>>> >> >>>
>> >>>>>>>>>> >> >>
>> >>>>>>>>>> >> >
>> >>>>>>>>>> >>
>> >>>>>>>>>> >
>> >>>>>>>>>> > --
>> >>>>>>>>>> > You received this message because you are subscribed to the
>> >>>>>>>>>> Google Groups
>> >>>>>>>>>> > "amp-infra" group.
>> >>>>>>>>>> > To unsubscribe from this group and stop receiving emails fr=
om
>> >>>>>>>>>> it, send an
>> >>>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>> >>>>>>>>>> > For more options, visit https://groups.google.com/d/optout.
>> >>>>>>>>>> >
>> >>>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>
>> >>>>>>>
>> >>>>>>
>> >>>>>
>> >>>>
>> >>>
>> >>
>> >
>>
>
>

--047d7b15aa23bf8ab805028963d8--

From dev-return-9367-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep  8 15:42:32 2014
Return-Path: <dev-return-9367-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EB35211C18
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  8 Sep 2014 15:42:31 +0000 (UTC)
Received: (qmail 23179 invoked by uid 500); 8 Sep 2014 15:42:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23108 invoked by uid 500); 8 Sep 2014 15:42:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23095 invoked by uid 99); 8 Sep 2014 15:42:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 15:42:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 08 Sep 2014 15:42:27 +0000
Received: by mail-lb0-f180.google.com with SMTP id b12so354703lbj.39
        for <dev@spark.apache.org>; Mon, 08 Sep 2014 08:42:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=v26NiThU6j1CHg1lzJlwG8iOEsisbjWH9hk4QpWA/kQ=;
        b=mLD8PySeHXrQNMu+zdOWJrroIN/nh1Kecb+At6+dFjZ4P1rYHkqFHtRj7nhVsLQ4n0
         7t86bRN27zsoxTYm8QFpK6oN0R6nTmb/qtKsaLG2f20o67EHT5qURWpzKcUMsWRG1Ajj
         Ftlt4OVRdwq+/zOElIjybk8efbejQxYYec+mUcMMhfWrwAI9LY28dtlJCaZxcCOUnA3F
         1zSwfe4ZLQCC4cAfbKpOxNBhutm2K6CQZAh+zW5vQyGUnmMMAtP+w7kQSo4/C7LmqevR
         UALbYX2VsuDAiNQCkMgaR90o1FoE0zuhrgr6FQ8kQcMZwX84jqHaq/yj/ZwkGcd+/Fuw
         gBWQ==
X-Gm-Message-State: ALoCoQlozioxi7/cM12YSEPqEq9Bn9Jq+O6rYaOK6WgPW2rX1y9cyRcbioEITHjaaPQRVNnjyL7S
X-Received: by 10.112.105.168 with SMTP id gn8mr28053761lbb.77.1410190924276;
 Mon, 08 Sep 2014 08:42:04 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Mon, 8 Sep 2014 08:41:43 -0700 (PDT)
In-Reply-To: <CAOEPXP7xsbvrZfwbpsQZgQC=CGjfa9snsb60dLQ+jZQnxyqPeg@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CACdU-dQ-5i5e0C_LRnvsE-rviWWox2HZtETDjWQy2yo+BVhPAA@mail.gmail.com>
 <CACdU-dQrAvddE3c3GZu2b-ggmJhjhTmnTpg4o=Gs+i6NtGEZYg@mail.gmail.com>
 <CAOhmDzcXFzURW0aKwjUUKvCoTTTWmAMEwHgdbtK-12jxL+me6Q@mail.gmail.com>
 <CACdU-dScGWdtmawaQBhjyYpsc7g-23nj-SzARCx3S_9u0DDGUw@mail.gmail.com>
 <CAOhmDze3Q4cebi4x0EdX1hyik80j4+W_fxe_44x=B8vdTpQN6Q@mail.gmail.com>
 <CACdU-dQjNcLc8LpHL58JXW2sPad6TTNfev5VfnZ=ggr+zOirmg@mail.gmail.com>
 <CACdU-dTvOma3omPecYOor-gm8qr2zUw_qissqWdCUkw6SnDu_w@mail.gmail.com>
 <CAOhmDzf=0cmhg6Ks+SNcWLO9u6tduT21DT3i=N01JgOkueazog@mail.gmail.com>
 <CACdU-dQSUUkmJtKiXvVCgt=sk4u6TNWC30ABJHboLk4E_4cnsA@mail.gmail.com>
 <CAOhmDzc2RkC+HBLSAC0KNXj768YD0_qLRPsU7K-hX+nvaErk6g@mail.gmail.com>
 <CACdU-dTeRuBPqhYrqgwRdjX1VGx5dOeoO8bnVBUSU9_rsNL=Mg@mail.gmail.com>
 <CAOhmDzebLzHRyK6zwN5Jcr+_UG9DBJfNoCGVZQwppQ=QnZ_cAA@mail.gmail.com>
 <CAOhmDzfj+4c2jxHr3FPp=gpZU0d-4VygoBQ8TNMpGWvt-9Ojtg@mail.gmail.com>
 <CACdU-dRODjfRfNfa-mxGF7jJqHvHiFN6EEO=M2vX=wkZtZ4_Ww@mail.gmail.com>
 <etPan.540a5a1b.238e1f29.112@joshs-mbp> <etPan.540b6509.3d1b58ba.112@joshs-mbp>
 <etPan.540ce54e.79e2a9e3.112@joshs-mbp.att.net> <CAOYDGoDLwrrJmXAjap005hRPUrDKwqwWYXs=GLoYsYS7wigNnQ@mail.gmail.com>
 <CAOEPXP7xsbvrZfwbpsQZgQC=CGjfa9snsb60dLQ+jZQnxyqPeg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 8 Sep 2014 08:41:43 -0700
Message-ID: <CACdU-dQyb9sEpkG_USFPDkCHfLYakNGU5ZopR9h+EA9-ih6_Lw@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Josh Rosen <rosenville@gmail.com>
Cc: Prashant Sharma <scrapcodes@gmail.com>, Nicholas Chammas <nicholas.chammas@gmail.com>, 
	dev <dev@spark.apache.org>, Mike Patterson <mike@databricks.com>, 
	Matthew L Massie <massie@cs.berkeley.edu>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11345e221ba52905028fa996
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11345e221ba52905028fa996
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

i'll take a look at this today.


On Mon, Sep 8, 2014 at 1:13 AM, Josh Rosen <rosenville@gmail.com> wrote:

> Yeah, I think https://github.com/apache/spark/pull/2315 should have fixed
> the Mima issue.  We're still seeing some intermittent failures due to
> DriverSuite and SparkSubmitSuite tests failing, so I'd appreciate any hel=
p
> in diagnosing that issue.
>
> On Sun, Sep 7, 2014 at 10:08 PM, Prashant Sharma <scrapcodes@gmail.com>
> wrote:
>
>> Looks like this is already taken care of ?
>>
>> Prashant Sharma
>>
>>
>>
>> On Mon, Sep 8, 2014 at 4:37 AM, Josh Rosen <rosenville@gmail.com> wrote:
>>
>>> Does anyone know why some of the MiMa tests have started failing?
>>>
>>> See
>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/1994=
8/consoleFull for
>>> an example.
>>>
>>> On September 6, 2014 at 12:48:27 PM, Josh Rosen (rosenville@gmail.com)
>>> wrote:
>>>
>>> It looks like Jenkins is up and running, but there seems to be a delay
>>> in responding to requests to re-test patches.  It seems like Jenkins is
>>> promptly testing new PRs, or new commits as they=E2=80=99re added to ex=
isting PRs,
>>> but taking a very long time to respond to requests to re-test PRs.
>>>
>>> I=E2=80=99m going to continue monitoring this today.  I=E2=80=99m consi=
dering creating
>>> my own fork of the Jenkins pull request builder plugin so that we can a=
dd
>>> extra logging in order to diagnose what=E2=80=99s causing this lag.
>>>
>>> - Josh
>>> On September 5, 2014 at 5:49:32 PM, Josh Rosen (rosenville@gmail.com)
>>> wrote:
>>>
>>> We have successfully purged Jenkins=E2=80=99 build queue.  If you want =
a PR to
>>> be re-tested, please ask Jenkins again.
>>>
>>> On September 5, 2014 at 5:36:30 PM, shane knapp (sknapp@berkeley.edu)
>>> wrote:
>>>
>>> yeah, it was a problem w/the PRB's OAuth key. josh rosen added a new ke=
y,
>>> and magique!
>>>
>>> we're about to clear the queue of all builds as most aren't
>>> wanted/needed.
>>>
>>>
>>> On Fri, Sep 5, 2014 at 5:33 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com
>>> > wrote:
>>>
>>> > Looks like Jenkins is back!
>>> >
>>> > lol The poor guy has like a million builds
>>> > <
>>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/j=
ob/SparkPullRequestBuilder/
>>> >
>>> > to catch up on.
>>> >
>>> >
>>> > On Fri, Sep 5, 2014 at 4:15 PM, Nicholas Chammas <
>>> > nicholas.chammas@gmail.com> wrote:
>>> >
>>> >> How's it going?
>>> >>
>>> >> It looks like during the last build
>>> >> <
>>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/j=
ob/SparkPullRequestBuilder/lastBuild/console
>>> >
>>> >> from about 30 min ago Jenkins was still having trouble fetching from
>>> >> GitHub. It also looks like not all requests for testing are triggeri=
ng
>>> >> builds.
>>> >>
>>> >>
>>> >> On Fri, Sep 5, 2014 at 1:23 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>> >>
>>> >>> it's looking like everything except the pull request builders are
>>> >>> working. i'm going to be working on getting this resolved today.
>>> >>>
>>> >>>
>>> >>> On Fri, Sep 5, 2014 at 8:18 AM, Nicholas Chammas <
>>> >>> nicholas.chammas@gmail.com> wrote:
>>> >>>
>>> >>>> Hmm, looks like at least some builds
>>> >>>> <
>>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/j=
ob/SparkPullRequestBuilder/19804/consoleFull
>>> >
>>> >>>> are working now, though this last one was from ~5 hours ago.
>>> >>>>
>>> >>>>
>>> >>>> On Fri, Sep 5, 2014 at 1:02 AM, shane knapp <sknapp@berkeley.edu>
>>> >>>> wrote:
>>> >>>>
>>> >>>>> yep. that's exactly the behavior i saw earlier, and will be
>>> figuring
>>> >>>>> out first thing tomorrow morning. i bet it's an environment issue=
s
>>> on the
>>> >>>>> slaves.
>>> >>>>>
>>> >>>>>
>>> >>>>> On Thu, Sep 4, 2014 at 7:10 PM, Nicholas Chammas <
>>> >>>>> nicholas.chammas@gmail.com> wrote:
>>> >>>>>
>>> >>>>>> Looks like during the last build
>>> >>>>>> <
>>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/j=
ob/SparkPullRequestBuilder/19797/console
>>> >
>>> >>>>>> Jenkins was unable to execute a git fetch?
>>> >>>>>>
>>> >>>>>>
>>> >>>>>> On Thu, Sep 4, 2014 at 7:58 PM, shane knapp <sknapp@berkeley.edu=
>
>>> >>>>>> wrote:
>>> >>>>>>
>>> >>>>>>> i'm going to restart jenkins and see if that fixes things.
>>> >>>>>>>
>>> >>>>>>>
>>> >>>>>>> On Thu, Sep 4, 2014 at 4:56 PM, shane knapp <sknapp@berkeley.ed=
u
>>> >
>>> >>>>>>> wrote:
>>> >>>>>>>
>>> >>>>>>>> looking
>>> >>>>>>>>
>>> >>>>>>>>
>>> >>>>>>>> On Thu, Sep 4, 2014 at 4:21 PM, Nicholas Chammas <
>>> >>>>>>>> nicholas.chammas@gmail.com> wrote:
>>> >>>>>>>>
>>> >>>>>>>>> It appears that our main man is having trouble
>>> >>>>>>>>> <
>>> https://amplab.cs.berkeley.edu/jenkins/view/Pull%20Request%20Builders/j=
ob/SparkPullRequestBuilder/
>>> >
>>> >>>>>>>>> hearing new requests
>>> >>>>>>>>> <
>>> https://github.com/apache/spark/pull/2277#issuecomment-54549106>.
>>> >>>>>>>>>
>>> >>>>>>>>> Do we need some smelling salts?
>>> >>>>>>>>>
>>> >>>>>>>>>
>>> >>>>>>>>> On Thu, Sep 4, 2014 at 5:49 PM, shane knapp <
>>> sknapp@berkeley.edu>
>>> >>>>>>>>> wrote:
>>> >>>>>>>>>
>>> >>>>>>>>>> i'd ping the Jenkinsmench... the master was completely
>>> offline,
>>> >>>>>>>>>> so any new
>>> >>>>>>>>>> jobs wouldn't have reached it. any jobs that were queued whe=
n
>>> >>>>>>>>>> power was
>>> >>>>>>>>>> lost probably started up, but jobs that were running would
>>> fail.
>>> >>>>>>>>>>
>>> >>>>>>>>>>
>>> >>>>>>>>>> On Thu, Sep 4, 2014 at 2:45 PM, Nicholas Chammas <
>>> >>>>>>>>>> nicholas.chammas@gmail.com
>>> >>>>>>>>>> > wrote:
>>> >>>>>>>>>>
>>> >>>>>>>>>> > Woohoo! Thanks Shane.
>>> >>>>>>>>>> >
>>> >>>>>>>>>> > Do you know if queued PR builds will automatically be pick=
ed
>>> >>>>>>>>>> up? Or do we
>>> >>>>>>>>>> > have to ping the Jenkinmensch manually from each PR?
>>> >>>>>>>>>> >
>>> >>>>>>>>>> > Nick
>>> >>>>>>>>>> >
>>> >>>>>>>>>> >
>>> >>>>>>>>>> > On Thu, Sep 4, 2014 at 5:37 PM, shane knapp <
>>> >>>>>>>>>> sknapp@berkeley.edu> wrote:
>>> >>>>>>>>>> >
>>> >>>>>>>>>> >> AND WE'RE UP!
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >> sorry that this took so long... i'll send out a more
>>> detailed
>>> >>>>>>>>>> explanation
>>> >>>>>>>>>> >> of what happened soon.
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >> now, off to back up jenkins.
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >> shane
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >> On Thu, Sep 4, 2014 at 1:27 PM, shane knapp <
>>> >>>>>>>>>> sknapp@berkeley.edu> wrote:
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >> > it's a faulty power switch on the firewall, which has
>>> been
>>> >>>>>>>>>> swapped out.
>>> >>>>>>>>>> >> > we're about to reboot and be good to go.
>>> >>>>>>>>>> >> >
>>> >>>>>>>>>> >> >
>>> >>>>>>>>>> >> > On Thu, Sep 4, 2014 at 1:19 PM, shane knapp <
>>> >>>>>>>>>> sknapp@berkeley.edu>
>>> >>>>>>>>>> >> wrote:
>>> >>>>>>>>>> >> >
>>> >>>>>>>>>> >> >> looks like some hardware failed, and we're swapping in=
 a
>>> >>>>>>>>>> replacement.
>>> >>>>>>>>>> >> i
>>> >>>>>>>>>> >> >> don't have more specific information yet -- including
>>> >>>>>>>>>> *what* failed,
>>> >>>>>>>>>> >> as our
>>> >>>>>>>>>> >> >> sysadmin is super busy ATM. the root cause was an
>>> >>>>>>>>>> incorrect circuit
>>> >>>>>>>>>> >> being
>>> >>>>>>>>>> >> >> switched off during building maintenance.
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >> on a side note, this incident will be accelerating our
>>> plan
>>> >>>>>>>>>> to move the
>>> >>>>>>>>>> >> >> entire jenkins infrastructure in to a managed datacent=
er
>>> >>>>>>>>>> environment.
>>> >>>>>>>>>> >> this
>>> >>>>>>>>>> >> >> will be our major push over the next couple of weeks.
>>> more
>>> >>>>>>>>>> details
>>> >>>>>>>>>> >> about
>>> >>>>>>>>>> >> >> this, also, as soon as i get them.
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >> i'm very sorry about the downtime, we'll get everythin=
g
>>> up
>>> >>>>>>>>>> and running
>>> >>>>>>>>>> >> >> ASAP.
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >> On Thu, Sep 4, 2014 at 12:27 PM, shane knapp <
>>> >>>>>>>>>> sknapp@berkeley.edu>
>>> >>>>>>>>>> >> wrote:
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >>> looks like a power outage in soda hall. more updates =
as
>>> >>>>>>>>>> they happen.
>>> >>>>>>>>>> >> >>>
>>> >>>>>>>>>> >> >>>
>>> >>>>>>>>>> >> >>> On Thu, Sep 4, 2014 at 12:25 PM, shane knapp <
>>> >>>>>>>>>> sknapp@berkeley.edu>
>>> >>>>>>>>>> >> >>> wrote:
>>> >>>>>>>>>> >> >>>
>>> >>>>>>>>>> >> >>>> i am trying to get things up and running, but it loo=
ks
>>> >>>>>>>>>> like either
>>> >>>>>>>>>> >> the
>>> >>>>>>>>>> >> >>>> firewall gateway or jenkins server itself is down.
>>> i'll
>>> >>>>>>>>>> update as
>>> >>>>>>>>>> >> soon as
>>> >>>>>>>>>> >> >>>> i know more.
>>> >>>>>>>>>> >> >>>>
>>> >>>>>>>>>> >> >>>
>>> >>>>>>>>>> >> >>>
>>> >>>>>>>>>> >> >>
>>> >>>>>>>>>> >> >
>>> >>>>>>>>>> >>
>>> >>>>>>>>>> >
>>> >>>>>>>>>> > --
>>> >>>>>>>>>> > You received this message because you are subscribed to th=
e
>>> >>>>>>>>>> Google Groups
>>> >>>>>>>>>> > "amp-infra" group.
>>> >>>>>>>>>> > To unsubscribe from this group and stop receiving emails
>>> from
>>> >>>>>>>>>> it, send an
>>> >>>>>>>>>> > email to amp-infra+unsubscribe@googlegroups.com.
>>> >>>>>>>>>> > For more options, visit https://groups.google.com/d/optout=
.
>>> >>>>>>>>>> >
>>> >>>>>>>>>>
>>> >>>>>>>>>
>>> >>>>>>>>>
>>> >>>>>>>>
>>> >>>>>>>
>>> >>>>>>
>>> >>>>>
>>> >>>>
>>> >>>
>>> >>
>>> >
>>>
>>
>>
>

--001a11345e221ba52905028fa996--

From dev-return-9368-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 14:33:03 2014
Return-Path: <dev-return-9368-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5D4F111572
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 14:33:03 +0000 (UTC)
Received: (qmail 89084 invoked by uid 500); 9 Sep 2014 14:33:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89009 invoked by uid 500); 9 Sep 2014 14:33:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88997 invoked by uid 99); 9 Sep 2014 14:33:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 14:33:02 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.175 as permitted sender)
Received: from [209.85.217.175] (HELO mail-lb0-f175.google.com) (209.85.217.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 14:32:36 +0000
Received: by mail-lb0-f175.google.com with SMTP id v6so2941422lbi.6
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 07:32:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=j3+CstDHi/aJ90JPX4MAlc/BB7qAjC12gqw+E4ZJEfw=;
        b=DZejYq1gVduk4qDoNihpwPyOOxd798tJbgommTIw6s09WHFCd7cphzoaX8epyGg1r1
         33QtUEc+mVJq26jD1A+OIs6FOnvnBy9G/TpXid2yM8hTHZehA6CSFCUjU+oNm1YEjUcp
         KLBgxYH2r1ZTg5RGqGbcCL+F7/6HW+nORZ+El7pnFRYy/nmoDMgKCNbofbUE+gdo3oAZ
         CH7joS4m6m5X21XdZ0diK5yE2hoaOUl/4s2v6J8Sj5WVEZNyPnGeRCXHGw2e4OZ+teYo
         wC943zG6yzwnnQJ74JQka00bei1SRu70pxWsX39hQtGhbRocPNyeHI1PgiUB2nOCaTOS
         7rcA==
MIME-Version: 1.0
X-Received: by 10.152.28.74 with SMTP id z10mr6049575lag.10.1410273155380;
 Tue, 09 Sep 2014 07:32:35 -0700 (PDT)
Received: by 10.25.31.78 with HTTP; Tue, 9 Sep 2014 07:32:35 -0700 (PDT)
In-Reply-To: <CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
Date: Tue, 9 Sep 2014 07:32:35 -0700
Message-ID: <CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>, Sandy Ryza <sandy.ryza@cloudera.com>
Content-Type: multipart/alternative; boundary=089e0160b81e767a6a0502a2cef3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160b81e767a6a0502a2cef3
Content-Type: text/plain; charset=UTF-8

Hi Sandy,

Any resolution for YARN failures ? It's a blocker for running spark on top
of YARN.

Thanks.
Deb

On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Hi Deb,
>
> I think this may be the same issue as described in
> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
> container got killed by YARN because it used much more memory that it
> requested. But we haven't figured out the root cause yet.
>
> +Sandy
>
> Best,
> Xiangrui
>
> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > During the 4th ALS iteration, I am noticing that one of the executor gets
> > disconnected:
> >
> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
> > SendingConnectionManagerId not found
> >
> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor 5
> > disconnected, so removing it
> >
> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
> executor 5
> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client disassociated
> >
> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch
> 12)
> > Any idea if this is a bug related to akka on YARN ?
> >
> > I am using master
> >
> > Thanks.
> > Deb
>

--089e0160b81e767a6a0502a2cef3--

From dev-return-9369-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 16:06:01 2014
Return-Path: <dev-return-9369-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A910B119C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 16:06:01 +0000 (UTC)
Received: (qmail 79383 invoked by uid 500); 9 Sep 2014 16:06:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79311 invoked by uid 500); 9 Sep 2014 16:06:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79299 invoked by uid 99); 9 Sep 2014 16:05:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 16:05:59 +0000
X-ASF-Spam-Status: No, hits=3.8 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gurongwalker@gmail.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 16:05:25 +0000
Received: by mail-qg0-f53.google.com with SMTP id q108so396465qgd.12
        for <dev@spark.incubator.apache.org>; Tue, 09 Sep 2014 09:05:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Zf58lr7rRI7Rc0xJaMB1dfRxtXOgsedvHsfGOQZty2A=;
        b=Eph7m4K5dsi9BHdZhoS+iB0zFCV5CFWumlhuGNtMR+Sd+Sl3OOvSD5kzi9d5ejokX5
         V2mSGa+qwOUWztm4pqrcIri8f0zqRG9YJIPaqIZQoOWAxZXOFi6+DLAkp5K85dq5mo8l
         To0q/a6O+rrH07BgRC7oFvLIo6B2weD9QeSQQazUaBGKuSKfkN7F4378OP0ZzSe4mga1
         th1rj5/SQYEY/XoH4Cu2761Vlh1lxP5w+0jf5RKuVl986hgrFbpb7nkbH0eRtNQ9BhHw
         LpdgRC0uElhelRTp/HFhgAGNnQ2SOJzmcrccf4xJZTdYcHzJ1te8U06NHnNOCt8ydum9
         0tkg==
MIME-Version: 1.0
X-Received: by 10.229.33.202 with SMTP id i10mr52278338qcd.2.1410278723053;
 Tue, 09 Sep 2014 09:05:23 -0700 (PDT)
Received: by 10.140.49.135 with HTTP; Tue, 9 Sep 2014 09:05:22 -0700 (PDT)
In-Reply-To: <CAJgQjQ9+QGNkWMpVnetHf-Oc8T89_XqPpF0myM5whm4oNCuEAw@mail.gmail.com>
References: <1409909219731-8291.post@n3.nabble.com>
	<CADtDQQKjQrivU2Tnj_-ikyXKeSZDVZO6vfEu5xS4Gnvi7QoX0g@mail.gmail.com>
	<1409930280353-8293.post@n3.nabble.com>
	<CABjXkq77eE4qs+ARVywb2fPkq7oZShw6ODKzYQE8_e7q=20nSQ@mail.gmail.com>
	<1409933903848-8296.post@n3.nabble.com>
	<CABPQxsuzX6VAf+-psussm8OwKD0cho-rMh0Mw5-RBiiknyPUMg@mail.gmail.com>
	<EBD77AAF-9618-483C-9ACE-049EF8E8484B@gmail.com>
	<CAEJ05AGBBfzeq=Hz64y4CZOMs9tvJZXBYSyGLn3bXigm-5+1Dg@mail.gmail.com>
	<1409992086513-8310.post@n3.nabble.com>
	<CAJgQjQ9+QGNkWMpVnetHf-Oc8T89_XqPpF0myM5whm4oNCuEAw@mail.gmail.com>
Date: Wed, 10 Sep 2014 00:05:22 +0800
Message-ID: <CAEJ05AEJmm7bS=XMkCA36m5DPyazLQTszf0mfLB-NCkCsr9sqQ@mail.gmail.com>
Subject: Re: [mllib] Add multiplying large scale matrices
From: =?UTF-8?B?6aG+6I2j?= <gurongwalker@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>, dev <dev@spark.incubator.apache.org>
Content-Type: multipart/mixed; boundary=001a1133b8d252c9440502a41af7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133b8d252c9440502a41af7
Content-Type: multipart/alternative; boundary=001a1133b8d252c9400502a41af5

--001a1133b8d252c9400502a41af5
Content-Type: text/plain; charset=UTF-8

Hi All,

Sorry for my late reply!

Yu Ishikawa,Thanks for your interests in Saury project. You are welcomed to
try that out. If you have questions about that, please email me. We are
keeping improving performance/adding features for the project.

Xiangrui, thanks for your encouragement. If you have any problems with my
CSDN reports, please feel free to contact me. We had some design for Saury
on our lab's private JIRA which is in Chinese. I will translate into
English then share it to you these days. Acutally, I also have surveyed the
related algorithms/systems before we started the Saury project. The survey
is attached in this email, not on CSDN report. We also had considered the
2.5D algorithm for reducing communication. However, at that time, MLlib did
not have a distributed block matrix representation. So, we decided to
firstly implement the distributed matrix multiplication on the
IndexRowMatrix as time is limited for the Summer Code project. Also, as far
as we know, nobody had tried that at that time. Actually, adopting 2.5D
algorithm to reduce network communication is on our roadmap. We are also
planning to do that in the next days.

Best,
Rong


2014-09-08 15:31 GMT+08:00 Xiangrui Meng <mengxr@gmail.com>:

> Sorry for my late reply! I'm also very interested in the
> implementation of distributed matrix multiplication. As Shivaram
> mentioned, the communication is the concern here. But maybe we can
> start with a reasonable implementation and then iterate on its
> performance. It would be great if eventually we can implement an
> algorithm close to the 2.5D algorithm
> (http://www.netlib.org/lapack/lawnspdf/lawn248.pdf).
>
> I created two JIRAs for this topic:
>
> 1. Distributed block matrix:
> https://issues.apache.org/jira/browse/SPARK-3434
> 2. Distributed matrix multiplication:
> https://issues.apache.org/jira/browse/SPARK-3435
>
> We can move our discussion there.
>
> Rong, I'm really happy to see the Saury project. It would be great if
> you can share your design and experience (maybe on the JIRA page so it
> is easier to track). I will read the reports on CSDN and ping you if I
> ran into problems. Thanks!
>
> Best,
> Xiangrui
>
> On Sat, Sep 6, 2014 at 1:28 AM, Yu Ishikawa
> <yuu.ishikawa+spark@gmail.com> wrote:
> > Hi Rong,
> >
> > Great job! Thank you for let me know your work.
> > I will read the source code of saury later.
> >
> > Although AMPLab is working to implement them, would you like to merge it
> > into Spark?
> >
> > Best,
> >
> > -- Yu Ishikawa
> >
> >
> >
> >
> > --
> > View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8310.html
> > Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
------------------
Rong Gu
Department of Computer Science and Technology
State Key Laboratory for Novel Software Technology
Nanjing University
Phone: +86 15850682791
Email: gurongwalker@gmail.com
Homepage: http://pasa-bigdata.nju.edu.cn/people/ronggu/

--001a1133b8d252c9400502a41af5
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Hi All,<br><br>Sorry for my late reply!<br><br>Yu Ish=
ikawa,Thanks for your interests in Saury project. You are welcomed to try t=
hat out. If you have questions about that, please email me. We are keeping =
improving performance/adding features for the project.<br><br>Xiangrui, tha=
nks for your encouragement. If you have any problems with my CSDN reports, =
please feel free to contact me. We had some design for Saury on our lab&#39=
;s private JIRA which is in Chinese. I will translate into English then sha=
re it to you these days. Acutally, I also have surveyed the related algorit=
hms/systems before we started the Saury project. The survey is attached in =
this email, not on CSDN report. We also had considered the 2.5D algorithm f=
or reducing communication. However, at that time, MLlib did not have a dist=
ributed block matrix representation. So, we decided to firstly implement th=
e distributed matrix multiplication on the IndexRowMatrix as time is limite=
d for the Summer Code project. Also, as far as we know, nobody had tried th=
at at that time. Actually, adopting 2.5D algorithm to reduce network commun=
ication is on our roadmap. We are also planning to do that in the next days=
.<br><br>Best,<br>Rong<br><br></div></div><div class=3D"gmail_extra"><br><d=
iv class=3D"gmail_quote">2014-09-08 15:31 GMT+08:00 Xiangrui Meng <span dir=
=3D"ltr">&lt;<a href=3D"mailto:mengxr@gmail.com" target=3D"_blank">mengxr@g=
mail.com</a>&gt;</span>:<br><blockquote class=3D"gmail_quote" style=3D"marg=
in:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Sorry for my lat=
e reply! I&#39;m also very interested in the<br>
implementation of distributed matrix multiplication. As Shivaram<br>
mentioned, the communication is the concern here. But maybe we can<br>
start with a reasonable implementation and then iterate on its<br>
performance. It would be great if eventually we can implement an<br>
algorithm close to the 2.5D algorithm<br>
(<a href=3D"http://www.netlib.org/lapack/lawnspdf/lawn248.pdf" target=3D"_b=
lank">http://www.netlib.org/lapack/lawnspdf/lawn248.pdf</a>).<br>
<br>
I created two JIRAs for this topic:<br>
<br>
1. Distributed block matrix: <a href=3D"https://issues.apache.org/jira/brow=
se/SPARK-3434" target=3D"_blank">https://issues.apache.org/jira/browse/SPAR=
K-3434</a><br>
2. Distributed matrix multiplication:<br>
<a href=3D"https://issues.apache.org/jira/browse/SPARK-3435" target=3D"_bla=
nk">https://issues.apache.org/jira/browse/SPARK-3435</a><br>
<br>
We can move our discussion there.<br>
<br>
Rong, I&#39;m really happy to see the Saury project. It would be great if<b=
r>
you can share your design and experience (maybe on the JIRA page so it<br>
is easier to track). I will read the reports on CSDN and ping you if I<br>
ran into problems. Thanks!<br>
<br>
Best,<br>
Xiangrui<br>
<div class=3D"HOEnZb"><div class=3D"h5"><br>
On Sat, Sep 6, 2014 at 1:28 AM, Yu Ishikawa<br>
&lt;<a href=3D"mailto:yuu.ishikawa%2Bspark@gmail.com">yuu.ishikawa+spark@gm=
ail.com</a>&gt; wrote:<br>
&gt; Hi Rong,<br>
&gt;<br>
&gt; Great job! Thank you for let me know your work.<br>
&gt; I will read the source code of saury later.<br>
&gt;<br>
&gt; Although AMPLab is working to implement them, would you like to merge =
it<br>
&gt; into Spark?<br>
&gt;<br>
&gt; Best,<br>
&gt;<br>
&gt; -- Yu Ishikawa<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; --<br>
&gt; View this message in context: <a href=3D"http://apache-spark-developer=
s-list.1001551.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8=
291p8310.html" target=3D"_blank">http://apache-spark-developers-list.100155=
1.n3.nabble.com/mllib-Add-multiplying-large-scale-matrices-tp8291p8310.html=
</a><br>
&gt; Sent from the Apache Spark Developers List mailing list archive at Nab=
ble.com.<br>
&gt;<br>
&gt; ---------------------------------------------------------------------<=
br>
&gt; To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache=
.org">dev-unsubscribe@spark.apache.org</a><br>
&gt; For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apac=
he.org">dev-help@spark.apache.org</a><br>
&gt;<br>
<br>
---------------------------------------------------------------------<br>
To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache.org"=
>dev-unsubscribe@spark.apache.org</a><br>
For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apache.or=
g">dev-help@spark.apache.org</a><br>
<br>
</div></div></blockquote></div><br><br clear=3D"all"><br>-- <br><div dir=3D=
"ltr"><div>------------------<br>Rong Gu<br>Department of Computer Science =
and Technology<br>State Key Laboratory for Novel Software Technology<br>Nan=
jing University<br>Phone: +86 15850682791<br>Email: <a href=3D"mailto:guron=
gwalker@gmail.com" target=3D"_blank">gurongwalker@gmail.com</a><br></div>Ho=
mepage: <a href=3D"http://pasa-bigdata.nju.edu.cn/people/ronggu/" target=3D=
"_blank">http://pasa-bigdata.nju.edu.cn/people/ronggu/</a><br></div>
</div>

--001a1133b8d252c9400502a41af5--

--001a1133b8d252c9440502a41af7
Content-Type: text/plain; charset=us-ascii


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--001a1133b8d252c9440502a41af7--

From dev-return-9370-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 16:16:49 2014
Return-Path: <dev-return-9370-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7F51911A3E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 16:16:49 +0000 (UTC)
Received: (qmail 7124 invoked by uid 500); 9 Sep 2014 16:16:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7060 invoked by uid 500); 9 Sep 2014 16:16:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7048 invoked by uid 99); 9 Sep 2014 16:16:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 16:16:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.43 as permitted sender)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 16:16:42 +0000
Received: by mail-oi0-f43.google.com with SMTP id i138so4134009oig.2
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 09:16:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=mG1GxjFPB+AXxFuAkCpyx0N/0U+SGjC1lB3A+HCMfN4=;
        b=jzwwBpNSO7kq2F4eqgzyxBoIDe3cLXo8ULW2P3MZMRVGATHfklObejcQema/UVqlc/
         zMky9uMV1YRXVgih7DEWOjtJnCSnaZD8/aKXn+jy8OikDZ6fTjuMQfT7dUXdKMn0pZmE
         dwZSq14EgYld/4lO+2mz9eoX36pjza+/T+Zz9oondKWMOX6qvuD3qZfCWy1VqzIyX7E3
         GvEwJVaqRSLc2PRgdJ4gGRNJXC7E9193AHuAf2FxH+Rtm1FpNxvs+GWXiDdmyEtKRdtp
         1Imw9gitcEaMV1UtP0Fcd/j3PgPkr7dr8bq7FUWgXBWeAvKS1Ji4jwNc5m6Iaw9IrcP4
         voFw==
MIME-Version: 1.0
X-Received: by 10.60.175.228 with SMTP id cd4mr4918606oec.83.1410279381651;
 Tue, 09 Sep 2014 09:16:21 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 9 Sep 2014 09:16:21 -0700 (PDT)
Date: Tue, 9 Sep 2014 09:16:21 -0700
Message-ID: <CABPQxsvVqzSisPn4GukorkUcfSJgkwco6XW9m1McF2VkT4BS1Q@mail.gmail.com>
Subject: RFC: Deprecating YARN-alpha API's
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Everyone,

This is a call to the community for comments on SPARK-3445 [1]. In a
nutshell, we are trying to figure out timelines for deprecation of the
YARN-alpha API's as Yahoo is now moving off of them. It's helpful for
us to have a sense of whether anyone else uses these.

Please comment on the JIRA if you have feeback, thanks!

[1] https://issues.apache.org/jira/browse/SPARK-3445

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9371-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 17:18:06 2014
Return-Path: <dev-return-9371-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F3EA11C9A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 17:18:06 +0000 (UTC)
Received: (qmail 57689 invoked by uid 500); 9 Sep 2014 17:18:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57616 invoked by uid 500); 9 Sep 2014 17:18:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57605 invoked by uid 99); 9 Sep 2014 17:18:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:18:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.46] (HELO mail-oi0-f46.google.com) (209.85.218.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:17:59 +0000
Received: by mail-oi0-f46.google.com with SMTP id g201so2918855oib.33
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 10:17:38 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=QkimSyukp4Iez3nnpBaI6Z1T40vKgr7LgbvJMT+FJcA=;
        b=kwVEjakRHvmQJCxP+anrYIBk3MK1Wulid3l+9XnzuDDla3OS/KerwrAf3mCWm8cFWc
         BA2+dr0qX6P98DAfndyqC0EewvWzyeyI6RkAx2I9fXFq7JAyW9gJdBd+pG6xKG/ugtB5
         XsAnkIPwgKTgItc7FEvnoxuOrfRQEIQH15HTwPN9woOhFWNRSjo2EgDJMvstYFY/EUNW
         VOlY63KpnpVVBKuUXZp/JXAaygopDjJA/J8KqsiMv/3MWxTUTYWTZDk9OSXeaQlsLzcN
         xVmQtuthl9sVLWvK162T6Xf4JRMQtq/H6z0Ypwj2P56bIcLRs33Lpk9VmIWU3VSvmfRx
         4AIw==
X-Gm-Message-State: ALoCoQmT2JNlegVdDdvg2eazjmWmL29qOTHfy4m6pCEu1eU+v+mmg2y4/Zh0ZK7JrRFnvcivTBpY
MIME-Version: 1.0
X-Received: by 10.60.34.199 with SMTP id b7mr5344479oej.86.1410283058010; Tue,
 09 Sep 2014 10:17:38 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Tue, 9 Sep 2014 10:17:37 -0700 (PDT)
Date: Tue, 9 Sep 2014 12:17:37 -0500
Message-ID: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
Subject: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013d0d54b5a4de0502a51ce3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d0d54b5a4de0502a51ce3
Content-Type: text/plain; charset=UTF-8

I've been looking at performance differences between spark sql queries
against single parquet tables, vs a unionAll of two tables.  It's a
significant difference, like 5 to 10x

Is there a reason in general not to push projections and predicates down
into the individual ParquetTableScans in a union?

Here's an example of what I'm talking about:


scala> p.printSchema
root
 |-- name: string (nullable = true)
 |-- age: integer (nullable = false)
 |-- phones: array (nullable = true)
 |    |-- element: string (containsNull = true)


scala> p2.printSchema
root
 |-- name: string (nullable = true)
 |-- age: integer (nullable = false)
 |-- phones: array (nullable = true)
 |    |-- element: string (containsNull = true)


scala> val b = p.unionAll(p2)


// single table, pushdown
scala> p.where('age < 40).select('name)
res36: org.apache.spark.sql.SchemaRDD =
SchemaRDD[97] at RDD at SchemaRDD.scala:103
== Query Plan ==
== Physical Plan ==
Project [name#3]
 ParquetTableScan [name#3,age#4], (ParquetRelation /var/tmp/people,
Some(Configuration: core-default.xml, core-site.xml, mapred-default.xml,
mapred-site.xml), org.apache.spark.sql.SQLContext@6d7e79f6, []), [(age#4 <
40)]


// union of 2 tables, no pushdown
scala> b.where('age < 40).select('name)
res37: org.apache.spark.sql.SchemaRDD =
SchemaRDD[99] at RDD at SchemaRDD.scala:103
== Query Plan ==
== Physical Plan ==
Project [name#3]
 Filter (age#4 < 40)
  Union [ParquetTableScan [name#3,age#4,phones#5], (ParquetRelation
/var/tmp/people, Some(Configuration: core-default.xml, core-site.xml,
mapred-default.xml, mapred-site.xml),
org.apache.spark.sql.SQLContext@6d7e79f6, []), []
,ParquetTableScan [name#0,age#1,phones#2], (ParquetRelation
/var/tmp/people2, Some(Configuration: core-default.xml, core-site.xml,
mapred-default.xml, mapred-site.xml),
org.apache.spark.sql.SQLContext@6d7e79f6, []), []
]
   ParquetTableScan [name#3,age#4,phones#5], (ParquetRelation
/var/tmp/people, Some(Configuration: core-default.xml, core-site.xml,
mapred-default.xml, mapred-site.xml), org.apache.spark.sql...

--089e013d0d54b5a4de0502a51ce3--

From dev-return-9372-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 17:47:35 2014
Return-Path: <dev-return-9372-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6FB2C11D8D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 17:47:35 +0000 (UTC)
Received: (qmail 42051 invoked by uid 500); 9 Sep 2014 17:47:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41987 invoked by uid 500); 9 Sep 2014 17:47:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41971 invoked by uid 99); 9 Sep 2014 17:47:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:47:34 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:47:30 +0000
Received: by mail-lb0-f170.google.com with SMTP id u10so2804058lbd.15
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 10:47:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=wNSe17gpeUKoA7jnf0VZjg5Mk/F9OSfMXeYUA0VbQPw=;
        b=eJSpCB3f88hW68pcZ0EYdpvYBgvc4Ow9ZAwmHG4Iv2TvJWmBR+bdzrT2hPSoSzjtT+
         pbC8s8iM2dvxaYzsCIJEXWq3R/wPp3W5AgLnJTz5X98UPwAbW34LxhVOM1AYkOCxsgWI
         PoVziKsA16rmnuy9BpR3xtPx/7oN672LQPlcu1bc3zov1JNfo7c5CKdF9pM8YCiH9ILJ
         cGKdnL4PfW4cqBy9Or7EAxBkMR+wa9CzZlfIFYKw3W/S+M77yRmsGK3BCYbe5Ja37qDf
         E5vqCnyblIYnFjnoirBZwZtEWug0ptP6fx1VvR5gSrh4Iuaktl+fFLKbNeD+i5OY0US3
         0wpQ==
X-Gm-Message-State: ALoCoQkmnVC0Q65c+MDy41KOVCg3qr4x/POtxqXbd+AlcJ/+y9epT95yoo7VZHExhazqW2SiiQDb
X-Received: by 10.152.170.227 with SMTP id ap3mr2783782lac.15.1410284828160;
 Tue, 09 Sep 2014 10:47:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Tue, 9 Sep 2014 10:46:48 -0700 (PDT)
In-Reply-To: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 9 Sep 2014 10:46:48 -0700
Message-ID: <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c655837060a0502a58614
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c655837060a0502a58614
Content-Type: text/plain; charset=UTF-8

On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org> wrote:
>
> Is there a reason in general not to push projections and predicates down
> into the individual ParquetTableScans in a union?
>

This would be a great case to add to ColumnPruning.  Would be awesome if
you could open a JIRA or even a PR :)

--089e013c655837060a0502a58614--

From dev-return-9373-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 17:49:41 2014
Return-Path: <dev-return-9373-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C71D811D9F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 17:49:41 +0000 (UTC)
Received: (qmail 49382 invoked by uid 500); 9 Sep 2014 17:49:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49311 invoked by uid 500); 9 Sep 2014 17:49:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49299 invoked by uid 99); 9 Sep 2014 17:49:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:49:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.192.50 as permitted sender)
Received: from [209.85.192.50] (HELO mail-qg0-f50.google.com) (209.85.192.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 17:49:36 +0000
Received: by mail-qg0-f50.google.com with SMTP id z60so2338996qgd.23
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 10:49:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=pT8abOVp4mKlMDF6fwizDdN8vF2t4hHqudkllmM2fjE=;
        b=KrqYx/+w2b9wdaVd5HUNBVKQj8WzKkbsCbghdWdyhyQt15hnWWRFA26/9L5BnVpmJb
         nHnH+MtkHg2X3zgQ49T2cCTh4HGF+VbkJVxuA2Ljjf8uyVzDI8zwpWUvZnv6V+PgAiHz
         YAhZ5L51vfyCXY6R08h7YUx2FJ1qz5k5AWSM+yOA724rmQ6MEudGdG3yu/WMTRD84gPc
         Hv8u3NiQFLzAXUiL1/HH14UfdnA1KM8mE1Yk3IF+TWk555O2TtoVktcJBNY5Hp0a49m3
         vMLu30X6OwRqxXQEGvXDVZa+MqcK4984Zo7klc/B+q9DNicvtlD+qD9SnwOK8VCnX+VV
         qwIQ==
X-Gm-Message-State: ALoCoQnEQngao33sz9i7eL8M+34GhTeCe4YU7+wg9drnhpAzmL0GZApAVaQ0CmbtcVxM62F15EUe
MIME-Version: 1.0
X-Received: by 10.140.35.242 with SMTP id n105mr50035018qgn.11.1410284955586;
 Tue, 09 Sep 2014 10:49:15 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Tue, 9 Sep 2014 10:49:15 -0700 (PDT)
In-Reply-To: <CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
	<CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
Date: Tue, 9 Sep 2014 10:49:15 -0700
Message-ID: <CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c03ce0cf63070502a58d19
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c03ce0cf63070502a58d19
Content-Type: text/plain; charset=UTF-8

Hi Deb,

The current state of the art is to increase
spark.yarn.executor.memoryOverhead until the job stops failing.  We do have
plans to try to automatically scale this based on the amount of memory
requested, but it will still just be a heuristic.

-Sandy

On Tue, Sep 9, 2014 at 7:32 AM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Hi Sandy,
>
> Any resolution for YARN failures ? It's a blocker for running spark on top
> of YARN.
>
> Thanks.
> Deb
>
> On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>
>> Hi Deb,
>>
>> I think this may be the same issue as described in
>> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
>> container got killed by YARN because it used much more memory that it
>> requested. But we haven't figured out the root cause yet.
>>
>> +Sandy
>>
>> Best,
>> Xiangrui
>>
>> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>> > Hi,
>> >
>> > During the 4th ALS iteration, I am noticing that one of the executor
>> gets
>> > disconnected:
>> >
>> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
>> > SendingConnectionManagerId not found
>> >
>> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor 5
>> > disconnected, so removing it
>> >
>> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
>> executor 5
>> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client disassociated
>> >
>> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch
>> 12)
>> > Any idea if this is a bug related to akka on YARN ?
>> >
>> > I am using master
>> >
>> > Thanks.
>> > Deb
>>
>
>

--001a11c03ce0cf63070502a58d19--

From dev-return-9374-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:00:40 2014
Return-Path: <dev-return-9374-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6966D11E03
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:00:40 +0000 (UTC)
Received: (qmail 71671 invoked by uid 500); 9 Sep 2014 18:00:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71602 invoked by uid 500); 9 Sep 2014 18:00:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71590 invoked by uid 99); 9 Sep 2014 18:00:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:00:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:00:33 +0000
Received: by mail-ie0-f179.google.com with SMTP id rl12so4559327iec.38
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:00:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=O0bQNNbD7nDh8FEGNm2/UuVrmMQDCZjOeYUWS8m+CSE=;
        b=eW51dczMzKR9WxQuDxXKaG1Je5yqB45bgodv+wDAM8fd/FD0SAPT9vZ0liiawBgFRc
         plMFwiApXuxfHcj+64Tka4Oky1L5AcB9XGmhQkakIlPqZDT5WI/7uIV9ODdW0VH2mbxp
         /Pl0DmIMqT3JboHdgkvlyII36In3EUOq+6JTeZtkJ3XFPPoh8/sFvYR/cC7y7WxcnPeB
         bj2N6LWmLIMichvbCLe3LjmPRgxG0bHGr7IJHe4chWyIDmB71saGpbTls3bPFW4YOpOU
         NwFEIqbZlhzKLsQlqGzeRnWxDeuUkcYJwKNBngGzK0gP3R0tWMfoa3icGei7Yhp6o9cV
         9HIA==
X-Gm-Message-State: ALoCoQkb6UOA8Yhu9RpKfyCcOu1enunCDzXJYZeiMZWQlYJcAv4WE7bFA2uEEZ8XahLYyDIEIP+K
X-Received: by 10.42.58.65 with SMTP id g1mr40462716ich.38.1410285612889; Tue,
 09 Sep 2014 11:00:12 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Tue, 9 Sep 2014 10:59:52 -0700 (PDT)
In-Reply-To: <CABPQxsvVqzSisPn4GukorkUcfSJgkwco6XW9m1McF2VkT4BS1Q@mail.gmail.com>
References: <CABPQxsvVqzSisPn4GukorkUcfSJgkwco6XW9m1McF2VkT4BS1Q@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 9 Sep 2014 18:59:52 +0100
Message-ID: <CAMAsSd+S6vMjggFRZYWft_96sXETZniFUr4WZKRZX8nODUYNRw@mail.gmail.com>
Subject: Re: RFC: Deprecating YARN-alpha API's
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

FWIW consensus from Cloudera folk seems to be that there's no need or
demand on this end for YARN alpha. It wouldn't have an impact if it
were removed sooner even.

It will be a small positive to reduce complexity by removing this
support, making it a little easier to develop for current YARN APIs.

On Tue, Sep 9, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hi Everyone,
>
> This is a call to the community for comments on SPARK-3445 [1]. In a
> nutshell, we are trying to figure out timelines for deprecation of the
> YARN-alpha API's as Yahoo is now moving off of them. It's helpful for
> us to have a sense of whether anyone else uses these.
>
> Please comment on the JIRA if you have feeback, thanks!
>
> [1] https://issues.apache.org/jira/browse/SPARK-3445
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9375-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:07:38 2014
Return-Path: <dev-return-9375-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3593611E51
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:07:38 +0000 (UTC)
Received: (qmail 97155 invoked by uid 500); 9 Sep 2014 18:07:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97088 invoked by uid 500); 9 Sep 2014 18:07:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97077 invoked by uid 99); 9 Sep 2014 18:07:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:07:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.50] (HELO mail-oa0-f50.google.com) (209.85.219.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:07:33 +0000
Received: by mail-oa0-f50.google.com with SMTP id o6so12185545oag.9
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:07:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=ejq00zYOQmPt8TMQX9XgIECRLf06VplbWYheP5ZE6Ws=;
        b=SaOQZwdTAfknGAgo6Rk9VbiiPy4zk7UGh7jTPRNWAxaTMLu+2T+LNq6LRJujhRIlTu
         CnSZNmzBrFy6SWs+4N7FuatOI/pauq78OxYcGDOf8elkRQizigd2Hh2JWM3aAcasD8ST
         w/4CWsYq4ZEduKPtnEpb7YFj42XHNbGkZNUhKETn6Fmjhnd9MBqOGkf+M+iwJGgREl8b
         sZAKKTQUcH8wex1nCEN08AC21MPgmxmjjIjbO2GsyEDSf1QmCTAoAjlo7CBcwJCAlABk
         t5m96I1EPVI6Ugl2D6cPlaxswXnRXQoEbNcYfTdDRgbTrTEQtkMbcg+1ctKvfynSJIVg
         kRHA==
X-Gm-Message-State: ALoCoQmZrnZgcRtbXLWPKrCG636Xzje2v42uAeTnjCtoL/N/EN8atTAhpIjDqa8nXgYNisLSZBAf
MIME-Version: 1.0
X-Received: by 10.182.44.135 with SMTP id e7mr40886262obm.18.1410286032345;
 Tue, 09 Sep 2014 11:07:12 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Tue, 9 Sep 2014 11:07:12 -0700 (PDT)
In-Reply-To: <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
Date: Tue, 9 Sep 2014 13:07:12 -0500
Message-ID: <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3075cfdefea0502a5cdee
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3075cfdefea0502a5cdee
Content-Type: text/plain; charset=UTF-8

Opened

https://issues.apache.org/jira/browse/SPARK-3462

I'll take a look at ColumnPruning and see what I can do

On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <michael@databricks.com>
wrote:

> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>>
>> Is there a reason in general not to push projections and predicates down
>> into the individual ParquetTableScans in a union?
>>
>
> This would be a great case to add to ColumnPruning.  Would be awesome if
> you could open a JIRA or even a PR :)
>

--001a11c3075cfdefea0502a5cdee--

From dev-return-9376-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:09:37 2014
Return-Path: <dev-return-9376-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 152A611E61
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:09:37 +0000 (UTC)
Received: (qmail 1116 invoked by uid 500); 9 Sep 2014 18:09:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1041 invoked by uid 500); 9 Sep 2014 18:09:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1028 invoked by uid 99); 9 Sep 2014 18:09:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:09:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:09:10 +0000
Received: by mail-la0-f50.google.com with SMTP id ty20so5012124lab.9
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:09:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=nIz2b3hp3hfINgz6gg8iDSCqdivodmyNQSqd0wx5CG8=;
        b=Vz9PEF/xg1u+zaZKYTOUEhluRXzofx8OHhdGVL1YhtnQ0OOd+FCM2pYajvcnEgrJPH
         qV7oy3jMiwFJsY8bg7nQhoB/8S11uY5F31IvZpZhbKHIIIVfLnv3C93zQBj2HfDYbbok
         VdLeZoS5/kGkcpnC2xgWSqRjxxn3DwsG5TYJOsbn6VBTQbyy5t39jcKj9KfYgqZzkOue
         JHKxZWgqDL3MPSdiP+uudlDo+PCKperRxclGabmxhp+wtiybxw37ZCLXzmuW68KF+D3u
         VMJUkrUVQ0ActgfqWRwS8/WrM/gCySe8L1ZdnzcP6Z/kdqNVhzG+bFsPxRpqVuL/qm4w
         Y2bQ==
X-Gm-Message-State: ALoCoQmlNYku71Nf3TulnHphIHVIgTs+Clp5ZhNfvIf8f5kDV3bfR1s4u8Pr48Ipx+9RHJtMj5rO
X-Received: by 10.152.170.227 with SMTP id ap3mr2887681lac.15.1410286148758;
 Tue, 09 Sep 2014 11:09:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Tue, 9 Sep 2014 11:08:48 -0700 (PDT)
In-Reply-To: <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
 <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com> <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 9 Sep 2014 11:08:48 -0700
Message-ID: <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c6558edb71c0502a5d426
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6558edb71c0502a5d426
Content-Type: text/plain; charset=UTF-8

Thanks!

On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org> wrote:

> Opened
>
> https://issues.apache.org/jira/browse/SPARK-3462
>
> I'll take a look at ColumnPruning and see what I can do
>
> On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>>
>>> Is there a reason in general not to push projections and predicates down
>>> into the individual ParquetTableScans in a union?
>>>
>>
>> This would be a great case to add to ColumnPruning.  Would be awesome if
>> you could open a JIRA or even a PR :)
>>
>
>

--089e013c6558edb71c0502a5d426--

From dev-return-9377-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:26:35 2014
Return-Path: <dev-return-9377-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D04D111ECD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:26:35 +0000 (UTC)
Received: (qmail 38428 invoked by uid 500); 9 Sep 2014 18:26:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38355 invoked by uid 500); 9 Sep 2014 18:26:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38343 invoked by uid 99); 9 Sep 2014 18:26:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:26:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of malouf.gary@gmail.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:26:30 +0000
Received: by mail-qa0-f51.google.com with SMTP id j7so15756621qaq.38
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:26:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=mAr68Q5qJgt/goL7/8Da0bbMzBa/EDagza55rd0g5aA=;
        b=zQpWND3D6MtWgZnw5Rr5+nBIrRPd/0zgSn3qlilfpeauh22vE7LcG7taIV/WK+tPkW
         5nlTQVJRm2l+9yonW5GfwJIuOHmbmSdYzlWDRQFi9WwYKuaKOQp9dgmqWYayV/op7g1E
         C+eMx7SSAN1bgvOuKEXdFKKYnR7rx0us33in0Mo1gryMvMhsBCqSSrZPruhhBtK1UFTz
         HgbsPEuCqGJBUBQKAkvyRfVnCRHRvjRPbOg7p5sz8YZbgJOuE+B9mOXTDYxlwPdM9qLs
         AoXxKoZLPITsNy265b2kurGGuHiUyKql7CKqLrIf+M7pDa8ZeIEd45TzmxcX/IiVzhUo
         +a2w==
MIME-Version: 1.0
X-Received: by 10.224.162.196 with SMTP id w4mr52756910qax.60.1410287169692;
 Tue, 09 Sep 2014 11:26:09 -0700 (PDT)
Received: by 10.140.29.102 with HTTP; Tue, 9 Sep 2014 11:26:09 -0700 (PDT)
In-Reply-To: <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
Date: Tue, 9 Sep 2014 14:26:09 -0400
Message-ID: <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Gary Malouf <malouf.gary@gmail.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Cody Koeninger <cody@koeninger.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e012946b6c7f6c10502a61178
X-Virus-Checked: Checked by ClamAV on apache.org

--089e012946b6c7f6c10502a61178
Content-Type: text/plain; charset=UTF-8

I'm kind of surprised this was not run into before.  Do people not
segregate their data by day/week in the HDFS directory structure?


On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <michael@databricks.com>
wrote:

> Thanks!
>
> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
> > Opened
> >
> > https://issues.apache.org/jira/browse/SPARK-3462
> >
> > I'll take a look at ColumnPruning and see what I can do
> >
> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
> michael@databricks.com>
> > wrote:
> >
> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
> >> wrote:
> >>>
> >>> Is there a reason in general not to push projections and predicates
> down
> >>> into the individual ParquetTableScans in a union?
> >>>
> >>
> >> This would be a great case to add to ColumnPruning.  Would be awesome if
> >> you could open a JIRA or even a PR :)
> >>
> >
> >
>

--089e012946b6c7f6c10502a61178--

From dev-return-9378-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:29:55 2014
Return-Path: <dev-return-9378-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0A88B11EDB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:29:55 +0000 (UTC)
Received: (qmail 45377 invoked by uid 500); 9 Sep 2014 18:29:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45310 invoked by uid 500); 9 Sep 2014 18:29:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45299 invoked by uid 99); 9 Sep 2014 18:29:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:29:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:29:49 +0000
Received: by mail-lb0-f180.google.com with SMTP id b12so2558271lbj.11
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:29:27 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=4yBHAfzBK+wbQj+4NJuqYKqiAg+lvFFgAtOqdUSrux8=;
        b=gMflD/uwGbaRxXDf+NK/wCD3Wpyr4UXMih9+aEgEMa+XEeiZYjb638JMwa1IFY/Jbr
         b7VboeASCG2vxqpKBLk9o8OUQ1YxHd+RRU/rzVoDB3EL+Kr5ETjOFDQQzOhAxKKBPn97
         uCYktBkhfR0k94d0lmis3eRxCTnWYzgD4uMGl2IT8hTkML33tnJwAlbaRGpolazlAbVF
         BFosx/h1EwB5tdl8Oy4GatARsjw5Z0tRgjd4avea3NP23u3nyHqOSTxjeWtiQ/wXsL9x
         oyuJ5WdqaCgM3Kgiowgb5xkMnKvIBW8ydZw2qD9arlznJBFYfEZocXVdqKiwynZBUjVO
         5YXQ==
X-Gm-Message-State: ALoCoQlZ1SoOZFD7t63skoYekV2Q3GN/xe1H9Yl44OMF1nVnR51jb1IupNTrNW+HZ5114xweltv7
X-Received: by 10.112.76.230 with SMTP id n6mr36025358lbw.8.1410287367316;
 Tue, 09 Sep 2014 11:29:27 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Tue, 9 Sep 2014 11:29:07 -0700 (PDT)
In-Reply-To: <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
 <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
 <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
 <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com> <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 9 Sep 2014 11:29:07 -0700
Message-ID: <CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Gary Malouf <malouf.gary@gmail.com>
Cc: Cody Koeninger <cody@koeninger.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=14dae9cfcd388f884a0502a61d75
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae9cfcd388f884a0502a61d75
Content-Type: text/plain; charset=UTF-8

I think usually people add these directories as multiple partitions of the
same table instead of union.  This actually allows us to efficiently prune
directories when reading in addition to standard column pruning.

On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com> wrote:

> I'm kind of surprised this was not run into before.  Do people not
> segregate their data by day/week in the HDFS directory structure?
>
>
> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> Thanks!
>>
>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>> > Opened
>> >
>> > https://issues.apache.org/jira/browse/SPARK-3462
>> >
>> > I'll take a look at ColumnPruning and see what I can do
>> >
>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>> michael@databricks.com>
>> > wrote:
>> >
>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
>> >> wrote:
>> >>>
>> >>> Is there a reason in general not to push projections and predicates
>> down
>> >>> into the individual ParquetTableScans in a union?
>> >>>
>> >>
>> >> This would be a great case to add to ColumnPruning.  Would be awesome
>> if
>> >> you could open a JIRA or even a PR :)
>> >>
>> >
>> >
>>
>
>

--14dae9cfcd388f884a0502a61d75--

From dev-return-9379-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 18:58:52 2014
Return-Path: <dev-return-9379-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2F18811033
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 18:58:52 +0000 (UTC)
Received: (qmail 25341 invoked by uid 500); 9 Sep 2014 18:58:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25266 invoked by uid 500); 9 Sep 2014 18:58:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25254 invoked by uid 99); 9 Sep 2014 18:58:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:58:50 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 18:58:25 +0000
Received: by mail-la0-f47.google.com with SMTP id q1so481087lam.6
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 11:58:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=4kIjMbQMzGBs/zsGD2siZVoz9d9C7uiqbgIvvAXCkac=;
        b=al1hXdnCqJvRb/0lpU8aTm+kkaQuikqNOBb1dnztPoDzqwIhQEQDbYxXBQcUHJlC6q
         N9+i+aV2vAXKmXXgBjzYszGeXIZF5TFuaKs6LAqS68PVobDDIfrVwniTLamMfJFWyRjU
         0EP0Bqw5d9j1qeu7JrGd8BEd9vlivyO28ydIUZH/hoVYEu/I/z/XQWJss64/FRHToyNQ
         T2ADkFaE1qgH9y3Kt+lRxQQNJkekicWIg01GoYM3QmQjsnOKt4A0dYJ+tLps+Tfbs58m
         bTAW+dE28ciQRM0qqWxWEaJgK7aCf1pQB3+u3uVE1pTQWTTKYgK9IhpsObPMZcrFvbkv
         bNBQ==
MIME-Version: 1.0
X-Received: by 10.152.21.229 with SMTP id y5mr28180136lae.9.1410289104782;
 Tue, 09 Sep 2014 11:58:24 -0700 (PDT)
Received: by 10.25.31.78 with HTTP; Tue, 9 Sep 2014 11:58:24 -0700 (PDT)
In-Reply-To: <CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
	<CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
	<CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
Date: Tue, 9 Sep 2014 11:58:24 -0700
Message-ID: <CA+B-+fxAA2mPO=cwmnw18UWE36BXnaAKWkQNf3BaC9iF7rQ8MQ@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Debasish Das <debasish.das83@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b3741f09390502a6855c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b3741f09390502a6855c
Content-Type: text/plain; charset=UTF-8

Hmm...I did try it increase to few gb but did not get a successful run
yet...

Any idea if I am using say 40 executors, each running 16GB, what's the
typical spark.yarn.executor.memoryOverhead for say 100M x 10 M large
matrices with say few billion ratings...

On Tue, Sep 9, 2014 at 10:49 AM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> Hi Deb,
>
> The current state of the art is to increase
> spark.yarn.executor.memoryOverhead until the job stops failing.  We do have
> plans to try to automatically scale this based on the amount of memory
> requested, but it will still just be a heuristic.
>
> -Sandy
>
> On Tue, Sep 9, 2014 at 7:32 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
>
>> Hi Sandy,
>>
>> Any resolution for YARN failures ? It's a blocker for running spark on
>> top of YARN.
>>
>> Thanks.
>> Deb
>>
>> On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>>
>>> Hi Deb,
>>>
>>> I think this may be the same issue as described in
>>> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
>>> container got killed by YARN because it used much more memory that it
>>> requested. But we haven't figured out the root cause yet.
>>>
>>> +Sandy
>>>
>>> Best,
>>> Xiangrui
>>>
>>> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <debasish.das83@gmail.com>
>>> wrote:
>>> > Hi,
>>> >
>>> > During the 4th ALS iteration, I am noticing that one of the executor
>>> gets
>>> > disconnected:
>>> >
>>> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
>>> > SendingConnectionManagerId not found
>>> >
>>> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor 5
>>> > disconnected, so removing it
>>> >
>>> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
>>> executor 5
>>> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client disassociated
>>> >
>>> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5 (epoch
>>> 12)
>>> > Any idea if this is a bug related to akka on YARN ?
>>> >
>>> > I am using master
>>> >
>>> > Thanks.
>>> > Deb
>>>
>>
>>
>

--089e0158b3741f09390502a6855c--

From dev-return-9380-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 19:01:40 2014
Return-Path: <dev-return-9380-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2CEC81104B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 19:01:40 +0000 (UTC)
Received: (qmail 28819 invoked by uid 500); 9 Sep 2014 19:01:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28752 invoked by uid 500); 9 Sep 2014 19:01:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28741 invoked by uid 99); 9 Sep 2014 19:01:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:01:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:01:33 +0000
Received: by mail-ob0-f170.google.com with SMTP id m8so12406612obr.29
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 12:01:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=XbmBV2L8RZKM616HGu9Vj3XorRJpcPlgUDlWsqy27aE=;
        b=LTKiIJUoz4MT2pGWfrmG+uT0dmAqi3R/p/QOajkRSNiJqJsDcotBY4DUzd0gFGFmrf
         ygegeRKX1NCfiWhOqnXCH6wJ37EV8kxBYvQr3eghvWw9Iua3cWNKKglz+wGNBDjUtkaz
         WPphVi2Q7Z6Ugc6kHFFeR3rX78Mqm1/dnYeZaiH89N+irVjJsdojZptCyjvIGrHjYDhW
         dt1cZBSYwlA4JIczYZe2aUbCg452TfkmJOigDR9woqVcymKTUfE/QYJZxWbTSCGOunI3
         lR7tXcI3cy1kuNJJYS+IGuDQQCmhU6vuv+5nH/KygNtdrbBPugLsgiD6VreaRpHsGkSH
         fGxQ==
X-Gm-Message-State: ALoCoQlpYquNKqj2SFHOVn3LblQufK9ua5MhzvskuyYIb3A7UrzKakrLXXHqyse3QXtW5reeF64B
MIME-Version: 1.0
X-Received: by 10.60.174.3 with SMTP id bo3mr41778652oec.31.1410289272031;
 Tue, 09 Sep 2014 12:01:12 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Tue, 9 Sep 2014 12:01:11 -0700 (PDT)
In-Reply-To: <CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
Date: Tue, 9 Sep 2014 14:01:11 -0500
Message-ID: <CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Gary Malouf <malouf.gary@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011844ce17c59e0502a68f7b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011844ce17c59e0502a68f7b
Content-Type: text/plain; charset=UTF-8

Maybe I'm missing something, I thought parquet was generally a write-once
format and the sqlContext interface to it seems that way as well.

d1.saveAsParquetFile("/foo/d1")

// another day, another table, with same schema
d2.saveAsParquetFile("/foo/d2")

Will give a directory structure like

/foo/d1/_metadata
/foo/d1/part-r-1.parquet
/foo/d1/part-r-2.parquet
/foo/d1/_SUCCESS

/foo/d2/_metadata
/foo/d2/part-r-1.parquet
/foo/d2/part-r-2.parquet
/foo/d2/_SUCCESS

// ParquetFileReader will fail, because /foo/d1 is a directory, not a
parquet partition
sqlContext.parquetFile("/foo")

// works, but has the noted lack of pushdown
sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))


Is there another alternative?



On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <michael@databricks.com>
wrote:

> I think usually people add these directories as multiple partitions of the
> same table instead of union.  This actually allows us to efficiently prune
> directories when reading in addition to standard column pruning.
>
> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
> wrote:
>
>> I'm kind of surprised this was not run into before.  Do people not
>> segregate their data by day/week in the HDFS directory structure?
>>
>>
>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <michael@databricks.com>
>> wrote:
>>
>>> Thanks!
>>>
>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
>>> wrote:
>>>
>>> > Opened
>>> >
>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>> >
>>> > I'll take a look at ColumnPruning and see what I can do
>>> >
>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>> michael@databricks.com>
>>> > wrote:
>>> >
>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
>>> >> wrote:
>>> >>>
>>> >>> Is there a reason in general not to push projections and predicates
>>> down
>>> >>> into the individual ParquetTableScans in a union?
>>> >>>
>>> >>
>>> >> This would be a great case to add to ColumnPruning.  Would be awesome
>>> if
>>> >> you could open a JIRA or even a PR :)
>>> >>
>>> >
>>> >
>>>
>>
>>
>

--089e011844ce17c59e0502a68f7b--

From dev-return-9381-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 19:09:45 2014
Return-Path: <dev-return-9381-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7265711081
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 19:09:45 +0000 (UTC)
Received: (qmail 47126 invoked by uid 500); 9 Sep 2014 19:09:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47058 invoked by uid 500); 9 Sep 2014 19:09:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47046 invoked by uid 99); 9 Sep 2014 19:09:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:09:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:09:40 +0000
Received: by mail-oa0-f47.google.com with SMTP id i7so12271176oag.20
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 12:09:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Au/gURXUclwqQlvghmWSp0mp7xxvrbANZFpmyVgn2Mk=;
        b=heFPOBngTF3BH4DMHh7cQGSW3yCfurRd3NZXt4IMD8toIQH3o7C1UD0w01nbdMyKsw
         l0lOXZ8TkqJRVqgJAvO4+gQzQ8yUD4MCizW2toEuGfPLyw5g+wOuCQ9TMYpJ4DWly22+
         TXtFBnBT6Vrx69dQlBkhCGa+84nVMMQ+9fMIR0YaX+IIYDo5yMUJK8p/rZgSfQFF70dN
         bGBWFGVSLg4y7EhWHSHev31oTMNXINeJG9bL/OOwjM3OS7/l/1iU3a56sdg+gpL1cpPp
         jeEbdF2G+QNUl6xK21aeKPj7yw5QxL1EmfaYEzn5Du7B5tF/lQ3YLwONoTQYrtCEBVQZ
         IKFw==
MIME-Version: 1.0
X-Received: by 10.60.37.9 with SMTP id u9mr8991945oej.18.1410289759512; Tue,
 09 Sep 2014 12:09:19 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 9 Sep 2014 12:09:19 -0700 (PDT)
In-Reply-To: <CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
Date: Tue, 9 Sep 2014 12:09:19 -0700
Message-ID: <CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Patrick Wendell <pwendell@gmail.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: Michael Armbrust <michael@databricks.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I think what Michael means is people often use this to read existing
partitioned Parquet tables that are defined in a Hive metastore rather
than data generated directly from within Spark and then reading it
back as a table. I'd expect the latter case to become more common, but
for now most users connect to an existing metastore.

I think you could go this route by creating a partitioned external
table based on the on-disk layout you create. The downside is that
you'd have to go through a hive metastore whereas what you are doing
now doesn't need hive at all.

We should also just fix the case you are mentioning where a union is
used directly from within spark. But that's the context.

- Patrick

On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org> wrote:
> Maybe I'm missing something, I thought parquet was generally a write-once
> format and the sqlContext interface to it seems that way as well.
>
> d1.saveAsParquetFile("/foo/d1")
>
> // another day, another table, with same schema
> d2.saveAsParquetFile("/foo/d2")
>
> Will give a directory structure like
>
> /foo/d1/_metadata
> /foo/d1/part-r-1.parquet
> /foo/d1/part-r-2.parquet
> /foo/d1/_SUCCESS
>
> /foo/d2/_metadata
> /foo/d2/part-r-1.parquet
> /foo/d2/part-r-2.parquet
> /foo/d2/_SUCCESS
>
> // ParquetFileReader will fail, because /foo/d1 is a directory, not a
> parquet partition
> sqlContext.parquetFile("/foo")
>
> // works, but has the noted lack of pushdown
> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>
>
> Is there another alternative?
>
>
>
> On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> I think usually people add these directories as multiple partitions of the
>> same table instead of union.  This actually allows us to efficiently prune
>> directories when reading in addition to standard column pruning.
>>
>> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
>> wrote:
>>
>>> I'm kind of surprised this was not run into before.  Do people not
>>> segregate their data by day/week in the HDFS directory structure?
>>>
>>>
>>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <michael@databricks.com>
>>> wrote:
>>>
>>>> Thanks!
>>>>
>>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
>>>> wrote:
>>>>
>>>> > Opened
>>>> >
>>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>> >
>>>> > I'll take a look at ColumnPruning and see what I can do
>>>> >
>>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>> michael@databricks.com>
>>>> > wrote:
>>>> >
>>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <cody@koeninger.org>
>>>> >> wrote:
>>>> >>>
>>>> >>> Is there a reason in general not to push projections and predicates
>>>> down
>>>> >>> into the individual ParquetTableScans in a union?
>>>> >>>
>>>> >>
>>>> >> This would be a great case to add to ColumnPruning.  Would be awesome
>>>> if
>>>> >> you could open a JIRA or even a PR :)
>>>> >>
>>>> >
>>>> >
>>>>
>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9382-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 19:16:03 2014
Return-Path: <dev-return-9382-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A15CC110C9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 19:16:03 +0000 (UTC)
Received: (qmail 70497 invoked by uid 500); 9 Sep 2014 19:16:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70426 invoked by uid 500); 9 Sep 2014 19:16:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70410 invoked by uid 99); 9 Sep 2014 19:16:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:16:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.43 as permitted sender)
Received: from [209.85.216.43] (HELO mail-qa0-f43.google.com) (209.85.216.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 19:15:36 +0000
Received: by mail-qa0-f43.google.com with SMTP id cm18so16399931qab.30
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 12:15:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=7pnhEOnD6uh6V6ojIyIVZzEikgMGZm/B3rzBFhMLFmc=;
        b=aRd8xtJZk/tJxVser2ElXKNLsII0auBVQB/OAyvQk8mEmM1FlXIgj+4iHqEtsz7uT7
         EniXM/JhjVuS7WREU7E7xENqTKlP7UGpvQcTmU1dHtZGGYo4kGhSRqbyG6RmZsie/EWw
         kUwjKmzHxEUMYGxEJHNlDkUcqXvzDCkxI4zAL7veTSQtwKI814TfPefCgOFeOOkQQGns
         gCNmTeHuKdwU7XgbO1qdJ15wia/R6N6Cpc6+seovhB3ACKOzhbLrO7Em15ooNpl2+Rjk
         FZIMIKzmwofW4G8RbQ2yBCaYEgdL65y097kNbfyy1/ToVKpGy6W7qFlWnss36w+iMD4j
         Al7w==
X-Gm-Message-State: ALoCoQmpMoL72mzTIaaKn2ciRVSmmthWvQNRApzbdsf9D5r3rQlsy6LjJkw0a+3hYXSQNOLC/2Co
MIME-Version: 1.0
X-Received: by 10.224.44.14 with SMTP id y14mr51131965qae.34.1410290135260;
 Tue, 09 Sep 2014 12:15:35 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Tue, 9 Sep 2014 12:15:35 -0700 (PDT)
In-Reply-To: <CA+B-+fxAA2mPO=cwmnw18UWE36BXnaAKWkQNf3BaC9iF7rQ8MQ@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
	<CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
	<CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
	<CA+B-+fxAA2mPO=cwmnw18UWE36BXnaAKWkQNf3BaC9iF7rQ8MQ@mail.gmail.com>
Date: Tue, 9 Sep 2014 12:15:35 -0700
Message-ID: <CACBYxKLd28eQ+z6VuvEWchNwu=QyQfb=57Zf71DeD=Th7+N41w@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc8d5e8af7100502a6c2c5
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc8d5e8af7100502a6c2c5
Content-Type: text/plain; charset=UTF-8

I would expect 2 GB would be enough or more than enough for 16 GB executors
(unless ALS is using a bunch of off-heap memory?).  You mentioned earlier
in this thread that the property wasn't showing up in the Environment tab.
 Are you sure it's making it in?

-Sandy

On Tue, Sep 9, 2014 at 11:58 AM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Hmm...I did try it increase to few gb but did not get a successful run
> yet...
>
> Any idea if I am using say 40 executors, each running 16GB, what's the
> typical spark.yarn.executor.memoryOverhead for say 100M x 10 M large
> matrices with say few billion ratings...
>
> On Tue, Sep 9, 2014 at 10:49 AM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> Hi Deb,
>>
>> The current state of the art is to increase
>> spark.yarn.executor.memoryOverhead until the job stops failing.  We do have
>> plans to try to automatically scale this based on the amount of memory
>> requested, but it will still just be a heuristic.
>>
>> -Sandy
>>
>> On Tue, Sep 9, 2014 at 7:32 AM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>>
>>> Hi Sandy,
>>>
>>> Any resolution for YARN failures ? It's a blocker for running spark on
>>> top of YARN.
>>>
>>> Thanks.
>>> Deb
>>>
>>> On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com>
>>> wrote:
>>>
>>>> Hi Deb,
>>>>
>>>> I think this may be the same issue as described in
>>>> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
>>>> container got killed by YARN because it used much more memory that it
>>>> requested. But we haven't figured out the root cause yet.
>>>>
>>>> +Sandy
>>>>
>>>> Best,
>>>> Xiangrui
>>>>
>>>> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <debasish.das83@gmail.com>
>>>> wrote:
>>>> > Hi,
>>>> >
>>>> > During the 4th ALS iteration, I am noticing that one of the executor
>>>> gets
>>>> > disconnected:
>>>> >
>>>> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
>>>> > SendingConnectionManagerId not found
>>>> >
>>>> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor 5
>>>> > disconnected, so removing it
>>>> >
>>>> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
>>>> executor 5
>>>> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client
>>>> disassociated
>>>> >
>>>> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5
>>>> (epoch 12)
>>>> > Any idea if this is a bug related to akka on YARN ?
>>>> >
>>>> > I am using master
>>>> >
>>>> > Thanks.
>>>> > Deb
>>>>
>>>
>>>
>>
>

--047d7bdc8d5e8af7100502a6c2c5--

From dev-return-9383-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 20:02:57 2014
Return-Path: <dev-return-9383-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 42D2811260
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 20:02:57 +0000 (UTC)
Received: (qmail 69850 invoked by uid 500); 9 Sep 2014 20:02:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69775 invoked by uid 500); 9 Sep 2014 20:02:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 69762 invoked by uid 99); 9 Sep 2014 20:02:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 20:02:55 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 20:02:30 +0000
Received: by mail-la0-f46.google.com with SMTP id pv20so20384118lab.33
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 13:02:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=nTjF2tnsobfeHgx63VcBzYhQ+jQs1DPqqh0f8nmx7gI=;
        b=DQ6TfteQmhb4hw69yEJLSVetO5Gi7ZViHwghRF9CV/72ewQJNjWYcdzX9tuiEjQpZe
         KTvkNVkjuP+NvMxBbe9S12IM5w6J2E8mNq3lO8TejsnBXlUXkNayFj2OVOpKwb8fNMQf
         fdxvJkePNsRHZRNYH7vKKvirBfRGmHtDP3gbGa4BaNycb81sjHAzRrcr4AKlOOwu7CpD
         2eaAN7dtSz6ALihacICpilfl2ypI5LirNfFOSoewcJGJGeQe049o2wnj6JZWYhFKrUTq
         Z1XxbUd75QqpeaLT+w4X+3RE6aFW3sUbHm+g1FDDlz5mQi7LqsrQm8nMDzI2FdzD/P1l
         +LGw==
X-Gm-Message-State: ALoCoQncbhlVgF+nkWIZOr+4+Z4gyMY5xlmwli+mzLRccAjcCbyVUB4Q+aUMBFfV0//ThIf+MWNn
X-Received: by 10.112.219.71 with SMTP id pm7mr35987316lbc.3.1410292948924;
 Tue, 09 Sep 2014 13:02:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Tue, 9 Sep 2014 13:02:08 -0700 (PDT)
In-Reply-To: <CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
 <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
 <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
 <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
 <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
 <CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
 <CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com> <CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 9 Sep 2014 13:02:08 -0700
Message-ID: <CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Patrick Wendell <pwendell@gmail.com>
Cc: Cody Koeninger <cody@koeninger.org>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3ce4c4014ad0502a76add
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3ce4c4014ad0502a76add
Content-Type: text/plain; charset=UTF-8

What Patrick said is correct.  Two other points:
 - In the 1.2 release we are hoping to beef up the support for working with
partitioned parquet independent of the metastore.
 - You can actually do operations like INSERT INTO for parquet tables to
add data.  This creates new parquet files for each insertion.  This will
break if there are multiple concurrent writers to the same table.

On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> I think what Michael means is people often use this to read existing
> partitioned Parquet tables that are defined in a Hive metastore rather
> than data generated directly from within Spark and then reading it
> back as a table. I'd expect the latter case to become more common, but
> for now most users connect to an existing metastore.
>
> I think you could go this route by creating a partitioned external
> table based on the on-disk layout you create. The downside is that
> you'd have to go through a hive metastore whereas what you are doing
> now doesn't need hive at all.
>
> We should also just fix the case you are mentioning where a union is
> used directly from within spark. But that's the context.
>
> - Patrick
>
> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
> wrote:
> > Maybe I'm missing something, I thought parquet was generally a write-once
> > format and the sqlContext interface to it seems that way as well.
> >
> > d1.saveAsParquetFile("/foo/d1")
> >
> > // another day, another table, with same schema
> > d2.saveAsParquetFile("/foo/d2")
> >
> > Will give a directory structure like
> >
> > /foo/d1/_metadata
> > /foo/d1/part-r-1.parquet
> > /foo/d1/part-r-2.parquet
> > /foo/d1/_SUCCESS
> >
> > /foo/d2/_metadata
> > /foo/d2/part-r-1.parquet
> > /foo/d2/part-r-2.parquet
> > /foo/d2/_SUCCESS
> >
> > // ParquetFileReader will fail, because /foo/d1 is a directory, not a
> > parquet partition
> > sqlContext.parquetFile("/foo")
> >
> > // works, but has the noted lack of pushdown
> >
> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
> >
> >
> > Is there another alternative?
> >
> >
> >
> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <michael@databricks.com
> >
> > wrote:
> >
> >> I think usually people add these directories as multiple partitions of
> the
> >> same table instead of union.  This actually allows us to efficiently
> prune
> >> directories when reading in addition to standard column pruning.
> >>
> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
> >> wrote:
> >>
> >>> I'm kind of surprised this was not run into before.  Do people not
> >>> segregate their data by day/week in the HDFS directory structure?
> >>>
> >>>
> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
> michael@databricks.com>
> >>> wrote:
> >>>
> >>>> Thanks!
> >>>>
> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
> >>>> wrote:
> >>>>
> >>>> > Opened
> >>>> >
> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
> >>>> >
> >>>> > I'll take a look at ColumnPruning and see what I can do
> >>>> >
> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
> >>>> michael@databricks.com>
> >>>> > wrote:
> >>>> >
> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
> cody@koeninger.org>
> >>>> >> wrote:
> >>>> >>>
> >>>> >>> Is there a reason in general not to push projections and
> predicates
> >>>> down
> >>>> >>> into the individual ParquetTableScans in a union?
> >>>> >>>
> >>>> >>
> >>>> >> This would be a great case to add to ColumnPruning.  Would be
> awesome
> >>>> if
> >>>> >> you could open a JIRA or even a PR :)
> >>>> >>
> >>>> >
> >>>> >
> >>>>
> >>>
> >>>
> >>
>

--001a11c3ce4c4014ad0502a76add--

From dev-return-9384-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 21:01:18 2014
Return-Path: <dev-return-9384-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8674311456
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 21:01:18 +0000 (UTC)
Received: (qmail 13095 invoked by uid 500); 9 Sep 2014 21:01:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13026 invoked by uid 500); 9 Sep 2014 21:01:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13015 invoked by uid 99); 9 Sep 2014 21:01:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:01:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:01:12 +0000
Received: by mail-la0-f42.google.com with SMTP id hz20so5234599lab.1
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 14:00:50 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=5uj0i+Lj/EtR4h0BNnEuLQ7ux4y+npHiKqfzb8lOTuY=;
        b=BVFIiTIIT8Hhu3a/MUwQTnH4LfrAXlBDBc1DHiWsv91tzJUnA5IpTH4/B9y8+lw2N2
         Da5x/02xLlZXA5CzKrW9XH16fAEheUl4Ym19p0W/BFyph7HEjUyClHIzMotuWdiaP3K6
         hzf9gnLusJ3lOfcaf1WraMK2RtmW+G5Awbl27cOtzwJQB5yuMqgmluPLtFIGW+jo87be
         Di/A/8T4W4buvfa8LzyR1Zmpi0wMmGoUXAllaaly1MoLgYOQgqb12hTdl9gXVTKtiubh
         OZg3r8ynWC7TdhZmn5NLyoKA27tGvSTzA27pIGLdg5nYpkphdq8CrhEukKx+3AL7UKYY
         jyuA==
X-Gm-Message-State: ALoCoQkJwEwMvopXLPcd+wlT4hKxZ5ifYb30fVzs+I/zzFGlRzRApPa8iOygO4md5pGxEWuQfYQU
X-Received: by 10.112.204.36 with SMTP id kv4mr18796257lbc.54.1410296450457;
 Tue, 09 Sep 2014 14:00:50 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.246.1 with HTTP; Tue, 9 Sep 2014 14:00:30 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 9 Sep 2014 14:00:30 -0700
Message-ID: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
Subject: yet another jenkins restart early thursday morning -- 730am PDT (and
 a brief update on our new jenkins infra)
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c3cf32f52fd30502a83a0b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3cf32f52fd30502a83a0b
Content-Type: text/plain; charset=UTF-8

since the power incident last thursday, the github pull request builder
plugin is still not really working 100%.  i found an open issue
w/jenkins[1] that could definitely be affecting us, i will be pausing
builds early thursday morning and then restarting jenkins.
i'll send out a reminder tomorrow, and if this causes any problems for you,
please let me know and we can work out a better time.

but, now for some good news!  yesterday morning, we racked and stacked the
systems for the new jenkins instance in the berkeley datacenter.  tomorrow
i should be able to log in to them and start getting them set up and
configured.  this is a major step in getting us in to a much more
'production' style environment!

anyways:  thanks for your patience, and i think we've all learned that hard
powering down your build system is a definite recipe for disaster.  :)

shane

[1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509

--001a11c3cf32f52fd30502a83a0b--

From dev-return-9385-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 21:05:02 2014
Return-Path: <dev-return-9385-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6498811487
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 21:05:02 +0000 (UTC)
Received: (qmail 24981 invoked by uid 500); 9 Sep 2014 21:05:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24908 invoked by uid 500); 9 Sep 2014 21:05:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24892 invoked by uid 99); 9 Sep 2014 21:05:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:05:00 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:04:35 +0000
Received: by mail-la0-f54.google.com with SMTP id b17so20516543lan.13
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 14:04:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=wRsV0M4d0C/caXUjCZ53Q9Oky2lIEEUwXcFs2tbh5Wc=;
        b=Ybspa5Rbpuv3iVHWkKazNmlRyMCTgUgeHCSkGCtWQ46cadCtKPNmE14hS6hnRRmvoT
         3mQEtlJUB6LKlJObDmDyxKlhgFekTNJ9KGKqyQX7DF1tppOfmVfehHNt5NJGxsJDEQgR
         VTYQhlvn1H5EIqRnyAinK3VCC+2CaXIueP87YiFaggqfGolv4vyJKo9KCfkqQcVcDLwt
         l/OlQ+6EeSrCv6NzJYc4B7sqIr7W4eaHLGT7AWPGXqgfY7+SNmPntYXYhDE2ZC5M0ho4
         +fJunX64mUi7vN/uGzbchFioeJiAx7pQWqwZRon1FNZa+5bZi5Qs+B/W2ZDxVvEgqDUp
         2n5Q==
MIME-Version: 1.0
X-Received: by 10.112.118.141 with SMTP id km13mr36409147lbb.37.1410296674739;
 Tue, 09 Sep 2014 14:04:34 -0700 (PDT)
Received: by 10.25.31.78 with HTTP; Tue, 9 Sep 2014 14:04:34 -0700 (PDT)
In-Reply-To: <CACBYxKLd28eQ+z6VuvEWchNwu=QyQfb=57Zf71DeD=Th7+N41w@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
	<CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
	<CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
	<CA+B-+fxAA2mPO=cwmnw18UWE36BXnaAKWkQNf3BaC9iF7rQ8MQ@mail.gmail.com>
	<CACBYxKLd28eQ+z6VuvEWchNwu=QyQfb=57Zf71DeD=Th7+N41w@mail.gmail.com>
Date: Tue, 9 Sep 2014 14:04:34 -0700
Message-ID: <CA+B-+fzLbDFarQL96hiQpY=Rh+O6MU83=xvoZrcuDParsR+2ow@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Debasish Das <debasish.das83@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfcfd7e536d370502a84897
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfcfd7e536d370502a84897
Content-Type: text/plain; charset=UTF-8

Last time it did not show up on environment tab but I will give it another
shot...Expected behavior is that this env variable will show up right ?

On Tue, Sep 9, 2014 at 12:15 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> I would expect 2 GB would be enough or more than enough for 16 GB
> executors (unless ALS is using a bunch of off-heap memory?).  You mentioned
> earlier in this thread that the property wasn't showing up in the
> Environment tab.  Are you sure it's making it in?
>
> -Sandy
>
> On Tue, Sep 9, 2014 at 11:58 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
>
>> Hmm...I did try it increase to few gb but did not get a successful run
>> yet...
>>
>> Any idea if I am using say 40 executors, each running 16GB, what's the
>> typical spark.yarn.executor.memoryOverhead for say 100M x 10 M large
>> matrices with say few billion ratings...
>>
>> On Tue, Sep 9, 2014 at 10:49 AM, Sandy Ryza <sandy.ryza@cloudera.com>
>> wrote:
>>
>>> Hi Deb,
>>>
>>> The current state of the art is to increase
>>> spark.yarn.executor.memoryOverhead until the job stops failing.  We do have
>>> plans to try to automatically scale this based on the amount of memory
>>> requested, but it will still just be a heuristic.
>>>
>>> -Sandy
>>>
>>> On Tue, Sep 9, 2014 at 7:32 AM, Debasish Das <debasish.das83@gmail.com>
>>> wrote:
>>>
>>>> Hi Sandy,
>>>>
>>>> Any resolution for YARN failures ? It's a blocker for running spark on
>>>> top of YARN.
>>>>
>>>> Thanks.
>>>> Deb
>>>>
>>>> On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Deb,
>>>>>
>>>>> I think this may be the same issue as described in
>>>>> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
>>>>> container got killed by YARN because it used much more memory that it
>>>>> requested. But we haven't figured out the root cause yet.
>>>>>
>>>>> +Sandy
>>>>>
>>>>> Best,
>>>>> Xiangrui
>>>>>
>>>>> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <
>>>>> debasish.das83@gmail.com> wrote:
>>>>> > Hi,
>>>>> >
>>>>> > During the 4th ALS iteration, I am noticing that one of the executor
>>>>> gets
>>>>> > disconnected:
>>>>> >
>>>>> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
>>>>> > SendingConnectionManagerId not found
>>>>> >
>>>>> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor 5
>>>>> > disconnected, so removing it
>>>>> >
>>>>> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
>>>>> executor 5
>>>>> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client
>>>>> disassociated
>>>>> >
>>>>> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5
>>>>> (epoch 12)
>>>>> > Any idea if this is a bug related to akka on YARN ?
>>>>> >
>>>>> > I am using master
>>>>> >
>>>>> > Thanks.
>>>>> > Deb
>>>>>
>>>>
>>>>
>>>
>>
>

--047d7bfcfd7e536d370502a84897--

From dev-return-9386-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 21:39:53 2014
Return-Path: <dev-return-9386-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3B552115A7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 21:39:53 +0000 (UTC)
Received: (qmail 13176 invoked by uid 500); 9 Sep 2014 21:39:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13108 invoked by uid 500); 9 Sep 2014 21:39:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13092 invoked by uid 99); 9 Sep 2014 21:39:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:39:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chester@alpinenow.com designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 21:39:47 +0000
Received: by mail-la0-f42.google.com with SMTP id hz20so5283537lab.1
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 14:39:26 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=afSub29vDE+Q/hwRiknY4juB8osVuTvgLvMYIx60Qx8=;
        b=aCcWfGeNbWsodAe1BSKV1YKzBZVHPPN5Vks8jrVOgIyYMRta/EFj8DR/XFabPDIjSz
         cgmUCGvBEbPhLDkx40F1TUra/hz8PAAy3Hz0qg/OaYwFUfijbjPjLcdBYBY1RTGYz06W
         +ugtOv9F3+7cF5QAkQLZc1ZCA+l7SZtaMiS/ohiV0RVVpWui3X3qzz8SykJvd1VXPLek
         fYShJaZ/EnrmGJH7Eicq7hLvJ0N3k6c3yP7kJ0aSRRoCosc6k4G0qZbmUNlitZqrw2de
         xFiss5P0nW2TU4EMjrlsLnD45kMH9q/mdF+QiyqSSXR5AOCyuirbQszvbP+7Eywd+HCn
         mASA==
X-Gm-Message-State: ALoCoQl3b1AF6HcTue3xgvg3dF7i53oXH5E93ysdZRDZjTFS5MVnuhqQ9rvnsb/LorZmj24Y68bz
MIME-Version: 1.0
X-Received: by 10.112.204.36 with SMTP id kv4mr18928083lbc.54.1410298766282;
 Tue, 09 Sep 2014 14:39:26 -0700 (PDT)
Received: by 10.25.217.206 with HTTP; Tue, 9 Sep 2014 14:39:26 -0700 (PDT)
In-Reply-To: <CAMAsSd+S6vMjggFRZYWft_96sXETZniFUr4WZKRZX8nODUYNRw@mail.gmail.com>
References: <CABPQxsvVqzSisPn4GukorkUcfSJgkwco6XW9m1McF2VkT4BS1Q@mail.gmail.com>
	<CAMAsSd+S6vMjggFRZYWft_96sXETZniFUr4WZKRZX8nODUYNRw@mail.gmail.com>
Date: Tue, 9 Sep 2014 14:39:26 -0700
Message-ID: <CAPYnQ0UW2H3MgvPQR6cLzEpJmWPr69pKoLtaLtq6-jJEmDdRLg@mail.gmail.com>
Subject: Re: RFC: Deprecating YARN-alpha API's
From: Chester Chen <chester@alpinenow.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3cf32fde8630502a8c432
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3cf32fde8630502a8c432
Content-Type: text/plain; charset=UTF-8

We were using it until recently, we are talking to our customers and see if
we can get off it.

Chester
Alpine Data Labs



On Tue, Sep 9, 2014 at 10:59 AM, Sean Owen <sowen@cloudera.com> wrote:

> FWIW consensus from Cloudera folk seems to be that there's no need or
> demand on this end for YARN alpha. It wouldn't have an impact if it
> were removed sooner even.
>
> It will be a small positive to reduce complexity by removing this
> support, making it a little easier to develop for current YARN APIs.
>
> On Tue, Sep 9, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hi Everyone,
> >
> > This is a call to the community for comments on SPARK-3445 [1]. In a
> > nutshell, we are trying to figure out timelines for deprecation of the
> > YARN-alpha API's as Yahoo is now moving off of them. It's helpful for
> > us to have a sense of whether anyone else uses these.
> >
> > Please comment on the JIRA if you have feeback, thanks!
> >
> > [1] https://issues.apache.org/jira/browse/SPARK-3445
> >
> > - Patrick
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c3cf32fde8630502a8c432--

From dev-return-9387-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep  9 23:10:20 2014
Return-Path: <dev-return-9387-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 514431189B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  9 Sep 2014 23:10:20 +0000 (UTC)
Received: (qmail 45728 invoked by uid 500); 9 Sep 2014 23:10:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45656 invoked by uid 500); 9 Sep 2014 23:10:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45645 invoked by uid 99); 9 Sep 2014 23:10:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 23:10:17 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.219.50] (HELO mail-oa0-f50.google.com) (209.85.219.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 09 Sep 2014 23:09:51 +0000
Received: by mail-oa0-f50.google.com with SMTP id o6so12354720oag.23
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 16:09:48 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=18OZY0oGOrpK4Ou4g5NeZUrUQM1jxwYTTe2XZcb+d2k=;
        b=kQ+T4Aw904hS7zlnJEj64aI8vAslBZdep28kOYZn0kvUwS8lUbcD0L+5vdOybx360o
         YikLcjUQHH3fBomansrjJqwZ9I/6ukWRAAFs6SPjVEUQQNL8ILAuyrQiqtxCi3gHa5p8
         Vt3PZYNhGyYBKD12yn2TvvqRNUz6RvRBDAO8X99AugGY9CgfKkWDSamUgZOTutrQV6Mg
         xNpZO6KhNxBmxbosxc5ImcxeuPJmPUj1GUnbjczdFt0boCBYcknMNk4Fxtl8VZUFlpnQ
         Wtb7mUc5mgdta+LSYDw2Xp2F2MP9Y51pyk5Icg3NvdVsKEXaxpZnt8kXukricUN7/2PJ
         U6TA==
X-Gm-Message-State: ALoCoQmECmB3sdv1l6HNTOU8wAuCqFcXamIFEV2oc2u+VeyxtRxAXkKuzGjFnfKFOvr0erRDYe0c
MIME-Version: 1.0
X-Received: by 10.182.79.65 with SMTP id h1mr42028253obx.53.1410304188734;
 Tue, 09 Sep 2014 16:09:48 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Tue, 9 Sep 2014 16:09:48 -0700 (PDT)
In-Reply-To: <CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
	<CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
	<CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
Date: Tue, 9 Sep 2014 18:09:48 -0500
Message-ID: <CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b2e4ede31f95b0502aa083b
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b2e4ede31f95b0502aa083b
Content-Type: text/plain; charset=UTF-8

Ok, so looking at the optimizer code for the first time and trying the
simplest rule that could possibly work,

object UnionPushdown extends Rule[LogicalPlan] {
  def apply(plan: LogicalPlan): LogicalPlan = plan transform {
    // Push down filter into
union
    case f @ Filter(condition, u @ Union(left, right)) =>

      u.copy(left = f.copy(child = left), right = f.copy(child =
right))


    // Push down projection into
union
    case p @ Project(projectList, u @ Union(left, right)) =>
      u.copy(left = p.copy(child = left), right = p.copy(child =
right))

}

}


If I try manually applying that rule to a logical plan in the repl, it
produces the query shape I'd expect, and executing that plan results in
parquet pushdowns as I'd expect.

But adding those cases to ColumnPruning results in a runtime exception
(below)

I can keep digging, but it seems like I'm missing some obvious initial
context around naming of attributes.  If you can provide any pointers to
speed me on my way I'd appreciate it.


java.lang.AssertionError: assertion failed: ArrayBuffer() + ArrayBuffer()
!= WrappedArray(name#6, age#7), List(name#9, age#10, phones#11)
        at scala.Predef$.assert(Predef.scala:179)
        at
org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
        at
org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
        at
org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
        at
org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
        at
org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
        at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
        at
org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
        at
org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at
scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at
org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
        at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
        at
org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
        at
org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
        at
org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
        at
org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
        at
org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
        at
org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)




On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <michael@databricks.com>
wrote:

> What Patrick said is correct.  Two other points:
>  - In the 1.2 release we are hoping to beef up the support for working
> with partitioned parquet independent of the metastore.
>  - You can actually do operations like INSERT INTO for parquet tables to
> add data.  This creates new parquet files for each insertion.  This will
> break if there are multiple concurrent writers to the same table.
>
> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
>> I think what Michael means is people often use this to read existing
>> partitioned Parquet tables that are defined in a Hive metastore rather
>> than data generated directly from within Spark and then reading it
>> back as a table. I'd expect the latter case to become more common, but
>> for now most users connect to an existing metastore.
>>
>> I think you could go this route by creating a partitioned external
>> table based on the on-disk layout you create. The downside is that
>> you'd have to go through a hive metastore whereas what you are doing
>> now doesn't need hive at all.
>>
>> We should also just fix the case you are mentioning where a union is
>> used directly from within spark. But that's the context.
>>
>> - Patrick
>>
>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>> > Maybe I'm missing something, I thought parquet was generally a
>> write-once
>> > format and the sqlContext interface to it seems that way as well.
>> >
>> > d1.saveAsParquetFile("/foo/d1")
>> >
>> > // another day, another table, with same schema
>> > d2.saveAsParquetFile("/foo/d2")
>> >
>> > Will give a directory structure like
>> >
>> > /foo/d1/_metadata
>> > /foo/d1/part-r-1.parquet
>> > /foo/d1/part-r-2.parquet
>> > /foo/d1/_SUCCESS
>> >
>> > /foo/d2/_metadata
>> > /foo/d2/part-r-1.parquet
>> > /foo/d2/part-r-2.parquet
>> > /foo/d2/_SUCCESS
>> >
>> > // ParquetFileReader will fail, because /foo/d1 is a directory, not a
>> > parquet partition
>> > sqlContext.parquetFile("/foo")
>> >
>> > // works, but has the noted lack of pushdown
>> >
>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>> >
>> >
>> > Is there another alternative?
>> >
>> >
>> >
>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>> michael@databricks.com>
>> > wrote:
>> >
>> >> I think usually people add these directories as multiple partitions of
>> the
>> >> same table instead of union.  This actually allows us to efficiently
>> prune
>> >> directories when reading in addition to standard column pruning.
>> >>
>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
>> >> wrote:
>> >>
>> >>> I'm kind of surprised this was not run into before.  Do people not
>> >>> segregate their data by day/week in the HDFS directory structure?
>> >>>
>> >>>
>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>> michael@databricks.com>
>> >>> wrote:
>> >>>
>> >>>> Thanks!
>> >>>>
>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org>
>> >>>> wrote:
>> >>>>
>> >>>> > Opened
>> >>>> >
>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>> >>>> >
>> >>>> > I'll take a look at ColumnPruning and see what I can do
>> >>>> >
>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>> >>>> michael@databricks.com>
>> >>>> > wrote:
>> >>>> >
>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>> cody@koeninger.org>
>> >>>> >> wrote:
>> >>>> >>>
>> >>>> >>> Is there a reason in general not to push projections and
>> predicates
>> >>>> down
>> >>>> >>> into the individual ParquetTableScans in a union?
>> >>>> >>>
>> >>>> >>
>> >>>> >> This would be a great case to add to ColumnPruning.  Would be
>> awesome
>> >>>> if
>> >>>> >> you could open a JIRA or even a PR :)
>> >>>> >>
>> >>>> >
>> >>>> >
>> >>>>
>> >>>
>> >>>
>> >>
>>
>
>

--047d7b2e4ede31f95b0502aa083b--

From dev-return-9388-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 00:14:32 2014
Return-Path: <dev-return-9388-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1B19B11AD9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 00:14:32 +0000 (UTC)
Received: (qmail 70306 invoked by uid 500); 10 Sep 2014 00:14:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70242 invoked by uid 500); 10 Sep 2014 00:14:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70230 invoked by uid 99); 10 Sep 2014 00:14:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:14:30 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sudershan.malpani@gmail.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:14:24 +0000
Received: by mail-pd0-f169.google.com with SMTP id fp1so4441317pdb.28
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 17:14:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:from:content-type:message-id:date:to
         :content-transfer-encoding:mime-version;
        bh=XTudFLurK/TdCMK0tRLxBau9Qlp+XZ0zDJRIZ1h9N1U=;
        b=XiKWu4CKCqsw/kE2fWWqasFLvl32coPi4xVoXM4R7v/yuS/Hg6uJzOCldu0woqkRbz
         e6s8gg46fA9ltUgARDfiHWCa86nmu5POnt2SMjHRt1orQiD0ZVr7UjCTxvLMIf+UyKoa
         9r8x0XMFZW9uZc13flB1UPWvGGUY9NZUz2c3mS7oAlb7wLOG8btM5DrQVtCU0l7At0u/
         08NBw9+uJ7rkJWa3widNcFvhFpLgvkmwxbeixQUpIbAm1m9vohxgz3MlyQon9WO5WSuh
         bCH59FqmCF4nGVggr6eLoAPtfNWoa7/+jIPVfS7lKHx6nJHD0fT1pyTZHEtwjYJPfzLE
         NSyw==
X-Received: by 10.66.149.70 with SMTP id ty6mr3114736pab.31.1410308043924;
        Tue, 09 Sep 2014 17:14:03 -0700 (PDT)
Received: from [10.194.27.221] (mobile-166-171-249-033.mycingular.net. [166.171.249.33])
        by mx.google.com with ESMTPSA id ke2sm12623579pbc.90.2014.09.09.17.14.02
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 09 Sep 2014 17:14:03 -0700 (PDT)
Subject: Junit spark tests
From: Sudershan Malpani <sudershan.malpani@gmail.com>
Content-Type: text/plain;
	charset=us-ascii
X-Mailer: iPhone Mail (11D257)
Message-Id: <AEE6386C-E36E-477A-B69E-9663BD89B807@gmail.com>
Date: Tue, 9 Sep 2014 17:14:01 -0700
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Mime-Version: 1.0 (1.0)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I am calling an object which in turn is calling a method inside a map RDD in=
 spark. While writing the tests how can I mock that object's call? Currently=
 I did doNothing().when(class).method() is called but it is giving task not s=
erializable exception. I tried making the class both spy and mock.=20

Sudershan Malpani
Sent from my iPhone=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9389-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 00:17:34 2014
Return-Path: <dev-return-9389-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 850DD11AE3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 00:17:34 +0000 (UTC)
Received: (qmail 75871 invoked by uid 500); 10 Sep 2014 00:17:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75797 invoked by uid 500); 10 Sep 2014 00:17:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75786 invoked by uid 99); 10 Sep 2014 00:17:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:17:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:17:05 +0000
Received: by mail-qa0-f54.google.com with SMTP id x12so16795874qac.27
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 17:17:03 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=TfKaK7G8oU40jOL8aRJiNe84XIDBTZ3aZ4hz2puwLFQ=;
        b=cgZWqubGNL6TJWsOBXIny6ea1wscS18qSvnTL9vhps767Du96uba78Fs0FLAmcHFyU
         E7IuRkzfjtR2fdTeijE6pM/gSLU+zbBAPn/PKLB11L957Ys275eWpejGehBEeO/hbcz7
         qy2V3WUNj2wablK/1IdKniCP14ADWXCa4OHvA2fXTcOHZfp8C+zZq6T4j8JMkOJtlxR1
         gpdl+YEUnHTJTTDLMun8g2phSj+D9tkkfM8Mgtpt5FcTncwSlczl0nEB7VkbMWEuOgf8
         dUgInBBqhrg4Us5UCxAm1G/yUfo8/OAUEJULGRnxAW9HrmX1Rd4WDDQ5RZyh0XDbOFac
         E9og==
X-Gm-Message-State: ALoCoQls0cwRJhEsjZ63/XP4dDwWTn0+6fbaW8mGwmdRcvU5JrWNDs2QoSeQBHsloD6DkFG8Ovio
X-Received: by 10.140.30.136 with SMTP id d8mr54936178qgd.55.1410308223606;
 Tue, 09 Sep 2014 17:17:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Tue, 9 Sep 2014 17:16:43 -0700 (PDT)
In-Reply-To: <AEE6386C-E36E-477A-B69E-9663BD89B807@gmail.com>
References: <AEE6386C-E36E-477A-B69E-9663BD89B807@gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 9 Sep 2014 17:16:43 -0700
Message-ID: <CAPh_B=ZDGKPCMKvuVFvev5yX3TJbXGae=w=LdOq+10nEH1dhzQ@mail.gmail.com>
Subject: Re: Junit spark tests
To: Sudershan Malpani <sudershan.malpani@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a921ab13cef0502aaf8ce
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a921ab13cef0502aaf8ce
Content-Type: text/plain; charset=UTF-8

Can you be a little bit more specific, maybe give a code snippet?


On Tue, Sep 9, 2014 at 5:14 PM, Sudershan Malpani <
sudershan.malpani@gmail.com> wrote:

> Hi all,
>
> I am calling an object which in turn is calling a method inside a map RDD
> in spark. While writing the tests how can I mock that object's call?
> Currently I did doNothing().when(class).method() is called but it is giving
> task not serializable exception. I tried making the class both spy and mock.
>
> Sudershan Malpani
> Sent from my iPhone
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113a921ab13cef0502aaf8ce--

From dev-return-9390-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 00:39:30 2014
Return-Path: <dev-return-9390-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 52CFA11B83
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 00:39:30 +0000 (UTC)
Received: (qmail 25021 invoked by uid 500); 10 Sep 2014 00:39:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24951 invoked by uid 500); 10 Sep 2014 00:39:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24938 invoked by uid 99); 10 Sep 2014 00:39:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:39:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sudershan.malpani@gmail.com designates 209.85.220.42 as permitted sender)
Received: from [209.85.220.42] (HELO mail-pa0-f42.google.com) (209.85.220.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 00:39:00 +0000
Received: by mail-pa0-f42.google.com with SMTP id lj1so5275470pab.15
        for <dev@spark.apache.org>; Tue, 09 Sep 2014 17:38:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=1toVJVq/AhOimlEJYJ1idsZ8BoBgV44KcM4paz8c9NY=;
        b=eD1x9Da0DagIOyEkcQw6QzBDyj3/b53n8t7GPI7oro6CtaiOYeqEwTuO41QOcE4P8R
         FIUa5o3eoUUMuplAAsVqppvTI3lLG57YrejkLnmgXWeb/NsgJW/BQdImlFL2WTU3+2uq
         q21uMdiL4Vit4/rAsc6yUY+R5beBUUHn+gvUMY+WXjyMA8KQ5SDrT/KiHFQfYPI41rsw
         R0QzNj6t2K1hlwZruyp1bVdH4FEGCHNejAuP/ih5+lHF/3+J8Qsnnx43g+U+F4yKW14N
         yL6A5jRjdmHR66S3o9o5/XK8vBW42hjWOIgobMg6V5uzy3GQwe5X78KWA2YlgenKKoRk
         uv/w==
X-Received: by 10.70.42.135 with SMTP id o7mr20780606pdl.141.1410309539403;
        Tue, 09 Sep 2014 17:38:59 -0700 (PDT)
Received: from [10.194.27.221] (mobile-166-171-249-033.mycingular.net. [166.171.249.33])
        by mx.google.com with ESMTPSA id ou6sm12652027pbb.88.2014.09.09.17.38.58
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 09 Sep 2014 17:38:58 -0700 (PDT)
References: <AEE6386C-E36E-477A-B69E-9663BD89B807@gmail.com> <CAPh_B=ZDGKPCMKvuVFvev5yX3TJbXGae=w=LdOq+10nEH1dhzQ@mail.gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <CAPh_B=ZDGKPCMKvuVFvev5yX3TJbXGae=w=LdOq+10nEH1dhzQ@mail.gmail.com>
Content-Type: multipart/alternative;
	boundary=Apple-Mail-11C95BD1-C248-4415-B824-6572C3F59E92
Content-Transfer-Encoding: 7bit
Message-Id: <2672D68B-6035-4ABF-B2CD-B2AF3462A0C6@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
X-Mailer: iPhone Mail (11D257)
From: Sudershan Malpani <sudershan.malpani@gmail.com>
Subject: Re: Junit spark tests
Date: Tue, 9 Sep 2014 17:38:57 -0700
To: Reynold Xin <rxin@databricks.com>
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-11C95BD1-C248-4415-B824-6572C3F59E92
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable

Class1.java

@Autowired
Private ClassX cx;

Public list method1(JavaPairRDD data){
     List list1 =3D new ArrayList();
     List list2 =3D new ArrayList();
     JavaPairRDD computed =3D data.map(
            new Function<Tuple2<object, list>>() {
                Public List call(object obj) throws exception {
              cx.method2(list2);
           Return list1;
}});
    Return computed.flatMap(new FlatMapfunc() { do something }}).collect();
  }
}

Class1Test.java

@Mock
Private ClassX cx;

@InjectMocks
Private Class1 c1;

@Before
Public void init() {
  Super.init();
   Sc =3D getSparkContext();
   doNothing().when(cx).method2(Collections.<object>emptyList());
}

@Test
Public void testMethod1() {
   JavaRDD alldata =3D Sc.paraalelize("");
   JavaPairRDD data =3D createrdd(alldata);
   c1.method1(rdd);
}
  =20


Sudershan Malpani
Sent from my iPhone

> On Sep 9, 2014, at 5:16 PM, Reynold Xin <rxin@databricks.com> wrote:
>=20
> Can you be a little bit more specific, maybe give a code snippet?
>=20
>=20
>> On Tue, Sep 9, 2014 at 5:14 PM, Sudershan Malpani <sudershan.malpani@gmai=
l.com> wrote:
>> Hi all,
>>=20
>> I am calling an object which in turn is calling a method inside a map RDD=
 in spark. While writing the tests how can I mock that object's call? Curren=
tly I did doNothing().when(class).method() is called but it is giving task n=
ot serializable exception. I tried making the class both spy and mock.
>>=20
>> Sudershan Malpani
>> Sent from my iPhone
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>=20

--Apple-Mail-11C95BD1-C248-4415-B824-6572C3F59E92--

From dev-return-9391-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 13:19:32 2014
Return-Path: <dev-return-9391-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C953111FC3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 13:19:32 +0000 (UTC)
Received: (qmail 70178 invoked by uid 500); 10 Sep 2014 13:19:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70111 invoked by uid 500); 10 Sep 2014 13:19:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70098 invoked by uid 99); 10 Sep 2014 13:19:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 13:19:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 13:19:26 +0000
Received: by mail-oi0-f42.google.com with SMTP id e131so4512343oig.15
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 06:19:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=ePJ9WKdTjxumnDu/Jh6o664FAzxZOslPpGe/db/v0X4=;
        b=bP6E1NbdpxQAiVMYbB0KRutE/pUpDeBitYmLd2kz8wVBl2HjtjGBCwfOJhg/Pv/8Ir
         5ysPHBhNn/cp9B/zlPyhSDsAYFixjuSbJBr1kb8nc3AO5o3g3Eg3yzTpARkuEpFRy1/J
         xjqU+TPDdfap23pzACoxCPQiLTBBkxHAj2I1zEuZdCeVikiC1ThNGQiI8up8BTlLH4pj
         /PgGphREIUhYrgCl56rCxQOL+lMrtZeMUxFvLloT09HwwlTF+Sog3Xb1fc8Fo4K5r9ut
         bHXkKA5M8EA5nfS0/LA3+OL57Wi8YReUQxxSgmtIyTFKPwXVIucHZr0kqpDNoKHrwZWg
         VWRA==
X-Gm-Message-State: ALoCoQm09ivANzWNzPmn5JFlij4AfVPXD9fvDb3t9OaI0eENAHCsnMuiv/yJnEYPLFe0U0XP11Ly
MIME-Version: 1.0
X-Received: by 10.182.44.135 with SMTP id e7mr45458839obm.18.1410355145471;
 Wed, 10 Sep 2014 06:19:05 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Wed, 10 Sep 2014 06:19:05 -0700 (PDT)
In-Reply-To: <CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
	<CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
	<CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
	<CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
Date: Wed, 10 Sep 2014 08:19:05 -0500
Message-ID: <CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3075c740f3e0502b5e5ad
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3075c740f3e0502b5e5ad
Content-Type: text/plain; charset=UTF-8

So the obvious thing I was missing is that the analyzer has already
resolved attributes by the time the optimizer runs, so the references in
the filter / projection need to be fixed up to match the children.

Created a PR, let me know if there's a better way to do it.  I'll see about
testing performance against some actual data sets.

On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org> wrote:

> Ok, so looking at the optimizer code for the first time and trying the
> simplest rule that could possibly work,
>
> object UnionPushdown extends Rule[LogicalPlan] {
>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>     // Push down filter into
> union
>     case f @ Filter(condition, u @ Union(left, right)) =>
>
>       u.copy(left = f.copy(child = left), right = f.copy(child =
> right))
>
>
>     // Push down projection into
> union
>     case p @ Project(projectList, u @ Union(left, right)) =>
>       u.copy(left = p.copy(child = left), right = p.copy(child =
> right))
>
> }
>
> }
>
>
> If I try manually applying that rule to a logical plan in the repl, it
> produces the query shape I'd expect, and executing that plan results in
> parquet pushdowns as I'd expect.
>
> But adding those cases to ColumnPruning results in a runtime exception
> (below)
>
> I can keep digging, but it seems like I'm missing some obvious initial
> context around naming of attributes.  If you can provide any pointers to
> speed me on my way I'd appreciate it.
>
>
> java.lang.AssertionError: assertion failed: ArrayBuffer() + ArrayBuffer()
> != WrappedArray(name#6, age#7), List(name#9, age#10, phones#11)
>         at scala.Predef$.assert(Predef.scala:179)
>         at
> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>         at
> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>         at
> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>         at
> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>         at
> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>         at
> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>         at
> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>         at
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>         at
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>         at scala.collection.immutable.List.foreach(List.scala:318)
>         at
> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>         at scala.collection.AbstractTraversable.map(Traversable.scala:105)
>         at
> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>         at
> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>         at
> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>         at
> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>         at
> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>         at
> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>         at
> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>
>
>
>
> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> What Patrick said is correct.  Two other points:
>>  - In the 1.2 release we are hoping to beef up the support for working
>> with partitioned parquet independent of the metastore.
>>  - You can actually do operations like INSERT INTO for parquet tables to
>> add data.  This creates new parquet files for each insertion.  This will
>> break if there are multiple concurrent writers to the same table.
>>
>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>>> I think what Michael means is people often use this to read existing
>>> partitioned Parquet tables that are defined in a Hive metastore rather
>>> than data generated directly from within Spark and then reading it
>>> back as a table. I'd expect the latter case to become more common, but
>>> for now most users connect to an existing metastore.
>>>
>>> I think you could go this route by creating a partitioned external
>>> table based on the on-disk layout you create. The downside is that
>>> you'd have to go through a hive metastore whereas what you are doing
>>> now doesn't need hive at all.
>>>
>>> We should also just fix the case you are mentioning where a union is
>>> used directly from within spark. But that's the context.
>>>
>>> - Patrick
>>>
>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>> wrote:
>>> > Maybe I'm missing something, I thought parquet was generally a
>>> write-once
>>> > format and the sqlContext interface to it seems that way as well.
>>> >
>>> > d1.saveAsParquetFile("/foo/d1")
>>> >
>>> > // another day, another table, with same schema
>>> > d2.saveAsParquetFile("/foo/d2")
>>> >
>>> > Will give a directory structure like
>>> >
>>> > /foo/d1/_metadata
>>> > /foo/d1/part-r-1.parquet
>>> > /foo/d1/part-r-2.parquet
>>> > /foo/d1/_SUCCESS
>>> >
>>> > /foo/d2/_metadata
>>> > /foo/d2/part-r-1.parquet
>>> > /foo/d2/part-r-2.parquet
>>> > /foo/d2/_SUCCESS
>>> >
>>> > // ParquetFileReader will fail, because /foo/d1 is a directory, not a
>>> > parquet partition
>>> > sqlContext.parquetFile("/foo")
>>> >
>>> > // works, but has the noted lack of pushdown
>>> >
>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>> >
>>> >
>>> > Is there another alternative?
>>> >
>>> >
>>> >
>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>> michael@databricks.com>
>>> > wrote:
>>> >
>>> >> I think usually people add these directories as multiple partitions
>>> of the
>>> >> same table instead of union.  This actually allows us to efficiently
>>> prune
>>> >> directories when reading in addition to standard column pruning.
>>> >>
>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
>>> >> wrote:
>>> >>
>>> >>> I'm kind of surprised this was not run into before.  Do people not
>>> >>> segregate their data by day/week in the HDFS directory structure?
>>> >>>
>>> >>>
>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>> michael@databricks.com>
>>> >>> wrote:
>>> >>>
>>> >>>> Thanks!
>>> >>>>
>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <cody@koeninger.org
>>> >
>>> >>>> wrote:
>>> >>>>
>>> >>>> > Opened
>>> >>>> >
>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>> >>>> >
>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>> >>>> >
>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>> >>>> michael@databricks.com>
>>> >>>> > wrote:
>>> >>>> >
>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>> cody@koeninger.org>
>>> >>>> >> wrote:
>>> >>>> >>>
>>> >>>> >>> Is there a reason in general not to push projections and
>>> predicates
>>> >>>> down
>>> >>>> >>> into the individual ParquetTableScans in a union?
>>> >>>> >>>
>>> >>>> >>
>>> >>>> >> This would be a great case to add to ColumnPruning.  Would be
>>> awesome
>>> >>>> if
>>> >>>> >> you could open a JIRA or even a PR :)
>>> >>>> >>
>>> >>>> >
>>> >>>> >
>>> >>>>
>>> >>>
>>> >>>
>>> >>
>>>
>>
>>
>

--001a11c3075c740f3e0502b5e5ad--

From dev-return-9392-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 16:32:04 2014
Return-Path: <dev-return-9392-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1495D1177F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 16:32:04 +0000 (UTC)
Received: (qmail 27338 invoked by uid 500); 10 Sep 2014 16:32:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27263 invoked by uid 500); 10 Sep 2014 16:32:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27249 invoked by uid 99); 10 Sep 2014 16:32:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:32:03 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:31:59 +0000
Received: by mail-oi0-f42.google.com with SMTP id e131so4662438oig.29
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 09:31:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=MARpFKGaGtDyhi9hF9hdUSTf1LQ/kcvgPSbRvwIso9s=;
        b=hbbOjMWFe4adQoejFj9yHEeaDmYuyHLsZTS2mb10LVq5aPafjtVmhQ1qa7JP2Og0XT
         1RrUg99hkHVqGedDIenF8UIQp60LItmC6AO9WPZ/HFT4eKEwLUteJDKmLMB0vai0O62n
         bLNNaECeSB7PxfJxBXILwnbiYYXnbR4Cp21YDyUPT5Wj5quAWzC8LXR09winWB1zV5/V
         eVSY3io64Wy95kA969AS7l7oaQui9Q3/+hmIyVcToyx9nj08pQyDDKlvAcgq5IMgTqWK
         DtxrvW/VaSz67Y99XdlvxFMnTfbL7Dt7488Kf9QU/jVrNTKG1ON0NQmByLFdCkX9uNu4
         Abbw==
X-Gm-Message-State: ALoCoQl0Gre/K/2H8bmhZV43CIoHkmbYOSD9YqW3SpSvD0m1NzIE4wx+pCb8bqpRu0hGVan5LCqD
MIME-Version: 1.0
X-Received: by 10.60.174.3 with SMTP id bo3mr47308502oec.31.1410366697634;
 Wed, 10 Sep 2014 09:31:37 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Wed, 10 Sep 2014 09:31:37 -0700 (PDT)
In-Reply-To: <CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
	<CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
	<CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
	<CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
	<CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
Date: Wed, 10 Sep 2014 11:31:37 -0500
Message-ID: <CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011844ce041a750502b896d8
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011844ce041a750502b896d8
Content-Type: text/plain; charset=UTF-8

Tested the patch against a cluster with some real data.  Initial results
seem like going from one table to a union of 2 tables is now closer to a
doubling of query time as expected, instead of 5 to 10x.

Let me know if you see any issues with that PR.

On Wed, Sep 10, 2014 at 8:19 AM, Cody Koeninger <cody@koeninger.org> wrote:

> So the obvious thing I was missing is that the analyzer has already
> resolved attributes by the time the optimizer runs, so the references in
> the filter / projection need to be fixed up to match the children.
>
> Created a PR, let me know if there's a better way to do it.  I'll see
> about testing performance against some actual data sets.
>
> On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org> wrote:
>
>> Ok, so looking at the optimizer code for the first time and trying the
>> simplest rule that could possibly work,
>>
>> object UnionPushdown extends Rule[LogicalPlan] {
>>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>>     // Push down filter into
>> union
>>     case f @ Filter(condition, u @ Union(left, right)) =>
>>
>>       u.copy(left = f.copy(child = left), right = f.copy(child =
>> right))
>>
>>
>>     // Push down projection into
>> union
>>     case p @ Project(projectList, u @ Union(left, right)) =>
>>       u.copy(left = p.copy(child = left), right = p.copy(child =
>> right))
>>
>> }
>>
>> }
>>
>>
>> If I try manually applying that rule to a logical plan in the repl, it
>> produces the query shape I'd expect, and executing that plan results in
>> parquet pushdowns as I'd expect.
>>
>> But adding those cases to ColumnPruning results in a runtime exception
>> (below)
>>
>> I can keep digging, but it seems like I'm missing some obvious initial
>> context around naming of attributes.  If you can provide any pointers to
>> speed me on my way I'd appreciate it.
>>
>>
>> java.lang.AssertionError: assertion failed: ArrayBuffer() + ArrayBuffer()
>> != WrappedArray(name#6, age#7), List(name#9, age#10, phones#11)
>>         at scala.Predef$.assert(Predef.scala:179)
>>         at
>> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>         at
>> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>         at
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>         at
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>         at scala.collection.immutable.List.foreach(List.scala:318)
>>         at
>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>         at scala.collection.AbstractTraversable.map(Traversable.scala:105)
>>         at
>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>         at
>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>         at
>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>>         at
>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>>         at
>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>>         at
>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>>         at
>> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>>
>>
>>
>>
>> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <michael@databricks.com>
>> wrote:
>>
>>> What Patrick said is correct.  Two other points:
>>>  - In the 1.2 release we are hoping to beef up the support for working
>>> with partitioned parquet independent of the metastore.
>>>  - You can actually do operations like INSERT INTO for parquet tables to
>>> add data.  This creates new parquet files for each insertion.  This will
>>> break if there are multiple concurrent writers to the same table.
>>>
>>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>>> I think what Michael means is people often use this to read existing
>>>> partitioned Parquet tables that are defined in a Hive metastore rather
>>>> than data generated directly from within Spark and then reading it
>>>> back as a table. I'd expect the latter case to become more common, but
>>>> for now most users connect to an existing metastore.
>>>>
>>>> I think you could go this route by creating a partitioned external
>>>> table based on the on-disk layout you create. The downside is that
>>>> you'd have to go through a hive metastore whereas what you are doing
>>>> now doesn't need hive at all.
>>>>
>>>> We should also just fix the case you are mentioning where a union is
>>>> used directly from within spark. But that's the context.
>>>>
>>>> - Patrick
>>>>
>>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>>> wrote:
>>>> > Maybe I'm missing something, I thought parquet was generally a
>>>> write-once
>>>> > format and the sqlContext interface to it seems that way as well.
>>>> >
>>>> > d1.saveAsParquetFile("/foo/d1")
>>>> >
>>>> > // another day, another table, with same schema
>>>> > d2.saveAsParquetFile("/foo/d2")
>>>> >
>>>> > Will give a directory structure like
>>>> >
>>>> > /foo/d1/_metadata
>>>> > /foo/d1/part-r-1.parquet
>>>> > /foo/d1/part-r-2.parquet
>>>> > /foo/d1/_SUCCESS
>>>> >
>>>> > /foo/d2/_metadata
>>>> > /foo/d2/part-r-1.parquet
>>>> > /foo/d2/part-r-2.parquet
>>>> > /foo/d2/_SUCCESS
>>>> >
>>>> > // ParquetFileReader will fail, because /foo/d1 is a directory, not a
>>>> > parquet partition
>>>> > sqlContext.parquetFile("/foo")
>>>> >
>>>> > // works, but has the noted lack of pushdown
>>>> >
>>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>>> >
>>>> >
>>>> > Is there another alternative?
>>>> >
>>>> >
>>>> >
>>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>>> michael@databricks.com>
>>>> > wrote:
>>>> >
>>>> >> I think usually people add these directories as multiple partitions
>>>> of the
>>>> >> same table instead of union.  This actually allows us to efficiently
>>>> prune
>>>> >> directories when reading in addition to standard column pruning.
>>>> >>
>>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com>
>>>> >> wrote:
>>>> >>
>>>> >>> I'm kind of surprised this was not run into before.  Do people not
>>>> >>> segregate their data by day/week in the HDFS directory structure?
>>>> >>>
>>>> >>>
>>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>>> michael@databricks.com>
>>>> >>> wrote:
>>>> >>>
>>>> >>>> Thanks!
>>>> >>>>
>>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <
>>>> cody@koeninger.org>
>>>> >>>> wrote:
>>>> >>>>
>>>> >>>> > Opened
>>>> >>>> >
>>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>> >>>> >
>>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>>> >>>> >
>>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>> >>>> michael@databricks.com>
>>>> >>>> > wrote:
>>>> >>>> >
>>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>>> cody@koeninger.org>
>>>> >>>> >> wrote:
>>>> >>>> >>>
>>>> >>>> >>> Is there a reason in general not to push projections and
>>>> predicates
>>>> >>>> down
>>>> >>>> >>> into the individual ParquetTableScans in a union?
>>>> >>>> >>>
>>>> >>>> >>
>>>> >>>> >> This would be a great case to add to ColumnPruning.  Would be
>>>> awesome
>>>> >>>> if
>>>> >>>> >> you could open a JIRA or even a PR :)
>>>> >>>> >>
>>>> >>>> >
>>>> >>>> >
>>>> >>>>
>>>> >>>
>>>> >>>
>>>> >>
>>>>
>>>
>>>
>>
>

--089e011844ce041a750502b896d8--

From dev-return-9393-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 16:40:02 2014
Return-Path: <dev-return-9393-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9B886117D1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 16:40:02 +0000 (UTC)
Received: (qmail 60691 invoked by uid 500); 10 Sep 2014 16:40:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60623 invoked by uid 500); 10 Sep 2014 16:40:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60605 invoked by uid 99); 10 Sep 2014 16:40:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:40:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:39:35 +0000
Received: by mail-la0-f46.google.com with SMTP id el20so1324885lab.33
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 09:39:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=4cmenlhaNsYY6vtVXZqRMdlQQ8vFU2pvVUeghhV0kN4=;
        b=VZD7PpiFSXcywIMIc2KHKLYjn2ob5eTAUlApeEDyXjDAg8awPB7yTApROC0h/Asz03
         JlbrkLyC/bZvWehDFyUnI+qqU95fp3yDMNYQ1AzNdzOXQniYc3CAR8yv/rqoP45brvkH
         n4ePMP0MKYG525rSEOZsCZnY/RB8wZAck+6HTCmnlGXXZOD5btPCbghvYKTYEBcBj8F6
         MN/fYXMLVvueFcgR5sdUE/5amnwCIQ1Dv9pIXePQ6yo9Tv8AYiTEI+YGaq7gNKmBg01I
         vsyCBA78KIwoRvHlQT63306Dwv0eq3IpUHhnxww7Dq0AWu2zOZBz5y/CMgkvmR/PwlOv
         h+1w==
X-Gm-Message-State: ALoCoQmMkxCyx8xM5YD1fnY/dM0vfKCWU8VX+NftPCP2QREhuMMvJlxAvQBVY9QIH1NIVuNfwE39
X-Received: by 10.152.28.230 with SMTP id e6mr43559142lah.62.1410367174103;
 Wed, 10 Sep 2014 09:39:34 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Wed, 10 Sep 2014 09:39:14 -0700 (PDT)
In-Reply-To: <CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
 <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
 <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
 <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
 <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
 <CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
 <CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
 <CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
 <CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
 <CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
 <CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com> <CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 10 Sep 2014 09:39:14 -0700
Message-ID: <CAAswR-5LKtMAUxqusHAe-Tz1xgfhWp0kzKymkFFSEw2Y5TzH-g@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Cody Koeninger <cody@koeninger.org>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160b79a6a631a0502b8b2fe
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160b79a6a631a0502b8b2fe
Content-Type: text/plain; charset=UTF-8

Hey Cody,

Thanks for doing this!  Will look at your PR later today.

Michael

On Wed, Sep 10, 2014 at 9:31 AM, Cody Koeninger <cody@koeninger.org> wrote:

> Tested the patch against a cluster with some real data.  Initial results
> seem like going from one table to a union of 2 tables is now closer to a
> doubling of query time as expected, instead of 5 to 10x.
>
> Let me know if you see any issues with that PR.
>
> On Wed, Sep 10, 2014 at 8:19 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
>> So the obvious thing I was missing is that the analyzer has already
>> resolved attributes by the time the optimizer runs, so the references in
>> the filter / projection need to be fixed up to match the children.
>>
>> Created a PR, let me know if there's a better way to do it.  I'll see
>> about testing performance against some actual data sets.
>>
>> On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>>> Ok, so looking at the optimizer code for the first time and trying the
>>> simplest rule that could possibly work,
>>>
>>> object UnionPushdown extends Rule[LogicalPlan] {
>>>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>>>     // Push down filter into
>>> union
>>>     case f @ Filter(condition, u @ Union(left, right)) =>
>>>
>>>       u.copy(left = f.copy(child = left), right = f.copy(child =
>>> right))
>>>
>>>
>>>     // Push down projection into
>>> union
>>>     case p @ Project(projectList, u @ Union(left, right)) =>
>>>       u.copy(left = p.copy(child = left), right = p.copy(child =
>>> right))
>>>
>>> }
>>>
>>> }
>>>
>>>
>>> If I try manually applying that rule to a logical plan in the repl, it
>>> produces the query shape I'd expect, and executing that plan results in
>>> parquet pushdowns as I'd expect.
>>>
>>> But adding those cases to ColumnPruning results in a runtime exception
>>> (below)
>>>
>>> I can keep digging, but it seems like I'm missing some obvious initial
>>> context around naming of attributes.  If you can provide any pointers to
>>> speed me on my way I'd appreciate it.
>>>
>>>
>>> java.lang.AssertionError: assertion failed: ArrayBuffer() +
>>> ArrayBuffer() != WrappedArray(name#6, age#7), List(name#9, age#10,
>>> phones#11)
>>>         at scala.Predef$.assert(Predef.scala:179)
>>>         at
>>> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>         at
>>> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>         at
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>         at
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>         at scala.collection.immutable.List.foreach(List.scala:318)
>>>         at
>>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>>         at
>>> scala.collection.AbstractTraversable.map(Traversable.scala:105)
>>>         at
>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>         at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>         at
>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>         at
>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>>>         at
>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>>>         at
>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>>>         at
>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>>>         at
>>> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>>>
>>>
>>>
>>>
>>> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <michael@databricks.com
>>> > wrote:
>>>
>>>> What Patrick said is correct.  Two other points:
>>>>  - In the 1.2 release we are hoping to beef up the support for working
>>>> with partitioned parquet independent of the metastore.
>>>>  - You can actually do operations like INSERT INTO for parquet tables
>>>> to add data.  This creates new parquet files for each insertion.  This will
>>>> break if there are multiple concurrent writers to the same table.
>>>>
>>>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>>
>>>>> I think what Michael means is people often use this to read existing
>>>>> partitioned Parquet tables that are defined in a Hive metastore rather
>>>>> than data generated directly from within Spark and then reading it
>>>>> back as a table. I'd expect the latter case to become more common, but
>>>>> for now most users connect to an existing metastore.
>>>>>
>>>>> I think you could go this route by creating a partitioned external
>>>>> table based on the on-disk layout you create. The downside is that
>>>>> you'd have to go through a hive metastore whereas what you are doing
>>>>> now doesn't need hive at all.
>>>>>
>>>>> We should also just fix the case you are mentioning where a union is
>>>>> used directly from within spark. But that's the context.
>>>>>
>>>>> - Patrick
>>>>>
>>>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>>>> wrote:
>>>>> > Maybe I'm missing something, I thought parquet was generally a
>>>>> write-once
>>>>> > format and the sqlContext interface to it seems that way as well.
>>>>> >
>>>>> > d1.saveAsParquetFile("/foo/d1")
>>>>> >
>>>>> > // another day, another table, with same schema
>>>>> > d2.saveAsParquetFile("/foo/d2")
>>>>> >
>>>>> > Will give a directory structure like
>>>>> >
>>>>> > /foo/d1/_metadata
>>>>> > /foo/d1/part-r-1.parquet
>>>>> > /foo/d1/part-r-2.parquet
>>>>> > /foo/d1/_SUCCESS
>>>>> >
>>>>> > /foo/d2/_metadata
>>>>> > /foo/d2/part-r-1.parquet
>>>>> > /foo/d2/part-r-2.parquet
>>>>> > /foo/d2/_SUCCESS
>>>>> >
>>>>> > // ParquetFileReader will fail, because /foo/d1 is a directory, not a
>>>>> > parquet partition
>>>>> > sqlContext.parquetFile("/foo")
>>>>> >
>>>>> > // works, but has the noted lack of pushdown
>>>>> >
>>>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>>>> >
>>>>> >
>>>>> > Is there another alternative?
>>>>> >
>>>>> >
>>>>> >
>>>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>>>> michael@databricks.com>
>>>>> > wrote:
>>>>> >
>>>>> >> I think usually people add these directories as multiple partitions
>>>>> of the
>>>>> >> same table instead of union.  This actually allows us to
>>>>> efficiently prune
>>>>> >> directories when reading in addition to standard column pruning.
>>>>> >>
>>>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <malouf.gary@gmail.com
>>>>> >
>>>>> >> wrote:
>>>>> >>
>>>>> >>> I'm kind of surprised this was not run into before.  Do people not
>>>>> >>> segregate their data by day/week in the HDFS directory structure?
>>>>> >>>
>>>>> >>>
>>>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>>>> michael@databricks.com>
>>>>> >>> wrote:
>>>>> >>>
>>>>> >>>> Thanks!
>>>>> >>>>
>>>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <
>>>>> cody@koeninger.org>
>>>>> >>>> wrote:
>>>>> >>>>
>>>>> >>>> > Opened
>>>>> >>>> >
>>>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>>> >>>> >
>>>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>>>> >>>> >
>>>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>>> >>>> michael@databricks.com>
>>>>> >>>> > wrote:
>>>>> >>>> >
>>>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>>>> cody@koeninger.org>
>>>>> >>>> >> wrote:
>>>>> >>>> >>>
>>>>> >>>> >>> Is there a reason in general not to push projections and
>>>>> predicates
>>>>> >>>> down
>>>>> >>>> >>> into the individual ParquetTableScans in a union?
>>>>> >>>> >>>
>>>>> >>>> >>
>>>>> >>>> >> This would be a great case to add to ColumnPruning.  Would be
>>>>> awesome
>>>>> >>>> if
>>>>> >>>> >> you could open a JIRA or even a PR :)
>>>>> >>>> >>
>>>>> >>>> >
>>>>> >>>> >
>>>>> >>>>
>>>>> >>>
>>>>> >>>
>>>>> >>
>>>>>
>>>>
>>>>
>>>
>>
>

--089e0160b79a6a631a0502b8b2fe--

From dev-return-9394-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 16:59:02 2014
Return-Path: <dev-return-9394-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 07A6411869
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 16:59:02 +0000 (UTC)
Received: (qmail 21119 invoked by uid 500); 10 Sep 2014 16:59:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21045 invoked by uid 500); 10 Sep 2014 16:59:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20801 invoked by uid 99); 10 Sep 2014 16:59:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:59:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.43 as permitted sender)
Received: from [209.85.216.43] (HELO mail-qa0-f43.google.com) (209.85.216.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 16:58:56 +0000
Received: by mail-qa0-f43.google.com with SMTP id cm18so17927553qab.30
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 09:58:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=3MqTzVTfD5tvwBZ9DtAFrULtgkdCOzrVdganaVuLs34=;
        b=eMDa6bdpJZxMR89+pLoft4jZy4nEg1ioFoBgGMu0yW36LxsS5q2hgoaPm/G2SzoL9s
         QLJDXKaWv5k8YvgV8rvrXJT+Il2lHNWi6qgpfWR1AfzX66STrtHOcENaTETKvGDAM5tq
         ZkW4v+ziq2FfDamydCyq4JBVnJPBK8j2AbXrvUDURWzHOH29sIDCkTxET2bmj8rtrTgs
         Vui3ep+8INU3Zw1dJ/QMkhOT/U48nAwZFyzisBe+hDx/UTMGjanhDiL5qL2OU4rxr6v9
         Zzk4jM30OJIZ27AU7+adNf/sbM1I81bQPf55B74XJk+yIRq99AWRgWTmeZeuMBc97hQi
         6CYQ==
X-Gm-Message-State: ALoCoQlYKnf9d7ZgBcH3Xd1Z40JnBbk5W4vTE4aeoejgO1bxZVPxBJCHBHXYWlgDgsEtsGiC+Nwk
MIME-Version: 1.0
X-Received: by 10.224.162.196 with SMTP id w4mr61465996qax.60.1410368316059;
 Wed, 10 Sep 2014 09:58:36 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Wed, 10 Sep 2014 09:58:35 -0700 (PDT)
In-Reply-To: <CA+B-+fzLbDFarQL96hiQpY=Rh+O6MU83=xvoZrcuDParsR+2ow@mail.gmail.com>
References: <CA+B-+fwLb3xte0HMCZT4T2ix747=N1aZn1=JXQV56CACk0JXbQ@mail.gmail.com>
	<CAJgQjQ83DLvNKSwq9SExwZczQpOWFaMxPKTzWSn-d77-DLKYvw@mail.gmail.com>
	<CA+B-+fxRBd4M3-EQhna4JcFMu1MzxwAo06YLuuXnvSszvZ5esw@mail.gmail.com>
	<CACBYxKJHo2zG+5=VvLnn-G3ehPRY-3bOzXumeuY_TK+sCX6GTQ@mail.gmail.com>
	<CA+B-+fxAA2mPO=cwmnw18UWE36BXnaAKWkQNf3BaC9iF7rQ8MQ@mail.gmail.com>
	<CACBYxKLd28eQ+z6VuvEWchNwu=QyQfb=57Zf71DeD=Th7+N41w@mail.gmail.com>
	<CA+B-+fzLbDFarQL96hiQpY=Rh+O6MU83=xvoZrcuDParsR+2ow@mail.gmail.com>
Date: Wed, 10 Sep 2014 09:58:35 -0700
Message-ID: <CACBYxKL3a6xmHCeTJPJaPF_HYAt4LuaruxqdBXgZfyxOdTT36A@mail.gmail.com>
Subject: Re: Lost executor on YARN ALS iterations
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e012946b67b49510502b8f6e2
X-Virus-Checked: Checked by ClamAV on apache.org

--089e012946b67b49510502b8f6e2
Content-Type: text/plain; charset=UTF-8

That's right

On Tue, Sep 9, 2014 at 2:04 PM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Last time it did not show up on environment tab but I will give it another
> shot...Expected behavior is that this env variable will show up right ?
>
> On Tue, Sep 9, 2014 at 12:15 PM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> I would expect 2 GB would be enough or more than enough for 16 GB
>> executors (unless ALS is using a bunch of off-heap memory?).  You mentioned
>> earlier in this thread that the property wasn't showing up in the
>> Environment tab.  Are you sure it's making it in?
>>
>> -Sandy
>>
>> On Tue, Sep 9, 2014 at 11:58 AM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>>
>>> Hmm...I did try it increase to few gb but did not get a successful run
>>> yet...
>>>
>>> Any idea if I am using say 40 executors, each running 16GB, what's the
>>> typical spark.yarn.executor.memoryOverhead for say 100M x 10 M large
>>> matrices with say few billion ratings...
>>>
>>> On Tue, Sep 9, 2014 at 10:49 AM, Sandy Ryza <sandy.ryza@cloudera.com>
>>> wrote:
>>>
>>>> Hi Deb,
>>>>
>>>> The current state of the art is to increase
>>>> spark.yarn.executor.memoryOverhead until the job stops failing.  We do have
>>>> plans to try to automatically scale this based on the amount of memory
>>>> requested, but it will still just be a heuristic.
>>>>
>>>> -Sandy
>>>>
>>>> On Tue, Sep 9, 2014 at 7:32 AM, Debasish Das <debasish.das83@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Sandy,
>>>>>
>>>>> Any resolution for YARN failures ? It's a blocker for running spark on
>>>>> top of YARN.
>>>>>
>>>>> Thanks.
>>>>> Deb
>>>>>
>>>>> On Tue, Aug 19, 2014 at 11:29 PM, Xiangrui Meng <mengxr@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Deb,
>>>>>>
>>>>>> I think this may be the same issue as described in
>>>>>> https://issues.apache.org/jira/browse/SPARK-2121 . We know that the
>>>>>> container got killed by YARN because it used much more memory that it
>>>>>> requested. But we haven't figured out the root cause yet.
>>>>>>
>>>>>> +Sandy
>>>>>>
>>>>>> Best,
>>>>>> Xiangrui
>>>>>>
>>>>>> On Tue, Aug 19, 2014 at 8:51 PM, Debasish Das <
>>>>>> debasish.das83@gmail.com> wrote:
>>>>>> > Hi,
>>>>>> >
>>>>>> > During the 4th ALS iteration, I am noticing that one of the
>>>>>> executor gets
>>>>>> > disconnected:
>>>>>> >
>>>>>> > 14/08/19 23:40:00 ERROR network.ConnectionManager: Corresponding
>>>>>> > SendingConnectionManagerId not found
>>>>>> >
>>>>>> > 14/08/19 23:40:00 INFO cluster.YarnClientSchedulerBackend: Executor
>>>>>> 5
>>>>>> > disconnected, so removing it
>>>>>> >
>>>>>> > 14/08/19 23:40:00 ERROR cluster.YarnClientClusterScheduler: Lost
>>>>>> executor 5
>>>>>> > on tblpmidn42adv-hdp.tdc.vzwcorp.com: remote Akka client
>>>>>> disassociated
>>>>>> >
>>>>>> > 14/08/19 23:40:00 INFO scheduler.DAGScheduler: Executor lost: 5
>>>>>> (epoch 12)
>>>>>> > Any idea if this is a bug related to akka on YARN ?
>>>>>> >
>>>>>> > I am using master
>>>>>> >
>>>>>> > Thanks.
>>>>>> > Deb
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

--089e012946b67b49510502b8f6e2--

From dev-return-9395-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 21:47:45 2014
Return-Path: <dev-return-9395-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C32A311532
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 21:47:45 +0000 (UTC)
Received: (qmail 91854 invoked by uid 500); 10 Sep 2014 21:47:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91786 invoked by uid 500); 10 Sep 2014 21:47:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91769 invoked by uid 99); 10 Sep 2014 21:47:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 21:47:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 21:47:40 +0000
Received: by mail-wg0-f50.google.com with SMTP id x13so6931702wgg.9
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 14:47:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=eD4est0A91adeANxSCtnygIM96GnNdMSbTI3D1AQytU=;
        b=IaerqNVw1GeqfPVMOnpbT/KlIwlPi1C9LhJ34M4yP3sDh88GIn60gjUYSftTvyNcES
         WD7k+kHUDCTw+VTSWSNjh3gQyvZXrAVv3mtmEcktX0iR8JNoivu4svWDhB4fWVWcTrTp
         WpI2kQjuDzXlLYd47D4j8g6dj436ZTPbEq3B6uGQkjJnPreKZmlrOHEfrXZ1VunroCv3
         UFlXPKbRp97sqkN+N5uhYlzgqTyG0Vbxxg1jLE52M6N2x4KU9f/lXxZ2wEkCjIgKKbPB
         ky/8XbihL/aVR4M0OeYzSTciz4VZFS4Ri4p6f2QrlursxlxAq/wWnZ8agcouXJDtUAxC
         habQ==
X-Received: by 10.180.187.144 with SMTP id fs16mr2206305wic.75.1410385639553;
 Wed, 10 Sep 2014 14:47:19 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Wed, 10 Sep 2014 14:46:39 -0700 (PDT)
In-Reply-To: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 10 Sep 2014 17:46:39 -0400
Message-ID: <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
To: shane knapp <sknapp@berkeley.edu>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c266a80ac1830502bcff75
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c266a80ac1830502bcff75
Content-Type: text/plain; charset=UTF-8

I'm looking forward to this. :)

Looks like Jenkins is having trouble triggering builds for new commits or
after user requests (e.g.
<https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
Hopefully that will be resolved tomorrow.

Nick

On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:

> since the power incident last thursday, the github pull request builder
> plugin is still not really working 100%.  i found an open issue
> w/jenkins[1] that could definitely be affecting us, i will be pausing
> builds early thursday morning and then restarting jenkins.
> i'll send out a reminder tomorrow, and if this causes any problems for you,
> please let me know and we can work out a better time.
>
> but, now for some good news!  yesterday morning, we racked and stacked the
> systems for the new jenkins instance in the berkeley datacenter.  tomorrow
> i should be able to log in to them and start getting them set up and
> configured.  this is a major step in getting us in to a much more
> 'production' style environment!
>
> anyways:  thanks for your patience, and i think we've all learned that hard
> powering down your build system is a definite recipe for disaster.  :)
>
> shane
>
> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>

--001a11c266a80ac1830502bcff75--

From dev-return-9396-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 10 22:45:13 2014
Return-Path: <dev-return-9396-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 922E3117AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 10 Sep 2014 22:45:13 +0000 (UTC)
Received: (qmail 73493 invoked by uid 500); 10 Sep 2014 22:45:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73411 invoked by uid 500); 10 Sep 2014 22:45:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72984 invoked by uid 99); 10 Sep 2014 22:45:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 22:45:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 10 Sep 2014 22:44:46 +0000
Received: by mail-lb0-f169.google.com with SMTP id p9so10719833lbv.14
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 15:44:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=fwUkWwUifE8igfpekp8rPXSA9XiYE0AZv2L1VqGslco=;
        b=lDr90kBbnLw2RcFUNUDUqnItHBJ4vAYM/Q2giyB0R7jUixOS3wdfGgMWMmRRPZ7q8N
         qkztc8EmnpYbsPUq4BBhvA5nN+l6TB2wHfwyYmCY7odwObMd/vVwcFYBH/wxxdLu0BEL
         UJVSiO2vAvR7cXGpwSGusxeMwQ5we6aaNinfdWbme6sPwZJqYRa+pVunlRNoc5quxTKt
         3EUrj99yqvSx8W4E1KctaIVJ+pvALsidAcwMrQ7lVRd4sET3NLhbq3/a+UvGxLLZ8nmm
         fHfdGzEEIkYepYvlXY4Sxt0ZZ+kXewJ9+NjA2dRZylUr2OgDAZmWnppXmjlgZAIEH+im
         l+vw==
X-Gm-Message-State: ALoCoQnO8HjWxGz/sVJqc7ZKWQkKyufKY0bBdLgXmWVeXD+rDQaWrtGBHJ2+5U9erg8812+dvuRM
X-Received: by 10.152.21.98 with SMTP id u2mr18901532lae.80.1410389084844;
 Wed, 10 Sep 2014 15:44:44 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Wed, 10 Sep 2014 15:44:24 -0700 (PDT)
In-Reply-To: <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
 <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 10 Sep 2014 15:44:24 -0700
Message-ID: <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=089e013d15d465be3a0502bdcc52
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d15d465be3a0502bdcc52
Content-Type: text/plain; charset=UTF-8

that's kinda what we're hoping as well.  :)

On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I'm looking forward to this. :)
>
> Looks like Jenkins is having trouble triggering builds for new commits or
> after user requests (e.g.
> <https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
> Hopefully that will be resolved tomorrow.
>
> Nick
>
> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> since the power incident last thursday, the github pull request builder
>> plugin is still not really working 100%.  i found an open issue
>> w/jenkins[1] that could definitely be affecting us, i will be pausing
>> builds early thursday morning and then restarting jenkins.
>> i'll send out a reminder tomorrow, and if this causes any problems for
>> you,
>> please let me know and we can work out a better time.
>>
>> but, now for some good news!  yesterday morning, we racked and stacked the
>> systems for the new jenkins instance in the berkeley datacenter.  tomorrow
>> i should be able to log in to them and start getting them set up and
>> configured.  this is a major step in getting us in to a much more
>> 'production' style environment!
>>
>> anyways:  thanks for your patience, and i think we've all learned that
>> hard
>> powering down your build system is a definite recipe for disaster.  :)
>>
>> shane
>>
>> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>>
>
>

--089e013d15d465be3a0502bdcc52--

From dev-return-9397-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 06:23:48 2014
Return-Path: <dev-return-9397-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C670611526
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 06:23:48 +0000 (UTC)
Received: (qmail 95749 invoked by uid 500); 11 Sep 2014 06:23:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95677 invoked by uid 500); 11 Sep 2014 06:23:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95664 invoked by uid 99); 11 Sep 2014 06:23:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 06:23:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 06:23:42 +0000
Received: by mail-oa0-f47.google.com with SMTP id i7so13997087oag.20
        for <dev@spark.apache.org>; Wed, 10 Sep 2014 23:23:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=syrkI42aoBEhfdVzTewTbpX/a0Ys+/vVzzGlhgdsbzY=;
        b=H5jbg2qFM7ni0jN+E982xofiflxdhjqxmvMdRkKwhErxxNKVxCfaQq/ASjksRec6KD
         9Qra3zk4k2LUuJ1ErsS7DBXxeKbonVqJaFyEbjQfKllMO/NPf3ULT527H6cmGbRp58bz
         539fOXKp3+fIIMPwD1GqeCGcsl0NDcBBYHO0k5biwjmK6jbhu/iwkmpQvjl7fjd1fcgl
         vFehwzezA2uPCJ4q2zxa/DRovUrCKqaJ1xKLJdi41GdkJ+z1ILwZ8pjiakRv8mk3tJ6d
         tSrp2+tkLbYiPmOrazIEHx0s+BSeAcbmlvPTlzjzt23r7LlkdUNsGes+unhqEFASFyvU
         feUw==
MIME-Version: 1.0
X-Received: by 10.182.22.201 with SMTP id g9mr283385obf.75.1410416601150; Wed,
 10 Sep 2014 23:23:21 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 10 Sep 2014 23:23:21 -0700 (PDT)
In-Reply-To: <CABPQxstrKkVRP5rgw0gYvW459QW1i1JeNn5dYQCCJXmD2UTiNQ@mail.gmail.com>
References: <CABPQxstrKkVRP5rgw0gYvW459QW1i1JeNn5dYQCCJXmD2UTiNQ@mail.gmail.com>
Date: Wed, 10 Sep 2014 23:23:21 -0700
Message-ID: <CABPQxsscTCE2+fZRE93iTfpF9vLLZz0tYwTSsvR93EHDoqQ31A@mail.gmail.com>
Subject: Re: [RESULT] [VOTE] Release Apache Spark 1.1.0 (RC4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey just a heads up to everyone - running a bit behind on getting the
final artifacts and notes up. Finalizing this release was much more
complicated than previous ones due to new binary formats (we need to
redesign the download page a bit for this to work) and the large
increase in contributor count. Next time we can pipeline this work to
avoid a delay.

I did cut the v1.1.0 tag today. We should be able to do the full
announce tomorrow.

Thanks,
Patrick

On Sun, Sep 7, 2014 at 5:50 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> This vote passes with 8 binding +1 votes and no -1 votes. I'll post
> the final release in the next 48 hours... just finishing the release
> notes and packaging (which now takes a long time given the number of
> contributors!).
>
> +1:
> Reynold Xin*
> Michael Armbrust*
> Xiangrui Meng*
> Andrew Or*
> Sean Owen
> Matthew Farrellee
> Marcelo Vanzin
> Josh Rosen*
> Cheng Lian
> Mubarak Seyed
> Matei Zaharia*
> Nan Zhu
> Jeremy Freeman
> Denny Lee
> Tom Graves*
> Henry Saputra
> Egor Pahomov
> Rohit Sinha
> Kan Zhang
> Tathagata Das*
> Reza Zadeh
>
> -1:
>
> 0:
>
> * = binding

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9398-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 09:17:38 2014
Return-Path: <dev-return-9398-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 12CCD11B3E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 09:17:38 +0000 (UTC)
Received: (qmail 20136 invoked by uid 500); 11 Sep 2014 09:17:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20070 invoked by uid 500); 11 Sep 2014 09:17:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20057 invoked by uid 99); 11 Sep 2014 09:17:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 09:17:36 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_IMAGE_ONLY_20,HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of liujunf@cn.ibm.com designates 202.81.31.145 as permitted sender)
Received: from [202.81.31.145] (HELO e23smtp03.au.ibm.com) (202.81.31.145)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 09:17:28 +0000
Received: from /spool/local
	by e23smtp03.au.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
	for <dev@spark.apache.org> from <liujunf@cn.ibm.com>;
	Thu, 11 Sep 2014 19:16:46 +1000
Received: from d23dlp02.au.ibm.com (202.81.31.213)
	by e23smtp03.au.ibm.com (202.81.31.209) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
	Thu, 11 Sep 2014 19:16:45 +1000
Received: from d23relay04.au.ibm.com (d23relay04.au.ibm.com [9.190.234.120])
	by d23dlp02.au.ibm.com (Postfix) with ESMTP id B6D112BB0023
	for <dev@spark.apache.org>; Thu, 11 Sep 2014 19:16:44 +1000 (EST)
Received: from d23av03.au.ibm.com (d23av03.au.ibm.com [9.190.234.97])
	by d23relay04.au.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id s8B8wd7w35127310
	for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:58:48 +1000
Received: from d23av03.au.ibm.com (localhost [127.0.0.1])
	by d23av03.au.ibm.com (8.14.4/8.14.4/NCO v10.0 AVout) with ESMTP id s8B9GBlK004232
	for <dev@spark.apache.org>; Thu, 11 Sep 2014 19:16:11 +1000
Received: from d23ml028.cn.ibm.com (d23ml028.cn.ibm.com [9.119.32.184])
	by d23av03.au.ibm.com (8.14.4/8.14.4/NCO v10.0 AVin) with ESMTP id s8B9GANb003317
	for <dev@spark.apache.org>; Thu, 11 Sep 2014 19:16:11 +1000
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Spark authenticate enablement
X-KeepSent: 9565F075:274C74B9-48257D50:0031C5D4;
 type=4; name=$KeepSent
X-Mailer: Lotus Notes Release 8.5.3 September 15, 2011
Message-ID: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
From: Jun Feng Liu <liujunf@cn.ibm.com>
Date: Thu, 11 Sep 2014 17:14:45 +0800
X-MIMETrack: Serialize by Router on d23ml028/23/M/IBM(Release 8.5.3FP6HF485 | May 7, 2014) at
 09/11/2014 17:15:13,
	Serialize complete at 09/11/2014 17:15:13
Content-Type: multipart/related; boundary="=_related 0032E0CF48257D50_="
X-TM-AS-MML: disable
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 14091109-0009-0000-0000-00000048E673
X-Virus-Checked: Checked by ClamAV on apache.org

--=_related 0032E0CF48257D50_=
Content-Type: multipart/alternative; boundary="=_alternative 0032E0CF48257D50_="


--=_alternative 0032E0CF48257D50_=
Content-Type: text/plain; charset="US-ASCII"

Hi, there

I am trying to enable the authentication on spark on standealone model. 
Seems like only SparkSubmit load the properties from spark-defaults.conf. 
org.apache.spark.deploy.master.Master dose not really load the default 
setting from spark-defaults.conf. 

Dose it mean the spark authentication only work for like YARN model? Or I 
missed something with standalone model.
 
Best Regards
 
Jun Feng Liu
IBM China Systems & Technology Laboratory in Beijing



Phone: 86-10-82452683 
E-mail: liujunf@cn.ibm.com


BLD 28,ZGC Software Park 
No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193 
China 
 

 
--=_alternative 0032E0CF48257D50_=
Content-Type: text/html; charset="GB2312"
Content-Transfer-Encoding: base64

PGZvbnQgc2l6ZT0yIGZhY2U9InNhbnMtc2VyaWYiPkhpLCB0aGVyZTwvZm9udD4NCjxicj4NCjxi
cj48Zm9udCBzaXplPTIgZmFjZT0ic2Fucy1zZXJpZiI+SSBhbSB0cnlpbmcgdG8gZW5hYmxlIHRo
ZSBhdXRoZW50aWNhdGlvbg0Kb24gc3Bhcmsgb24gc3RhbmRlYWxvbmUgbW9kZWwuIFNlZW1zIGxp
a2Ugb25seSBTcGFya1N1Ym1pdCBsb2FkIHRoZSBwcm9wZXJ0aWVzDQpmcm9tIHNwYXJrLWRlZmF1
bHRzLmNvbmYuICZuYnNwO29yZy5hcGFjaGUuc3BhcmsuZGVwbG95Lm1hc3Rlci5NYXN0ZXIgZG9z
ZQ0Kbm90IHJlYWxseSBsb2FkIHRoZSBkZWZhdWx0IHNldHRpbmcgZnJvbSBzcGFyay1kZWZhdWx0
cy5jb25mLiA8L2ZvbnQ+DQo8YnI+DQo8YnI+PGZvbnQgc2l6ZT0yIGZhY2U9InNhbnMtc2VyaWYi
PkRvc2UgaXQgbWVhbiB0aGUgc3BhcmsgYXV0aGVudGljYXRpb24NCm9ubHkgd29yayBmb3IgbGlr
ZSBZQVJOIG1vZGVsPyBPciBJIG1pc3NlZCBzb21ldGhpbmcgd2l0aCBzdGFuZGFsb25lIG1vZGVs
Ljxicj4NCjwvZm9udD48Zm9udCBzaXplPTEgZmFjZT0iQXJpYWwiPiA8L2ZvbnQ+DQo8cD48Zm9u
dCBzaXplPTEgZmFjZT0iQXJpYWwiPkJlc3QgUmVnYXJkczwvZm9udD4NCjxwPjxmb250IHNpemU9
MSBmYWNlPSJBcmlhbCI+Jm5ic3A7PC9mb250Pg0KPGJyPjxmb250IHNpemU9MyBjb2xvcj0jOGY4
ZjhmIGZhY2U9IkFyaWFsIj48Yj5KdW4gRmVuZyBMaXU8L2I+PC9mb250Pjxmb250IHNpemU9MSBm
YWNlPSJBcmlhbCI+PGJyPg0KSUJNIENoaW5hIFN5c3RlbXMgJmFtcDsgVGVjaG5vbG9neSBMYWJv
cmF0b3J5IGluIEJlaWppbmc8L2ZvbnQ+DQo8cD4NCjx0YWJsZT4NCjx0cj4NCjx0ZCBjb2xzcGFu
PTM+DQo8ZGl2IGFsaWduPWNlbnRlcj4NCjxociBub3NoYWRlPjwvZGl2Pg0KPHRyPg0KPHRkIHJv
d3NwYW49Mj48aW1nIHNyYz1jaWQ6XzJfMTUxQjM4RTgxNTFCMzUxNDAwMzJFMENGNDgyNTdENTAg
YWx0PSIyRCBiYXJjb2RlIC0gZW5jb2RlZCB3aXRoIGNvbnRhY3QgaW5mb3JtYXRpb24iPg0KPHRk
Pjxmb250IHNpemU9MSBjb2xvcj0jNDE4MWMwIGZhY2U9IsvOzOUiPjxiPlBob25lOiA8L2I+PC9m
b250Pjxmb250IHNpemU9MSBjb2xvcj0jNWY1ZjVmIGZhY2U9IsvOzOUiPjg2LTEwLTgyNDUyNjgz
DQo8L2ZvbnQ+PGZvbnQgc2l6ZT0xIGNvbG9yPSM0MTgxYzA+PGI+PGJyPg0KRS1tYWlsOjwvYj48
L2ZvbnQ+PGZvbnQgc2l6ZT0xIGNvbG9yPSM1ZjVmNWY+IDwvZm9udD48YSBocmVmPW1haWx0bzps
aXVqdW5mQGNuLmlibS5jb20gdGFyZ2V0PV9ibGFuaz48Zm9udCBzaXplPTEgY29sb3I9IzVmNWY1
ZiBmYWNlPSLLzszlIj48dT5saXVqdW5mQGNuLmlibS5jb208L3U+PC9mb250PjwvYT4NCjx0ZCBy
b3dzcGFuPTI+DQo8ZGl2IGFsaWduPXJpZ2h0Pjxmb250IHNpemU9MSBjb2xvcj0jNWY1ZjVmPjxi
cj4NCjwvZm9udD48Zm9udCBzaXplPTEgY29sb3I9IzVmNWY1ZiBmYWNlPSLLzszlIj48YnI+DQpC
TEQgMjgsWkdDIFNvZnR3YXJlIFBhcmsgPGJyPg0KTm8uOCBSZC5Eb25nIEJlaSBXYW5nIFdlc3Qs
IERpc3QuSGFpZGlhbiBCZWlqaW5nIDEwMDE5MyA8YnI+DQpDaGluYSA8L2ZvbnQ+PC9kaXY+DQo8
dHI+DQo8dGQ+PGZvbnQgc2l6ZT0xIGNvbG9yPSM1ZjVmNWY+Jm5ic3A7PC9mb250PjwvdGFibGU+
DQo8YnI+DQo8cD48Zm9udCBzaXplPTM+Jm5ic3A7PC9mb250Pg0K
--=_alternative 0032E0CF48257D50_=--
--=_related 0032E0CF48257D50_=--


From dev-return-9399-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 10:09:41 2014
Return-Path: <dev-return-9399-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 61B7911CD3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 10:09:41 +0000 (UTC)
Received: (qmail 30326 invoked by uid 500); 11 Sep 2014 10:09:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30260 invoked by uid 500); 11 Sep 2014 10:09:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30248 invoked by uid 99); 11 Sep 2014 10:09:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 10:09:40 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.217.175 as permitted sender)
Received: from [209.85.217.175] (HELO mail-lb0-f175.google.com) (209.85.217.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 10:09:13 +0000
Received: by mail-lb0-f175.google.com with SMTP id v6so6285439lbi.6
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 03:09:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Yl2HzDyvewRrV285qIBU9hXpcGKsH2OoiJOQgqdutTg=;
        b=XXkGoC/mTJlIHImLDfg9S3uJOzLn4G4DXF76oKQSHl6L+10/coUl1HdtfPrz8libky
         OQ1Tb/4yLCPnz8dLGDSKnhWZ0LIwM1/P7QzXZEBKWHEGLupaeY7bvIZ43rwePVekef/q
         zF6pWSPx1mt4UzqjOoOwVETe2JISOxvlkjoZTX4RCSEK5Rtji19dzhgw9tmwyA/5ngcj
         z1ST45bTBmrIr/Bf4axcS/loNcogRCqRjkez45m3MQWEDt2V0UdIE4ABbGi9yNKb/2jV
         OeVGr94RzDp5LURFQMI0dokMUzqR2EVt5skn9bHiaPn/FfSsbQP0o4gJsd7jNj/rSKlp
         zUAw==
MIME-Version: 1.0
X-Received: by 10.152.20.132 with SMTP id n4mr2101324lae.86.1410430152200;
 Thu, 11 Sep 2014 03:09:12 -0700 (PDT)
Received: by 10.152.37.231 with HTTP; Thu, 11 Sep 2014 03:09:12 -0700 (PDT)
In-Reply-To: <CALte62yLoTaw4u2M7=G=zLXkaXAMNEs8zOJB9ogs6+1hyRQZtQ@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
	<CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
	<CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
	<CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
	<CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
	<CALte62yLoTaw4u2M7=G=zLXkaXAMNEs8zOJB9ogs6+1hyRQZtQ@mail.gmail.com>
Date: Thu, 11 Sep 2014 15:39:12 +0530
Message-ID: <CAJOb8bv8HqtdhEuHMvQ4CiRMU4neg7w2OGoMY1t364E6m2YyKw@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Tathagata Das <tathagata.das1565@gmail.com>, Koert Kuipers <koert@tresata.com>, 
	Felix Garcia Borrego <fborrego@gilt.com>, Sean Owen <sowen@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493b9033d7df0502c75c28
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493b9033d7df0502c75c28
Content-Type: text/plain; charset=UTF-8

Thanks everyone for weighing in on this.

I had backported kinesis module from master to spark 1.0.2 so just to
confirm if I am not missing anything, I did a dependency graph compare of
my spark build with spark-master
and org.apache.httpcomponents:httpclient:jar does seem to resolve to 4.1.2
dependency.

I need Hive so, I can't really do a build without it. Even if I
exclude httpclient
dependency from my project's build, it will not solve the problem because
AWS SDK has been compiled with a greater version of http client. My spark
stream project does not uses http client directly. AWS SDK will look for
 class org.apache.http.impl.conn.DefaultClientConnectionOperator and it
will be loaded from spark-assembly jar regardless of how I package my
project (unless I am missing something?). I enabled verbosed classloading
to confirm that the class is indeed loading from spark-assembly jar.

spark.files.userClassPathFirst option doesn't seem to be working on my
spark 1.0.2 build (not sure why).

I was only left custom building spark and forcingly introduce latest
httpclient's latest version as dependency.

Finally, I tested this on 1.1.0-RC4 today and it has the same issue. Has
anyone ever been able to get the Kinesis example work with spark-hadoop2.4
(with hive and yarn) build? I feel like this is a bug that exists even in
1.1.0.

I still believe we need a better solution to address the dependency hell
problem. If OSGi is deemed too over the top, what are the solutions being
investigated?

On 6 September 2014 04:44, Ted Yu <yuzhihong@gmail.com> wrote:

> From output of dependency:tree:
>
> [INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @
> spark-streaming_2.10 ---
> [INFO] org.apache.spark:spark-streaming_2.10:jar:1.1.0-SNAPSHOT
> INFO] +- org.apache.spark:spark-core_2.10:jar:1.1.0-SNAPSHOT:compile
> [INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.4.0:compile
> ...
> [INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile
> [INFO] |  |  +- commons-codec:commons-codec:jar:1.5:compile
> [INFO] |  |  +- org.apache.httpcomponents:httpclient:jar:4.1.2:compile
> [INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.1.2:compile
>
> bq. excluding httpclient from spark-streaming dependency in your
> sbt/maven project
>
> This should work.
>
>
> On Fri, Sep 5, 2014 at 3:14 PM, Tathagata Das <tathagata.das1565@gmail.com
> > wrote:
>
>> If httpClient dependency is coming from Hive, you could build Spark
>> without
>> Hive. Alternatively, have you tried excluding httpclient from
>> spark-streaming dependency in your sbt/maven project?
>>
>> TD
>>
>>
>>
>> On Thu, Sep 4, 2014 at 6:42 AM, Koert Kuipers <koert@tresata.com> wrote:
>>
>> > custom spark builds should not be the answer. at least not if spark ever
>> > wants to have a vibrant community for spark apps.
>> >
>> > spark does support a user-classpath-first option, which would deal with
>> > some of these issues, but I don't think it works.
>> > On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com>
>> wrote:
>> >
>> > > Hi,
>> > > I run into the same issue and apart from the ideas Aniket said, I only
>> > > could find a nasty workaround. Add my custom
>> > PoolingClientConnectionManager
>> > > to my classpath.
>> > >
>> > >
>> > >
>> >
>> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
>> > >
>> > >
>> > >
>> > > On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com>
>> wrote:
>> > >
>> > > > Dumb question -- are you using a Spark build that includes the
>> Kinesis
>> > > > dependency? that build would have resolved conflicts like this for
>> > > > you. Your app would need to use the same version of the Kinesis
>> client
>> > > > SDK, ideally.
>> > > >
>> > > > All of these ideas are well-known, yes. In cases of super-common
>> > > > dependencies like Guava, they are already shaded. This is a
>> > > > less-common source of conflicts so I don't think http-client is
>> > > > shaded, especially since it is not used directly by Spark. I think
>> > > > this is a case of your app conflicting with a third-party
>> dependency?
>> > > >
>> > > > I think OSGi is deemed too over the top for things like this.
>> > > >
>> > > > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
>> > > > <aniket.bhatnagar@gmail.com> wrote:
>> > > > > I am trying to use Kinesis as source to Spark Streaming and have
>> run
>> > > > into a
>> > > > > dependency issue that can't be resolved without making my own
>> custom
>> > > > Spark
>> > > > > build. The issue is that Spark is transitively dependent
>> > > > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think
>> because of
>> > > > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is
>> > dependent
>> > > > > on org.apache.httpcomponents:httpclient:jar:4.2. When I package
>> and
>> > run
>> > > > > Spark Streaming application, I get the following:
>> > > > >
>> > > > > Caused by: java.lang.NoSuchMethodError:
>> > > > >
>> > > >
>> > >
>> >
>> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
>> > > > >         at
>> > > > >
>> com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
>> > > > >         at
>> > > > >
>> > > >
>> > >
>> >
>> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
>> > > > >
>> > > > > I can create a custom Spark build with
>> > > > > org.apache.httpcomponents:httpclient:jar:4.2 included in the
>> assembly
>> > > > but I
>> > > > > was wondering if this is something Spark devs have noticed and are
>> > > > looking
>> > > > > to resolve in near releases. Here are my thoughts on this issue:
>> > > > >
>> > > > > Containers that allow running custom user code have to often
>> resolve
>> > > > > dependency issues in case of conflicts between framework's and
>> user
>> > > > code's
>> > > > > dependency. Here is how I have seen some frameworks resolve the
>> > issue:
>> > > > > 1. Provide a child-first class loader: Some JEE containers
>> provided a
>> > > > > child-first class loader that allowed for loading classes from
>> user
>> > > code
>> > > > > first. I don't think this approach completely solves the problem
>> as
>> > the
>> > > > > framework is then susceptible to class mismatch errors.
>> > > > > 2. Fold in all dependencies in a sub-package: This approach
>> involves
>> > > > > folding all dependencies in a project specific sub-package (like
>> > > > > spark.dependencies). This approach is tedious because it involves
>> > > > building
>> > > > > custom version of all dependencies (and their transitive
>> > dependencies)
>> > > > > 3. Use something like OSGi: Some frameworks has successfully used
>> > OSGi
>> > > to
>> > > > > manage dependencies between the modules. The challenge in this
>> > approach
>> > > > is
>> > > > > to OSGify the framework and hide OSGi complexities from end user.
>> > > > >
>> > > > > My personal preference is OSGi (or atleast some support for OSGi)
>> > but I
>> > > > > would love to hear what Spark devs are thinking in terms of
>> resolving
>> > > the
>> > > > > problem.
>> > > > >
>> > > > > Thanks,
>> > > > > Aniket
>> > > >
>> > > >
>> ---------------------------------------------------------------------
>> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > > For additional commands, e-mail: dev-help@spark.apache.org
>> > > >
>> > > >
>> > >
>> >
>>
>
>

--089e01493b9033d7df0502c75c28--

From dev-return-9400-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 14:28:42 2014
Return-Path: <dev-return-9400-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1FC081185A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 14:28:42 +0000 (UTC)
Received: (qmail 66715 invoked by uid 500); 11 Sep 2014 14:28:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66646 invoked by uid 500); 11 Sep 2014 14:28:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65582 invoked by uid 99); 11 Sep 2014 14:28:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:28:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:28:12 +0000
Received: by mail-ie0-f175.google.com with SMTP id at20so4300598iec.20
        for <multiple recipients>; Thu, 11 Sep 2014 07:28:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=H36mSSSeasNgOk75n9eSBk3td24T2UVygtAmDgYwaEM=;
        b=hqOC33s1oPk3OfCCVUNkxPGL5GV3uJbNXUFw/j5+7HfoPel/4H/E08/ZDtmXLMkpQ8
         lQ0fUzX3NpppYM/vHZ8h2gLHwdtaJl3x2kHBqaOECOqt7Rc97qI9knsDbnPOLV2dbNB5
         ouB5qD8JtLBzS6vCfqIx7jYKUL2d1rgVNcY+XDZhgVRF2EsJhpxPUCBfeTbG8pmiP3CR
         t+QUbVduwRRK3844PicDqnW8V84cvC6C/bW08VxwGYj0NCmuPNDpLbjNCfU7r5+6ouDl
         dd2169vDfj85n1+QTsFy/vup4to22QHAF/gkddyF/JDvd0VEqEUk4f9Y/y62DdDmeZMm
         dq/g==
X-Received: by 10.42.61.146 with SMTP id u18mr2333020ich.1.1410445690994;
        Thu, 11 Sep 2014 07:28:10 -0700 (PDT)
Received: from [142.157.43.46] (wpa043046.Wireless.McGill.CA. [142.157.43.46])
        by mx.google.com with ESMTPSA id l19sm4875245igk.6.2014.09.11.07.28.10
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 07:28:10 -0700 (PDT)
Date: Thu, 11 Sep 2014 10:42:00 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Dibyendu Bhattacharya <dibyendu.bhattachary@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, user
 <user@spark.apache.org>
Message-ID: <E0D4F031CBD24ECEACE511B5A06FF2C3@gmail.com>
In-Reply-To: <CAFiYKR8sJ08=K4kshaqDQWFw8B57r_cnNLqrRfk9r1GNzTEFTQ@mail.gmail.com>
References: <CAFiYKR8sJ08=K4kshaqDQWFw8B57r_cnNLqrRfk9r1GNzTEFTQ@mail.gmail.com>
Subject: Re: Some Serious Issue with Spark Streaming ? Blocks Getting
 Removed and Jobs have Failed..
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5411b4b8_109cf92e_238"
X-Virus-Checked: Checked by ClamAV on apache.org

--5411b4b8_109cf92e_238
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi,  =20

Can you attach more logs to see if there is some entry from ContextCleane=
r=3F

I met very similar issue before=E2=80=A6but haven=E2=80=99t get resolved =
=20

Best, =20

-- =20
Nan Zhu


On Thursday, September 11, 2014 at 10:13 AM, Dibyendu Bhattacharya wrote:=


> Dear All, =20
> =20
> Not sure if this is a false alarm. But wanted to raise to this to under=
stand what is happening. =20
> =20
> I am testing the Kafka Receiver which I have written (https://github.co=
m/dibbhatt/kafka-spark-consumer) which basically a low level Kafka Consum=
er implemented custom Receivers for every Kafka topic partitions and pull=
ing data in parallel. Individual streams from all topic partitions are th=
en merged to create Union stream which used for further processing.
> =20
> The custom Receiver working fine in normal load with no issues. But whe=
n I tested this with huge amount of backlog messages from Kafka ( 50 mill=
ion + messages), I see couple of major issue in Spark Streaming. Wanted t=
o get some opinion on this....
> =20
> I am using latest Spark 1.1 taken from the source and built it. Running=
 in Amazon EMR , 3 m1.xlarge Node Spark cluster running in Standalone Mod=
e.
> =20
> Below are two main question I have..
> =20
> 1. What I am seeing when I run the Spark Streaming with my Kafka Consum=
er with a huge backlog in Kafka ( around 50 Million), Spark is completely=
 busy performing the Receiving task and hardly schedule any processing ta=
sk. Can you let me if this is expected =3F If there is large backlog, Spa=
rk will take long time pulling them . Why Spark not doing any processing =
=3F Is it because of resource limitation ( say all cores are busy puling =
) or it is by design =3F I am setting the executor-memory to 10G and driv=
er-memory to 4G .
> =20
> 2. This issue seems to be more serious. I have attached the Driver trac=
e with this email. What I can see very frequently Block are selected to b=
e Removed...This kind of entries are all over the place. But when a Block=
 is removed , below problem happen.... May be this issue cause the issue =
1 that no Jobs are getting processed ..
> =20
> =20
> IN=46O : org.apache.spark.storage.MemoryStore - 1 blocks selected for d=
ropping
> IN=46O : org.apache.spark.storage.BlockManager - Dropping block input-0=
-1410443074600 from memory
> IN=46O : org.apache.spark.storage.MemoryStore - Block input-0-141044307=
4600 of size 12651900 dropped from memory (free 21220667)
> IN=46O : org.apache.spark.storage.BlockManagerInfo - Removed input-0-14=
10443074600 on ip-10-252-5-113.asskickery.us:53752 (http://ip-10-252-5-11=
3.asskickery.us:53752) in memory (size: 12.1 MB, free: 100.6 MB)
> =20
> ...........
> =20
> IN=46O : org.apache.spark.storage.BlockManagerInfo - Removed input-0-14=
10443074600 on ip-10-252-5-62.asskickery.us:37033 (http://ip-10-252-5-62.=
asskickery.us:37033) in memory (size: 12.1 MB, free: 154.6 MB)
> ..............
> =20
> =20
> WARN : org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in sta=
ge 7.0 (TID 118, ip-10-252-5-62.asskickery.us (http://ip-10-252-5-62.assk=
ickery.us)): java.lang.Exception: Could not compute split, block input-0-=
1410443074600 not found
> =20
> ...........
> =20
> IN=46O : org.apache.spark.scheduler.TaskSetManager - Lost task 0.1 in s=
tage 7.0 (TID 126) on executor ip-10-252-5-62.asskickery.us (http://ip-10=
-252-5-62.asskickery.us): java.lang.Exception (Could not compute split, b=
lock input-0-1410443074600 not found) =5Bduplicate 1=5D
> =20
> =20
> org.apache.spark.SparkException: Job aborted due to stage failure: Task=
 0 in stage 7.0 failed 4 times, most recent failure: Lost task 0.3 in sta=
ge 7.0 (TID 139, ip-10-252-5-62.asskickery.us (http://ip-10-252-5-62.assk=
ickery.us)): java.lang.Exception: Could not compute split, block input-0-=
1410443074600 not found
>         org.apache.spark.rdd.BlockRDD.compute(BlockRDD.scala:51)
>         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)=

>         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
>         org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:87)
>         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)=

>         org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:6=
1)
>         org.apache.spark.rdd.RDD.iterator(RDD.scala:227)
>         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:=
62)
>         org.apache.spark.scheduler.Task.run(Task.scala:54)
>         org.apache.spark.executor.Executor=24TaskRunner.run(Executor.sc=
ala:177)
>         java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExe=
cutor.java:1145)
>         java.util.concurrent.ThreadPoolExecutor=24Worker.run(ThreadPool=
Executor.java:615)
>         java.lang.Thread.run(Thread.java:744)
> =20
> =20
> Regards, =20
> Dibyendu
> =20
> =20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe=40spark.apache.org (mailto:use=
r-unsubscribe=40spark.apache.org)
> =46or additional commands, e-mail: user-help=40spark.apache.org (mailto=
:user-help=40spark.apache.org)
> =20
> =20
> =20
> =20
> Attachments: =20
> - driver-trace.txt
> =20



--5411b4b8_109cf92e_238--


From dev-return-9401-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 14:30:10 2014
Return-Path: <dev-return-9401-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A29D11865
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 14:30:10 +0000 (UTC)
Received: (qmail 72612 invoked by uid 500); 11 Sep 2014 14:30:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72543 invoked by uid 500); 11 Sep 2014 14:30:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71448 invoked by uid 99); 11 Sep 2014 14:30:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:30:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.169 as permitted sender)
Received: from [209.85.223.169] (HELO mail-ie0-f169.google.com) (209.85.223.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:30:02 +0000
Received: by mail-ie0-f169.google.com with SMTP id rl12so8225372iec.0
        for <multiple recipients>; Thu, 11 Sep 2014 07:29:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=tEmd8Wcpl6XpbRNqmpSlwqK0t4s7Clh4AJQaF4jg96I=;
        b=zcW2tMmG8exTVQJijPpYpICSpBSXiI/h8CRSKxEoLmmJZUbv5MpNvQQrYuHlCwvfN6
         /9nIPFz0rIm18NXjjkfx+POsiTz70hOEiGO0QNsEOOfL/Cr5vWlUXRokoGrTfeznyrht
         SOeVUgZtzFw8ikrbZ5Zx2IcOeLplyezoKoyjAuBT4PoPUV8+dzE2Rdxos3+ReYJiRl/X
         SpeGad4YCoHLqfa/9w7CvxLTUmguALeP3QvNKnyhCUQIUp/xYDBjtU7Qt3ZkkVQ25Sow
         W9u4i8wOXmfkQqeqrmAvHOZITyOKEUYe864DNw1HY8zrGkNJPE5YPmk2wIpTfE0q7IvS
         G7Dw==
X-Received: by 10.42.230.144 with SMTP id jm16mr2379240icb.68.1410445781980;
        Thu, 11 Sep 2014 07:29:41 -0700 (PDT)
Received: from [142.157.43.46] (wpa043046.Wireless.McGill.CA. [142.157.43.46])
        by mx.google.com with ESMTPSA id j4sm1124795igx.20.2014.09.11.07.29.41
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 07:29:41 -0700 (PDT)
Date: Thu, 11 Sep 2014 10:43:32 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Dibyendu Bhattacharya <dibyendu.bhattachary@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, user
 <user@spark.apache.org>
Message-ID: <0EC465563D0D428EBDACF008801C92E6@gmail.com>
In-Reply-To: <E0D4F031CBD24ECEACE511B5A06FF2C3@gmail.com>
References: <CAFiYKR8sJ08=K4kshaqDQWFw8B57r_cnNLqrRfk9r1GNzTEFTQ@mail.gmail.com>
 <E0D4F031CBD24ECEACE511B5A06FF2C3@gmail.com>
Subject: Re: Some Serious Issue with Spark Streaming ? Blocks Getting
 Removed and Jobs have Failed..
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5411b514_431bd7b7_238"
X-Virus-Checked: Checked by ClamAV on apache.org

--5411b514_431bd7b7_238
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

This is my case about broadcast variable: =20

14/07/21 19:49:13 IN=46O Executor: Running task ID 4 14/07/21 19:49:13 IN=
=46O DAGScheduler: Completed ResultTask(0, 2) 14/07/21 19:49:13 IN=46O Ta=
skSetManager: =46inished TID 2 in 95 ms on localhost (progress: 3/106) 14=
/07/21 19:49:13 IN=46O TableOutput=46ormat: Created table instance for hd=
fstest=5Fcustomers 14/07/21 19:49:13 IN=46O Executor: Serialized size of =
result for 3 is 596 14/07/21 19:49:13 IN=46O Executor: Sending result for=
 3 directly to driver 14/07/21 19:49:13 IN=46O BlockManager: =46ound bloc=
k broadcast=5F0 locally 14/07/21 19:49:13 IN=46O Executor: =46inished tas=
k ID 3 14/07/21 19:49:13 IN=46O TaskSetManager: Starting task 0.0:5 as TI=
D 5 on executor localhost: localhost (PROCESS=5FLOCAL) 14/07/21 19:49:13 =
IN=46O TaskSetManager: Serialized task 0.0:5 as 11885 bytes in 0 ms 14/07=
/21 19:49:13 IN=46O Executor: Running task ID 5 14/07/21 19:49:13 IN=46O =
BlockManager: Removing broadcast 0 14/07/21 19:49:13 IN=46O DAGScheduler:=
 Completed ResultTask(0, 3) 14/07/21 19:49:13 IN=46O ContextCleaner: Clea=
ned broadcast 0 14/07/21 19:49:13 IN=46O TaskSetManager: =46inished TID 3=
 in 97 ms on localhost (progress: 4/106) 14/07/21 19:49:13 IN=46O BlockMa=
nager: =46ound block broadcast=5F0 locally 14/07/21 19:49:13 IN=46O Block=
Manager: Removing block broadcast=5F0 14/07/21 19:49:13 IN=46O MemoryStor=
e: Block broadcast=5F0 of size 202564 dropped from memory (free 886623436=
) 14/07/21 19:49:13 IN=46O ContextCleaner: Cleaned shuffle 0 14/07/21 19:=
49:13 IN=46O ShuffleBlockManager: Deleted all files for shuffle 0 14/07/2=
1 19:49:13 IN=46O HadoopRDD: Input split: hdfs://172.31.34.184:9000/etlte=
st/hdfsData/customer.csv:25+5 14/07/21 19:49:13 IN=46O HadoopRDD: Input s=
plit: hdfs://172.31.34.184:9000/etltest/hdfsData/customer.csv:20+5 14/07/=
21 19:49:13 IN=46O TableOutput=46ormat: Created table instance for hdfste=
st=5Fcustomers 14/07/21 19:49:13 IN=46O Executor: Serialized size of resu=
lt for 4 is 596 14/07/21 19:49:13 IN=46O Executor: Sending result for 4 d=
irectly to driver 14/07/21 19:49:13 IN=46O Executor: =46inished task ID 4=
 14/07/21 19:49:13 IN=46O TaskSetManager: Starting task 0.0:6 as TID 6 on=
 executor localhost: localhost (PROCESS=5FLOCAL) 14/07/21 19:49:13 IN=46O=
 TaskSetManager: Serialized task 0.0:6 as 11885 bytes in 0 ms 14/07/21 19=
:49:13 IN=46O Executor: Running task ID 6 14/07/21 19:49:13 IN=46O DAGSch=
eduler: Completed ResultTask(0, 4) 14/07/21 19:49:13 IN=46O TaskSetManage=
r: =46inished TID 4 in 80 ms on localhost (progress: 5/106) 14/07/21 19:4=
9:13 IN=46O TableOutput=46ormat: Created table instance for hdfstest=5Fcu=
stomers 14/07/21 19:49:13 IN=46O Executor: Serialized size of result for =
5 is 596 14/07/21 19:49:13 IN=46O Executor: Sending result for 5 directly=
 to driver 14/07/21 19:49:13 IN=46O Executor: =46inished task ID 5 14/07/=
21 19:49:13 IN=46O TaskSetManager: Starting task 0.0:7 as TID 7 on execut=
or localhost: localhost (PROCESS=5FLOCAL) 14/07/21 19:49:13 IN=46O TaskSe=
tManager: Serialized task 0.0:7 as 11885 bytes in 0 ms 14/07/21 19:49:13 =
IN=46O Executor: Running task ID 7 14/07/21 19:49:13 IN=46O DAGScheduler:=
 Completed ResultTask(0, 5) 14/07/21 19:49:13 IN=46O TaskSetManager: =46i=
nished TID 5 in 77 ms on localhost (progress: 6/106) 14/07/21 19:49:13 IN=
=46O HttpBroadcast: Started reading broadcast variable 0 14/07/21 19:49:1=
3 IN=46O HttpBroadcast: Started reading broadcast variable 0 14/07/21 19:=
49:13 ERROR Executor: Exception in task ID 6 java.io.=46ileNot=46oundExce=
ption: http://172.31.34.174:52070/broadcast=5F0 at sun.net.www.protocol.h=
ttp.HttpURLConnection.getInputStream (http://www.protocol.http.HttpURLCon=
nection.getInputStream)(HttpURLConnection.java:1624) at org.apache.spark.=
broadcast.HttpBroadcast=24.read(HttpBroadcast.scala:196) at org.apache.sp=
ark.broadcast.HttpBroadcast.readObject(HttpBroadcast.scala:89) at sun.ref=
lect.GeneratedMethodAccessor24.invoke(Unknown Source) at sun.reflect.Dele=
gatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at =
java.lang.reflect.Method.invoke(Method.java:606) at java.io.ObjectStreamC=
lass.invokeReadObject(ObjectStreamClass.java:1017) at java.io.ObjectInput=
Stream.readSerialData(ObjectInputStream.java:1893) at java.io.ObjectInput=
Stream.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.ObjectI=
nputStream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectInpu=
tStream.defaultRead=46ields(ObjectInputStream.java:1990) at java.io.Objec=
tInputStream.readSerialData(ObjectInputStream.java:1915) at java.io.Objec=
tInputStream.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.O=
bjectInputStream.readObject0(ObjectInputStream.java:1350) at java.io.Obje=
ctInputStream.defaultRead=46ields(ObjectInputStream.java:1990) at java.io=
.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) at java.io=
.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798) at jav=
a.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) at java.i=
o.ObjectInputStream.readObject(ObjectInputStream.java:370) at scala.colle=
ction.immutable.=24colon=24colon.readObject(List.scala:362) at sun.reflec=
t.GeneratedMethodAccessor16.invoke(Unknown Source) at sun.reflect.Delegat=
ingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at jav=
a.lang.reflect.Method.invoke(Method.java:606) at java.io.ObjectStreamClas=
s.invokeReadObject(ObjectStreamClass.java:1017) at java.io.ObjectInputStr=
eam.readSerialData(ObjectInputStream.java:1893) at java.io.ObjectInputStr=
eam.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.ObjectInpu=
tStream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectInputSt=
ream.defaultRead=46ields(ObjectInputStream.java:1990) at java.io.ObjectIn=
putStream.readSerialData(ObjectInputStream.java:1915) at java.io.ObjectIn=
putStream.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.Obje=
ctInputStream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectI=
nputStream.defaultRead=46ields(ObjectInputStream.java:1990) at java.io.Ob=
jectInputStream.readSerialData(ObjectInputStream.java:1915) at java.io.Ob=
jectInputStream.readOrdinaryObject(ObjectInputStream.java:1798) at java.i=
o.ObjectInputStream.readObject0(ObjectInputStream.java:1350) at java.io.O=
bjectInputStream.readObject(ObjectInputStream.java:370) at scala.collecti=
on.immutable.=24colon=24colon.readObject(List.scala:362) at sun.reflect.G=
eneratedMethodAccessor16.invoke(Unknown Source) at sun.reflect.Delegating=
MethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.l=
ang.reflect.Method.invoke(Method.java:606) at java.io.ObjectStreamClass.i=
nvokeReadObject(ObjectStreamClass.java:1017) at java.io.ObjectInputStream=
.readSerialData(ObjectInputStream.java:1893) at java.io.ObjectInputStream=
.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.ObjectInputSt=
ream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectInputStrea=
m.defaultRead=46ields(ObjectInputStream.java:1990) at java.io.ObjectInput=
Stream.readSerialData(ObjectInputStream.java:1915) at java.io.ObjectInput=
Stream.readOrdinaryObject(ObjectInputStream.java:1798) at java.io.ObjectI=
nputStream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectInpu=
tStream.readObject(ObjectInputStream.java:370) at org.apache.spark.serial=
izer.JavaDeserializationStream.readObject(JavaSerializer.scala:63) at org=
.apache.spark.scheduler.ResultTask=24.deserializeInfo(ResultTask.scala:61=
) at org.apache.spark.scheduler.ResultTask.readExternal(ResultTask.scala:=
141) at java.io.ObjectInputStream.readExternalData(ObjectInputStream.java=
:1837) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.=
java:1796) at java.io.ObjectInputStream.readObject0(ObjectInputStream.jav=
a:1350) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:37=
0) at org.apache.spark.serializer.JavaDeserializationStream.readObject(Ja=
vaSerializer.scala:63) at org.apache.spark.serializer.JavaSerializerInsta=
nce.deserialize(JavaSerializer.scala:85) at org.apache.spark.executor.Exe=
cutor=24TaskRunner.run(Executor.scala:169) at java.util.concurrent.Thread=
PoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurr=
ent.ThreadPoolExecutor=24Worker.run(ThreadPoolExecutor.java:615) at java.=
lang.Thread.run(Thread.java:744)



-- =20
Nan Zhu


On Thursday, September 11, 2014 at 10:42 AM, Nan Zhu wrote:

> Hi,  =20
> =20
> Can you attach more logs to see if there is some entry from ContextClea=
ner=3F
> =20
> I met very similar issue before=E2=80=A6but haven=E2=80=99t get resolve=
d =20
> =20
> Best, =20
> =20
> -- =20
> Nan Zhu
> =20
> =20
> On Thursday, September 11, 2014 at 10:13 AM, Dibyendu Bhattacharya wrot=
e:
> =20
> > Dear All, =20
> > =20
> > Not sure if this is a false alarm. But wanted to raise to this to und=
erstand what is happening. =20
> > =20
> > I am testing the Kafka Receiver which I have written (https://github.=
com/dibbhatt/kafka-spark-consumer) which basically a low level Kafka Cons=
umer implemented custom Receivers for every Kafka topic partitions and pu=
lling data in parallel. Individual streams from all topic partitions are =
then merged to create Union stream which used for further processing.
> > =20
> > The custom Receiver working fine in normal load with no issues. But w=
hen I tested this with huge amount of backlog messages from Kafka ( 50 mi=
llion + messages), I see couple of major issue in Spark Streaming. Wanted=
 to get some opinion on this....
> > =20
> > I am using latest Spark 1.1 taken from the source and built it. Runni=
ng in Amazon EMR , 3 m1.xlarge Node Spark cluster running in Standalone M=
ode.
> > =20
> > Below are two main question I have..
> > =20
> > 1. What I am seeing when I run the Spark Streaming with my Kafka Cons=
umer with a huge backlog in Kafka ( around 50 Million), Spark is complete=
ly busy performing the Receiving task and hardly schedule any processing =
task. Can you let me if this is expected =3F If there is large backlog, S=
park will take long time pulling them . Why Spark not doing any processin=
g =3F Is it because of resource limitation ( say all cores are busy pulin=
g ) or it is by design =3F I am setting the executor-memory to 10G and dr=
iver-memory to 4G .
> > =20
> > 2. This issue seems to be more serious. I have attached the Driver tr=
ace with this email. What I can see very frequently Block are selected to=
 be Removed...This kind of entries are all over the place. But when a Blo=
ck is removed , below problem happen.... May be this issue cause the issu=
e 1 that no Jobs are getting processed ..
> > =20
> > =20
> > IN=46O : org.apache.spark.storage.MemoryStore - 1 blocks selected for=
 dropping
> > IN=46O : org.apache.spark.storage.BlockManager - Dropping block input=
-0-1410443074600 from memory
> > IN=46O : org.apache.spark.storage.MemoryStore - Block input-0-1410443=
074600 of size 12651900 dropped from memory (free 21220667)
> > IN=46O : org.apache.spark.storage.BlockManagerInfo - Removed input-0-=
1410443074600 on ip-10-252-5-113.asskickery.us:53752 (http://ip-10-252-5-=
113.asskickery.us:53752) in memory (size: 12.1 MB, free: 100.6 MB)
> > =20
> > ...........
> > =20
> > IN=46O : org.apache.spark.storage.BlockManagerInfo - Removed input-0-=
1410443074600 on ip-10-252-5-62.asskickery.us:37033 (http://ip-10-252-5-6=
2.asskickery.us:37033) in memory (size: 12.1 MB, free: 154.6 MB)
> > ..............
> > =20
> > =20
> > WARN : org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in s=
tage 7.0 (TID 118, ip-10-252-5-62.asskickery.us (http://ip-10-252-5-62.as=
skickery.us)): java.lang.Exception: Could not compute split, block input-=
0-1410443074600 not found
> > =20
> > ...........
> > =20
> > IN=46O : org.apache.spark.scheduler.TaskSetManager - Lost task 0.1 in=
 stage 7.0 (TID 126) on executor ip-10-252-5-62.asskickery.us (http://ip-=
10-252-5-62.asskickery.us): java.lang.Exception (Could not compute split,=
 block input-0-1410443074600 not found) =5Bduplicate 1=5D
> > =20
> > =20
> > org.apache.spark.SparkException: Job aborted due to stage failure: Ta=
sk 0 in stage 7.0 failed 4 times, most recent failure: Lost task 0.3 in s=
tage 7.0 (TID 139, ip-10-252-5-62.asskickery.us (http://ip-10-252-5-62.as=
skickery.us)): java.lang.Exception: Could not compute split, block input-=
0-1410443074600 not found
> >         org.apache.spark.rdd.BlockRDD.compute(BlockRDD.scala:51)
> >         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:26=
2)
> >         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> >         org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:87)
> >         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:26=
2)
> >         org.apache.spark.CacheManager.getOrCompute(CacheManager.scala=
:61)
> >         org.apache.spark.rdd.RDD.iterator(RDD.scala:227)
> >         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scal=
a:62)
> >         org.apache.spark.scheduler.Task.run(Task.scala:54)
> >         org.apache.spark.executor.Executor=24TaskRunner.run(Executor.=
scala:177)
> >         java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolE=
xecutor.java:1145)
> >         java.util.concurrent.ThreadPoolExecutor=24Worker.run(ThreadPo=
olExecutor.java:615)
> >         java.lang.Thread.run(Thread.java:744)
> > =20
> > =20
> > Regards, =20
> > Dibyendu
> > =20
> > =20
> > ---------------------------------------------------------------------=

> > To unsubscribe, e-mail: user-unsubscribe=40spark.apache.org (mailto:u=
ser-unsubscribe=40spark.apache.org)
> > =46or additional commands, e-mail: user-help=40spark.apache.org (mail=
to:user-help=40spark.apache.org)
> > =20
> > =20
> > =20
> > =20
> > Attachments: =20
> > - driver-trace.txt
> > =20
> > =20
> =20
> =20


--5411b514_431bd7b7_238--


From dev-return-9402-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 14:39:10 2014
Return-Path: <dev-return-9402-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2CEB811929
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 14:39:10 +0000 (UTC)
Received: (qmail 98691 invoked by uid 500); 11 Sep 2014 14:39:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98615 invoked by uid 500); 11 Sep 2014 14:39:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98604 invoked by uid 99); 11 Sep 2014 14:39:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:39:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 14:38:43 +0000
Received: by mail-lb0-f179.google.com with SMTP id p9so9915011lbv.38
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 07:38:42 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Dnb2escED0Cjx5e+8wS1kLPVkB2Ox/VhmWh0a4YUCIE=;
        b=aSvgMIEyawcON+njmCXPNvwBQ8UqleeLX4IuoZB3/2VcaXnZgPGv0geB5LFnMqML2i
         sTrwIgYPrjYCidlGPoZ4N548cYHag1gZhWuNR0rKaqyOLZGYRRy5QHRbseeX34/D++LG
         mYnjQ8rx2auMLcZIpnQ5d4H2mWuOCnEl9waHHPBp8BzgqRPqJ/mK0Sucdz5tV/T5xF61
         OIyzSESByf4+uzxm9ROpCgYzIWuzXppr1SY9/Pt40UIQB9Liv8s0JPr2GQfmTI2sq3Gb
         Amli+/W15syeyFYxCH7U0WMSw8WR6UBm69uCoEsaDvMauWGhdlF8tYUyZ/Ppqk59fFe/
         XJQg==
X-Gm-Message-State: ALoCoQkAnuuPtEwOInWdyyS7pqLGkMyuh/AChEZBlK8OXjpwTGYskHUZvoiQXh2bS1gV6CWhhObN
X-Received: by 10.152.6.40 with SMTP id x8mr1811897lax.18.1410446319833; Thu,
 11 Sep 2014 07:38:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Thu, 11 Sep 2014 07:38:19 -0700 (PDT)
In-Reply-To: <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
 <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com> <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 11 Sep 2014 07:38:19 -0700
Message-ID: <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=089e0141a020de68240502cb1f3d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0141a020de68240502cb1f3d
Content-Type: text/plain; charset=UTF-8

jenkins is now in quiet mode, and a restart is happening soon.

On Wed, Sep 10, 2014 at 3:44 PM, shane knapp <sknapp@berkeley.edu> wrote:

> that's kinda what we're hoping as well.  :)
>
> On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> I'm looking forward to this. :)
>>
>> Looks like Jenkins is having trouble triggering builds for new commits or
>> after user requests (e.g.
>> <https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
>> Hopefully that will be resolved tomorrow.
>>
>> Nick
>>
>> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> since the power incident last thursday, the github pull request builder
>>> plugin is still not really working 100%.  i found an open issue
>>> w/jenkins[1] that could definitely be affecting us, i will be pausing
>>> builds early thursday morning and then restarting jenkins.
>>> i'll send out a reminder tomorrow, and if this causes any problems for
>>> you,
>>> please let me know and we can work out a better time.
>>>
>>> but, now for some good news!  yesterday morning, we racked and stacked
>>> the
>>> systems for the new jenkins instance in the berkeley datacenter.
>>> tomorrow
>>> i should be able to log in to them and start getting them set up and
>>> configured.  this is a major step in getting us in to a much more
>>> 'production' style environment!
>>>
>>> anyways:  thanks for your patience, and i think we've all learned that
>>> hard
>>> powering down your build system is a definite recipe for disaster.  :)
>>>
>>> shane
>>>
>>> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>>>
>>
>>
>

--089e0141a020de68240502cb1f3d--

From dev-return-9403-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 15:30:31 2014
Return-Path: <dev-return-9403-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4C81E11B48
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 15:30:31 +0000 (UTC)
Received: (qmail 21133 invoked by uid 500); 11 Sep 2014 15:30:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21063 invoked by uid 500); 11 Sep 2014 15:30:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21051 invoked by uid 99); 11 Sep 2014 15:30:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 15:30:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.44 as permitted sender)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 15:30:26 +0000
Received: by mail-la0-f44.google.com with SMTP id mc6so8262444lab.31
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 08:30:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=F/zl/MoDU8nKOXm69r7AXyyS2kdbpxrF9gMRdrvSFjA=;
        b=QG+607IafHbLJZlKSgzx3U/7s3YEtpqICEzA+ET/Rw09Rt2c07BR5KV+zn9oXSOTzY
         rrRaeEr5dPkmLHRzzoMEAYZUUQtiYGgX/Sv7AAKRkBb5fRHED/tn2NTkrFcFe0CujTBA
         eeqIDEOU89smllq9Uy5oHyYp4d6GoEQzOUf0OGDz3n/++1HZ6/y9fkvyqci1ptifvUgn
         KFH8Es0fsPBub/2GoZu50ktJ4PhYCvkUo/srzGovrAmfhZumD4tUd9yPaRaBrLn8l34l
         2b/pec1BCbR9er6lxiJ4SEmqFZA1Rqn+WpLy/Mfinl5Tpw0Ssb+BYdRRqdAllMrtbqvW
         IqWg==
X-Gm-Message-State: ALoCoQkdMhDfUvXeAGNVwIII6xLMMQuPSiDqARCoOpFnI8E5im0nPGYl3hbWaWwlqKHFwe8ir2v3
X-Received: by 10.152.6.40 with SMTP id x8mr2171111lax.18.1410449402526; Thu,
 11 Sep 2014 08:30:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Thu, 11 Sep 2014 08:29:42 -0700 (PDT)
In-Reply-To: <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
 <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
 <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com> <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 11 Sep 2014 08:29:42 -0700
Message-ID: <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=089e0141a0209c92d20502cbd756
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0141a0209c92d20502cbd756
Content-Type: text/plain; charset=UTF-8

...and the restart is done.

On Thu, Sep 11, 2014 at 7:38 AM, shane knapp <sknapp@berkeley.edu> wrote:

> jenkins is now in quiet mode, and a restart is happening soon.
>
> On Wed, Sep 10, 2014 at 3:44 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> that's kinda what we're hoping as well.  :)
>>
>> On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> I'm looking forward to this. :)
>>>
>>> Looks like Jenkins is having trouble triggering builds for new commits
>>> or after user requests (e.g.
>>> <https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
>>> Hopefully that will be resolved tomorrow.
>>>
>>> Nick
>>>
>>> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>>> since the power incident last thursday, the github pull request builder
>>>> plugin is still not really working 100%.  i found an open issue
>>>> w/jenkins[1] that could definitely be affecting us, i will be pausing
>>>> builds early thursday morning and then restarting jenkins.
>>>> i'll send out a reminder tomorrow, and if this causes any problems for
>>>> you,
>>>> please let me know and we can work out a better time.
>>>>
>>>> but, now for some good news!  yesterday morning, we racked and stacked
>>>> the
>>>> systems for the new jenkins instance in the berkeley datacenter.
>>>> tomorrow
>>>> i should be able to log in to them and start getting them set up and
>>>> configured.  this is a major step in getting us in to a much more
>>>> 'production' style environment!
>>>>
>>>> anyways:  thanks for your patience, and i think we've all learned that
>>>> hard
>>>> powering down your build system is a definite recipe for disaster.  :)
>>>>
>>>> shane
>>>>
>>>> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>>>>
>>>
>>>
>>
>

--089e0141a0209c92d20502cbd756--

From dev-return-9404-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 16:15:52 2014
Return-Path: <dev-return-9404-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35D7A11E60
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 16:15:52 +0000 (UTC)
Received: (qmail 71955 invoked by uid 500); 11 Sep 2014 16:15:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71879 invoked by uid 500); 11 Sep 2014 16:15:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71868 invoked by uid 99); 11 Sep 2014 16:15:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 16:15:51 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 16:15:47 +0000
Received: from int-mx10.intmail.prod.int.phx2.redhat.com (int-mx10.intmail.prod.int.phx2.redhat.com [10.5.11.23])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s8BGFDiD017360
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Thu, 11 Sep 2014 12:15:13 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx10.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s8BGFBeJ013326;
	Thu, 11 Sep 2014 12:15:12 -0400
Message-ID: <5411CA8F.3080701@redhat.com>
Date: Thu, 11 Sep 2014 12:15:11 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: shane knapp <sknapp@berkeley.edu>
CC: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com> <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com> <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com> <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com> <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com>
In-Reply-To: <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.23
X-Virus-Checked: Checked by ClamAV on apache.org

shane,

is there anything we should do for pull requests that failed, but for 
unrelated issues?

best,


matt

On 09/11/2014 11:29 AM, shane knapp wrote:
> ...and the restart is done.
>
> On Thu, Sep 11, 2014 at 7:38 AM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> jenkins is now in quiet mode, and a restart is happening soon.
>>
>> On Wed, Sep 10, 2014 at 3:44 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> that's kinda what we're hoping as well.  :)
>>>
>>> On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> I'm looking forward to this. :)
>>>>
>>>> Looks like Jenkins is having trouble triggering builds for new commits
>>>> or after user requests (e.g.
>>>> <https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
>>>> Hopefully that will be resolved tomorrow.
>>>>
>>>> Nick
>>>>
>>>> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>>
>>>>> since the power incident last thursday, the github pull request builder
>>>>> plugin is still not really working 100%.  i found an open issue
>>>>> w/jenkins[1] that could definitely be affecting us, i will be pausing
>>>>> builds early thursday morning and then restarting jenkins.
>>>>> i'll send out a reminder tomorrow, and if this causes any problems for
>>>>> you,
>>>>> please let me know and we can work out a better time.
>>>>>
>>>>> but, now for some good news!  yesterday morning, we racked and stacked
>>>>> the
>>>>> systems for the new jenkins instance in the berkeley datacenter.
>>>>> tomorrow
>>>>> i should be able to log in to them and start getting them set up and
>>>>> configured.  this is a major step in getting us in to a much more
>>>>> 'production' style environment!
>>>>>
>>>>> anyways:  thanks for your patience, and i think we've all learned that
>>>>> hard
>>>>> powering down your build system is a definite recipe for disaster.  :)
>>>>>
>>>>> shane
>>>>>
>>>>> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>>>>>
>>>>
>>>>
>>>
>>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9405-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 16:19:18 2014
Return-Path: <dev-return-9405-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6AC7211E6A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 16:19:18 +0000 (UTC)
Received: (qmail 78664 invoked by uid 500); 11 Sep 2014 16:19:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78593 invoked by uid 500); 11 Sep 2014 16:19:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78578 invoked by uid 99); 11 Sep 2014 16:19:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 16:19:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 16:18:51 +0000
Received: by mail-la0-f47.google.com with SMTP id mc6so1217327lab.20
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 09:18:47 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=wtYB2IY6ewWOZYmgsTOyk7W85lOx1QeLAD/AeA/dg2c=;
        b=bh/XFzWuZeuQrfLZd5NH2+tKZ+iIpM06e7TzRfQMqbBhwqkQBj/sJhcvQR2fN4Ijpw
         ffc4jVRy46pQnOIxrsLbE8cso4s2u3qb14VhXzxJcCTOWmns/0gD5nej7GPSqQ9MOlql
         +Q7piLvG0e3wVO1GpdKr73oqUe/7RUyGpXss6+2vo9mRhrd6xnv4E6UNtK8pLkj2otPv
         gSEjoOVNMmH5XnNIw8f1Q6YVOwhc3roVMCMm6t3K3k8SnGclCIq8NMdVcvTAb6+KzDxk
         ih0xRdpVxWcTgm8ob2hnAiCa+V5Svj+6Acwxs6hpmTKpLY91/Th5OpTYeUU+nTfKsDcJ
         tqoQ==
X-Gm-Message-State: ALoCoQnFrF70741lm7ZDy14aVzs1AGA/kLyNHz+TXXev3TGCpXnBqadgpfnUwEKIGK/Gsk2hFyQ+
X-Received: by 10.112.217.2 with SMTP id ou2mr2160176lbc.101.1410452325826;
 Thu, 11 Sep 2014 09:18:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Thu, 11 Sep 2014 09:18:25 -0700 (PDT)
In-Reply-To: <5411CA8F.3080701@redhat.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
 <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
 <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com>
 <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com>
 <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com> <5411CA8F.3080701@redhat.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 11 Sep 2014 09:18:25 -0700
Message-ID: <CACdU-dTT1dnSD1h_detZGOaLGTkgn1wmGjnsWXNQGPC-QPFRjQ@mail.gmail.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
To: Matthew Farrellee <matt@redhat.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11348408da932c0502cc854b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11348408da932c0502cc854b
Content-Type: text/plain; charset=UTF-8

you can just click on 'rebuild', if you'd like.  what project specifically?
 (i had forgotten that i'd killed
https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-with-YARN/557/,
which i just started a rebuild on)

On Thu, Sep 11, 2014 at 9:15 AM, Matthew Farrellee <matt@redhat.com> wrote:

> shane,
>
> is there anything we should do for pull requests that failed, but for
> unrelated issues?
>
> best,
>
>
> matt
>
> On 09/11/2014 11:29 AM, shane knapp wrote:
>
>> ...and the restart is done.
>>
>> On Thu, Sep 11, 2014 at 7:38 AM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>  jenkins is now in quiet mode, and a restart is happening soon.
>>>
>>> On Wed, Sep 10, 2014 at 3:44 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>  that's kinda what we're hoping as well.  :)
>>>>
>>>> On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>  I'm looking forward to this. :)
>>>>>
>>>>> Looks like Jenkins is having trouble triggering builds for new commits
>>>>> or after user requests (e.g.
>>>>> <https://github.com/apache/spark/pull/2339#issuecomment-55165937>).
>>>>> Hopefully that will be resolved tomorrow.
>>>>>
>>>>> Nick
>>>>>
>>>>> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>>
>>>>>  since the power incident last thursday, the github pull request
>>>>>> builder
>>>>>> plugin is still not really working 100%.  i found an open issue
>>>>>> w/jenkins[1] that could definitely be affecting us, i will be pausing
>>>>>> builds early thursday morning and then restarting jenkins.
>>>>>> i'll send out a reminder tomorrow, and if this causes any problems for
>>>>>> you,
>>>>>> please let me know and we can work out a better time.
>>>>>>
>>>>>> but, now for some good news!  yesterday morning, we racked and stacked
>>>>>> the
>>>>>> systems for the new jenkins instance in the berkeley datacenter.
>>>>>> tomorrow
>>>>>> i should be able to log in to them and start getting them set up and
>>>>>> configured.  this is a major step in getting us in to a much more
>>>>>> 'production' style environment!
>>>>>>
>>>>>> anyways:  thanks for your patience, and i think we've all learned that
>>>>>> hard
>>>>>> powering down your build system is a definite recipe for disaster.  :)
>>>>>>
>>>>>> shane
>>>>>>
>>>>>> [1] -- https://issues.jenkins-ci.org/browse/JENKINS-22509
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

--001a11348408da932c0502cc854b--

From dev-return-9406-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 18:41:38 2014
Return-Path: <dev-return-9406-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 30E6611506
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 18:41:38 +0000 (UTC)
Received: (qmail 90806 invoked by uid 500); 11 Sep 2014 18:41:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90723 invoked by uid 500); 11 Sep 2014 18:41:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90711 invoked by uid 99); 11 Sep 2014 18:41:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 18:41:37 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matt@redhat.com designates 209.132.183.28 as permitted sender)
Received: from [209.132.183.28] (HELO mx1.redhat.com) (209.132.183.28)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 18:41:33 +0000
Received: from int-mx14.intmail.prod.int.phx2.redhat.com (int-mx14.intmail.prod.int.phx2.redhat.com [10.5.11.27])
	by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s8BIf7qu027912
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256 verify=FAIL);
	Thu, 11 Sep 2014 14:41:08 -0400
Received: from eeyore.local (ovpn01.gateway.prod.ext.phx2.redhat.com [10.5.9.1])
	by int-mx14.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s8BIf5KE026775;
	Thu, 11 Sep 2014 14:41:05 -0400
Message-ID: <5411ECC1.2070508@redhat.com>
Date: Thu, 11 Sep 2014 14:41:05 -0400
From: Matthew Farrellee <matt@redhat.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.7.0
MIME-Version: 1.0
To: shane knapp <sknapp@berkeley.edu>
CC: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am PDT
 (and a brief update on our new jenkins infra)
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com> <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com> <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com> <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com> <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com> <5411CA8F.3080701@redhat.com> <CACdU-dTT1dnSD1h_detZGOaLGTkgn1wmGjnsWXNQGPC-QPFRjQ@mail.gmail.com>
In-Reply-To: <CACdU-dTT1dnSD1h_detZGOaLGTkgn1wmGjnsWXNQGPC-QPFRjQ@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.27
X-Virus-Checked: Checked by ClamAV on apache.org

it was part of the review queue, but it looks like the runs have been 
gc'd. oh well!

best,


matt

On 09/11/2014 12:18 PM, shane knapp wrote:
> you can just click on 'rebuild', if you'd like.  what project
> specifically?  (i had forgotten that i'd killed
> https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-with-YARN/557/,
> which i just started a rebuild on)
>
> On Thu, Sep 11, 2014 at 9:15 AM, Matthew Farrellee <matt@redhat.com
> <mailto:matt@redhat.com>> wrote:
>
>     shane,
>
>     is there anything we should do for pull requests that failed, but
>     for unrelated issues?
>
>     best,
>
>
>     matt
>
>     On 09/11/2014 11:29 AM, shane knapp wrote:
>
>         ...and the restart is done.
>
>         On Thu, Sep 11, 2014 at 7:38 AM, shane knapp
>         <sknapp@berkeley.edu <mailto:sknapp@berkeley.edu>> wrote:
>
>             jenkins is now in quiet mode, and a restart is happening soon.
>
>             On Wed, Sep 10, 2014 at 3:44 PM, shane knapp
>             <sknapp@berkeley.edu <mailto:sknapp@berkeley.edu>> wrote:
>
>                 that's kinda what we're hoping as well.  :)
>
>                 On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas <
>                 nicholas.chammas@gmail.com
>                 <mailto:nicholas.chammas@gmail.com>> wrote:
>
>                     I'm looking forward to this. :)
>
>                     Looks like Jenkins is having trouble triggering
>                     builds for new commits
>                     or after user requests (e.g.
>                     <https://github.com/apache/__spark/pull/2339#issuecomment-__55165937
>                     <https://github.com/apache/spark/pull/2339#issuecomment-55165937>>).
>                     Hopefully that will be resolved tomorrow.
>
>                     Nick
>
>                     On Tue, Sep 9, 2014 at 5:00 PM, shane knapp
>                     <sknapp@berkeley.edu <mailto:sknapp@berkeley.edu>>
>                     wrote:
>
>                         since the power incident last thursday, the
>                         github pull request builder
>                         plugin is still not really working 100%.  i
>                         found an open issue
>                         w/jenkins[1] that could definitely be affecting
>                         us, i will be pausing
>                         builds early thursday morning and then
>                         restarting jenkins.
>                         i'll send out a reminder tomorrow, and if this
>                         causes any problems for
>                         you,
>                         please let me know and we can work out a better
>                         time.
>
>                         but, now for some good news!  yesterday morning,
>                         we racked and stacked
>                         the
>                         systems for the new jenkins instance in the
>                         berkeley datacenter.
>                         tomorrow
>                         i should be able to log in to them and start
>                         getting them set up and
>                         configured.  this is a major step in getting us
>                         in to a much more
>                         'production' style environment!
>
>                         anyways:  thanks for your patience, and i think
>                         we've all learned that
>                         hard
>                         powering down your build system is a definite
>                         recipe for disaster.  :)
>
>                         shane
>
>                         [1] --
>                         https://issues.jenkins-ci.org/__browse/JENKINS-22509
>                         <https://issues.jenkins-ci.org/browse/JENKINS-22509>
>
>
>
>
>
>
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9407-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 18:43:29 2014
Return-Path: <dev-return-9407-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E5FB911516
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 18:43:29 +0000 (UTC)
Received: (qmail 99571 invoked by uid 500); 11 Sep 2014 18:43:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99506 invoked by uid 500); 11 Sep 2014 18:43:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99450 invoked by uid 99); 11 Sep 2014 18:43:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 18:43:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 18:43:02 +0000
Received: by mail-pa0-f51.google.com with SMTP id kx10so10410647pab.10
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 11:43:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=dzt2RLo8WlQbVC9dl8jWmae5LSum+MpkJ339R7nIySg=;
        b=sT4UfjpDbK8XzyMBWVZxt7WM+cIlXlc3ccIa/OJLEZlhwhtSjQzdbPZR9q92wZz6hO
         XVRCem0JoOSV9Ot7Moc2Edw4GwF/QXUwUxBPp9ghOx5WLyz+pnufaqsQUiSukdtXPE+m
         cXquV7yZKytIW14qcBy4i8B79iQYZCeZtHpeLRVM/3c+k3bKtcOcZ+ATNZbi+xtd7o8J
         bgZdO7gd9FZ4qIs3m9V+H17D6viekryUasgV2/3oKDEmGEKIJnvL1q3jqJHQdhlEy6+B
         ribQ/phRdcrlwBSaiGQWqQDunYZQA1AzL9kaK9AQ3kIXutNKtIHOge8kS/d+bm9lRaRi
         b8qw==
X-Received: by 10.70.52.199 with SMTP id v7mr4421118pdo.49.1410460980753;
        Thu, 11 Sep 2014 11:43:00 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id ka1sm1710310pbd.70.2014.09.11.11.42.59
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 11:43:00 -0700 (PDT)
Date: Thu, 11 Sep 2014 11:42:59 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Matthew Farrellee <matt@redhat.com>, shane knapp
 <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Message-ID: <etPan.5411ed33.507ed7ab.44f9@joshs-mbp>
In-Reply-To: <5411ECC1.2070508@redhat.com>
References: <CACdU-dR7N1zyGN0igtbZUJ27Fov=LMV6f6UKMxcbV=W4rLZxtg@mail.gmail.com>
 <CAOhmDzdq1SUbkzwY-VGhrV=D-02d46wNVkGkLcCunYYm28=N3w@mail.gmail.com>
 <CACdU-dRm73KdEMJG_AxS4w5u1Vhxh8tCmFJeZtLBH1id1s9rhw@mail.gmail.com>
 <CACdU-dTqHEL9aRO7Taqh0-yRGo1P-xWhPQrt0LbhROh9J3nZRg@mail.gmail.com>
 <CACdU-dTvtKY3Qb4+HMvU4f81GUEzoicNCc-PbNYdVEyc8S9obA@mail.gmail.com>
 <5411CA8F.3080701@redhat.com>
 <CACdU-dTT1dnSD1h_detZGOaLGTkgn1wmGjnsWXNQGPC-QPFRjQ@mail.gmail.com>
 <5411ECC1.2070508@redhat.com>
Subject: Re: yet another jenkins restart early thursday morning -- 730am
 PDT (and a brief update on our new jenkins infra)
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5411ed33_2eb141f2_44f9"
X-Virus-Checked: Checked by ClamAV on apache.org

--5411ed33_2eb141f2_44f9
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I purposely disabled the Maven master tests while we=E2=80=99re debugging=
 why they=E2=80=99re always failing the Hive tests. =C2=A0We=E2=80=99ll p=
ost an update later when we learn more; in the meantime, please don=E2=80=
=99t trigger those tests, since we don=E2=80=99t want them to clobber som=
e of the work that we=E2=80=99re doing by hand in those workspaces.

Thanks,
Josh

On September 11, 2014 at 11:41:38 AM, Matthew =46arrellee (matt=40redhat.=
com) wrote:

it was part of the review queue, but it looks like the runs have been =20
gc'd. oh well=21 =20

best, =20


matt =20

On 09/11/2014 12:18 PM, shane knapp wrote: =20
> you can just click on 'rebuild', if you'd like. what project =20
> specifically=3F (i had forgotten that i'd killed =20
> https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-with-YARN=
/557/, =20
> which i just started a rebuild on) =20
> =20
> On Thu, Sep 11, 2014 at 9:15 AM, Matthew =46arrellee <matt=40redhat.com=
 =20
> <mailto:matt=40redhat.com>> wrote: =20
> =20
> shane, =20
> =20
> is there anything we should do for pull requests that failed, but =20
> for unrelated issues=3F =20
> =20
> best, =20
> =20
> =20
> matt =20
> =20
> On 09/11/2014 11:29 AM, shane knapp wrote: =20
> =20
> ...and the restart is done. =20
> =20
> On Thu, Sep 11, 2014 at 7:38 AM, shane knapp =20
> <sknapp=40berkeley.edu <mailto:sknapp=40berkeley.edu>> wrote: =20
> =20
> jenkins is now in quiet mode, and a restart is happening soon. =20
> =20
> On Wed, Sep 10, 2014 at 3:44 PM, shane knapp =20
> <sknapp=40berkeley.edu <mailto:sknapp=40berkeley.edu>> wrote: =20
> =20
> that's kinda what we're hoping as well. :) =20
> =20
> On Wed, Sep 10, 2014 at 2:46 PM, Nicholas Chammas < =20
> nicholas.chammas=40gmail.com =20
> <mailto:nicholas.chammas=40gmail.com>> wrote: =20
> =20
> I'm looking forward to this. :) =20
> =20
> Looks like Jenkins is having trouble triggering =20
> builds for new commits =20
> or after user requests (e.g. =20
> <https://github.com/apache/=5F=5Fspark/pull/2339=23issuecomment-=5F=5F5=
5165937 =20
> <https://github.com/apache/spark/pull/2339=23issuecomment-55165937>>). =
=20
> Hopefully that will be resolved tomorrow. =20
> =20
> Nick =20
> =20
> On Tue, Sep 9, 2014 at 5:00 PM, shane knapp =20
> <sknapp=40berkeley.edu <mailto:sknapp=40berkeley.edu>> =20
> wrote: =20
> =20
> since the power incident last thursday, the =20
> github pull request builder =20
> plugin is still not really working 100%. i =20
> found an open issue =20
> w/jenkins=5B1=5D that could definitely be affecting =20
> us, i will be pausing =20
> builds early thursday morning and then =20
> restarting jenkins. =20
> i'll send out a reminder tomorrow, and if this =20
> causes any problems for =20
> you, =20
> please let me know and we can work out a better =20
> time. =20
> =20
> but, now for some good news=21 yesterday morning, =20
> we racked and stacked =20
> the =20
> systems for the new jenkins instance in the =20
> berkeley datacenter. =20
> tomorrow =20
> i should be able to log in to them and start =20
> getting them set up and =20
> configured. this is a major step in getting us =20
> in to a much more =20
> 'production' style environment=21 =20
> =20
> anyways: thanks for your patience, and i think =20
> we've all learned that =20
> hard =20
> powering down your build system is a definite =20
> recipe for disaster. :) =20
> =20
> shane =20
> =20
> =5B1=5D -- =20
> https://issues.jenkins-ci.org/=5F=5Fbrowse/JENKINS-22509 =20
> <https://issues.jenkins-ci.org/browse/JENKINS-22509> =20
> =20
> =20
> =20
> =20
> =20
> =20
> =20
> =20


--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--5411ed33_2eb141f2_44f9--


From dev-return-9408-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 11 21:18:26 2014
Return-Path: <dev-return-9408-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1BDDC11DB8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 11 Sep 2014 21:18:26 +0000 (UTC)
Received: (qmail 20447 invoked by uid 500); 11 Sep 2014 21:18:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20368 invoked by uid 500); 11 Sep 2014 21:18:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20355 invoked by uid 99); 11 Sep 2014 21:18:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 21:18:24 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 11 Sep 2014 21:18:20 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XSBkd-0003kq-UP
	for dev@spark.incubator.apache.org; Thu, 11 Sep 2014 14:17:59 -0700
Date: Thu, 11 Sep 2014 14:17:59 -0700 (PDT)
From: Tom <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1410470279838-8376.post@n3.nabble.com>
Subject: Questions regarding memory usage
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi All, I currently have 3 questions regarding memory usage:

1)
Regarding overall memory usage:
If I set SPARK_DRIVER_MEMORY to x GB, Spark reports
/14/09/11 15:36:41 INFO MemoryStore: MemoryStore started with capacity
~0.55*x GB/
*Question:*
Does this relate to spark.storage.memoryFraction (default 0.6), and is the
other 0.4 used by spark.shulffle.memoryFraction (default 0.2) and spark
general usage (0,2?).

2)
Regarding RDD=E2=80=99s and intermediate storage:
Say I have two different programs:
a)
JavaPairRDD<String, String> a =3D file.flatMapToPair(some class());
JavaPairRDD<String, String> b =3D a.reduceByKey(some class());
JavaPairRDD<String, String> c =3D b.mapValues(some class());

b)
file.flatMapToPair(some class()).reduceByKey(some class()).mapValues(some
class());

I am now wondering which RDD's are actually created, and if they are the
same in both situations:
I could see a scenario in a) in which lazy evaluation has a similar
situation too
Int a, b, c;
a =3D 0;
b =3D a;
c =3D b;
Were the compiler removes a and b, and only stores c.=20

I could also see a scenario in b) in which Spark has a need to create
intermediate RDD=E2=80=99s to pass the data to the next function, without t=
hem being
explicitly mentioned, but still being there. In this case, there are RDD's
created, and potentially removed.

Now when I look into the output, I see
/MappedRDD[37]/
But I only defined 18 RDD's in my code with JavaPairRDD.

*Question:*
When are RDD's actually created? Can I trace these one-on-one in the output=
?=20

3)
Regarding the size of an RDD:
When I run a program, I see the following lines:
/14/09/11 15:36:44 INFO MemoryStore: ensureFreeSpace(3760) called with
curMem=3D360852, maxMem=3D2899102924
14/09/11 15:36:44 INFO MemoryStore: Block broadcast_9 stored as values in
memory (estimated size 3.7 KB, free 2.7 GB)/
But also
/14/09/11 12:57:08 INFO ExternalAppendOnlyMap: Thread 239 spilling in-memor=
y
map of 493 MB to disk (7 times so far)
14/09/11 12:57:09 INFO ExternalAppendOnlyMap: Thread 239 spilling in-memory
map of 493 MB to disk (8 times so far)/

I could see a scenario in which a shuffle uses more than an actual RDD stor=
e
needs, but this seems disproportional to me.=20
*Question:*
Where can I see the actual size of an individual RDD? Or is there a way to
calculate it?

Thanks a lot for any help!!

Tom








--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/Questions-regarding-memory-usage-tp8376.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9409-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 00:13:10 2014
Return-Path: <dev-return-9409-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DFF0B113C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 00:13:09 +0000 (UTC)
Received: (qmail 64920 invoked by uid 500); 12 Sep 2014 00:13:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64863 invoked by uid 500); 12 Sep 2014 00:13:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63690 invoked by uid 99); 12 Sep 2014 00:13:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 00:13:06 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 00:12:40 +0000
Received: by mail-ob0-f181.google.com with SMTP id wo20so83687obc.12
        for <multiple recipients>; Thu, 11 Sep 2014 17:12:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=NoVVpdcRBtKPsgzH2Hm+u6B/WHm59MYfuEDW2Iv01J8=;
        b=Jh1auzomMjIKkn0iefbS/l8+lb8yEwGgsrp+vqwTuWSN4E7nZEQW3ksvSsVOl/cXCf
         gNEIZfDKamHw1A//HUJPoFEz+P8svqnOmnlSwhpIqEIXHQWxjaLxh7TVPC0vq0k28m+n
         H/raOTa9tWjv9kVm7dt+3mCWssCZkuTyzvBzTc+iuweaTh99BDH5B7JcbSIQm/smm27a
         UNR5g10AXUEk0quWct1oJSodpjWCIqSVvjQ0CNuiHZXYVPGCvuavLiRqf1yutz+cinDb
         48zMSXSiKeHXZwwTrPWLCgcMXFpbyyD9PLQIofeVaqULn5jA/uBFnjeFQ/oasrl/tpjC
         LRYQ==
MIME-Version: 1.0
X-Received: by 10.60.147.130 with SMTP id tk2mr4866525oeb.68.1410480759043;
 Thu, 11 Sep 2014 17:12:39 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Thu, 11 Sep 2014 17:12:38 -0700 (PDT)
Date: Thu, 11 Sep 2014 17:12:38 -0700
Message-ID: <CABPQxstxZco8QG2p-eEpbzPnKJOVR3TfPjjTDbxTTv=8t9Mhmg@mail.gmail.com>
Subject: Announcing Spark 1.1.0!
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I am happy to announce the availability of Spark 1.1.0! Spark 1.1.0 is
the second release on the API-compatible 1.X line. It is Spark's
largest release ever, with contributions from 171 developers!

This release brings operational and performance improvements in Spark
core including a new implementation of the Spark shuffle designed for
very large scale workloads. Spark 1.1 adds significant extensions to
the newest Spark modules, MLlib and Spark SQL. Spark SQL introduces a
JDBC server, byte code generation for fast expression evaluation, a
public types API, JSON support, and other features and optimizations.
MLlib introduces a new statistics library along with several new
algorithms and optimizations. Spark 1.1 also builds out Spark's Python
support and adds new components to the Spark Streaming module.

Visit the release notes [1] to read about the new features, or
download [2] the release today.

[1] http://spark.eu.apache.org/releases/spark-release-1-1-0.html
[2] http://spark.eu.apache.org/downloads.html

NOTE: SOME ASF DOWNLOAD MIRRORS WILL NOT CONTAIN THE RELEASE FOR SEVERAL HOURS.

Please e-mail me directly for any type-o's in the release notes or name listing.

Thanks, and congratulations!
- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9410-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 00:27:50 2014
Return-Path: <dev-return-9410-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2BC791142F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 00:27:50 +0000 (UTC)
Received: (qmail 84427 invoked by uid 500); 12 Sep 2014 00:27:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84345 invoked by uid 500); 12 Sep 2014 00:27:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83229 invoked by uid 99); 12 Sep 2014 00:27:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 00:27:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.174 as permitted sender)
Received: from [74.125.82.174] (HELO mail-we0-f174.google.com) (74.125.82.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 00:27:35 +0000
Received: by mail-we0-f174.google.com with SMTP id t60so6506646wes.33
        for <multiple recipients>; Thu, 11 Sep 2014 17:27:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=2ARESgLfWMx48Yzq5T4sItGTMg8aen0TSfm2HC+5JF8=;
        b=C39N4uTDfvxUWn2IitgPRHZFkwy9FqRrjnxesfLHbygf9XARz38+17+iRzsteywKNi
         8NbHSKwRsU34oDRiBwxt9WbG+UrLm/O6N5swrufT+xHyoXS/lPwfHnlwVcKNH/cqJSuA
         EDP1LvAqmt6UaLfj/oDyOWhV6YBkEVVWDnF0QX81ZTvzhFcoG1IEZ8sGVbRlpqC/KFj5
         X5c5vTDz4uYUg2pJd6MChEX9olfGdBdDlexYeN8EwowP4JHVRmYFh73YNgnAjJj0IrLH
         qDpW/fv0BGh55kp2YstKbzbs9rJM0S1zma71gib+RLblU5cVOssy+uxYatVZ+lxvhOu7
         H6og==
X-Received: by 10.194.71.210 with SMTP id x18mr6185251wju.6.1410481634327;
 Thu, 11 Sep 2014 17:27:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Thu, 11 Sep 2014 17:26:34 -0700 (PDT)
In-Reply-To: <CABPQxstxZco8QG2p-eEpbzPnKJOVR3TfPjjTDbxTTv=8t9Mhmg@mail.gmail.com>
References: <CABPQxstxZco8QG2p-eEpbzPnKJOVR3TfPjjTDbxTTv=8t9Mhmg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 11 Sep 2014 20:26:34 -0400
Message-ID: <CAOhmDzcCDYGVMxJ0KXf4+8N92x63o6ovSEFhM8Tyk9Z-WikD3w@mail.gmail.com>
Subject: Re: Announcing Spark 1.1.0!
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfd0776c6c65e0502d3583d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfd0776c6c65e0502d3583d
Content-Type: text/plain; charset=UTF-8

Nice work everybody! I'm looking forward to trying out this release!

On Thu, Sep 11, 2014 at 8:12 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> I am happy to announce the availability of Spark 1.1.0! Spark 1.1.0 is
> the second release on the API-compatible 1.X line. It is Spark's
> largest release ever, with contributions from 171 developers!
>
> This release brings operational and performance improvements in Spark
> core including a new implementation of the Spark shuffle designed for
> very large scale workloads. Spark 1.1 adds significant extensions to
> the newest Spark modules, MLlib and Spark SQL. Spark SQL introduces a
> JDBC server, byte code generation for fast expression evaluation, a
> public types API, JSON support, and other features and optimizations.
> MLlib introduces a new statistics library along with several new
> algorithms and optimizations. Spark 1.1 also builds out Spark's Python
> support and adds new components to the Spark Streaming module.
>
> Visit the release notes [1] to read about the new features, or
> download [2] the release today.
>
> [1] http://spark.eu.apache.org/releases/spark-release-1-1-0.html
> [2] http://spark.eu.apache.org/downloads.html
>
> NOTE: SOME ASF DOWNLOAD MIRRORS WILL NOT CONTAIN THE RELEASE FOR SEVERAL
> HOURS.
>
> Please e-mail me directly for any type-o's in the release notes or name
> listing.
>
> Thanks, and congratulations!
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>

--047d7bfd0776c6c65e0502d3583d--

From dev-return-9411-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:10:49 2014
Return-Path: <dev-return-9411-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D0D3D11589
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:10:49 +0000 (UTC)
Received: (qmail 61407 invoked by uid 500); 12 Sep 2014 01:10:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61335 invoked by uid 500); 12 Sep 2014 01:10:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61324 invoked by uid 99); 12 Sep 2014 01:10:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:10:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.192.54 as permitted sender)
Received: from [209.85.192.54] (HELO mail-qg0-f54.google.com) (209.85.192.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:10:22 +0000
Received: by mail-qg0-f54.google.com with SMTP id z60so27317qgd.13
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:10:20 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=uoAUp4jUkOKnhVkrSszyI7geb7DJrlF0mpvCsnDPocg=;
        b=lII3WNCaJY6Kk3AD1K0affdKr6knq+UMA3gtiBAHXXwqFlkCJNqU+36Pa3d+CppSnO
         EzH9bcWRMskUcikgJZhrqw9TezOuRlbN5vIDhxkUxIBbT09Ub0hvnahgT1xJ99AbHqjg
         1deJsnqO2AsmkjLf6+KsZOhSaSsBHRXsn7qd6JvCjaDN63gnpX8BWrr2JT0mj7UWHXmV
         DixwoB6Z5ocJ7Q4Zo6kprhdHko9+cGjyMZ79Hd4zcQlOl+jTGHVsaxHNlsou39VFomrn
         qNnH9CTAFIExduDvEP08wl/hi9CboQIlJe+Sk0nyKTSddQqBlqcCZPvGU7HXwGVXK7a6
         6ySg==
X-Gm-Message-State: ALoCoQnLPE7SG9oUJP6QLUwG/6JzpAHLpMYUCJIuS8pUXbsAhykqGU+hAZhQLM9lxPBzhmiRKsyI
MIME-Version: 1.0
X-Received: by 10.224.46.67 with SMTP id i3mr7418531qaf.90.1410483751068; Thu,
 11 Sep 2014 18:02:31 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Thu, 11 Sep 2014 18:02:31 -0700 (PDT)
Date: Thu, 11 Sep 2014 18:02:31 -0700
Message-ID: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
Subject: Reporting serialized task size after task broadcast change?
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c29feef1c00e0502d3d619
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c29feef1c00e0502d3d619
Content-Type: text/plain; charset=UTF-8

After the change to broadcast all task data, is there any easy way to
discover the serialized size of the data getting sent down for a task?

thanks,
-Sandy

--001a11c29feef1c00e0502d3d619--

From dev-return-9412-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:26:52 2014
Return-Path: <dev-return-9412-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EBF011623
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:26:52 +0000 (UTC)
Received: (qmail 1398 invoked by uid 500); 12 Sep 2014 01:26:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1325 invoked by uid 500); 12 Sep 2014 01:26:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1313 invoked by uid 99); 12 Sep 2014 01:26:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:26:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.54] (HELO mail-qg0-f54.google.com) (209.85.192.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:26:26 +0000
Received: by mail-qg0-f54.google.com with SMTP id z60so41493qgd.13
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:26:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=Rb5wlV3E3iivawjB2kTPNNkEbo9ThcALq9pe635XyAw=;
        b=ePNEHKi4hWPOl8FFTR0xr28OxPVzR9BRfXkBQj2YEBAOCZC41rM2+26b0J2amBmVKO
         Sda2WVTCzeybSj+MGd7OYi+I3Hv6E1esdqj57alY0M4RYWf/rFjXxwXSc8UJIqA8GCF0
         kwoRs4+8ik2yY1xzgg7Z8NGhP09G08pVSNaAoha8VpBg78WTjABOdUJbMleTALZuMlgc
         olLS8AendHd0c9UuUlywFPQ45k/j/1M9df9cqClMcIDeMTvseU2ZG3OdXRd+9xvKXSUR
         2RniCMsN+oGOQ4si0kRA0V1O8LpifBJ/tpCw6IkLLnNOASxTFlqX2fGN0ajoLYh0ub+U
         fzHg==
X-Gm-Message-State: ALoCoQkF6+ZpuKps3ZdPYLRD6PO/VAyiKMrdxoUMLKkzz5sxnzecFYrPjc/PM6eKMl8TXUjK5NtZ
MIME-Version: 1.0
X-Received: by 10.229.68.131 with SMTP id v3mr7676306qci.10.1410485184525;
 Thu, 11 Sep 2014 18:26:24 -0700 (PDT)
Received: by 10.96.41.34 with HTTP; Thu, 11 Sep 2014 18:26:24 -0700 (PDT)
In-Reply-To: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
Date: Thu, 11 Sep 2014 18:26:24 -0700
Message-ID: <CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com>
Subject: Re: Reporting serialized task size after task broadcast change?
From: Reynold Xin <rxin@databricks.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113395926297860502d42c21
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113395926297860502d42c21
Content-Type: text/plain; charset=UTF-8

I don't think so. We should probably add a line to log it.

On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> After the change to broadcast all task data, is there any easy way to
> discover the serialized size of the data getting sent down for a task?
>
> thanks,
> -Sandy
>

--001a113395926297860502d42c21--

From dev-return-9413-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:30:18 2014
Return-Path: <dev-return-9413-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0F24A11630
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:30:18 +0000 (UTC)
Received: (qmail 8728 invoked by uid 500); 12 Sep 2014 01:30:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8662 invoked by uid 500); 12 Sep 2014 01:30:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8651 invoked by uid 99); 12 Sep 2014 01:30:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:30:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.171 as permitted sender)
Received: from [209.85.216.171] (HELO mail-qc0-f171.google.com) (209.85.216.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:30:12 +0000
Received: by mail-qc0-f171.google.com with SMTP id x3so49000qcv.30
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:29:51 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=cyrxCSR0x9SI5iN1jlYd/CqYdKZKxlw+O54wEuFPBOE=;
        b=ETvj4MVSiqwL6kIaYOIelkSOTYbz2hOLcPjiX1mYT43Qj3+LxjMhh2dwvtGOWNAPmG
         TN+4UFNztADvxH5MP1ZTw507ugxxJhG2IKrIEnS8vvbeXWUU7O07y3H6Xt2+NQH3xddF
         ww0DT8i63mp0OyiI7BniFn7MfAZgS+Jq62uk0DU7hvVVGIFRkWVP4+EIZlTMqQSX6u7z
         kd2HJAenC8IqAnjFesF7wysdNI1B/lNm723gJ3mTWdqYHXf1VoC0rTzDyX3fYyKA2nDh
         KKJHc7trmBLMQfesnjI5O/Li9eWOsD5c/9429HxHX3Tctm0Ak64pXzL88cgAgYTU9/ND
         tqsQ==
X-Gm-Message-State: ALoCoQlqnIXVlR4jFj6pHDj+KNXOlsNAYY7GTzS6IHopKY84GjVlYvCYKzr/KhSmoMc9R7Sy7ryB
MIME-Version: 1.0
X-Received: by 10.224.123.9 with SMTP id n9mr7650542qar.84.1410485391620; Thu,
 11 Sep 2014 18:29:51 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Thu, 11 Sep 2014 18:29:51 -0700 (PDT)
In-Reply-To: <CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com>
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
	<CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com>
Date: Thu, 11 Sep 2014 18:29:51 -0700
Message-ID: <CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com>
Subject: Re: Reporting serialized task size after task broadcast change?
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01536d20baaf6d0502d438aa
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01536d20baaf6d0502d438aa
Content-Type: text/plain; charset=UTF-8

It used to be available on the UI, no?

On Thu, Sep 11, 2014 at 6:26 PM, Reynold Xin <rxin@databricks.com> wrote:

> I don't think so. We should probably add a line to log it.
>
>
> On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> After the change to broadcast all task data, is there any easy way to
>> discover the serialized size of the data getting sent down for a task?
>>
>> thanks,
>> -Sandy
>>
>

--089e01536d20baaf6d0502d438aa--

From dev-return-9414-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:34:14 2014
Return-Path: <dev-return-9414-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4AE3F11643
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:34:14 +0000 (UTC)
Received: (qmail 22777 invoked by uid 500); 12 Sep 2014 01:34:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22703 invoked by uid 500); 12 Sep 2014 01:34:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22690 invoked by uid 99); 12 Sep 2014 01:34:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:34:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.44] (HELO mail-qg0-f44.google.com) (209.85.192.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:33:47 +0000
Received: by mail-qg0-f44.google.com with SMTP id f51so45512qge.31
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:33:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=1rfeAwA/kkb4BfYlm2FolcR03kMWGN3duLkl9OtJoZE=;
        b=ZNrcnn9p2Tn1F2NemqcnJwHSJmEfBc0E4tuznBlTJeX2xTfuhirtrYuNeVJ26JFts6
         MDL+JA/gKLEuRLyAZ01MWGxDzhsPWoqwemvqZEFQB/cqm6wSvpDPkTLrCkXnvCcHrKP4
         /yDzqnrZBx5jGKcciU+8d0E7TSjn6gaJtBSm4lBb7wQIuRz5vETxF3jhtMhcXS6p9a7+
         wOX1n4FYxU+g3tjPTyNdkSk4lq6VWZbfImmZF2AOZECwqrnohoYu8HNx2BkToUBbdB7B
         p/LxBTl50roytL2ki0jOR1u1DJAnZYxnp/ldEr3mieSzEmDATuJpVwUxoyvcb38f9ZCP
         Bcvw==
X-Gm-Message-State: ALoCoQlb2GNj2IvrqeQtOkz8QePA5A8BFpDV6RXt33STqwb4yEoH2zDWs19By/4y7NJ/XrIm2/BK
X-Received: by 10.140.96.200 with SMTP id k66mr8139902qge.78.1410485624935;
 Thu, 11 Sep 2014 18:33:44 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Thu, 11 Sep 2014 18:33:24 -0700 (PDT)
In-Reply-To: <CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com>
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
 <CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com> <CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Thu, 11 Sep 2014 18:33:24 -0700
Message-ID: <CAPh_B=YeUtFCZ+Ebnz7fNJFHKVcBKpPKJGZgxitL-TNeTEgyYg@mail.gmail.com>
Subject: Re: Reporting serialized task size after task broadcast change?
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11396846a2adcd0502d44610
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11396846a2adcd0502d44610
Content-Type: text/plain; charset=UTF-8

I didn't know about that ....

On Thu, Sep 11, 2014 at 6:29 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> It used to be available on the UI, no?
>
> On Thu, Sep 11, 2014 at 6:26 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > I don't think so. We should probably add a line to log it.
> >
> >
> > On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com>
> > wrote:
> >
> >> After the change to broadcast all task data, is there any easy way to
> >> discover the serialized size of the data getting sent down for a task?
> >>
> >> thanks,
> >> -Sandy
> >>
> >
>

--001a11396846a2adcd0502d44610--

From dev-return-9415-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:35:34 2014
Return-Path: <dev-return-9415-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EADE31164A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:35:34 +0000 (UTC)
Received: (qmail 26584 invoked by uid 500); 12 Sep 2014 01:35:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26496 invoked by uid 500); 12 Sep 2014 01:35:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25420 invoked by uid 99); 12 Sep 2014 01:35:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:35:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.192.176 as permitted sender)
Received: from [209.85.192.176] (HELO mail-pd0-f176.google.com) (209.85.192.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:35:27 +0000
Received: by mail-pd0-f176.google.com with SMTP id y13so84455pdi.7
        for <multiple recipients>; Thu, 11 Sep 2014 18:35:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=hOpyVxGeZ/3A8Y0O8+I0edFblXBqadriGDbnMwFq408=;
        b=ZpZ/FvhHtXTk6DsZMXLNjel3ZpITmf1fi3bu6bVcsy4t26h64HqC48rEu0XGp3Jh5v
         PU/hkXV9KtVxnr8JGAsGboZTcjZS2WN/4JkjvRPJqwCHLYSUzU2sEgJgZ4b0aXTGaacK
         6I2a0U8uTHS/Wm0TT3akVlQQSRUx6XWXJmnQ4qqAR800bX37i/eh7hmM1Mln4EVUFZkF
         aah8+p9dU57I0/ehS+DWKf6VOXVUT29nhbRLLmPx+e8u5rPuHbscIgHNfTC4gd16UZgq
         4bF3/09mAtRV+9i9A/E9Qp5zWQunrjjGS54hBP/qqU0N89NhxpkaPNwQwkI20bYt/XU+
         VWPA==
X-Received: by 10.66.158.200 with SMTP id ww8mr6863515pab.15.1410485706648;
        Thu, 11 Sep 2014 18:35:06 -0700 (PDT)
Received: from gallifrey.local ([2601:8:9880:5e8:d8dc:17a0:84fb:74c3])
        by mx.google.com with ESMTPSA id dn5sm2273993pbb.2.2014.09.11.18.35.05
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 18:35:06 -0700 (PDT)
Date: Thu, 11 Sep 2014 18:35:04 -0700
From: Denny Lee <denny.g.lee@gmail.com>
To: user@spark.apache.org, Haopu Wang <hwang@qilinsoft.com>, 
 dev@spark.apache.org, Patrick Wendell <pwendell@gmail.com>
Message-ID: <etPan.54124dc8.7545e146.18e2@gallifrey.local>
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13A957@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13A957@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Subject: RE: Announcing Spark 1.1.0!
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54124dc8_515f007c_18e2"
X-Virus-Checked: Checked by ClamAV on apache.org

--54124dc8_515f007c_18e2
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I=E2=80=99m not sure if I=E2=80=99m completely answering your question he=
re but I=E2=80=99m currently working (on OSX) with Hadoop 2.5 and I used =
the Spark 1.1 with Hadoop 2.4 without any issues.


On September 11, 2014 at 18:11:46, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

I see the binary packages include hadoop 1, 2.3 and 2.4. =20
Does Spark 1.1.0 support hadoop 2.5.0 at below address=3F =20

http://hadoop.apache.org/releases.html=2311+August%2C+2014%3A+Release+2.5=
.0+available =20

-----Original Message----- =20
=46rom: Patrick Wendell =5Bmailto:pwendell=40gmail.com=5D =20
Sent: =46riday, September 12, 2014 8:13 AM =20
To: dev=40spark.apache.org; user=40spark.apache.org =20
Subject: Announcing Spark 1.1.0=21 =20

I am happy to announce the availability of Spark 1.1.0=21 Spark 1.1.0 is =
=20
the second release on the API-compatible 1.X line. It is Spark's =20
largest release ever, with contributions from 171 developers=21 =20

This release brings operational and performance improvements in Spark =20
core including a new implementation of the Spark shuffle designed for =20
very large scale workloads. Spark 1.1 adds significant extensions to =20
the newest Spark modules, MLlib and Spark SQL. Spark SQL introduces a =20
JDBC server, byte code generation for fast expression evaluation, a =20
public types API, JSON support, and other features and optimizations. =20
MLlib introduces a new statistics library along with several new =20
algorithms and optimizations. Spark 1.1 also builds out Spark's Python =20
support and adds new components to the Spark Streaming module. =20

Visit the release notes =5B1=5D to read about the new features, or =20
download =5B2=5D the release today. =20

=5B1=5D http://spark.eu.apache.org/releases/spark-release-1-1-0.html =20
=5B2=5D http://spark.eu.apache.org/downloads.html =20

NOTE: SOME AS=46 DOWNLOAD MIRRORS WILL NOT CONTAIN THE RELEASE =46OR SEVE=
RAL HOURS. =20

Please e-mail me directly for any type-o's in the release notes or name l=
isting. =20

Thanks, and congratulations=21 =20
- Patrick =20

--------------------------------------------------------------------- =20
To unsubscribe, e-mail: user-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: user-help=40spark.apache.org =20


--54124dc8_515f007c_18e2--


From dev-return-9416-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 01:48:28 2014
Return-Path: <dev-return-9416-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 300F711685
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 01:48:28 +0000 (UTC)
Received: (qmail 49067 invoked by uid 500); 12 Sep 2014 01:48:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48993 invoked by uid 500); 12 Sep 2014 01:48:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48981 invoked by uid 99); 12 Sep 2014 01:48:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:48:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.173 as permitted sender)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:48:01 +0000
Received: by mail-qc0-f173.google.com with SMTP id w7so67101qcr.32
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:47:59 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=RmWQ3/pwuFlZInh6JPLB2q7I64O2X9B2I2M0x4hph7I=;
        b=CTVMey8NWF8u845txIlmeEG/VA96mZtyPF3kVoRdoMCl672k8JPHG7KVJ/DTybMXU8
         rxJtvL3vns6J7XJV5fJc5FBswstB8GcgU6cRpINbwj2kVLZ5P5ARa0/AVccPw/V91xTA
         xaCOXnPZp9fjxTH2Y8XrLqjYwDb7xQa5z1MX8xM7hgYLkqimnkFb4YD17KMjXshLjZal
         /fRIV6PdP8GuoENtvygzcvOKzL+QBLkIm5+TMBdBAuqYm4BTz8Ar2Wy3RCmo0UIXroSx
         GaI647bzPldc79Ora1sLMM6Lb/y7xmVUMbnyIzulW1hY295cohMpoqUfBx6YBVqbSEoz
         eqyg==
X-Gm-Message-State: ALoCoQmxYOm9hWrPZxWtzlwoHEbsoOqbBlBin7F8PzpdAcdCIJ2LLu60zVWn7+YUgUthyJphF0qa
MIME-Version: 1.0
X-Received: by 10.224.46.67 with SMTP id i3mr7702931qaf.90.1410486479813; Thu,
 11 Sep 2014 18:47:59 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Thu, 11 Sep 2014 18:47:59 -0700 (PDT)
In-Reply-To: <CAPh_B=YeUtFCZ+Ebnz7fNJFHKVcBKpPKJGZgxitL-TNeTEgyYg@mail.gmail.com>
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
	<CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com>
	<CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com>
	<CAPh_B=YeUtFCZ+Ebnz7fNJFHKVcBKpPKJGZgxitL-TNeTEgyYg@mail.gmail.com>
Date: Thu, 11 Sep 2014 18:47:59 -0700
Message-ID: <CACBYxKKW9c3eM-tgbanOy-1reeFncaDzMa8vJ=1yzptU1fzK6Q@mail.gmail.com>
Subject: Re: Reporting serialized task size after task broadcast change?
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c29fee9722d10502d47928
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c29fee9722d10502d47928
Content-Type: text/plain; charset=UTF-8

Hmm, well I can't find it now, must have been hallucinating.  Do you know
off the top of your head where I'd be able to find the size to log it?

On Thu, Sep 11, 2014 at 6:33 PM, Reynold Xin <rxin@databricks.com> wrote:

> I didn't know about that ....
>
> On Thu, Sep 11, 2014 at 6:29 PM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> It used to be available on the UI, no?
>>
>> On Thu, Sep 11, 2014 at 6:26 PM, Reynold Xin <rxin@databricks.com> wrote:
>>
>> > I don't think so. We should probably add a line to log it.
>> >
>> >
>> > On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com>
>> > wrote:
>> >
>> >> After the change to broadcast all task data, is there any easy way to
>> >> discover the serialized size of the data getting sent down for a task?
>> >>
>> >> thanks,
>> >> -Sandy
>> >>
>> >
>>
>
>

--001a11c29fee9722d10502d47928--

From dev-return-9417-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 02:00:15 2014
Return-Path: <dev-return-9417-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 48742116C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 02:00:15 +0000 (UTC)
Received: (qmail 58087 invoked by uid 500); 12 Sep 2014 02:00:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58013 invoked by uid 500); 12 Sep 2014 02:00:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58002 invoked by uid 99); 12 Sep 2014 02:00:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 02:00:12 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 01:59:46 +0000
Received: by mail-qc0-f177.google.com with SMTP id i8so76809qcq.36
        for <dev@spark.apache.org>; Thu, 11 Sep 2014 18:59:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=QcMAErLunJEOeH0T28cRhak5B2XyfFbWNfj+UcPsJS8=;
        b=Yrz1cAYtYD65ZvBTP7yAlnU2ta2e0Df04kTY5k8szllZI80H9jJrzd2A2Ltqb+Nr8j
         ezVHnxKRByuob380/b5epBde4+j1OUfGRGjqOkkmI12e02SYhJwlXrTkUxfOSJ0+0STm
         kbRdFJRyiONyfvMX/ZjxuHqMEUM2bbKEnBBAOkl6Ba3I6PMQJnG1NLDtG/ZkvtMCfFXW
         6XEiXZzZGRjM52W5PJqriyQ8k0T1fT07sXA1urBUmJ3qhEKHQfskTY6VJ0cuW8i/pYfN
         mS0Gf6qE++rd7GgSfNx2hcnNmDtQ2A3CSu1PKz/8wAmr6OgF7FtyFLNkt2mtNtJXHJU8
         I0NQ==
X-Gm-Message-State: ALoCoQnHkia9UTh51TBnCkqBI1brVdBVoCusxTI2R18W7eewww/4fsVrbIuoFb0YyexxAzk6HfjG
MIME-Version: 1.0
X-Received: by 10.224.79.13 with SMTP id n13mr7687104qak.79.1410487185327;
 Thu, 11 Sep 2014 18:59:45 -0700 (PDT)
Received: by 10.96.41.34 with HTTP; Thu, 11 Sep 2014 18:59:45 -0700 (PDT)
In-Reply-To: <CACBYxKKW9c3eM-tgbanOy-1reeFncaDzMa8vJ=1yzptU1fzK6Q@mail.gmail.com>
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com>
	<CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com>
	<CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com>
	<CAPh_B=YeUtFCZ+Ebnz7fNJFHKVcBKpPKJGZgxitL-TNeTEgyYg@mail.gmail.com>
	<CACBYxKKW9c3eM-tgbanOy-1reeFncaDzMa8vJ=1yzptU1fzK6Q@mail.gmail.com>
Date: Thu, 11 Sep 2014 18:59:45 -0700
Message-ID: <CAPh_B=awtb=4dqB-jUXZamoxz4GU=551MHVzvEd-TbwvOtJTaw@mail.gmail.com>
Subject: Re: Reporting serialized task size after task broadcast change?
From: Reynold Xin <rxin@databricks.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc8016a4917c0502d4a337
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc8016a4917c0502d4a337
Content-Type: text/plain; charset=UTF-8

It is in the dag scheduler. Look for broadcast.

On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> Hmm, well I can't find it now, must have been hallucinating.  Do you know
> off the top of your head where I'd be able to find the size to log it?
>
> On Thu, Sep 11, 2014 at 6:33 PM, Reynold Xin <rxin@databricks.com
> <javascript:_e(%7B%7D,'cvml','rxin@databricks.com');>> wrote:
>
>> I didn't know about that ....
>>
>> On Thu, Sep 11, 2014 at 6:29 PM, Sandy Ryza <sandy.ryza@cloudera.com
>> <javascript:_e(%7B%7D,'cvml','sandy.ryza@cloudera.com');>> wrote:
>>
>>> It used to be available on the UI, no?
>>>
>>> On Thu, Sep 11, 2014 at 6:26 PM, Reynold Xin <rxin@databricks.com
>>> <javascript:_e(%7B%7D,'cvml','rxin@databricks.com');>> wrote:
>>>
>>> > I don't think so. We should probably add a line to log it.
>>> >
>>> >
>>> > On Thursday, September 11, 2014, Sandy Ryza <sandy.ryza@cloudera.com
>>> <javascript:_e(%7B%7D,'cvml','sandy.ryza@cloudera.com');>>
>>> > wrote:
>>> >
>>> >> After the change to broadcast all task data, is there any easy way to
>>> >> discover the serialized size of the data getting sent down for a task?
>>> >>
>>> >> thanks,
>>> >> -Sandy
>>> >>
>>> >
>>>
>>
>>
>

--047d7bdc8016a4917c0502d4a337--

From dev-return-9418-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 02:00:44 2014
Return-Path: <dev-return-9418-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 96147116CD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 02:00:44 +0000 (UTC)
Received: (qmail 62163 invoked by uid 500); 12 Sep 2014 02:00:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62096 invoked by uid 500); 12 Sep 2014 02:00:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60919 invoked by uid 99); 12 Sep 2014 02:00:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 02:00:41 +0000
X-ASF-Spam-Status: No, hits=1.8 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.49 as permitted sender)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 02:00:14 +0000
Received: by mail-pa0-f49.google.com with SMTP id lf10so125307pab.8
        for <multiple recipients>; Thu, 11 Sep 2014 19:00:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=CCtj9o+RvP7RLZtMmpCDMRTGN3lms+IVbdlP8AN7OLY=;
        b=jWFUj71UPIQp78bJMByp/xEMVyorO3bBnKyJ9IM59ksoT4JgTB+I/kCZFNJyvo8sIh
         2bthcBywvV2tOGdk7tVNSyqhnGsXhrw3DRuh2uSZGkW93/3ycelx8lkpa2IfgOSECpsM
         K4xnlqiRAugXGvbLq4r0WLpAI+wdbR1CYCsF1+W36EFfS/N3WxE+9D4ooQ9beGc9q2+z
         Q2zAmxrw4ojazDCIHIp2Qavcpw/BN1nDslW0vdIU4KQ1e+X9uL5ufV+106qBP4U6PNEY
         pzIHg7sofAUZsp6atwbi5q4uVgpKEHhN0iTSgIqbbwpBR6j4lCiemEx2Mh465YK6DdaL
         kwgw==
X-Received: by 10.70.96.102 with SMTP id dr6mr7554101pdb.86.1410487212835;
        Thu, 11 Sep 2014 19:00:12 -0700 (PDT)
Received: from gallifrey.local (c-71-231-196-182.hsd1.wa.comcast.net. [71.231.196.182])
        by mx.google.com with ESMTPSA id df10sm2275926pdb.25.2014.09.11.19.00.11
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 19:00:12 -0700 (PDT)
Date: Thu, 11 Sep 2014 19:00:10 -0700
From: Denny Lee <denny.g.lee@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>, Haopu Wang
 <hwang@qilinsoft.com>, dev@spark.apache.org, user@spark.apache.org
Message-ID: <etPan.541253aa.4db127f8.18e2@gallifrey.local>
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13A95A@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13A95A@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Subject: RE: Announcing Spark 1.1.0!
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="541253aa_216231b_18e2"
X-Virus-Checked: Checked by ClamAV on apache.org

--541253aa_216231b_18e2
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Please correct me if I=E2=80=99m wrong but I was under the impression as =
per the maven repositories that it was just to stay more in sync with the=
 various version of Hadoop. =C2=A0Looking at the latest documentation (ht=
tps://spark.apache.org/docs/latest/building-with-maven.html), there are m=
ultiple Hadoop versions called out.

As for the potential differences in Spark, this is more about ensuring th=
e various jars and library dependencies of the correct version of Hadoop =
are included so there can be proper connectivity to Hadoop from Spark vs.=
 any differences in Spark itself. =C2=A0 Another good reference on this t=
opic is call out for Hadoop versions within github:=C2=A0https://github.c=
om/apache/spark

HTH=21


On September 11, 2014 at 18:39:10, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

Danny, thanks for the response.

=C2=A0

I raise the question because in Spark 1.0.2, I saw one binary package for=
 hadoop2, but in Spark 1.1.0, there are separate packages for hadoop 2.3 =
and 2.4.

That implies some difference in Spark according to hadoop version.

=C2=A0

=46rom:Denny Lee =5Bmailto:denny.g.lee=40gmail.com=5D
Sent: =46riday, September 12, 2014 9:35 AM
To: user=40spark.apache.org; Haopu Wang; dev=40spark.apache.org; Patrick =
Wendell
Subject: RE: Announcing Spark 1.1.0=21

=C2=A0

I=E2=80=99m not sure if I=E2=80=99m completely answering your question he=
re but I=E2=80=99m currently working (on OSX) with Hadoop 2.5 and I used =
the Spark 1.1 with Hadoop 2.4 without any issues.

=C2=A0

=C2=A0

On September 11, 2014 at 18:11:46, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

I see the binary packages include hadoop 1, 2.3 and 2.4.
Does Spark 1.1.0 support hadoop 2.5.0 at below address=3F

http://hadoop.apache.org/releases.html=2311+August%2C+2014%3A+Release+2.5=
.0+available

-----Original Message-----
=46rom: Patrick Wendell =5Bmailto:pwendell=40gmail.com=5D
Sent: =46riday, September 12, 2014 8:13 AM
To: dev=40spark.apache.org; user=40spark.apache.org
Subject: Announcing Spark 1.1.0=21

I am happy to announce the availability of Spark 1.1.0=21 Spark 1.1.0 is
the second release on the API-compatible 1.X line. It is Spark's
largest release ever, with contributions from 171 developers=21

This release brings operational and performance improvements in Spark
core including a new implementation of the Spark shuffle designed for
very large scale workloads. Spark 1.1 adds significant extensions to
the newest Spark modules, MLlib and Spark SQL. Spark SQL introduces a
JDBC server, byte code generation for fast expression evaluation, a
public types API, JSON support, and other features and optimizations.
MLlib introduces a new statistics library along with several new
algorithms and optimizations. Spark 1.1 also builds out Spark's Python
support and adds new components to the Spark Streaming module.

Visit the release notes =5B1=5D to read about the new features, or
download =5B2=5D the release today.

=5B1=5D http://spark.eu.apache.org/releases/spark-release-1-1-0.html
=5B2=5D http://spark.eu.apache.org/downloads.html

NOTE: SOME AS=46 DOWNLOAD MIRRORS WILL NOT CONTAIN THE RELEASE =46OR SEVE=
RAL HOURS.

Please e-mail me directly for any type-o's in the release notes or name l=
isting.

Thanks, and congratulations=21
- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: user-unsubscribe=40spark.apache.org
=46or additional commands, e-mail: user-help=40spark.apache.org
--541253aa_216231b_18e2--


From dev-return-9419-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 02:06:35 2014
Return-Path: <dev-return-9419-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 19E3C116FB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 02:06:35 +0000 (UTC)
Received: (qmail 79000 invoked by uid 500); 12 Sep 2014 02:06:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78923 invoked by uid 500); 12 Sep 2014 02:06:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78902 invoked by uid 99); 12 Sep 2014 02:06:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 02:06:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wyphao.2007@163.com designates 220.181.13.91 as permitted sender)
Received: from [220.181.13.91] (HELO m13-91.163.com) (220.181.13.91)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 02:06:26 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:MIME-Version:Message-ID; bh=LG4pu
	AKpCvskIDVCzmtkagni+N+jd5WIkE5cu13V6hk=; b=I97ZlcaupRBqbuw3LUuq+
	HKVMk+LBubeDL9HAPdClX7pePuqSl9XKT+AUJQCv/FPVgehq+2XcoIJBZidu3QjK
	K78qOmcqyzpveUTjvecUQ0dM2fEnted3930SaSHu2udKFgJNLbiwmLJeAAfK3/kR
	v1mVew72VReZQ/Pl/0m9kQ=
Received: from wyphao.2007$163.com ( [211.151.238.51] ) by
 ajax-webmail-wmsvr91 (Coremail) ; Fri, 12 Sep 2014 10:05:48 +0800 (CST)
X-Originating-IP: [211.151.238.51]
Date: Fri, 12 Sep 2014 10:05:48 +0800 (CST)
From: "wyphao.2007" <wyphao.2007@163.com>
To: dev@spark.apache.org, user@spark.apache.org
Subject: How to use jdbcRDD in JAVA
X-Priority: 3
X-Mailer: Coremail Webmail Server Version SP_ntes V3.5 build
 20140725(28226.6623) Copyright (c) 2002-2014 www.mailtech.cn 163com
X-CM-CTRLDATA: x9+ZvmZvb3Rlcl9odG09NzEwOjgx
Content-Type: multipart/alternative; 
	boundary="----=_Part_560510_1844436902.1410487548201"
MIME-Version: 1.0
Message-ID: <3ab722e4.2bc8.148679bf929.Coremail.wyphao.2007@163.com>
X-CM-TRANSID:W8GowED5LUMMVRJUSpPTAA--.913W
X-CM-SenderInfo: xz1sxtbrosiiqx6rljoofrz/1tbiXBUFKFEAKNY2IwAAse
X-Coremail-Antispam: 1U5529EdanIXcx71UUUUU7vcSsGvfC2KfnxnUU==
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_560510_1844436902.1410487548201
Content-Type: text/plain; charset=GBK
Content-Transfer-Encoding: base64

SGksSSB3YW50IHRvIGtub3cgaG93IHRvIHVzZSBqZGJjUkREIGluIEpBVkEgbm90IHNjYWxhLCB0
cnlpbmcgdG8gZmlndXJlIG91dCB0aGUgbGFzdCBwYXJhbWV0ZXIgaW4gdGhlIGNvbnN0cnVjdG9y
IG9mIGpkYmNSREQKCgp0aGFua3M=
------=_Part_560510_1844436902.1410487548201--


From dev-return-9420-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 03:04:03 2014
Return-Path: <dev-return-9420-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6E9C711836
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 03:04:03 +0000 (UTC)
Received: (qmail 45964 invoked by uid 500); 12 Sep 2014 03:04:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43882 invoked by uid 500); 12 Sep 2014 03:03:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43859 invoked by uid 99); 12 Sep 2014 03:03:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 03:03:57 +0000
X-ASF-Spam-Status: No, hits=1.8 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.46 as permitted sender)
Received: from [209.85.220.46] (HELO mail-pa0-f46.google.com) (209.85.220.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 03:03:53 +0000
Received: by mail-pa0-f46.google.com with SMTP id kq14so225180pab.33
        for <multiple recipients>; Thu, 11 Sep 2014 20:03:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=l4pTn8FQqgbpn4HQ0dW+wr9kbhUjR0kPCK0/HJs5U1s=;
        b=T92XNAZlABKk6UP+lTLKowg1TVLH5R+nHC5lFYqP4BRTL4TYC0jqUXVK8rbJTfBeTI
         uBsSWzxWCcWIR3dQt6b+viMfBYzM0Xk3FhmjN34If/IeOuBaM7ztwJpUBTX+V7ZFawHh
         yHnxR+la0FJ07cUPO/UmZxO095oW9nhqoDhvKjM3jZ5RjSSqhelQ+kyyL5mAQMKg0EkD
         OdYF2gRF+NTf3ly0w/MiNdiw/2TClwItL7+uG6asFUhQzlBqK4xbq0rYtWrKmmQ60hgQ
         NXxMh8d/3LYB73UlKXwT+cflsh00PoR2q75lJ17geJJnf2yc5vNMYUP/QEmuTfHfaieT
         7vlw==
X-Received: by 10.70.126.168 with SMTP id mz8mr7962158pdb.3.1410491012478;
        Thu, 11 Sep 2014 20:03:32 -0700 (PDT)
Received: from gallifrey.local ([2601:8:9880:5e8:d8dc:17a0:84fb:74c3])
        by mx.google.com with ESMTPSA id e11sm2333286pdm.47.2014.09.11.20.03.31
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 11 Sep 2014 20:03:31 -0700 (PDT)
Date: Thu, 11 Sep 2014 20:03:30 -0700
From: Denny Lee <denny.g.lee@gmail.com>
To: user@spark.apache.org, Haopu Wang <hwang@qilinsoft.com>, 
 dev@spark.apache.org, Patrick Wendell <pwendell@gmail.com>
Message-ID: <etPan.54126283.1f16e9e8.18e2@gallifrey.local>
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13A960@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13A960@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Subject: RE: Announcing Spark 1.1.0!
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54126283_1190cde7_18e2"
X-Virus-Checked: Checked by ClamAV on apache.org

--54126283_1190cde7_18e2
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Yes, atleast for my query scenarios, I have been able to use Spark 1.1 wi=
th Hadoop 2.4 against Hadoop 2.5. =C2=A0Note, Hadoop 2.5 is considered a =
relatively minor release (http://hadoop.apache.org/releases.html=2311+Aug=
ust%2C+2014%3A+Release+2.5.0+available) where Hadoop 2.4 and 2.3 were con=
sidered more significant releases.



On September 11, 2014 at 19:22:05, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

=46rom the web page (https://spark.apache.org/docs/latest/building-with-m=
aven.html) which is pointed out by you, it=E2=80=99s saying =E2=80=9CBeca=
use HD=46S is not protocol-compatible across versions, if you want to rea=
d from HD=46S, you=E2=80=99ll need to build Spark against the specific HD=
=46S version in your environment.=E2=80=9D

=C2=A0

Did you try to read a hadoop 2.5.0 file using Spark 1.1 with hadoop 2.4=3F=


=C2=A0

Thanks=21

=C2=A0

=46rom:Denny Lee =5Bmailto:denny.g.lee=40gmail.com=5D
Sent: =46riday, September 12, 2014 10:00 AM
To: Patrick Wendell; Haopu Wang; dev=40spark.apache.org; user=40spark.apa=
che.org
Subject: RE: Announcing Spark 1.1.0=21

=C2=A0

Please correct me if I=E2=80=99m wrong but I was under the impression as =
per the maven repositories that it was just to stay more in sync with the=
 various version of Hadoop. =C2=A0Looking at the latest documentation (ht=
tps://spark.apache.org/docs/latest/building-with-maven.html), there are m=
ultiple Hadoop versions called out.

=C2=A0

As for the potential differences in Spark, this is more about ensuring th=
e various jars and library dependencies of the correct version of Hadoop =
are included so there can be proper connectivity to Hadoop from Spark vs.=
 any differences in Spark itself. =C2=A0 Another good reference on this t=
opic is call out for Hadoop versions within github:=C2=A0https://github.c=
om/apache/spark

=C2=A0

HTH=21

=C2=A0

=C2=A0

On September 11, 2014 at 18:39:10, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

Danny, thanks for the response.

=C2=A0

I raise the question because in Spark 1.0.2, I saw one binary package for=
 hadoop2, but in Spark 1.1.0, there are separate packages for hadoop 2.3 =
and 2.4.

That implies some difference in Spark according to hadoop version.

=C2=A0

=46rom:Denny Lee =5Bmailto:denny.g.lee=40gmail.com=5D
Sent: =46riday, September 12, 2014 9:35 AM
To: user=40spark.apache.org; Haopu Wang; dev=40spark.apache.org; Patrick =
Wendell
Subject: RE: Announcing Spark 1.1.0=21

=C2=A0

I=E2=80=99m not sure if I=E2=80=99m completely answering your question he=
re but I=E2=80=99m currently working (on OSX) with Hadoop 2.5 and I used =
the Spark 1.1 with Hadoop 2.4 without any issues.

=C2=A0

=C2=A0

On September 11, 2014 at 18:11:46, Haopu Wang (hwang=40qilinsoft.com) wro=
te:

I see the binary packages include hadoop 1, 2.3 and 2.4.
Does Spark 1.1.0 support hadoop 2.5.0 at below address=3F

http://hadoop.apache.org/releases.html=2311+August%2C+2014%3A+Release+2.5=
.0+available

-----Original Message-----
=46rom: Patrick Wendell =5Bmailto:pwendell=40gmail.com=5D
Sent: =46riday, September 12, 2014 8:13 AM
To: dev=40spark.apache.org; user=40spark.apache.org
Subject: Announcing Spark 1.1.0=21

I am happy to announce the availability of Spark 1.1.0=21 Spark 1.1.0 is
the second release on the API-compatible 1.X line. It is Spark's
largest release ever, with contributions from 171 developers=21

This release brings operational and performance improvements in Spark
core including a new implementation of the Spark shuffle designed for
very large scale workloads. Spark 1.1 adds significant extensions to
the newest Spark modules, MLlib and Spark SQL. Spark SQL introduces a
JDBC server, byte code generation for fast expression evaluation, a
public types API, JSON support, and other features and optimizations.
MLlib introduces a new statistics library along with several new
algorithms and optimizations. Spark 1.1 also builds out Spark's Python
support and adds new components to the Spark Streaming module.

Visit the release notes =5B1=5D to read about the new features, or
download =5B2=5D the release today.

=5B1=5D http://spark.eu.apache.org/releases/spark-release-1-1-0.html
=5B2=5D http://spark.eu.apache.org/downloads.html

NOTE: SOME AS=46 DOWNLOAD MIRRORS WILL NOT CONTAIN THE RELEASE =46OR SEVE=
RAL HOURS.

Please e-mail me directly for any type-o's in the release notes or name l=
isting.

Thanks, and congratulations=21
- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: user-unsubscribe=40spark.apache.org
=46or additional commands, e-mail: user-help=40spark.apache.org
--54126283_1190cde7_18e2--


From dev-return-9421-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 08:04:04 2014
Return-Path: <dev-return-9421-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF5C111EA1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 08:04:04 +0000 (UTC)
Received: (qmail 75426 invoked by uid 500); 12 Sep 2014 08:04:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75351 invoked by uid 500); 12 Sep 2014 08:04:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75340 invoked by uid 99); 12 Sep 2014 08:04:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:04:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:03:58 +0000
Received: by mail-ie0-f179.google.com with SMTP id rl12so448282iec.10
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 01:03:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=YeXjwxIqtB6yZz+4d27KgFmLOjRcxXyegcKez9FsFvk=;
        b=afz6QG0OwKEnSwjWiW2l/ICnZvtMnTj07yJyaAqoVTginxxZvsE1xxFs69zAspyAZK
         INkJmftl7Ou2STnMyDR/qJqtZXu9eNg4XT07L4E/G/4n8/M8E2JPIjhfxO2GEWbFrIrI
         2pUHQQKUddml4uNjY27HMK7ZF6nJeJxjVPh/2eVDMLKUj+0Iizuapo64Hm3sYk7Qt93v
         Y/rUMgoElmKLFEB6s9tbVC7PYEe2CMZVTCS2aTKCzkJ2Y+S3epiBP3rveZx8c+KaHxwv
         ZZLJRyLlhpEKfWidOA9IcFm2P9Pdr9H+KWPulGTDreK9jqah5Bp2ID2lyRDDdXN+5G7j
         bt5w==
X-Gm-Message-State: ALoCoQmx62LISrNJhLpbceIYOLf681fhceJjHBH6VXgJglmR3gR3T1lIR+3nZH8ojdMx+MPP3dgu
X-Received: by 10.43.158.195 with SMTP id lv3mr7818470icc.30.1410509017763;
 Fri, 12 Sep 2014 01:03:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.40.72 with HTTP; Fri, 12 Sep 2014 01:03:17 -0700 (PDT)
In-Reply-To: <1410470279838-8376.post@n3.nabble.com>
References: <1410470279838-8376.post@n3.nabble.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 12 Sep 2014 09:03:17 +0100
Message-ID: <CAMAsSdLDrbyAaP+zbEUyCw+r=09BB8S_MdXEVS1WQLTz4BrPbQ@mail.gmail.com>
Subject: Re: Questions regarding memory usage
To: Tom <thubregtsen@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Thu, Sep 11, 2014 at 10:17 PM, Tom <thubregtsen@gmail.com> wrote:
> If I set SPARK_DRIVER_MEMORY to x GB, Spark reports
> /14/09/11 15:36:41 INFO MemoryStore: MemoryStore started with capacity
> ~0.55*x GB/
> *Question:*
> Does this relate to spark.storage.memoryFraction (default 0.6), and is the
> other 0.4 used by spark.shulffle.memoryFraction (default 0.2) and spark
> general usage (0,2?).

Yes, that matches my understanding.


> Say I have two different programs:
> a)
> JavaPairRDD<String, String> a = file.flatMapToPair(some class());
> JavaPairRDD<String, String> b = a.reduceByKey(some class());
> JavaPairRDD<String, String> c = b.mapValues(some class());
>
> b)
> file.flatMapToPair(some class()).reduceByKey(some class()).mapValues(some
> class());
>
> I am now wondering which RDD's are actually created, and if they are the
> same in both situations:
> I could see a scenario in a) in which lazy evaluation has a similar
> situation too
> Int a, b, c;
> a = 0;
> b = a;
> c = b;
> Were the compiler removes a and b, and only stores c.

These programs create the same RDDs. The difference in how references
to JavaPairRDD are saved or moved around are immaterial. This is not
equivalent to the assignments you mention since these aren't
assignments, but method calls, and not least of which because they
have side effects.


> Now when I look into the output, I see
> /MappedRDD[37]/
> But I only defined 18 RDD's in my code with JavaPairRDD.
>
> *Question:*
> When are RDD's actually created? Can I trace these one-on-one in the output?

I would not necessarily take the [37] to be a count of RDDs created so
far, not necessarily. But they are not 1-1 with method calls,
necessarily, either. It shouldn't really matter. They are handles on
stages of computations, and are materialized or computed as needed for
you.


> When I run a program, I see the following lines:
> /14/09/11 15:36:44 INFO MemoryStore: ensureFreeSpace(3760) called with
> curMem=360852, maxMem=2899102924
> 14/09/11 15:36:44 INFO MemoryStore: Block broadcast_9 stored as values in
> memory (estimated size 3.7 KB, free 2.7 GB)/
> But also
> /14/09/11 12:57:08 INFO ExternalAppendOnlyMap: Thread 239 spilling in-memory
> map of 493 MB to disk (7 times so far)
> 14/09/11 12:57:09 INFO ExternalAppendOnlyMap: Thread 239 spilling in-memory
> map of 493 MB to disk (8 times so far)/
>
> I could see a scenario in which a shuffle uses more than an actual RDD store
> needs, but this seems disproportional to me.
> *Question:*
> Where can I see the actual size of an individual RDD? Or is there a way to
> calculate it?

Look at the "Storage" tab in the UI to see persisted RDDs. For RDDs
that aren't persisted, I'm not sure you can meaningfully say what
their actual resource consumption is. It could be nothing if it has
not yet been computed for example. Memory used for shuffling is not
the same as for persisting RDDs. Yes you can imagine situations in
which shuffles are really large.

I think the answers may depend more specifically on what you're getting at.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9422-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 08:18:14 2014
Return-Path: <dev-return-9422-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9621111F4A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 08:18:14 +0000 (UTC)
Received: (qmail 10202 invoked by uid 500); 12 Sep 2014 08:18:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10113 invoked by uid 500); 12 Sep 2014 08:18:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10092 invoked by uid 99); 12 Sep 2014 08:18:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:18:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:17:48 +0000
Received: by mail-qc0-f173.google.com with SMTP id i8so66603qcq.18
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 01:17:46 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=QprBtxps0OjgqQ4sYn9USDjOfCXCtfYfGL17eo5HpHg=;
        b=N9be8C4y16dOmH4z+lBPTsY6IRp9/dku14+cIQxfxtT6va7z5CDwCTnTz7mcsbble0
         fq9LTqEzSSdFHMKBONYbShGNzNt/JTDPKNz12EXTwtIGfUNhCTrMN+r42nm6qP5BNgOs
         eodTDs1hlMVKHNBtzhtvmTPFx7jUp4m/a13sTOO+utbjMOiWYReyXy/ujMhMe6W1y1//
         1Un6tgqQ1E1n3KYY4Sss3GStB/TDVF4i7YYX6VboAwy6icaG/aU4dTHRwd5w2hlHbwWK
         mS9xWRLSAw4KzDIj+rUQDPXm/LZi5HWPC3x6yw8g330aGkevxFWTfM/NRyn4sGdGOLr0
         FSgg==
X-Gm-Message-State: ALoCoQlvWTgn2TOEzhWTNJfgLavzGKSREtRXMUFqR+hOKpiynQExRH9sbF+FeaI24hrg1PqogW33
X-Received: by 10.224.30.139 with SMTP id u11mr9606709qac.77.1410509866538;
 Fri, 12 Sep 2014 01:17:46 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Fri, 12 Sep 2014 01:17:26 -0700 (PDT)
In-Reply-To: <492403270.18096969.1410017243818.JavaMail.zimbra@redhat.com>
References: <651684514.18096142.1410016399575.JavaMail.zimbra@redhat.com> <492403270.18096969.1410017243818.JavaMail.zimbra@redhat.com>
From: Reynold Xin <rxin@databricks.com>
Date: Fri, 12 Sep 2014 01:17:26 -0700
Message-ID: <CAPh_B=bam8juJEZzNhkTO_VnX_cbTz+QpFM+0daUTSrfhspP3Q@mail.gmail.com>
Subject: Re: PSA: SI-8835 (Iterator 'drop' method has a complexity bug causing
 quadratic behavior)
To: Erik Erlandson <eje@redhat.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bea2dd88c50e60502d9ebc7
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea2dd88c50e60502d9ebc7
Content-Type: text/plain; charset=UTF-8

Thanks for the email, Erik.

The Scala collection library implementation is a complicated beast ...


On Sat, Sep 6, 2014 at 8:27 AM, Erik Erlandson <eje@redhat.com> wrote:

> I tripped over this recently while preparing a solution for SPARK-3250
> (efficient sampling):
>
> Iterator 'drop' method has a complexity bug causing quadratic behavior
> https://issues.scala-lang.org/browse/SI-8835
>
> It's something of a corner case, as the impact is serious only if one is
> repeatedly invoking 'drop' on Iterator[T], and it doesn't apply to all
> iterator subclasses (e.g. Array().iterator).   It's actually a bug in
> 'slice', and so invocations of 'drop', 'take' and 'slice' are potential
> vulnerabilities.
>
> Not something I'd expect to show up frequently, but it seemed worth
> mentioning, as RDD partitions are ubiquitously presented as Iterator[T] in
> the compute model, and if it does happen it turns a linear algorithm into
> something having quadratic behavior.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7bea2dd88c50e60502d9ebc7--

From dev-return-9423-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 08:44:38 2014
Return-Path: <dev-return-9423-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0EA6D11FEB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 08:44:38 +0000 (UTC)
Received: (qmail 46236 invoked by uid 500); 12 Sep 2014 08:44:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46155 invoked by uid 500); 12 Sep 2014 08:44:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45198 invoked by uid 99); 12 Sep 2014 08:44:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:44:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dibyendu.bhattachary@gmail.com designates 209.85.218.48 as permitted sender)
Received: from [209.85.218.48] (HELO mail-oi0-f48.google.com) (209.85.218.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 08:44:32 +0000
Received: by mail-oi0-f48.google.com with SMTP id a141so276377oig.21
        for <multiple recipients>; Fri, 12 Sep 2014 01:44:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=oJmQjsnaSif9LNjo5aE8fKU2k4d7+0Z46Siii7XPhnA=;
        b=Xt/2jehfEEmg9ABrifdZddGbLADrDfX7nk8lkM4khvfWhwgHcsT4GEjFxfrVfTwz/H
         aIbFyhV/bVsL/ffRtKq0iazgR7594Sbxx8X8LggPbuQlT/T+XLhfcStHiE3E0f4MjWXE
         UrKCsd+Y6Nf1MtAC7ZRfFXB+5SUZChlGoGX7H02AwuX3uvvU33lo//87QPq+GPauWiFy
         8NzMC6wOc8no5uHUJg4OVxzmWuOajV8n9CE8u4+Tvc0GOdhQt/mDyYouP1jVDmRk5Ik1
         jMbwY0PeATCAu9wvHR4FKDMITIFZcDz8zSGdh8IT5oynwrkBYr0Ajb6enoRs437e94dP
         NdGg==
MIME-Version: 1.0
X-Received: by 10.60.60.167 with SMTP id i7mr6886186oer.41.1410511451669; Fri,
 12 Sep 2014 01:44:11 -0700 (PDT)
Received: by 10.76.108.140 with HTTP; Fri, 12 Sep 2014 01:44:11 -0700 (PDT)
In-Reply-To: <0EC465563D0D428EBDACF008801C92E6@gmail.com>
References: <CAFiYKR8sJ08=K4kshaqDQWFw8B57r_cnNLqrRfk9r1GNzTEFTQ@mail.gmail.com>
	<E0D4F031CBD24ECEACE511B5A06FF2C3@gmail.com>
	<0EC465563D0D428EBDACF008801C92E6@gmail.com>
Date: Fri, 12 Sep 2014 14:14:11 +0530
Message-ID: <CAFiYKR8ZFVuLwVPBw=ALM7yHyOydkbxMFWA_2kex8Foja-mzPA@mail.gmail.com>
Subject: Re: Some Serious Issue with Spark Streaming ? Blocks Getting Removed
 and Jobs have Failed..
From: Dibyendu Bhattacharya <dibyendu.bhattachary@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, user <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158bab40749d70502da4a94
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158bab40749d70502da4a94
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Dear all,

I am sorry. This was a false alarm

There was some issue in the RDD processing logic which leads to large
backlog. Once I fixed the issues in my processing logic, I can see all
messages being pulled nicely without any Block Removed error. I need to
tune certain configurations in my Kafka Consumer to modify the data rate
and also the batch size.

Sorry again.


Regards,
Dibyendu

On Thu, Sep 11, 2014 at 8:13 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  This is my case about broadcast variable:
>
> 14/07/21 19:49:13 INFO Executor: Running task ID 4
> 14/07/21 19:49:13 INFO DAGScheduler: Completed ResultTask(0, 2)
> 14/07/21 19:49:13 INFO TaskSetManager: Finished TID 2 in 95 ms on localho=
st (progress: 3/106)
> 14/07/21 19:49:13 INFO TableOutputFormat: Created table instance for hdfs=
test_customers
> 14/07/21 19:49:13 INFO Executor: Serialized size of result for 3 is 596
> 14/07/21 19:49:13 INFO Executor: Sending result for 3 directly to driver
> 14/07/21 19:49:13 INFO BlockManager: Found block broadcast_0 locally
> 14/07/21 19:49:13 INFO Executor: Finished task ID 3
> 14/07/21 19:49:13 INFO TaskSetManager: Starting task 0.0:5 as TID 5 on ex=
ecutor localhost: localhost (PROCESS_LOCAL)
> 14/07/21 19:49:13 INFO TaskSetManager: Serialized task 0.0:5 as 11885 byt=
es in 0 ms
> 14/07/21 19:49:13 INFO Executor: Running task ID 5
> 14/07/21 19:49:13 INFO BlockManager: Removing broadcast 0
> 14/07/21 19:49:13 INFO DAGScheduler: Completed ResultTask(0, 3)*14/07/21 =
19:49:13 INFO ContextCleaner: Cleaned broadcast 0*
> 14/07/21 19:49:13 INFO TaskSetManager: Finished TID 3 in 97 ms on localho=
st (progress: 4/106)
> 14/07/21 19:49:13 INFO BlockManager: Found block broadcast_0 locally
> 14/07/21 19:49:13 INFO BlockManager: Removing block broadcast_0*14/07/21 =
19:49:13 INFO MemoryStore: Block broadcast_0 of size 202564 dropped from me=
mory (free 886623436)*
> 14/07/21 19:49:13 INFO ContextCleaner: Cleaned shuffle 0
> 14/07/21 19:49:13 INFO ShuffleBlockManager: Deleted all files for shuffle=
 0
> 14/07/21 19:49:13 INFO HadoopRDD: Input split: hdfs://172.31.34.184:9000/=
etltest/hdfsData/customer.csv:25+5
> 14/07/21 <http://172.31.34.184:9000/etltest/hdfsData/customer.csv:25+514/=
07/21> 19:49:13 INFO HadoopRDD: Input split: hdfs://172.31.34.184:9000/etlt=
est/hdfsData/customer.csv:20+5
> 14/07/21 <http://172.31.34.184:9000/etltest/hdfsData/customer.csv:20+514/=
07/21> 19:49:13 INFO TableOutputFormat: Created table instance for hdfstest=
_customers
> 14/07/21 19:49:13 INFO Executor: Serialized size of result for 4 is 596
> 14/07/21 19:49:13 INFO Executor: Sending result for 4 directly to driver
> 14/07/21 19:49:13 INFO Executor: Finished task ID 4
> 14/07/21 19:49:13 INFO TaskSetManager: Starting task 0.0:6 as TID 6 on ex=
ecutor localhost: localhost (PROCESS_LOCAL)
> 14/07/21 19:49:13 INFO TaskSetManager: Serialized task 0.0:6 as 11885 byt=
es in 0 ms
> 14/07/21 19:49:13 INFO Executor: Running task ID 6
> 14/07/21 19:49:13 INFO DAGScheduler: Completed ResultTask(0, 4)
> 14/07/21 19:49:13 INFO TaskSetManager: Finished TID 4 in 80 ms on localho=
st (progress: 5/106)
> 14/07/21 19:49:13 INFO TableOutputFormat: Created table instance for hdfs=
test_customers
> 14/07/21 19:49:13 INFO Executor: Serialized size of result for 5 is 596
> 14/07/21 19:49:13 INFO Executor: Sending result for 5 directly to driver
> 14/07/21 19:49:13 INFO Executor: Finished task ID 5
> 14/07/21 19:49:13 INFO TaskSetManager: Starting task 0.0:7 as TID 7 on ex=
ecutor localhost: localhost (PROCESS_LOCAL)
> 14/07/21 19:49:13 INFO TaskSetManager: Serialized task 0.0:7 as 11885 byt=
es in 0 ms
> 14/07/21 19:49:13 INFO Executor: Running task ID 7
> 14/07/21 19:49:13 INFO DAGScheduler: Completed ResultTask(0, 5)
> 14/07/21 19:49:13 INFO TaskSetManager: Finished TID 5 in 77 ms on localho=
st (progress: 6/106)
> 14/07/21 19:49:13 INFO HttpBroadcast: Started reading broadcast variable =
0
> 14/07/21 19:49:13 INFO HttpBroadcast: Started reading broadcast variable =
0
> 14/07/21 19:49:13 ERROR Executor: Exception in task ID 6
> java.io.FileNotFoundException: http://172.31.34.174:52070/broadcast_0
> 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLCon=
nection.java:1624)
> 	at org.apache.spark.broadcast.HttpBroadcast$.read(HttpBroadcast.scala:19=
6)
> 	at org.apache.spark.broadcast.HttpBroadcast.readObject(HttpBroadcast.sca=
la:89)
> 	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
> 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces=
sorImpl.java:43)
> 	at java.lang.reflect.Method.invoke(Method.java:606)
> 	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:101=
7)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:19=
90)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:19=
90)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> 	at scala.collection.immutable.$colon$colon.readObject(List.scala:362)
> 	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
> 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces=
sorImpl.java:43)
> 	at java.lang.reflect.Method.invoke(Method.java:606)
> 	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:101=
7)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:19=
90)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:19=
90)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> 	at scala.collection.immutable.$colon$colon.readObject(List.scala:362)
> 	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
> 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces=
sorImpl.java:43)
> 	at java.lang.reflect.Method.invoke(Method.java:606)
> 	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:101=
7)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:19=
90)
> 	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
798)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> 	at org.apache.spark.serializer.JavaDeserializationStream.readObject(Java=
Serializer.scala:63)
> 	at org.apache.spark.scheduler.ResultTask$.deserializeInfo(ResultTask.sca=
la:61)
> 	at org.apache.spark.scheduler.ResultTask.readExternal(ResultTask.scala:1=
41)
> 	at java.io.ObjectInputStream.readExternalData(ObjectInputStream.java:183=
7)
> 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1=
796)
> 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> 	at org.apache.spark.serializer.JavaDeserializationStream.readObject(Java=
Serializer.scala:63)
> 	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSe=
rializer.scala:85)
> 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:169)
> 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.=
java:1145)
> 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor=
.java:615)
> 	at java.lang.Thread.run(Thread.java:744)
>
>
>
>
> --
> Nan Zhu
>
> On Thursday, September 11, 2014 at 10:42 AM, Nan Zhu wrote:
>
>  Hi,
>
> Can you attach more logs to see if there is some entry from ContextCleane=
r?
>
> I met very similar issue before=E2=80=A6but haven=E2=80=99t get resolved
>
> Best,
>
> --
> Nan Zhu
>
> On Thursday, September 11, 2014 at 10:13 AM, Dibyendu Bhattacharya wrote:
>
> Dear All,
>
> Not sure if this is a false alarm. But wanted to raise to this to
> understand what is happening.
>
> I am testing the Kafka Receiver which I have written (
> https://github.com/dibbhatt/kafka-spark-consumer) which basically a low
> level Kafka Consumer implemented custom Receivers for every Kafka topic
> partitions and pulling data in parallel. Individual streams from all topi=
c
> partitions are then merged to create Union stream which used for further
> processing.
>
> The custom Receiver working fine in normal load with no issues. But when =
I
> tested this with huge amount of backlog messages from Kafka ( 50 million =
+
> messages), I see couple of major issue in Spark Streaming. Wanted to get
> some opinion on this....
>
> I am using latest Spark 1.1 taken from the source and built it. Running i=
n
> Amazon EMR , 3 m1.xlarge Node Spark cluster running in Standalone Mode.
>
> Below are two main question I have..
>
> 1. What I am seeing when I run the Spark Streaming with my Kafka Consumer
> with a huge backlog in Kafka ( around 50 Million), Spark is completely bu=
sy
> performing the Receiving task and hardly schedule any processing task. Ca=
n
> you let me if this is expected ? If there is large backlog, Spark will ta=
ke
> long time pulling them . Why Spark not doing any processing ? Is it becau=
se
> of resource limitation ( say all cores are busy puling ) or it is by desi=
gn
> ? I am setting the executor-memory to 10G and driver-memory to 4G .
>
> 2. *This issue seems to be more serious.* I have attached the Driver
> trace with this email. What I can see very frequently Block are selected =
to
> be Removed...This kind of entries are all over the place. But when a Bloc=
k
> is removed , below problem happen.... May be this issue cause the issue 1
> that no Jobs are getting processed ..
>
>
> INFO : org.apache.spark.storage.MemoryStore - 1 blocks selected for
> dropping
> INFO : org.apache.spark.storage.BlockManager - Dropping block
> *input-0-1410443074600* from memory
> INFO : org.apache.spark.storage.MemoryStore - Block input-0-1410443074600=
 of
> size 12651900 dropped from memory (free 21220667)
> INFO : org.apache.spark.storage.BlockManagerInfo - Removed
> input-0-1410443074600 on ip-10-252-5-113.asskickery.us:53752 in memory
> (size: 12.1 MB, free: 100.6 MB)
> ...........
>
> INFO : org.apache.spark.storage.BlockManagerInfo - Removed
> input-0-1410443074600 on ip-10-252-5-62.asskickery.us:37033 in memory
> (size: 12.1 MB, free: 154.6 MB)
> ..............
>
> WARN : org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage
> 7.0 (TID 118, ip-10-252-5-62.asskickery.us): java.lang.Exception: Could
> not compute split, block input-0-1410443074600 not found
>
> ...........
>
> INFO : org.apache.spark.scheduler.TaskSetManager - Lost task 0.1 in stage
> 7.0 (TID 126) on executor ip-10-252-5-62.asskickery.us:
> java.lang.Exception (Could not compute split, block input-0-1410443074600
> not found) [duplicate 1]
>
>
> org.apache.spark.SparkException: *Job aborted due to stage failure*: Task
> 0 in stage 7.0 failed 4 times, most recent failure: Lost task 0.3 in stag=
e
> 7.0 (TID 139, ip-10-252-5-62.asskickery.us): java.lang.Exception: Could
> not compute split, block input-0-1410443074600 not found
>         org.apache.spark.rdd.BlockRDD.compute(BlockRDD.scala:51)
>         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
>         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
>         org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:87)
>         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
>         org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:61)
>         org.apache.spark.rdd.RDD.iterator(RDD.scala:227)
>         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62=
)
>         org.apache.spark.scheduler.Task.run(Task.scala:54)
>
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java=
:1145)
>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.jav=
a:615)
>         java.lang.Thread.run(Thread.java:744)
>
> Regards,
> Dibyendu
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
> Attachments:
>  - driver-trace.txt
>
>
>
>

--089e0158bab40749d70502da4a94--

From dev-return-9424-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 09:12:18 2014
Return-Path: <dev-return-9424-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 186AF110B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 09:12:18 +0000 (UTC)
Received: (qmail 143 invoked by uid 500); 12 Sep 2014 09:12:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99962 invoked by uid 500); 12 Sep 2014 09:12:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99923 invoked by uid 99); 12 Sep 2014 09:12:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 09:12:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.173 as permitted sender)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 09:12:09 +0000
Received: by mail-qc0-f173.google.com with SMTP id i8so112541qcq.32
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 02:11:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=gaL3h9WXL35MK/LCjGCAuCZQFlsbp61YYWudtrwgQGc=;
        b=fGG/Epu3uemAj9gFdj6uwf+EyqYTEfnqzfuS+Qq8Ia39MMvg8J+loPB+Wf+qYaazYB
         JY0IL+d7D6v51VpmcSPjYHQT234xxixjXP/PubnaT7gd4FHS9THn7653XRyHuj7jOVo/
         W3LPHwptiKKtEZYxbkN93wWY6yNBYmbCD5g4kIwexc9CsBm97Vy2px8XuZQjHSlkASEW
         VO4kIKQQuXhs5ns5piLIxtEP1ti3PMeXN4oihGYP7fWI7+K2gWLlbPRsO6RS0u3LOqOk
         D/MOwY8hdaHKFByV6fcIXKxlxwkVXZ9mlzpFhOoJPkLNxFg1rg5F4cq/5QiVwg2lfwtL
         fNOg==
MIME-Version: 1.0
X-Received: by 10.224.86.5 with SMTP id q5mr10158514qal.36.1410513108520; Fri,
 12 Sep 2014 02:11:48 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Fri, 12 Sep 2014 02:11:48 -0700 (PDT)
Date: Fri, 12 Sep 2014 13:11:48 +0400
Message-ID: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
Subject: Adding abstraction in MLlib
From: Egor Pahomov <pahomov.egor@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2c172c8debc0502daac59
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c172c8debc0502daac59
Content-Type: text/plain; charset=UTF-8

Here in Yandex, during implementation of gradient boosting in spark and
creating our ML tool for internal use, we found next serious problems in
MLLib:


   - There is no Regression/Classification model abstraction. We were
   building abstract data processing pipelines, which should work just with
   some regression - exact algorithm specified outside this code. There is no
   abstraction, which will allow me to do that. *(It's main reason for all
   further problems) *
   - There is no common practice among MLlib for testing algorithms: every
   model generates it's own random test data. There is no easy extractable
   test cases applible to another algorithm. There is no benchmarks for
   comparing algorithms. After implementing new algorithm it's very hard to
   understand how it should be tested.
   - Lack of serialization testing: MLlib algorithms don't contain tests
   which test that model work after serialization.
   - During implementation of new algorithm it's hard to understand what
   API you should create and which interface to implement.

Start for solving all these problems must be done in creating common
interface for typical algorithms/models - regression, classification,
clustering, collaborative filtering.

All main tests should be written against these interfaces, so when new
algorithm implemented - all it should do is passed already written tests.
It allow us to have managble quality among all lib.

There should be couple benchmarks which allow new spark user to get feeling
about which algorithm to use.

Test set against these abstractions should contain serialization test. In
production most time there is no need in model, which can't be stored.

As the first step of this roadmap I'd like to create trait RegressionModel,
*ADD* methods to current algorithms to implement this trait and create some
tests against it. Planning of doing it next week.

Purpose of this letter is to collect any objections to this approach on
early stage: please give any feedback. Second reason is to set lock on this
activity so we wouldn't do the same thing twice: I'll create pull request
by the end of the next week and any parallalizm in development we can start
from there.



-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a11c2c172c8debc0502daac59--

From dev-return-9425-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 11:53:54 2014
Return-Path: <dev-return-9425-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CFFE6114D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 11:53:54 +0000 (UTC)
Received: (qmail 37037 invoked by uid 500); 12 Sep 2014 11:53:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36965 invoked by uid 500); 12 Sep 2014 11:53:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36945 invoked by uid 99); 12 Sep 2014 11:53:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 11:53:53 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of christoph.sawade@googlemail.com designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 11:53:28 +0000
Received: by mail-la0-f49.google.com with SMTP id pv20so761780lab.8
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 04:53:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=googlemail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=urv/eunYqCyjH4hijlNcKyKKTKG8IbjuIM0HmR5/qOw=;
        b=X39Waioy1UD+C1Zi8WoUiYMCczYayxeJdSEM8Lzbe8QBzbATZYrZ9AeuX13jKaX/uM
         qvR5d/YliTwDbHDiUFD2pfPpxgSg7bVIOL9480dYO+m6Ve/LpwxLukQDtji26u7ykR5R
         p/VqvtI98Z5ULEPOqnLRVIUswFrG9Fskm07IS9OmzAaEnOCRnwFi5MhK/F4eDYZLEuN3
         EA6s7Ig4mJVXrDWOKSf1rfaBB2GxG1ZP+b0p/49JriJbvWNJEk9AkcEPoX+UpsOjvijy
         Jb9GyCLeVJBa0HwAwKrHzD92oSKgXSW9O0B5ix8GtSV+QNoloEwsl/tcu9uvX+h5Rbqm
         cWEQ==
MIME-Version: 1.0
X-Received: by 10.112.148.133 with SMTP id ts5mr7972758lbb.45.1410522807010;
 Fri, 12 Sep 2014 04:53:27 -0700 (PDT)
Received: by 10.114.229.3 with HTTP; Fri, 12 Sep 2014 04:53:26 -0700 (PDT)
In-Reply-To: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
Date: Fri, 12 Sep 2014 13:53:26 +0200
Message-ID: <CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Christoph Sawade <christoph.sawade@googlemail.com>
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a838adc0b010502dceed2
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a838adc0b010502dceed2
Content-Type: text/plain; charset=UTF-8

I totally agree, and we discovered also some drawbacks with the
classification models implementation that are based on GLMs:

- There is no distinction between predicting scores, classes, and
calibrated scores (probabilities). For these models it is common to have
access to all of them and the prediction function ``predict``should be
consistent and stateless. Currently, the score is only available after
removing the threshold from the model.
- There is no distinction between multinomial and binomial classification.
For multinomial problems, it is necessary to handle multiple weight vectors
and multiple confidences.
- Models are not serialisable, which makes it hard to use them in practise.

I started a pull request [1] some time ago. I would be happy to continue
the discussion and clarify the interfaces, too!

Cheers, Christoph

[1] https://github.com/apache/spark/pull/2137/

2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:

> Here in Yandex, during implementation of gradient boosting in spark and
> creating our ML tool for internal use, we found next serious problems in
> MLLib:
>
>
>    - There is no Regression/Classification model abstraction. We were
>    building abstract data processing pipelines, which should work just with
>    some regression - exact algorithm specified outside this code. There is
> no
>    abstraction, which will allow me to do that. *(It's main reason for all
>    further problems) *
>    - There is no common practice among MLlib for testing algorithms: every
>    model generates it's own random test data. There is no easy extractable
>    test cases applible to another algorithm. There is no benchmarks for
>    comparing algorithms. After implementing new algorithm it's very hard to
>    understand how it should be tested.
>    - Lack of serialization testing: MLlib algorithms don't contain tests
>    which test that model work after serialization.
>    - During implementation of new algorithm it's hard to understand what
>    API you should create and which interface to implement.
>
> Start for solving all these problems must be done in creating common
> interface for typical algorithms/models - regression, classification,
> clustering, collaborative filtering.
>
> All main tests should be written against these interfaces, so when new
> algorithm implemented - all it should do is passed already written tests.
> It allow us to have managble quality among all lib.
>
> There should be couple benchmarks which allow new spark user to get feeling
> about which algorithm to use.
>
> Test set against these abstractions should contain serialization test. In
> production most time there is no need in model, which can't be stored.
>
> As the first step of this roadmap I'd like to create trait RegressionModel,
> *ADD* methods to current algorithms to implement this trait and create some
> tests against it. Planning of doing it next week.
>
> Purpose of this letter is to collect any objections to this approach on
> early stage: please give any feedback. Second reason is to set lock on this
> activity so we wouldn't do the same thing twice: I'll create pull request
> by the end of the next week and any parallalizm in development we can start
> from there.
>
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--047d7b3a838adc0b010502dceed2--

From dev-return-9426-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 12:18:15 2014
Return-Path: <dev-return-9426-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DC0FE115B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 12:18:14 +0000 (UTC)
Received: (qmail 90324 invoked by uid 500); 12 Sep 2014 12:18:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90252 invoked by uid 500); 12 Sep 2014 12:18:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90241 invoked by uid 99); 12 Sep 2014 12:18:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:18:13 +0000
X-ASF-Spam-Status: No, hits=0.0 required=10.0
	tests=MSGID_FROM_MTA_HEADER,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gdmeda@outlook.com designates 65.55.111.89 as permitted sender)
Received: from [65.55.111.89] (HELO BLU004-OMC2S14.hotmail.com) (65.55.111.89)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:17:47 +0000
Received: from BLU436-SMTP29 ([65.55.111.72]) by BLU004-OMC2S14.hotmail.com over TLS secured channel with Microsoft SMTPSVC(7.5.7601.22724);
	 Fri, 12 Sep 2014 05:17:46 -0700
X-TMN: [cghMcq4U9LLgQtMl1QLZthY8WAuYxC8n]
X-Originating-Email: [gdmeda@outlook.com]
Message-ID: <BLU436-SMTP29DCC03F8BBDE358A8CDB9D2CD0@phx.gbl>
Received: from [10.0.1.4] ([24.148.52.191]) by BLU436-SMTP29.smtp.hotmail.com over TLS secured channel with Microsoft SMTPSVC(8.0.9200.16384);
	 Fri, 12 Sep 2014 05:17:45 -0700
Content-Type: text/plain; charset="us-ascii"
MIME-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Reporting serialized task size after task broadcast change?
From: Guru Medasani <gdmeda@outlook.com>
In-Reply-To: <CACBYxKKW9c3eM-tgbanOy-1reeFncaDzMa8vJ=1yzptU1fzK6Q@mail.gmail.com>
Date: Fri, 12 Sep 2014 07:17:43 -0500
CC: Reynold Xin <rxin@databricks.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
References: <CACBYxKKRZW0MddX3HyoTQPKOMBquzaUuYT7wA-pEcGe3LrxKJQ@mail.gmail.com> <CAPh_B=bxti+qO8uy78ijDJH4p+b6jjCVTuCmrO=mzUzJO-pnHg@mail.gmail.com> <CACBYxKL4QNcSVgGXYkEe+P0P=n40pc8EAa+nM3jyYsD0j_3uXQ@mail.gmail.com> <CAPh_B=YeUtFCZ+Ebnz7fNJFHKVcBKpPKJGZgxitL-TNeTEgyYg@mail.gmail.com> <CACBYxKKW9c3eM-tgbanOy-1reeFncaDzMa8vJ=1yzptU1fzK6Q@mail.gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
X-Mailer: Apple Mail (2.1878.6)
X-OriginalArrivalTime: 12 Sep 2014 12:17:45.0242 (UTC) FILETIME=[8F0327A0:01CFCE83]
X-Virus-Checked: Checked by ClamAV on apache.org

I thought we could see this on the Spark Web UI storage tab. May be I =
was looking at something else too.

On Sep 11, 2014, at 8:47 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> Hmm, well I can't find it now, must have been hallucinating.  Do you =
know
> off the top of your head where I'd be able to find the size to log it?
>=20
> On Thu, Sep 11, 2014 at 6:33 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>=20
>> I didn't know about that ....
>>=20
>> On Thu, Sep 11, 2014 at 6:29 PM, Sandy Ryza <sandy.ryza@cloudera.com>
>> wrote:
>>=20
>>> It used to be available on the UI, no?
>>>=20
>>> On Thu, Sep 11, 2014 at 6:26 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>>>=20
>>>> I don't think so. We should probably add a line to log it.
>>>>=20
>>>>=20
>>>> On Thursday, September 11, 2014, Sandy Ryza =
<sandy.ryza@cloudera.com>
>>>> wrote:
>>>>=20
>>>>> After the change to broadcast all task data, is there any easy way =
to
>>>>> discover the serialized size of the data getting sent down for a =
task?
>>>>>=20
>>>>> thanks,
>>>>> -Sandy
>>>>>=20
>>>>=20
>>>=20
>>=20
>>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9427-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 12:28:34 2014
Return-Path: <dev-return-9427-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 30E641160D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 12:28:34 +0000 (UTC)
Received: (qmail 9942 invoked by uid 500); 12 Sep 2014 12:28:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9870 invoked by uid 500); 12 Sep 2014 12:28:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9854 invoked by uid 99); 12 Sep 2014 12:28:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:28:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of archit279thakur@gmail.com designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:28:06 +0000
Received: by mail-la0-f50.google.com with SMTP id ty20so824231lab.9
        for <dev@spark.incubator.apache.org>; Fri, 12 Sep 2014 05:28:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=HXYN2+YfL/dftSvnrvdLgAby9RefRV2aa7/H8PjPBT0=;
        b=pxo39b6tWfYfsSHpdaJxmAWWgS+bja+/GSgQOpt7R44BNcz0x7QxugQ2qZH1EB20yq
         mtH4U5lvJMXHv78BWfUKptUAZz8WmZzCF/aQeMtxgof39efD3muepLSITUfGq/sMx4vH
         OIklVVAbJl+mcnBQ48m+H5cvPF0vYAghMD4ze1aJCgmHwCsrYSRnww4s6DvSW0Bwo/Iz
         3RnJbGku+KpJcsdv3rZqFTC+Q9Th4Pvt69U+F+lJo13jvs8ayapRvSI4udi2JYzja1C+
         2arb09hqGiBDzYH5TDDL+XLsBYp0IQ0PUmM14d29gbPy4DM449tKQuR+oz0EvTlsHbL8
         upxg==
MIME-Version: 1.0
X-Received: by 10.152.43.50 with SMTP id t18mr8703702lal.25.1410524885619;
 Fri, 12 Sep 2014 05:28:05 -0700 (PDT)
Received: by 10.112.219.226 with HTTP; Fri, 12 Sep 2014 05:28:05 -0700 (PDT)
Date: Fri, 12 Sep 2014 17:58:05 +0530
Message-ID: <CA+KkaUZ2sJrTvY5gvitb9TBm3eVJPUk12ZeySzv_S-Gbwn3Exw@mail.gmail.com>
Subject: Use Case of mutable RDD - any ideas around will help.
From: Archit Thakur <archit279thakur@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c239d0c117660502dd6a7d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c239d0c117660502dd6a7d
Content-Type: text/plain; charset=UTF-8

Hi,

We have a use case where we are planning to keep sparkcontext alive in a
server and run queries on it. But the issue is we have  a continuous
flowing data the comes in batches of constant duration(say, 1hour). Now we
want to exploit the schemaRDD and its benefits of columnar caching and
compression. Is there a way I can append the new batch (uncached) to the
older(cached) batch without losing the older data from cache and caching
the whole dataset.

Thanks and Regards,


Archit Thakur.
Sr Software Developer,
Guavus, Inc.

--001a11c239d0c117660502dd6a7d--

From dev-return-9428-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 12:39:21 2014
Return-Path: <dev-return-9428-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8073F1165D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 12:39:21 +0000 (UTC)
Received: (qmail 29539 invoked by uid 500); 12 Sep 2014 12:39:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29465 invoked by uid 500); 12 Sep 2014 12:39:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29453 invoked by uid 99); 12 Sep 2014 12:39:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:39:19 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.192.41 as permitted sender)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 12:38:54 +0000
Received: by mail-qg0-f41.google.com with SMTP id a108so632321qge.14
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 05:38:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Wd47PTN3Pa/moffefJFX+gLTG7JGcnRnqnq/JrDynfg=;
        b=xuv6lYzFuwnnRT0shV3p5HODlAUavlIl/HlLyiP+PQE9MwDjOwvv3Fmy733ok31rR1
         ypXaw1H+NXk511hO6obz5084wrvw5h1rgMQOm2nPXKbrTRZJDnf8/UPQcoXTu87wBJMD
         F6q2dZjVGMAcuCeSDX6pPlKrpQe42MUThl8vTw+I2oNEKB6NB8peQT1BRYGmIYPiKb73
         6Td9RtK6Cgzr+bqMmlbXYmFNaqQ/Blb5n3TdwLmblPem1xeswhmeQonsfl28zBWjQUNa
         WwspKULVcALPkNE4/R0nE+g802eR8fjN+/UXvfPYINsemqqTbUd9xioHMFoIt9HjHIzp
         PGPQ==
MIME-Version: 1.0
X-Received: by 10.140.31.133 with SMTP id f5mr9851573qgf.34.1410525532656;
 Fri, 12 Sep 2014 05:38:52 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Fri, 12 Sep 2014 05:38:52 -0700 (PDT)
In-Reply-To: <CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
Date: Fri, 12 Sep 2014 16:38:52 +0400
Message-ID: <CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Christoph Sawade <christoph.sawade@googlemail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a933e5222ae0502dd91db
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a933e5222ae0502dd91db
Content-Type: text/plain; charset=UTF-8

Sorry, I misswrote  - I meant learners part of framework - models already
exists.

2014-09-12 15:53 GMT+04:00 Christoph Sawade <christoph.sawade@googlemail.com
>:

> I totally agree, and we discovered also some drawbacks with the
> classification models implementation that are based on GLMs:
>
> - There is no distinction between predicting scores, classes, and
> calibrated scores (probabilities). For these models it is common to have
> access to all of them and the prediction function ``predict``should be
> consistent and stateless. Currently, the score is only available after
> removing the threshold from the model.
> - There is no distinction between multinomial and binomial classification.
> For multinomial problems, it is necessary to handle multiple weight vectors
> and multiple confidences.
> - Models are not serialisable, which makes it hard to use them in practise.
>
> I started a pull request [1] some time ago. I would be happy to continue
> the discussion and clarify the interfaces, too!
>
> Cheers, Christoph
>
> [1] https://github.com/apache/spark/pull/2137/
>
> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
>
>> Here in Yandex, during implementation of gradient boosting in spark and
>> creating our ML tool for internal use, we found next serious problems in
>> MLLib:
>>
>>
>>    - There is no Regression/Classification model abstraction. We were
>>    building abstract data processing pipelines, which should work just
>> with
>>    some regression - exact algorithm specified outside this code. There
>> is no
>>    abstraction, which will allow me to do that. *(It's main reason for all
>>    further problems) *
>>    - There is no common practice among MLlib for testing algorithms: every
>>    model generates it's own random test data. There is no easy extractable
>>    test cases applible to another algorithm. There is no benchmarks for
>>    comparing algorithms. After implementing new algorithm it's very hard
>> to
>>    understand how it should be tested.
>>    - Lack of serialization testing: MLlib algorithms don't contain tests
>>    which test that model work after serialization.
>>    - During implementation of new algorithm it's hard to understand what
>>    API you should create and which interface to implement.
>>
>> Start for solving all these problems must be done in creating common
>> interface for typical algorithms/models - regression, classification,
>> clustering, collaborative filtering.
>>
>> All main tests should be written against these interfaces, so when new
>> algorithm implemented - all it should do is passed already written tests.
>> It allow us to have managble quality among all lib.
>>
>> There should be couple benchmarks which allow new spark user to get
>> feeling
>> about which algorithm to use.
>>
>> Test set against these abstractions should contain serialization test. In
>> production most time there is no need in model, which can't be stored.
>>
>> As the first step of this roadmap I'd like to create trait
>> RegressionModel,
>> *ADD* methods to current algorithms to implement this trait and create
>> some
>> tests against it. Planning of doing it next week.
>>
>> Purpose of this letter is to collect any objections to this approach on
>> early stage: please give any feedback. Second reason is to set lock on
>> this
>> activity so we wouldn't do the same thing twice: I'll create pull request
>> by the end of the next week and any parallalizm in development we can
>> start
>> from there.
>>
>>
>>
>> --
>>
>>
>>
>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>
>
>


-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a113a933e5222ae0502dd91db--

From dev-return-9429-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 15:20:46 2014
Return-Path: <dev-return-9429-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 46F7711C00
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 15:20:46 +0000 (UTC)
Received: (qmail 33959 invoked by uid 500); 12 Sep 2014 15:20:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33883 invoked by uid 500); 12 Sep 2014 15:20:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33863 invoked by uid 99); 12 Sep 2014 15:20:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 15:20:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.169 as permitted sender)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 15:20:18 +0000
Received: by mail-qc0-f169.google.com with SMTP id r5so939617qcx.14
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 08:20:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Wzr5ulOaLYSO5nC+j8vhddYIfxxYO5FvgosgFWrFbQI=;
        b=oaK3eNGly4wfLTWcu0dEp8ThuEhmcnYLCC+ikDOMY2vvJ3scabK9icKxVJNThhLnbM
         wd2q7iu9Fif1v/WsDYMIr+ijpgtjFctla4qLtNeM52m7AU9fe7nYqCtFew+AGvBH3wHd
         9j2Pc8lBOW/khtC/8VH0r5SDm4S+1uO53nuuP5hoqCJj+/g+oQSVUp4PEjXjMUXjaVMN
         MGgfQZOrYc2AcCq95vlJfWl9ngtA8LIdAl97EVDG8ft1A4Rv85e3HpbTV9bbjL7ZBYaZ
         Co4/bSJ3hjGbuCpY80u9CzOlGCoJZ3v+dguCaquchY0gEx77sAAoS/4QTxodtQ9OMY1s
         fW1A==
MIME-Version: 1.0
X-Received: by 10.224.29.195 with SMTP id r3mr11758513qac.47.1410535213865;
 Fri, 12 Sep 2014 08:20:13 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Fri, 12 Sep 2014 08:20:13 -0700 (PDT)
In-Reply-To: <CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
	<CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
Date: Fri, 12 Sep 2014 19:20:13 +0400
Message-ID: <CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Christoph Sawade <christoph.sawade@googlemail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bf0c37e5da1e10502dfd25f
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0c37e5da1e10502dfd25f
Content-Type: text/plain; charset=UTF-8

Some architect suggestions on this matter -
https://github.com/apache/spark/pull/2371

2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:

> Sorry, I misswrote  - I meant learners part of framework - models already
> exists.
>
> 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
> christoph.sawade@googlemail.com>:
>
>> I totally agree, and we discovered also some drawbacks with the
>> classification models implementation that are based on GLMs:
>>
>> - There is no distinction between predicting scores, classes, and
>> calibrated scores (probabilities). For these models it is common to have
>> access to all of them and the prediction function ``predict``should be
>> consistent and stateless. Currently, the score is only available after
>> removing the threshold from the model.
>> - There is no distinction between multinomial and binomial
>> classification. For multinomial problems, it is necessary to handle
>> multiple weight vectors and multiple confidences.
>> - Models are not serialisable, which makes it hard to use them in
>> practise.
>>
>> I started a pull request [1] some time ago. I would be happy to continue
>> the discussion and clarify the interfaces, too!
>>
>> Cheers, Christoph
>>
>> [1] https://github.com/apache/spark/pull/2137/
>>
>> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
>>
>>> Here in Yandex, during implementation of gradient boosting in spark and
>>> creating our ML tool for internal use, we found next serious problems in
>>> MLLib:
>>>
>>>
>>>    - There is no Regression/Classification model abstraction. We were
>>>    building abstract data processing pipelines, which should work just
>>> with
>>>    some regression - exact algorithm specified outside this code. There
>>> is no
>>>    abstraction, which will allow me to do that. *(It's main reason for
>>> all
>>>    further problems) *
>>>    - There is no common practice among MLlib for testing algorithms:
>>> every
>>>    model generates it's own random test data. There is no easy
>>> extractable
>>>    test cases applible to another algorithm. There is no benchmarks for
>>>    comparing algorithms. After implementing new algorithm it's very hard
>>> to
>>>    understand how it should be tested.
>>>    - Lack of serialization testing: MLlib algorithms don't contain tests
>>>    which test that model work after serialization.
>>>    - During implementation of new algorithm it's hard to understand what
>>>    API you should create and which interface to implement.
>>>
>>> Start for solving all these problems must be done in creating common
>>> interface for typical algorithms/models - regression, classification,
>>> clustering, collaborative filtering.
>>>
>>> All main tests should be written against these interfaces, so when new
>>> algorithm implemented - all it should do is passed already written tests.
>>> It allow us to have managble quality among all lib.
>>>
>>> There should be couple benchmarks which allow new spark user to get
>>> feeling
>>> about which algorithm to use.
>>>
>>> Test set against these abstractions should contain serialization test. In
>>> production most time there is no need in model, which can't be stored.
>>>
>>> As the first step of this roadmap I'd like to create trait
>>> RegressionModel,
>>> *ADD* methods to current algorithms to implement this trait and create
>>> some
>>> tests against it. Planning of doing it next week.
>>>
>>> Purpose of this letter is to collect any objections to this approach on
>>> early stage: please give any feedback. Second reason is to set lock on
>>> this
>>> activity so we wouldn't do the same thing twice: I'll create pull request
>>> by the end of the next week and any parallalizm in development we can
>>> start
>>> from there.
>>>
>>>
>>>
>>> --
>>>
>>>
>>>
>>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>>
>>
>>
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>



-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--047d7bf0c37e5da1e10502dfd25f--

From dev-return-9430-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 15:49:45 2014
Return-Path: <dev-return-9430-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 633A111CD9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 15:49:45 +0000 (UTC)
Received: (qmail 3462 invoked by uid 500); 12 Sep 2014 15:49:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3386 invoked by uid 500); 12 Sep 2014 15:49:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3369 invoked by uid 99); 12 Sep 2014 15:49:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 15:49:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rajiv.abraham@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 15:49:39 +0000
Received: by mail-la0-f51.google.com with SMTP id gi9so1205279lab.38
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 08:49:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=KJukCZQ79hC4YRuvVQ74alpgO72lT+MDQpij21dVRn4=;
        b=XdI3kiHID2BcfV5LAyhAFoZDQu940QWrd7x+R+kImTRSoav+jpzCFuBGcsIAJufe/B
         QXT40nOAqBJlUCZhQzMTiuS+O6SaQ/K/L7q2SWBY967WWO21eMNd3FOzuLsVkAlIgP0y
         JlF8x8UDX0mkA8cetX3r7P7mL4P0IQjjrMlHoHNHsctmgI7985qvFp+xgwEORuJ4lijj
         Y0ViMtPBs8psezJQfag5YAfK/aRe+fZ4p/ud+XhGoayKdZCkUwNs+lpiuA2hwMYKyouB
         Lva6hCjDAHYG21jmSP8ZDil5FyQD+feNgIRV/o8x6WlxC1tRjqPLjWzb/n57wNcBuRk0
         yCCw==
X-Received: by 10.112.184.161 with SMTP id ev1mr9166387lbc.82.1410536957769;
 Fri, 12 Sep 2014 08:49:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.79.199 with HTTP; Fri, 12 Sep 2014 08:48:47 -0700 (PDT)
In-Reply-To: <2672D68B-6035-4ABF-B2CD-B2AF3462A0C6@gmail.com>
References: <AEE6386C-E36E-477A-B69E-9663BD89B807@gmail.com>
 <CAPh_B=ZDGKPCMKvuVFvev5yX3TJbXGae=w=LdOq+10nEH1dhzQ@mail.gmail.com> <2672D68B-6035-4ABF-B2CD-B2AF3462A0C6@gmail.com>
From: Rajiv Abraham <rajiv.abraham@gmail.com>
Date: Fri, 12 Sep 2014 11:48:47 -0400
Message-ID: <CADnDY-U4tFs0WT-55=LjwQJ4GQsR=-LEsZLjTYwnktpT2S0Dfg@mail.gmail.com>
Subject: Re: Junit spark tests
To: Sudershan Malpani <sudershan.malpani@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c31d0e4f7d470502e03ace
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c31d0e4f7d470502e03ace
Content-Type: text/plain; charset=UTF-8

Hi Sudershan,

That's interesting. I don't have an answer to your question but considering
the functional nature of Spark, I have hardly had to use mock objects(maybe
you could inform us of your use case). Mock object 'expectations' are in
'most' cases implementation of 'Tell, Don't ask' principle which deals with
stateful object interactions unlike the 'value object/type' (POJO objects,
I think , in Java parlance) kind of design expected by data driven
computation or functional programming(and Spark , I guess).

Maybe you could map a value object from your stateful domain object and
then feed that to Spark? And then it may become easier.

Another question to ask is are the tests testing multiple responsibilities
which sometimes is a pain to maintain. Should one separate out the mocking
into a unit test just for that domain object and have a separate unit test
just to test the data computation done by spark(which I suggested above).



2014-09-09 20:38 GMT-04:00 Sudershan Malpani <sudershan.malpani@gmail.com>:

> Class1.java
>
> @Autowired
> Private ClassX cx;
>
> Public list method1(JavaPairRDD data){
>      List list1 = new ArrayList();
>      List list2 = new ArrayList();
>      JavaPairRDD computed = data.map(
>             new Function<Tuple2<object, list>>() {
>                 Public List call(object obj) throws exception {
>               cx.method2(list2);
>            Return list1;
> }});
>     Return computed.flatMap(new FlatMapfunc() { do something }}).collect();
>   }
> }
>
> Class1Test.java
>
> @Mock
> Private ClassX cx;
>
> @InjectMocks
> Private Class1 c1;
>
> @Before
> Public void init() {
>   Super.init();
>    Sc = getSparkContext();
>    doNothing().when(cx).method2(Collections.<object>emptyList());
> }
>
> @Test
> Public void testMethod1() {
>    JavaRDD alldata = Sc.paraalelize("");
>    JavaPairRDD data = createrdd(alldata);
>    c1.method1(rdd);
> }
>
>
>
> Sudershan Malpani
> Sent from my iPhone
>
> > On Sep 9, 2014, at 5:16 PM, Reynold Xin <rxin@databricks.com> wrote:
> >
> > Can you be a little bit more specific, maybe give a code snippet?
> >
> >
> >> On Tue, Sep 9, 2014 at 5:14 PM, Sudershan Malpani <
> sudershan.malpani@gmail.com> wrote:
> >> Hi all,
> >>
> >> I am calling an object which in turn is calling a method inside a map
> RDD in spark. While writing the tests how can I mock that object's call?
> Currently I did doNothing().when(class).method() is called but it is giving
> task not serializable exception. I tried making the class both spy and mock.
> >>
> >> Sudershan Malpani
> >> Sent from my iPhone
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >
>



-- 
Take care,
Rajiv

--001a11c31d0e4f7d470502e03ace--

From dev-return-9431-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 16:07:33 2014
Return-Path: <dev-return-9431-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C42C711D8A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 16:07:33 +0000 (UTC)
Received: (qmail 73978 invoked by uid 500); 12 Sep 2014 16:07:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73907 invoked by uid 500); 12 Sep 2014 16:07:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73894 invoked by uid 99); 12 Sep 2014 16:07:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 16:07:32 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.48 as permitted sender)
Received: from [209.85.219.48] (HELO mail-oa0-f48.google.com) (209.85.219.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 16:07:27 +0000
Received: by mail-oa0-f48.google.com with SMTP id g18so651674oah.7
        for <dev@spark.incubator.apache.org>; Fri, 12 Sep 2014 09:07:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ntkyXctNjeSAlDzOCsE9//pfKxKEt0jPhfnoDU/w/9U=;
        b=YAjbkOeLqO/UF17wP/fuOlkcPw6EnX1i1PuGVJHAbvfLa9RZQF/EealTedZetfnDZC
         6ScQ+CDP64YQ67Cfbn4qTOHhhsefGSlwH3+QkNgwXHDnWyQnCUFq6z49wrBuiLSkn3U8
         oo/JbzJJxE7gz4YCum7SKmmNhji5K6V0mU+sFiM5DLlI0qbSnTYmtgmNt02+wDFxu9AZ
         0uoUXI1F/dC51M8MCnxm75YQ62VsFhRCnfkMADdBvDR+huZfT2mMehOv+7hQjZVoa6I/
         LlAUEN0vmR0r4nX/X36e+BQ6nzWcgzZwEhdCRJVVQjJlSLMauayd7EssqCqdFbx1Y0FF
         8Trg==
MIME-Version: 1.0
X-Received: by 10.60.175.228 with SMTP id cd4mr3473154oec.83.1410538026769;
 Fri, 12 Sep 2014 09:07:06 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Fri, 12 Sep 2014 09:07:06 -0700 (PDT)
In-Reply-To: <CA+KkaUZ2sJrTvY5gvitb9TBm3eVJPUk12ZeySzv_S-Gbwn3Exw@mail.gmail.com>
References: <CA+KkaUZ2sJrTvY5gvitb9TBm3eVJPUk12ZeySzv_S-Gbwn3Exw@mail.gmail.com>
Date: Fri, 12 Sep 2014 09:07:06 -0700
Message-ID: <CABPQxsshKEJYgMAhjn_zOMmkj7-tNHA807hzzGCvSZjG+UoMRQ@mail.gmail.com>
Subject: Re: Use Case of mutable RDD - any ideas around will help.
From: Patrick Wendell <pwendell@gmail.com>
To: Archit Thakur <archit279thakur@gmail.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

[moving to user@]

This would typically be accomplished with a union() operation. You
can't mutate an RDD in-place, but you can create a new RDD with a
union() which is an inexpensive operator.

On Fri, Sep 12, 2014 at 5:28 AM, Archit Thakur
<archit279thakur@gmail.com> wrote:
> Hi,
>
> We have a use case where we are planning to keep sparkcontext alive in a
> server and run queries on it. But the issue is we have  a continuous
> flowing data the comes in batches of constant duration(say, 1hour). Now we
> want to exploit the schemaRDD and its benefits of columnar caching and
> compression. Is there a way I can append the new batch (uncached) to the
> older(cached) batch without losing the older data from cache and caching
> the whole dataset.
>
> Thanks and Regards,
>
>
> Archit Thakur.
> Sr Software Developer,
> Guavus, Inc.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9432-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 16:27:39 2014
Return-Path: <dev-return-9432-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 02E3B11E5D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 16:27:39 +0000 (UTC)
Received: (qmail 27330 invoked by uid 500); 12 Sep 2014 16:27:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27258 invoked by uid 500); 12 Sep 2014 16:27:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27245 invoked by uid 99); 12 Sep 2014 16:27:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 16:27:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 16:27:33 +0000
Received: by mail-oa0-f47.google.com with SMTP id n16so681966oag.20
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 09:27:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=WJhkH4ZTSbkB3jB9w8wfhnVnRXQKEWpcEhJQCXi18IY=;
        b=GcvPSr3BtBQUr5Y+ktiE2M+q4to/CZZiWr8a1F7QPXx8AYuKLDnLC3bryvxVEyoHXA
         AtLUx/aD5DOJqDm8e5ros/Wo8AG/PWVBSDRiomLiZjJ4WeR5j2nZoTByIW4HHtfs2fad
         KsdQwzH/BT+vOXKxrU57fMDLU3iqjgzaSA5O8YEGtYIdXvejLuTsEH3jJjkK7uy+SRLs
         8n/y7IrLlJ4rP0oaxz8kpTxrhvTtn7rYpr+gYExGdfvQ/74d/qApQ1SrHvBl/QmGELaW
         DeswEGWcYq+rtsSKM13zQcte1qoWtOA4ep8XMjKqbgIpnW+a8rBFkV6OOBJW57Rc9vk9
         CDDQ==
X-Gm-Message-State: ALoCoQlOjVUDKzZsob5psctr2Ox+xsDAgSTzgtlpdaRs/+Ce6y3ZEjVyXVTpSv1+wtj1368E8gpc
MIME-Version: 1.0
X-Received: by 10.60.174.3 with SMTP id bo3mr9425019oec.31.1410539232183; Fri,
 12 Sep 2014 09:27:12 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Fri, 12 Sep 2014 09:27:12 -0700 (PDT)
In-Reply-To: <CAAswR-5LKtMAUxqusHAe-Tz1xgfhWp0kzKymkFFSEw2Y5TzH-g@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
	<CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
	<CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
	<CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
	<CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
	<CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
	<CAAswR-5LKtMAUxqusHAe-Tz1xgfhWp0kzKymkFFSEw2Y5TzH-g@mail.gmail.com>
Date: Fri, 12 Sep 2014 11:27:12 -0500
Message-ID: <CAKWX9VUEoa6J_ZCNPMttge0nucMjesxmVpvjQGYxx3+zOYjirw@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011844cee067e10502e0c1ad
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011844cee067e10502e0c1ad
Content-Type: text/plain; charset=UTF-8

Cool, thanks for your help on this.  Any chance of adding it to the 1.1.1
point release, assuming there ends up being one?

On Wed, Sep 10, 2014 at 11:39 AM, Michael Armbrust <michael@databricks.com>
wrote:

> Hey Cody,
>
> Thanks for doing this!  Will look at your PR later today.
>
> Michael
>
> On Wed, Sep 10, 2014 at 9:31 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
>> Tested the patch against a cluster with some real data.  Initial results
>> seem like going from one table to a union of 2 tables is now closer to a
>> doubling of query time as expected, instead of 5 to 10x.
>>
>> Let me know if you see any issues with that PR.
>>
>> On Wed, Sep 10, 2014 at 8:19 AM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>>> So the obvious thing I was missing is that the analyzer has already
>>> resolved attributes by the time the optimizer runs, so the references in
>>> the filter / projection need to be fixed up to match the children.
>>>
>>> Created a PR, let me know if there's a better way to do it.  I'll see
>>> about testing performance against some actual data sets.
>>>
>>> On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org>
>>> wrote:
>>>
>>>> Ok, so looking at the optimizer code for the first time and trying the
>>>> simplest rule that could possibly work,
>>>>
>>>> object UnionPushdown extends Rule[LogicalPlan] {
>>>>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>>>>     // Push down filter into
>>>> union
>>>>     case f @ Filter(condition, u @ Union(left, right)) =>
>>>>
>>>>       u.copy(left = f.copy(child = left), right = f.copy(child =
>>>> right))
>>>>
>>>>
>>>>     // Push down projection into
>>>> union
>>>>     case p @ Project(projectList, u @ Union(left, right)) =>
>>>>       u.copy(left = p.copy(child = left), right = p.copy(child =
>>>> right))
>>>>
>>>> }
>>>>
>>>> }
>>>>
>>>>
>>>> If I try manually applying that rule to a logical plan in the repl, it
>>>> produces the query shape I'd expect, and executing that plan results in
>>>> parquet pushdowns as I'd expect.
>>>>
>>>> But adding those cases to ColumnPruning results in a runtime exception
>>>> (below)
>>>>
>>>> I can keep digging, but it seems like I'm missing some obvious initial
>>>> context around naming of attributes.  If you can provide any pointers to
>>>> speed me on my way I'd appreciate it.
>>>>
>>>>
>>>> java.lang.AssertionError: assertion failed: ArrayBuffer() +
>>>> ArrayBuffer() != WrappedArray(name#6, age#7), List(name#9, age#10,
>>>> phones#11)
>>>>         at scala.Predef$.assert(Predef.scala:179)
>>>>         at
>>>> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>         at
>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>         at
>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>         at
>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>         at scala.collection.immutable.List.foreach(List.scala:318)
>>>>         at
>>>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>>>         at
>>>> scala.collection.AbstractTraversable.map(Traversable.scala:105)
>>>>         at
>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>         at
>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>         at
>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>>>>         at
>>>> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>>>>
>>>>
>>>>
>>>>
>>>> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <
>>>> michael@databricks.com> wrote:
>>>>
>>>>> What Patrick said is correct.  Two other points:
>>>>>  - In the 1.2 release we are hoping to beef up the support for working
>>>>> with partitioned parquet independent of the metastore.
>>>>>  - You can actually do operations like INSERT INTO for parquet tables
>>>>> to add data.  This creates new parquet files for each insertion.  This will
>>>>> break if there are multiple concurrent writers to the same table.
>>>>>
>>>>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> I think what Michael means is people often use this to read existing
>>>>>> partitioned Parquet tables that are defined in a Hive metastore rather
>>>>>> than data generated directly from within Spark and then reading it
>>>>>> back as a table. I'd expect the latter case to become more common, but
>>>>>> for now most users connect to an existing metastore.
>>>>>>
>>>>>> I think you could go this route by creating a partitioned external
>>>>>> table based on the on-disk layout you create. The downside is that
>>>>>> you'd have to go through a hive metastore whereas what you are doing
>>>>>> now doesn't need hive at all.
>>>>>>
>>>>>> We should also just fix the case you are mentioning where a union is
>>>>>> used directly from within spark. But that's the context.
>>>>>>
>>>>>> - Patrick
>>>>>>
>>>>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>>>>> wrote:
>>>>>> > Maybe I'm missing something, I thought parquet was generally a
>>>>>> write-once
>>>>>> > format and the sqlContext interface to it seems that way as well.
>>>>>> >
>>>>>> > d1.saveAsParquetFile("/foo/d1")
>>>>>> >
>>>>>> > // another day, another table, with same schema
>>>>>> > d2.saveAsParquetFile("/foo/d2")
>>>>>> >
>>>>>> > Will give a directory structure like
>>>>>> >
>>>>>> > /foo/d1/_metadata
>>>>>> > /foo/d1/part-r-1.parquet
>>>>>> > /foo/d1/part-r-2.parquet
>>>>>> > /foo/d1/_SUCCESS
>>>>>> >
>>>>>> > /foo/d2/_metadata
>>>>>> > /foo/d2/part-r-1.parquet
>>>>>> > /foo/d2/part-r-2.parquet
>>>>>> > /foo/d2/_SUCCESS
>>>>>> >
>>>>>> > // ParquetFileReader will fail, because /foo/d1 is a directory, not
>>>>>> a
>>>>>> > parquet partition
>>>>>> > sqlContext.parquetFile("/foo")
>>>>>> >
>>>>>> > // works, but has the noted lack of pushdown
>>>>>> >
>>>>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>>>>> >
>>>>>> >
>>>>>> > Is there another alternative?
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>>>>> michael@databricks.com>
>>>>>> > wrote:
>>>>>> >
>>>>>> >> I think usually people add these directories as multiple
>>>>>> partitions of the
>>>>>> >> same table instead of union.  This actually allows us to
>>>>>> efficiently prune
>>>>>> >> directories when reading in addition to standard column pruning.
>>>>>> >>
>>>>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <
>>>>>> malouf.gary@gmail.com>
>>>>>> >> wrote:
>>>>>> >>
>>>>>> >>> I'm kind of surprised this was not run into before.  Do people not
>>>>>> >>> segregate their data by day/week in the HDFS directory structure?
>>>>>> >>>
>>>>>> >>>
>>>>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>>>>> michael@databricks.com>
>>>>>> >>> wrote:
>>>>>> >>>
>>>>>> >>>> Thanks!
>>>>>> >>>>
>>>>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <
>>>>>> cody@koeninger.org>
>>>>>> >>>> wrote:
>>>>>> >>>>
>>>>>> >>>> > Opened
>>>>>> >>>> >
>>>>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>>>> >>>> >
>>>>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>>>>> >>>> >
>>>>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>>>> >>>> michael@databricks.com>
>>>>>> >>>> > wrote:
>>>>>> >>>> >
>>>>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>>>>> cody@koeninger.org>
>>>>>> >>>> >> wrote:
>>>>>> >>>> >>>
>>>>>> >>>> >>> Is there a reason in general not to push projections and
>>>>>> predicates
>>>>>> >>>> down
>>>>>> >>>> >>> into the individual ParquetTableScans in a union?
>>>>>> >>>> >>>
>>>>>> >>>> >>
>>>>>> >>>> >> This would be a great case to add to ColumnPruning.  Would be
>>>>>> awesome
>>>>>> >>>> if
>>>>>> >>>> >> you could open a JIRA or even a PR :)
>>>>>> >>>> >>
>>>>>> >>>> >
>>>>>> >>>> >
>>>>>> >>>>
>>>>>> >>>
>>>>>> >>>
>>>>>> >>
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

--089e011844cee067e10502e0c1ad--

From dev-return-9433-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 17:45:54 2014
Return-Path: <dev-return-9433-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A078B11192
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 17:45:54 +0000 (UTC)
Received: (qmail 59935 invoked by uid 500); 12 Sep 2014 17:45:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59874 invoked by uid 500); 12 Sep 2014 17:45:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59863 invoked by uid 99); 12 Sep 2014 17:45:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 17:45:53 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 17:45:49 +0000
Received: by mail-qc0-f178.google.com with SMTP id x13so1313845qcv.9
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 10:45:27 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Lvmw9ildXbpXqY/bkVaaMDsTchUWFkvXww1VrOJOuu0=;
        b=azc6p/qkeTTVqiJ4maewPjDilPFJL9Wf8hWlO0H3Lul5cPnQVIezYk1uCHulNdkP+3
         83nP3h7O8cwdjtg/oYags76Ck+3cbiavehn/VgPYjSZw434qDltO4HekN8nZ4BGowWRe
         c/hEJrNJ0QxQucPq9OO+zO/DFf4no5pvbKMtIHSZUdcitqCnrzME0vwjYk9uJ+sxJj3o
         ZrsE7KWvfdvmeW/ElFFM6TF0WNVO6nTnsoSoyCUDQrizgLc1yiYG/Qdm8ltszQ/aFoOp
         gfzxCtccAmuMTPBsmCH7+DulifuCbg9G4KKjH4/GbSS7iIsMBCwq+ew4kUiBLTRkIGKZ
         TkQA==
X-Gm-Message-State: ALoCoQmwueeBTOtYhi9D2otX2UKrlRHH7fv69/98V4Y9JoJ57kO0ERWbj5KThDA09AOn1/IK9KM0
X-Received: by 10.140.47.137 with SMTP id m9mr12266006qga.95.1410543927168;
 Fri, 12 Sep 2014 10:45:27 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Fri, 12 Sep 2014 10:45:07 -0700 (PDT)
In-Reply-To: <CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
 <CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
 <CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com> <CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Fri, 12 Sep 2014 10:45:07 -0700
Message-ID: <CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: multipart/alternative; boundary=001a11c165d6b8b0a30502e1d93d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c165d6b8b0a30502e1d93d
Content-Type: text/plain; charset=UTF-8

Xiangrui can comment more, but I believe Joseph and him are actually
working on standardize interface and pipeline feature for 1.2 release.

On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <pahomov.egor@gmail.com>
wrote:

> Some architect suggestions on this matter -
> https://github.com/apache/spark/pull/2371
>
> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>
> > Sorry, I misswrote  - I meant learners part of framework - models already
> > exists.
> >
> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
> > christoph.sawade@googlemail.com>:
> >
> >> I totally agree, and we discovered also some drawbacks with the
> >> classification models implementation that are based on GLMs:
> >>
> >> - There is no distinction between predicting scores, classes, and
> >> calibrated scores (probabilities). For these models it is common to have
> >> access to all of them and the prediction function ``predict``should be
> >> consistent and stateless. Currently, the score is only available after
> >> removing the threshold from the model.
> >> - There is no distinction between multinomial and binomial
> >> classification. For multinomial problems, it is necessary to handle
> >> multiple weight vectors and multiple confidences.
> >> - Models are not serialisable, which makes it hard to use them in
> >> practise.
> >>
> >> I started a pull request [1] some time ago. I would be happy to continue
> >> the discussion and clarify the interfaces, too!
> >>
> >> Cheers, Christoph
> >>
> >> [1] https://github.com/apache/spark/pull/2137/
> >>
> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
> >>
> >>> Here in Yandex, during implementation of gradient boosting in spark and
> >>> creating our ML tool for internal use, we found next serious problems
> in
> >>> MLLib:
> >>>
> >>>
> >>>    - There is no Regression/Classification model abstraction. We were
> >>>    building abstract data processing pipelines, which should work just
> >>> with
> >>>    some regression - exact algorithm specified outside this code. There
> >>> is no
> >>>    abstraction, which will allow me to do that. *(It's main reason for
> >>> all
> >>>    further problems) *
> >>>    - There is no common practice among MLlib for testing algorithms:
> >>> every
> >>>    model generates it's own random test data. There is no easy
> >>> extractable
> >>>    test cases applible to another algorithm. There is no benchmarks for
> >>>    comparing algorithms. After implementing new algorithm it's very
> hard
> >>> to
> >>>    understand how it should be tested.
> >>>    - Lack of serialization testing: MLlib algorithms don't contain
> tests
> >>>    which test that model work after serialization.
> >>>    - During implementation of new algorithm it's hard to understand
> what
> >>>    API you should create and which interface to implement.
> >>>
> >>> Start for solving all these problems must be done in creating common
> >>> interface for typical algorithms/models - regression, classification,
> >>> clustering, collaborative filtering.
> >>>
> >>> All main tests should be written against these interfaces, so when new
> >>> algorithm implemented - all it should do is passed already written
> tests.
> >>> It allow us to have managble quality among all lib.
> >>>
> >>> There should be couple benchmarks which allow new spark user to get
> >>> feeling
> >>> about which algorithm to use.
> >>>
> >>> Test set against these abstractions should contain serialization test.
> In
> >>> production most time there is no need in model, which can't be stored.
> >>>
> >>> As the first step of this roadmap I'd like to create trait
> >>> RegressionModel,
> >>> *ADD* methods to current algorithms to implement this trait and create
> >>> some
> >>> tests against it. Planning of doing it next week.
> >>>
> >>> Purpose of this letter is to collect any objections to this approach on
> >>> early stage: please give any feedback. Second reason is to set lock on
> >>> this
> >>> activity so we wouldn't do the same thing twice: I'll create pull
> request
> >>> by the end of the next week and any parallalizm in development we can
> >>> start
> >>> from there.
> >>>
> >>>
> >>>
> >>> --
> >>>
> >>>
> >>>
> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >>>
> >>
> >>
> >
> >
> > --
> >
> >
> >
> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >
>
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--001a11c165d6b8b0a30502e1d93d--

From dev-return-9434-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 18:45:56 2014
Return-Path: <dev-return-9434-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B7410114A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 18:45:56 +0000 (UTC)
Received: (qmail 49306 invoked by uid 500); 12 Sep 2014 18:45:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49235 invoked by uid 500); 12 Sep 2014 18:45:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49218 invoked by uid 99); 12 Sep 2014 18:45:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:45:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of guhansu@gmail.com designates 209.85.212.181 as permitted sender)
Received: from [209.85.212.181] (HELO mail-wi0-f181.google.com) (209.85.212.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:45:29 +0000
Received: by mail-wi0-f181.google.com with SMTP id bs8so1162501wib.8
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 11:45:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=Shy7rU8zHVQifYbnqumINrFk5MBB5mWEt/BdkAtf5QQ=;
        b=Ij85W0D2Hhnr4hxHXysEJomGnR6PBYUP3/4MSlUFCr1EAF/C29vXudTk2q7rGmUi/q
         Z3Hyz/yUKcKT91s1IDfcUZ7/q5DVNE5ffo2TgMI1Rd1Vbp2GuJQuF9ujyFz3ZHrxWMqt
         PIy0ahFBeYD/k6qVl7dLKVHGg4nl/dhILfDUqOW+dJ7LjHKyFlCU6N/FU4TRBlwyF9PS
         xKBZV3JUDPEryUn1KsOoF6EyNKYQphMkJviFot4mzFm7EDxInCUrImJrJXS7dcyryMMU
         N7Ht8no8Ro0WZeZ/rZzBB05Akhmx0HCuTAiwpuwfi3/zIKx58KxNUK3aF2v9U4FcrVjR
         L70Q==
MIME-Version: 1.0
X-Received: by 10.180.211.233 with SMTP id nf9mr4508808wic.33.1410547527905;
 Fri, 12 Sep 2014 11:45:27 -0700 (PDT)
Received: by 10.194.135.38 with HTTP; Fri, 12 Sep 2014 11:45:27 -0700 (PDT)
Date: Fri, 12 Sep 2014 12:45:27 -0600
Message-ID: <CAP4y_1r04Xq-fG3z8BgNy++720OC7rvU-d9bNTzRmgBiJiCX_g@mail.gmail.com>
Subject: A Spark Compilation Question
From: Hansu GU <guhansu@gmail.com>
To: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I downloaded the source and imported it into IntelliJ 13.1 as a Maven project.

When I used IntelliJ Build -> make Project, I encountered:

Error:(44, 66) not found: type SparkFlumeProtocol val
transactionTimeout: Int, val backOffInterval: Int) extends
SparkFlumeProtocol with Logging {

I think there are some avro generated files missing but I am not sure.
Could anyone help me understand this in order to successfully compile
the source?

Thanks,
Hansu

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9435-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 18:48:24 2014
Return-Path: <dev-return-9435-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 176A5114E0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 18:48:24 +0000 (UTC)
Received: (qmail 78810 invoked by uid 500); 12 Sep 2014 18:48:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78731 invoked by uid 500); 12 Sep 2014 18:48:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78720 invoked by uid 99); 12 Sep 2014 18:48:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:48:22 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_IMAGE_ONLY_24,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.174 as permitted sender)
Received: from [209.85.216.174] (HELO mail-qc0-f174.google.com) (209.85.216.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:47:55 +0000
Received: by mail-qc0-f174.google.com with SMTP id m20so1243908qcx.5
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 11:47:54 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=b5BUY0oJxNn94q+w9fgbnedSAc38pED1mOuvTGW91Rk=;
        b=Q1PHY2xu5nS9XpLrzvvLnVRHPQfZ6UgqMlI45dRT5pGF4xvfVLjv2W10hjND/E+lsu
         xcyAN41gsZ44bBJYwcmsya7pZufQTnAIWyykcvSlMSLLPywdmpthH3kQ15InDqdG2CH9
         w86kFFIyAMMdXe6ZAb6kxr19NbbsDcBC+IAEgV+sTWxjX83O+xQV4xbA7swZwLHnZruJ
         tuBliyUqeZqF9wYr27tk70wS7JmVGMcBb1NriAsUFcQVnD7weUcRKOjDOapSqlGXRSGo
         nNPxZuhld7K2aiXB4YMsSIzZppauPX9ifzJoTG2UpGArRu4czufBwvggSY4pJVWxkm9n
         G7QQ==
X-Gm-Message-State: ALoCoQkH6bAZms+a5Bwwne/QUb4KQwTyWEhQpPIslAcNWKGc4/l7qhZs2dqtS/MLgg143JgRK0JR
MIME-Version: 1.0
X-Received: by 10.140.19.36 with SMTP id 33mr13543376qgg.32.1410547673258;
 Fri, 12 Sep 2014 11:47:53 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Fri, 12 Sep 2014 11:47:53 -0700 (PDT)
In-Reply-To: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
References: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
Date: Fri, 12 Sep 2014 11:47:53 -0700
Message-ID: <CACBYxKLfJ0sR2DkHJKSKi0L6DVap5NqQycSGstYba2suDvTGmg@mail.gmail.com>
Subject: Re: Spark authenticate enablement
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Jun Feng Liu <liujunf@cn.ibm.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1135523800f5a90502e2b91b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135523800f5a90502e2b91b
Content-Type: text/plain; charset=UTF-8

Hi Jun,

I believe that's correct that Spark authentication only works against YARN.

-Sandy

On Thu, Sep 11, 2014 at 2:14 AM, Jun Feng Liu <liujunf@cn.ibm.com> wrote:

> Hi, there
>
> I am trying to enable the authentication on spark on standealone model.
> Seems like only SparkSubmit load the properties from spark-defaults.conf.
>  org.apache.spark.deploy.master.Master dose not really load the default
> setting from spark-defaults.conf.
>
> Dose it mean the spark authentication only work for like YARN model? Or I
> missed something with standalone model.
>
> Best Regards
>
>
> *Jun Feng Liu*
> IBM China Systems & Technology Laboratory in Beijing
>
>   ------------------------------
>  [image: 2D barcode - encoded with contact information] *Phone: *86-10-82452683
>
> * E-mail:* *liujunf@cn.ibm.com* <liujunf@cn.ibm.com>
>
>
> BLD 28,ZGC Software Park
> No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193
> China
>
>
>
>
>

--001a1135523800f5a90502e2b91b--

From dev-return-9436-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 18:52:19 2014
Return-Path: <dev-return-9436-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0D588114FB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 18:52:19 +0000 (UTC)
Received: (qmail 92635 invoked by uid 500); 12 Sep 2014 18:52:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92559 invoked by uid 500); 12 Sep 2014 18:52:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92547 invoked by uid 99); 12 Sep 2014 18:52:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:52:17 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.171 as permitted sender)
Received: from [209.85.213.171] (HELO mail-ig0-f171.google.com) (209.85.213.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 18:52:14 +0000
Received: by mail-ig0-f171.google.com with SMTP id r10so1033975igi.4
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 11:51:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=afcLSgcxxO5lJ+b6t5mGRdVqpaofAr0ZT83pic7ERR0=;
        b=at3GoROlJ3t9gRsrp1DOnfvzd3+VqB8x6Fv+QjXr+QZOWcZ67jEt/wSv5TZ2DcNJx4
         eqPmoIiafUOY2QJaV6WIQusrj2cgT0TlCgMcLqlphZ2VVZNklesk+u2j5uaSa2xWrFnv
         rmdOfqgrsrh86Zg8pkAJzUTVSevUDlfm6quo8DO1s7PlVNklQyldnt45oUCvGNFx41BO
         un9t+YUN3KjXSeSHD/PpPqKtzud9Zxi2CrCmygBrKS32LO4W1f2+YIQvj5t+MIe8t06E
         7Nz4lT/l3ZEwRCIYKVokIrG4d/Ky39yoFM8NAQ1s9QF+4OJwEhdBnZAQdiDJ+GsfaSFC
         XIpQ==
MIME-Version: 1.0
X-Received: by 10.42.207.68 with SMTP id fx4mr11578416icb.67.1410547913434;
 Fri, 12 Sep 2014 11:51:53 -0700 (PDT)
Received: by 10.107.152.196 with HTTP; Fri, 12 Sep 2014 11:51:53 -0700 (PDT)
In-Reply-To: <CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
	<CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
	<CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
	<CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
Date: Fri, 12 Sep 2014 11:51:53 -0700
Message-ID: <CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Xiangrui Meng <mengxr@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Egor Pahomov <pahomov.egor@gmail.com>, 
	Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Egor,

Thanks for the feedback! We are aware of some of the issues you
mentioned and there are JIRAs created for them. Specifically, I'm
pushing out the design on pipeline features and algorithm/model
parameters this week. We can move our discussion to
https://issues.apache.org/jira/browse/SPARK-1856 .

It would be nice to make tests against interfaces. But it definitely
needs more discussion before making PRs. For example, we discussed the
learning interfaces in Christoph's PR
(https://github.com/apache/spark/pull/2137/) but it takes time to
reach a consensus, especially on interfaces. Hopefully all of us could
benefit from the discussion. The best practice is to break down the
proposal into small independent piece and discuss them on the JIRA
before submitting PRs.

For performance tests, there is a spark-perf package
(https://github.com/databricks/spark-perf) and we added performance
tests for MLlib in v1.1. But definitely more work needs to be done.

The dev-list may not be a good place for discussion on the design,
could you create JIRAs for each of the issues you pointed out, and we
track the discussion on JIRA? Thanks!

Best,
Xiangrui

On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com> wrote:
> Xiangrui can comment more, but I believe Joseph and him are actually
> working on standardize interface and pipeline feature for 1.2 release.
>
> On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>
>> Some architect suggestions on this matter -
>> https://github.com/apache/spark/pull/2371
>>
>> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>>
>> > Sorry, I misswrote  - I meant learners part of framework - models already
>> > exists.
>> >
>> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
>> > christoph.sawade@googlemail.com>:
>> >
>> >> I totally agree, and we discovered also some drawbacks with the
>> >> classification models implementation that are based on GLMs:
>> >>
>> >> - There is no distinction between predicting scores, classes, and
>> >> calibrated scores (probabilities). For these models it is common to have
>> >> access to all of them and the prediction function ``predict``should be
>> >> consistent and stateless. Currently, the score is only available after
>> >> removing the threshold from the model.
>> >> - There is no distinction between multinomial and binomial
>> >> classification. For multinomial problems, it is necessary to handle
>> >> multiple weight vectors and multiple confidences.
>> >> - Models are not serialisable, which makes it hard to use them in
>> >> practise.
>> >>
>> >> I started a pull request [1] some time ago. I would be happy to continue
>> >> the discussion and clarify the interfaces, too!
>> >>
>> >> Cheers, Christoph
>> >>
>> >> [1] https://github.com/apache/spark/pull/2137/
>> >>
>> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
>> >>
>> >>> Here in Yandex, during implementation of gradient boosting in spark and
>> >>> creating our ML tool for internal use, we found next serious problems
>> in
>> >>> MLLib:
>> >>>
>> >>>
>> >>>    - There is no Regression/Classification model abstraction. We were
>> >>>    building abstract data processing pipelines, which should work just
>> >>> with
>> >>>    some regression - exact algorithm specified outside this code. There
>> >>> is no
>> >>>    abstraction, which will allow me to do that. *(It's main reason for
>> >>> all
>> >>>    further problems) *
>> >>>    - There is no common practice among MLlib for testing algorithms:
>> >>> every
>> >>>    model generates it's own random test data. There is no easy
>> >>> extractable
>> >>>    test cases applible to another algorithm. There is no benchmarks for
>> >>>    comparing algorithms. After implementing new algorithm it's very
>> hard
>> >>> to
>> >>>    understand how it should be tested.
>> >>>    - Lack of serialization testing: MLlib algorithms don't contain
>> tests
>> >>>    which test that model work after serialization.
>> >>>    - During implementation of new algorithm it's hard to understand
>> what
>> >>>    API you should create and which interface to implement.
>> >>>
>> >>> Start for solving all these problems must be done in creating common
>> >>> interface for typical algorithms/models - regression, classification,
>> >>> clustering, collaborative filtering.
>> >>>
>> >>> All main tests should be written against these interfaces, so when new
>> >>> algorithm implemented - all it should do is passed already written
>> tests.
>> >>> It allow us to have managble quality among all lib.
>> >>>
>> >>> There should be couple benchmarks which allow new spark user to get
>> >>> feeling
>> >>> about which algorithm to use.
>> >>>
>> >>> Test set against these abstractions should contain serialization test.
>> In
>> >>> production most time there is no need in model, which can't be stored.
>> >>>
>> >>> As the first step of this roadmap I'd like to create trait
>> >>> RegressionModel,
>> >>> *ADD* methods to current algorithms to implement this trait and create
>> >>> some
>> >>> tests against it. Planning of doing it next week.
>> >>>
>> >>> Purpose of this letter is to collect any objections to this approach on
>> >>> early stage: please give any feedback. Second reason is to set lock on
>> >>> this
>> >>> activity so we wouldn't do the same thing twice: I'll create pull
>> request
>> >>> by the end of the next week and any parallalizm in development we can
>> >>> start
>> >>> from there.
>> >>>
>> >>>
>> >>>
>> >>> --
>> >>>
>> >>>
>> >>>
>> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >>>
>> >>
>> >>
>> >
>> >
>> > --
>> >
>> >
>> >
>> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >
>>
>>
>>
>> --
>>
>>
>>
>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9437-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 19:08:45 2014
Return-Path: <dev-return-9437-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 088A9115BF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 19:08:45 +0000 (UTC)
Received: (qmail 59046 invoked by uid 500); 12 Sep 2014 19:08:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58963 invoked by uid 500); 12 Sep 2014 19:08:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58952 invoked by uid 99); 12 Sep 2014 19:08:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:08:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.171] (HELO mail-lb0-f171.google.com) (209.85.217.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:08:17 +0000
Received: by mail-lb0-f171.google.com with SMTP id 10so1493568lbg.30
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 12:08:16 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=u6gsf0gulf93SrhgFHSmtsRHoFP0Aa+Z1q0Al6Lg8PE=;
        b=LOqwnLZLGhFb2OqW/zJ260LAIf/UTdkdxQgRFMaYWtV7stsuC01YP6gSrQHhvejavA
         /uFTY6bt3W5hMoRmc+TkwEG7Dl4lCvFTeHBBm+VbEq1t/SiuAFyp9x+PFI7THY0dQ/B8
         /siRmEPPdbcnBSr2NgaWk8VHojweqMFBWsik/Eual16pcZMSlVmCFQOBavOeOAVzWFA1
         iAMVq+Q86+zs0dwaWJPMhVvA2dd2MfE8R9rjgs/OCTpl1LknDrOsMWCng6rdq3txP0op
         AVJy+FuvyAs5mP/F59Kaj392D0OgL99hC4FsGkL20RCyTSIwh+9hO/+ptUUIGvtbYLev
         31hA==
X-Gm-Message-State: ALoCoQmd6kKA+da7gSq0DDW3RBLCtooRGd7LsY+UokvAEDlLTCHtnh93KoqVc2RnjKL66WxiHXn8
X-Received: by 10.112.52.225 with SMTP id w1mr10773549lbo.44.1410548896614;
 Fri, 12 Sep 2014 12:08:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Fri, 12 Sep 2014 12:07:56 -0700 (PDT)
In-Reply-To: <CAKWX9VUEoa6J_ZCNPMttge0nucMjesxmVpvjQGYxx3+zOYjirw@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
 <CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
 <CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
 <CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
 <CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
 <CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
 <CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
 <CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
 <CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
 <CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
 <CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
 <CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
 <CAAswR-5LKtMAUxqusHAe-Tz1xgfhWp0kzKymkFFSEw2Y5TzH-g@mail.gmail.com> <CAKWX9VUEoa6J_ZCNPMttge0nucMjesxmVpvjQGYxx3+zOYjirw@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Fri, 12 Sep 2014 12:07:56 -0700
Message-ID: <CAAswR-719W4rme+tj02YStY0CthxY1K+cYid6jzaWYKv87B_Cw@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
To: Cody Koeninger <cody@koeninger.org>
Cc: Patrick Wendell <pwendell@gmail.com>, Gary Malouf <malouf.gary@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3fe90ebda1b0502e3010b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3fe90ebda1b0502e3010b
Content-Type: text/plain; charset=UTF-8

Yeah, thanks for implementing it!

Since Spark SQL is an alpha component and moving quickly the plan is to
backport all of master into the next point release in the 1.1 series.

On Fri, Sep 12, 2014 at 9:27 AM, Cody Koeninger <cody@koeninger.org> wrote:

> Cool, thanks for your help on this.  Any chance of adding it to the 1.1.1
> point release, assuming there ends up being one?
>
> On Wed, Sep 10, 2014 at 11:39 AM, Michael Armbrust <michael@databricks.com
> > wrote:
>
>> Hey Cody,
>>
>> Thanks for doing this!  Will look at your PR later today.
>>
>> Michael
>>
>> On Wed, Sep 10, 2014 at 9:31 AM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>>> Tested the patch against a cluster with some real data.  Initial results
>>> seem like going from one table to a union of 2 tables is now closer to a
>>> doubling of query time as expected, instead of 5 to 10x.
>>>
>>> Let me know if you see any issues with that PR.
>>>
>>> On Wed, Sep 10, 2014 at 8:19 AM, Cody Koeninger <cody@koeninger.org>
>>> wrote:
>>>
>>>> So the obvious thing I was missing is that the analyzer has already
>>>> resolved attributes by the time the optimizer runs, so the references in
>>>> the filter / projection need to be fixed up to match the children.
>>>>
>>>> Created a PR, let me know if there's a better way to do it.  I'll see
>>>> about testing performance against some actual data sets.
>>>>
>>>> On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org>
>>>> wrote:
>>>>
>>>>> Ok, so looking at the optimizer code for the first time and trying the
>>>>> simplest rule that could possibly work,
>>>>>
>>>>> object UnionPushdown extends Rule[LogicalPlan] {
>>>>>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>>>>>     // Push down filter into
>>>>> union
>>>>>     case f @ Filter(condition, u @ Union(left, right)) =>
>>>>>
>>>>>       u.copy(left = f.copy(child = left), right = f.copy(child =
>>>>> right))
>>>>>
>>>>>
>>>>>     // Push down projection into
>>>>> union
>>>>>     case p @ Project(projectList, u @ Union(left, right)) =>
>>>>>       u.copy(left = p.copy(child = left), right = p.copy(child =
>>>>> right))
>>>>>
>>>>> }
>>>>>
>>>>> }
>>>>>
>>>>>
>>>>> If I try manually applying that rule to a logical plan in the repl, it
>>>>> produces the query shape I'd expect, and executing that plan results in
>>>>> parquet pushdowns as I'd expect.
>>>>>
>>>>> But adding those cases to ColumnPruning results in a runtime exception
>>>>> (below)
>>>>>
>>>>> I can keep digging, but it seems like I'm missing some obvious initial
>>>>> context around naming of attributes.  If you can provide any pointers to
>>>>> speed me on my way I'd appreciate it.
>>>>>
>>>>>
>>>>> java.lang.AssertionError: assertion failed: ArrayBuffer() +
>>>>> ArrayBuffer() != WrappedArray(name#6, age#7), List(name#9, age#10,
>>>>> phones#11)
>>>>>         at scala.Predef$.assert(Predef.scala:179)
>>>>>         at
>>>>> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>         at
>>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>>         at
>>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>>         at
>>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>>         at scala.collection.immutable.List.foreach(List.scala:318)
>>>>>         at
>>>>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>>>>         at
>>>>> scala.collection.AbstractTraversable.map(Traversable.scala:105)
>>>>>         at
>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>         at
>>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>>         at
>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>>>>>         at
>>>>> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <
>>>>> michael@databricks.com> wrote:
>>>>>
>>>>>> What Patrick said is correct.  Two other points:
>>>>>>  - In the 1.2 release we are hoping to beef up the support for
>>>>>> working with partitioned parquet independent of the metastore.
>>>>>>  - You can actually do operations like INSERT INTO for parquet tables
>>>>>> to add data.  This creates new parquet files for each insertion.  This will
>>>>>> break if there are multiple concurrent writers to the same table.
>>>>>>
>>>>>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> I think what Michael means is people often use this to read existing
>>>>>>> partitioned Parquet tables that are defined in a Hive metastore
>>>>>>> rather
>>>>>>> than data generated directly from within Spark and then reading it
>>>>>>> back as a table. I'd expect the latter case to become more common,
>>>>>>> but
>>>>>>> for now most users connect to an existing metastore.
>>>>>>>
>>>>>>> I think you could go this route by creating a partitioned external
>>>>>>> table based on the on-disk layout you create. The downside is that
>>>>>>> you'd have to go through a hive metastore whereas what you are doing
>>>>>>> now doesn't need hive at all.
>>>>>>>
>>>>>>> We should also just fix the case you are mentioning where a union is
>>>>>>> used directly from within spark. But that's the context.
>>>>>>>
>>>>>>> - Patrick
>>>>>>>
>>>>>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>>>>>> wrote:
>>>>>>> > Maybe I'm missing something, I thought parquet was generally a
>>>>>>> write-once
>>>>>>> > format and the sqlContext interface to it seems that way as well.
>>>>>>> >
>>>>>>> > d1.saveAsParquetFile("/foo/d1")
>>>>>>> >
>>>>>>> > // another day, another table, with same schema
>>>>>>> > d2.saveAsParquetFile("/foo/d2")
>>>>>>> >
>>>>>>> > Will give a directory structure like
>>>>>>> >
>>>>>>> > /foo/d1/_metadata
>>>>>>> > /foo/d1/part-r-1.parquet
>>>>>>> > /foo/d1/part-r-2.parquet
>>>>>>> > /foo/d1/_SUCCESS
>>>>>>> >
>>>>>>> > /foo/d2/_metadata
>>>>>>> > /foo/d2/part-r-1.parquet
>>>>>>> > /foo/d2/part-r-2.parquet
>>>>>>> > /foo/d2/_SUCCESS
>>>>>>> >
>>>>>>> > // ParquetFileReader will fail, because /foo/d1 is a directory,
>>>>>>> not a
>>>>>>> > parquet partition
>>>>>>> > sqlContext.parquetFile("/foo")
>>>>>>> >
>>>>>>> > // works, but has the noted lack of pushdown
>>>>>>> >
>>>>>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>>>>>> >
>>>>>>> >
>>>>>>> > Is there another alternative?
>>>>>>> >
>>>>>>> >
>>>>>>> >
>>>>>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>>>>>> michael@databricks.com>
>>>>>>> > wrote:
>>>>>>> >
>>>>>>> >> I think usually people add these directories as multiple
>>>>>>> partitions of the
>>>>>>> >> same table instead of union.  This actually allows us to
>>>>>>> efficiently prune
>>>>>>> >> directories when reading in addition to standard column pruning.
>>>>>>> >>
>>>>>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <
>>>>>>> malouf.gary@gmail.com>
>>>>>>> >> wrote:
>>>>>>> >>
>>>>>>> >>> I'm kind of surprised this was not run into before.  Do people
>>>>>>> not
>>>>>>> >>> segregate their data by day/week in the HDFS directory structure?
>>>>>>> >>>
>>>>>>> >>>
>>>>>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>>>>>> michael@databricks.com>
>>>>>>> >>> wrote:
>>>>>>> >>>
>>>>>>> >>>> Thanks!
>>>>>>> >>>>
>>>>>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <
>>>>>>> cody@koeninger.org>
>>>>>>> >>>> wrote:
>>>>>>> >>>>
>>>>>>> >>>> > Opened
>>>>>>> >>>> >
>>>>>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>>>>> >>>> >
>>>>>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>>>>>> >>>> >
>>>>>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>>>>> >>>> michael@databricks.com>
>>>>>>> >>>> > wrote:
>>>>>>> >>>> >
>>>>>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>>>>>> cody@koeninger.org>
>>>>>>> >>>> >> wrote:
>>>>>>> >>>> >>>
>>>>>>> >>>> >>> Is there a reason in general not to push projections and
>>>>>>> predicates
>>>>>>> >>>> down
>>>>>>> >>>> >>> into the individual ParquetTableScans in a union?
>>>>>>> >>>> >>>
>>>>>>> >>>> >>
>>>>>>> >>>> >> This would be a great case to add to ColumnPruning.  Would
>>>>>>> be awesome
>>>>>>> >>>> if
>>>>>>> >>>> >> you could open a JIRA or even a PR :)
>>>>>>> >>>> >>
>>>>>>> >>>> >
>>>>>>> >>>> >
>>>>>>> >>>>
>>>>>>> >>>
>>>>>>> >>>
>>>>>>> >>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a11c3fe90ebda1b0502e3010b--

From dev-return-9438-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 19:11:00 2014
Return-Path: <dev-return-9438-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4EC46115CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 19:11:00 +0000 (UTC)
Received: (qmail 65891 invoked by uid 500); 12 Sep 2014 19:10:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65810 invoked by uid 500); 12 Sep 2014 19:10:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65788 invoked by uid 99); 12 Sep 2014 19:10:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:10:59 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of eerlands@redhat.com designates 209.132.183.25 as permitted sender)
Received: from [209.132.183.25] (HELO mx4-phx2.redhat.com) (209.132.183.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:10:55 +0000
Received: from zmail12.collab.prod.int.phx2.redhat.com (zmail12.collab.prod.int.phx2.redhat.com [10.5.83.14])
	by mx4-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s8CJANZ0008860;
	Fri, 12 Sep 2014 15:10:23 -0400
Date: Fri, 12 Sep 2014 15:10:21 -0400 (EDT)
From: Erik Erlandson <eje@redhat.com>
Reply-To: Erik Erlandson <eje@redhat.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, Egor Pahomov <pahomov.egor@gmail.com>,
        Christoph Sawade <christoph.sawade@googlemail.com>,
        dev@spark.apache.org, Xiangrui Meng <meng@databricks.com>,
        Joseph Bradley <joseph@databricks.com>
Message-ID: <703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
In-Reply-To: <CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com> <CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com> <CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com> <CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com> <CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com> <CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.6]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - GC36 (Linux)/8.0.6_GA_5922)
Thread-Topic: Adding abstraction in MLlib
Thread-Index: igrTdIiH3fnADchWepMx5xJii9hMOw==
X-Virus-Checked: Checked by ClamAV on apache.org


Are interface designs being captured anywhere as documents that the community can follow along with as the proposals evolve?

I've worked on other open source projects where design docs were published as "living documents" (e.g. on google docs, or etherpad, but the particular mechanism isn't crucial).   FWIW, I found that to be a good way to work in a community environment.


----- Original Message -----
> Hi Egor,
> 
> Thanks for the feedback! We are aware of some of the issues you
> mentioned and there are JIRAs created for them. Specifically, I'm
> pushing out the design on pipeline features and algorithm/model
> parameters this week. We can move our discussion to
> https://issues.apache.org/jira/browse/SPARK-1856 .
> 
> It would be nice to make tests against interfaces. But it definitely
> needs more discussion before making PRs. For example, we discussed the
> learning interfaces in Christoph's PR
> (https://github.com/apache/spark/pull/2137/) but it takes time to
> reach a consensus, especially on interfaces. Hopefully all of us could
> benefit from the discussion. The best practice is to break down the
> proposal into small independent piece and discuss them on the JIRA
> before submitting PRs.
> 
> For performance tests, there is a spark-perf package
> (https://github.com/databricks/spark-perf) and we added performance
> tests for MLlib in v1.1. But definitely more work needs to be done.
> 
> The dev-list may not be a good place for discussion on the design,
> could you create JIRAs for each of the issues you pointed out, and we
> track the discussion on JIRA? Thanks!
> 
> Best,
> Xiangrui
> 
> On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com> wrote:
> > Xiangrui can comment more, but I believe Joseph and him are actually
> > working on standardize interface and pipeline feature for 1.2 release.
> >
> > On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <pahomov.egor@gmail.com>
> > wrote:
> >
> >> Some architect suggestions on this matter -
> >> https://github.com/apache/spark/pull/2371
> >>
> >> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
> >>
> >> > Sorry, I misswrote  - I meant learners part of framework - models
> >> > already
> >> > exists.
> >> >
> >> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
> >> > christoph.sawade@googlemail.com>:
> >> >
> >> >> I totally agree, and we discovered also some drawbacks with the
> >> >> classification models implementation that are based on GLMs:
> >> >>
> >> >> - There is no distinction between predicting scores, classes, and
> >> >> calibrated scores (probabilities). For these models it is common to
> >> >> have
> >> >> access to all of them and the prediction function ``predict``should be
> >> >> consistent and stateless. Currently, the score is only available after
> >> >> removing the threshold from the model.
> >> >> - There is no distinction between multinomial and binomial
> >> >> classification. For multinomial problems, it is necessary to handle
> >> >> multiple weight vectors and multiple confidences.
> >> >> - Models are not serialisable, which makes it hard to use them in
> >> >> practise.
> >> >>
> >> >> I started a pull request [1] some time ago. I would be happy to
> >> >> continue
> >> >> the discussion and clarify the interfaces, too!
> >> >>
> >> >> Cheers, Christoph
> >> >>
> >> >> [1] https://github.com/apache/spark/pull/2137/
> >> >>
> >> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
> >> >>
> >> >>> Here in Yandex, during implementation of gradient boosting in spark
> >> >>> and
> >> >>> creating our ML tool for internal use, we found next serious problems
> >> in
> >> >>> MLLib:
> >> >>>
> >> >>>
> >> >>>    - There is no Regression/Classification model abstraction. We were
> >> >>>    building abstract data processing pipelines, which should work just
> >> >>> with
> >> >>>    some regression - exact algorithm specified outside this code.
> >> >>>    There
> >> >>> is no
> >> >>>    abstraction, which will allow me to do that. *(It's main reason for
> >> >>> all
> >> >>>    further problems) *
> >> >>>    - There is no common practice among MLlib for testing algorithms:
> >> >>> every
> >> >>>    model generates it's own random test data. There is no easy
> >> >>> extractable
> >> >>>    test cases applible to another algorithm. There is no benchmarks
> >> >>>    for
> >> >>>    comparing algorithms. After implementing new algorithm it's very
> >> hard
> >> >>> to
> >> >>>    understand how it should be tested.
> >> >>>    - Lack of serialization testing: MLlib algorithms don't contain
> >> tests
> >> >>>    which test that model work after serialization.
> >> >>>    - During implementation of new algorithm it's hard to understand
> >> what
> >> >>>    API you should create and which interface to implement.
> >> >>>
> >> >>> Start for solving all these problems must be done in creating common
> >> >>> interface for typical algorithms/models - regression, classification,
> >> >>> clustering, collaborative filtering.
> >> >>>
> >> >>> All main tests should be written against these interfaces, so when new
> >> >>> algorithm implemented - all it should do is passed already written
> >> tests.
> >> >>> It allow us to have managble quality among all lib.
> >> >>>
> >> >>> There should be couple benchmarks which allow new spark user to get
> >> >>> feeling
> >> >>> about which algorithm to use.
> >> >>>
> >> >>> Test set against these abstractions should contain serialization test.
> >> In
> >> >>> production most time there is no need in model, which can't be stored.
> >> >>>
> >> >>> As the first step of this roadmap I'd like to create trait
> >> >>> RegressionModel,
> >> >>> *ADD* methods to current algorithms to implement this trait and create
> >> >>> some
> >> >>> tests against it. Planning of doing it next week.
> >> >>>
> >> >>> Purpose of this letter is to collect any objections to this approach
> >> >>> on
> >> >>> early stage: please give any feedback. Second reason is to set lock on
> >> >>> this
> >> >>> activity so we wouldn't do the same thing twice: I'll create pull
> >> request
> >> >>> by the end of the next week and any parallalizm in development we can
> >> >>> start
> >> >>> from there.
> >> >>>
> >> >>>
> >> >>>
> >> >>> --
> >> >>>
> >> >>>
> >> >>>
> >> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >>>
> >> >>
> >> >>
> >> >
> >> >
> >> > --
> >> >
> >> >
> >> >
> >> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >
> >>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >>
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9439-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 19:49:20 2014
Return-Path: <dev-return-9439-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6469B11720
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 19:49:20 +0000 (UTC)
Received: (qmail 78327 invoked by uid 500); 12 Sep 2014 19:49:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78250 invoked by uid 500); 12 Sep 2014 19:49:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78237 invoked by uid 99); 12 Sep 2014 19:49:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:49:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.171 as permitted sender)
Received: from [74.125.82.171] (HELO mail-we0-f171.google.com) (74.125.82.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:49:14 +0000
Received: by mail-we0-f171.google.com with SMTP id p10so1275965wes.2
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 12:48:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=PrkPqg9XpggW5e8qn4+ew0ZcXWrYunqhp6zSOObTabk=;
        b=V95fE+8LFiYc87uZkpWRKAHUAEVfjJ20sbEdZnj/nZw/lWq+uUOmFmTX3NuPjlaoZL
         xQ7KLp6rlJpduFzJpu57mn1J5pJ8ZJ56orinuTBCibmJ4/i0ioRWBVrVx6z8pNCiVSsB
         CPQL0Y7xPLr/UhkGjdqn+EOlZ0xwn9eMC2gHQXtW02HyeIa7wjeyJ4uTQeOWdp2JXTfH
         JqFtPsjDCaiKg7ml2XRkcGe0fz7OGDdJAhsN7D9Cfr7mvcp1jdE7trw7HtE+XmRPLmk2
         4b0IMGnjicELQNedcYoJNL6LzECEuHkSoeh8D8gealm3bJh0Vy69cX3G1GWUfNbU6kB/
         7wNQ==
X-Received: by 10.195.11.200 with SMTP id ek8mr13971785wjd.85.1410551333599;
 Fri, 12 Sep 2014 12:48:53 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Fri, 12 Sep 2014 12:48:13 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 12 Sep 2014 15:48:13 -0400
Message-ID: <CAOhmDzc1=pp6ce4y7Uj4zSq4+9WrfTbypMkjW6P_TZyyAsz0aQ@mail.gmail.com>
Subject: don't trigger tests when only .md files are changed
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b8737622d45010502e393ea
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b8737622d45010502e393ea
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Would it make sense to have Jenkins *not* trigger tests when the only files
that have changed are .md files (example
<https://github.com/apache/spark/pull/2367>)? Those don=E2=80=99t even need=
 RAT
checks, right?

I can make this change if it makes sense.

Nick
=E2=80=8B

--047d7b8737622d45010502e393ea--

From dev-return-9440-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 19:52:44 2014
Return-Path: <dev-return-9440-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F8D311736
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 19:52:44 +0000 (UTC)
Received: (qmail 87242 invoked by uid 500); 12 Sep 2014 19:52:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87169 invoked by uid 500); 12 Sep 2014 19:52:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87157 invoked by uid 99); 12 Sep 2014 19:52:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:52:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 19:52:38 +0000
Received: by mail-wi0-f177.google.com with SMTP id em10so1222674wid.16
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 12:52:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=6aqBTmot+jPd/GO6/SFDz1yMW+kI/hUGAFn7IVobFG8=;
        b=w4hPiG++YFuwoQicoL3KGGr4n6SEzke7I5gd9AHYFTOIjlw1o2cd/uun85zSMr7PMx
         sYCsN1lGz9/IAFLo6BPxIMNKIccXudplIJX0pQI+YNx1+zpYGZykNV05Gqbvnz1senfz
         aOzXPcXonwHADGDsw+tdyCB5a8t2bd/TQUUJbSsVmZXkulwt+9muTkafp3hK2jArQuF0
         j9SJPSXJXbT6Gpvn9GCt+JdotGPng/qX8NSYX19jIHJT3zWMus3XPWY9xlnMvfPOZeva
         qU46+E5l8gmU2X7Vlj0PLs1plLGX+pLMhjwZ4HEklOB2UkUhjeaJWDe/5rSq8ZLD3rPg
         GG1A==
X-Received: by 10.194.59.18 with SMTP id v18mr14414419wjq.64.1410551536671;
 Fri, 12 Sep 2014 12:52:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Fri, 12 Sep 2014 12:51:36 -0700 (PDT)
In-Reply-To: <CAOhmDzc1=pp6ce4y7Uj4zSq4+9WrfTbypMkjW6P_TZyyAsz0aQ@mail.gmail.com>
References: <CAOhmDzc1=pp6ce4y7Uj4zSq4+9WrfTbypMkjW6P_TZyyAsz0aQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 12 Sep 2014 15:51:36 -0400
Message-ID: <CAOhmDzd5xsugSjQyJR9tLG-XLkYuy_FSvqnV+jmn6KhjxEbRUA@mail.gmail.com>
Subject: Re: don't trigger tests when only .md files are changed
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bacb0a647e4120502e39fe9
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bacb0a647e4120502e39fe9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

We could still have Jenkins post a message to the effect of =E2=80=9Cthis p=
atch
only modifies .md files; no tests will be run=E2=80=9D.
=E2=80=8B

On Fri, Sep 12, 2014 at 3:48 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Would it make sense to have Jenkins *not* trigger tests when the only
> files that have changed are .md files (example
> <https://github.com/apache/spark/pull/2367>)? Those don=E2=80=99t even ne=
ed RAT
> checks, right?
>
> I can make this change if it makes sense.
>
> Nick
> =E2=80=8B
>

--047d7bacb0a647e4120502e39fe9--

From dev-return-9441-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 20:00:50 2014
Return-Path: <dev-return-9441-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EDF7A11771
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 20:00:49 +0000 (UTC)
Received: (qmail 1621 invoked by uid 500); 12 Sep 2014 20:00:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1544 invoked by uid 500); 12 Sep 2014 20:00:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1528 invoked by uid 99); 12 Sep 2014 20:00:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 20:00:48 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 20:00:23 +0000
Received: by mail-ob0-f174.google.com with SMTP id uz6so941326obc.5
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 13:00:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=p8pEFCaR6jVeoMciOo+y8oystphTW7FLNAhXCqXDilw=;
        b=gnU++NkiDvF8K9Ozw4OMmvrgzwfzv0jqGIc4zitET4a9Ek/ScvW98KekX2UOLaz3se
         qJkfoXQlwdWfAJm5KHO8y895UnBKK6Rd/l6VCh5EEA6CzYkY9rX0+9/USzc42r7CJ7ca
         30jT4Pf3z5cPKh4fOCsJ8COlt92FGD1NfKqGEzjhRQ34q7PnsthlxUqc3sreII0Sd48k
         trBL7kwZqPMenPcX5NSR3Sfo2juIyyUDsDXqEfVfJIT9UzFtDt2FMO9+Tlraj2TJts1d
         lJiU3Qksctn76BbL5GVsNltphybJ0Xs0l+kXPsb3J1FNXwpWYeTBflL9hmRD9MJyxfAB
         K0nQ==
MIME-Version: 1.0
X-Received: by 10.182.191.39 with SMTP id gv7mr10693584obc.14.1410552021858;
 Fri, 12 Sep 2014 13:00:21 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Fri, 12 Sep 2014 13:00:21 -0700 (PDT)
In-Reply-To: <703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
	<CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
	<CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
	<CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
	<CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
	<703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
Date: Fri, 12 Sep 2014 13:00:21 -0700
Message-ID: <CABPQxsuJfL9PUYEKsaE=9YyaTfiB5Y5SbR8mAsLnWY1B9YCC+Q@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Patrick Wendell <pwendell@gmail.com>
To: Erik Erlandson <eje@redhat.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	Egor Pahomov <pahomov.egor@gmail.com>, Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

We typically post design docs on JIRA's before major work starts. For
instance, pretty sure SPARk-1856 will have a design doc posted
shortly.

On Fri, Sep 12, 2014 at 12:10 PM, Erik Erlandson <eje@redhat.com> wrote:
>
> Are interface designs being captured anywhere as documents that the community can follow along with as the proposals evolve?
>
> I've worked on other open source projects where design docs were published as "living documents" (e.g. on google docs, or etherpad, but the particular mechanism isn't crucial).   FWIW, I found that to be a good way to work in a community environment.
>
>
> ----- Original Message -----
>> Hi Egor,
>>
>> Thanks for the feedback! We are aware of some of the issues you
>> mentioned and there are JIRAs created for them. Specifically, I'm
>> pushing out the design on pipeline features and algorithm/model
>> parameters this week. We can move our discussion to
>> https://issues.apache.org/jira/browse/SPARK-1856 .
>>
>> It would be nice to make tests against interfaces. But it definitely
>> needs more discussion before making PRs. For example, we discussed the
>> learning interfaces in Christoph's PR
>> (https://github.com/apache/spark/pull/2137/) but it takes time to
>> reach a consensus, especially on interfaces. Hopefully all of us could
>> benefit from the discussion. The best practice is to break down the
>> proposal into small independent piece and discuss them on the JIRA
>> before submitting PRs.
>>
>> For performance tests, there is a spark-perf package
>> (https://github.com/databricks/spark-perf) and we added performance
>> tests for MLlib in v1.1. But definitely more work needs to be done.
>>
>> The dev-list may not be a good place for discussion on the design,
>> could you create JIRAs for each of the issues you pointed out, and we
>> track the discussion on JIRA? Thanks!
>>
>> Best,
>> Xiangrui
>>
>> On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com> wrote:
>> > Xiangrui can comment more, but I believe Joseph and him are actually
>> > working on standardize interface and pipeline feature for 1.2 release.
>> >
>> > On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <pahomov.egor@gmail.com>
>> > wrote:
>> >
>> >> Some architect suggestions on this matter -
>> >> https://github.com/apache/spark/pull/2371
>> >>
>> >> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>> >>
>> >> > Sorry, I misswrote  - I meant learners part of framework - models
>> >> > already
>> >> > exists.
>> >> >
>> >> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
>> >> > christoph.sawade@googlemail.com>:
>> >> >
>> >> >> I totally agree, and we discovered also some drawbacks with the
>> >> >> classification models implementation that are based on GLMs:
>> >> >>
>> >> >> - There is no distinction between predicting scores, classes, and
>> >> >> calibrated scores (probabilities). For these models it is common to
>> >> >> have
>> >> >> access to all of them and the prediction function ``predict``should be
>> >> >> consistent and stateless. Currently, the score is only available after
>> >> >> removing the threshold from the model.
>> >> >> - There is no distinction between multinomial and binomial
>> >> >> classification. For multinomial problems, it is necessary to handle
>> >> >> multiple weight vectors and multiple confidences.
>> >> >> - Models are not serialisable, which makes it hard to use them in
>> >> >> practise.
>> >> >>
>> >> >> I started a pull request [1] some time ago. I would be happy to
>> >> >> continue
>> >> >> the discussion and clarify the interfaces, too!
>> >> >>
>> >> >> Cheers, Christoph
>> >> >>
>> >> >> [1] https://github.com/apache/spark/pull/2137/
>> >> >>
>> >> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
>> >> >>
>> >> >>> Here in Yandex, during implementation of gradient boosting in spark
>> >> >>> and
>> >> >>> creating our ML tool for internal use, we found next serious problems
>> >> in
>> >> >>> MLLib:
>> >> >>>
>> >> >>>
>> >> >>>    - There is no Regression/Classification model abstraction. We were
>> >> >>>    building abstract data processing pipelines, which should work just
>> >> >>> with
>> >> >>>    some regression - exact algorithm specified outside this code.
>> >> >>>    There
>> >> >>> is no
>> >> >>>    abstraction, which will allow me to do that. *(It's main reason for
>> >> >>> all
>> >> >>>    further problems) *
>> >> >>>    - There is no common practice among MLlib for testing algorithms:
>> >> >>> every
>> >> >>>    model generates it's own random test data. There is no easy
>> >> >>> extractable
>> >> >>>    test cases applible to another algorithm. There is no benchmarks
>> >> >>>    for
>> >> >>>    comparing algorithms. After implementing new algorithm it's very
>> >> hard
>> >> >>> to
>> >> >>>    understand how it should be tested.
>> >> >>>    - Lack of serialization testing: MLlib algorithms don't contain
>> >> tests
>> >> >>>    which test that model work after serialization.
>> >> >>>    - During implementation of new algorithm it's hard to understand
>> >> what
>> >> >>>    API you should create and which interface to implement.
>> >> >>>
>> >> >>> Start for solving all these problems must be done in creating common
>> >> >>> interface for typical algorithms/models - regression, classification,
>> >> >>> clustering, collaborative filtering.
>> >> >>>
>> >> >>> All main tests should be written against these interfaces, so when new
>> >> >>> algorithm implemented - all it should do is passed already written
>> >> tests.
>> >> >>> It allow us to have managble quality among all lib.
>> >> >>>
>> >> >>> There should be couple benchmarks which allow new spark user to get
>> >> >>> feeling
>> >> >>> about which algorithm to use.
>> >> >>>
>> >> >>> Test set against these abstractions should contain serialization test.
>> >> In
>> >> >>> production most time there is no need in model, which can't be stored.
>> >> >>>
>> >> >>> As the first step of this roadmap I'd like to create trait
>> >> >>> RegressionModel,
>> >> >>> *ADD* methods to current algorithms to implement this trait and create
>> >> >>> some
>> >> >>> tests against it. Planning of doing it next week.
>> >> >>>
>> >> >>> Purpose of this letter is to collect any objections to this approach
>> >> >>> on
>> >> >>> early stage: please give any feedback. Second reason is to set lock on
>> >> >>> this
>> >> >>> activity so we wouldn't do the same thing twice: I'll create pull
>> >> request
>> >> >>> by the end of the next week and any parallalizm in development we can
>> >> >>> start
>> >> >>> from there.
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> --
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >> >>>
>> >> >>
>> >> >>
>> >> >
>> >> >
>> >> > --
>> >> >
>> >> >
>> >> >
>> >> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >>
>> >>
>> >>
>> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9442-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 20:08:13 2014
Return-Path: <dev-return-9442-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DBE311178F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 20:08:12 +0000 (UTC)
Received: (qmail 12366 invoked by uid 500); 12 Sep 2014 20:08:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12288 invoked by uid 500); 12 Sep 2014 20:08:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12277 invoked by uid 99); 12 Sep 2014 20:08:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 20:08:11 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 20:07:45 +0000
Received: by mail-qc0-f177.google.com with SMTP id o8so1111568qcw.22
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 13:07:42 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ly8t7j0h2TdRWhh7xbRAp8pd2dlYjbtlnxdzevneSN8=;
        b=erzLpGbubuNU1cGkMl5Gxwb45OU0l9qayfABJSeTsp4/wnECsmjKZpLMu3uVC0H6jC
         zjIf68TzeZzinKOr9MUJbJH9zED9uGs08Ft9KKDR60QstWKIAPDQFd6AeYBiyXnzrZM+
         enGIZUOS5ltd0H7ihU/MMwjlDBK5gLu+BoKCH4rdnI8VkApmCyjF2rON8SJLLkOTqmKN
         iXZooGppAPqonomuoBGRrG9BnlpWoZlF0qXVhulpOA8Yv4XMWxsPaw7V/ThRfiAvyode
         LXPLOHoB43Jqnlp1LYY671n4ljWVkwBpUWIjBydeBNYo/LwQmYVv0lUODn8w7wBHIWng
         AmdA==
X-Gm-Message-State: ALoCoQlgU3aMtwiQo70OzVs55XzdOt6uFG8Fyzcc/B8cGwycCWy3tY4PELC3Wi0D+l5P+W5UYt59
X-Received: by 10.140.47.137 with SMTP id m9mr13479153qga.95.1410552061840;
 Fri, 12 Sep 2014 13:01:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Fri, 12 Sep 2014 13:00:41 -0700 (PDT)
In-Reply-To: <CAOhmDzd5xsugSjQyJR9tLG-XLkYuy_FSvqnV+jmn6KhjxEbRUA@mail.gmail.com>
References: <CAOhmDzc1=pp6ce4y7Uj4zSq4+9WrfTbypMkjW6P_TZyyAsz0aQ@mail.gmail.com>
 <CAOhmDzd5xsugSjQyJR9tLG-XLkYuy_FSvqnV+jmn6KhjxEbRUA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Fri, 12 Sep 2014 13:00:41 -0700
Message-ID: <CAPh_B=aJSe67vJhgnJ1y1gOSvUyJXosQ5fQeMOR_s6aHYuh_Bw@mail.gmail.com>
Subject: Re: don't trigger tests when only .md files are changed
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c165d695ec790502e3be94
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c165d695ec790502e3be94
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I like that idea, but the load on Jenkins isn't very high. The more
complexity we add to the test script, the easier it is to screw it up (at
some point we would need to add unit tests for the build scripts).

Maybe we can just add the message part, so it becomes clear that a pull
request does not change anything other than markdown files, but still run
through the regular tests?



On Fri, Sep 12, 2014 at 12:51 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> We could still have Jenkins post a message to the effect of =E2=80=9Cthis=
 patch
> only modifies .md files; no tests will be run=E2=80=9D.
> =E2=80=8B
>
> On Fri, Sep 12, 2014 at 3:48 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
> > Would it make sense to have Jenkins *not* trigger tests when the only
> > files that have changed are .md files (example
> > <https://github.com/apache/spark/pull/2367>)? Those don=E2=80=99t even =
need RAT
> > checks, right?
> >
> > I can make this change if it makes sense.
> >
> > Nick
> > =E2=80=8B
> >
>

--001a11c165d695ec790502e3be94--

From dev-return-9443-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 12 21:20:45 2014
Return-Path: <dev-return-9443-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25F0411A5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 12 Sep 2014 21:20:45 +0000 (UTC)
Received: (qmail 80750 invoked by uid 500); 12 Sep 2014 21:20:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80679 invoked by uid 500); 12 Sep 2014 21:20:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80667 invoked by uid 99); 12 Sep 2014 21:20:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 21:20:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rajiv.abraham@gmail.com designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 12 Sep 2014 21:20:18 +0000
Received: by mail-la0-f45.google.com with SMTP id b17so1759377lan.18
        for <dev@spark.apache.org>; Fri, 12 Sep 2014 14:20:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=4XJqePbu95ArPvE/3iBYOc0cvZC2NdRo5WI240tFrlU=;
        b=aGwVW5L50e5FF3lFfgXj8r8kbJWQJ8lOKWO/gy6q2LuXN7bPU6r/Zd3GtOQ8Zq2TIt
         46zMRuaS5RF8yxgKMxkQHz5eiAmebdS2mMjPeV7k8oa8vSPpoQEXahp1cUqeJje2puln
         FfJbhy6bOi3WNNctq75hhmdW08T+QVZCUnTAcN29IDD3bxT7pc29uh7Yb8t+J11r8GnK
         +d04mccS4c4m6ywmndSccq89FWPWVOb7MkktntmJf9jrAyN38Sm159HRGbflQYJ01eAa
         ro89G5zq9vFKHRYkJPp9gUpbmgxVDQxC5Kk56OPjJMGUrPXAjQL6GoZl8KTHG1RZZhBY
         M7mw==
X-Received: by 10.112.53.199 with SMTP id d7mr6227373lbp.106.1410556818021;
 Fri, 12 Sep 2014 14:20:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.114.79.199 with HTTP; Fri, 12 Sep 2014 14:19:47 -0700 (PDT)
From: Rajiv Abraham <rajiv.abraham@gmail.com>
Date: Fri, 12 Sep 2014 17:19:47 -0400
Message-ID: <CADnDY-Uab4Qw2nd+YCmz-NrnpbZWkeKu8tCm=RivhjPE_3+Azg@mail.gmail.com>
Subject: Response to archived question 'Spark and Scala Worksheet'
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133d09e12e5a90502e4da77
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133d09e12e5a90502e4da77
Content-Type: text/plain; charset=UTF-8

Hi,
This is a response to an archived email about how to run Spark in a Scala
worksheet in the Scala IDE.

http://mail-archives.apache.org/mod_mbox/spark-user/201401.mbox/%3CCAAUywg8A+mJQwhtgYtz0LUMntLGFwA-NOxTOPEYaDEQ+GwSLYg@mail.gmail.com%3E

I know it's a bit late :) but here is how I do it.

https://gist.github.com/RAbraham/585939e5390d46a7d6f8



-- 
Take care,
Rajiv

--001a1133d09e12e5a90502e4da77--

From dev-return-9444-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 13 01:02:36 2014
Return-Path: <dev-return-9444-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3BB14110F8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 13 Sep 2014 01:02:36 +0000 (UTC)
Received: (qmail 39547 invoked by uid 500); 13 Sep 2014 01:02:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39483 invoked by uid 500); 13 Sep 2014 01:02:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 12491 invoked by uid 99); 13 Sep 2014 00:48:35 -0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 216.145.54.171 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: NullWritable not serializable
Thread-Topic: NullWritable not serializable
Thread-Index: AQHPzuxUsMmeZ0mdo0abGieZRDwkjA==
Date: Sat, 13 Sep 2014 00:47:44 +0000
Message-ID: <D038E23E.36A2%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D038E23E36A2liduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 569265006
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D038E23E36A2liduyahooinccom_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi,

I was trying the following on spark-shell (built with apache master and had=
oop 2.4.0). Both calling rdd2.collect and calling rdd3.collect threw java.i=
o.NotSerializableException: org.apache.hadoop.io.NullWritable.

I got the same problem in similar code of my app which uses the newly relea=
sed Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine with spark 1.=
0.2 under either hadoop 2.40 and 0.23.10.

Anybody knows what caused the problem?

Thanks,
Du

----
import org.apache.hadoop.io.{NullWritable, Text}
val rdd =3D sc.textFile("README.md")
val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
res.saveAsSequenceFile("./test_data")
val rdd2 =3D sc.sequenceFile("./test_data", classOf[NullWritable], classOf[=
Text])
rdd2.collect
val rdd3 =3D sc.sequenceFile[NullWritable,Text]("./test_data")
rdd3.collect



--_000_D038E23E36A2liduyahooinccom_--

From dev-return-9445-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 13 04:10:41 2014
Return-Path: <dev-return-9445-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2ED781144F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 13 Sep 2014 04:10:41 +0000 (UTC)
Received: (qmail 75721 invoked by uid 500); 13 Sep 2014 04:10:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75606 invoked by uid 500); 13 Sep 2014 04:10:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74503 invoked by uid 99); 13 Sep 2014 04:10:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 04:10:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 04:10:13 +0000
Received: by mail-ie0-f177.google.com with SMTP id rd18so2029960iec.22
        for <multiple recipients>; Fri, 12 Sep 2014 21:10:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=dT2/SzLE+iDkXHqgUUQd5s0gosmbaO4UE7OXciRA7Vk=;
        b=WqgRtqvnHBDD8JOxUM1ipg9XIB2/Iid7G273+Axhu77wDxCGCO/cv97W8iEKOZtRiJ
         l8tHUUDC2ng3eNIdwz+eHDinUS12uDU2cNw5f/GetgzRZ8NTVWvQUIzwN/LXbewwUAdU
         cxiI3PZgID27s4qXk8MMSfF56aShE9RfAVPYCGS8doLZ+jp35JycFBqVGCM+an2KLKtI
         +J87JFRBd027I3Nsvq33RPkmA+P0wZdmz0a2io7stQ/D+27+I1+h+BtBLY08f218IXdo
         DeGaoLy/zbCldIPpFzaURKfASO9YnWkBoJeUIKIooEm5a9XTA0+D8oSSq6M8moLhAjx/
         M7BQ==
X-Received: by 10.42.230.144 with SMTP id jm16mr6439004icb.68.1410581411697;
        Fri, 12 Sep 2014 21:10:11 -0700 (PDT)
Received: from mbp-3.local (CPE68b6fc3fbad3-CM68b6fc3fbad0.cpe.net.cable.rogers.com. [99.226.46.122])
        by mx.google.com with ESMTPSA id z5sm3367081igl.21.2014.09.12.21.10.10
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 12 Sep 2014 21:10:11 -0700 (PDT)
Date: Sat, 13 Sep 2014 00:10:11 -0400
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Du Li <lidu@yahoo-inc.com.invalid>, 
 "=?utf-8?Q?user=40spark.apache.org?=" <user@spark.apache.org>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.5413c3a3.628c895d.59d1@mbp-3.local>
In-Reply-To: <D038E23E.36A2%lidu@yahoo-inc.com>
References: <D038E23E.36A2%lidu@yahoo-inc.com>
Subject: Re: NullWritable not serializable
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5413c3a3_333ab105_59d1"
X-Virus-Checked: Checked by ClamAV on apache.org

--5413c3a3_333ab105_59d1
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi Du,

I don't think NullWritable has ever been serializable, so you must be doi=
ng something differently from your previous program. In this case though,=
 just use a map() to turn your Writables to serializable types (e.g. null=
 and String).

Matie

On September 12, 2014 at 8:48:36 PM, Du Li (lidu=40yahoo-inc.com.invalid)=
 wrote:

Hi,

I was trying the following on spark-shell (built with apache master and h=
adoop 2.4.0). Both calling rdd2.collect and calling rdd3.collect threw=C2=
=A0java.io.NotSerializableException: org.apache.hadoop.io.NullWritable.=C2=
=A0

I got the same problem in similar code of my app which uses the newly rel=
eased Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine with spar=
k 1.0.2 under either hadoop 2.40 and 0.23.10.

Anybody knows what caused the problem=3F

Thanks,
Du

----
import org.apache.hadoop.io.=7BNullWritable, Text=7D
val rdd =3D sc.text=46ile(=22README.md=22)
val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
res.saveAsSequence=46ile(=22./test=5Fdata=22)
val rdd2 =3D sc.sequence=46ile(=22./test=5Fdata=22, classOf=5BNullWritabl=
e=5D, classOf=5BText=5D)
rdd2.collect
val rdd3 =3D sc.sequence=46ile=5BNullWritable,Text=5D(=22./test=5Fdata=22=
)
rdd3.collect



--5413c3a3_333ab105_59d1--


From dev-return-9446-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 13 09:12:54 2014
Return-Path: <dev-return-9446-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 17E3C1186B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 13 Sep 2014 09:12:54 +0000 (UTC)
Received: (qmail 5776 invoked by uid 500); 13 Sep 2014 09:12:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5603 invoked by uid 500); 13 Sep 2014 09:12:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4688 invoked by uid 99); 13 Sep 2014 09:12:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:12:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yanbohappy@gmail.com designates 74.125.82.179 as permitted sender)
Received: from [74.125.82.179] (HELO mail-we0-f179.google.com) (74.125.82.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:12:45 +0000
Received: by mail-we0-f179.google.com with SMTP id u56so1771172wes.10
        for <multiple recipients>; Sat, 13 Sep 2014 02:12:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=VEI5DvuZ15x885pyrsNtcTe72VnlUyiBDv0vsqs7ErY=;
        b=XBAq/Nf4E6cb8ijK7DBkuDDK+bCUg/p0CWs2M4rNQcjXN67kq+ABbFUilh7VxYH9J5
         2P0NG4FijSFvx2tR/A1mP9GNZ/SkLu7RQezX/IuZGD1lY+8V+4c9akxrpRFlzniFMozs
         6AMmAMWP12NCe2t+YjDh/DSUzNQ8Dxce3EYUNbkSMkmtDmHceO9nVxppuAxvTcKzXIet
         0cPCqpxD+1W0aEOlIuEVnHBADMKW5/CdkT1r3+BsWD5ne3K59i9UQEAz242uD9lc/+cT
         /Tk5pGWn/qCOrIRL+UDJMcVxzgCfO0LBhLjr+GuBQnYVD4wVQvKgb+r5uywSK4sypJvr
         ffIw==
MIME-Version: 1.0
X-Received: by 10.180.102.40 with SMTP id fl8mr9004469wib.17.1410599541409;
 Sat, 13 Sep 2014 02:12:21 -0700 (PDT)
Received: by 10.217.56.1 with HTTP; Sat, 13 Sep 2014 02:12:21 -0700 (PDT)
Date: Sat, 13 Sep 2014 17:12:21 +0800
Message-ID: <CALDQvde2QgHUunHec5FNx7G0PSb3sNf+2LgtXYdFo7oMHcYZnQ@mail.gmail.com>
Subject: [mllib] LogisticRegressionWithLBFGS interface is not consistent with LogisticRegressionWithSGD
From: Yanbo Liang <yanbohappy@gmail.com>
To: "user@spark.apache.org" <user@spark.apache.org>, dev@spark.apache.org, mengxr@gmail.com, 
	dbtsai@dbtsai.com
Content-Type: multipart/alternative; boundary=f46d0444ec5d960db10502eecc3b
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0444ec5d960db10502eecc3b
Content-Type: text/plain; charset=UTF-8

Hi All,

I found that LogisticRegressionWithLBFGS interface is not consistent
with LogisticRegressionWithSGD in master and 1.1 release.

https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/classification/LogisticRegression.scala#L199

In the above code snippet, users can only construct a
LogisticRegressionWithLBFGS without any user specified parameters.
Although users can specific training parameters calling corresponding
function of class LBFGS.
But this behave different with LogisticRegressionWithSGD.
Could anyone can tell me why we did not refactor the code to keep
consistent interface?

Thank you
Yanbo

--f46d0444ec5d960db10502eecc3b--

From dev-return-9447-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 13 09:15:46 2014
Return-Path: <dev-return-9447-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B120811878
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 13 Sep 2014 09:15:46 +0000 (UTC)
Received: (qmail 11391 invoked by uid 500); 13 Sep 2014 09:15:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11342 invoked by uid 500); 13 Sep 2014 09:15:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10148 invoked by uid 99); 13 Sep 2014 09:15:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:15:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yanbohappy@gmail.com designates 209.85.212.181 as permitted sender)
Received: from [209.85.212.181] (HELO mail-wi0-f181.google.com) (209.85.212.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:15:38 +0000
Received: by mail-wi0-f181.google.com with SMTP id bs8so1828228wib.14
        for <multiple recipients>; Sat, 13 Sep 2014 02:15:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=+SXr9nsdbvKCeaImjGdpi6+Y4qk1IOsNzYI6qun4fmA=;
        b=zI+hT8q6dNPfO1FyGGc5rS1KwODt9/oZcGRus055iwMRLC2eODow+KqrshH9DVO/n4
         pdx6L4P+aPxQCFIsRHO0zMdsar0/GQwEuZgUxu+qPsJXxbcdDFXuqnHb+3s91sAyRxpJ
         xEBnhDw10BtwlnmhjJr9NMkertkr6iRo8JyY9s8cZBywefcz8n9+PF7atwWICThvg/G9
         fZLKHZlFNYmbtQ+B+hQnaHtyHdmjfDb2160NAsNBl/7UyAf8lLpdGU1RWcAj45lHKPA1
         GbApgRd7wblTdVRVdnzLhYZ6NUwKKDsOI/39tRPAHi2KsfoKpgoGZgChiKVwBZmC2SVQ
         cC6w==
MIME-Version: 1.0
X-Received: by 10.180.19.233 with SMTP id i9mr8893192wie.17.1410599717698;
 Sat, 13 Sep 2014 02:15:17 -0700 (PDT)
Received: by 10.217.56.1 with HTTP; Sat, 13 Sep 2014 02:15:17 -0700 (PDT)
In-Reply-To: <CALDQvde2QgHUunHec5FNx7G0PSb3sNf+2LgtXYdFo7oMHcYZnQ@mail.gmail.com>
References: <CALDQvde2QgHUunHec5FNx7G0PSb3sNf+2LgtXYdFo7oMHcYZnQ@mail.gmail.com>
Date: Sat, 13 Sep 2014 17:15:17 +0800
Message-ID: <CALDQvddFTj-pa-5v0ZDXDNjQecyurTMKV0uTfrN4+=wroaLCsA@mail.gmail.com>
Subject: Re: [mllib] LogisticRegressionWithLBFGS interface is not consistent
 with LogisticRegressionWithSGD
From: Yanbo Liang <yanbohappy@gmail.com>
To: "user@spark.apache.org" <user@spark.apache.org>, dev@spark.apache.org, mengxr@gmail.com, 
	dbtsai@dbtsai.com
Content-Type: multipart/alternative; boundary=bcaec53d5e031802530502eed729
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53d5e031802530502eed729
Content-Type: text/plain; charset=UTF-8

I also found
https://github.com/apache/spark/commit/8f6e2e9df41e7de22b1d1cbd524e20881f861dd0
had resolve this issue but it seems that right code snippet not occurs in
master or 1.1 release.

2014-09-13 17:12 GMT+08:00 Yanbo Liang <yanbohappy@gmail.com>:

> Hi All,
>
> I found that LogisticRegressionWithLBFGS interface is not consistent
> with LogisticRegressionWithSGD in master and 1.1 release.
>
>
> https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/classification/LogisticRegression.scala#L199
>
> In the above code snippet, users can only construct a
> LogisticRegressionWithLBFGS without any user specified parameters.
> Although users can specific training parameters calling corresponding
> function of class LBFGS.
> But this behave different with LogisticRegressionWithSGD.
> Could anyone can tell me why we did not refactor the code to keep
> consistent interface?
>
> Thank you
> Yanbo
>
>
>

--bcaec53d5e031802530502eed729--

From dev-return-9448-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 13 09:26:03 2014
Return-Path: <dev-return-9448-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1398411884
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 13 Sep 2014 09:26:03 +0000 (UTC)
Received: (qmail 17259 invoked by uid 500); 13 Sep 2014 09:25:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17204 invoked by uid 500); 13 Sep 2014 09:25:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16028 invoked by uid 99); 13 Sep 2014 09:25:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:25:58 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.52] (HELO mail-qa0-f52.google.com) (209.85.216.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 13 Sep 2014 09:25:55 +0000
Received: by mail-qa0-f52.google.com with SMTP id m5so1819845qaj.11
        for <dev@spark.apache.org>; Sat, 13 Sep 2014 02:25:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=KtmLoOZjbTUeOqzuu/3k4G3i/ZrD+Z6cqEQJ9VwPLSU=;
        b=UMuTFc6p5embkwRisDntycZRLPU8y1hnNqTwtK3tvRPO+Ys9F2EgsxnswB9xGgtRwS
         X4dOC7eeVRIuTb/AuqAYpUpiSi1PQYdHY2/Y4I7iek3qLfWRM+2rdy0KyRlSjK6g8p/D
         o013BWzY4/8NFcY8qfX52Yuk6Ui1E4Wjsk9cbg0zP+raFNJIg1Wvsj18xwrOtvWYh+YH
         7hJuq7QXLEky59HK94NJ93M/hPCxRwIA55+Bl7t99LqSUB7Aff2l56l54sEdOSl+KQRQ
         jnFyEyXXhB1rALOVrZexw02zgadUyhs1lH+dLEL+0ABmYAw/iYdkryIKfq+deZiRqJY4
         sMYg==
X-Gm-Message-State: ALoCoQknqp5+9Wdn5SK2Vi6BQ2f1j98QpXsU7ra62DqouJ3iqUTqaYQM6QU1XQA5wLVw5XG121Hj
MIME-Version: 1.0
X-Received: by 10.140.91.46 with SMTP id y43mr15573640qgd.58.1410600334130;
 Sat, 13 Sep 2014 02:25:34 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.44.73 with HTTP; Sat, 13 Sep 2014 02:25:34 -0700 (PDT)
In-Reply-To: <CALDQvde2QgHUunHec5FNx7G0PSb3sNf+2LgtXYdFo7oMHcYZnQ@mail.gmail.com>
References: <CALDQvde2QgHUunHec5FNx7G0PSb3sNf+2LgtXYdFo7oMHcYZnQ@mail.gmail.com>
Date: Sat, 13 Sep 2014 02:25:34 -0700
X-Google-Sender-Auth: hUPATxT7K_W1gHKUMCINEhQ8bi4
Message-ID: <CAEYYnxa+nk-j0Okath6tBqSxfupcbfwZ+r2svptBM8vS-aJPAQ@mail.gmail.com>
Subject: Re: [mllib] LogisticRegressionWithLBFGS interface is not consistent
 with LogisticRegressionWithSGD
From: DB Tsai <dbtsai@dbtsai.com>
To: Yanbo Liang <yanbohappy@gmail.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, dev@spark.apache.org, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Yanbo,

We made the change here
https://github.com/apache/spark/commit/5d25c0b74f6397d78164b96afb8b8cbb1b15cfbd

Those apis to set the parameters are very difficult to maintain, so we
decide not to provide them. In next release, Spark 1.2, we will have a
better api design for parameter setting.

Sincerely,

DB Tsai
-------------------------------------------------------
My Blog: https://www.dbtsai.com
LinkedIn: https://www.linkedin.com/in/dbtsai


On Sat, Sep 13, 2014 at 2:12 AM, Yanbo Liang <yanbohappy@gmail.com> wrote:
> Hi All,
>
> I found that LogisticRegressionWithLBFGS interface is not consistent with
> LogisticRegressionWithSGD in master and 1.1 release.
>
> https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/classification/LogisticRegression.scala#L199
>
> In the above code snippet, users can only construct a
> LogisticRegressionWithLBFGS without any user specified parameters.
> Although users can specific training parameters calling corresponding
> function of class LBFGS.
> But this behave different with LogisticRegressionWithSGD.
> Could anyone can tell me why we did not refactor the code to keep consistent
> interface?
>
> Thank you
> Yanbo
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9449-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 01:23:33 2014
Return-Path: <dev-return-9449-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6E8E0115B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 01:23:33 +0000 (UTC)
Received: (qmail 25885 invoked by uid 500); 14 Sep 2014 01:23:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25809 invoked by uid 500); 14 Sep 2014 01:23:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24606 invoked by uid 99); 14 Sep 2014 01:23:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 01:23:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nzjemail@gmail.com designates 74.125.82.178 as permitted sender)
Received: from [74.125.82.178] (HELO mail-we0-f178.google.com) (74.125.82.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 01:23:23 +0000
Received: by mail-we0-f178.google.com with SMTP id q58so2433366wes.37
        for <multiple recipients>; Sat, 13 Sep 2014 18:23:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=qWi16CTZwr7T5yUxmz8/R0iDxBr9v9CZ8OKFf3TFCeU=;
        b=hY/th9e0qxcHPui6ZQr1GjryopeZKc3tdQ2/V1T3zf1C5CoRDOP5b7PvSXE4fefBia
         S9NBBbW7tBwsVTjrI7RaFkhxwW69xzSZuLKC0gPj1D57kN5ozOZNjVY65wUFBpt594nG
         0mX9yaDqFyAT9IFpPrSO9CbhjOXZr4l8lEgEGcTwQdhgKQ+NC86z5vJNS6EANq7gJqM3
         M3QlG1Hdh70JhT9FlG2/enWOuQQ/e1wU+U5u2178ao/5F7wTqVuPoMgFwsB058/Y51QU
         MErIQ7oVh4w9EklIZo4mcFz7qhmEAkD87ib5LFT0+j4E/gwPHyZL4oETLVdymspGQ3vW
         QvPQ==
MIME-Version: 1.0
X-Received: by 10.195.11.200 with SMTP id ek8mr23025372wjd.85.1410657782336;
 Sat, 13 Sep 2014 18:23:02 -0700 (PDT)
Received: by 10.194.174.231 with HTTP; Sat, 13 Sep 2014 18:23:02 -0700 (PDT)
Date: Sun, 14 Sep 2014 09:23:02 +0800
Message-ID: <CAHc8ag1F5ZhGoyU2vPgR7mvx=QJ6f87A6EdDzV0FE-k8rwMt2A@mail.gmail.com>
Subject: Workload for spark testing
From: =?UTF-8?B?54mb5YWG5o23?= <nzjemail@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b8737620413b40502fc5cce
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b8737620413b40502fc5cce
Content-Type: text/plain; charset=UTF-8

Hi All:

We know some memory of spark are used for computing (e.g.,
spark.shuffle.memoryFraction) and some are used for caching RDD for future
use (e.g., spark.storage.memoryFraction).

Is there any existing workload which can utilize both of them during the
running left cycle? I want to do some performance by adjusting the ratio of
them.

Thanks.

-- 
*Regards,*
*Zhaojie*

--047d7b8737620413b40502fc5cce--

From dev-return-9450-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 06:08:00 2014
Return-Path: <dev-return-9450-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5EFFD11939
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 06:08:00 +0000 (UTC)
Received: (qmail 97877 invoked by uid 500); 14 Sep 2014 06:07:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97809 invoked by uid 500); 14 Sep 2014 06:07:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97796 invoked by uid 99); 14 Sep 2014 06:07:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 06:07:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.45 as permitted sender)
Received: from [209.85.218.45] (HELO mail-oi0-f45.google.com) (209.85.218.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 06:07:53 +0000
Received: by mail-oi0-f45.google.com with SMTP id v63so1525132oia.32
        for <dev@spark.apache.org>; Sat, 13 Sep 2014 23:07:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=NUpjifH+b9bJIVdiT9mtnfy4uCrCAAw3hLO7vMD5UE8=;
        b=dWG7pDb28+tG1t5BRg7exssW+gmi2CMkLpum6XpDvE/2wWcmZUWKim5n0Hsksk0pqo
         299hLof5pbUNuVr1UzEv3NHlTRIsS2hsCEXzyKevNnYKhaAdG0XrfJxwtNUhwlcpDw+F
         nU6yH0STwwLyNYijuQPujrOq7vETAUKth/F8EqEQGPFC1ymaYze9D0v+ze6ANw9FbsJQ
         CAt0zRfqVAQvAZgxK5hcRx3Zz4T1GS9H5O6W4XvhBidcY2/uATsu/ZbUmkzH+DXIxgLN
         IlsPg6Y14gSvJlO/VszT9igTkG44xsL29GL1WZTWH15HjgHKPDbH5ayOF7/lWkQImase
         ZkuQ==
MIME-Version: 1.0
X-Received: by 10.60.60.131 with SMTP id h3mr1893899oer.17.1410674853135; Sat,
 13 Sep 2014 23:07:33 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Sat, 13 Sep 2014 23:07:33 -0700 (PDT)
Date: Sat, 13 Sep 2014 23:07:33 -0700
Message-ID: <CABPQxssauravgrs_qTey-XxuV7Q0Lk395OL1naB0TVtE-4ztTw@mail.gmail.com>
Subject: Tests and Test Infrastructure
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

Wanted to send a quick update about test infrastructure. With the
number of contributors we have and the rate of development,
maintaining a well-oiled test infra is really important.

Every time a flaky test fails a legitimate pull request, it wastes
developer time and effort.

1. Master build: Spark's master builds are back to green again in
Maven and SBT after a long time of instability. Big thanks to Josh
Rosen, Andrew Or, Nick Chammas, Shane Knapp, Sean Owen, and many
others who were involved in pinpointing and fixing fairly convoluted
test failure issues.

2. Jenkins PRB: The Jenkins Pull Request Builder is mostly functioning
again. However, we are working on a simpler technical pipeline for
testing patches, as this plug-in has been a constant source of
downtime and issues for us, and is very hard to debug.

3. Reverting flaky patches: Going forward - we may revert patches that
seem to be the root cause of flaky or failing tests. This is necessary
as these days, the test infra being down will block something like
10-30 in-flight patches on a given day. This puts the onus back on the
test writer to try and figure out what's going on - we'll of course
help debug the issue!

4. Time of tests: With hundreds (thousands?) of tests, we will have a
very high bar for tests which take several seconds or longer. Things
like Thread.sleep() bloat test time when proper synchronization
mechanisms should be used. Expect reviewers to push back on any
long-running tests, in many cases they can be re-written to be both
shorter and better.

Thanks again to everyone putting in effort on this, we've made a ton
of progress in the last few weeks. A solid test infra will help us
scale and move quickly as Spark development continues to accelerate.

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9451-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 06:20:47 2014
Return-Path: <dev-return-9451-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B75B911971
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 06:20:47 +0000 (UTC)
Received: (qmail 43911 invoked by uid 500); 14 Sep 2014 06:20:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43840 invoked by uid 500); 14 Sep 2014 06:20:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43828 invoked by uid 99); 14 Sep 2014 06:20:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 06:20:46 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 06:20:41 +0000
Received: by mail-qc0-f178.google.com with SMTP id c9so761840qcz.23
        for <dev@spark.apache.org>; Sat, 13 Sep 2014 23:20:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=ucqoClw3sEbj03UDREEfWE7EUO9AFIcSliS/Zf6KN4w=;
        b=AuMxCF+jZ78NoYqlQ2P8of9ov2k6zOmNjTk23gOYjTXK4bWMO1NZbYwmfYzzZRxNEB
         gQjNKbXfbziGofi3Q0k7a0g+JhFMXRUNGwmrZBzyVqumTobCzNBXq1U4YP++FP8BpSMf
         7ljVhzt+lG+xTDOpNYFG95KnHgYJIc5rqF3qyIVXa1zgtQ0DTKhEEfZHXYyqOMTMYdLz
         YavixN9Ccmpp0feQTWvU2TI2y1A27kUUrdPUfHs9S+fdU2Qyl/cZP0tmXp+Ah99ls8TV
         RPV0UW1W3CgobuSb+syqd7/pTTFYZuVzelxJu0LEw72lhDij1e7uw8FZSh7iMW1twyY5
         Ts6Q==
X-Received: by 10.224.160.83 with SMTP id m19mr52411qax.95.1410675620574;
        Sat, 13 Sep 2014 23:20:20 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:e56b:c061:722f:9bf1])
        by mx.google.com with ESMTPSA id l7sm6844433qae.45.2014.09.13.23.20.19
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Sat, 13 Sep 2014 23:20:19 -0700 (PDT)
Date: Sat, 13 Sep 2014 23:20:17 -0700
From: Josh Rosen <rosenville@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Patrick
 Wendell <pwendell@gmail.com>
Message-ID: <etPan.541533a1.238e1f29.b3c8@joshs-mbp.att.net>
In-Reply-To: <CABPQxssauravgrs_qTey-XxuV7Q0Lk395OL1naB0TVtE-4ztTw@mail.gmail.com>
References: <CABPQxssauravgrs_qTey-XxuV7Q0Lk395OL1naB0TVtE-4ztTw@mail.gmail.com>
Subject: Re: Tests and Test Infrastructure
X-Mailer: Airmail Beta (250)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="541533a1_46e87ccd_b3c8"
X-Virus-Checked: Checked by ClamAV on apache.org

--541533a1_46e87ccd_b3c8
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Also, huge thanks to Cheng Lian, who tracked down and fixed the final iss=
ue that was causing the Maven master build=E2=80=99s Spark SQL tests to f=
ail=21

On September 13, 2014 at 11:08:00 PM, Patrick Wendell (pwendell=40gmail.c=
om) wrote:
Hey All, =20

Wanted to send a quick update about test infrastructure. With the =20
number of contributors we have and the rate of development, =20
maintaining a well-oiled test infra is really important. =20

Every time a flaky test fails a legitimate pull request, it wastes =20
developer time and effort. =20

1. Master build: Spark's master builds are back to green again in =20
Maven and SBT after a long time of instability. Big thanks to Josh =20
Rosen, Andrew Or, Nick Chammas, Shane Knapp, Sean Owen, and many =20
others who were involved in pinpointing and fixing fairly convoluted =20
test failure issues. =20

2. Jenkins PRB: The Jenkins Pull Request Builder is mostly functioning =20
again. However, we are working on a simpler technical pipeline for =20
testing patches, as this plug-in has been a constant source of =20
downtime and issues for us, and is very hard to debug. =20

3. Reverting flaky patches: Going forward - we may revert patches that =20
seem to be the root cause of flaky or failing tests. This is necessary =20
as these days, the test infra being down will block something like =20
10-30 in-flight patches on a given day. This puts the onus back on the =20
test writer to try and figure out what's going on - we'll of course =20
help debug the issue=21 =20

4. Time of tests: With hundreds (thousands=3F) of tests, we will have a =20
very high bar for tests which take several seconds or longer. Things =20
like Thread.sleep() bloat test time when proper synchronization =20
mechanisms should be used. Expect reviewers to push back on any =20
long-running tests, in many cases they can be re-written to be both =20
shorter and better. =20

Thanks again to everyone putting in effort on this, we've made a ton =20
of progress in the last few weeks. A solid test infra will help us =20
scale and move quickly as Spark development continues to accelerate. =20

- Patrick =20

--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--541533a1_46e87ccd_b3c8--


From dev-return-9452-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 22:05:28 2014
Return-Path: <dev-return-9452-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 674A1118D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 22:05:28 +0000 (UTC)
Received: (qmail 46531 invoked by uid 500); 14 Sep 2014 22:05:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46447 invoked by uid 500); 14 Sep 2014 22:05:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46434 invoked by uid 99); 14 Sep 2014 22:05:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:05:27 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.182 as permitted sender)
Received: from [74.125.82.182] (HELO mail-we0-f182.google.com) (74.125.82.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:05:21 +0000
Received: by mail-we0-f182.google.com with SMTP id k48so3095533wev.13
        for <dev@spark.apache.org>; Sun, 14 Sep 2014 15:05:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=7yn7W74sAb6iogkpTjqRT9erGeN/OGnvJaSjtM50PZ0=;
        b=JobsoRfcn+DIRnetHb8kAmMymGXNj3RLW4YOkgezUCcWxS7uVDik4VxcbpdZCT2X9Y
         h4oQtGRDwUojF90T23wOhhSa9tFZk0l+vMQvBpcKQpfvFGR5cTnW2tWF5k3bEIKl4jdU
         EbaFHULzTRM2cDHHv5PlGQqyJ/YU5KeQygFPizcxfBgqZBp285itelkx0xbJi+6RcQmv
         YOYz2JKbzdAtQIUsDeEOcKsE2ITs8STEw7hpHmx/emyG9Mp4t44EPpJgVawdB1lZJJz4
         eRHb44EdxX0xGgHU+4s9p3XsP7M95TAZpQvsK5h0BRcg0a/ClvBzmsh0KVlskNf/BSVn
         03yQ==
X-Received: by 10.195.11.234 with SMTP id el10mr5770021wjd.95.1410732300312;
 Sun, 14 Sep 2014 15:05:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.92.232 with HTTP; Sun, 14 Sep 2014 15:04:20 -0700 (PDT)
In-Reply-To: <etPan.541533a1.238e1f29.b3c8@joshs-mbp.att.net>
References: <CABPQxssauravgrs_qTey-XxuV7Q0Lk395OL1naB0TVtE-4ztTw@mail.gmail.com>
 <etPan.541533a1.238e1f29.b3c8@joshs-mbp.att.net>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 14 Sep 2014 18:04:20 -0400
Message-ID: <CAOhmDzcvGu68Of8s_mNZBFBjRrR4GwLv9qfu8QZ9mJXFzm=Afw@mail.gmail.com>
Subject: Re: Tests and Test Infrastructure
To: Josh Rosen <rosenville@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Patrick Wendell <pwendell@gmail.com>
Content-Type: multipart/alternative; boundary=047d7b87375ca2289105030db57b
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b87375ca2289105030db57b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I fully support this. A smoothly running test infrastructure helps
everybody=E2=80=99s work just flow better.

The Jenkins Pull Request Builder is mostly functioning
again. However, we are working on a simpler technical pipeline for
testing patches, as this plug-in has been a constant source of
downtime and issues for us, and is very hard to debug.

Yep. One such issue that happens too often is that Jenkins simply fails to
fetch from git. Hopefully a new pipeline will be able to fetch more
reliably.

flaky tests

Dunno if these were some of the ones recently fixed, but the flakiest tests
seem to be the Kafka and Flume tests in Spark Streaming, based purely on my
subjective experience. It would be great if we could stabilize them!

Time of tests

PSA: Here are some related JIRA issues for those interested in working on
our testing setup:

   - SPARK-3431: Parallelize execution of tests
   <https://issues.apache.org/jira/browse/SPARK-3431>
   - SPARK-3432: Fix logging of unit test execution time
   <https://issues.apache.org/jira/browse/SPARK-3432>

Nick
=E2=80=8B

On Sun, Sep 14, 2014 at 2:20 AM, Josh Rosen <rosenville@gmail.com> wrote:

> Also, huge thanks to Cheng Lian, who tracked down and fixed the final
> issue that was causing the Maven master build=E2=80=99s Spark SQL tests t=
o fail!
>
> On September 13, 2014 at 11:08:00 PM, Patrick Wendell (pwendell@gmail.com=
)
> wrote:
> Hey All,
>
> Wanted to send a quick update about test infrastructure. With the
> number of contributors we have and the rate of development,
> maintaining a well-oiled test infra is really important.
>
> Every time a flaky test fails a legitimate pull request, it wastes
> developer time and effort.
>
> 1. Master build: Spark's master builds are back to green again in
> Maven and SBT after a long time of instability. Big thanks to Josh
> Rosen, Andrew Or, Nick Chammas, Shane Knapp, Sean Owen, and many
> others who were involved in pinpointing and fixing fairly convoluted
> test failure issues.
>
> 2. Jenkins PRB: The Jenkins Pull Request Builder is mostly functioning
> again. However, we are working on a simpler technical pipeline for
> testing patches, as this plug-in has been a constant source of
> downtime and issues for us, and is very hard to debug.
>
> 3. Reverting flaky patches: Going forward - we may revert patches that
> seem to be the root cause of flaky or failing tests. This is necessary
> as these days, the test infra being down will block something like
> 10-30 in-flight patches on a given day. This puts the onus back on the
> test writer to try and figure out what's going on - we'll of course
> help debug the issue!
>
> 4. Time of tests: With hundreds (thousands?) of tests, we will have a
> very high bar for tests which take several seconds or longer. Things
> like Thread.sleep() bloat test time when proper synchronization
> mechanisms should be used. Expect reviewers to push back on any
> long-running tests, in many cases they can be re-written to be both
> shorter and better.
>
> Thanks again to everyone putting in effort on this, we've made a ton
> of progress in the last few weeks. A solid test infra will help us
> scale and move quickly as Spark development continues to accelerate.
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b87375ca2289105030db57b--

From dev-return-9453-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 22:10:29 2014
Return-Path: <dev-return-9453-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 97244118ED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 22:10:29 +0000 (UTC)
Received: (qmail 50273 invoked by uid 500); 14 Sep 2014 22:10:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50194 invoked by uid 500); 14 Sep 2014 22:10:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50182 invoked by uid 99); 14 Sep 2014 22:10:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:10:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.48] (HELO mail-oa0-f48.google.com) (209.85.219.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:10:22 +0000
Received: by mail-oa0-f48.google.com with SMTP id g18so1983193oah.7
        for <dev@spark.apache.org>; Sun, 14 Sep 2014 15:10:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=QNlmECUrXc/z5gUpDqBYA7DwJGKeMRDDCFeLDvEx1BA=;
        b=HPTZBDllF+O3+hDnAh+QZaYJgp9skox0kOk9LmN8LQYlyd8Xhk8e8azxIHy9Eoi2YC
         78xAQw5EFQzpKOTn85qrXdXC786Y9h3pWAzcU9zxop9GgP8uAJRLUzrInj6Df86WQn3s
         rxIqj4VrZnM4JNSp+SMenPCzViAlbgc9j+eM22yK6l+MSkECTMaDBISS5DzV3j9ZiPN/
         I9/jKRJowTwzR4/V18fLsaPvbScBSvHkpTt/MSsKmR9sa0FMz/jPiq1CvFj2FbYg4qq2
         M39mKhvMGJCDgK3wmMcfJMNB8+cf9zo5cn4gM2dl2QOt8O1Eb738BMAfnFwGydl3fU7L
         FUZA==
X-Gm-Message-State: ALoCoQkPQWCVvnii3TslNXneZ+N9uPXLpPCXt84ZuKaHhAMr0M4nJYGnunP4Ql4EwFiDGARjA05A
MIME-Version: 1.0
X-Received: by 10.182.126.233 with SMTP id nb9mr22965764obb.46.1410732601048;
 Sun, 14 Sep 2014 15:10:01 -0700 (PDT)
Received: by 10.76.153.164 with HTTP; Sun, 14 Sep 2014 15:10:01 -0700 (PDT)
Date: Sun, 14 Sep 2014 17:10:01 -0500
Message-ID: <CAKWX9VV4R73ae239ZEFtLR1WXPOCAKwXaEEUeZT8fz3GrhiC0A@mail.gmail.com>
Subject: Support for Hive buckets
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1e5508f16aa05030dc7e8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1e5508f16aa05030dc7e8
Content-Type: text/plain; charset=UTF-8

I noticed that the release notes for 1.1.0 said that spark doesn't support
Hive buckets "yet".  I didn't notice any jira issues related to adding
support.

Broadly speaking, what would be involved in supporting buckets, especially
the bucketmapjoin and sortedmerge optimizations?

--001a11c1e5508f16aa05030dc7e8--

From dev-return-9454-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 14 22:41:57 2014
Return-Path: <dev-return-9454-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED9251194A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 14 Sep 2014 22:41:56 +0000 (UTC)
Received: (qmail 81385 invoked by uid 500); 14 Sep 2014 22:41:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81314 invoked by uid 500); 14 Sep 2014 22:41:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81303 invoked by uid 99); 14 Sep 2014 22:41:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:41:55 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_HELO_PASS,SPF_PASS,UNPARSEABLE_RELAY
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dtung@touchtunes.com designates 216.82.251.1 as permitted sender)
Received: from [216.82.251.1] (HELO mail1.bemta12.messagelabs.com) (216.82.251.1)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 14 Sep 2014 22:41:49 +0000
Received: from [216.82.249.35:50765] by server-1.bemta-12.messagelabs.com id E1/2A-09607-79916145; Sun, 14 Sep 2014 22:41:27 +0000
X-Env-Sender: dtung@touchtunes.com
X-Msg-Ref: server-13.tower-138.messagelabs.com!1410734486!10960844!1
X-Originating-IP: [207.96.182.162]
X-StarScan-Received:
X-StarScan-Version: 6.11.3; banners=touchtunes.com,-,-
X-VirusChecked: Checked
Received: (qmail 25219 invoked from network); 14 Sep 2014 22:41:26 -0000
Received: from mail.touchtunes.com (HELO exchange2007.touchtunes.com) (207.96.182.162)
  by server-13.tower-138.messagelabs.com with AES128-SHA encrypted SMTP; 14 Sep 2014 22:41:26 -0000
Received: from EXCHANGE2007.touchtunes.com ([192.168.132.112]) by
 exchange2007.touchtunes.com ([192.168.132.112]) with mapi; Sun, 14 Sep 2014
 18:41:25 -0400
From: David Tung <dtung@touchtunes.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Date: Sun, 14 Sep 2014 18:41:23 -0400
Subject: Source code for mining big data with Spark
Thread-Topic: Source code for mining big data with Spark
Thread-Index: Ac/QbQPz41APSXAAQ6S3T1EIKr7Tqw==
Message-ID: <D03B669D.11A05%dtung@touchtunes.com>
In-Reply-To: <CAKWX9VV4R73ae239ZEFtLR1WXPOCAKwXaEEUeZT8fz3GrhiC0A@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
user-agent: Microsoft-MacOutlook/14.0.0.100825
acceptlanguage: en-US
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I watched am impressed spark demo video by Reynold Xin and Aaron Davidson
in youtube ( https://www.youtube.com/watch?v=3DFjhRkfAuU7I ). Can someone
let me know where can I find the source codes for the demo? I can=B9t see
the source codes from video clearly.

Thanks in advance

CONFIDENTIALITY CAUTION=20
This e-mail and any attachments may be confidential or legally privileged.=
 If you received this message in error or are not the intended recipient, =
you should destroy the e-mail message and any attachments or copies, and y=
ou are prohibited from retaining, distributing, disclosing or using any in=
formation contained herein. Please inform us of the erroneous delivery by =
return e-mail. Thank you for your cooperation.
DOCUMENT CONFIDENTIEL=20
Le pr=E9sent courriel et tout fichier joint =E0 celui-ci peuvent contenir =
des renseignements confidentiels ou privil=E9gi=E9s. Si cet envoi ne s'adr=
esse pas =E0 vous ou si vous l'avez re=E7u par erreur, vous devez l'efface=
r. Vous ne pouvez conserver, distribuer, communiquer ou utiliser les rense=
ignements qu'il contient. Nous vous prions de nous signaler l'erreur par c=
ourriel. Merci de votre collaboration.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9455-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 06:26:33 2014
Return-Path: <dev-return-9455-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AE62B1113C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 06:26:33 +0000 (UTC)
Received: (qmail 6750 invoked by uid 500); 15 Sep 2014 06:26:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6679 invoked by uid 500); 15 Sep 2014 06:26:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6662 invoked by uid 99); 15 Sep 2014 06:26:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 06:26:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 06:26:06 +0000
Received: by mail-qg0-f53.google.com with SMTP id q108so3413419qgd.12
        for <dev@spark.apache.org>; Sun, 14 Sep 2014 23:26:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=afVM/0yl+mKcY4cJNC6acM1PSwYw14QmrbA8vMGoAl4=;
        b=tgvLTSJwWjzg0rcM/Q3012q0n1G/CdG7I1FImAh/mzYcEakmo3eBDdM6dBvrbbgHam
         3T0xcsQAUu57z0K58a0jigQPF3ER1iQBroDbFSn8dv3XEjk0GyFH9gaHfVrmo+N0ud8f
         ZGXyj/1/s3dimMxwRF/A6/65dp0FloKCyz58qBAE9eSP5sB17aE6HEBSsutcCYPJq7RW
         xbrroVUcv5sZ043qIHuvtgKlHF1B83nK3yNe9zM3LwfhlWH7TQz2/+kge6Nsm8C+0CFB
         kmLSUQIN999pKmKO2mC6IRwfiiFg/mUixwYDxxzi7ciFZ2bBzru2I0N/9o/hbKGv8x5C
         ldvA==
MIME-Version: 1.0
X-Received: by 10.140.93.230 with SMTP id d93mr34333413qge.53.1410762365442;
 Sun, 14 Sep 2014 23:26:05 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Sun, 14 Sep 2014 23:26:05 -0700 (PDT)
In-Reply-To: <CABPQxsuJfL9PUYEKsaE=9YyaTfiB5Y5SbR8mAsLnWY1B9YCC+Q@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
	<CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
	<CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
	<CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
	<CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
	<703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
	<CABPQxsuJfL9PUYEKsaE=9YyaTfiB5Y5SbR8mAsLnWY1B9YCC+Q@mail.gmail.com>
Date: Mon, 15 Sep 2014 10:26:05 +0400
Message-ID: <CAMrx5Dy+JFJCbK+yg94wCiH2_LNobkasNuiT97MjimmfGyxa-w@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Erik Erlandson <eje@redhat.com>, Xiangrui Meng <mengxr@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: multipart/alternative; boundary=001a11396236a7a02f050314b590
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11396236a7a02f050314b590
Content-Type: text/plain; charset=UTF-8

It's good, that databricks working on this issue! However current process
of working on that is not very clear for outsider.

   - Last update on this ticket is August 5. If all this time was active
   development, I have concerns that without feedback from community for such
   long time development can fall in wrong way.
   - Even if it would be great big patch as soon as you introduce new
   interfaces to community it would allow us to start working on our pipeline
   code. It would allow us write algorithm in new paradigm instead of in lack
   of any paradigms like it was before. It would allow us to help you transfer
   old code to new paradigm.

My main point - shorter iterations with more transparency.

I think it would be good idea to create some pull request with code, which
you have so far, even if it doesn't pass tests, so just we can comment on
it before formulating it in design doc.


2014-09-13 0:00 GMT+04:00 Patrick Wendell <pwendell@gmail.com>:

> We typically post design docs on JIRA's before major work starts. For
> instance, pretty sure SPARk-1856 will have a design doc posted
> shortly.
>
> On Fri, Sep 12, 2014 at 12:10 PM, Erik Erlandson <eje@redhat.com> wrote:
> >
> > Are interface designs being captured anywhere as documents that the
> community can follow along with as the proposals evolve?
> >
> > I've worked on other open source projects where design docs were
> published as "living documents" (e.g. on google docs, or etherpad, but the
> particular mechanism isn't crucial).   FWIW, I found that to be a good way
> to work in a community environment.
> >
> >
> > ----- Original Message -----
> >> Hi Egor,
> >>
> >> Thanks for the feedback! We are aware of some of the issues you
> >> mentioned and there are JIRAs created for them. Specifically, I'm
> >> pushing out the design on pipeline features and algorithm/model
> >> parameters this week. We can move our discussion to
> >> https://issues.apache.org/jira/browse/SPARK-1856 .
> >>
> >> It would be nice to make tests against interfaces. But it definitely
> >> needs more discussion before making PRs. For example, we discussed the
> >> learning interfaces in Christoph's PR
> >> (https://github.com/apache/spark/pull/2137/) but it takes time to
> >> reach a consensus, especially on interfaces. Hopefully all of us could
> >> benefit from the discussion. The best practice is to break down the
> >> proposal into small independent piece and discuss them on the JIRA
> >> before submitting PRs.
> >>
> >> For performance tests, there is a spark-perf package
> >> (https://github.com/databricks/spark-perf) and we added performance
> >> tests for MLlib in v1.1. But definitely more work needs to be done.
> >>
> >> The dev-list may not be a good place for discussion on the design,
> >> could you create JIRAs for each of the issues you pointed out, and we
> >> track the discussion on JIRA? Thanks!
> >>
> >> Best,
> >> Xiangrui
> >>
> >> On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com>
> wrote:
> >> > Xiangrui can comment more, but I believe Joseph and him are actually
> >> > working on standardize interface and pipeline feature for 1.2 release.
> >> >
> >> > On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <pahomov.egor@gmail.com
> >
> >> > wrote:
> >> >
> >> >> Some architect suggestions on this matter -
> >> >> https://github.com/apache/spark/pull/2371
> >> >>
> >> >> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
> >> >>
> >> >> > Sorry, I misswrote  - I meant learners part of framework - models
> >> >> > already
> >> >> > exists.
> >> >> >
> >> >> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
> >> >> > christoph.sawade@googlemail.com>:
> >> >> >
> >> >> >> I totally agree, and we discovered also some drawbacks with the
> >> >> >> classification models implementation that are based on GLMs:
> >> >> >>
> >> >> >> - There is no distinction between predicting scores, classes, and
> >> >> >> calibrated scores (probabilities). For these models it is common
> to
> >> >> >> have
> >> >> >> access to all of them and the prediction function
> ``predict``should be
> >> >> >> consistent and stateless. Currently, the score is only available
> after
> >> >> >> removing the threshold from the model.
> >> >> >> - There is no distinction between multinomial and binomial
> >> >> >> classification. For multinomial problems, it is necessary to
> handle
> >> >> >> multiple weight vectors and multiple confidences.
> >> >> >> - Models are not serialisable, which makes it hard to use them in
> >> >> >> practise.
> >> >> >>
> >> >> >> I started a pull request [1] some time ago. I would be happy to
> >> >> >> continue
> >> >> >> the discussion and clarify the interfaces, too!
> >> >> >>
> >> >> >> Cheers, Christoph
> >> >> >>
> >> >> >> [1] https://github.com/apache/spark/pull/2137/
> >> >> >>
> >> >> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com>:
> >> >> >>
> >> >> >>> Here in Yandex, during implementation of gradient boosting in
> spark
> >> >> >>> and
> >> >> >>> creating our ML tool for internal use, we found next serious
> problems
> >> >> in
> >> >> >>> MLLib:
> >> >> >>>
> >> >> >>>
> >> >> >>>    - There is no Regression/Classification model abstraction. We
> were
> >> >> >>>    building abstract data processing pipelines, which should
> work just
> >> >> >>> with
> >> >> >>>    some regression - exact algorithm specified outside this code.
> >> >> >>>    There
> >> >> >>> is no
> >> >> >>>    abstraction, which will allow me to do that. *(It's main
> reason for
> >> >> >>> all
> >> >> >>>    further problems) *
> >> >> >>>    - There is no common practice among MLlib for testing
> algorithms:
> >> >> >>> every
> >> >> >>>    model generates it's own random test data. There is no easy
> >> >> >>> extractable
> >> >> >>>    test cases applible to another algorithm. There is no
> benchmarks
> >> >> >>>    for
> >> >> >>>    comparing algorithms. After implementing new algorithm it's
> very
> >> >> hard
> >> >> >>> to
> >> >> >>>    understand how it should be tested.
> >> >> >>>    - Lack of serialization testing: MLlib algorithms don't
> contain
> >> >> tests
> >> >> >>>    which test that model work after serialization.
> >> >> >>>    - During implementation of new algorithm it's hard to
> understand
> >> >> what
> >> >> >>>    API you should create and which interface to implement.
> >> >> >>>
> >> >> >>> Start for solving all these problems must be done in creating
> common
> >> >> >>> interface for typical algorithms/models - regression,
> classification,
> >> >> >>> clustering, collaborative filtering.
> >> >> >>>
> >> >> >>> All main tests should be written against these interfaces, so
> when new
> >> >> >>> algorithm implemented - all it should do is passed already
> written
> >> >> tests.
> >> >> >>> It allow us to have managble quality among all lib.
> >> >> >>>
> >> >> >>> There should be couple benchmarks which allow new spark user to
> get
> >> >> >>> feeling
> >> >> >>> about which algorithm to use.
> >> >> >>>
> >> >> >>> Test set against these abstractions should contain serialization
> test.
> >> >> In
> >> >> >>> production most time there is no need in model, which can't be
> stored.
> >> >> >>>
> >> >> >>> As the first step of this roadmap I'd like to create trait
> >> >> >>> RegressionModel,
> >> >> >>> *ADD* methods to current algorithms to implement this trait and
> create
> >> >> >>> some
> >> >> >>> tests against it. Planning of doing it next week.
> >> >> >>>
> >> >> >>> Purpose of this letter is to collect any objections to this
> approach
> >> >> >>> on
> >> >> >>> early stage: please give any feedback. Second reason is to set
> lock on
> >> >> >>> this
> >> >> >>> activity so we wouldn't do the same thing twice: I'll create pull
> >> >> request
> >> >> >>> by the end of the next week and any parallalizm in development
> we can
> >> >> >>> start
> >> >> >>> from there.
> >> >> >>>
> >> >> >>>
> >> >> >>>
> >> >> >>> --
> >> >> >>>
> >> >> >>>
> >> >> >>>
> >> >> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >> >>>
> >> >> >>
> >> >> >>
> >> >> >
> >> >> >
> >> >> > --
> >> >> >
> >> >> >
> >> >> >
> >> >> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >> >
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >>
> >> >>
> >> >>
> >> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >>
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>



-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a11396236a7a02f050314b590--

From dev-return-9456-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 07:45:29 2014
Return-Path: <dev-return-9456-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 03E97112B7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 07:45:29 +0000 (UTC)
Received: (qmail 20019 invoked by uid 500); 15 Sep 2014 07:45:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19952 invoked by uid 500); 15 Sep 2014 07:45:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19941 invoked by uid 99); 15 Sep 2014 07:45:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 07:45:26 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 07:45:00 +0000
Received: by mail-qg0-f52.google.com with SMTP id i50so3514861qgf.39
        for <dev@spark.apache.org>; Mon, 15 Sep 2014 00:44:59 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=2jAI4LUBNxmbGlSnJXW/Pi6RkGsIyqiW/DzqMIYWw9Y=;
        b=M3s+TsgXlzXkKdXPPkWplbv5w5GtUzYdy3mHDwrE+/kh7G4ZGW6iu2P0a6fIp2XTiL
         DbWPHPJ1ykB9Duj6YcZJuKOQ1vy1XbGfiIIMkLozTfNc9QngoEBRsT3f46E/54zXCV4o
         R0W6ndbOvMbX/CuOpctAx1bJDMoDqwaFV7OqcvKNOuUDRd6I/nLjs6KuLM9GqNwQqD4a
         qnEyt/2KGXiYOxOXSxEQP9Blh4UNe3UuBY27SYdNV7abJO9gJvD7QWcBqTWhZ5zlRXxX
         zj6yAQcRJL3DkKIMG32uklYsRB43PH5p88jEOdNuJorbahCZsOw268t4vOVK3jh9ufw4
         a89A==
X-Gm-Message-State: ALoCoQnOoLioDMOCirms4W4M//ZS4XNZJnoQwolYyfeDfQ2iB0jUc9SlKg9EliyXziQ7ul+h6DRj
X-Received: by 10.224.114.136 with SMTP id e8mr32477209qaq.67.1410767099056;
 Mon, 15 Sep 2014 00:44:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Mon, 15 Sep 2014 00:44:38 -0700 (PDT)
In-Reply-To: <CAMrx5Dy+JFJCbK+yg94wCiH2_LNobkasNuiT97MjimmfGyxa-w@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
 <CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
 <CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
 <CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
 <CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
 <CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
 <703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
 <CABPQxsuJfL9PUYEKsaE=9YyaTfiB5Y5SbR8mAsLnWY1B9YCC+Q@mail.gmail.com> <CAMrx5Dy+JFJCbK+yg94wCiH2_LNobkasNuiT97MjimmfGyxa-w@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 15 Sep 2014 00:44:38 -0700
Message-ID: <CAPh_B=bW-YvL+UTkN1SWv6VbscKpB-VhWuzxVVGvvm=AejnRAA@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Erik Erlandson <eje@redhat.com>, Xiangrui Meng <mengxr@gmail.com>, 
	Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: multipart/alternative; boundary=047d7bea3b74cce920050315cf99
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea3b74cce920050315cf99
Content-Type: text/plain; charset=UTF-8

Hi Egor,

Thanks for the suggestion. It is definitely our intention and practice to
post design docs as soon as they are ready, and short iteration cycles. As
a matter of fact, we encourage design docs for major features posted before
implementation starts, and WIP pull requests before they are fully baked
for large features.

That said, no, not 100% of a committer's time is on a specific ticket.
There are lots of tickets that are open for a long time before somebody
starts actively working on it. So no, it is not true that "all this time
was active development". Xiangrui should post the design doc as soon as it
is ready for feedback.



On Sun, Sep 14, 2014 at 11:26 PM, Egor Pahomov <pahomov.egor@gmail.com>
wrote:

> It's good, that databricks working on this issue! However current process
> of working on that is not very clear for outsider.
>
>    - Last update on this ticket is August 5. If all this time was active
>    development, I have concerns that without feedback from community for such
>    long time development can fall in wrong way.
>    - Even if it would be great big patch as soon as you introduce new
>    interfaces to community it would allow us to start working on our pipeline
>    code. It would allow us write algorithm in new paradigm instead of in lack
>    of any paradigms like it was before. It would allow us to help you transfer
>    old code to new paradigm.
>
> My main point - shorter iterations with more transparency.
>
> I think it would be good idea to create some pull request with code, which
> you have so far, even if it doesn't pass tests, so just we can comment on
> it before formulating it in design doc.
>
>
> 2014-09-13 0:00 GMT+04:00 Patrick Wendell <pwendell@gmail.com>:
>
>> We typically post design docs on JIRA's before major work starts. For
>> instance, pretty sure SPARk-1856 will have a design doc posted
>> shortly.
>>
>> On Fri, Sep 12, 2014 at 12:10 PM, Erik Erlandson <eje@redhat.com> wrote:
>> >
>> > Are interface designs being captured anywhere as documents that the
>> community can follow along with as the proposals evolve?
>> >
>> > I've worked on other open source projects where design docs were
>> published as "living documents" (e.g. on google docs, or etherpad, but the
>> particular mechanism isn't crucial).   FWIW, I found that to be a good way
>> to work in a community environment.
>> >
>> >
>> > ----- Original Message -----
>> >> Hi Egor,
>> >>
>> >> Thanks for the feedback! We are aware of some of the issues you
>> >> mentioned and there are JIRAs created for them. Specifically, I'm
>> >> pushing out the design on pipeline features and algorithm/model
>> >> parameters this week. We can move our discussion to
>> >> https://issues.apache.org/jira/browse/SPARK-1856 .
>> >>
>> >> It would be nice to make tests against interfaces. But it definitely
>> >> needs more discussion before making PRs. For example, we discussed the
>> >> learning interfaces in Christoph's PR
>> >> (https://github.com/apache/spark/pull/2137/) but it takes time to
>> >> reach a consensus, especially on interfaces. Hopefully all of us could
>> >> benefit from the discussion. The best practice is to break down the
>> >> proposal into small independent piece and discuss them on the JIRA
>> >> before submitting PRs.
>> >>
>> >> For performance tests, there is a spark-perf package
>> >> (https://github.com/databricks/spark-perf) and we added performance
>> >> tests for MLlib in v1.1. But definitely more work needs to be done.
>> >>
>> >> The dev-list may not be a good place for discussion on the design,
>> >> could you create JIRAs for each of the issues you pointed out, and we
>> >> track the discussion on JIRA? Thanks!
>> >>
>> >> Best,
>> >> Xiangrui
>> >>
>> >> On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com>
>> wrote:
>> >> > Xiangrui can comment more, but I believe Joseph and him are actually
>> >> > working on standardize interface and pipeline feature for 1.2
>> release.
>> >> >
>> >> > On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov <
>> pahomov.egor@gmail.com>
>> >> > wrote:
>> >> >
>> >> >> Some architect suggestions on this matter -
>> >> >> https://github.com/apache/spark/pull/2371
>> >> >>
>> >> >> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>> >> >>
>> >> >> > Sorry, I misswrote  - I meant learners part of framework - models
>> >> >> > already
>> >> >> > exists.
>> >> >> >
>> >> >> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
>> >> >> > christoph.sawade@googlemail.com>:
>> >> >> >
>> >> >> >> I totally agree, and we discovered also some drawbacks with the
>> >> >> >> classification models implementation that are based on GLMs:
>> >> >> >>
>> >> >> >> - There is no distinction between predicting scores, classes, and
>> >> >> >> calibrated scores (probabilities). For these models it is common
>> to
>> >> >> >> have
>> >> >> >> access to all of them and the prediction function
>> ``predict``should be
>> >> >> >> consistent and stateless. Currently, the score is only available
>> after
>> >> >> >> removing the threshold from the model.
>> >> >> >> - There is no distinction between multinomial and binomial
>> >> >> >> classification. For multinomial problems, it is necessary to
>> handle
>> >> >> >> multiple weight vectors and multiple confidences.
>> >> >> >> - Models are not serialisable, which makes it hard to use them in
>> >> >> >> practise.
>> >> >> >>
>> >> >> >> I started a pull request [1] some time ago. I would be happy to
>> >> >> >> continue
>> >> >> >> the discussion and clarify the interfaces, too!
>> >> >> >>
>> >> >> >> Cheers, Christoph
>> >> >> >>
>> >> >> >> [1] https://github.com/apache/spark/pull/2137/
>> >> >> >>
>> >> >> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov <pahomov.egor@gmail.com
>> >:
>> >> >> >>
>> >> >> >>> Here in Yandex, during implementation of gradient boosting in
>> spark
>> >> >> >>> and
>> >> >> >>> creating our ML tool for internal use, we found next serious
>> problems
>> >> >> in
>> >> >> >>> MLLib:
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>    - There is no Regression/Classification model abstraction.
>> We were
>> >> >> >>>    building abstract data processing pipelines, which should
>> work just
>> >> >> >>> with
>> >> >> >>>    some regression - exact algorithm specified outside this
>> code.
>> >> >> >>>    There
>> >> >> >>> is no
>> >> >> >>>    abstraction, which will allow me to do that. *(It's main
>> reason for
>> >> >> >>> all
>> >> >> >>>    further problems) *
>> >> >> >>>    - There is no common practice among MLlib for testing
>> algorithms:
>> >> >> >>> every
>> >> >> >>>    model generates it's own random test data. There is no easy
>> >> >> >>> extractable
>> >> >> >>>    test cases applible to another algorithm. There is no
>> benchmarks
>> >> >> >>>    for
>> >> >> >>>    comparing algorithms. After implementing new algorithm it's
>> very
>> >> >> hard
>> >> >> >>> to
>> >> >> >>>    understand how it should be tested.
>> >> >> >>>    - Lack of serialization testing: MLlib algorithms don't
>> contain
>> >> >> tests
>> >> >> >>>    which test that model work after serialization.
>> >> >> >>>    - During implementation of new algorithm it's hard to
>> understand
>> >> >> what
>> >> >> >>>    API you should create and which interface to implement.
>> >> >> >>>
>> >> >> >>> Start for solving all these problems must be done in creating
>> common
>> >> >> >>> interface for typical algorithms/models - regression,
>> classification,
>> >> >> >>> clustering, collaborative filtering.
>> >> >> >>>
>> >> >> >>> All main tests should be written against these interfaces, so
>> when new
>> >> >> >>> algorithm implemented - all it should do is passed already
>> written
>> >> >> tests.
>> >> >> >>> It allow us to have managble quality among all lib.
>> >> >> >>>
>> >> >> >>> There should be couple benchmarks which allow new spark user to
>> get
>> >> >> >>> feeling
>> >> >> >>> about which algorithm to use.
>> >> >> >>>
>> >> >> >>> Test set against these abstractions should contain
>> serialization test.
>> >> >> In
>> >> >> >>> production most time there is no need in model, which can't be
>> stored.
>> >> >> >>>
>> >> >> >>> As the first step of this roadmap I'd like to create trait
>> >> >> >>> RegressionModel,
>> >> >> >>> *ADD* methods to current algorithms to implement this trait and
>> create
>> >> >> >>> some
>> >> >> >>> tests against it. Planning of doing it next week.
>> >> >> >>>
>> >> >> >>> Purpose of this letter is to collect any objections to this
>> approach
>> >> >> >>> on
>> >> >> >>> early stage: please give any feedback. Second reason is to set
>> lock on
>> >> >> >>> this
>> >> >> >>> activity so we wouldn't do the same thing twice: I'll create
>> pull
>> >> >> request
>> >> >> >>> by the end of the next week and any parallalizm in development
>> we can
>> >> >> >>> start
>> >> >> >>> from there.
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> --
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >> >> >>>
>> >> >> >>
>> >> >> >>
>> >> >> >
>> >> >> >
>> >> >> > --
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >> >> >
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >>
>> >> >>
>> >> >>
>> >> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >> >>
>> >>
>> >> ---------------------------------------------------------------------
>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>> >>
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>>
>
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--047d7bea3b74cce920050315cf99--

From dev-return-9457-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 13:44:54 2014
Return-Path: <dev-return-9457-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3B4E911CFA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 13:44:54 +0000 (UTC)
Received: (qmail 33485 invoked by uid 500); 15 Sep 2014 13:44:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33414 invoked by uid 500); 15 Sep 2014 13:44:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33395 invoked by uid 99); 15 Sep 2014 13:44:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 13:44:52 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tgraves_cs@yahoo.com designates 98.139.213.126 as permitted sender)
Received: from [98.139.213.126] (HELO nm30-vm0.bullet.mail.bf1.yahoo.com) (98.139.213.126)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 13:44:45 +0000
Received: from [98.139.212.152] by nm30.bullet.mail.bf1.yahoo.com with NNFMP; 15 Sep 2014 13:44:24 -0000
Received: from [98.139.212.201] by tm9.bullet.mail.bf1.yahoo.com with NNFMP; 15 Sep 2014 13:44:24 -0000
Received: from [127.0.0.1] by omp1010.mail.bf1.yahoo.com with NNFMP; 15 Sep 2014 13:44:24 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 470189.93152.bm@omp1010.mail.bf1.yahoo.com
Received: (qmail 76227 invoked by uid 60001); 15 Sep 2014 13:44:24 -0000
X-YMail-OSG: DmN8zmUVM1n9mNE6YA7i0xLeKxDN9PLvoEFhDixblpDv5En
 39L4PPEhFD4fIyFnf2pdvlMeVJS4e2Ovr7XZBOcf9C6sLgec_CjNMCD767qY
 AYDKQeYKZeWYvbIyf3HEpKC8RolCvP9LynwLcJl.uT96u3HJ0BfvHXYMSPSy
 RP0lohRgb4DCZ0ZLocj_oxR9UKOKy77jSXy2lPajnKzwWM_6nIVLp0LKzGLB
 XulkP8.e9MuV80s6wF7TQ55lSrTXSnMaXK51CcP8kMDrKHe1Zk1bQogJmcxT
 lmscGiu71EOlfP6X99ARx0.h2EQUnqA0X925fwiAn6YP2Bp1uaqzVqAPZqDe
 zG141wqf.X7L40ckrrqyolRve15FMg5dpi1SrSk.5T9S2kMivHp3DXZrF5ws
 XeVJ2EjZcuRI3ilPVBIAd9y0xd24ozJzWYgxuBRIxy6n4hqmmkF4__B6Rz7A
 GFLuYMiYfPeCjPpuK26y9XCbY88iRx91k.6AGxCHSCgr5DSBJtXTrF7W.OjB
 dluXdNkYvT6bVTs4QJxM1VZV0oqJCmJFE7Ffjp69fzsmmEk3iQTQYpJhZdPe
 NyQ--
Received: from [209.131.52.50] by web140101.mail.bf1.yahoo.com via HTTP; Mon, 15 Sep 2014 06:44:24 PDT
X-Rocket-MIMEInfo: 002.001,U3BhcmsgYXV0aGVudGljYXRpb24gZG9lcyB3b3JrIGluIHN0YW5kYWxvbmUgbW9kZSAoYXRsZWFzdCBpdCBkaWQsIEkgaGF2ZW4ndCB0ZXN0ZWQgaXQgaW4gYSB3aGlsZSkuIFRoZSBzYW1lIHNoYXJlZCBzZWNyZXQgaGFzIHRvIGJlIHNldCBvbiBhbGwgdGhlIGRhZW1vbnMgKG1hc3RlciBhbmQgd29ya2VycykgYW5kIHRoZW4gYWxzbyBpbiB0aGUgY29uZmlncyBvZiBhbnkgYXBwbGljYXRpb25zIHN1Ym1pdHRlZC4gIFNpbmNlIGV2ZXJ5b25lIHNoYXJlcyB0aGUgc2FtZSBzZWNyZXQgaXRzIGJ5IG5vIG1lYW4BMAEBAQE-
X-Mailer: YahooMailWebService/0.8.203.696
References: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
Message-ID: <1410788664.95241.YahooMailNeo@web140101.mail.bf1.yahoo.com>
Date: Mon, 15 Sep 2014 06:44:24 -0700
From: Tom Graves <tgraves_cs@yahoo.com.INVALID>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
Subject: Re: Spark authenticate enablement
To: Jun Feng Liu <liujunf@cn.ibm.com>,
  "dev@spark.apache.org" <dev@spark.apache.org>
In-Reply-To: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="584511794-2037877177-1410788664=:95241"
X-Virus-Checked: Checked by ClamAV on apache.org

--584511794-2037877177-1410788664=:95241
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Spark authentication does work in standalone mode (atleast it did, I haven'=
t tested it in a while). The same shared secret has to be set on all the da=
emons (master and workers) and then also in the configs of any applications=
 submitted.  Since everyone shares the same secret its by no means ideal or=
 a strong authentication.=0A=0ATom=0A=0A=0AOn Thursday, September 11, 2014 =
4:17 AM, Jun Feng Liu <liujunf@cn.ibm.com> wrote:=0A =0A=0A=0AHi, there =0A=
=0AI am trying to enable the authentication=0Aon spark on standealone model=
. Seems like only SparkSubmit load the properties=0Afrom spark-defaults.con=
f.  org.apache.spark.deploy.master.Master dose=0Anot really load the defaul=
t setting from spark-defaults.conf.  =0A=0ADose it mean the spark authentic=
ation=0Aonly work for like YARN model? Or I missed something with standalon=
e model.=0A =0ABest Regards =0A  =0AJun Feng Liu=0AIBM China Systems & Tech=
nology Laboratory in Beijing =0A=0A________________________________=0A =0A =
 Phone: 86-10-82452683 =0AE-mail:liujunf@cn.ibm.com  =0A=0ABLD 28,ZGC Softw=
are Park =0ANo.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193 =0AChin=
a  
--584511794-2037877177-1410788664=:95241--

From dev-return-9458-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 16:00:42 2014
Return-Path: <dev-return-9458-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3150D11183
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 16:00:42 +0000 (UTC)
Received: (qmail 48927 invoked by uid 500); 15 Sep 2014 16:00:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48863 invoked by uid 500); 15 Sep 2014 16:00:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48849 invoked by uid 99); 15 Sep 2014 16:00:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 16:00:40 +0000
X-ASF-Spam-Status: No, hits=3.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.170] (HELO mail-vc0-f170.google.com) (209.85.220.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 16:00:12 +0000
Received: by mail-vc0-f170.google.com with SMTP id hy4so3648588vcb.29
        for <dev@spark.incubator.apache.org>; Mon, 15 Sep 2014 09:00:10 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=rNAa56dTCKmzeT0Pj2xsEVdbIhCk0ERQD984hZd+j7Q=;
        b=PEpGQZPEm6PReJBaifHQrwWWBLizS5ov4vFU05jXtVnALYZ1dXG0i1OtE9LDO9+cRz
         aF2wZDmdxacRG0CwrqGxlbzap0iyrJUo78bL7MD1bPpbGsDaM5zNLA9fkNkZEIFo9LSE
         kaGsu9s+gl1i0ZQiCMDl4SqCq1UbT2rNzZvq80RH5aPJeQJHwxoCj5eCwxfEclpcvaYd
         nAIqWq+wzrgvrUnWFHmcDsLQp9dXXP8AIJ4lYFm+mvutFF3TZvquJYmWksGJo4IOayMN
         kSluLboS5NjIOiLOmKtQW5ZMPsx2hKPqJzUYd5oUYKhi9a0QGECE6HGYC/vnGh8TJn1C
         k3Uw==
X-Gm-Message-State: ALoCoQlcKi2itOvrosNMaXj6CdUHqZ+5vYhArfiA+y7v6XtgWoNANSxasE/1PMY8RAZqNrrkBZ6c
X-Received: by 10.52.51.203 with SMTP id m11mr1841461vdo.72.1410796810471;
        Mon, 15 Sep 2014 09:00:10 -0700 (PDT)
Received: from mail-vc0-f178.google.com (mail-vc0-f178.google.com [209.85.220.178])
        by mx.google.com with ESMTPSA id vm20sm3560286vdb.21.2014.09.15.09.00.09
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 15 Sep 2014 09:00:09 -0700 (PDT)
Received: by mail-vc0-f178.google.com with SMTP id hy4so3551822vcb.23
        for <dev@spark.incubator.apache.org>; Mon, 15 Sep 2014 09:00:08 -0700 (PDT)
X-Received: by 10.52.227.72 with SMTP id ry8mr3339019vdc.64.1410796808818;
 Mon, 15 Sep 2014 09:00:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.17.197 with HTTP; Mon, 15 Sep 2014 08:59:48 -0700 (PDT)
In-Reply-To: <1408655692487-7944.post@n3.nabble.com>
References: <1408655692487-7944.post@n3.nabble.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Mon, 15 Sep 2014 08:59:48 -0700
Message-ID: <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
Subject: Re: PARSING_ERROR from kryo
To: npanj <nitinpanj@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e011765b9a3db2405031cba34
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011765b9a3db2405031cba34
Content-Type: text/plain; charset=UTF-8

Hi npanj,

I'm seeing the same exception now on the Spark 1.1.0 release.  Did you ever
get this figured out?

Andrew

On Thu, Aug 21, 2014 at 2:14 PM, npanj <nitinpanj@gmail.com> wrote:

> Hi All,
>
> I am getting PARSING_ERROR while running my job on the code checked out up
> to commit# db56f2df1b8027171da1b8d2571d1f2ef1e103b6. I am running this job
> on EC2.
>
> Any idea if there is something wrong with my config?
>
> Here is my config:
> --
>     .set("spark.executor.extraJavaOptions", "-XX:+UseCompressedOops
> -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps")
>       .set("spark.storage.memoryFraction", "0.2")
>       .set("spark.serializer",
> "org.apache.spark.serializer.KryoSerializer")
>       .set("spark.kryo.registrator",
> "org.apache.spark.graphx.GraphKryoRegistrator")
>       .set("spark.akka.frameSize", "20")
>       .set("spark.akka.timeout", "300")
>       .set("spark.shuffle.memoryFraction", "0.5")
>       .set("spark.core.connection.ack.wait.timeout", "1800")
> --
>
>
>
> --
> Job aborted due to stage failure: Task 947 in stage 11.0 failed 4 times,
> most recent failure: Lost task 947.3 in stage 11.0 (TID 12750,
> ip-10-167-149-118.ec2.internal): com.esotericsoftware.kryo.KryoException:
> java.io.IOException: failed to uncompress the chunk: PARSING_ERROR(2)
> Serialization trace:
> vids (org.apache.spark.graphx.impl.VertexAttributeBlock)
>         com.esotericsoftware.kryo.io.Input.fill(Input.java:142)
>         com.esotericsoftware.kryo.io.Input.require(Input.java:169)
>         com.esotericsoftware.kryo.io.Input.readLong_slow(Input.java:719)
>         com.esotericsoftware.kryo.io.Input.readLong(Input.java:665)
>
>
> com.esotericsoftware.kryo.serializers.DefaultArraySerializers$LongArraySerializer.read(DefaultArraySerializers.java:127)
>
>
> com.esotericsoftware.kryo.serializers.DefaultArraySerializers$LongArraySerializer.read(DefaultArraySerializers.java:107)
>         com.esotericsoftware.kryo.Kryo.readObjectOrNull(Kryo.java:699)
>
>
> com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:611)
>
>
> com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)
>         com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
>         com.twitter.chill.Tuple2Serializer.read(TupleSerializers.scala:43)
>         com.twitter.chill.Tuple2Serializer.read(TupleSerializers.scala:34)
>         com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)
>
>
> org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:119)
>
>
> org.apache.spark.serializer.DeserializationStream$$anon$1.getNext(Serializer.scala:129)
>         org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:71)
>
>
> org.apache.spark.storage.BlockManager$LazyProxyIterator$1.hasNext(BlockManager.scala:1038)
>         scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>
>
> org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
>
>
> org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
>         scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>         scala.collection.Iterator$class.foreach(Iterator.scala:727)
>         scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
>
>
> org.apache.spark.graphx.impl.VertexPartitionBaseOps.innerJoinKeepLeft(VertexPartitionBaseOps.scala:192)
>
>
> org.apache.spark.graphx.impl.EdgePartition.updateVertices(EdgePartition.scala:78)
>
>
> org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:75)
>
>
> org.apache.spark.graphx.impl.ReplicatedVertexView$$anonfun$2$$anonfun$apply$1.apply(ReplicatedVertexView.scala:73)
>         scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
>         scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>         scala.collection.Iterator$class.foreach(Iterator.scala:727)
>         scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
>
>
> org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
>
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
>
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
>         org.apache.spark.scheduler.Task.run(Task.scala:51)
>
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:189)
>
>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>
>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>         java.lang.Thread.run(Thread.java:745)
> --
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/PARSING-ERROR-from-kryo-tp7944.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e011765b9a3db2405031cba34--

From dev-return-9459-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 21:11:25 2014
Return-Path: <dev-return-9459-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F141811FB0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 21:11:24 +0000 (UTC)
Received: (qmail 78321 invoked by uid 500); 15 Sep 2014 21:11:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78249 invoked by uid 500); 15 Sep 2014 21:11:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78232 invoked by uid 99); 15 Sep 2014 21:11:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 21:11:23 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ankurdave@gmail.com designates 209.85.220.53 as permitted sender)
Received: from [209.85.220.53] (HELO mail-pa0-f53.google.com) (209.85.220.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 21:10:57 +0000
Received: by mail-pa0-f53.google.com with SMTP id rd3so7162839pab.26
        for <dev@spark.incubator.apache.org>; Mon, 15 Sep 2014 14:10:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:to:cc:subject:in-reply-to:references:user-agent:date
         :message-id:mime-version:content-type;
        bh=VXowxFQYXUCgOCAo0A7khNm0VfzDRe3kRocVQcvPR6E=;
        b=1HFKvwfi4ZDiVfQnoxnAp0g4aNxybE5FwdSsE4+feySjgpZH152sXlDi2awjS7V0m6
         P1fHrHC1i/Cim+rkJgStvcuA3Ou03psx7j4btXWIG7vHr17Bp7hezUhwDTBKLBlSq4F/
         fQcdu4oXrbE4WoYk/gKGDA3I9n7Hz9CFYARut/69yyP3+WZWoFoJxwvCkX9LD95YSndi
         7tY1jfjbry1oZRDeXtizfO/6rWtvzzWRGT1LlHiMauyZU647P9bqGeCLdch6IpIKA47B
         tZdNfaSmCZtue97lw4PwZbc3zaEXN30kU4AWrgexAyg3PxuGG25DvZfst/qxgHa5I/c0
         SUtA==
X-Received: by 10.70.98.176 with SMTP id ej16mr10522213pdb.165.1410815455448;
        Mon, 15 Sep 2014 14:10:55 -0700 (PDT)
Received: from ankur-mbp-2 (c-67-164-94-63.hsd1.ca.comcast.net. [67.164.94.63])
        by mx.google.com with ESMTPSA id dg9sm511896pdb.50.2014.09.15.14.10.54
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 15 Sep 2014 14:10:54 -0700 (PDT)
From: Ankur Dave <ankurdave@gmail.com>
To: Andrew Ash <andrew@andrewash.com>, npanj <nitinpanj@gmail.com>
Cc: "dev\@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: Re: PARSING_ERROR from kryo
In-Reply-To: <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
References: <1408655692487-7944.post@n3.nabble.com> <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
User-Agent: Notmuch/0.18.1 (http://notmuchmail.org) Emacs/24.4.50.1 (x86_64-apple-darwin13.2.0)
Date: Mon, 15 Sep 2014 14:10:52 -0700
Message-ID: <m2egvczj1f.fsf@gmail.com>
MIME-Version: 1.0
Content-Type: text/plain
X-Virus-Checked: Checked by ClamAV on apache.org

At 2014-09-15 08:59:48 -0700, Andrew Ash <andrew@andrewash.com> wrote:
> I'm seeing the same exception now on the Spark 1.1.0 release.  Did you ever
> get this figured out?
>
> [...]
>
> On Thu, Aug 21, 2014 at 2:14 PM, npanj <nitinpanj@gmail.com> wrote:
>> I am getting PARSING_ERROR while running my job on the code checked out up
>> to commit# db56f2df1b8027171da1b8d2571d1f2ef1e103b6.

The error is because I merged a GraphX PR that introduced a nondeterministic bug [1]. I reverted the faulty PR, but it was too late for the 1.1.0 release. The problem should go away if you use branch-1.1 or master. Sorry about that...

Ankur

[1] https://issues.apache.org/jira/browse/SPARK-3400

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9460-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 22:22:20 2014
Return-Path: <dev-return-9460-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DB0A611296
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 22:22:20 +0000 (UTC)
Received: (qmail 75881 invoked by uid 500); 15 Sep 2014 22:22:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75780 invoked by uid 500); 15 Sep 2014 22:22:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75768 invoked by uid 99); 15 Sep 2014 22:22:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 22:22:19 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rarecactus@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 22:22:15 +0000
Received: by mail-wg0-f45.google.com with SMTP id z12so4668653wgg.16
        for <dev@spark.apache.org>; Mon, 15 Sep 2014 15:21:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=fLpEp+oAhA+LwB6mmYmmaSe9KDPgBH8q14gA8fniN3E=;
        b=Ss89ReXODc6p/hBK3aK9xV4X5cOrGlZFwjqtzGKF5iAANyGbD9Gj2UsFVZS67JRoUa
         3Tz+zECmaqztzTYiEU+3llIkaW3aMs63B3yrqECUphTZHevBjZDL59Vdfnl2cgtQm8Vs
         9LTm+lmjHn3HBrFSkQY7f8pjwVrWKHMr+OrAQEeBS+9nBG8KaS5jVEP00Gpj/fJr0yhb
         ZEm5x+PJmi1Cu/ukA5LrAWVwfpugxab/Ok14rHVkNjxaVZ181+DL3qglAiBPxsG+b+tx
         f7gDdz9GNwRnPk43/LRBOb4/vs5MY/5iDrv1QjB5EI4fGKlLklNYtBM1ylL55507GT3F
         oK7w==
MIME-Version: 1.0
X-Received: by 10.194.173.234 with SMTP id bn10mr37834653wjc.81.1410819713936;
 Mon, 15 Sep 2014 15:21:53 -0700 (PDT)
Sender: rarecactus@gmail.com
Received: by 10.194.28.6 with HTTP; Mon, 15 Sep 2014 15:21:53 -0700 (PDT)
In-Reply-To: <CAGOvqio9vdiDApeV=XshexXtCnkwbBbBZPeCeAo2EaOhFNMGng@mail.gmail.com>
References: <CAGOvqipJEM=biUE5W7r_f+2q5CTh_Ndnq=PE3rHfVMruBWN05g@mail.gmail.com>
	<CAGOvqio9vdiDApeV=XshexXtCnkwbBbBZPeCeAo2EaOhFNMGng@mail.gmail.com>
Date: Mon, 15 Sep 2014 15:21:53 -0700
X-Google-Sender-Auth: HMdxlh4CbX_LQzj9nq2awYv7oag
Message-ID: <CA+qbEUMCxz5usbOm4QoOkvznTotXA7mxBM2a0utkdt=eh2SeBw@mail.gmail.com>
Subject: Re: CoHadoop Papers
From: Colin McCabe <cmccabe@alumni.cmu.edu>
To: Gary Malouf <malouf.gary@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

This feature is called "block affinity groups" and it's been under
discussion for a while, but isn't fully implemented yet.  HDFS-2576 is
not a complete solution because it doesn't change the way the balancer
works, just the initial placement of blocks.  Once heterogeneous
storage management (HDFS-2832) is implemented, you will be able to get
a similar effect through using separate storages, at the cost of
fragmenting the backing store somewhat.

Of course, "co-locating related data blocks" is often bad, not good,
because it reduces the amount of parallelism a single job can exploit,
and can increase the chance of losing an entire dataset due to node
failures.  That's one reason why the current semi-random placement
strategy has lasted so long.  In other words, this is
workload-dependent.

best,
Colin

On Tue, Aug 26, 2014 at 5:20 AM, Gary Malouf <malouf.gary@gmail.com> wrote:
> It appears support for this type of control over block placement is going
> out in the next version of HDFS:
> https://issues.apache.org/jira/browse/HDFS-2576
>
>
> On Tue, Aug 26, 2014 at 7:43 AM, Gary Malouf <malouf.gary@gmail.com> wrote:
>
>> One of my colleagues has been questioning me as to why Spark/HDFS makes no
>> attempts to try to co-locate related data blocks.  He pointed to this
>> paper: http://www.vldb.org/pvldb/vol4/p575-eltabakh.pdf from 2011 on the
>> CoHadoop research and the performance improvements it yielded for
>> Map/Reduce jobs.
>>
>> Would leveraging these ideas for writing data from Spark make sense/be
>> worthwhile?
>>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9461-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 22:32:02 2014
Return-Path: <dev-return-9461-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2DE0911303
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 22:32:02 +0000 (UTC)
Received: (qmail 13342 invoked by uid 500); 15 Sep 2014 22:32:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13267 invoked by uid 500); 15 Sep 2014 22:32:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13204 invoked by uid 99); 15 Sep 2014 22:32:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 22:32:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.220.175] (HELO mail-vc0-f175.google.com) (209.85.220.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 22:31:55 +0000
Received: by mail-vc0-f175.google.com with SMTP id hq11so4128825vcb.34
        for <dev@spark.incubator.apache.org>; Mon, 15 Sep 2014 15:31:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=H4yz1d2HqCFP7q00aGGCuUFhcK78IFKXNliEi5kVSjU=;
        b=k5ZTO7G38R3K0mbJ5+A67IH8mIyzsytPXvJ60ZJlt1dCXUyf5VR985mHigvqMe+PKG
         NVy7EMPiufkYvbfJbM72lgNlKBcedvoidGW2IDjtgVVz8IXAajNR1DIXIcrpjEBlfTns
         BQxu+X5LrdSzkcF+vpd8OTlp0dDBR7buELr0A982Hm8ssoDO+k4CafU9jA2xUH/V040B
         yWn9KIhclb9necougE1l+lclpH6JPBN3fK7dKaWQgZYhaRbhUjR9INAmoZVaccsT3Kib
         hJ9n6dLoitnZyCoaqlI/QdSdGIZhDWX3W8F2KEjTMgOBE6MlQUgij5HNp4P2BKjg64Xi
         QxmQ==
X-Gm-Message-State: ALoCoQlbdy+X9Xy3p0tRQyY7lRgdQKAoIIx729Wlfvb/42YXoGAZKCaD2BYQlKytrbEfiF24v6CD
X-Received: by 10.52.137.51 with SMTP id qf19mr2649342vdb.97.1410820294736;
        Mon, 15 Sep 2014 15:31:34 -0700 (PDT)
Received: from mail-vc0-f172.google.com (mail-vc0-f172.google.com [209.85.220.172])
        by mx.google.com with ESMTPSA id vi19sm3767452vdb.16.2014.09.15.15.31.33
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 15 Sep 2014 15:31:33 -0700 (PDT)
Received: by mail-vc0-f172.google.com with SMTP id hy10so4136692vcb.17
        for <dev@spark.incubator.apache.org>; Mon, 15 Sep 2014 15:31:33 -0700 (PDT)
X-Received: by 10.52.38.134 with SMTP id g6mr21815300vdk.34.1410820293243;
 Mon, 15 Sep 2014 15:31:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.17.197 with HTTP; Mon, 15 Sep 2014 15:31:13 -0700 (PDT)
In-Reply-To: <m2egvczj1f.fsf@gmail.com>
References: <1408655692487-7944.post@n3.nabble.com> <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
 <m2egvczj1f.fsf@gmail.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Mon, 15 Sep 2014 15:31:13 -0700
Message-ID: <CA+-p3AFdBF02nRpaTtki8dcNku8vxsDG1GLhA3XL4Lo-=U2zsA@mail.gmail.com>
Subject: Re: PARSING_ERROR from kryo
To: Ankur Dave <ankurdave@gmail.com>
Cc: npanj <nitinpanj@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51d282a6bbd66050322321b
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51d282a6bbd66050322321b
Content-Type: text/plain; charset=UTF-8

I should clarify: I'm not using GraphX, it's a different
application-specific Kryo registrator that causes the same stacktrace
ending in PARSING_ERROR:

com.esotericsoftware.kryo.KryoException: java.io.IOException: failed to
uncompress the chunk: PARSING_ERROR(2)
com.esotericsoftware.kryo.io.Input.fill(Input.java:142)
com.esotericsoftware.kryo.io.Input.require(Input.java:169)
com.esotericsoftware.kryo.io.Input.readInt(Input.java:325)
com.esotericsoftware.kryo.io.Input.readFloat(Input.java:624)
com.esotericsoftware.kryo.serializers.DefaultSerializers$FloatSerializer.read(DefaultSerializers.java:127)
com.esotericsoftware.kryo.serializers.DefaultSerializers$FloatSerializer.read(DefaultSerializers.java:117)
com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:732)
com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:109)
com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:18)
com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:732)
... my registrator


Ankur from my read of the ticket there's not a root cause identified for
those PARSING_ERROR exceptions in GraphX yet?


Andrew

On Mon, Sep 15, 2014 at 2:10 PM, Ankur Dave <ankurdave@gmail.com> wrote:

> At 2014-09-15 08:59:48 -0700, Andrew Ash <andrew@andrewash.com> wrote:
> > I'm seeing the same exception now on the Spark 1.1.0 release.  Did you
> ever
> > get this figured out?
> >
> > [...]
> >
> > On Thu, Aug 21, 2014 at 2:14 PM, npanj <nitinpanj@gmail.com> wrote:
> >> I am getting PARSING_ERROR while running my job on the code checked out
> up
> >> to commit# db56f2df1b8027171da1b8d2571d1f2ef1e103b6.
>
> The error is because I merged a GraphX PR that introduced a
> nondeterministic bug [1]. I reverted the faulty PR, but it was too late for
> the 1.1.0 release. The problem should go away if you use branch-1.1 or
> master. Sorry about that...
>
> Ankur
>
> [1] https://issues.apache.org/jira/browse/SPARK-3400
>

--bcaec51d282a6bbd66050322321b--

From dev-return-9462-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 15 23:23:48 2014
Return-Path: <dev-return-9462-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 992E0115A1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 15 Sep 2014 23:23:48 +0000 (UTC)
Received: (qmail 71824 invoked by uid 500); 15 Sep 2014 23:23:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71748 invoked by uid 500); 15 Sep 2014 23:23:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71737 invoked by uid 99); 15 Sep 2014 23:23:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 23:23:47 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of eerlands@redhat.com designates 209.132.183.24 as permitted sender)
Received: from [209.132.183.24] (HELO mx3-phx2.redhat.com) (209.132.183.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 15 Sep 2014 23:23:41 +0000
Received: from zmail12.collab.prod.int.phx2.redhat.com (zmail12.collab.prod.int.phx2.redhat.com [10.5.83.14])
	by mx3-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s8FNNJf5010687
	for <dev@spark.apache.org>; Mon, 15 Sep 2014 19:23:19 -0400
Date: Mon, 15 Sep 2014 19:23:19 -0400 (EDT)
From: Erik Erlandson <eje@redhat.com>
Reply-To: Erik Erlandson <eje@redhat.com>
To: dev <dev@spark.apache.org>
Message-ID: <1721633581.23081915.1410823399518.JavaMail.zimbra@redhat.com>
In-Reply-To: <868024919.23069341.1410822913019.JavaMail.zimbra@redhat.com>
Subject: why does BernoulliSampler class use a lower and upper bound?
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.7]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - GC36 (Linux)/8.0.6_GA_5922)
Thread-Topic: why does BernoulliSampler class use a lower and upper bound?
Thread-Index: KAgkB7dn/su+W/N4M2Rl/krv3sXZkw==
X-Virus-Checked: Checked by ClamAV on apache.org

I'm climbing under the hood in there for SPARK-3250, and I see this:

override def sample(items: Iterator[T]): Iterator[T] = {
  items.filter { item =>
    val x = rng.nextDouble()
    (x >= lb && x < ub) ^ complement
  }
}


The clause (x >= lb && x < ub) is equivalent to (x < ub-lb), which is faster, and requires only one parameter (sampling fraction).   Any caller asking for BernoulliSampler(a, b) can equally well ask for BernoulliSampler(b-a).

Is there some angle I'm missing?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9463-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 00:14:48 2014
Return-Path: <dev-return-9463-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 88663116FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 00:14:48 +0000 (UTC)
Received: (qmail 98518 invoked by uid 500); 16 Sep 2014 00:14:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98452 invoked by uid 500); 16 Sep 2014 00:14:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98440 invoked by uid 99); 16 Sep 2014 00:14:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 00:14:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 00:14:41 +0000
Received: by mail-qa0-f46.google.com with SMTP id k15so4755508qaq.33
        for <dev@spark.apache.org>; Mon, 15 Sep 2014 17:14:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=jOL0bz3e7u2rMmUKYAhDcF68numcu3MD42qALqlzw2E=;
        b=0ZV6ooxfo9IQAYpJ62+CZ8M2OZsf6lUgM4ZXjPoApHmNQlTmKsxXf4fJTDmc9tzMNo
         hrahIVebAYaBKYz3KIBwcDaqoEU2fyhVQrwytbUXF9M8FfSjrZ3LZpGOg12a2n2+Bfw/
         iG3KDz4y/oxXGzDMVJSUtFwFKka8Ov27aKffOhJC92pGxN3/qJ0v9BUWbgQvfoPH9jmN
         Le7HSDxlYQIVsWe6805uk4YIetDKhUtixH8N2NeOSb4JXpbHdilLzkVEE1XqQrs/97hF
         MWuBDdXjMnRPq+lo0khEwGU5ii19ORl/HE6/p91pFcTTckvqpdVi87JJJ+SIv/Cxtxug
         UgFg==
MIME-Version: 1.0
X-Received: by 10.224.64.201 with SMTP id f9mr42890749qai.64.1410826461011;
 Mon, 15 Sep 2014 17:14:21 -0700 (PDT)
Received: by 10.141.6.194 with HTTP; Mon, 15 Sep 2014 17:14:20 -0700 (PDT)
In-Reply-To: <1721633581.23081915.1410823399518.JavaMail.zimbra@redhat.com>
References: <868024919.23069341.1410822913019.JavaMail.zimbra@redhat.com>
	<1721633581.23081915.1410823399518.JavaMail.zimbra@redhat.com>
Date: Mon, 15 Sep 2014 17:14:20 -0700
Message-ID: <CAJgQjQ9+U_4ZB5SGweMupAXoeBvY8Ak53bRuk_1q6bFavD1nNA@mail.gmail.com>
Subject: Re: why does BernoulliSampler class use a lower and upper bound?
From: Xiangrui Meng <mengxr@gmail.com>
To: Erik Erlandson <eje@redhat.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

It is also used in RDD.randomSplit. -Xiangrui

On Mon, Sep 15, 2014 at 4:23 PM, Erik Erlandson <eje@redhat.com> wrote:
> I'm climbing under the hood in there for SPARK-3250, and I see this:
>
> override def sample(items: Iterator[T]): Iterator[T] = {
>   items.filter { item =>
>     val x = rng.nextDouble()
>     (x >= lb && x < ub) ^ complement
>   }
> }
>
>
> The clause (x >= lb && x < ub) is equivalent to (x < ub-lb), which is faster, and requires only one parameter (sampling fraction).   Any caller asking for BernoulliSampler(a, b) can equally well ask for BernoulliSampler(b-a).
>
> Is there some angle I'm missing?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9464-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 01:49:30 2014
Return-Path: <dev-return-9464-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E40DF119CC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 01:49:29 +0000 (UTC)
Received: (qmail 58153 invoked by uid 500); 16 Sep 2014 01:49:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58079 invoked by uid 500); 16 Sep 2014 01:49:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58064 invoked by uid 99); 16 Sep 2014 01:49:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 01:49:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of otis.gospodnetic@gmail.com designates 209.85.216.169 as permitted sender)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 01:49:03 +0000
Received: by mail-qc0-f169.google.com with SMTP id r5so5276899qcx.0
        for <dev@spark.apache.org>; Mon, 15 Sep 2014 18:49:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=3p7gx9BYsIMRbXpmTFqCZFRazA9s+HMfRvxCgmgPK9E=;
        b=uCXqYYl/MNwYXuCDDXJHTPB/Vylr+Bre+7ItFKTq6OCW5WN0tNbu0anvCciC9sNXNs
         K4nrLbrzEtQ1yMWq+o7ZOZ4BcqORDedPgz/R8DPzCyB30B3Ia3lKF9x2FZlVTnUbw3bR
         a1oPP3nEGLK9lIp8GaeTgX9dhlgENjNsMEU2Wjh/GghFGTv3Bj/OsoArL2KQHPBhgQ2n
         rF+o5mn5P3wXvBWwoNY63pLxMfvmx4Vp9hayxZ9ELYo1ASUdlEaE1pWovISGRhau3C0P
         ADXAzvn3cY5OYSEFoVu60370aDf50Lj47kLTJ9c7SbQQe+tUs7hzq9reGno2r7BX2M5t
         eSyQ==
MIME-Version: 1.0
X-Received: by 10.140.109.75 with SMTP id k69mr17508278qgf.96.1410832142068;
 Mon, 15 Sep 2014 18:49:02 -0700 (PDT)
Received: by 10.229.51.132 with HTTP; Mon, 15 Sep 2014 18:49:02 -0700 (PDT)
Date: Mon, 15 Sep 2014 21:49:02 -0400
Message-ID: <CANNBgPJx2c9JLv5pjyUv22AkHmhsjmAaF8pddpit7JEjynKo4g@mail.gmail.com>
Subject: Wiki page for Operations/Monitoring tools?
From: Otis Gospodnetic <otis.gospodnetic@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139bd02aa7244050324f4bd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139bd02aa7244050324f4bd
Content-Type: text/plain; charset=UTF-8

Hi,

I'm looking for a suitable place on the Wiki to add some info about a Spark
monitoring we've built.  The Wiki looks nice and orderly, so I didn't want
to go in and mess it up without asking where to put such info.  I don't see
an existing "Operations" or "Monitoring" or similar pages.  Should I just
create a Child page under https://cwiki.apache.org/confluence/display/SPARK
?

Thanks,
Otis
--
Monitoring * Alerting * Anomaly Detection * Centralized Log Management
Solr & Elasticsearch Support * http://sematext.com/

--001a1139bd02aa7244050324f4bd--

From dev-return-9465-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 01:57:30 2014
Return-Path: <dev-return-9465-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CB4D8119F7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 01:57:30 +0000 (UTC)
Received: (qmail 70175 invoked by uid 500); 16 Sep 2014 01:57:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70107 invoked by uid 500); 16 Sep 2014 01:57:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70094 invoked by uid 99); 16 Sep 2014 01:57:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 01:57:29 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of nitinpanj@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 01:57:04 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <nitinpanj@gmail.com>)
	id 1XTi0s-0004ut-Ry
	for dev@spark.incubator.apache.org; Mon, 15 Sep 2014 18:57:02 -0700
Date: Mon, 15 Sep 2014 18:57:02 -0700 (PDT)
From: npanj <nitinpanj@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1410832622860-8433.post@n3.nabble.com>
In-Reply-To: <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
References: <1408655692487-7944.post@n3.nabble.com> <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
Subject: Re: PARSING_ERROR from kryo
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Andrew,

No I could not figure out the root cause. This seems to be non-deterministic
error... I didn't see same error after rerunning same program. But I noticed
same error on a different program. 

First I thought that this may be related to SPARK-2878, but @Graham replied
that this looks irrelevant.






--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/PARSING-ERROR-from-kryo-tp7944p8433.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9466-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 05:52:52 2014
Return-Path: <dev-return-9466-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7177E11058
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 05:52:52 +0000 (UTC)
Received: (qmail 12869 invoked by uid 500); 16 Sep 2014 05:52:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12756 invoked by uid 500); 16 Sep 2014 05:52:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11734 invoked by uid 99); 16 Sep 2014 05:52:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 05:52:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.42 as permitted sender)
Received: from [209.85.220.42] (HELO mail-pa0-f42.google.com) (209.85.220.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 05:52:23 +0000
Received: by mail-pa0-f42.google.com with SMTP id lj1so8114762pab.29
        for <multiple recipients>; Mon, 15 Sep 2014 22:52:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=60u+lwCloENiCdPpAd8ywtwYkomS1V6DoWzNcuIwvWQ=;
        b=qnj6+Jxs87CWSVGTW/cGMS9ZCHxq0zqD9huf9XBnco+tf5y0nsKZK5MY16VJ6gUy4z
         ZSBs9VmdfrH1ThxbfrMMofBZqRFMKf7Poekpdm/15jXqqj42S7DKqsfF5pgdMP992Qb0
         lGmYuwrwn80Ic4DR2l0XX7vU5Bu66geHqA64KYleMImBxngsxgBQJ16lJqodAelQ48Je
         qzhv+8ihzrLkbH7toy0/OXN5j4mRTU1Ydc5NOzqZw3EMzFpIM4sjpCtPREyPjBCFfPng
         I5YSAZZxIesSjdFbzpwjicpJe7fLv11eSfXEY5h5sy9c8WtLinuourjuyhHc0Z7IyX8g
         fYAw==
X-Received: by 10.68.201.230 with SMTP id kd6mr24536181pbc.74.1410846741061;
        Mon, 15 Sep 2014 22:52:21 -0700 (PDT)
Received: from mbp-3.local (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id i9sm13044737pbq.17.2014.09.15.22.52.19
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 15 Sep 2014 22:52:20 -0700 (PDT)
Date: Mon, 15 Sep 2014 22:52:18 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Du Li <lidu@yahoo-inc.com>
Cc: "=?utf-8?Q?user=40spark.apache.org?=" <user@spark.apache.org>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.5417d012.71ea1109.59d1@mbp-3.local>
In-Reply-To: <D03D03D5.37BD%lidu@yahoo-inc.com>
References: <D038E23E.36A2%lidu@yahoo-inc.com>
 <etPan.5413c3a3.628c895d.59d1@mbp-3.local>
 <D03D03D5.37BD%lidu@yahoo-inc.com>
Subject: Re: NullWritable not serializable
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5417d012_100f59dc_59d1"
X-Virus-Checked: Checked by ClamAV on apache.org

--5417d012_100f59dc_59d1
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Can you post the exact code for the test that worked in 1.0=3F I can't th=
ink of much that could've changed. The one possibility is if =C2=A0we had=
 some operations that were computed locally on the driver (this happens w=
ith things like first() and take(), which will try to do the first partit=
ion locally). But generally speaking these operations should *not* work o=
ver a network, so you'll have to make sure that you only send serializabl=
e types through shuffles or collects, or use a serialization framework li=
ke Kryo that might be okay with Writables.

Matei

On September 15, 2014 at 9:13:13 PM, Du Li (lidu=40yahoo-inc.com) wrote:

Hi Matei,

Thanks for your reply.=C2=A0

The Writable classes have never been serializable and this is why it is w=
eird. I did try as you suggested to map the Writables to integers and str=
ings. It didn=E2=80=99t pass, either. Similar exceptions were thrown exce=
pt that the messages became IntWritable, Text are not serializable. The r=
eason is in the implicits defined in the SparkContext object that convert=
 those values into their corresponding Writable classes before saving the=
 data in sequence file.

My original code was actual some test cases to try out Sequence=46ile rel=
ated APIs. The tests all passed when the spark version was specified as 1=
.0.2. But this one failed after I changed the spark version to 1.1.0 the =
new release, nothing else changed. In addition, it failed when I called r=
dd2.collect(), take(1), and first(). But it worked fine when calling rdd2=
.count(). As you can see, count() does not need to serialize and ship dat=
a while the other three methods do.

Do you recall any difference between spark 1.0 and 1.1 that might cause t=
his problem=3F

Thanks,
Du


=46rom: Matei Zaharia <matei.zaharia=40gmail.com>
Date: =46riday, September 12, 2014 at 9:10 PM
To: Du Li <lidu=40yahoo-inc.com.invalid>, =22user=40spark.apache.org=22 <=
user=40spark.apache.org>, =22dev=40spark.apache.org=22 <dev=40spark.apach=
e.org>
Subject: Re: NullWritable not serializable

Hi Du,

I don't think NullWritable has ever been serializable, so you must be doi=
ng something differently from your previous program. In this case though,=
 just use a map() to turn your Writables to serializable types (e.g. null=
 and String).

Matie

On September 12, 2014 at 8:48:36 PM, Du Li (lidu=40yahoo-inc.com.invalid)=
 wrote:

Hi,

I was trying the following on spark-shell (built with apache master and h=
adoop 2.4.0). Both calling rdd2.collect and calling rdd3.collect threw=C2=
=A0java.io.NotSerializableException: org.apache.hadoop.io.NullWritable.=C2=
=A0

I got the same problem in similar code of my app which uses the newly rel=
eased Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine with spar=
k 1.0.2 under either hadoop 2.40 and 0.23.10.

Anybody knows what caused the problem=3F

Thanks,
Du

----
import org.apache.hadoop.io.=7BNullWritable, Text=7D
val rdd =3D sc.text=46ile(=22README.md=22)
val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
res.saveAsSequence=46ile(=22./test=5Fdata=22)
val rdd2 =3D sc.sequence=46ile(=22./test=5Fdata=22, classOf=5BNullWritabl=
e=5D, classOf=5BText=5D)
rdd2.collect
val rdd3 =3D sc.sequence=46ile=5BNullWritable,Text=5D(=22./test=5Fdata=22=
)
rdd3.collect



--5417d012_100f59dc_59d1--


From dev-return-9467-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 06:39:46 2014
Return-Path: <dev-return-9467-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C7E8111D0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 06:39:46 +0000 (UTC)
Received: (qmail 6699 invoked by uid 500); 16 Sep 2014 06:39:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6629 invoked by uid 500); 16 Sep 2014 06:39:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 96773 invoked by uid 99); 16 Sep 2014 06:35:19 -0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of kartheek.mbms@gmail.com designates 209.85.212.177 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=vCUv3AitoHRwLNRRPEipi+dis3t8zsgrms4Ok4d1/4g=;
        b=tbQ+89HgCMQ7X7o8inF/izo/TgldEh6ClM40D3WcjJcwwJFfA6steZ+LiGF7Ra9XD/
         KIHVJntFdT1PknXLu3oOIDWZe4ObcDl3LQIC9om4v/0Mh0gql/R6Wn6MF2OnQlYs3Fae
         nkysxCx0o3MMtldx2400H6mqh2uAVHtDFRS2ZfEiIRj4tl+t7SiJ7/cKiAaXRkuAXx7Y
         0Dss+ByLm2L8wjMAflAdM1h74GB1am5bO3EbmJuA/vAV1aIduh0tAGtDghHlpI1nS9nZ
         gUIKJ860M7qTz9dod0UGUJs4x2fOUmMCnOuxC6vkKx9e95dV+Q7QArutFbTqXb6GCdjY
         VAIg==
MIME-Version: 1.0
X-Received: by 10.180.108.176 with SMTP id hl16mr29591024wib.4.1410849292688;
 Mon, 15 Sep 2014 23:34:52 -0700 (PDT)
Date: Tue, 16 Sep 2014 12:04:52 +0530
Message-ID: <CAAbaoBCM9+fjK0tuuX9156FR1q7+BX8j_+ARKuOXoj1q17JcjQ@mail.gmail.com>
Subject: how does replicate() method in BlockManager.scala aquires resources
 for rdd replication
From: rapelly kartheek <kartheek.mbms@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=e89a8f3ba457ec26bc050328f210
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f3ba457ec26bc050328f210
Content-Type: text/plain; charset=UTF-8

HI,

I was tracing the flow of replicate method in BlockManager.scala. I am
trying to find out as to where exactly in the code, the resources are
aquired for rdd replication.

I find that the BlockManagerMaster.getPeers() method returns only one
BlockManagerId for all the rdd partitions.

But, the storage details of the rdd in WebUI depicts that all the
partitions are replicated over multiple nodes.

I just want to find out where do we get the resources allocated for rdd
replication.

Can someone please help me out in this regard!!

Thank you
Karthik

--e89a8f3ba457ec26bc050328f210--

From dev-return-9468-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 08:07:51 2014
Return-Path: <dev-return-9468-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EFE5D113F9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 08:07:50 +0000 (UTC)
Received: (qmail 81119 invoked by uid 500); 16 Sep 2014 08:07:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81047 invoked by uid 500); 16 Sep 2014 08:07:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 66349 invoked by uid 99); 16 Sep 2014 07:08:00 -0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of sochiseung@gmail.com does not designate 216.139.236.26 as permitted sender)
Date: Tue, 16 Sep 2014 00:07:34 -0700 (PDT)
From: sochi <sochiseung@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1410851254010-8436.post@n3.nabble.com>
Subject: GraphX: some vertex with specific edge
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi. Im ChiSeung. 

1. How to know each vertices connecting some edges? 

I want to know how I find edges connected some vertices. 

And 
  
2. 
example, there are vertex a, b, c, d and edge e1. 
On graph, 
      a and b is connected by e1 
      b and c is connected by e1 
      c and d is also connected by e1 

so, above example is like  a ---(e1)---> b ---(e1)---> c ---(e1)---> d 

In this case, can I find b,c and d when I have just src vertex, a and edge,
e1?  



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/GraphX-some-vertex-with-specific-edge-tp8436.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9469-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 09:30:19 2014
Return-Path: <dev-return-9469-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6671111659
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 09:30:19 +0000 (UTC)
Received: (qmail 31121 invoked by uid 500); 16 Sep 2014 09:30:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31037 invoked by uid 500); 16 Sep 2014 09:30:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31025 invoked by uid 99); 16 Sep 2014 09:30:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 09:30:18 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ankurdave@gmail.com designates 209.85.192.175 as permitted sender)
Received: from [209.85.192.175] (HELO mail-pd0-f175.google.com) (209.85.192.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 09:30:13 +0000
Received: by mail-pd0-f175.google.com with SMTP id z10so8107401pdj.34
        for <dev@spark.incubator.apache.org>; Tue, 16 Sep 2014 02:29:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:to:subject:in-reply-to:references:user-agent:date:message-id
         :mime-version:content-type;
        bh=qMSgVe/JHgf+TNByy0MYnOxQ4yLM1w4R4WpYfwQeUog=;
        b=fkMshlhwP9L9dAe8Tgc5880LjPa5MXqMmLfCGOEYfOadZLwzI0P7qxDSxckKkw0EgN
         giH+7+uPv+hfPHtMy8JHlwEyVURlrqZ59B3M+K6/4VO6L07aokZz8NDJuGc//Rz5XKuj
         nKk3NrvjYZOoL2wsU4Lun2L94/7+McptVaHJMmnAiNBGxQY/7uI/dz6pPT9MMRZdjG42
         iyOecL0lwdr8ZS/52ktX7EV7pskhB4oBB5nMzaYAn+B0qYaxyjJp8zrYG5rIgIa84k+c
         JZSvO+jmu5DV7QayA9qhntE6IOQgr1Srki1e9YhDOldHubSH1tc2Plk3awZKpZ4biy/f
         Jt4w==
X-Received: by 10.70.130.195 with SMTP id og3mr55970258pdb.59.1410859792676;
        Tue, 16 Sep 2014 02:29:52 -0700 (PDT)
Received: from ankur-mbp-2 (c-67-164-94-63.hsd1.ca.comcast.net. [67.164.94.63])
        by mx.google.com with ESMTPSA id v1sm13641524pdg.28.2014.09.16.02.29.51
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 16 Sep 2014 02:29:51 -0700 (PDT)
From: Ankur Dave <ankurdave@gmail.com>
To: sochi <sochiseung@gmail.com>, dev@spark.incubator.apache.org
Subject: Re: GraphX: some vertex with specific edge
In-Reply-To: <1410851254010-8436.post@n3.nabble.com>
References: <1410851254010-8436.post@n3.nabble.com>
User-Agent: Notmuch/0.18.1 (http://notmuchmail.org) Emacs/24.4.50.1 (x86_64-apple-darwin13.2.0)
Date: Tue, 16 Sep 2014 02:29:47 -0700
Message-ID: <m2a95zzzec.fsf@gmail.com>
MIME-Version: 1.0
Content-Type: text/plain
X-Virus-Checked: Checked by ClamAV on apache.org

At 2014-09-16 00:07:34 -0700, sochi <sochiseung@gmail.com> wrote:
> so, above example is like  a ---(e1)---> b ---(e1)---> c ---(e1)---> d
>
> In this case, can I find b,c and d when I have just src vertex, a and edge,
> e1?

First, to clarify: the three edges in your example are all distinct, since they have different source and destination vertices. Therefore I assume you're using e1 to refer to the edge property that they have in common.

In that case, this problem is equivalent to finding the connected component containing vertex a in the subgraph where edges have property e1. Here is how to do that in the Spark shell: https://gist.github.com/ankurdave/25732a493bc8c8541c97

Ankur

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9470-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 10:00:22 2014
Return-Path: <dev-return-9470-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2E0E11174E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 10:00:22 +0000 (UTC)
Received: (qmail 1108 invoked by uid 500); 16 Sep 2014 10:00:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1036 invoked by uid 500); 16 Sep 2014 10:00:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1024 invoked by uid 99); 16 Sep 2014 10:00:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 10:00:20 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wyphao.2007@163.com designates 220.181.13.73 as permitted sender)
Received: from [220.181.13.73] (HELO m13-73.163.com) (220.181.13.73)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 10:00:14 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:MIME-Version:Message-ID; bh=STpNz
	WLc8PBoaDyc8WEnoJH+lGzmYKyRbjKg1efs8Wo=; b=Orzqs8Zp7HnMeK2Wspc0l
	ZJhjd5XkQ6tBhThJCM0EdypEy7JauiPg1R+LQByd6hINMTyO88H2bwmhxQsyKhb1
	K9QRGTjl5OyL6toNTeNBdOeXODoMnQ4+kAgPxdVWI1brBdrRS+AGmAe0DWKTqGu4
	BquueRkyhYYVHKfrf0jKlA=
Received: from wyphao.2007$163.com ( [211.151.238.51] ) by
 ajax-webmail-wmsvr73 (Coremail) ; Tue, 16 Sep 2014 17:59:45 +0800 (CST)
X-Originating-IP: [211.151.238.51]
Date: Tue, 16 Sep 2014 17:59:45 +0800 (CST)
From: "wyphao.2007" <wyphao.2007@163.com>
To: dev@spark.incubator.apache.org, "Reynold Xin" <rxin@databricks.com>
Subject: Building Spark source error with maven
X-Priority: 3
X-Mailer: Coremail Webmail Server Version SP_ntes V3.5 build
 20140725(28226.6623) Copyright (c) 2002-2014 www.mailtech.cn 163com
X-CM-CTRLDATA: NmC15WZvb3Rlcl9odG09Nzk0MTo4MQ==
Content-Type: multipart/alternative; 
	boundary="----=_Part_637154_1502616791.1410861585968"
MIME-Version: 1.0
Message-ID: <eb5c630.2ecc.1487de75631.Coremail.wyphao.2007@163.com>
X-CM-TRANSID:ScGowAC3TRgTChhUnnKlAA--.10968W
X-CM-SenderInfo: xz1sxtbrosiiqx6rljoofrz/1tbiGgMJKFD+R7oKeQAAsY
X-Coremail-Antispam: 1U5529EdanIXcx71UUUUU7vcSsGvfC2KfnxnUU==
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_637154_1502616791.1410861585968
Content-Type: text/plain; charset=GBK
Content-Transfer-Encoding: base64

SGksIFdoZW4gSSBidWlsZGluZyBzcGFyayB3aXRoIG1hdmVuLCBidXQgIGZhaWxlZCwgdGhlIGVy
cm9yIG1lc3NhZ2UgaXMgYXMgZm9sbG93aW5nLiAgSSBkaWRuJ3QgZm91bmQgdGhlIHNhdGlzZmFj
dG9yeSBzb2x1dGlvbiBieSBnb29nbGUuICBBbnlvbmUgY2FuIGhlbHAgbWU/IFRoYW5rIHlvdSEK
CgpJTkZPXSAtLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0KW0lORk9dIFJlYWN0b3IgU3VtbWFyeToKW0lORk9dIApb
SU5GT10gU3BhcmsgUHJvamVjdCBQYXJlbnQgUE9NIC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4u
IFNVQ0NFU1MgWzIuMTczc10KW0lORk9dIFNwYXJrIFByb2plY3QgQ29yZSAuLi4uLi4uLi4uLi4u
Li4uLi4uLi4uLi4uLi4uLi4uLiBTVUNDRVNTIFszOjEzLjYzOHNdCltJTkZPXSBTcGFyayBQcm9q
ZWN0IEJhZ2VsIC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4gU1VDQ0VTUyBbMjIuNDA1
c10KW0lORk9dIFNwYXJrIFByb2plY3QgR3JhcGhYIC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4u
Li4uLiBGQUlMVVJFIFsxLjcxOXNdCltJTkZPXSBTcGFyayBQcm9qZWN0IFN0cmVhbWluZyAuLi4u
Li4uLi4uLi4uLi4uLi4uLi4uLi4uLi4gU0tJUFBFRApbSU5GT10gU3BhcmsgUHJvamVjdCBNTCBM
aWJyYXJ5IC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uIFNLSVBQRUQKW0lORk9dIFNwYXJrIFBy
b2plY3QgVG9vbHMgLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLiBTS0lQUEVECltJTkZP
XSBTcGFyayBQcm9qZWN0IENhdGFseXN0IC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4gU0tJ
UFBFRApbSU5GT10gU3BhcmsgUHJvamVjdCBTUUwgLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4u
Li4uLi4uIFNLSVBQRUQKW0lORk9dIFNwYXJrIFByb2plY3QgSGl2ZSAuLi4uLi4uLi4uLi4uLi4u
Li4uLi4uLi4uLi4uLi4uLiBTS0lQUEVECltJTkZPXSBTcGFyayBQcm9qZWN0IFJFUEwgLi4uLi4u
Li4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4gU0tJUFBFRApbSU5GT10gU3BhcmsgUHJvamVjdCBZ
QVJOIFBhcmVudCBQT00gLi4uLi4uLi4uLi4uLi4uLi4uLi4uIFNLSVBQRUQKW0lORk9dIFNwYXJr
IFByb2plY3QgWUFSTiBTdGFibGUgQVBJIC4uLi4uLi4uLi4uLi4uLi4uLi4uLiBTS0lQUEVECltJ
TkZPXSBTcGFyayBQcm9qZWN0IEFzc2VtYmx5IC4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4uLi4g
U0tJUFBFRApbSU5GT10gU3BhcmsgUHJvamVjdCBFeHRlcm5hbCBUd2l0dGVyIC4uLi4uLi4uLi4u
Li4uLi4uLi4uIFNLSVBQRUQKW0lORk9dIFNwYXJrIFByb2plY3QgRXh0ZXJuYWwgS2Fma2EgLi4u
Li4uLi4uLi4uLi4uLi4uLi4uLiBTS0lQUEVECltJTkZPXSBTcGFyayBQcm9qZWN0IEV4dGVybmFs
IEZsdW1lIFNpbmsgLi4uLi4uLi4uLi4uLi4uLi4gU0tJUFBFRApbSU5GT10gU3BhcmsgUHJvamVj
dCBFeHRlcm5hbCBGbHVtZSAuLi4uLi4uLi4uLi4uLi4uLi4uLi4uIFNLSVBQRUQKW0lORk9dIFNw
YXJrIFByb2plY3QgRXh0ZXJuYWwgWmVyb01RIC4uLi4uLi4uLi4uLi4uLi4uLi4uLiBTS0lQUEVE
CltJTkZPXSBTcGFyayBQcm9qZWN0IEV4dGVybmFsIE1RVFQgLi4uLi4uLi4uLi4uLi4uLi4uLi4u
Li4gU0tJUFBFRApbSU5GT10gU3BhcmsgUHJvamVjdCBFeGFtcGxlcyAuLi4uLi4uLi4uLi4uLi4u
Li4uLi4uLi4uLi4uIFNLSVBQRUQKW0lORk9dIC0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLQpbSU5GT10gQlVJTEQg
RkFJTFVSRQpbSU5GT10gLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tCltJTkZPXSBUb3RhbCB0aW1lOiAzOjQwLjU0
NXMKW0lORk9dIEZpbmlzaGVkIGF0OiBUdWUgU2VwIDE2IDE3OjUzOjAyIENTVCAyMDE0CltJTkZP
XSBGaW5hbCBNZW1vcnk6IDU5TS85NDlNCltJTkZPXSAtLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0KW0VSUk9SXSBG
YWlsZWQgdG8gZXhlY3V0ZSBnb2FsIG5ldC5hbGNoaW0zMS5tYXZlbjpzY2FsYS1tYXZlbi1wbHVn
aW46My4yLjA6Y29tcGlsZSAoc2NhbGEtY29tcGlsZS1maXJzdCkgb24gcHJvamVjdCBzcGFyay1n
cmFwaHhfMi4xMDogd3JhcDogc2NhbGEucmVmbGVjdC5pbnRlcm5hbC5NaXNzaW5nUmVxdWlyZW1l
bnRFcnJvcjogb2JqZWN0IHNjYWxhLnJ1bnRpbWUgaW4gY29tcGlsZXIgbWlycm9yIG5vdCBmb3Vu
ZC4gLT4gW0hlbHAgMV0KW0VSUk9SXSAKW0VSUk9SXSBUbyBzZWUgdGhlIGZ1bGwgc3RhY2sgdHJh
Y2Ugb2YgdGhlIGVycm9ycywgcmUtcnVuIE1hdmVuIHdpdGggdGhlIC1lIHN3aXRjaC4KW0VSUk9S
XSBSZS1ydW4gTWF2ZW4gdXNpbmcgdGhlIC1YIHN3aXRjaCB0byBlbmFibGUgZnVsbCBkZWJ1ZyBs
b2dnaW5nLgpbRVJST1JdIApbRVJST1JdIEZvciBtb3JlIGluZm9ybWF0aW9uIGFib3V0IHRoZSBl
cnJvcnMgYW5kIHBvc3NpYmxlIHNvbHV0aW9ucywgcGxlYXNlIHJlYWQgdGhlIGZvbGxvd2luZyBh
cnRpY2xlczoKW0VSUk9SXSBbSGVscCAxXSBodHRwOi8vY3dpa2kuYXBhY2hlLm9yZy9jb25mbHVl
bmNlL2Rpc3BsYXkvTUFWRU4vTW9qb0V4ZWN1dGlvbkV4Y2VwdGlvbgpbRVJST1JdIApbRVJST1Jd
IEFmdGVyIGNvcnJlY3RpbmcgdGhlIHByb2JsZW1zLCB5b3UgY2FuIHJlc3VtZSB0aGUgYnVpbGQg
d2l0aCB0aGUgY29tbWFuZApbRVJST1JdICAgbXZuIDxnb2Fscz4gLXJmIDpzcGFyay1ncmFwaHhf
Mi4xMA==
------=_Part_637154_1502616791.1410861585968--


From dev-return-9471-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 18:06:44 2014
Return-Path: <dev-return-9471-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5069A1186E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 18:06:44 +0000 (UTC)
Received: (qmail 3268 invoked by uid 500); 16 Sep 2014 18:06:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3196 invoked by uid 500); 16 Sep 2014 18:06:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3184 invoked by uid 99); 16 Sep 2014 18:06:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 18:06:43 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 18:06:16 +0000
Received: by mail-pa0-f48.google.com with SMTP id hz1so282869pad.35
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 11:06:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=1lii31fKTVcFDJE8gy9Ro6q6NRNTqqi4vjQpmsQxmkw=;
        b=FoiLG1h+8e8u1PVg5ejbj5gkcnyw0Svy+4r76AYXgCXrmlY+/i/Qpq3Txn8HasTD0X
         lvoiPpCRhLcSeTQ1xMySpQkPsm/D7ZCmZ9OrdKXc2t+I4SZ+4a11v2ND6AtgTyQiwGQ1
         1HZIok3mkr/0NU/BSo8kf0FgUY30b5XB+1SBga6gfA+q6NK56ShBuMdz6vjZgjX7UhSa
         JID2ODGWe2UJRn3Tn3+IQR9n3z61Lwx5xko+x/sP0qSpZqF7+SmJRrm9wsSKlGH3y3OC
         VXdDGO0iKLX/LPHn1LgpBTmqWvVgApEu7Hiv2S/vBxcyXk1gx2ARniVX/sHQR9k0u5nm
         cm/w==
X-Gm-Message-State: ALoCoQl5tebpQIP/T0XmYY6/czGr5jmsltNa2cFPEDy62dBnRgqbI1uRwajWZhnWK2wdGXCMwLCg
MIME-Version: 1.0
X-Received: by 10.68.87.225 with SMTP id bb1mr53102386pbb.89.1410890774775;
 Tue, 16 Sep 2014 11:06:14 -0700 (PDT)
Received: by 10.70.26.100 with HTTP; Tue, 16 Sep 2014 11:06:14 -0700 (PDT)
In-Reply-To: <1410788664.95241.YahooMailNeo@web140101.mail.bf1.yahoo.com>
References: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
	<1410788664.95241.YahooMailNeo@web140101.mail.bf1.yahoo.com>
Date: Tue, 16 Sep 2014 11:06:14 -0700
Message-ID: <CAMJOb8=ZG=2_sqmvZK2q8UKTd_qYvCQ4VyXr5HLLYH5cgGOVUQ@mail.gmail.com>
Subject: Re: Spark authenticate enablement
From: Andrew Or <andrew@databricks.com>
To: Tom Graves <tgraves_cs@yahoo.com>
Cc: Jun Feng Liu <liujunf@cn.ibm.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b621d6472a14b0503329b65
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b621d6472a14b0503329b65
Content-Type: text/plain; charset=UTF-8

Hi Jun,

You can still set the authentication variables through `spark-env.sh`, by
exporting SPARK_MASTER_OPTS, SPARK_WORKER_OPTS, SPARK_HISTORY_OPTS etc to
include "-Dspark.auth.{...}". There is an open pull request that allows
these processes to also read from spark-defaults.conf, but this is not
merged into master yet.

Andrew

2014-09-15 6:44 GMT-07:00 Tom Graves <tgraves_cs@yahoo.com.invalid>:

> Spark authentication does work in standalone mode (atleast it did, I
> haven't tested it in a while). The same shared secret has to be set on all
> the daemons (master and workers) and then also in the configs of any
> applications submitted.  Since everyone shares the same secret its by no
> means ideal or a strong authentication.
>
> Tom
>
>
> On Thursday, September 11, 2014 4:17 AM, Jun Feng Liu <liujunf@cn.ibm.com>
> wrote:
>
>
>
> Hi, there
>
> I am trying to enable the authentication
> on spark on standealone model. Seems like only SparkSubmit load the
> properties
> from spark-defaults.conf.  org.apache.spark.deploy.master.Master dose
> not really load the default setting from spark-defaults.conf.
>
> Dose it mean the spark authentication
> only work for like YARN model? Or I missed something with standalone model.
>
> Best Regards
>
> Jun Feng Liu
> IBM China Systems & Technology Laboratory in Beijing
>
> ________________________________
>
>   Phone: 86-10-82452683
> E-mail:liujunf@cn.ibm.com
>
> BLD 28,ZGC Software Park
> No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193
> China
>

--047d7b621d6472a14b0503329b65--

From dev-return-9472-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 18:26:06 2014
Return-Path: <dev-return-9472-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 69F2B11944
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 18:26:06 +0000 (UTC)
Received: (qmail 53545 invoked by uid 500); 16 Sep 2014 18:26:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53471 invoked by uid 500); 16 Sep 2014 18:26:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 42365 invoked by uid 99); 16 Sep 2014 17:06:14 -0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of kartheek.mbms@gmail.com designates 74.125.82.46 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=Mi9dKfTxHjQd3pY81/n7wHBLrK+8mpBL+XgdOQ3FaYs=;
        b=shmUUMf59LZtmJ1+ewSauzxKbLCsWLGPljU+2jWVdbGwva2J11iipteQmt4THvnpf2
         ybKZ7v7Oqj3hA6PgK1UtyZodZ+oJxOFjSoBLsDUHsgNM0TlIPvl7rE9ELBrsOXotGHlv
         E4LjnZgQrEMncA9IrEkxgFQMYA09hZuUDXXxBbO8M+So/SJyhC0L8Nww8ZyyBP+uWvFU
         ep9GX/X6VzMB+ApZZt7mFrWsOXJuf7Vgcm4XkZkEh/Jf4KXGH0oLr/lfu2WWDP1nquOE
         MB3RnijPRDfY/nLSXmN42YDrmInOTILUGmZEKUaMt1Un853kKaocrVoU6PxPWk2P+yiS
         5Kxg==
MIME-Version: 1.0
X-Received: by 10.194.216.74 with SMTP id oo10mr5311708wjc.126.1410887147809;
 Tue, 16 Sep 2014 10:05:47 -0700 (PDT)
In-Reply-To: <CAAbaoBCM9+fjK0tuuX9156FR1q7+BX8j_+ARKuOXoj1q17JcjQ@mail.gmail.com>
References: <CAAbaoBCM9+fjK0tuuX9156FR1q7+BX8j_+ARKuOXoj1q17JcjQ@mail.gmail.com>
Date: Tue, 16 Sep 2014 22:35:47 +0530
Message-ID: <CAAbaoBAzFsH5U-oL-ziCiPOkONC_cAwKk_jxoVXQAzZ3D3DV1w@mail.gmail.com>
Subject: Re: how does replicate() method in BlockManager.scala aquires
 resources for rdd replication
From: rapelly kartheek <kartheek.mbms@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e013d1b2a437132050331c36e
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d1b2a437132050331c36e
Content-Type: text/plain; charset=UTF-8

I could resolve the conflict between my method trace and the details from
the webUI.

I was modifying and compiling only on the master node. So, I found only
node in the print trace. Now, I incorporated the prints in all the nodes
and compiled them individually. Then started all the processes and ran a
job. Each node was dealing with one node for partition replication. That
way, storage details from the webUI and the print traces from all the nodes
are both in sink.

But, Where do I get all the replication nodes at a time? The getPeers()
method calls askDriverWithReply(), which returns only one BlockManagerId in
each node.

Can someone please help me where to look for obtaining all the nodes chosen
for replication.

Thank you

On Tue, Sep 16, 2014 at 12:04 PM, rapelly kartheek <kartheek.mbms@gmail.com>
wrote:

> HI,
>
> I was tracing the flow of replicate method in BlockManager.scala. I am
> trying to find out as to where exactly in the code, the resources are
> aquired for rdd replication.
>
> I find that the BlockManagerMaster.getPeers() method returns only one
> BlockManagerId for all the rdd partitions.
>
> But, the storage details of the rdd in WebUI depicts that all the
> partitions are replicated over multiple nodes.
>
> I just want to find out where do we get the resources allocated for rdd
> replication.
>
> Can someone please help me out in this regard!!
>
> Thank you
> Karthik
>

--089e013d1b2a437132050331c36e--

From dev-return-9473-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 19:33:24 2014
Return-Path: <dev-return-9473-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 266A411C65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 19:33:24 +0000 (UTC)
Received: (qmail 45453 invoked by uid 500); 16 Sep 2014 19:33:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45375 invoked by uid 500); 16 Sep 2014 19:33:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 29099 invoked by uid 99); 16 Sep 2014 19:26:52 -0000
X-ASF-Spam-Status: No, hits=2.9 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 98.139.253.104 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: Matei Zaharia <matei.zaharia@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: Re: NullWritable not serializable
Thread-Topic: NullWritable not serializable
Thread-Index: AQHPzuxUsMmeZ0mdo0abGieZRDwkjJv+6LmAgARCZICAAJEiAIAAbfqA
Date: Tue, 16 Sep 2014 19:25:56 +0000
Message-ID: <D03DDAD9.382E%lidu@yahoo-inc.com>
References: <D038E23E.36A2%lidu@yahoo-inc.com>
 <etPan.5413c3a3.628c895d.59d1@mbp-3.local>
 <D03D03D5.37BD%lidu@yahoo-inc.com> <etPan.5417d012.71ea1109.59d1@mbp-3.local>
In-Reply-To: <etPan.5417d012.71ea1109.59d1@mbp-3.local>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/mixed; boundary="_004_D03DDAD9382Eliduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 895559000
X-Virus-Checked: Checked by ClamAV on apache.org

--_004_D03DDAD9382Eliduyahooinccom_
Content-Type: multipart/alternative;
	boundary="_000_D03DDAD9382Eliduyahooinccom_"

--_000_D03DDAD9382Eliduyahooinccom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

Hi,

The test case is separated out as follows. The call to rdd2.first() breaks =
when spark version is changed to 1.1.0, reporting exception NullWritable no=
t serializable. However, the same test passed with spark 1.0.2. The pom.xml=
 file is attached. The test data README.md was copied from spark.

Thanks,
Du
-----

package com.company.project.test

import org.scalatest._

class WritableTestSuite extends FunSuite {
  test("generated sequence file should be readable from spark") {
    import org.apache.hadoop.io.{NullWritable, Text}
    import org.apache.spark.{SparkContext, SparkConf}
    import org.apache.spark.SparkContext._

    val conf =3D new SparkConf(false).setMaster("local").setAppName("test d=
ata exchange with spark")
    val sc =3D new SparkContext(conf)

    val rdd =3D sc.textFile("README.md")
    val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
    res.saveAsSequenceFile("./test_data")

    val rdd2 =3D sc.sequenceFile("./test_data", classOf[NullWritable], clas=
sOf[Text])

    assert(rdd.first =3D=3D rdd2.first._2.toString)
  }
}



From: Matei Zaharia <matei.zaharia@gmail.com<mailto:matei.zaharia@gmail.com=
>>
Date: Monday, September 15, 2014 at 10:52 PM
To: Du Li <lidu@yahoo-inc.com<mailto:lidu@yahoo-inc.com>>
Cc: "user@spark.apache.org<mailto:user@spark.apache.org>" <user@spark.apach=
e.org<mailto:user@spark.apache.org>>, "dev@spark.apache.org<mailto:dev@spar=
k.apache.org>" <dev@spark.apache.org<mailto:dev@spark.apache.org>>
Subject: Re: NullWritable not serializable

Can you post the exact code for the test that worked in 1.0? I can't think =
of much that could've changed. The one possibility is if  we had some opera=
tions that were computed locally on the driver (this happens with things li=
ke first() and take(), which will try to do the first partition locally). B=
ut generally speaking these operations should *not* work over a network, so=
 you'll have to make sure that you only send serializable types through shu=
ffles or collects, or use a serialization framework like Kryo that might be=
 okay with Writables.

Matei


On September 15, 2014 at 9:13:13 PM, Du Li (lidu@yahoo-inc.com<mailto:lidu@=
yahoo-inc.com>) wrote:

Hi Matei,

Thanks for your reply.

The Writable classes have never been serializable and this is why it is wei=
rd. I did try as you suggested to map the Writables to integers and strings=
. It didn=92t pass, either. Similar exceptions were thrown except that the =
messages became IntWritable, Text are not serializable. The reason is in th=
e implicits defined in the SparkContext object that convert those values in=
to their corresponding Writable classes before saving the data in sequence =
file.

My original code was actual some test cases to try out SequenceFile related=
 APIs. The tests all passed when the spark version was specified as 1.0.2. =
But this one failed after I changed the spark version to 1.1.0 the new rele=
ase, nothing else changed. In addition, it failed when I called rdd2.collec=
t(), take(1), and first(). But it worked fine when calling rdd2.count(). As=
 you can see, count() does not need to serialize and ship data while the ot=
her three methods do.

Do you recall any difference between spark 1.0 and 1.1 that might cause thi=
s problem?

Thanks,
Du


From: Matei Zaharia <matei.zaharia@gmail.com<mailto:matei.zaharia@gmail.com=
>>
Date: Friday, September 12, 2014 at 9:10 PM
To: Du Li <lidu@yahoo-inc.com.invalid<mailto:lidu@yahoo-inc.com.invalid>>, =
"user@spark.apache.org<mailto:user@spark.apache.org>" <user@spark.apache.or=
g<mailto:user@spark.apache.org>>, "dev@spark.apache.org<mailto:dev@spark.ap=
ache.org>" <dev@spark.apache.org<mailto:dev@spark.apache.org>>
Subject: Re: NullWritable not serializable

Hi Du,

I don't think NullWritable has ever been serializable, so you must be doing=
 something differently from your previous program. In this case though, jus=
t use a map() to turn your Writables to serializable types (e.g. null and S=
tring).

Matie


On September 12, 2014 at 8:48:36 PM, Du Li (lidu@yahoo-inc.com.invalid<mail=
to:lidu@yahoo-inc.com.invalid>) wrote:

Hi,

I was trying the following on spark-shell (built with apache master and had=
oop 2.4.0). Both calling rdd2.collect and calling rdd3.collect threw java.i=
o.NotSerializableException: org.apache.hadoop.io.NullWritable.

I got the same problem in similar code of my app which uses the newly relea=
sed Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine with spark 1.=
0.2 under either hadoop 2.40 and 0.23.10.

Anybody knows what caused the problem?

Thanks,
Du

----
import org.apache.hadoop.io.{NullWritable, Text}
val rdd =3D sc.textFile("README.md")
val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
res.saveAsSequenceFile("./test_data")
val rdd2 =3D sc.sequenceFile("./test_data", classOf[NullWritable], classOf[=
Text])
rdd2.collect
val rdd3 =3D sc.sequenceFile[NullWritable,Text]("./test_data")
rdd3.collect



--_000_D03DDAD9382Eliduyahooinccom_
Content-Type: text/html; charset="Windows-1252"
Content-ID: <F01F223B79C51B41B3B05BB9B24C605A@yforest.corp.yahoo.com>
Content-Transfer-Encoding: quoted-printable

<html>
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3DWindows-1=
252">
</head>
<body style=3D"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-lin=
e-break: after-white-space; color: rgb(0, 0, 0); font-size: 14px; font-fami=
ly: Calibri, sans-serif;">
<div>
<div>
<div>Hi,</div>
<div><br>
</div>
<div>The test case is separated out as follows. The call to rdd2.first() br=
eaks when spark version is changed to 1.1.0, reporting exception NullWritab=
le not serializable. However, the same test passed with spark 1.0.2. The po=
m.xml file is attached. The test
 data README.md was copied from spark.</div>
<div><br>
</div>
<div>Thanks,</div>
<div>Du</div>
<div>-----</div>
<div><br>
</div>
<div>package com.company.project.test</div>
<div><br>
</div>
<div>import org.scalatest._</div>
<div><br>
</div>
<div>class WritableTestSuite extends FunSuite {</div>
<div>&nbsp; test(&quot;generated sequence file should be readable from spar=
k&quot;) {</div>
<div>&nbsp; &nbsp; import org.apache.hadoop.io.{NullWritable, Text}</div>
<div>&nbsp; &nbsp; import org.apache.spark.{SparkContext, SparkConf}</div>
<div>&nbsp; &nbsp; import org.apache.spark.SparkContext._</div>
<div><br>
</div>
<div>&nbsp; &nbsp; val conf =3D new SparkConf(false).setMaster(&quot;local&=
quot;).setAppName(&quot;test data exchange with spark&quot;)</div>
<div>&nbsp; &nbsp; val sc =3D new SparkContext(conf)</div>
<div><br>
</div>
<div>&nbsp; &nbsp; val rdd =3D sc.textFile(&quot;README.md&quot;)</div>
<div>&nbsp; &nbsp; val res =3D rdd.map(x =3D&gt; (NullWritable.get(), new T=
ext(x)))</div>
<div>&nbsp; &nbsp; res.saveAsSequenceFile(&quot;./test_data&quot;)</div>
<div><br>
</div>
<div>&nbsp; &nbsp; val rdd2 =3D sc.sequenceFile(&quot;./test_data&quot;, cl=
assOf[NullWritable], classOf[Text])</div>
<div><br>
</div>
<div>&nbsp; &nbsp; assert(rdd.first =3D=3D rdd2.first._2.toString)</div>
<div>&nbsp; }</div>
<div>}</div>
</div>
<div>
<div><br>
</div>
<div><br>
</div>
</div>
</div>
<div><br>
</div>
<span id=3D"OLK_SRC_BODY_SECTION">
<div style=3D"font-family:Calibri; font-size:11pt; text-align:left; color:b=
lack; BORDER-BOTTOM: medium none; BORDER-LEFT: medium none; PADDING-BOTTOM:=
 0in; PADDING-LEFT: 0in; PADDING-RIGHT: 0in; BORDER-TOP: #b5c4df 1pt solid;=
 BORDER-RIGHT: medium none; PADDING-TOP: 3pt">
<span style=3D"font-weight:bold">From: </span>Matei Zaharia &lt;<a href=3D"=
mailto:matei.zaharia@gmail.com">matei.zaharia@gmail.com</a>&gt;<br>
<span style=3D"font-weight:bold">Date: </span>Monday, September 15, 2014 at=
 10:52 PM<br>
<span style=3D"font-weight:bold">To: </span>Du Li &lt;<a href=3D"mailto:lid=
u@yahoo-inc.com">lidu@yahoo-inc.com</a>&gt;<br>
<span style=3D"font-weight:bold">Cc: </span>&quot;<a href=3D"mailto:user@sp=
ark.apache.org">user@spark.apache.org</a>&quot; &lt;<a href=3D"mailto:user@=
spark.apache.org">user@spark.apache.org</a>&gt;, &quot;<a href=3D"mailto:de=
v@spark.apache.org">dev@spark.apache.org</a>&quot; &lt;<a href=3D"mailto:de=
v@spark.apache.org">dev@spark.apache.org</a>&gt;<br>
<span style=3D"font-weight:bold">Subject: </span>Re: NullWritable not seria=
lizable<br>
</div>
<div><br>
</div>
<div><style>body{font-family:Helvetica,Arial;font-size:13px}</style>
<div style=3D"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line=
-break: after-white-space;">
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
Can you post the exact code for the test that worked in 1.0? I can't think =
of much that could've changed. The one possibility is if &nbsp;we had some =
operations that were computed locally on the driver (this happens with thin=
gs like first() and take(), which will
 try to do the first partition locally). But generally speaking these opera=
tions should *not* work over a network, so you'll have to make sure that yo=
u only send serializable types through shuffles or collects, or use a seria=
lization framework like Kryo that
 might be okay with Writables.</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
<br>
</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
Matei</div>
<div id=3D"bloop_sign_1410846645784297984" class=3D"bloop_sign"></div>
<br>
<p style=3D"color:#000;">On September 15, 2014 at 9:13:13 PM, Du Li (<a hre=
f=3D"mailto:lidu@yahoo-inc.com">lidu@yahoo-inc.com</a>) wrote:</p>
<blockquote type=3D"cite" class=3D"clean_bq"><span>
<div style=3D"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line=
-break: after-white-space; color: rgb(0, 0, 0); font-size: 14px; font-famil=
y: Calibri, sans-serif;">
<div></div>
<div>
<title></title>
<div>
<div>Hi Matei,</div>
<div><br>
</div>
<div>Thanks for your reply.&nbsp;</div>
<div><br>
</div>
<div>The Writable classes have never been serializable and this is why it i=
s weird. I did try as you suggested to map the Writables to integers and st=
rings. It didn=92t pass, either. Similar exceptions were thrown except that=
 the messages became IntWritable,
 Text are not serializable. The reason is in the implicits defined in the S=
parkContext object that convert those values into their corresponding Writa=
ble classes before saving the data in sequence file.</div>
<div><br>
</div>
<div>My original code was actual some test cases to try out SequenceFile re=
lated APIs. The tests all passed when the spark version was specified as 1.=
0.2. But this one failed after I changed the spark version to 1.1.0 the new=
 release, nothing else changed.
 In addition, it failed when I called rdd2.collect(), take(1), and first().=
 But it worked fine when calling rdd2.count(). As you can see, count() does=
 not need to serialize and ship data while the other three methods do.</div=
>
<div><br>
</div>
<div>Do you recall any difference between spark 1.0 and 1.1 that might caus=
e this problem?</div>
<div><br>
</div>
<div>Thanks,</div>
<div>Du</div>
<div>
<div><br>
</div>
</div>
</div>
<div><br>
</div>
<span id=3D"OLK_SRC_BODY_SECTION"></span>
<div style=3D"font-family:Calibri; font-size:11pt; text-align:left; color:b=
lack; BORDER-BOTTOM: medium none; BORDER-LEFT: medium none; PADDING-BOTTOM:=
 0in; PADDING-LEFT: 0in; PADDING-RIGHT: 0in; BORDER-TOP: #b5c4df 1pt solid;=
 BORDER-RIGHT: medium none; PADDING-TOP: 3pt">
<span id=3D"OLK_SRC_BODY_SECTION"><span style=3D"font-weight:bold">From:</s=
pan> Matei Zaharia &lt;<a href=3D"mailto:matei.zaharia@gmail.com">matei.zah=
aria@gmail.com</a>&gt;<br>
<span style=3D"font-weight:bold">Date:</span> Friday, September 12, 2014 at=
 9:10 PM<br>
<span style=3D"font-weight:bold">To:</span> Du Li &lt;<a href=3D"mailto:lid=
u@yahoo-inc.com.invalid">lidu@yahoo-inc.com.invalid</a>&gt;, &quot;<a href=
=3D"mailto:user@spark.apache.org">user@spark.apache.org</a>&quot; &lt;<a hr=
ef=3D"mailto:user@spark.apache.org">user@spark.apache.org</a>&gt;,
 &quot;<a href=3D"mailto:dev@spark.apache.org">dev@spark.apache.org</a>&quo=
t; &lt;<a href=3D"mailto:dev@spark.apache.org">dev@spark.apache.org</a>&gt;=
<br>
<span style=3D"font-weight:bold">Subject:</span> Re: NullWritable not seria=
lizable<br>
</span></div>
<div><br>
</div>
<div>
<div style=3D"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line=
-break: after-white-space;">
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
Hi Du,</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
<br>
</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
I don't think NullWritable has ever been serializable, so you must be doing=
 something differently from your previous program. In this case though, jus=
t use a map() to turn your Writables to serializable types (e.g. null and S=
tring).</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
<br>
</div>
<div id=3D"bloop_customfont" style=3D"font-family:Helvetica,Arial;font-size=
:13px; color: rgba(0,0,0,1.0); margin: 0px; line-height: auto;">
Matie</div>
<div id=3D"bloop_sign_1410581372379930880" class=3D"bloop_sign"></div>
<br>
<p style=3D"color:#000;">On September 12, 2014 at 8:48:36 PM, Du Li (<a hre=
f=3D"mailto:lidu@yahoo-inc.com.invalid">lidu@yahoo-inc.com.invalid</a>) wro=
te:</p>
<blockquote type=3D"cite" class=3D"clean_bq">
<div style=3D"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line=
-break: after-white-space; color: rgb(0, 0, 0); font-size: 14px; font-famil=
y: Calibri, sans-serif;">
<div>
<div><span>Hi,</span></div>
<div><span><br>
</span></div>
<div><span>I was trying the following on spark-shell (built with apache mas=
ter and hadoop 2.4.0). Both calling rdd2.collect and calling rdd3.collect t=
hrew&nbsp;java.io.NotSerializableException: org.apache.hadoop.io.NullWritab=
le.&nbsp;</span></div>
<div><span><br>
</span></div>
<div><span>I got the same problem in similar code of my app which uses the =
newly released Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine wi=
th spark 1.0.2 under either hadoop 2.40 and 0.23.10.</span></div>
<div><span><br>
</span></div>
<div><span>Anybody knows what caused the problem?</span></div>
<div><span><br>
</span></div>
<div><span>Thanks,</span></div>
<div><span>Du</span></div>
<div><span><br>
</span></div>
<div><span>----</span></div>
<div><span>import org.apache.hadoop.io.{NullWritable, Text}</span></div>
<div>
<div><span>val rdd =3D sc.textFile(&quot;README.md&quot;)</span></div>
<div><span>val res =3D rdd.map(x =3D&gt; (NullWritable.get(), new Text(x)))=
</span></div>
<div><span>res.saveAsSequenceFile(&quot;./test_data&quot;)</span></div>
<div><span>val rdd2 =3D sc.sequenceFile(&quot;./test_data&quot;, classOf[Nu=
llWritable], classOf[Text])</span></div>
<div><span>rdd2.collect</span></div>
<div><span>val rdd3 =3D sc.sequenceFile[NullWritable,Text](&quot;./test_dat=
a&quot;)</span></div>
<div><span>rdd3.collect</span></div>
</div>
<div><span><br>
</span></div>
<div><span><br>
</span></div>
</div>
</div>
</blockquote>
</div>
</div>
</div>
</div>
</span></blockquote>
</div>
</div>
</span>
</body>
</html>

--_000_D03DDAD9382Eliduyahooinccom_--

--_004_D03DDAD9382Eliduyahooinccom_
Content-Type: application/xml; name="pom.xml"
Content-Description: pom.xml
Content-Disposition: attachment; filename="pom.xml"; size=34618;
	creation-date="Tue, 16 Sep 2014 19:25:56 GMT";
	modification-date="Tue, 16 Sep 2014 19:25:56 GMT"
Content-ID: <C0BA1C0812F1C54497BD8F04BF828617@yforest.corp.yahoo.com>
Content-Transfer-Encoding: base64
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--_004_D03DDAD9382Eliduyahooinccom_
Content-Type: text/plain; charset=us-ascii


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--_004_D03DDAD9382Eliduyahooinccom_--

From dev-return-9474-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 19:42:56 2014
Return-Path: <dev-return-9474-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 797EF11D3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 19:42:56 +0000 (UTC)
Received: (qmail 88537 invoked by uid 500); 16 Sep 2014 19:42:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88461 invoked by uid 500); 16 Sep 2014 19:42:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88443 invoked by uid 99); 16 Sep 2014 19:42:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 19:42:55 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of Yan.Zhou.sc@huawei.com designates 206.16.17.72 as permitted sender)
Received: from [206.16.17.72] (HELO dfwrgout.huawei.com) (206.16.17.72)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 19:42:26 +0000
Received: from 172.18.9.243 (EHLO dfweml706-chm.china.huawei.com) ([172.18.9.243])
	by dfwrg01-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id CGI96904;
	Tue, 16 Sep 2014 14:42:24 -0500 (CDT)
Received: from SJCEML703-CHM.china.huawei.com (10.212.94.49) by
 dfweml706-chm.china.huawei.com (10.193.5.225) with Microsoft SMTP Server
 (TLS) id 14.3.158.1; Tue, 16 Sep 2014 12:42:23 -0700
Received: from SJCEML701-CHM.china.huawei.com ([169.254.3.52]) by
 SJCEML703-CHM.china.huawei.com ([169.254.5.137]) with mapi id 14.03.0158.001;
 Tue, 16 Sep 2014 12:42:19 -0700
From: "Yan Zhou.sc" <Yan.Zhou.sc@huawei.com>
To: Du Li <lidu@yahoo-inc.com.INVALID>,
        Matei Zaharia
	<matei.zaharia@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: NullWritable not serializable
Thread-Topic: NullWritable not serializable
Thread-Index: AQHPzuxUsMmeZ0mdo0abGieZRDwkjJv+6LmAgAReXqiAAVh8AP//jVAg
Date: Tue, 16 Sep 2014 19:42:18 +0000
Message-ID: <C434A3773D08A842B26FED6A1BA2E6546D1654D2@SJCEML701-CHM.china.huawei.com>
References: <D038E23E.36A2%lidu@yahoo-inc.com>
 <etPan.5413c3a3.628c895d.59d1@mbp-3.local>
 <D03D03D5.37BD%lidu@yahoo-inc.com>
 <etPan.5417d012.71ea1109.59d1@mbp-3.local> <D03DDAD9.382E%lidu@yahoo-inc.com>
In-Reply-To: <D03DDAD9.382E%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
x-originating-ip: [10.193.36.55]
Content-Type: multipart/alternative;
	boundary="_000_C434A3773D08A842B26FED6A1BA2E6546D1654D2SJCEML701CHMchi_"
MIME-Version: 1.0
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_C434A3773D08A842B26FED6A1BA2E6546D1654D2SJCEML701CHMchi_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

There appears to be a newly added Boolean in DAGScheduler default to "False=
":

private val localExecutionEnabled =3D sc.getConf.getBoolean("spark.localExe=
cution.enabled", false)

Then

val shouldRunLocally =3D
        localExecutionEnabled && allowLocal && finalStage.parents.isEmpty &=
& partitions.length =3D=3D 1


I'm wondering whether by default "running locally" is disabled.

Yan

From: Du Li [mailto:lidu@yahoo-inc.com.INVALID]
Sent: Tuesday, September 16, 2014 12:26 PM
To: Matei Zaharia
Cc: user@spark.apache.org; dev@spark.apache.org
Subject: Re: NullWritable not serializable

Hi,

The test case is separated out as follows. The call to rdd2.first() breaks =
when spark version is changed to 1.1.0, reporting exception NullWritable no=
t serializable. However, the same test passed with spark 1.0.2. The pom.xml=
 file is attached. The test data README.md was copied from spark.

Thanks,
Du
-----

package com.company.project.test

import org.scalatest._

class WritableTestSuite extends FunSuite {
  test("generated sequence file should be readable from spark") {
    import org.apache.hadoop.io.{NullWritable, Text}
    import org.apache.spark.{SparkContext, SparkConf}
    import org.apache.spark.SparkContext._

    val conf =3D new SparkConf(false).setMaster("local").setAppName("test d=
ata exchange with spark")
    val sc =3D new SparkContext(conf)

    val rdd =3D sc.textFile("README.md")
    val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
    res.saveAsSequenceFile("./test_data")

    val rdd2 =3D sc.sequenceFile("./test_data", classOf[NullWritable], clas=
sOf[Text])

    assert(rdd.first =3D=3D rdd2.first._2.toString)
  }
}



From: Matei Zaharia <matei.zaharia@gmail.com<mailto:matei.zaharia@gmail.com=
>>
Date: Monday, September 15, 2014 at 10:52 PM
To: Du Li <lidu@yahoo-inc.com<mailto:lidu@yahoo-inc.com>>
Cc: "user@spark.apache.org<mailto:user@spark.apache.org>" <user@spark.apach=
e.org<mailto:user@spark.apache.org>>, "dev@spark.apache.org<mailto:dev@spar=
k.apache.org>" <dev@spark.apache.org<mailto:dev@spark.apache.org>>
Subject: Re: NullWritable not serializable

Can you post the exact code for the test that worked in 1.0? I can't think =
of much that could've changed. The one possibility is if  we had some opera=
tions that were computed locally on the driver (this happens with things li=
ke first() and take(), which will try to do the first partition locally). B=
ut generally speaking these operations should *not* work over a network, so=
 you'll have to make sure that you only send serializable types through shu=
ffles or collects, or use a serialization framework like Kryo that might be=
 okay with Writables.

Matei


On September 15, 2014 at 9:13:13 PM, Du Li (lidu@yahoo-inc.com<mailto:lidu@=
yahoo-inc.com>) wrote:
Hi Matei,

Thanks for your reply.

The Writable classes have never been serializable and this is why it is wei=
rd. I did try as you suggested to map the Writables to integers and strings=
. It didn't pass, either. Similar exceptions were thrown except that the me=
ssages became IntWritable, Text are not serializable. The reason is in the =
implicits defined in the SparkContext object that convert those values into=
 their corresponding Writable classes before saving the data in sequence fi=
le.

My original code was actual some test cases to try out SequenceFile related=
 APIs. The tests all passed when the spark version was specified as 1.0.2. =
But this one failed after I changed the spark version to 1.1.0 the new rele=
ase, nothing else changed. In addition, it failed when I called rdd2.collec=
t(), take(1), and first(). But it worked fine when calling rdd2.count(). As=
 you can see, count() does not need to serialize and ship data while the ot=
her three methods do.

Do you recall any difference between spark 1.0 and 1.1 that might cause thi=
s problem?

Thanks,
Du


From: Matei Zaharia <matei.zaharia@gmail.com<mailto:matei.zaharia@gmail.com=
>>
Date: Friday, September 12, 2014 at 9:10 PM
To: Du Li <lidu@yahoo-inc.com.invalid<mailto:lidu@yahoo-inc.com.invalid>>, =
"user@spark.apache.org<mailto:user@spark.apache.org>" <user@spark.apache.or=
g<mailto:user@spark.apache.org>>, "dev@spark.apache.org<mailto:dev@spark.ap=
ache.org>" <dev@spark.apache.org<mailto:dev@spark.apache.org>>
Subject: Re: NullWritable not serializable


Hi Du,

I don't think NullWritable has ever been serializable, so you must be doing=
 something differently from your previous program. In this case though, jus=
t use a map() to turn your Writables to serializable types (e.g. null and S=
tring).

Matie


On September 12, 2014 at 8:48:36 PM, Du Li (lidu@yahoo-inc.com.invalid<mail=
to:lidu@yahoo-inc.com.invalid>) wrote:
Hi,

I was trying the following on spark-shell (built with apache master and had=
oop 2.4.0). Both calling rdd2.collect and calling rdd3.collect threw java.i=
o.NotSerializableException: org.apache.hadoop.io.NullWritable.

I got the same problem in similar code of my app which uses the newly relea=
sed Spark 1.1.0 under hadoop 2.4.0. Previously it worked fine with spark 1.=
0.2 under either hadoop 2.40 and 0.23.10.

Anybody knows what caused the problem?

Thanks,
Du

----
import org.apache.hadoop.io.{NullWritable, Text}
val rdd =3D sc.textFile("README.md")
val res =3D rdd.map(x =3D> (NullWritable.get(), new Text(x)))
res.saveAsSequenceFile("./test_data")
val rdd2 =3D sc.sequenceFile("./test_data", classOf[NullWritable], classOf[=
Text])
rdd2.collect
val rdd3 =3D sc.sequenceFile[NullWritable,Text]("./test_data")
rdd3.collect



--_000_C434A3773D08A842B26FED6A1BA2E6546D1654D2SJCEML701CHMchi_--

From dev-return-9475-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 22:22:21 2014
Return-Path: <dev-return-9475-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4DAAE11524
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 22:22:21 +0000 (UTC)
Received: (qmail 50900 invoked by uid 500); 16 Sep 2014 22:22:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50827 invoked by uid 500); 16 Sep 2014 22:22:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50808 invoked by uid 99); 16 Sep 2014 22:22:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 22:22:20 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kellrott@soe.ucsc.edu designates 209.85.214.182 as permitted sender)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 22:21:55 +0000
Received: by mail-ob0-f182.google.com with SMTP id m8so434023obr.13
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 15:21:53 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=o34OqkehSCJlO2ycUm7PWAj+bewAoFRM6AAvIETu7bY=;
        b=Oq3o3gWk0QjgjQd9d+GOwjuqtFBTEEvARAxVjUYuXqB9qX1gJs3oEjgoEDqqDMZcvf
         YxVstCGQhnN7LzpKgSbaVOzm5fF8OHexbcekYPmJfSNQ+K7qnmjf1hfqwFJ21VglvtBH
         GTyBZ/nCdk1aDhRPsvdKvwkc5/5B/POxbtYQyGfxam4EHrGC5lnPhf6kdCh/DbFLuJE7
         pEjHAaFsXCB8pep/9YB0tD3lJ6M6AkNiNCrysUuYMhpnyJ1b7GES8HaBsQJs3ga9D1dX
         pkLmXw0hXywFCbPYU8tLdj/0JdYCg/ZXmwSamcpIjs5CMHFRsQOw/TjN1v6mY1axRDad
         e39A==
X-Gm-Message-State: ALoCoQkc+IX9ChbUoDC6FjNjAUQjq13XfRyqn3jAbvDZE6xyPNr4pKc1TBqySE4WwEt9weqTsFoB
MIME-Version: 1.0
X-Received: by 10.182.142.67 with SMTP id ru3mr39140448obb.15.1410906113472;
 Tue, 16 Sep 2014 15:21:53 -0700 (PDT)
Received: by 10.182.78.234 with HTTP; Tue, 16 Sep 2014 15:21:53 -0700 (PDT)
Date: Tue, 16 Sep 2014 15:21:53 -0700
Message-ID: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com>
Subject: [mllib] State of Multi-Model training
From: Kyle Ellrott <kellrott@soe.ucsc.edu>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2eceab4923f0503362d17
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2eceab4923f0503362d17
Content-Type: text/plain; charset=UTF-8

I'm curious about the state of development Multi-Model learning in MLlib
(training sets of models during the same training session, rather then one
at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't been
any notes on it in over a month.
I submitted a pull request for a possible method to do this work a little
over two months ago (https://github.com/apache/spark/pull/1292), but
haven't yet received any feedback on the patch yet.
Is anybody else working on multi-model training?

Kyle

--001a11c2eceab4923f0503362d17--

From dev-return-9476-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 23:09:56 2014
Return-Path: <dev-return-9476-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 66DE911706
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 23:09:56 +0000 (UTC)
Received: (qmail 3117 invoked by uid 500); 16 Sep 2014 23:09:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2989 invoked by uid 500); 16 Sep 2014 23:09:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2316 invoked by uid 99); 16 Sep 2014 23:09:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 23:09:54 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of byavuz@stanford.edu designates 171.67.219.82 as permitted sender)
Received: from [171.67.219.82] (HELO smtp.stanford.edu) (171.67.219.82)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 23:09:49 +0000
Received: from codegreen1.stanford.edu (codegreen1.Stanford.EDU [171.67.224.2])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by smtp.stanford.edu (Postfix) with ESMTPS id 95E3334182F;
	Tue, 16 Sep 2014 16:09:28 -0700 (PDT)
Received: from codegreen1.stanford.edu (localhost.localdomain [127.0.0.1])
	by codegreen1.stanford.edu (Postfix) with ESMTP id 7E35484;
	Tue, 16 Sep 2014 16:09:28 -0700 (PDT)
Received: from smtp.stanford.edu (smtp2.Stanford.EDU [171.67.219.82])
	(using TLSv1 with cipher ADH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by codegreen1.stanford.edu (Postfix) with ESMTP id 72CDB84;
	Tue, 16 Sep 2014 16:09:28 -0700 (PDT)
Received: from smtp.stanford.edu (localhost [127.0.0.1])
	by localhost (Postfix) with SMTP id 6104A34144D;
	Tue, 16 Sep 2014 16:09:28 -0700 (PDT)
Received: from zm01.stanford.edu (zm01.Stanford.EDU [171.67.219.145])
	by smtp.stanford.edu (Postfix) with ESMTP id DC29A3421EC;
	Tue, 16 Sep 2014 16:09:27 -0700 (PDT)
Date: Tue, 16 Sep 2014 16:09:27 -0700 (PDT)
From: Burak Yavuz <byavuz@stanford.edu>
To: Kyle Ellrott <kellrott@soe.ucsc.edu>
Cc: dev@spark.apache.org
Message-ID: <521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu>
In-Reply-To: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com>
References: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com>
Subject: Re: [mllib] State of Multi-Model training
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.34.121.111]
X-Mailer: Zimbra 8.0.7_GA_6021 (ZimbraWebClient - GC37 (Mac)/8.0.7_GA_6021)
X-Authenticated-User: byavuz@stanford.edu
Thread-Topic: State of Multi-Model training
Thread-Index: +b0PWIgMrlpk/TWrLY3OJNn4+AR1aA==
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Kyle,

I'm actively working on it now. It's pretty close to completion, I'm just trying to figure out bottlenecks and optimize as much as possible.
As Phase 1, I implemented multi model training on Gradient Descent. Instead of performing Vector-Vector operations on rows (examples) and weights,
I've batched them into matrices so that we can use Level 3 BLAS to speed things up. I've also added support for Sparse Matrices (https://github.com/apache/spark/pull/2294) as making use of sparsity will allow you to train more models at once.

Best,
Burak

----- Original Message -----
From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
To: dev@spark.apache.org
Sent: Tuesday, September 16, 2014 3:21:53 PM
Subject: [mllib] State of Multi-Model training

I'm curious about the state of development Multi-Model learning in MLlib
(training sets of models during the same training session, rather then one
at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't been
any notes on it in over a month.
I submitted a pull request for a possible method to do this work a little
over two months ago (https://github.com/apache/spark/pull/1292), but
haven't yet received any feedback on the patch yet.
Is anybody else working on multi-model training?

Kyle


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9477-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 16 23:23:17 2014
Return-Path: <dev-return-9477-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B19E61178C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 16 Sep 2014 23:23:17 +0000 (UTC)
Received: (qmail 31519 invoked by uid 500); 16 Sep 2014 23:23:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31446 invoked by uid 500); 16 Sep 2014 23:23:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31432 invoked by uid 99); 16 Sep 2014 23:23:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 23:23:16 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cwk32@vip.qq.com designates 54.207.22.56 as permitted sender)
Received: from [54.207.22.56] (HELO smtpbgbr2.qq.com) (54.207.22.56)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 16 Sep 2014 23:22:49 +0000
X-QQ-FEAT: a7mZj5LoYd8d+ML07QBatRr/DEHoMa3ZeHhJriB6J/S+7gs+NJMk8IS1FVHRh
	QjNA/hUYfwswWacKalrSHHnu0zvkBliw434BlczOQvdc/UkLVh/zWKTwuVus8k7n4SeEpQr
	YaEqjpo3G7TwHX9mEei081KJkT1DlP7THfFArLXwV5vgZwxfMsGDPn/ecTc5Ins5oLaS+O0
	=
X-QQ-SSF: 00000000000000F0
X-QQ-WAPMAIL: 1
X-QQ-BUSINESS-ORIGIN: 2
X-Originating-IP: 117.136.168.108
X-QQ-STYLE: 
X-QQ-mid: riamail19t1410909760t4708109
From: "=?ISO-8859-1?B?VHJpZGVudA==?=" <cwk32@vip.qq.com>
To: "=?ISO-8859-1?B?ZGV2QHNwYXJrLmFwYWNoZS5vcmc=?=" <dev@spark.apache.org>
Subject: Network Communication - Akka or more?
Mime-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_5418C640_099B2D90_5D5B0EC4"
Content-Transfer-Encoding: 8Bit
Date: Wed, 17 Sep 2014 07:22:40 +0800
X-Priority: 3
Message-ID: <tencent_72473F7E2E5E52F55A3BBD29@qq.com>
X-QQ-MIME: TCMime 1.0 by Tencent
X-Mailer: QQMail 2.x
X-QQ-Mailer: QQMail 2.x
X-QQ-SENDSIZE: 520
X-QQ-Bgrelay: 1
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_5418C640_099B2D90_5D5B0EC4
Content-Type: text/plain;
	charset="ISO-8859-1"
Content-Transfer-Encoding: base64

VGhhbmsgeW91IGZvciByZWFkaW5nIHRoaXMgbWFpbC4NCg0KSSdtIHRyeWluZyB0byBjaGFu
Z2UgdGhlIHVuZGVybHlpbmcgbmV0d29yayBjb25uZWN0aW9uIHN5c3RlbSBvZiBTcGFyayB0
byBzdXBwb3J0IEluZmluaXRlYmFuZC4gDQoNCjEuIEkgZG91YnQgd2hldGhlciBDb25uZWN0
aW9uTWFuYWdlciBhbmQgbmV0dHkgaXMgdW5kZXIgY29uc3RydWN0aW9uLiBJdCBzZWVtcyB0
aGF0IHRoZXkgYXJlIG5vdCB1c3VhbGx5IHVzZWQuDQoNCjIuIEhvdyBtdWNoIGNvbm5lY3Rp
b24gcGF5bG9hZCBpcyBjYXJyaWVkIGJ5IGFra2E/DQoNCjMuIFdoZW4gcnVubmluZyAuL2Jp
bi9ydW4tZXhhbXBsZSBTcGFya1BpICAgSSBub3RpY2VkIHRoYXQgdGhlIGphciBmaWxlIGhh
cyBiZWVuIHNlbnQgZnJvbSBzZXJ2ZXIgdG8gY2xpZW50LiBJdCBpcyBzY2FyeSBiZWNhdXNl
IHRoZSBqYXIgaXMgYmlnLiBJcyBpdCBjb21tb24/DQoNCiAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgIFRyaWRlbnQ=

------=_NextPart_5418C640_099B2D90_5D5B0EC4--




From dev-return-9478-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 00:11:23 2014
Return-Path: <dev-return-9478-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 00FB811930
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 00:11:23 +0000 (UTC)
Received: (qmail 67710 invoked by uid 500); 17 Sep 2014 00:11:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67639 invoked by uid 500); 17 Sep 2014 00:11:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67625 invoked by uid 99); 17 Sep 2014 00:11:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 00:11:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.173 as permitted sender)
Received: from [209.85.214.173] (HELO mail-ob0-f173.google.com) (209.85.214.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 00:10:56 +0000
Received: by mail-ob0-f173.google.com with SMTP id m8so525673obr.18
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 17:10:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5e0Dx8Dv5s6wglM0sMnG4+NT75MOUMwxvSMI8iTS4vc=;
        b=AnAPcO6/YADc9dtgOwzxgGg4hKzY37fJfDO2rwYJn4DnTGuret8nLf3QM/2BEtAtFJ
         r1p4wQBMiqEIn3TcnZ/v6Ccg1tb9rB/yklY0TS5BdXv/NyrqDC0BuoT+gY+gwpxa1Gm+
         pjUT0iQOoFpNy9//vc8XJ8JEh/m30SVwflTEBgVt7smx79xxSXBPbipiGq++Mn9HSQl4
         VCm4hKnmOcrdpT3um0gRDIXhjzKiM8eLDOeVVyk/urmPgUvIAZ37NlYivED//rFFfgLk
         p+AAOA5YR/OR9bHdOoUMnmLR/t49u7PpH1B9+dBuKtuZmuEFlZfS2k2bMo956Rzzylr4
         +pbw==
MIME-Version: 1.0
X-Received: by 10.182.200.166 with SMTP id jt6mr37802720obc.1.1410912655267;
 Tue, 16 Sep 2014 17:10:55 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 16 Sep 2014 17:10:55 -0700 (PDT)
In-Reply-To: <CANNBgPJx2c9JLv5pjyUv22AkHmhsjmAaF8pddpit7JEjynKo4g@mail.gmail.com>
References: <CANNBgPJx2c9JLv5pjyUv22AkHmhsjmAaF8pddpit7JEjynKo4g@mail.gmail.com>
Date: Tue, 16 Sep 2014 17:10:55 -0700
Message-ID: <CABPQxssorUDSUHCZSRNtDE6OBTmM2dy8HY4X+K8HVXjqpSTkKA@mail.gmail.com>
Subject: Re: Wiki page for Operations/Monitoring tools?
From: Patrick Wendell <pwendell@gmail.com>
To: Otis Gospodnetic <otis.gospodnetic@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Otis,

Could you describe a bit more about what your program is. Is it an
open source project? A product? This would help understand a bit where
it should go.

- Patrick

On Mon, Sep 15, 2014 at 6:49 PM, Otis Gospodnetic
<otis.gospodnetic@gmail.com> wrote:
> Hi,
>
> I'm looking for a suitable place on the Wiki to add some info about a Spark
> monitoring we've built.  The Wiki looks nice and orderly, so I didn't want
> to go in and mess it up without asking where to put such info.  I don't see
> an existing "Operations" or "Monitoring" or similar pages.  Should I just
> create a Child page under https://cwiki.apache.org/confluence/display/SPARK
> ?
>
> Thanks,
> Otis
> --
> Monitoring * Alerting * Anomaly Detection * Centralized Log Management
> Solr & Elasticsearch Support * http://sematext.com/

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9479-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 01:37:29 2014
Return-Path: <dev-return-9479-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 56F1C11BFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 01:37:29 +0000 (UTC)
Received: (qmail 72367 invoked by uid 500); 17 Sep 2014 01:37:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72291 invoked by uid 500); 17 Sep 2014 01:37:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72277 invoked by uid 99); 17 Sep 2014 01:37:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 01:37:27 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=HTML_MESSAGE,MISSING_HEADERS,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of otis.gospodnetic@gmail.com designates 209.85.192.47 as permitted sender)
Received: from [209.85.192.47] (HELO mail-qg0-f47.google.com) (209.85.192.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 01:37:02 +0000
Received: by mail-qg0-f47.google.com with SMTP id i50so989162qgf.6
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 18:37:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:cc
         :content-type;
        bh=HVX1Gg3UzdrNxkVA2HuFHbJera82WABBFujy23QsbZo=;
        b=Re0P3zuLuwvvgnTS9UyzfWIIndgQ3adMmbutqOfIPS7DvPBd75la92FC9hMg8qytue
         iCPWCq2yYDBGnrPws+FT/3oS/iA8dXYDQIAJD5sp9aDQeA6UOUuemji/IMcZrPrR0FEY
         jRdkIT3Oo8W573BlV0sqbIDRvtOb4al1WtXj32VtFXoIo1tUtSQRwTrONRWIfob9siMN
         60ZUoAwz42b7EbGqUoYsfyEVPUdWFTv1JRyPrZUk5NgddmjrloCP9KJt18t+KfjaZEBE
         cMLfGql3fgK6N7BHBvB1lV5fYaxFeE1JP/1ekuOqAreN2ySXsDyp/ba2TB0CDg9idrEW
         W6Ew==
MIME-Version: 1.0
X-Received: by 10.224.151.143 with SMTP id c15mr7491286qaw.10.1410917820720;
 Tue, 16 Sep 2014 18:37:00 -0700 (PDT)
Received: by 10.229.51.132 with HTTP; Tue, 16 Sep 2014 18:37:00 -0700 (PDT)
In-Reply-To: <CABPQxssorUDSUHCZSRNtDE6OBTmM2dy8HY4X+K8HVXjqpSTkKA@mail.gmail.com>
References: <CANNBgPJx2c9JLv5pjyUv22AkHmhsjmAaF8pddpit7JEjynKo4g@mail.gmail.com>
	<CABPQxssorUDSUHCZSRNtDE6OBTmM2dy8HY4X+K8HVXjqpSTkKA@mail.gmail.com>
Date: Tue, 16 Sep 2014 21:37:00 -0400
Message-ID: <CANNBgP+gbyPvxcqZ_qRwr+wnHN8T=cGvf6U0Ry5h4CLYCdMCmA@mail.gmail.com>
Subject: Re: Wiki page for Operations/Monitoring tools?
From: Otis Gospodnetic <otis.gospodnetic@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0149bc1682efc7050338e7a4
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149bc1682efc7050338e7a4
Content-Type: text/plain; charset=UTF-8

Hi Patrick,

In our case we have a performance monitoring, alerting, and anomaly
detection product (Cloud + On Premises) and we just added Storm performance
monitoring to it.  My thinking was Spark, like any similar project really,
needs a page/section/something listing various operational tools or
services, both open-source and non-open-source.

Thanks,
Otis
--
Monitoring * Alerting * Anomaly Detection * Centralized Log Management
Solr & Elasticsearch Support * http://sematext.com/


On Tue, Sep 16, 2014 at 8:10 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Otis,
>
> Could you describe a bit more about what your program is. Is it an
> open source project? A product? This would help understand a bit where
> it should go.
>
> - Patrick
>
> On Mon, Sep 15, 2014 at 6:49 PM, Otis Gospodnetic
> <otis.gospodnetic@gmail.com> wrote:
> > Hi,
> >
> > I'm looking for a suitable place on the Wiki to add some info about a
> Spark
> > monitoring we've built.  The Wiki looks nice and orderly, so I didn't
> want
> > to go in and mess it up without asking where to put such info.  I don't
> see
> > an existing "Operations" or "Monitoring" or similar pages.  Should I just
> > create a Child page under
> https://cwiki.apache.org/confluence/display/SPARK
> > ?
> >
> > Thanks,
> > Otis
> > --
> > Monitoring * Alerting * Anomaly Detection * Centralized Log Management
> > Solr & Elasticsearch Support * http://sematext.com/
>

--089e0149bc1682efc7050338e7a4--

From dev-return-9480-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 04:17:27 2014
Return-Path: <dev-return-9480-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1511611FDD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 04:17:27 +0000 (UTC)
Received: (qmail 87572 invoked by uid 500); 17 Sep 2014 04:17:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87493 invoked by uid 500); 17 Sep 2014 04:17:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87479 invoked by uid 99); 17 Sep 2014 04:17:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:17:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mohitjaggi@gmail.com designates 209.85.192.52 as permitted sender)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:16:59 +0000
Received: by mail-qg0-f52.google.com with SMTP id i50so1156904qgf.39
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 21:16:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=vH0C7MlI2valtXXb6IAeuey/u/EDDgNy+gS8ScTXtRA=;
        b=vA+dxrE3T4deNw+Bucq9WH0+Mk3NInco1G86DWNraDf6/vRd1LiQ48bsgr5iOTBfJu
         ZxkTKz0n0Qmkua/msgFWEALDENcr3dG2Rfb+TENxHeigchdMr45RDX3M3CVKLQc6Samd
         sTIFlf4noXTicjKaB1d78TwvvMkCG3vr4hDDKsuxz44YWoru1s/Li9MNTBxwBPLmxCKt
         LxVlyzLm/4bQYqL3U0UwWEPUgdnqFS9LXwSsZAunpKJVwuEmq4Eirlvow5zWq791OoeH
         SwkZozOZWMjCVPvcaZOf1MbaNTo/ju18pDyZ8d3COdoc3kOH6fYT1Iecsrey3hhbj9HM
         +lvQ==
MIME-Version: 1.0
X-Received: by 10.224.88.198 with SMTP id b6mr25622612qam.37.1410927418336;
 Tue, 16 Sep 2014 21:16:58 -0700 (PDT)
Received: by 10.140.93.36 with HTTP; Tue, 16 Sep 2014 21:16:58 -0700 (PDT)
Date: Tue, 16 Sep 2014 21:16:58 -0700
Message-ID: <CALRVTpJhK0wQzYTo6BNhJ5bie-UqZr4Z91N2ZnqyGzmZrP5E5Q@mail.gmail.com>
Subject: greeting from new member and jira 3489
From: Mohit Jaggi <mohitjaggi@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c29f3e92f66005033b23bd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c29f3e92f66005033b23bd
Content-Type: text/plain; charset=UTF-8

https://issues.apache.org/jira/browse/SPARK-3489

Folks,
I am Mohit Jaggi and I work for Ayasdi Inc. After experimenting with Spark
for  a while and discovering its awesomeness(!) I made an attempt to
provide a wrapper API that looks like R and/or pandas dataframe.

https://github.com/AyasdiOpenSource/df

"df" uses a collection of RDDs, each element in the collection being a
column in a dataframe. To make rows from the columns I used zip() in a loop
but that is not very efficient. I created JIRA 3489 requesting a zip()
variant that zips a sequence of RDDs. I noticed that it was easy to write
that code so I wrote that code and it seems to work. I attached the diff to
the jira. I believe that this API would be useful in general and is not
specific to "df". Please take a look at the request and the proposed
solution and let me know what you think.

Cheers,
Mohit

--001a11c29f3e92f66005033b23bd--

From dev-return-9481-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 04:36:38 2014
Return-Path: <dev-return-9481-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 039BE1105A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 04:36:38 +0000 (UTC)
Received: (qmail 32376 invoked by uid 500); 17 Sep 2014 04:36:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32304 invoked by uid 500); 17 Sep 2014 04:36:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32290 invoked by uid 99); 17 Sep 2014 04:36:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:36:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.44 as permitted sender)
Received: from [209.85.219.44] (HELO mail-oa0-f44.google.com) (209.85.219.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:36:32 +0000
Received: by mail-oa0-f44.google.com with SMTP id eb12so683057oac.3
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 21:36:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=6LGb0MoZBpxwKVzBkxdEBpLHFVozS5NxWfMWC161rUE=;
        b=ymURG+9ovNesCJflPLaqYvYm/BJsXETEL0UngLeSPEN82+E7aBlhh6JkTjUDuhM9j6
         hUEu4QEKEI6p2iSW4ceyXicvCneiR/1TvXxH0Qf3kiswkD6OM1c51Zx7maARsWgHfP4K
         S0w74kAIdIsRKsLV9lt8YUsb2Kp6LyubR2dD0VHX9w/0niaiJ8AMnN9InHS9drF+qsEE
         NMZoITq6hNE831Lf84EGITCXrQBzV0FG5N7Nui5apH1Uvy0DFjQpF31aQu1mWCUQs051
         MUX2XyvL2kOZ/xH7AsxF98GIjviA/Hba9Td4N43LfjZAdUBtENQi9yZmw3zdJs3skq64
         fUfQ==
MIME-Version: 1.0
X-Received: by 10.182.20.242 with SMTP id q18mr40116238obe.52.1410928571755;
 Tue, 16 Sep 2014 21:36:11 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Tue, 16 Sep 2014 21:36:11 -0700 (PDT)
In-Reply-To: <CALRVTpJhK0wQzYTo6BNhJ5bie-UqZr4Z91N2ZnqyGzmZrP5E5Q@mail.gmail.com>
References: <CALRVTpJhK0wQzYTo6BNhJ5bie-UqZr4Z91N2ZnqyGzmZrP5E5Q@mail.gmail.com>
Date: Tue, 16 Sep 2014 21:36:11 -0700
Message-ID: <CABPQxssmgiaUfH0m3qPFjW9HY+yEPQv9OYpZbO3MhYdQRAsmeQ@mail.gmail.com>
Subject: Re: greeting from new member and jira 3489
From: Patrick Wendell <pwendell@gmail.com>
To: Mohit Jaggi <mohitjaggi@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Mohit,

Welcome to the Spark community! We normally look at feature proposals
using github pull requests mind submitting one? The contribution
process is covered here:

https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark

On Tue, Sep 16, 2014 at 9:16 PM, Mohit Jaggi <mohitjaggi@gmail.com> wrote:
> https://issues.apache.org/jira/browse/SPARK-3489
>
> Folks,
> I am Mohit Jaggi and I work for Ayasdi Inc. After experimenting with Spark
> for  a while and discovering its awesomeness(!) I made an attempt to
> provide a wrapper API that looks like R and/or pandas dataframe.
>
> https://github.com/AyasdiOpenSource/df
>
> "df" uses a collection of RDDs, each element in the collection being a
> column in a dataframe. To make rows from the columns I used zip() in a loop
> but that is not very efficient. I created JIRA 3489 requesting a zip()
> variant that zips a sequence of RDDs. I noticed that it was easy to write
> that code so I wrote that code and it seems to work. I attached the diff to
> the jira. I believe that this API would be useful in general and is not
> specific to "df". Please take a look at the request and the proposed
> solution and let me know what you think.
>
> Cheers,
> Mohit

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9482-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 04:42:13 2014
Return-Path: <dev-return-9482-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0BFFA11076
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 04:42:13 +0000 (UTC)
Received: (qmail 39616 invoked by uid 500); 17 Sep 2014 04:42:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39538 invoked by uid 500); 17 Sep 2014 04:42:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39523 invoked by uid 99); 17 Sep 2014 04:42:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:42:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kellrott@soe.ucsc.edu designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 04:41:46 +0000
Received: by mail-ob0-f175.google.com with SMTP id vb8so677944obc.20
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 21:41:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=gh6RMXeUJ0aAjF7nbU59kzIgG6LKPfuIJYSwpduvyo0=;
        b=d9JV5YeiIpEQqOlb2I+bu65mNXxtq9FWNckVM61CL8+VtqVe6x28cByuC6wq1/BdVU
         dT7vS1ihRGQYOQ3XaWVVwkWC2dfXRofM8i5qob7gNJR6kdeb2JXq8DlRwJCBmwFLgXO+
         5ZkDZfTITefBWYg4KYhe/FAF1TmDUpcaSu2utzwq4H3476wIgIr0+VV+Grr4Dtcoytzz
         cVADQYbQgKfiHlTSu1JI5nLGjIiVJJO84eBFkMbFne0PptE6XPjO9nJ4p9rybZm7sx9/
         o2AV6Sqd96NJnOfAp8jDqPcQIwhre/nyC4lQMZgKuagxE4vSf4PrqB5+gesapmIYMxHL
         reBw==
X-Gm-Message-State: ALoCoQnfXn6aSVYnqi1dLupI8KCuBvEw3cC6V8GbQroLiC/DAg0N0u492MJm7YNJU0jEy7VUja30
MIME-Version: 1.0
X-Received: by 10.182.200.166 with SMTP id jt6mr38739994obc.1.1410928905342;
 Tue, 16 Sep 2014 21:41:45 -0700 (PDT)
Received: by 10.182.78.234 with HTTP; Tue, 16 Sep 2014 21:41:45 -0700 (PDT)
In-Reply-To: <521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu>
References: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com>
	<521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu>
Date: Tue, 16 Sep 2014 21:41:45 -0700
Message-ID: <CAKXMip3idBRKbd0zGgbvfBSN1x1k+nmFXzDx4FJLEoGjxOvZ-g@mail.gmail.com>
Subject: Re: [mllib] State of Multi-Model training
From: Kyle Ellrott <kellrott@soe.ucsc.edu>
To: Burak Yavuz <byavuz@stanford.edu>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2cbd834e96905033b7c02
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2cbd834e96905033b7c02
Content-Type: text/plain; charset=UTF-8

I'd be interested in helping to test your code as soon as its available.
The version I wrote used a paired RDD and combined by key, it worked best
if it used a custom partitioner that put all the samples in the same area.
Running things in batched matrices would probably speed things up greatly.
You probably won't need my training code, but I did write some stuff
related to calculating Binary classifications metric (
https://github.com/apache/spark/pull/1292/files#diff-6) and AUC (
https://github.com/apache/spark/pull/1292/files#diff-5) for multiple models
that you might be able to use.

Kyle


On Tue, Sep 16, 2014 at 4:09 PM, Burak Yavuz <byavuz@stanford.edu> wrote:

> Hi Kyle,
>
> I'm actively working on it now. It's pretty close to completion, I'm just
> trying to figure out bottlenecks and optimize as much as possible.
> As Phase 1, I implemented multi model training on Gradient Descent.
> Instead of performing Vector-Vector operations on rows (examples) and
> weights,
> I've batched them into matrices so that we can use Level 3 BLAS to speed
> things up. I've also added support for Sparse Matrices (
> https://github.com/apache/spark/pull/2294) as making use of sparsity will
> allow you to train more models at once.
>
> Best,
> Burak
>
> ----- Original Message -----
> From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> To: dev@spark.apache.org
> Sent: Tuesday, September 16, 2014 3:21:53 PM
> Subject: [mllib] State of Multi-Model training
>
> I'm curious about the state of development Multi-Model learning in MLlib
> (training sets of models during the same training session, rather then one
> at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
> https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't been
> any notes on it in over a month.
> I submitted a pull request for a possible method to do this work a little
> over two months ago (https://github.com/apache/spark/pull/1292), but
> haven't yet received any feedback on the patch yet.
> Is anybody else working on multi-model training?
>
> Kyle
>
>

--001a11c2cbd834e96905033b7c02--

From dev-return-9483-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 05:22:39 2014
Return-Path: <dev-return-9483-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 412EC11127
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 05:22:39 +0000 (UTC)
Received: (qmail 11082 invoked by uid 500); 17 Sep 2014 05:22:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11009 invoked by uid 500); 17 Sep 2014 05:22:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10998 invoked by uid 99); 17 Sep 2014 05:22:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 05:22:38 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of byavuz@stanford.edu designates 171.67.219.82 as permitted sender)
Received: from [171.67.219.82] (HELO smtp.stanford.edu) (171.67.219.82)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 05:22:12 +0000
Received: from codegreen2.stanford.edu (codegreen2.Stanford.EDU [171.67.224.3])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by smtp.stanford.edu (Postfix) with ESMTPS id 657953421B0;
	Tue, 16 Sep 2014 22:22:08 -0700 (PDT)
Received: from codegreen2.stanford.edu (localhost.localdomain [127.0.0.1])
	by codegreen2.stanford.edu (Postfix) with ESMTP id 5767565;
	Tue, 16 Sep 2014 22:22:08 -0700 (PDT)
Received: from smtp.stanford.edu (smtp2.Stanford.EDU [171.67.219.82])
	(using TLSv1 with cipher ADH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by codegreen2.stanford.edu (Postfix) with ESMTP id 4179A65;
	Tue, 16 Sep 2014 22:22:08 -0700 (PDT)
Received: from smtp.stanford.edu (localhost [127.0.0.1])
	by localhost (Postfix) with SMTP id 3413E342347;
	Tue, 16 Sep 2014 22:22:08 -0700 (PDT)
Received: from zm01.stanford.edu (zm01.Stanford.EDU [171.67.219.145])
	by smtp.stanford.edu (Postfix) with ESMTP id F348E3421B0;
	Tue, 16 Sep 2014 22:22:07 -0700 (PDT)
Date: Tue, 16 Sep 2014 22:22:07 -0700 (PDT)
From: Burak Yavuz <byavuz@stanford.edu>
To: Kyle Ellrott <kellrott@soe.ucsc.edu>
Cc: dev@spark.apache.org
Message-ID: <1631425729.3052157.1410931327952.JavaMail.zimbra@stanford.edu>
In-Reply-To: <CAKXMip3idBRKbd0zGgbvfBSN1x1k+nmFXzDx4FJLEoGjxOvZ-g@mail.gmail.com>
References: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com> <521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu> <CAKXMip3idBRKbd0zGgbvfBSN1x1k+nmFXzDx4FJLEoGjxOvZ-g@mail.gmail.com>
Subject: Re: [mllib] State of Multi-Model training
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.30.146.110]
X-Mailer: Zimbra 8.0.7_GA_6021 (ZimbraWebClient - GC37 (Mac)/8.0.7_GA_6021)
X-Authenticated-User: byavuz@stanford.edu
Thread-Topic: State of Multi-Model training
Thread-Index: WJz4HeKI455REBxmtEQl906YF6jIvQ==
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Kyle,

Thank you for the code examples. We may be able to use some of the ideas there. I think initially the goal is to have the optimizers ready (SGD, LBFGS), 
and then the evaluation metrics will come next. It might take some time, however as MLlib is going to have a significant API "face-lift" (e.g. https://issues.apache.org/jira/browse/SPARK-3530). Evaluation metrics will be significant in the new "pipeline"s and the ability to evaluate multiple models
efficiently is very important. We encourage you to read through the design docs, and we would appreciate any feedback from you and the rest of the community!

Best,
Burak

----- Original Message -----
From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
To: "Burak Yavuz" <byavuz@stanford.edu>
Cc: dev@spark.apache.org
Sent: Tuesday, September 16, 2014 9:41:45 PM
Subject: Re: [mllib] State of Multi-Model training

I'd be interested in helping to test your code as soon as its available.
The version I wrote used a paired RDD and combined by key, it worked best
if it used a custom partitioner that put all the samples in the same area.
Running things in batched matrices would probably speed things up greatly.
You probably won't need my training code, but I did write some stuff
related to calculating Binary classifications metric (
https://github.com/apache/spark/pull/1292/files#diff-6) and AUC (
https://github.com/apache/spark/pull/1292/files#diff-5) for multiple models
that you might be able to use.

Kyle


On Tue, Sep 16, 2014 at 4:09 PM, Burak Yavuz <byavuz@stanford.edu> wrote:

> Hi Kyle,
>
> I'm actively working on it now. It's pretty close to completion, I'm just
> trying to figure out bottlenecks and optimize as much as possible.
> As Phase 1, I implemented multi model training on Gradient Descent.
> Instead of performing Vector-Vector operations on rows (examples) and
> weights,
> I've batched them into matrices so that we can use Level 3 BLAS to speed
> things up. I've also added support for Sparse Matrices (
> https://github.com/apache/spark/pull/2294) as making use of sparsity will
> allow you to train more models at once.
>
> Best,
> Burak
>
> ----- Original Message -----
> From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> To: dev@spark.apache.org
> Sent: Tuesday, September 16, 2014 3:21:53 PM
> Subject: [mllib] State of Multi-Model training
>
> I'm curious about the state of development Multi-Model learning in MLlib
> (training sets of models during the same training session, rather then one
> at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
> https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't been
> any notes on it in over a month.
> I submitted a pull request for a possible method to do this work a little
> over two months ago (https://github.com/apache/spark/pull/1292), but
> haven't yet received any feedback on the patch yet.
> Is anybody else working on multi-model training?
>
> Kyle
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9484-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 05:33:54 2014
Return-Path: <dev-return-9484-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 40E551116D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 05:33:54 +0000 (UTC)
Received: (qmail 33526 invoked by uid 500); 17 Sep 2014 05:33:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33457 invoked by uid 500); 17 Sep 2014 05:33:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33443 invoked by uid 99); 17 Sep 2014 05:33:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 05:33:52 +0000
X-ASF-Spam-Status: No, hits=0.2 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of liujunf@cn.ibm.com designates 202.81.31.144 as permitted sender)
Received: from [202.81.31.144] (HELO e23smtp02.au.ibm.com) (202.81.31.144)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 05:33:46 +0000
Received: from /spool/local
	by e23smtp02.au.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
	for <dev@spark.apache.org> from <liujunf@cn.ibm.com>;
	Wed, 17 Sep 2014 15:33:23 +1000
Received: from d23dlp01.au.ibm.com (202.81.31.203)
	by e23smtp02.au.ibm.com (202.81.31.208) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
	Wed, 17 Sep 2014 15:33:21 +1000
Received: from d23relay07.au.ibm.com (d23relay07.au.ibm.com [9.190.26.37])
	by d23dlp01.au.ibm.com (Postfix) with ESMTP id 3C17C2CE804D
	for <dev@spark.apache.org>; Wed, 17 Sep 2014 15:33:21 +1000 (EST)
Received: from d23av04.au.ibm.com (d23av04.au.ibm.com [9.190.235.139])
	by d23relay07.au.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id s8H5Yf9418481394
	for <dev@spark.apache.org>; Wed, 17 Sep 2014 15:34:41 +1000
Received: from d23av04.au.ibm.com (localhost [127.0.0.1])
	by d23av04.au.ibm.com (8.14.4/8.14.4/NCO v10.0 AVout) with ESMTP id s8H5XKCJ018448
	for <dev@spark.apache.org>; Wed, 17 Sep 2014 15:33:20 +1000
Received: from d23ml028.cn.ibm.com (d23ml028.cn.ibm.com [9.119.32.184])
	by d23av04.au.ibm.com (8.14.4/8.14.4/NCO v10.0 AVin) with ESMTP id s8H5XJ3n018438;
	Wed, 17 Sep 2014 15:33:19 +1000
In-Reply-To: <CAMJOb8=ZG=2_sqmvZK2q8UKTd_qYvCQ4VyXr5HLLYH5cgGOVUQ@mail.gmail.com>
References: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>	<1410788664.95241.YahooMailNeo@web140101.mail.bf1.yahoo.com> <CAMJOb8=ZG=2_sqmvZK2q8UKTd_qYvCQ4VyXr5HLLYH5cgGOVUQ@mail.gmail.com>
To: Andrew Or <andrew@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>,
        Tom Graves <tgraves_cs@yahoo.com>
MIME-Version: 1.0
Subject: Re: Spark authenticate enablement
X-KeepSent: 43B14B12:1435FFAB-48257D56:001E4DAD;
 type=4; name=$KeepSent
X-Mailer: Lotus Notes Release 8.5.3 September 15, 2011
Message-ID: <OF43B14B12.1435FFAB-ON48257D56.001E4DAD-48257D56.001E8291@cn.ibm.com>
From: Jun Feng Liu <liujunf@cn.ibm.com>
Date: Wed, 17 Sep 2014 13:32:22 +0800
X-MIMETrack: Serialize by Router on d23ml028/23/M/IBM(Release 8.5.3FP6HF485 | May 7, 2014) at
 09/17/2014 13:32:20,
	Serialize complete at 09/17/2014 13:32:20
Content-Type: multipart/related; boundary="=_related 001E828E48257D56_="
X-TM-AS-MML: disable
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 14091705-0005-0000-0000-000000B558D8
X-Virus-Checked: Checked by ClamAV on apache.org

--=_related 001E828E48257D56_=
Content-Type: multipart/alternative; boundary="=_alternative 001E828E48257D56_="


--=_alternative 001E828E48257D56_=
Content-Type: text/plain; charset="US-ASCII"

I see. Thank you, it works for me. It looks confusing to have two ways 
expose configuration though.
 
Best Regards
 
Jun Feng Liu
IBM China Systems & Technology Laboratory in Beijing



Phone: 86-10-82452683 
E-mail: liujunf@cn.ibm.com


BLD 28,ZGC Software Park 
No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193 
China 
 

 



Andrew Or <andrew@databricks.com> 
2014/09/17 02:06

To
Tom Graves <tgraves_cs@yahoo.com>, 
cc
Jun Feng Liu/China/IBM@IBMCN, "dev@spark.apache.org" 
<dev@spark.apache.org>
Subject
Re: Spark authenticate enablement






Hi Jun,

You can still set the authentication variables through `spark-env.sh`, by
exporting SPARK_MASTER_OPTS, SPARK_WORKER_OPTS, SPARK_HISTORY_OPTS etc to
include "-Dspark.auth.{...}". There is an open pull request that allows
these processes to also read from spark-defaults.conf, but this is not
merged into master yet.

Andrew

2014-09-15 6:44 GMT-07:00 Tom Graves <tgraves_cs@yahoo.com.invalid>:

> Spark authentication does work in standalone mode (atleast it did, I
> haven't tested it in a while). The same shared secret has to be set on 
all
> the daemons (master and workers) and then also in the configs of any
> applications submitted.  Since everyone shares the same secret its by no
> means ideal or a strong authentication.
>
> Tom
>
>
> On Thursday, September 11, 2014 4:17 AM, Jun Feng Liu 
<liujunf@cn.ibm.com>
> wrote:
>
>
>
> Hi, there
>
> I am trying to enable the authentication
> on spark on standealone model. Seems like only SparkSubmit load the
> properties
> from spark-defaults.conf.  org.apache.spark.deploy.master.Master dose
> not really load the default setting from spark-defaults.conf.
>
> Dose it mean the spark authentication
> only work for like YARN model? Or I missed something with standalone 
model.
>
> Best Regards
>
> Jun Feng Liu
> IBM China Systems & Technology Laboratory in Beijing
>
> ________________________________
>
>   Phone: 86-10-82452683
> E-mail:liujunf@cn.ibm.com
>
> BLD 28,ZGC Software Park
> No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193
> China
>


--=_alternative 001E828E48257D56_=
Content-Type: text/html; charset="GB2312"
Content-Transfer-Encoding: base64
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=
--=_alternative 001E828E48257D56_=--
--=_related 001E828E48257D56_=--


From dev-return-9485-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 06:45:41 2014
Return-Path: <dev-return-9485-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1EF6911311
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 06:45:41 +0000 (UTC)
Received: (qmail 63885 invoked by uid 500); 17 Sep 2014 06:45:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63804 invoked by uid 500); 17 Sep 2014 06:45:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63790 invoked by uid 99); 17 Sep 2014 06:45:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 06:45:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.192.41 as permitted sender)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 06:45:13 +0000
Received: by mail-qg0-f41.google.com with SMTP id a108so1329343qge.14
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 23:45:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=DGJtVHeYv3hoB676TKhJVzDno6/MNa/AFZ1r7De4paU=;
        b=zcdqXk8dDHF/7MKWWvmolJz3QwnxmAE8e8hOO4WIZmv/3txDviuAdvW7NfT4U3Zmyw
         a+oaXmAr05s3enpiOtzAbDum/0R5wSHSS9uZg6tPoFWuof8R/MjA0XiAbeptBa5Ql9dC
         z8q1pq+uGjG+khKLMylPGOXkvbt+LmNqxcC+fgPv5mNtFW8k4e/JRZlvcUX2KoFWwSFT
         s48qsIZDPalA/j7PpQ/TE/anh/niz/7VPx9MlSFKJFwyGPXOlZNVgc/2Ry8jbZW77IHj
         PjesoefoorzFGpblbmBOhiFBGK6leZzW3lBPWcJGcjEMnivyimcQLoGzKBsIFAVh4KjV
         h55g==
MIME-Version: 1.0
X-Received: by 10.140.97.247 with SMTP id m110mr56404096qge.80.1410936311583;
 Tue, 16 Sep 2014 23:45:11 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Tue, 16 Sep 2014 23:45:11 -0700 (PDT)
Date: Wed, 17 Sep 2014 10:45:11 +0400
Message-ID: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
Subject: Workflow Scheduler for Spark
From: Egor Pahomov <pahomov.egor@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a6d1ea71bc005033d35e4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a6d1ea71bc005033d35e4
Content-Type: text/plain; charset=UTF-8

There are two things we(Yandex) miss in Spark: MLlib good abstractions and
good workflow job scheduler. From threads "Adding abstraction in MlLib" and
"[mllib] State of Multi-Model training" I got the idea, that databricks
working on it and we should wait until first post doc, which would lead us.
What about workflow scheduler? Is there anyone already working on it? Does
anyone have a plan on doing it?

P.S. We thought that MLlib abstractions about multiple algorithms run with
same data would need such scheduler, which would rerun algorithm in case of
failure. I understand, that spark provide fault tolerance out of the box,
but we found some "Ooozie-like" scheduler more reliable for such long
living workflows.

-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a113a6d1ea71bc005033d35e4--

From dev-return-9486-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 06:53:56 2014
Return-Path: <dev-return-9486-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04C4A11343
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 06:53:56 +0000 (UTC)
Received: (qmail 85793 invoked by uid 500); 17 Sep 2014 06:53:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85661 invoked by uid 500); 17 Sep 2014 06:53:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85328 invoked by uid 99); 17 Sep 2014 06:53:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 06:53:53 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 06:53:28 +0000
Received: by mail-ie0-f175.google.com with SMTP id lx4so1151000iec.34
        for <dev@spark.apache.org>; Tue, 16 Sep 2014 23:53:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=atrm2IK7JJ4Wt5n9pZS88f6q0gWkIxgAk6t2oZ1Cr0k=;
        b=cERSqHjBGdBPk0WEFzJUTVjDX7fdDG+3T63W5nrg7nnSwytJIMV8FpHs2nKkEu70B/
         jpRiam2e40z13dMjuwcgfA+hKLmY46lTNqkPk1d2UizqoODmeR31CEVL5/57LXmcsa0c
         sDngJVLVFmoNACodmBAT+0meGErqrUFJ/oD7y5Px5IdWPVqtEyMsDtYbjIX03Y7kHqZq
         XeZgB2JrGwT7MyrNsYTT1DTprJdusbPgzRI1J5TCYdnz7v6J/sREpYT+2bna4+PbHuDl
         ne5VPisW59VDtAy74dnaLx2id4U60MLhInNyCXBnqLXR+eKqmeOsnM6oPbTNsyvBgK/l
         PBrQ==
MIME-Version: 1.0
X-Received: by 10.50.66.234 with SMTP id i10mr23863412igt.34.1410936807136;
 Tue, 16 Sep 2014 23:53:27 -0700 (PDT)
Received: by 10.107.152.3 with HTTP; Tue, 16 Sep 2014 23:53:27 -0700 (PDT)
In-Reply-To: <CAPh_B=bW-YvL+UTkN1SWv6VbscKpB-VhWuzxVVGvvm=AejnRAA@mail.gmail.com>
References: <CAMrx5DwF1c2FDbFcq0OHp2xppXZYtW=JN3GXXyPrZcuq7gTTNw@mail.gmail.com>
	<CAKxiPZO6F06dUmUDFVTRcc6sN+m2VZ8P2SXMgdyvA5eD2XSG4A@mail.gmail.com>
	<CAMrx5DwChP_b=kyMW5xF-45W+-01ndnj1GoGTFs=mEpuQB5ccg@mail.gmail.com>
	<CAMrx5DzjgQ2pQk3=5tQHBT+fAcbQ8kb+OPOfgpDZogRJqTWSRQ@mail.gmail.com>
	<CAPh_B=aPKPtF9vAbuCzUDDYhuQXZmCsBz5XaKmRt7QAP=oBGrQ@mail.gmail.com>
	<CAJgQjQ_bGfoutcosFKceW_FJZwRnRAApDsDyqtgQ5nhwUfAG0w@mail.gmail.com>
	<703329832.21829963.1410549021425.JavaMail.zimbra@redhat.com>
	<CABPQxsuJfL9PUYEKsaE=9YyaTfiB5Y5SbR8mAsLnWY1B9YCC+Q@mail.gmail.com>
	<CAMrx5Dy+JFJCbK+yg94wCiH2_LNobkasNuiT97MjimmfGyxa-w@mail.gmail.com>
	<CAPh_B=bW-YvL+UTkN1SWv6VbscKpB-VhWuzxVVGvvm=AejnRAA@mail.gmail.com>
Date: Tue, 16 Sep 2014 23:53:27 -0700
Message-ID: <CAJgQjQ-MOfvvP0aLYdYc4bUCrLX8cLbsay1xa_B_LKi2OzW6ew@mail.gmail.com>
Subject: Re: Adding abstraction in MLlib
From: Xiangrui Meng <mengxr@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Egor Pahomov <pahomov.egor@gmail.com>, Patrick Wendell <pwendell@gmail.com>, 
	Erik Erlandson <eje@redhat.com>, Christoph Sawade <christoph.sawade@googlemail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Xiangrui Meng <meng@databricks.com>, 
	Joseph Bradley <joseph@databricks.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Egor,

I posted the design doc for pipeline and parameters on the JIRA, now
I'm trying to work out some details of ML datasets, which I will post
it later this week. You feedback is welcome!

Best,
Xiangrui

On Mon, Sep 15, 2014 at 12:44 AM, Reynold Xin <rxin@databricks.com> wrote:
> Hi Egor,
>
> Thanks for the suggestion. It is definitely our intention and practice to
> post design docs as soon as they are ready, and short iteration cycles. As a
> matter of fact, we encourage design docs for major features posted before
> implementation starts, and WIP pull requests before they are fully baked for
> large features.
>
> That said, no, not 100% of a committer's time is on a specific ticket. There
> are lots of tickets that are open for a long time before somebody starts
> actively working on it. So no, it is not true that "all this time was active
> development". Xiangrui should post the design doc as soon as it is ready for
> feedback.
>
>
>
> On Sun, Sep 14, 2014 at 11:26 PM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>>
>> It's good, that databricks working on this issue! However current process
>> of working on that is not very clear for outsider.
>>
>> Last update on this ticket is August 5. If all this time was active
>> development, I have concerns that without feedback from community for such
>> long time development can fall in wrong way.
>> Even if it would be great big patch as soon as you introduce new
>> interfaces to community it would allow us to start working on our pipeline
>> code. It would allow us write algorithm in new paradigm instead of in lack
>> of any paradigms like it was before. It would allow us to help you transfer
>> old code to new paradigm.
>>
>> My main point - shorter iterations with more transparency.
>>
>> I think it would be good idea to create some pull request with code, which
>> you have so far, even if it doesn't pass tests, so just we can comment on it
>> before formulating it in design doc.
>>
>>
>> 2014-09-13 0:00 GMT+04:00 Patrick Wendell <pwendell@gmail.com>:
>>>
>>> We typically post design docs on JIRA's before major work starts. For
>>> instance, pretty sure SPARk-1856 will have a design doc posted
>>> shortly.
>>>
>>> On Fri, Sep 12, 2014 at 12:10 PM, Erik Erlandson <eje@redhat.com> wrote:
>>> >
>>> > Are interface designs being captured anywhere as documents that the
>>> > community can follow along with as the proposals evolve?
>>> >
>>> > I've worked on other open source projects where design docs were
>>> > published as "living documents" (e.g. on google docs, or etherpad, but the
>>> > particular mechanism isn't crucial).   FWIW, I found that to be a good way
>>> > to work in a community environment.
>>> >
>>> >
>>> > ----- Original Message -----
>>> >> Hi Egor,
>>> >>
>>> >> Thanks for the feedback! We are aware of some of the issues you
>>> >> mentioned and there are JIRAs created for them. Specifically, I'm
>>> >> pushing out the design on pipeline features and algorithm/model
>>> >> parameters this week. We can move our discussion to
>>> >> https://issues.apache.org/jira/browse/SPARK-1856 .
>>> >>
>>> >> It would be nice to make tests against interfaces. But it definitely
>>> >> needs more discussion before making PRs. For example, we discussed the
>>> >> learning interfaces in Christoph's PR
>>> >> (https://github.com/apache/spark/pull/2137/) but it takes time to
>>> >> reach a consensus, especially on interfaces. Hopefully all of us could
>>> >> benefit from the discussion. The best practice is to break down the
>>> >> proposal into small independent piece and discuss them on the JIRA
>>> >> before submitting PRs.
>>> >>
>>> >> For performance tests, there is a spark-perf package
>>> >> (https://github.com/databricks/spark-perf) and we added performance
>>> >> tests for MLlib in v1.1. But definitely more work needs to be done.
>>> >>
>>> >> The dev-list may not be a good place for discussion on the design,
>>> >> could you create JIRAs for each of the issues you pointed out, and we
>>> >> track the discussion on JIRA? Thanks!
>>> >>
>>> >> Best,
>>> >> Xiangrui
>>> >>
>>> >> On Fri, Sep 12, 2014 at 10:45 AM, Reynold Xin <rxin@databricks.com>
>>> >> wrote:
>>> >> > Xiangrui can comment more, but I believe Joseph and him are actually
>>> >> > working on standardize interface and pipeline feature for 1.2
>>> >> > release.
>>> >> >
>>> >> > On Fri, Sep 12, 2014 at 8:20 AM, Egor Pahomov
>>> >> > <pahomov.egor@gmail.com>
>>> >> > wrote:
>>> >> >
>>> >> >> Some architect suggestions on this matter -
>>> >> >> https://github.com/apache/spark/pull/2371
>>> >> >>
>>> >> >> 2014-09-12 16:38 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>>> >> >>
>>> >> >> > Sorry, I misswrote  - I meant learners part of framework - models
>>> >> >> > already
>>> >> >> > exists.
>>> >> >> >
>>> >> >> > 2014-09-12 15:53 GMT+04:00 Christoph Sawade <
>>> >> >> > christoph.sawade@googlemail.com>:
>>> >> >> >
>>> >> >> >> I totally agree, and we discovered also some drawbacks with the
>>> >> >> >> classification models implementation that are based on GLMs:
>>> >> >> >>
>>> >> >> >> - There is no distinction between predicting scores, classes,
>>> >> >> >> and
>>> >> >> >> calibrated scores (probabilities). For these models it is common
>>> >> >> >> to
>>> >> >> >> have
>>> >> >> >> access to all of them and the prediction function
>>> >> >> >> ``predict``should be
>>> >> >> >> consistent and stateless. Currently, the score is only available
>>> >> >> >> after
>>> >> >> >> removing the threshold from the model.
>>> >> >> >> - There is no distinction between multinomial and binomial
>>> >> >> >> classification. For multinomial problems, it is necessary to
>>> >> >> >> handle
>>> >> >> >> multiple weight vectors and multiple confidences.
>>> >> >> >> - Models are not serialisable, which makes it hard to use them
>>> >> >> >> in
>>> >> >> >> practise.
>>> >> >> >>
>>> >> >> >> I started a pull request [1] some time ago. I would be happy to
>>> >> >> >> continue
>>> >> >> >> the discussion and clarify the interfaces, too!
>>> >> >> >>
>>> >> >> >> Cheers, Christoph
>>> >> >> >>
>>> >> >> >> [1] https://github.com/apache/spark/pull/2137/
>>> >> >> >>
>>> >> >> >> 2014-09-12 11:11 GMT+02:00 Egor Pahomov
>>> >> >> >> <pahomov.egor@gmail.com>:
>>> >> >> >>
>>> >> >> >>> Here in Yandex, during implementation of gradient boosting in
>>> >> >> >>> spark
>>> >> >> >>> and
>>> >> >> >>> creating our ML tool for internal use, we found next serious
>>> >> >> >>> problems
>>> >> >> in
>>> >> >> >>> MLLib:
>>> >> >> >>>
>>> >> >> >>>
>>> >> >> >>>    - There is no Regression/Classification model abstraction.
>>> >> >> >>> We were
>>> >> >> >>>    building abstract data processing pipelines, which should
>>> >> >> >>> work just
>>> >> >> >>> with
>>> >> >> >>>    some regression - exact algorithm specified outside this
>>> >> >> >>> code.
>>> >> >> >>>    There
>>> >> >> >>> is no
>>> >> >> >>>    abstraction, which will allow me to do that. *(It's main
>>> >> >> >>> reason for
>>> >> >> >>> all
>>> >> >> >>>    further problems) *
>>> >> >> >>>    - There is no common practice among MLlib for testing
>>> >> >> >>> algorithms:
>>> >> >> >>> every
>>> >> >> >>>    model generates it's own random test data. There is no easy
>>> >> >> >>> extractable
>>> >> >> >>>    test cases applible to another algorithm. There is no
>>> >> >> >>> benchmarks
>>> >> >> >>>    for
>>> >> >> >>>    comparing algorithms. After implementing new algorithm it's
>>> >> >> >>> very
>>> >> >> hard
>>> >> >> >>> to
>>> >> >> >>>    understand how it should be tested.
>>> >> >> >>>    - Lack of serialization testing: MLlib algorithms don't
>>> >> >> >>> contain
>>> >> >> tests
>>> >> >> >>>    which test that model work after serialization.
>>> >> >> >>>    - During implementation of new algorithm it's hard to
>>> >> >> >>> understand
>>> >> >> what
>>> >> >> >>>    API you should create and which interface to implement.
>>> >> >> >>>
>>> >> >> >>> Start for solving all these problems must be done in creating
>>> >> >> >>> common
>>> >> >> >>> interface for typical algorithms/models - regression,
>>> >> >> >>> classification,
>>> >> >> >>> clustering, collaborative filtering.
>>> >> >> >>>
>>> >> >> >>> All main tests should be written against these interfaces, so
>>> >> >> >>> when new
>>> >> >> >>> algorithm implemented - all it should do is passed already
>>> >> >> >>> written
>>> >> >> tests.
>>> >> >> >>> It allow us to have managble quality among all lib.
>>> >> >> >>>
>>> >> >> >>> There should be couple benchmarks which allow new spark user to
>>> >> >> >>> get
>>> >> >> >>> feeling
>>> >> >> >>> about which algorithm to use.
>>> >> >> >>>
>>> >> >> >>> Test set against these abstractions should contain
>>> >> >> >>> serialization test.
>>> >> >> In
>>> >> >> >>> production most time there is no need in model, which can't be
>>> >> >> >>> stored.
>>> >> >> >>>
>>> >> >> >>> As the first step of this roadmap I'd like to create trait
>>> >> >> >>> RegressionModel,
>>> >> >> >>> *ADD* methods to current algorithms to implement this trait and
>>> >> >> >>> create
>>> >> >> >>> some
>>> >> >> >>> tests against it. Planning of doing it next week.
>>> >> >> >>>
>>> >> >> >>> Purpose of this letter is to collect any objections to this
>>> >> >> >>> approach
>>> >> >> >>> on
>>> >> >> >>> early stage: please give any feedback. Second reason is to set
>>> >> >> >>> lock on
>>> >> >> >>> this
>>> >> >> >>> activity so we wouldn't do the same thing twice: I'll create
>>> >> >> >>> pull
>>> >> >> request
>>> >> >> >>> by the end of the next week and any parallalizm in development
>>> >> >> >>> we can
>>> >> >> >>> start
>>> >> >> >>> from there.
>>> >> >> >>>
>>> >> >> >>>
>>> >> >> >>>
>>> >> >> >>> --
>>> >> >> >>>
>>> >> >> >>>
>>> >> >> >>>
>>> >> >> >>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>> >> >> >>>
>>> >> >> >>
>>> >> >> >>
>>> >> >> >
>>> >> >> >
>>> >> >> > --
>>> >> >> >
>>> >> >> >
>>> >> >> >
>>> >> >> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>> >> >> >
>>> >> >>
>>> >> >>
>>> >> >>
>>> >> >> --
>>> >> >>
>>> >> >>
>>> >> >>
>>> >> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>> >> >>
>>> >>
>>> >> ---------------------------------------------------------------------
>>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> >> For additional commands, e-mail: dev-help@spark.apache.org
>>> >>
>>> >>
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>
>>
>>
>>
>> --
>> Sincerely yours
>> Egor Pakhomov
>> Scala Developer, Yandex
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9487-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 07:07:03 2014
Return-Path: <dev-return-9487-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD7031139A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 07:07:03 +0000 (UTC)
Received: (qmail 16268 invoked by uid 500); 17 Sep 2014 07:07:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16193 invoked by uid 500); 17 Sep 2014 07:07:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16177 invoked by uid 99); 17 Sep 2014 07:07:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 07:07:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.42] (HELO mail-qg0-f42.google.com) (209.85.192.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 07:06:58 +0000
Received: by mail-qg0-f42.google.com with SMTP id q107so1321062qgd.1
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 00:06:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=0iusG3YDafwSlizCJTrVVKTrUI0P3TN2i9mPtEuxS54=;
        b=VzY/vrfhqsnwEiTVDEjXkVAWtVlKqlezG3RWXILj0CiFBG+ioGKynZqG1f4uAXd+44
         JbCZoiyuCbov20ij9K9FQw0nM50tEsuoo7xcN4OObQksxIanLocYThu1dkpGo8CZt8T2
         IqsMw/NJ5WN4XIayT1S9e0RehiwwRS+JM35oKtse6DDTfPqxmZm4NYb75+U+K/7+yCr6
         X0QvpFHUuKqfS/G2jUMas2+vbKhs7WBJJOjQUb5T+bYCaJDUEqqorhav8Pm67mD4oaOx
         HWREUBCXwgEzSIFuKo3kcdOjfdAKUk23o+MFBqq93wP0YlvLVprrcPof47cab8aoj64A
         T2QQ==
X-Gm-Message-State: ALoCoQlQ4pSIuZ5v84RPUl8HRkYQE5bJVB+OJ2H4K4HEnps90uGAS1841aiqSf8ihAGcDcRh25JG
X-Received: by 10.224.156.201 with SMTP id y9mr52963207qaw.53.1410937596683;
 Wed, 17 Sep 2014 00:06:36 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Wed, 17 Sep 2014 00:06:16 -0700 (PDT)
In-Reply-To: <tencent_72473F7E2E5E52F55A3BBD29@qq.com>
References: <tencent_72473F7E2E5E52F55A3BBD29@qq.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 17 Sep 2014 00:06:16 -0700
Message-ID: <CAPh_B=YF9X9B2XxsdH+mmS5HcyFqm6iFWUX0WhBE5M1jL27UXg@mail.gmail.com>
Subject: Re: Network Communication - Akka or more?
To: Trident <cwk32@vip.qq.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0149c9ea40de8005033d82f0
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149c9ea40de8005033d82f0
Content-Type: text/plain; charset=UTF-8

I'm not familiar with Infiniband, but I can chime in on the Spark part.

There are two kinds of communications in Spark: control plane and data
plane.  Task scheduling / dispatching is control, whereas fetching a block
(e.g. shuffle) is data.


On Tue, Sep 16, 2014 at 4:22 PM, Trident <cwk32@vip.qq.com> wrote:

> Thank you for reading this mail.
>
> I'm trying to change the underlying network connection system of Spark to
> support Infiniteband.
>
> 1. I doubt whether ConnectionManager and netty is under construction. It
> seems that they are not usually used.
>

They are used for data plane communication. Broadcast, shuffle, all use
them.



> 2. How much connection payload is carried by akka?
>

Akka is mainly responsible for control, i.e. dispatching tasks, reporting a
block being put into memory to the driver etc.



> 3. When running ./bin/run-example SparkPi   I noticed that the jar file
> has been sent from server to client. It is scary because the jar is big. Is
> it common?
>

How are you going to distribute the jar file if you don't send it? The
workers need to bytecode for those classes you are going to execute.

--089e0149c9ea40de8005033d82f0--

From dev-return-9488-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 07:21:49 2014
Return-Path: <dev-return-9488-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C7994113D8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 07:21:49 +0000 (UTC)
Received: (qmail 43154 invoked by uid 500); 17 Sep 2014 07:21:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43082 invoked by uid 500); 17 Sep 2014 07:21:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43068 invoked by uid 99); 17 Sep 2014 07:21:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 07:21:48 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 07:21:42 +0000
Received: by mail-qc0-f169.google.com with SMTP id r5so1535876qcx.28
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 00:21:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=JD+4KO31R12IUxny3/wzt6ccG4VZFiX/G60xpV+6miQ=;
        b=Ghm/nFRdJ0UeAumFXwW/j+x1nuUMstutYZhvtdaNPnKgwXbRSSnQEIMujyw+4u6a4t
         q28wF3Ck034tDaDtpXxUujf7/oZSpuAC8pZIUXCvS2H5tZH+rPbdkHNAjzl6tTk62vPb
         HjqQAtDKtrMUQvWlGwGESAvLcfwmIfZoVW5nkHyhycztLqeZpFU0/zKsdQVHHGLUZhws
         Ge6s/+41U+wMGi5CDTD9u0YLPTaK/8K2usIRnRSmJZf2hh0EOpsWV0owT6ZCnIZioHjm
         DCVQU8xRk0bYRBSxILvoBshe0ZM2d8x91mSu/z00ticAqmUKW8sO+YnPDF2DUeOzImTK
         BBLQ==
X-Gm-Message-State: ALoCoQk2XVGDdvHMMpo2LHhXKTvk8XX8Aq/Jjhso2IdAx0RPGp5F/oCCizCpAro5tuBdVFCAtxEg
X-Received: by 10.140.47.137 with SMTP id m9mr26184364qga.95.1410938481645;
 Wed, 17 Sep 2014 00:21:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Wed, 17 Sep 2014 00:21:01 -0700 (PDT)
In-Reply-To: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 17 Sep 2014 00:21:01 -0700
Message-ID: <CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c165d6ffb19605033db6bf
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c165d6ffb19605033db6bf
Content-Type: text/plain; charset=UTF-8

Hi Egor,

I think the design doc for the pipeline feature has been posted.

For the workflow, I believe Oozie actually works fine with Spark if you
want some external workflow system. Do you have any trouble using that?


On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <pahomov.egor@gmail.com>
wrote:

> There are two things we(Yandex) miss in Spark: MLlib good abstractions and
> good workflow job scheduler. From threads "Adding abstraction in MlLib" and
> "[mllib] State of Multi-Model training" I got the idea, that databricks
> working on it and we should wait until first post doc, which would lead us.
> What about workflow scheduler? Is there anyone already working on it? Does
> anyone have a plan on doing it?
>
> P.S. We thought that MLlib abstractions about multiple algorithms run with
> same data would need such scheduler, which would rerun algorithm in case of
> failure. I understand, that spark provide fault tolerance out of the box,
> but we found some "Ooozie-like" scheduler more reliable for such long
> living workflows.
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--001a11c165d6ffb19605033db6bf--

From dev-return-9489-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 09:00:34 2014
Return-Path: <dev-return-9489-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CF3981166F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 09:00:34 +0000 (UTC)
Received: (qmail 46967 invoked by uid 500); 17 Sep 2014 09:00:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46892 invoked by uid 500); 17 Sep 2014 09:00:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46868 invoked by uid 99); 17 Sep 2014 09:00:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:00:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pahomov.egor@gmail.com designates 209.85.192.49 as permitted sender)
Received: from [209.85.192.49] (HELO mail-qg0-f49.google.com) (209.85.192.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:00:07 +0000
Received: by mail-qg0-f49.google.com with SMTP id j5so1398790qga.22
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 02:00:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=pYJ+cIgYsqxpQdknxyJf/nvreKNnxB2XS95NCSDzWQE=;
        b=c/wbOHaWlVGPF9ub0Aq000LynO0vruTWVZDIKq8IymO0MIxo7K9JFO4j3Hcb+F58a0
         jfMHSrRw8tzaLK6eBV24DOvUe9tXcvMx3IFp0Ez9h8DHjVqAwe6csClRa4vZjATPRieg
         D/LDHY0wY6fzZci2KGECOEIMtIP6HXEr9PxGP0/MnreXFb8t2GM/GJW0MChK5/ouj7I3
         kThmaye7rMQuMMv8bRhzE9fhoADeyP9CmAPZdf9GThk703vDvPev0InVkvRysmfX0Gjp
         CHJ5w71OOQyjUIZ+6QM05e4iNX9vj2Mb3r+ifqWIdNoOSUZ7ZMsqSx+PVuTNvb9KiAam
         H6sg==
MIME-Version: 1.0
X-Received: by 10.140.31.133 with SMTP id f5mr41484580qgf.34.1410944406548;
 Wed, 17 Sep 2014 02:00:06 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Wed, 17 Sep 2014 02:00:06 -0700 (PDT)
In-Reply-To: <CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
	<CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
Date: Wed, 17 Sep 2014 13:00:06 +0400
Message-ID: <CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a933e267f1b05033f183d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a933e267f1b05033f183d
Content-Type: text/plain; charset=UTF-8

I have problems using Oozie. For example it doesn't sustain spark context
like ooyola job server does. Other than GUI interfaces like HUE it's hard
to work with - scoozie stopped in development year ago(I spoke with
creator) and oozie xml very hard to write.
Oozie still have all documentation and code in MR model rather than in yarn
model. And based on it's current speed of development I can't expect
radical changes in nearest future. There is no "Databricks" for oozie,
which would have people on salary to develop this kind of radical changes.
It's dinosaur.

Reunold, can you help finding this doc? Do you mean just pipelining spark
code or additional logic of persistence tasks, job server, task retry, data
availability and extra?


2014-09-17 11:21 GMT+04:00 Reynold Xin <rxin@databricks.com>:

> Hi Egor,
>
> I think the design doc for the pipeline feature has been posted.
>
> For the workflow, I believe Oozie actually works fine with Spark if you
> want some external workflow system. Do you have any trouble using that?
>
>
> On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>
>> There are two things we(Yandex) miss in Spark: MLlib good abstractions and
>> good workflow job scheduler. From threads "Adding abstraction in MlLib"
>> and
>> "[mllib] State of Multi-Model training" I got the idea, that databricks
>> working on it and we should wait until first post doc, which would lead
>> us.
>> What about workflow scheduler? Is there anyone already working on it? Does
>> anyone have a plan on doing it?
>>
>> P.S. We thought that MLlib abstractions about multiple algorithms run with
>> same data would need such scheduler, which would rerun algorithm in case
>> of
>> failure. I understand, that spark provide fault tolerance out of the box,
>> but we found some "Ooozie-like" scheduler more reliable for such long
>> living workflows.
>>
>> --
>>
>>
>>
>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>
>
>


-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a113a933e267f1b05033f183d--

From dev-return-9490-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 09:09:01 2014
Return-Path: <dev-return-9490-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CFA7A116BD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 09:09:01 +0000 (UTC)
Received: (qmail 65400 invoked by uid 500); 17 Sep 2014 09:09:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65325 invoked by uid 500); 17 Sep 2014 09:09:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65312 invoked by uid 99); 17 Sep 2014 09:09:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:09:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mark@clearstorydata.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:08:35 +0000
Received: by mail-wi0-f178.google.com with SMTP id ho1so790227wib.17
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 02:08:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=Qj0wy0eZl39qWCjnUv9XKGncmXoOqtafckUlLOnwXyU=;
        b=fPfN0f5YXp/hx1c6fAdQnGgYv0mZm817giT3sfccHSRKHX5jrmEeSdFRx4ETmVvSpu
         A5fUzcaILvV1MVgQhRcH2El3hIf7VmBuXkDDSGzgRXEWmR+Inr1QmpwX+dEzb+Dr9ekL
         Mb6vgeaWGp3oe/Q5ttibW5zd/c6uXAxUQFjeGiX0XCxkxdZWg88xAktj15hjAlvI+e3d
         IzJiao5fOXbHI7bV1E7Ht/u+jGdBp/SOE6HsMLzG9dACImnJvzs60xns742y2pRr8Yve
         mR2DFFMj2WCTdYC40qZQfk4bgKHLBEyNpBZ682tXtjrAS/be81OGH0lAAh5LjIG+LmjW
         PKEw==
X-Gm-Message-State: ALoCoQk7scJYYHowj9yo+/cWSQsS5MFiAs1rbjHoMz30lY+eW/2UdlSqcLLS17ogOCMjRmpx6Czz
MIME-Version: 1.0
X-Received: by 10.181.5.38 with SMTP id cj6mr39416194wid.53.1410944914130;
 Wed, 17 Sep 2014 02:08:34 -0700 (PDT)
Received: by 10.216.151.129 with HTTP; Wed, 17 Sep 2014 02:08:34 -0700 (PDT)
In-Reply-To: <CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
	<CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
	<CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
Date: Wed, 17 Sep 2014 02:08:34 -0700
Message-ID: <CAAsvFPkg1T3ATmbEjbrPN812LU4joFB433pVF47J_Nh0=bNg8w@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
From: Mark Hamstra <mark@clearstorydata.com>
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134d7fe67a27005033f36ce
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134d7fe67a27005033f36ce
Content-Type: text/plain; charset=UTF-8

See https://issues.apache.org/jira/browse/SPARK-3530 and this doc,
referenced in that JIRA:

https://docs.google.com/document/d/1rVwXRjWKfIb-7PI6b86ipytwbUH7irSNLF1_6dLmh8o/edit?usp=sharing

On Wed, Sep 17, 2014 at 2:00 AM, Egor Pahomov <pahomov.egor@gmail.com>
wrote:

> I have problems using Oozie. For example it doesn't sustain spark context
> like ooyola job server does. Other than GUI interfaces like HUE it's hard
> to work with - scoozie stopped in development year ago(I spoke with
> creator) and oozie xml very hard to write.
> Oozie still have all documentation and code in MR model rather than in yarn
> model. And based on it's current speed of development I can't expect
> radical changes in nearest future. There is no "Databricks" for oozie,
> which would have people on salary to develop this kind of radical changes.
> It's dinosaur.
>
> Reunold, can you help finding this doc? Do you mean just pipelining spark
> code or additional logic of persistence tasks, job server, task retry, data
> availability and extra?
>
>
> 2014-09-17 11:21 GMT+04:00 Reynold Xin <rxin@databricks.com>:
>
> > Hi Egor,
> >
> > I think the design doc for the pipeline feature has been posted.
> >
> > For the workflow, I believe Oozie actually works fine with Spark if you
> > want some external workflow system. Do you have any trouble using that?
> >
> >
> > On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <pahomov.egor@gmail.com>
> > wrote:
> >
> >> There are two things we(Yandex) miss in Spark: MLlib good abstractions
> and
> >> good workflow job scheduler. From threads "Adding abstraction in MlLib"
> >> and
> >> "[mllib] State of Multi-Model training" I got the idea, that databricks
> >> working on it and we should wait until first post doc, which would lead
> >> us.
> >> What about workflow scheduler? Is there anyone already working on it?
> Does
> >> anyone have a plan on doing it?
> >>
> >> P.S. We thought that MLlib abstractions about multiple algorithms run
> with
> >> same data would need such scheduler, which would rerun algorithm in case
> >> of
> >> failure. I understand, that spark provide fault tolerance out of the
> box,
> >> but we found some "Ooozie-like" scheduler more reliable for such long
> >> living workflows.
> >>
> >> --
> >>
> >>
> >>
> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >>
> >
> >
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--001a1134d7fe67a27005033f36ce--

From dev-return-9491-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 09:47:36 2014
Return-Path: <dev-return-9491-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DC24F117AF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 09:47:36 +0000 (UTC)
Received: (qmail 57669 invoked by uid 500); 17 Sep 2014 09:47:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57595 invoked by uid 500); 17 Sep 2014 09:47:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57578 invoked by uid 99); 17 Sep 2014 09:47:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:47:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.179 as permitted sender)
Received: from [209.85.216.179] (HELO mail-qc0-f179.google.com) (209.85.216.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 09:47:31 +0000
Received: by mail-qc0-f179.google.com with SMTP id i17so1681948qcy.10
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 02:47:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=zskm/EoJWHSsxkMMm/LuGIdMRDHKBGaHajMQZTR5V5E=;
        b=z6L3CQHwT1HzAYL03+v4pIGOyLFVEbdlRUWgQBjXn3EBAb/s8ypbI41LPjdhmQ34nV
         2LTPJdNJfhFckk7+k8hOJT0iaQKFYGkFnd8P3H+8s7j9xBZFjh5wsv3nWlRkPogIYl/f
         YPzL/+eRxMF7o5k1/gSQWVWIe13HEPdUM4MfwkMZMhXrlupj3J2aHxxtsFvRP9BLheT4
         /KKU2fzueobaLHSR16DiBHQUs9p8T6G53zKqreX4Z9ZX2wYO4znVhpN0vcQ9E+1U7pMw
         PvPXJzoS97TuruMYxhURGmEpW03Mg4Bb0mTh1mlwBbk72EqRDRunVOqRPya2t/Evl06l
         tieQ==
MIME-Version: 1.0
X-Received: by 10.224.163.83 with SMTP id z19mr55329404qax.68.1410947231116;
 Wed, 17 Sep 2014 02:47:11 -0700 (PDT)
Received: by 10.140.36.137 with HTTP; Wed, 17 Sep 2014 02:47:11 -0700 (PDT)
In-Reply-To: <CAAsvFPkg1T3ATmbEjbrPN812LU4joFB433pVF47J_Nh0=bNg8w@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
	<CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
	<CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
	<CAAsvFPkg1T3ATmbEjbrPN812LU4joFB433pVF47J_Nh0=bNg8w@mail.gmail.com>
Date: Wed, 17 Sep 2014 13:47:11 +0400
Message-ID: <CAMrx5DxOUJit8P-dLM7mousdMQxzZB=9shoLoK+yomnRhpE9gQ@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Mark Hamstra <mark@clearstorydata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01294f668215d305033fc07a
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01294f668215d305033fc07a
Content-Type: text/plain; charset=UTF-8

It's doc about MLLib pipeline functionality. What about oozie-like
workflow?

2014-09-17 13:08 GMT+04:00 Mark Hamstra <mark@clearstorydata.com>:

> See https://issues.apache.org/jira/browse/SPARK-3530 and this doc,
> referenced in that JIRA:
>
>
> https://docs.google.com/document/d/1rVwXRjWKfIb-7PI6b86ipytwbUH7irSNLF1_6dLmh8o/edit?usp=sharing
>
> On Wed, Sep 17, 2014 at 2:00 AM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>
>> I have problems using Oozie. For example it doesn't sustain spark context
>> like ooyola job server does. Other than GUI interfaces like HUE it's hard
>> to work with - scoozie stopped in development year ago(I spoke with
>> creator) and oozie xml very hard to write.
>> Oozie still have all documentation and code in MR model rather than in
>> yarn
>> model. And based on it's current speed of development I can't expect
>> radical changes in nearest future. There is no "Databricks" for oozie,
>> which would have people on salary to develop this kind of radical changes.
>> It's dinosaur.
>>
>> Reunold, can you help finding this doc? Do you mean just pipelining spark
>> code or additional logic of persistence tasks, job server, task retry,
>> data
>> availability and extra?
>>
>>
>> 2014-09-17 11:21 GMT+04:00 Reynold Xin <rxin@databricks.com>:
>>
>> > Hi Egor,
>> >
>> > I think the design doc for the pipeline feature has been posted.
>> >
>> > For the workflow, I believe Oozie actually works fine with Spark if you
>> > want some external workflow system. Do you have any trouble using that?
>> >
>> >
>> > On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <pahomov.egor@gmail.com>
>> > wrote:
>> >
>> >> There are two things we(Yandex) miss in Spark: MLlib good abstractions
>> and
>> >> good workflow job scheduler. From threads "Adding abstraction in MlLib"
>> >> and
>> >> "[mllib] State of Multi-Model training" I got the idea, that databricks
>> >> working on it and we should wait until first post doc, which would lead
>> >> us.
>> >> What about workflow scheduler? Is there anyone already working on it?
>> Does
>> >> anyone have a plan on doing it?
>> >>
>> >> P.S. We thought that MLlib abstractions about multiple algorithms run
>> with
>> >> same data would need such scheduler, which would rerun algorithm in
>> case
>> >> of
>> >> failure. I understand, that spark provide fault tolerance out of the
>> box,
>> >> but we found some "Ooozie-like" scheduler more reliable for such long
>> >> living workflows.
>> >>
>> >> --
>> >>
>> >>
>> >>
>> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>> >>
>> >
>> >
>>
>>
>> --
>>
>>
>>
>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>
>
>


-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--089e01294f668215d305033fc07a--

From dev-return-9492-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 10:43:52 2014
Return-Path: <dev-return-9492-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF5B911925
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 10:43:51 +0000 (UTC)
Received: (qmail 67720 invoked by uid 500); 17 Sep 2014 10:43:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67635 invoked by uid 500); 17 Sep 2014 10:43:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67620 invoked by uid 99); 17 Sep 2014 10:43:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 10:43:50 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wyphao.2007@163.com designates 220.181.13.22 as permitted sender)
Received: from [220.181.13.22] (HELO m13-22.163.com) (220.181.13.22)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 10:43:44 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:MIME-Version:Message-ID; bh=Ymfu/
	osHDxLwKAQ5grlMH0An6RT4XBm2lj3auXGLlXs=; b=Ipn/JP9e5CXZGf6LhGR0U
	96m6O8oMDPi4XQrghDLRhZE89L+S0UyaV7MlSz5nty3SB8SOBgz7KKNYaeUBAyKE
	93u2AB0vTGVVCMGWw4IQeh5fDZyGap552bbtz95t1tP7ubnCUQ1O/vTRg2rVugRA
	Ijrkg8NZvkX6jyr0bu1ApY=
Received: from wyphao.2007$163.com ( [211.151.238.51] ) by
 ajax-webmail-wmsvr22 (Coremail) ; Wed, 17 Sep 2014 18:43:14 +0800 (CST)
X-Originating-IP: [211.151.238.51]
Date: Wed, 17 Sep 2014 18:43:14 +0800 (CST)
From: "wyphao.2007" <wyphao.2007@163.com>
To: dev@spark.apache.org, "Reynold Xin" <rxin@databricks.com>
Subject: network.ConnectionManager error
X-Priority: 3
X-Mailer: Coremail Webmail Server Version SP_ntes V3.5 build
 20140725(28226.6623) Copyright (c) 2002-2014 www.mailtech.cn 163com
X-CM-CTRLDATA: qGX7kWZvb3Rlcl9odG09NDkyMTo4MQ==
Content-Type: multipart/alternative; 
	boundary="----=_Part_389255_945310329.1410950594543"
MIME-Version: 1.0
Message-ID: <648cdcc6.1f51.14883357fef.Coremail.wyphao.2007@163.com>
X-CM-TRANSID:FsGowAAXHbXCZRlU1ltWAA--.7857W
X-CM-SenderInfo: xz1sxtbrosiiqx6rljoofrz/xtbBRwgKKFO-rQZ25AABs5
X-Coremail-Antispam: 1U5529EdanIXcx71UUUUU7vcSsGvfC2KfnxnUU==
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_389255_945310329.1410950594543
Content-Type: text/plain; charset=GBK
Content-Transfer-Encoding: base64
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------=_Part_389255_945310329.1410950594543--


From dev-return-9493-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 15:44:56 2014
Return-Path: <dev-return-9493-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04E6011578
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 15:44:56 +0000 (UTC)
Received: (qmail 61583 invoked by uid 500); 17 Sep 2014 15:44:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61509 invoked by uid 500); 17 Sep 2014 15:44:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61498 invoked by uid 99); 17 Sep 2014 15:44:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 15:44:54 +0000
X-ASF-Spam-Status: No, hits=0.0 required=10.0
	tests=SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cc8678@icloud.com designates 17.164.110.66 as permitted sender)
Received: from [17.164.110.66] (HELO st13p29im-asmtp004.me.com) (17.164.110.66)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 15:44:49 +0000
Received: from [192.168.0.9]
 (c-50-148-161-96.hsd1.ca.comcast.net [50.148.161.96])
 by st13p29im-asmtp004.me.com
 (Oracle Communications Messaging Server 7u4-27.10(7.0.4.27.9) 64bit (built Jun
  6 2014)) with ESMTPSA id <0NC1004H7YE24920@st13p29im-asmtp004.me.com> for
 dev@spark.apache.org; Wed, 17 Sep 2014 15:44:28 +0000 (GMT)
X-Proofpoint-Virus-Version: vendor=fsecure
 engine=2.50.10432:5.12.52,1.0.28,0.0.0000
 definitions=2014-09-17_05:2014-09-17,2014-09-17,1970-01-01 signatures=0
X-Proofpoint-Spam-Details: rule=notspam policy=default score=0 spamscore=0
 suspectscore=9 phishscore=0 adultscore=0 bulkscore=0 classifier=spam adjust=0
 reason=mlx scancount=1 engine=7.0.1-1402240000 definitions=main-1409170128
References: <648cdcc6.1f51.14883357fef.Coremail.wyphao.2007@163.com>
MIME-version: 1.0 (1.0)
In-reply-to: <648cdcc6.1f51.14883357fef.Coremail.wyphao.2007@163.com>
Content-type: text/plain; charset=us-ascii
Content-transfer-encoding: quoted-printable
Message-id: <54C5C47B-0CEB-4CC3-A129-088282F35FF3@icloud.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>,
 Reynold Xin <rxin@databricks.com>
X-Mailer: iPad Mail (11D257)
From: Christian Chua <cc8678@icloud.com>
Subject: Re: network.ConnectionManager error
Date: Wed, 17 Sep 2014 08:44:26 -0700
To: "wyphao.2007" <wyphao.2007@163.com>
X-Virus-Checked: Checked by ClamAV on apache.org

I see the same thing.=20

A workaround is to put a Thread.sleep(5000) statement before sc.stop()

Let us know how it goes.=20



> On Sep 17, 2014, at 3:43 AM, "wyphao.2007" <wyphao.2007@163.com> wrote:
>=20
> Hi,  When I run spark job on yarn,and the job finished success,but I found=
 there are some error logs in the logfile as follow(the red color text):
>=20
>=20
> 14/09/17 18:25:03 INFO ui.SparkUI: Stopped Spark web UI at http://sparkser=
ver2.cn:63937
> 14/09/17 18:25:03 INFO scheduler.DAGScheduler: Stopping DAGScheduler
> 14/09/17 18:25:03 INFO cluster.YarnClusterSchedulerBackend: Shutting down a=
ll executors
> 14/09/17 18:25:03 INFO cluster.YarnClusterSchedulerBackend: Asking each ex=
ecutor to shut down
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing SendingConnecti=
on to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing ReceivingConnec=
tion to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:03 ERROR network.ConnectionManager: Corresponding SendingCo=
nnection to ConnectionManagerId(sparkserver2.cn,9072) not found
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing ReceivingConnec=
tion to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing SendingConnecti=
on to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing SendingConnecti=
on to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 INFO spark.MapOutputTrackerMasterActor: MapOutputTracker=
Actor stopped!
> 14/09/17 18:25:04 INFO network.ConnectionManager: Selector thread was inte=
rrupted!
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing SendingConnecti=
on to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing SendingConnecti=
on to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing ReceivingConnec=
tion to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:04 ERROR network.ConnectionManager: Corresponding SendingCo=
nnection to ConnectionManagerId(sparkserver2.cn,9072) not found
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing ReceivingConnec=
tion to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 ERROR network.ConnectionManager: Corresponding SendingCo=
nnection to ConnectionManagerId(sparkserver2.cn,14474) not found
> 14/09/17 18:25:04 WARN network.ConnectionManager: All connections not clea=
ned up
> 14/09/17 18:25:04 INFO network.ConnectionManager: ConnectionManager stoppe=
d
> 14/09/17 18:25:04 INFO storage.MemoryStore: MemoryStore cleared
> 14/09/17 18:25:04 INFO storage.BlockManager: BlockManager stopped
> 14/09/17 18:25:04 INFO storage.BlockManagerMaster: BlockManagerMaster stop=
ped
> 14/09/17 18:25:04 INFO spark.SparkContext: Successfully stopped SparkConte=
xt
> 14/09/17 18:25:04 INFO yarn.ApplicationMaster: Unregistering ApplicationMa=
ster with SUCCEEDED
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator: S=
hutting down remote daemon.
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator: R=
emote daemon shut down; proceeding with flushing remote transports.
> 14/09/17 18:25:04 INFO impl.AMRMClientImpl: Waiting for application to be s=
uccessfully unregistered.
> 14/09/17 18:25:04 INFO Remoting: Remoting shut down
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator: R=
emoting shut down.
>=20
>=20
> What is the cause of this error? My spark version is 1.1.0 &  hadoop versi=
on is 2.2.0.
> Thank you.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9494-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 16:49:24 2014
Return-Path: <dev-return-9494-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6223B119EE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 16:49:24 +0000 (UTC)
Received: (qmail 38981 invoked by uid 500); 17 Sep 2014 16:49:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38930 invoked by uid 500); 17 Sep 2014 16:49:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38919 invoked by uid 99); 17 Sep 2014 16:49:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 16:49:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kellrott@soe.ucsc.edu designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 16:48:56 +0000
Received: by mail-oi0-f52.google.com with SMTP id g201so1218679oib.11
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 09:48:55 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=xRQa6zBsi2oyMe0aqiAUPDFHHunMcz6flwkvjZHgpNM=;
        b=btowRtwjklt8tx2DFELr2YJr7VKq2/K4jDTiQSuOd1ZRyjRdZEwQsXX0iTZPfVaurM
         ap+IcU8PZ7rorFyHUnmLAYIhniloTR8Sm53EUpCKB//q1oJBfyWVNw2wuqmU6KXY7a6E
         ytRIhfFKmN+Laf5rfLgnKFTv0SfFXaw3t+7aDbLlzJ6kXEbS7Id0BCO3Q7X+O0D9hjwk
         OjThpRHTL8Eccj4IwIPw30ymRdZaNhgqlqeD/tUO2ltKX/RKBmlkaLvjPX2+0JmwlgX3
         V9UGkMavv9byEXUtkkP8WBNiLFeCDwzFJGVUKWDI8ygqOSlFuqkqa7rPPivon19ROUEI
         wK2g==
X-Gm-Message-State: ALoCoQkgYDoMxfx0unAuMdejzW6erR9XU0agbGRx3npNDGs8sabG5DpLL4RvBbE5LSqtKCST9/Nr
MIME-Version: 1.0
X-Received: by 10.182.142.67 with SMTP id ru3mr44451243obb.15.1410972534846;
 Wed, 17 Sep 2014 09:48:54 -0700 (PDT)
Received: by 10.182.78.234 with HTTP; Wed, 17 Sep 2014 09:48:54 -0700 (PDT)
In-Reply-To: <1631425729.3052157.1410931327952.JavaMail.zimbra@stanford.edu>
References: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com>
	<521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu>
	<CAKXMip3idBRKbd0zGgbvfBSN1x1k+nmFXzDx4FJLEoGjxOvZ-g@mail.gmail.com>
	<1631425729.3052157.1410931327952.JavaMail.zimbra@stanford.edu>
Date: Wed, 17 Sep 2014 09:48:54 -0700
Message-ID: <CAKXMip3ugno53v5M203gZHyC-qYA8b93Hs=790gJQVv9kT+k7w@mail.gmail.com>
Subject: Re: [mllib] State of Multi-Model training
From: Kyle Ellrott <kellrott@soe.ucsc.edu>
To: Burak Yavuz <byavuz@stanford.edu>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2eceabae85f050345a4a6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2eceabae85f050345a4a6
Content-Type: text/plain; charset=UTF-8

This sounds like a pretty major re-write of the system. Is it going to live
in an different repo during development? Or will we be able to track
progress in the main Spark repo?

Kyle

On Tue, Sep 16, 2014 at 10:22 PM, Burak Yavuz <byavuz@stanford.edu> wrote:

> Hi Kyle,
>
> Thank you for the code examples. We may be able to use some of the ideas
> there. I think initially the goal is to have the optimizers ready (SGD,
> LBFGS),
> and then the evaluation metrics will come next. It might take some time,
> however as MLlib is going to have a significant API "face-lift" (e.g.
> https://issues.apache.org/jira/browse/SPARK-3530). Evaluation metrics
> will be significant in the new "pipeline"s and the ability to evaluate
> multiple models
> efficiently is very important. We encourage you to read through the design
> docs, and we would appreciate any feedback from you and the rest of the
> community!
>
> Best,
> Burak
>
> ----- Original Message -----
> From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> To: "Burak Yavuz" <byavuz@stanford.edu>
> Cc: dev@spark.apache.org
> Sent: Tuesday, September 16, 2014 9:41:45 PM
> Subject: Re: [mllib] State of Multi-Model training
>
> I'd be interested in helping to test your code as soon as its available.
> The version I wrote used a paired RDD and combined by key, it worked best
> if it used a custom partitioner that put all the samples in the same area.
> Running things in batched matrices would probably speed things up greatly.
> You probably won't need my training code, but I did write some stuff
> related to calculating Binary classifications metric (
> https://github.com/apache/spark/pull/1292/files#diff-6) and AUC (
> https://github.com/apache/spark/pull/1292/files#diff-5) for multiple
> models
> that you might be able to use.
>
> Kyle
>
>
> On Tue, Sep 16, 2014 at 4:09 PM, Burak Yavuz <byavuz@stanford.edu> wrote:
>
> > Hi Kyle,
> >
> > I'm actively working on it now. It's pretty close to completion, I'm just
> > trying to figure out bottlenecks and optimize as much as possible.
> > As Phase 1, I implemented multi model training on Gradient Descent.
> > Instead of performing Vector-Vector operations on rows (examples) and
> > weights,
> > I've batched them into matrices so that we can use Level 3 BLAS to speed
> > things up. I've also added support for Sparse Matrices (
> > https://github.com/apache/spark/pull/2294) as making use of sparsity
> will
> > allow you to train more models at once.
> >
> > Best,
> > Burak
> >
> > ----- Original Message -----
> > From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> > To: dev@spark.apache.org
> > Sent: Tuesday, September 16, 2014 3:21:53 PM
> > Subject: [mllib] State of Multi-Model training
> >
> > I'm curious about the state of development Multi-Model learning in MLlib
> > (training sets of models during the same training session, rather then
> one
> > at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
> > https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't
> been
> > any notes on it in over a month.
> > I submitted a pull request for a possible method to do this work a little
> > over two months ago (https://github.com/apache/spark/pull/1292), but
> > haven't yet received any feedback on the patch yet.
> > Is anybody else working on multi-model training?
> >
> > Kyle
> >
> >
>
>

--001a11c2eceabae85f050345a4a6--

From dev-return-9495-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 16:54:28 2014
Return-Path: <dev-return-9495-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 997FE11A55
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 16:54:28 +0000 (UTC)
Received: (qmail 53166 invoked by uid 500); 17 Sep 2014 16:54:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53097 invoked by uid 500); 17 Sep 2014 16:54:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53085 invoked by uid 99); 17 Sep 2014 16:54:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 16:54:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.175] (HELO mail-qc0-f175.google.com) (209.85.216.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 16:54:22 +0000
Received: by mail-qc0-f175.google.com with SMTP id w7so2506100qcr.20
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 09:54:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=1u+8VbHcW5IAtOJB9+dcKjF+AGLhmoI32g+mW1bq5gM=;
        b=g9/gKh15kkw0KeBTRUeGt9b3AA/tJGF6bZLwZ9K7zvdEvcPGjAcHA15pcBDnO8g1OK
         d5EnbYdd7DsQbm5GqPRYujgGm+2X7k+nUxdli3ez89fBZRHz/ZR4ShwFq/pcS/jVnAE8
         zSPcQCDHVP7s8YKoKzHufM9U1TxSGYs/IfOVclWPOYnWDOWD6AgieQOn0ikMXppldbUT
         JXLwQOsxeDd4dgLethQUQOmOK56ZS2w1UV3A8LVFYGm5UCiJuFa/ys6BtJJwkfkhUFN0
         aYsvkoSdKc/rmxcavSqmW7gUsTDBCM9di4VbopDurLWPdpvXlz6J4sGiTIyQzhlOY9k8
         aEvw==
X-Gm-Message-State: ALoCoQlsKyML9xwZUcXBS4rQJIvu/S7aTyKTthyKU3K1I+0Z5Wi9rEmr/RMe/6zvFg05+eLakBaA
MIME-Version: 1.0
X-Received: by 10.224.126.202 with SMTP id d10mr56467521qas.22.1410972841527;
 Wed, 17 Sep 2014 09:54:01 -0700 (PDT)
Received: by 10.96.41.34 with HTTP; Wed, 17 Sep 2014 09:54:01 -0700 (PDT)
In-Reply-To: <648cdcc6.1f51.14883357fef.Coremail.wyphao.2007@163.com>
References: <648cdcc6.1f51.14883357fef.Coremail.wyphao.2007@163.com>
Date: Wed, 17 Sep 2014 09:54:01 -0700
Message-ID: <CAPh_B=ZuPOURZk1=WH-3xJFGaKFsNx=E=ay4ui-tDgBH6Fxv8Q@mail.gmail.com>
Subject: Re: network.ConnectionManager error
From: Reynold Xin <rxin@databricks.com>
To: "wyphao.2007" <wyphao.2007@163.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2dd1601edd8050345b702
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2dd1601edd8050345b702
Content-Type: text/plain; charset=UTF-8

This is during shutdown right? Looks ok to me since connections are being
closed. We could've handle this more gracefully, but the logs look
harmless.

On Wednesday, September 17, 2014, wyphao.2007 <wyphao.2007@163.com> wrote:

> Hi,  When I run spark job on yarn,and the job finished success,but I found
> there are some error logs in the logfile as follow(the red color text):
>
> 14/09/17 18:25:03 INFO ui.SparkUI: Stopped Spark web UI at
> http://sparkserver2.cn:63937
> 14/09/17 18:25:03 INFO scheduler.DAGScheduler: Stopping DAGScheduler
> 14/09/17 18:25:03 INFO cluster.YarnClusterSchedulerBackend: Shutting down
> all executors
> 14/09/17 18:25:03 INFO cluster.YarnClusterSchedulerBackend: Asking each
> executor to shut down
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing
> SendingConnection to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing
> ReceivingConnection to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:03 ERROR network.ConnectionManager: Corresponding
> SendingConnection to ConnectionManagerId(sparkserver2.cn,9072) not found
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing
> ReceivingConnection to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing
> SendingConnection to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:03 INFO network.ConnectionManager: Removing
> SendingConnection to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 INFO spark.MapOutputTrackerMasterActor:
> MapOutputTrackerActor stopped!
> 14/09/17 18:25:04 INFO network.ConnectionManager: Selector thread was
> interrupted!
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing
> SendingConnection to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing
> SendingConnection to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing
> ReceivingConnection to ConnectionManagerId(sparkserver2.cn,9072)
> 14/09/17 18:25:04 ERROR network.ConnectionManager: Corresponding
> SendingConnection to ConnectionManagerId(sparkserver2.cn,9072) not found
> 14/09/17 18:25:04 INFO network.ConnectionManager: Removing
> ReceivingConnection to ConnectionManagerId(sparkserver2.cn,14474)
> 14/09/17 18:25:04 ERROR network.ConnectionManager: Corresponding
> SendingConnection to ConnectionManagerId(sparkserver2.cn,14474) not found
> 14/09/17 18:25:04 WARN network.ConnectionManager: All connections not
> cleaned up
> 14/09/17 18:25:04 INFO network.ConnectionManager: ConnectionManager stopped
> 14/09/17 18:25:04 INFO storage.MemoryStore: MemoryStore cleared
> 14/09/17 18:25:04 INFO storage.BlockManager: BlockManager stopped
> 14/09/17 18:25:04 INFO storage.BlockManagerMaster: BlockManagerMaster
> stopped
> 14/09/17 18:25:04 INFO spark.SparkContext: Successfully stopped
> SparkContext
> 14/09/17 18:25:04 INFO yarn.ApplicationMaster: Unregistering
> ApplicationMaster with SUCCEEDED
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator:
> Shutting down remote daemon.
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator:
> Remote daemon shut down; proceeding with flushing remote transports.
> 14/09/17 18:25:04 INFO impl.AMRMClientImpl: Waiting for application to be
> successfully unregistered.
> 14/09/17 18:25:04 INFO Remoting: Remoting shut down
> 14/09/17 18:25:04 INFO remote.RemoteActorRefProvider$RemotingTerminator:
> Remoting shut down.
>
> What is the cause of this error? My spark version is 1.1.0 &  hadoop
> version is 2.2.0.
> Thank you.
>
>
>

--001a11c2dd1601edd8050345b702--

From dev-return-9496-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 18:29:34 2014
Return-Path: <dev-return-9496-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E9C451138C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 18:29:34 +0000 (UTC)
Received: (qmail 57379 invoked by uid 500); 17 Sep 2014 18:29:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57313 invoked by uid 500); 17 Sep 2014 18:29:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57302 invoked by uid 99); 17 Sep 2014 18:29:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 18:29:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.170] (HELO mail-qc0-f170.google.com) (209.85.216.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 18:29:07 +0000
Received: by mail-qc0-f170.google.com with SMTP id l6so2826289qcy.15
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 11:29:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=o0LKQntT6mPxx7PCh0sHkZh8XQlmjCPuy5ZRcc8zQGo=;
        b=ksaI2P4WzZ9e0lgvZhqrvt0OCEMKcMTHrourT7DDZzBbw33HcJtRbX1jr+l3OBoOR2
         3A260jGuGzN0vr5b7iQ9joEm68Zdvs/u5/GePhOo7WXzWIsmwlE8YEHEM85g5GOFWbk2
         zb8CAmPP7/t5Oe6xLzPNTHWBP3fh3MyfwdkX7VHH0wTTJ/OsuK0ZjEqQcquuhb+Gs32L
         6GU3kgFvkWKyDlDfxJqDg518xxi8Vxt04++9qgRlBDR9Mrer9RTq+Tg9mR921djPovpX
         R3NjFfQumODa1wYFhHRWR2C4dGrcs5mhwecpkcyBU1wN1WkSYnrzbuDXsCuj548dyXAV
         o1+A==
X-Gm-Message-State: ALoCoQmKadcKNkWflJH3j9Uhof96Y1wcUpdbOrw0/+XYawRxlD7oZyRKpB1BEpCgU5GZiFt9sP4M
X-Received: by 10.224.8.131 with SMTP id h3mr57218946qah.35.1410978515972;
 Wed, 17 Sep 2014 11:28:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Wed, 17 Sep 2014 11:28:15 -0700 (PDT)
In-Reply-To: <CAMrx5DxOUJit8P-dLM7mousdMQxzZB=9shoLoK+yomnRhpE9gQ@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
 <CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
 <CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
 <CAAsvFPkg1T3ATmbEjbrPN812LU4joFB433pVF47J_Nh0=bNg8w@mail.gmail.com> <CAMrx5DxOUJit8P-dLM7mousdMQxzZB=9shoLoK+yomnRhpE9gQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 17 Sep 2014 11:28:15 -0700
Message-ID: <CAPh_B=YKSX9EzjDb2Pf+tgikPEPyenU3BjTZE9PYyGmbXtY5YA@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
To: Egor Pahomov <pahomov.egor@gmail.com>
Cc: Mark Hamstra <mark@clearstorydata.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2be643bf4c30503470972
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2be643bf4c30503470972
Content-Type: text/plain; charset=UTF-8

There might've been some misunderstanding. I was referring to the MLlib
pipeline design doc when I said the design doc was posted, in response to
the first paragraph of your original email.


On Wed, Sep 17, 2014 at 2:47 AM, Egor Pahomov <pahomov.egor@gmail.com>
wrote:

> It's doc about MLLib pipeline functionality. What about oozie-like
> workflow?
>
> 2014-09-17 13:08 GMT+04:00 Mark Hamstra <mark@clearstorydata.com>:
>
> > See https://issues.apache.org/jira/browse/SPARK-3530 and this doc,
> > referenced in that JIRA:
> >
> >
> >
> https://docs.google.com/document/d/1rVwXRjWKfIb-7PI6b86ipytwbUH7irSNLF1_6dLmh8o/edit?usp=sharing
> >
> > On Wed, Sep 17, 2014 at 2:00 AM, Egor Pahomov <pahomov.egor@gmail.com>
> > wrote:
> >
> >> I have problems using Oozie. For example it doesn't sustain spark
> context
> >> like ooyola job server does. Other than GUI interfaces like HUE it's
> hard
> >> to work with - scoozie stopped in development year ago(I spoke with
> >> creator) and oozie xml very hard to write.
> >> Oozie still have all documentation and code in MR model rather than in
> >> yarn
> >> model. And based on it's current speed of development I can't expect
> >> radical changes in nearest future. There is no "Databricks" for oozie,
> >> which would have people on salary to develop this kind of radical
> changes.
> >> It's dinosaur.
> >>
> >> Reunold, can you help finding this doc? Do you mean just pipelining
> spark
> >> code or additional logic of persistence tasks, job server, task retry,
> >> data
> >> availability and extra?
> >>
> >>
> >> 2014-09-17 11:21 GMT+04:00 Reynold Xin <rxin@databricks.com>:
> >>
> >> > Hi Egor,
> >> >
> >> > I think the design doc for the pipeline feature has been posted.
> >> >
> >> > For the workflow, I believe Oozie actually works fine with Spark if
> you
> >> > want some external workflow system. Do you have any trouble using
> that?
> >> >
> >> >
> >> > On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <
> pahomov.egor@gmail.com>
> >> > wrote:
> >> >
> >> >> There are two things we(Yandex) miss in Spark: MLlib good
> abstractions
> >> and
> >> >> good workflow job scheduler. From threads "Adding abstraction in
> MlLib"
> >> >> and
> >> >> "[mllib] State of Multi-Model training" I got the idea, that
> databricks
> >> >> working on it and we should wait until first post doc, which would
> lead
> >> >> us.
> >> >> What about workflow scheduler? Is there anyone already working on it?
> >> Does
> >> >> anyone have a plan on doing it?
> >> >>
> >> >> P.S. We thought that MLlib abstractions about multiple algorithms run
> >> with
> >> >> same data would need such scheduler, which would rerun algorithm in
> >> case
> >> >> of
> >> >> failure. I understand, that spark provide fault tolerance out of the
> >> box,
> >> >> but we found some "Ooozie-like" scheduler more reliable for such long
> >> >> living workflows.
> >> >>
> >> >> --
> >> >>
> >> >>
> >> >>
> >> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >> >>
> >> >
> >> >
> >>
> >>
> >> --
> >>
> >>
> >>
> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >>
> >
> >
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>

--001a11c2be643bf4c30503470972--

From dev-return-9497-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 20:16:18 2014
Return-Path: <dev-return-9497-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 03631118F7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 20:16:18 +0000 (UTC)
Received: (qmail 26457 invoked by uid 500); 17 Sep 2014 20:16:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26405 invoked by uid 500); 17 Sep 2014 20:16:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26394 invoked by uid 99); 17 Sep 2014 20:16:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 20:16:15 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of byavuz@stanford.edu designates 171.67.219.83 as permitted sender)
Received: from [171.67.219.83] (HELO smtp.stanford.edu) (171.67.219.83)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 20:15:49 +0000
Received: from codegreen1.stanford.edu (codegreen1.Stanford.EDU [171.67.224.2])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by smtp.stanford.edu (Postfix) with ESMTPS id 84F181017D9;
	Wed, 17 Sep 2014 13:15:45 -0700 (PDT)
Received: from codegreen1.stanford.edu (localhost.localdomain [127.0.0.1])
	by codegreen1.stanford.edu (Postfix) with ESMTP id 69FEF85;
	Wed, 17 Sep 2014 13:15:45 -0700 (PDT)
Received: from smtp.stanford.edu (smtp2.Stanford.EDU [171.67.219.82])
	(using TLSv1 with cipher ADH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by codegreen1.stanford.edu (Postfix) with ESMTP id 539E585;
	Wed, 17 Sep 2014 13:15:45 -0700 (PDT)
Received: from smtp.stanford.edu (localhost [127.0.0.1])
	by localhost (Postfix) with SMTP id 4022C341021;
	Wed, 17 Sep 2014 13:15:45 -0700 (PDT)
Received: from zm01.stanford.edu (zm01.Stanford.EDU [171.67.219.145])
	by smtp.stanford.edu (Postfix) with ESMTP id 0750F341AA5;
	Wed, 17 Sep 2014 13:15:45 -0700 (PDT)
Date: Wed, 17 Sep 2014 13:15:44 -0700 (PDT)
From: Burak Yavuz <byavuz@stanford.edu>
To: Kyle Ellrott <kellrott@soe.ucsc.edu>
Cc: dev@spark.apache.org
Message-ID: <1218696076.3939019.1410984944965.JavaMail.zimbra@stanford.edu>
In-Reply-To: <CAKXMip3ugno53v5M203gZHyC-qYA8b93Hs=790gJQVv9kT+k7w@mail.gmail.com>
References: <CAKXMip2LQnajm6EDhes9MFnHq_eNiv+bnf5XkvCPkzfE2nhpnA@mail.gmail.com> <521529102.2737999.1410908967258.JavaMail.zimbra@stanford.edu> <CAKXMip3idBRKbd0zGgbvfBSN1x1k+nmFXzDx4FJLEoGjxOvZ-g@mail.gmail.com> <1631425729.3052157.1410931327952.JavaMail.zimbra@stanford.edu> <CAKXMip3ugno53v5M203gZHyC-qYA8b93Hs=790gJQVv9kT+k7w@mail.gmail.com>
Subject: Re: [mllib] State of Multi-Model training
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [67.164.94.237]
X-Mailer: Zimbra 8.0.7_GA_6021 (ZimbraWebClient - GC37 (Mac)/8.0.7_GA_6021)
X-Authenticated-User: byavuz@stanford.edu
Thread-Topic: State of Multi-Model training
Thread-Index: 0uV3mY3dA+X/C8AkZ5ntz8ZBGUu6Tg==
X-Virus-Checked: Checked by ClamAV on apache.org

I believe it will be in the main repo.

Burak

----- Original Message -----
From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
To: "Burak Yavuz" <byavuz@stanford.edu>
Cc: dev@spark.apache.org
Sent: Wednesday, September 17, 2014 9:48:54 AM
Subject: Re: [mllib] State of Multi-Model training

This sounds like a pretty major re-write of the system. Is it going to live
in an different repo during development? Or will we be able to track
progress in the main Spark repo?

Kyle

On Tue, Sep 16, 2014 at 10:22 PM, Burak Yavuz <byavuz@stanford.edu> wrote:

> Hi Kyle,
>
> Thank you for the code examples. We may be able to use some of the ideas
> there. I think initially the goal is to have the optimizers ready (SGD,
> LBFGS),
> and then the evaluation metrics will come next. It might take some time,
> however as MLlib is going to have a significant API "face-lift" (e.g.
> https://issues.apache.org/jira/browse/SPARK-3530). Evaluation metrics
> will be significant in the new "pipeline"s and the ability to evaluate
> multiple models
> efficiently is very important. We encourage you to read through the design
> docs, and we would appreciate any feedback from you and the rest of the
> community!
>
> Best,
> Burak
>
> ----- Original Message -----
> From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> To: "Burak Yavuz" <byavuz@stanford.edu>
> Cc: dev@spark.apache.org
> Sent: Tuesday, September 16, 2014 9:41:45 PM
> Subject: Re: [mllib] State of Multi-Model training
>
> I'd be interested in helping to test your code as soon as its available.
> The version I wrote used a paired RDD and combined by key, it worked best
> if it used a custom partitioner that put all the samples in the same area.
> Running things in batched matrices would probably speed things up greatly.
> You probably won't need my training code, but I did write some stuff
> related to calculating Binary classifications metric (
> https://github.com/apache/spark/pull/1292/files#diff-6) and AUC (
> https://github.com/apache/spark/pull/1292/files#diff-5) for multiple
> models
> that you might be able to use.
>
> Kyle
>
>
> On Tue, Sep 16, 2014 at 4:09 PM, Burak Yavuz <byavuz@stanford.edu> wrote:
>
> > Hi Kyle,
> >
> > I'm actively working on it now. It's pretty close to completion, I'm just
> > trying to figure out bottlenecks and optimize as much as possible.
> > As Phase 1, I implemented multi model training on Gradient Descent.
> > Instead of performing Vector-Vector operations on rows (examples) and
> > weights,
> > I've batched them into matrices so that we can use Level 3 BLAS to speed
> > things up. I've also added support for Sparse Matrices (
> > https://github.com/apache/spark/pull/2294) as making use of sparsity
> will
> > allow you to train more models at once.
> >
> > Best,
> > Burak
> >
> > ----- Original Message -----
> > From: "Kyle Ellrott" <kellrott@soe.ucsc.edu>
> > To: dev@spark.apache.org
> > Sent: Tuesday, September 16, 2014 3:21:53 PM
> > Subject: [mllib] State of Multi-Model training
> >
> > I'm curious about the state of development Multi-Model learning in MLlib
> > (training sets of models during the same training session, rather then
> one
> > at a time). The JIRA lists it as in progress targeting Spark 1.2.0 (
> > https://issues.apache.org/jira/browse/SPARK-1486 ). But there hasn't
> been
> > any notes on it in over a month.
> > I submitted a pull request for a possible method to do this work a little
> > over two months ago (https://github.com/apache/spark/pull/1292), but
> > haven't yet received any feedback on the patch yet.
> > Is anybody else working on multi-model training?
> >
> > Kyle
> >
> >
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9498-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 17 23:51:55 2014
Return-Path: <dev-return-9498-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 30DA21130B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 17 Sep 2014 23:51:55 +0000 (UTC)
Received: (qmail 27315 invoked by uid 500); 17 Sep 2014 23:51:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27179 invoked by uid 500); 17 Sep 2014 23:51:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26285 invoked by uid 99); 17 Sep 2014 23:51:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 23:51:52 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 216.145.54.173 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 17 Sep 2014 23:51:26 +0000
Received: from GQ1-EX10-CAHT15.y.corp.yahoo.com (gq1-ex10-caht15.corp.gq1.yahoo.com [10.73.119.196])
	by mrout3.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8HNonjx052878
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Wed, 17 Sep 2014 16:50:50 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT15.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Wed, 17
 Sep 2014 16:50:49 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: problem with HiveContext inside Actor
Thread-Topic: problem with HiveContext inside Actor
Thread-Index: AQHP0tI0aQTvx5a6e0qIRgutfaZbnA==
Date: Wed, 17 Sep 2014 23:50:49 +0000
Message-ID: <D03F6C67.39E1%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D03F6C6739E1liduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 997850001
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D03F6C6739E1liduyahooinccom_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi,

Wonder anybody had similar experience or any suggestion here.

I have an akka Actor that processes database requests in high-level message=
s. Inside this Actor, it creates a HiveContext object that does the actual =
db work. The main thread creates the needed SparkContext and passes in to t=
he Actor to create the HiveContext.

When a message is sent to the Actor, it is processed properly except that, =
when the message triggers the HiveContext to create a database, it throws a=
 NullPointerException in hive.ql.Driver.java which suggests that its conf v=
ariable is not initialized.

Ironically, it works fine if my main thread directly calls actor.hiveContex=
t to create the database. The spark version is 1.1.0.

Thanks,
Du

--_000_D03F6C6739E1liduyahooinccom_--

From dev-return-9499-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 01:52:27 2014
Return-Path: <dev-return-9499-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D19E111656
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 01:52:27 +0000 (UTC)
Received: (qmail 31338 invoked by uid 500); 18 Sep 2014 01:52:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31188 invoked by uid 500); 18 Sep 2014 01:52:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30806 invoked by uid 99); 18 Sep 2014 01:52:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 01:52:26 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of xiaodi@sjtu.edu.cn designates 202.112.26.52 as permitted sender)
Received: from [202.112.26.52] (HELO proxy01.sjtu.edu.cn) (202.112.26.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 01:52:19 +0000
Received: from proxy03.sjtu.edu.cn (unknown [202.121.179.33])
	by proxy01.sjtu.edu.cn (Postfix) with ESMTP id C483C261329;
	Thu, 18 Sep 2014 09:51:56 +0800 (CST)
Received: from localhost (localhost [127.0.0.1])
	by proxy03.sjtu.edu.cn (Postfix) with ESMTP id AD772260BCD;
	Thu, 18 Sep 2014 09:51:56 +0800 (GMT-8)
X-Virus-Scanned: amavisd-new at 
Received: from proxy03.sjtu.edu.cn ([127.0.0.1])
	by localhost (proxy03.sjtu.edu.cn [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id kTs9igyIqtZG; Thu, 18 Sep 2014 09:51:56 +0800 (GMT-8)
Received: from loca.ipads-lab.se.sjtu.edu.cn (unknown [202.120.40.83])
	(Authenticated sender: xiaodi)
	by proxy03.sjtu.edu.cn (Postfix) with ESMTPSA id 7FD67260B2E;
	Thu, 18 Sep 2014 09:51:56 +0800 (GMT-8)
Message-ID: <541A3AB9.3060502@sjtu.edu.cn>
Date: Thu, 18 Sep 2014 09:51:53 +0800
From: Larry Xiao <xiaodi@sjtu.edu.cn>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.0
MIME-Version: 1.0
To: ankurdave@gmail.com
CC: dev@spark.apache.org, xiaodi@sjtu.edu.cn
Subject: Re: GraphX graph partitioning strategy
References: <53D0AECE.2070608@sjtu.edu.cn>
In-Reply-To: <53D0AECE.2070608@sjtu.edu.cn>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Ankur, all,

I've implemented few graph partitioning algorithms, and done some 
evaluation.
The goal is to lower replication factor and produce better balanced 
graph, so to make work load more balance.
Detailed description and result: 
https://issues.apache.org/jira/browse/SPARK-3523

Can you help take a look?
Thank you!

Larry

On 7/24/14 2:59 PM, Larry Xiao wrote:
> Hi all,
>
> I'm implementing graph partitioning strategy for GraphX, learning from 
> researches on graph computing.
>
> I have two questions:
>
> - a specific implement question:
> In current design, only vertex ID of src and dst are provided 
> (PartitionStrategy.scala).
> And some strategies require knowledge about the graph (like degrees) 
> and can consist more than one passes to finally produce the partition ID.
> So I'm changing the PartitionStrategy.getPartition API to provide more 
> info, but I don't want to make it complex. (the current one looks very 
> clean)
>
> - an open question:
> What advice would you give considering partitioning, considering the 
> procedure Spark adopt on graph processing?
>
> Any advice is much appreciated.
>
> Best Regards,
> Larry Xiao
>
> Reference
>
> Bipartite-oriented Distributed Graph Partitioning for Big Learning.
> PowerLyra: Differentiated Graph Computation and Partitioning on 
> Skewed Graphs
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9500-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 02:22:09 2014
Return-Path: <dev-return-9500-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9AE111713
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 02:22:09 +0000 (UTC)
Received: (qmail 94072 invoked by uid 500); 18 Sep 2014 02:22:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94011 invoked by uid 500); 18 Sep 2014 02:22:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92826 invoked by uid 99); 18 Sep 2014 02:22:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 02:22:00 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hao.cheng@intel.com designates 192.55.52.115 as permitted sender)
Received: from [192.55.52.115] (HELO mga14.intel.com) (192.55.52.115)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 02:21:55 +0000
Received: from fmsmga003.fm.intel.com ([10.253.24.29])
  by fmsmga103.fm.intel.com with ESMTP; 17 Sep 2014 19:12:41 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.97,862,1389772800"; 
   d="scan'208,217";a="387809173"
Received: from fmsmsx104.amr.corp.intel.com ([10.18.124.202])
  by FMSMGA003.fm.intel.com with ESMTP; 17 Sep 2014 19:16:02 -0700
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 fmsmsx104.amr.corp.intel.com (10.18.124.202) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Wed, 17 Sep 2014 19:21:33 -0700
Received: from shsmsx102.ccr.corp.intel.com ([169.254.2.192]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.172]) with mapi id 14.03.0195.001;
 Thu, 18 Sep 2014 10:21:30 +0800
From: "Cheng, Hao" <hao.cheng@intel.com>
To: Du Li <lidu@yahoo-inc.com.INVALID>, "user@spark.apache.org"
	<user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: problem with HiveContext inside Actor
Thread-Topic: problem with HiveContext inside Actor
Thread-Index: AQHP0tI0aQTvx5a6e0qIRgutfaZbnJwGJy6g
Date: Thu, 18 Sep 2014 02:21:29 +0000
Message-ID: <80833ADD533E324CA05C160E41B6366102758F28@shsmsx102.ccr.corp.intel.com>
References: <D03F6C67.39E1%lidu@yahoo-inc.com>
In-Reply-To: <D03F6C67.39E1%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: multipart/alternative;
	boundary="_000_80833ADD533E324CA05C160E41B6366102758F28shsmsx102ccrcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_80833ADD533E324CA05C160E41B6366102758F28shsmsx102ccrcor_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi, Du
I am not sure what you mean "triggers the HiveContext to create a database"=
, do you create the sub class of HiveContext? Just be sure you call the "Hi=
veContext.sessionState" eagerly, since it will set the proper "hiveconf" in=
to the SessionState, otherwise the HiveDriver will always get the null valu=
e when retrieving HiveConf.

Cheng Hao

From: Du Li [mailto:lidu@yahoo-inc.com.INVALID]
Sent: Thursday, September 18, 2014 7:51 AM
To: user@spark.apache.org; dev@spark.apache.org
Subject: problem with HiveContext inside Actor

Hi,

Wonder anybody had similar experience or any suggestion here.

I have an akka Actor that processes database requests in high-level message=
s. Inside this Actor, it creates a HiveContext object that does the actual =
db work. The main thread creates the needed SparkContext and passes in to t=
he Actor to create the HiveContext.

When a message is sent to the Actor, it is processed properly except that, =
when the message triggers the HiveContext to create a database, it throws a=
 NullPointerException in hive.ql.Driver.java which suggests that its conf v=
ariable is not initialized.

Ironically, it works fine if my main thread directly calls actor.hiveContex=
t to create the database. The spark version is 1.1.0.

Thanks,
Du

--_000_80833ADD533E324CA05C160E41B6366102758F28shsmsx102ccrcor_--

From dev-return-9501-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 02:41:33 2014
Return-Path: <dev-return-9501-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EA3A1175A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 02:41:33 +0000 (UTC)
Received: (qmail 33109 invoked by uid 500); 18 Sep 2014 02:41:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33036 invoked by uid 500); 18 Sep 2014 02:41:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33024 invoked by uid 99); 18 Sep 2014 02:41:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 02:41:32 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 02:41:27 +0000
Received: by mail-lb0-f174.google.com with SMTP id l4so265572lbv.19
        for <dev@spark.apache.org>; Wed, 17 Sep 2014 19:41:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=JtwMw37hLz6i5kMHddNaprokPLjkRcIliLbVdlwJ+/o=;
        b=Sh7ajgbBzQ/KL9gIIzu7HJMMLEYi2+rk7O0N0ss/nvmJ+tGJi62AbNXNvdPJvFxlk+
         Zk+6DzD6/wmb8d7PnNQdR1sVtp+u9LdifSdwfewI/Bmm1CyhLRXIvlY4QbKzXYApbIXb
         uSFppAd6FxYJ4S/rQ2VYrrCh+pX3uQUSo+VouR8hkPtH7ANx7srs534HZdTS7ybs4/D2
         WVRG27YI8Zgl67mVdTPj4SpHA8sl4sOmGId+i1n5XRUnAzd6Oh84q3C81EFX+DTnynqt
         G5Gehv+SbDuxNzREx/WQOTOpBAwMPfk0Z3ZHnO+evLqwgzzzM5abSKXjkz4gKPHBVmlS
         xnyA==
X-Gm-Message-State: ALoCoQkQxE6gpiVE1JO6a35hgXz8+jLSongApLkVNz/4UQPGtsQWIK1ue3yRcUOFQ3UnGDbt/piZ
X-Received: by 10.112.128.228 with SMTP id nr4mr1137509lbb.42.1411008065562;
 Wed, 17 Sep 2014 19:41:05 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.30.5 with HTTP; Wed, 17 Sep 2014 19:40:45 -0700 (PDT)
In-Reply-To: <80833ADD533E324CA05C160E41B6366102758F28@shsmsx102.ccr.corp.intel.com>
References: <D03F6C67.39E1%lidu@yahoo-inc.com> <80833ADD533E324CA05C160E41B6366102758F28@shsmsx102.ccr.corp.intel.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 17 Sep 2014 19:40:45 -0700
Message-ID: <CAAswR-6eY=mC0-qYvW1Buh_yXXiDtLgOW2mgzKpXPdOizrcXpA@mail.gmail.com>
Subject: Re: problem with HiveContext inside Actor
To: "Cheng, Hao" <hao.cheng@intel.com>
Cc: Du Li <lidu@yahoo-inc.com.invalid>, 
	"user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a841885fc0205034dea47
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a841885fc0205034dea47
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

- dev

Is it possible that you are constructing more than one HiveContext in a
single JVM?  Due to global state in Hive code this is not allowed.

Michael

On Wed, Sep 17, 2014 at 7:21 PM, Cheng, Hao <hao.cheng@intel.com> wrote:

>  Hi, Du
>
> I am not sure what you mean =E2=80=9Ctriggers the HiveContext to create a
> database=E2=80=9D, do you create the sub class of HiveContext? Just be su=
re you
> call the =E2=80=9CHiveContext.sessionState=E2=80=9D eagerly, since it wil=
l set the proper
> =E2=80=9Chiveconf=E2=80=9D into the SessionState, otherwise the HiveDrive=
r will always get
> the null value when retrieving HiveConf.
>
>
>
> Cheng Hao
>
>
>
> *From:* Du Li [mailto:lidu@yahoo-inc.com.INVALID]
> *Sent:* Thursday, September 18, 2014 7:51 AM
> *To:* user@spark.apache.org; dev@spark.apache.org
> *Subject:* problem with HiveContext inside Actor
>
>
>
> Hi,
>
>
>
> Wonder anybody had similar experience or any suggestion here.
>
>
>
> I have an akka Actor that processes database requests in high-level
> messages. Inside this Actor, it creates a HiveContext object that does th=
e
> actual db work. The main thread creates the needed SparkContext and passe=
s
> in to the Actor to create the HiveContext.
>
>
>
> When a message is sent to the Actor, it is processed properly except that=
,
> when the message triggers the HiveContext to create a database, it throws=
 a
> NullPointerException in hive.ql.Driver.java which suggests that its conf
> variable is not initialized.
>
>
>
> Ironically, it works fine if my main thread directly calls
> actor.hiveContext to create the database. The spark version is 1.1.0.
>
>
>
> Thanks,
>
> Du
>

--047d7b3a841885fc0205034dea47--

From dev-return-9502-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 14:57:42 2014
Return-Path: <dev-return-9502-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7810511BBB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 14:57:42 +0000 (UTC)
Received: (qmail 6984 invoked by uid 500); 18 Sep 2014 14:57:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6911 invoked by uid 500); 18 Sep 2014 14:57:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6900 invoked by uid 99); 18 Sep 2014 14:57:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 14:57:41 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 14:57:16 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XUd90-0003t5-VX
	for dev@spark.incubator.apache.org; Thu, 18 Sep 2014 07:57:14 -0700
Date: Thu, 18 Sep 2014 07:57:14 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411052234918-8471.post@n3.nabble.com>
Subject: Spark spilling location
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

Just one line of context, since last post mentioned this would help:
I'm currently writing my masters thesis (Computer Engineering) on storage
and memory in both Spark and Hadoop.

Right now I'm trying to analyze the spilling behavior of Spark, and I do not
see what I expect. Therefor, I want to be sure that I am looking at the
correct location.

If I set spark.local.dir and SPARK_LOCAL_DIRS to, for instance, ~/temp
instead of /tmp. Will this be the location where all data will be spilled
to? I assume it is, based on the description of spark.local.dir at
https://spark.apache.org/docs/latest/configuration.html:
"Directory to use for "scratch" space in Spark, including map output files
and RDDs that get stored on disk."

Thanks!



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-spilling-location-tp8471.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9503-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 17:08:36 2014
Return-Path: <dev-return-9503-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CBCC911064
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 17:08:36 +0000 (UTC)
Received: (qmail 96285 invoked by uid 500); 18 Sep 2014 17:08:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96222 invoked by uid 500); 18 Sep 2014 17:08:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95737 invoked by uid 99); 18 Sep 2014 17:08:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 17:08:35 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.213.169 as permitted sender)
Received: from [209.85.213.169] (HELO mail-ig0-f169.google.com) (209.85.213.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 17:08:30 +0000
Received: by mail-ig0-f169.google.com with SMTP id l13so31215iga.2
        for <dev@spark.incubator.apache.org>; Thu, 18 Sep 2014 10:08:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=uP23uWr0UAhsl7a/uTWDRYkG+2Ti5Yh/cBD7LpDS89M=;
        b=pefwTBa6edU5J3N0EaYK90TlLb2zVr1ZJs/aXm90wlH/dCYSefQ9lAzoplDucLqt76
         SUZs461nRToLYzT3Sv9ich3K5ANE7CW0HiOMb3PzFbPBRKjHIgstfrjCYJT3PsnAbLU6
         dCCx3Ssc5ky12oQWQXugtReWllf8N+v7W5rXa3dsWvxJvKga2c84HJiBlSZaAejzCy2r
         1Lle1JQ6v/KCdb33MytOMQHdFqSJ7P6KDXKgRZnygYNdyGM0yguDz/Qvk7fNmA/6bYk3
         Ixq7uCx+g/DkyywfLtSjzo33sOGXk2vNpXRRcC4WQqmlfpZWks9FFyrUKZlkeNOL7C9v
         4ATw==
MIME-Version: 1.0
X-Received: by 10.42.161.198 with SMTP id u6mr13979648icx.31.1411060089702;
 Thu, 18 Sep 2014 10:08:09 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Thu, 18 Sep 2014 10:08:09 -0700 (PDT)
In-Reply-To: <1411052234918-8471.post@n3.nabble.com>
References: <1411052234918-8471.post@n3.nabble.com>
Date: Thu, 18 Sep 2014 10:08:09 -0700
Message-ID: <CABPQxssKK1fFLNpNzCvLoWUafaaDB6NEb19S8uavBRcYy120Tg@mail.gmail.com>
Subject: Re: Spark spilling location
From: Patrick Wendell <pwendell@gmail.com>
To: Tom Hubregtsen <thubregtsen@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Yes - I believe we use the local dirs for spilling as well.

On Thu, Sep 18, 2014 at 7:57 AM, Tom Hubregtsen <thubregtsen@gmail.com> wrote:
> Hi all,
>
> Just one line of context, since last post mentioned this would help:
> I'm currently writing my masters thesis (Computer Engineering) on storage
> and memory in both Spark and Hadoop.
>
> Right now I'm trying to analyze the spilling behavior of Spark, and I do not
> see what I expect. Therefor, I want to be sure that I am looking at the
> correct location.
>
> If I set spark.local.dir and SPARK_LOCAL_DIRS to, for instance, ~/temp
> instead of /tmp. Will this be the location where all data will be spilled
> to? I assume it is, based on the description of spark.local.dir at
> https://spark.apache.org/docs/latest/configuration.html:
> "Directory to use for "scratch" space in Spark, including map output files
> and RDDs that get stored on disk."
>
> Thanks!
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-spilling-location-tp8471.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9504-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 18 17:21:14 2014
Return-Path: <dev-return-9504-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04A7F110EE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 18 Sep 2014 17:21:14 +0000 (UTC)
Received: (qmail 43773 invoked by uid 500); 18 Sep 2014 17:21:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43698 invoked by uid 500); 18 Sep 2014 17:21:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43687 invoked by uid 99); 18 Sep 2014 17:21:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 17:21:12 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 18 Sep 2014 17:20:46 +0000
Received: by mail-pd0-f170.google.com with SMTP id fp1so1852238pdb.29
        for <dev@spark.apache.org>; Thu, 18 Sep 2014 10:20:44 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=uyjd4ZOAfgz/YI/Z9qz6SwuvC1HZM5K7HVSr2MvdOOU=;
        b=aegFVirVc+fmhhlUyoN+NGl2waRTxS4AYwTfaYhq4ooS7q7+8BpuOz+KZeehHvZOfP
         mAl1yFhztOyMiA0HkERmtux+uEODTOJ72bJVelNsIxW8UMq7P0TITCchlnqDoKlbd0aD
         voMcdinfsoftwBhBRGW986pPLlDbES+p6RQfjoBu4fSU4x3bNn6HDkdrLxhZi8Xlxd+f
         R3fa9cQi/OyrzFC6qCEoyvBb89BEt90hmm+P+r04zT+3tD6ptMVB9r7Ph4FCiJAojRs4
         TYDVDDUI4UL6U+STb57byP/ZKJffoXjOC+lPzXCi0XIGlez3glUBdiaSq6tlks0HUgaW
         DSRA==
X-Gm-Message-State: ALoCoQmlyCrzevzsA5CmRg5Ep50UIxnUaxyW+3kuDuK7JEClrtu0h5gopOiI3prYaVziz5Wj9Z+C
MIME-Version: 1.0
X-Received: by 10.70.42.7 with SMTP id j7mr7343356pdl.9.1411060844637; Thu, 18
 Sep 2014 10:20:44 -0700 (PDT)
Received: by 10.70.26.100 with HTTP; Thu, 18 Sep 2014 10:20:44 -0700 (PDT)
In-Reply-To: <OF43B14B12.1435FFAB-ON48257D56.001E4DAD-48257D56.001E8291@cn.ibm.com>
References: <OF9565F075.274C74B9-ON48257D50.0031C5D4-48257D50.0032E0D0@cn.ibm.com>
	<1410788664.95241.YahooMailNeo@web140101.mail.bf1.yahoo.com>
	<CAMJOb8=ZG=2_sqmvZK2q8UKTd_qYvCQ4VyXr5HLLYH5cgGOVUQ@mail.gmail.com>
	<OF43B14B12.1435FFAB-ON48257D56.001E4DAD-48257D56.001E8291@cn.ibm.com>
Date: Thu, 18 Sep 2014 10:20:44 -0700
Message-ID: <CAMJOb8=t=hswCwRUGC1FidSMkb4064KMW9XtbRRwjY58uVZJew@mail.gmail.com>
Subject: Re: Spark authenticate enablement
From: Andrew Or <andrew@databricks.com>
To: Jun Feng Liu <liujunf@cn.ibm.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Tom Graves <tgraves_cs@yahoo.com>
Content-Type: multipart/related; boundary=047d7bfeb1e066f1ce05035a3412
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfeb1e066f1ce05035a3412
Content-Type: multipart/alternative; boundary=047d7bfeb1e066f1cb05035a3411

--047d7bfeb1e066f1cb05035a3411
Content-Type: text/plain; charset=UTF-8

2014-09-16 22:32 GMT-07:00 Jun Feng Liu <liujunf@cn.ibm.com>:

> I see. Thank you, it works for me. It looks confusing to have two ways
> expose configuration though.
>

I agree. We're working on it. :)






>  Best Regards
>
>
> *Jun Feng Liu*
> IBM China Systems & Technology Laboratory in Beijing
>
>   ------------------------------
>  [image: 2D barcode - encoded with contact information] *Phone: *86-10-82452683
>
> * E-mail:* *liujunf@cn.ibm.com* <liujunf@cn.ibm.com>
> [image: IBM]
>
> BLD 28,ZGC Software Park
> No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193
> China
>
>
>
>
>
>  *Andrew Or <andrew@databricks.com <andrew@databricks.com>>*
>
> 2014/09/17 02:06
>   To
> Tom Graves <tgraves_cs@yahoo.com>,
> cc
> Jun Feng Liu/China/IBM@IBMCN, "dev@spark.apache.org" <dev@spark.apache.org
> >
> Subject
> Re: Spark authenticate enablement
>
>
>
>
> Hi Jun,
>
> You can still set the authentication variables through `spark-env.sh`, by
> exporting SPARK_MASTER_OPTS, SPARK_WORKER_OPTS, SPARK_HISTORY_OPTS etc to
> include "-Dspark.auth.{...}". There is an open pull request that allows
> these processes to also read from spark-defaults.conf, but this is not
> merged into master yet.
>
> Andrew
>
> 2014-09-15 6:44 GMT-07:00 Tom Graves <tgraves_cs@yahoo.com.invalid>:
>
> > Spark authentication does work in standalone mode (atleast it did, I
> > haven't tested it in a while). The same shared secret has to be set on
> all
> > the daemons (master and workers) and then also in the configs of any
> > applications submitted.  Since everyone shares the same secret its by no
> > means ideal or a strong authentication.
> >
> > Tom
> >
> >
> > On Thursday, September 11, 2014 4:17 AM, Jun Feng Liu <
> liujunf@cn.ibm.com>
> > wrote:
> >
> >
> >
> > Hi, there
> >
> > I am trying to enable the authentication
> > on spark on standealone model. Seems like only SparkSubmit load the
> > properties
> > from spark-defaults.conf.  org.apache.spark.deploy.master.Master dose
> > not really load the default setting from spark-defaults.conf.
> >
> > Dose it mean the spark authentication
> > only work for like YARN model? Or I missed something with standalone
> model.
> >
> > Best Regards
> >
> > Jun Feng Liu
> > IBM China Systems & Technology Laboratory in Beijing
> >
> > ________________________________
> >
> >   Phone: 86-10-82452683
> > E-mail:liujunf@cn.ibm.com
> >
> > BLD 28,ZGC Software Park
> > No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193
> > China
> >
>
>

--047d7bfeb1e066f1cb05035a3411
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">2014-09-16 22:32 GMT-07:00 Jun Feng Liu <span dir=3D"ltr">=
&lt;<a href=3D"mailto:liujunf@cn.ibm.com" target=3D"_blank">liujunf@cn.ibm.=
com</a>&gt;</span>:<br><div class=3D"gmail_extra"><div class=3D"gmail_quote=
"><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:=
1px #ccc solid;padding-left:1ex"><font face=3D"sans-serif">I see. Thank you=
, it works for me. It looks
confusing to have two ways expose configuration though.<br></font></blockqu=
ote><div><br></div><div>I agree. We&#39;re working on it. :)</div><div><br>=
</div><div><br></div><div><br></div><div><br></div><div>=C2=A0</div><blockq=
uote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc =
solid;padding-left:1ex"><font face=3D"sans-serif">
</font><font size=3D"1" face=3D"Arial"> </font>
<p><font size=3D"1" face=3D"Arial">Best Regards</font>
</p><p><span class=3D""><font size=3D"1" face=3D"Arial">=C2=A0</font>
<br><font size=3D"3" color=3D"#8f8f8f" face=3D"Arial"><b>Jun Feng Liu</b></=
font><font size=3D"1" face=3D"Arial"><br>
IBM China Systems &amp; Technology Laboratory in Beijing</font>
</span></p><p>
</p><table>
<tbody><tr>
<td colspan=3D"3">
<div align=3D"center">
<hr noshade></div>
</td></tr><tr>
<td rowspan=3D"2"><span class=3D""><img src=3D"cid:_2_161970E816196D14001E8=
28E48257D56" alt=3D"2D barcode - encoded with contact information">
</span></td><td><font size=3D"1" color=3D"#4181c0" face=3D"=E5=AE=8B=E4=BD=
=93"><b>Phone: </b></font><font size=3D"1" color=3D"#5f5f5f" face=3D"=E5=AE=
=8B=E4=BD=93">86-10-82452683
</font><font size=3D"1" color=3D"#4181c0"><b><br>
E-mail:</b></font><font size=3D"1" color=3D"#5f5f5f"> </font><a href=3D"mai=
lto:liujunf@cn.ibm.com" target=3D"_blank"><font size=3D"1" color=3D"#5f5f5f=
" face=3D"=E5=AE=8B=E4=BD=93"><u>liujunf@cn.ibm.com</u></font></a>
</td><td rowspan=3D"2">
<div align=3D"right"><img src=3D"cid:_1_16197A94161976C0001E828E48257D56" w=
idth=3D"32" height=3D"32" alt=3D"IBM"><span class=3D""><font size=3D"1" col=
or=3D"#5f5f5f"><br>
</font><font size=3D"1" color=3D"#5f5f5f" face=3D"=E5=AE=8B=E4=BD=93"><br>
BLD 28,ZGC Software Park <br>
No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193 <br>
China </font></span></div>
</td></tr><tr>
<td><font size=3D"1" color=3D"#5f5f5f">=C2=A0</font></td></tr></tbody></tab=
le>
<br>
<p><font size=3D"3">=C2=A0</font>
<br>
<br>
<br>
</p><p></p><table width=3D"100%">
<tbody><tr valign=3D"top">
<td width=3D"40%"><font size=3D"1" face=3D"sans-serif"><b>Andrew Or &lt;<a =
href=3D"mailto:andrew@databricks.com" target=3D"_blank">andrew@databricks.c=
om</a>&gt;</b>
</font>
<p><font size=3D"1" face=3D"sans-serif">2014/09/17 02:06</font>
</p></td><td width=3D"59%">
<table width=3D"100%">
<tbody><tr valign=3D"top">
<td>
<div align=3D"right"><font size=3D"1" face=3D"sans-serif">To</font></div>
</td><td><font size=3D"1" face=3D"sans-serif">Tom Graves &lt;<a href=3D"mai=
lto:tgraves_cs@yahoo.com" target=3D"_blank">tgraves_cs@yahoo.com</a>&gt;,
</font>
</td></tr><tr valign=3D"top">
<td>
<div align=3D"right"><font size=3D"1" face=3D"sans-serif">cc</font></div>
</td><td><font size=3D"1" face=3D"sans-serif">Jun Feng Liu/China/IBM@IBMCN,=
 &quot;<a href=3D"mailto:dev@spark.apache.org" target=3D"_blank">dev@spark.=
apache.org</a>&quot;
&lt;<a href=3D"mailto:dev@spark.apache.org" target=3D"_blank">dev@spark.apa=
che.org</a>&gt;</font>
</td></tr><tr valign=3D"top">
<td>
<div align=3D"right"><font size=3D"1" face=3D"sans-serif">Subject</font></d=
iv>
</td><td><font size=3D"1" face=3D"sans-serif">Re: Spark authenticate enable=
ment</font></td></tr></tbody></table>
<br>
<table>
<tbody><tr valign=3D"top">
<td>
</td><td></td></tr></tbody></table>
<br></td></tr></tbody></table><div><div class=3D"h5">
<br>
<br>
<br><tt><font>Hi Jun,<br>
<br>
You can still set the authentication variables through `spark-env.sh`,
by<br>
exporting SPARK_MASTER_OPTS, SPARK_WORKER_OPTS, SPARK_HISTORY_OPTS etc
to<br>
include &quot;-Dspark.auth.{...}&quot;. There is an open pull request that
allows<br>
these processes to also read from spark-defaults.conf, but this is not<br>
merged into master yet.<br>
<br>
Andrew<br>
<br>
2014-09-15 6:44 GMT-07:00 Tom Graves &lt;tgraves_cs@yahoo.com.invalid&gt;:<=
br>
<br>
&gt; Spark authentication does work in standalone mode (atleast it did,
I<br>
&gt; haven&#39;t tested it in a while). The same shared secret has to be se=
t
on all<br>
&gt; the daemons (master and workers) and then also in the configs of any<b=
r>
&gt; applications submitted. =C2=A0Since everyone shares the same secret
its by no<br>
&gt; means ideal or a strong authentication.<br>
&gt;<br>
&gt; Tom<br>
&gt;<br>
&gt;<br>
&gt; On Thursday, September 11, 2014 4:17 AM, Jun Feng Liu &lt;<a href=3D"m=
ailto:liujunf@cn.ibm.com" target=3D"_blank">liujunf@cn.ibm.com</a>&gt;<br>
&gt; wrote:<br>
&gt;<br>
&gt;<br>
&gt;<br>
&gt; Hi, there<br>
&gt;<br>
&gt; I am trying to enable the authentication<br>
&gt; on spark on standealone model. Seems like only SparkSubmit load the<br=
>
&gt; properties<br>
&gt; from spark-defaults.conf. =C2=A0org.apache.spark.deploy.master.Master
dose<br>
&gt; not really load the default setting from spark-defaults.conf.<br>
&gt;<br>
&gt; Dose it mean the spark authentication<br>
&gt; only work for like YARN model? Or I missed something with standalone
model.<br>
&gt;<br>
&gt; Best Regards<br>
&gt;<br>
&gt; Jun Feng Liu<br>
&gt; IBM China Systems &amp; Technology Laboratory in Beijing<br>
&gt;<br>
&gt; ________________________________<br>
&gt;<br>
&gt; =C2=A0 Phone: 86-10-82452683<br>
&gt; <a href=3D"mailto:E-mail%3Aliujunf@cn.ibm.com" target=3D"_blank">E-mai=
l:liujunf@cn.ibm.com</a><br>
&gt;<br>
&gt; BLD 28,ZGC Software Park<br>
&gt; No.8 Rd.Dong Bei Wang West, Dist.Haidian Beijing 100193<br>
&gt; China<br>
&gt;<br>
</font></tt>
<br>
</div></div><p></p><p></p><p></p><p></p></blockquote></div><br></div></div>

--047d7bfeb1e066f1cb05035a3411--
--047d7bfeb1e066f1ce05035a3412--

From dev-return-9505-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 05:26:28 2014
Return-Path: <dev-return-9505-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C9FF811C09
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 05:26:28 +0000 (UTC)
Received: (qmail 51610 invoked by uid 500); 19 Sep 2014 05:26:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51529 invoked by uid 500); 19 Sep 2014 05:26:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51482 invoked by uid 99); 19 Sep 2014 05:26:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 05:26:27 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_MESSAGE,HTTP_ESCAPED_HOST,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [66.46.182.58] (HELO relay.ihostexchange.net) (66.46.182.58)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 05:26:00 +0000
Received: from [192.168.125.249] (125.17.228.30) by smtp.ihostexchange.net
 (66.46.182.50) with Microsoft SMTP Server (TLS) id 8.3.348.2; Fri, 19 Sep
 2014 01:25:56 -0400
Message-ID: <541BBE61.4080608@flytxt.com>
Date: Fri, 19 Sep 2014 10:55:53 +0530
From: Meethu Mathew <meethu.mathew@flytxt.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.1.1
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Gaussian Mixture Model clustering
Content-Type: multipart/alternative;
	boundary="------------050403060407070106090408"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------050403060407070106090408
Content-Type: text/plain; charset="utf-8"; format=flowed
Content-Transfer-Encoding: 7bit

Hi all,

We have come up with an initial distributed implementation of Gaussian 
Mixture Model in pyspark where the parameters are estimated using the 
Expectation-Maximization algorithm.Our current implementation considers 
diagonal covariance matrix for each component.
We did an initial benchmark study on a 2 node Spark standalone cluster 
setup where each node config is 8 Cores,8 GB RAM, the spark version used 
is 1.0.0. We also evaluated python version of k-means available in spark 
on the same datasets.Below are the results from this benchmark study. 
The reported stats are average from 10 runs.Tests were done on multiple 
datasets with varying number of features and instances.


          Dataset 	      Gaussian mixture model
	               Kmeans(Python)

Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
	Avg time per iteration 	Time for 100 iterations
0.7million 	13
	7s
	12min
	  13s 	26min
1.8million 	11
	17s
	 29min 	   33s
	 53min
10 million 	16
	1.6min 	2.7hr
	  1.2min 	2 hr


We are interested in contributing this implementation as a patch to 
SPARK. Does MLLib accept python implementations? If not, can we 
contribute to the pyspark component
I have created a JIRA for the same 
https://issues.apache.org/jira/browse/SPARK-3588 .How do I get the 
ticket assigned to myself?

Please review and suggest how to take this forward.



-- 

Regards,


*Meethu Mathew*

*Engineer*

*Flytxt*

F: +91 471.2700202

www.flytxt.com | Visit our blog <http://blog.flytxt.com/> | Follow us 
<http://www.twitter.com/flytxt> | _Connect on Linkedin 
<http://www.linkedin.com/home?trk=hb_tab_home_top>_


--------------050403060407070106090408--

From dev-return-9506-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 05:38:50 2014
Return-Path: <dev-return-9506-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A430911C68
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 05:38:50 +0000 (UTC)
Received: (qmail 1332 invoked by uid 500); 19 Sep 2014 05:38:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1261 invoked by uid 500); 19 Sep 2014 05:38:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1250 invoked by uid 99); 19 Sep 2014 05:38:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 05:38:49 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_MESSAGE,HTTP_ESCAPED_HOST,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [66.46.182.58] (HELO relay.ihostexchange.net) (66.46.182.58)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 05:38:21 +0000
Received: from [192.168.125.249] (125.17.228.30) by smtp.ihostexchange.net
 (66.46.182.50) with Microsoft SMTP Server (TLS) id 8.3.348.2; Fri, 19 Sep
 2014 01:38:18 -0400
Message-ID: <541BC144.9000401@flytxt.com>
Date: Fri, 19 Sep 2014 11:08:12 +0530
From: Meethu Mathew <meethu.mathew@flytxt.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.1.1
MIME-Version: 1.0
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: Gaussian Mixture Model clustering
References: <541BBE61.4080608@flytxt.com>
In-Reply-To: <541BBE61.4080608@flytxt.com>
Content-Type: multipart/mixed;
	boundary="------------030404050703040407010405"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------030404050703040407010405
Content-Type: multipart/alternative;
	boundary="------------030006020704040701090007"

--------------030006020704040701090007
Content-Type: text/plain; charset="utf-8"; format=flowed
Content-Transfer-Encoding: 7bit

Hi all,
Please find attached the image of benchmark results. The table in the 
previous mail got messed up. Thanks.



On Friday 19 September 2014 10:55 AM, Meethu Mathew wrote:
> Hi all,
>
> We have come up with an initial distributed implementation of Gaussian
> Mixture Model in pyspark where the parameters are estimated using the
> Expectation-Maximization algorithm.Our current implementation considers
> diagonal covariance matrix for each component.
> We did an initial benchmark study on a 2 node Spark standalone cluster
> setup where each node config is 8 Cores,8 GB RAM, the spark version used
> is 1.0.0. We also evaluated python version of k-means available in spark
> on the same datasets.Below are the results from this benchmark study.
> The reported stats are average from 10 runs.Tests were done on multiple
> datasets with varying number of features and instances.
>
>
>            Dataset 	      Gaussian mixture model
> 	               Kmeans(Python)
>
> Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
> 	Avg time per iteration 	Time for 100 iterations
> 0.7million 	13
> 	7s
> 	12min
> 	  13s 	26min
> 1.8million 	11
> 	17s
> 	 29min 	   33s
> 	 53min
> 10 million 	16
> 	1.6min 	2.7hr
> 	  1.2min 	2 hr
>
>
> We are interested in contributing this implementation as a patch to
> SPARK. Does MLLib accept python implementations? If not, can we
> contribute to the pyspark component
> I have created a JIRA for the same
> https://issues.apache.org/jira/browse/SPARK-3588 .How do I get the
> ticket assigned to myself?
>
> Please review and suggest how to take this forward.
>
>
>

-- 

Regards,

*Meethu Mathew*

*Engineer*

*Flytxt*

Skype: meethu.mathew7

  F: +91 471.2700202

www.flytxt.com | Visit our blog <http://blog.flytxt.com/> | Follow us 
<http://www.twitter.com/flytxt> | _Connect on Linkedin 
<http://www.linkedin.com/home?trk=hb_tab_home_top>_


--------------030006020704040701090007
Content-Type: multipart/related;
	boundary="------------090501030101020408080007"

--------------090501030101020408080007
Content-Type: text/html; charset="utf-8"
Content-Transfer-Encoding: 8bit

<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  </head>
  <body text="#000000" bgcolor="#FFFFFF">
    Hi all,<br>
    Please find attached the image of benchmark results. The table in
    the previous mail got messed up. Thanks.<br>
    <br>
    <img alt="" src="cid:part1.01070405.00050500@flytxt.com"
      height="220" width="625"><br>
    <br>
    <div class="moz-cite-prefix">On Friday 19 September 2014 10:55 AM,
      Meethu Mathew wrote:<br>
    </div>
    <blockquote cite="mid:541BBE61.4080608@flytxt.com" type="cite">
      <pre wrap="">Hi all,

We have come up with an initial distributed implementation of Gaussian 
Mixture Model in pyspark where the parameters are estimated using the 
Expectation-Maximization algorithm.Our current implementation considers 
diagonal covariance matrix for each component.
We did an initial benchmark study on a 2 node Spark standalone cluster 
setup where each node config is 8 Cores,8 GB RAM, the spark version used 
is 1.0.0. We also evaluated python version of k-means available in spark 
on the same datasets.Below are the results from this benchmark study. 
The reported stats are average from 10 runs.Tests were done on multiple 
datasets with varying number of features and instances.


          Dataset 	      Gaussian mixture model
	               Kmeans(Python)

Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
	Avg time per iteration 	Time for 100 iterations
0.7million 	13
	7s
	12min
	  13s 	26min
1.8million 	11
	17s
	 29min 	   33s
	 53min
10 million 	16
	1.6min 	2.7hr
	  1.2min 	2 hr


We are interested in contributing this implementation as a patch to 
SPARK. Does MLLib accept python implementations? If not, can we 
contribute to the pyspark component
I have created a JIRA for the same 
<a class="moz-txt-link-freetext" href="https://issues.apache.org/jira/browse/SPARK-3588">https://issues.apache.org/jira/browse/SPARK-3588</a> .How do I get the 
ticket assigned to myself?

Please review and suggest how to take this forward.



</pre>
    </blockquote>
    <br>
    <div class="moz-signature">-- <br>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="ProgId" content="Word.Document">
      <meta name="Generator" content="Microsoft Word 14">
      <meta name="Originator" content="Microsoft Word 14">
      <link rel="File-List" href="Official%20New_files/filelist.xml">
      <!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->
      <link rel="themeData" href="Official%20New_files/themedata.thmx">
      <link rel="colorSchemeMapping"
        href="Official%20New_files/colorschememapping.xml">
      <!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:DoNotShadeFormData/>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]-->
      <style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
a:link, span.MsoHyperlink
	{mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	color:blue;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:purple;
	mso-themecolor:followedhyperlink;
	text-decoration:underline;
	text-underline:single;}
p
	{mso-style-noshow:yes;
	mso-style-priority:99;
	mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";
	mso-fareast-font-family:"Times New Roman";}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:11.0pt;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->
      <div class="WordSection1">
        <p class="MsoNormal"><span
            style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
Calibri;color:#000000;mso-themecolor:accent1;mso-themeshade:191;mso-bidi-font-weight:
            bold">Regards, <o:p></o:p>
          </span></p>
        <p class="MsoNormal"></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:black">Meethu Mathew<o:p></o:p></span></b></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:#4978BC">Engineer<o:p></o:p></span></b></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:#F78F28">Flytxt</span></b><span
            style="mso-ascii-font-family:
            Calibri;mso-hansi-font-family:Calibri;color:#F78F28"><o:p></o:p></span></p>
        <p class="MsoNormal"><span
            style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
            Calibri;color:#0D0D0D">Skype: </span><span
            style="mso-ascii-font-family:Calibri;
            mso-hansi-font-family:Calibri;color:#1F497D">meethu.mathew7<span
              style="color:#0D0D0D"><o:p></o:p></span></span></p>
        <p class="MsoNormal"><span style="mso-ascii-font-family:Calibri;
            mso-hansi-font-family:Calibri"><span style="color:#0D0D0D">F:
+91
              471.2700202 <o:p></o:p></span></span></p>
        <p class="MsoNormal"><span
            style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
            Calibri;color:#4978BC"><a href="www.flytxt.com"><span
                style="color:#4978BC">www.flytxt.com</span></a>
            | <a href="http://blog.flytxt.com/"><span
                style="color:#4978BC">Visit our blog </span></a>|
            <a href="http://www.twitter.com/flytxt"><span
                style="color:#4978BC">Follow us</span></a>|<u><a
                href="http://www.linkedin.com/home?trk=hb_tab_home_top"><span
                  style="color:
                  #4978BC">Connect on Linkedin</span></a></u></span> <o:p></o:p></p>
        <p class="MsoNormal"><o:p></o:p></p>
      </div>
    </div>
  </body>
</html>

--------------090501030101020408080007
Content-Type: image/png; name="sparktiming.png"
Content-Transfer-Encoding: base64
Content-ID: <part1.01070405.00050500@flytxt.com>
Content-Disposition: inline; filename="sparktiming.png"
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--------------090501030101020408080007--

--------------030006020704040701090007--


--------------030404050703040407010405
Content-Type: text/plain; charset=us-ascii


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--------------030404050703040407010405--

From dev-return-9507-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 16:19:29 2014
Return-Path: <dev-return-9507-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7E12E11154
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 16:19:29 +0000 (UTC)
Received: (qmail 85221 invoked by uid 500); 19 Sep 2014 16:19:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85142 invoked by uid 500); 19 Sep 2014 16:19:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85130 invoked by uid 99); 19 Sep 2014 16:19:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 16:19:28 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 16:19:24 +0000
Received: by mail-la0-f51.google.com with SMTP id gi9so3392559lab.24
        for <dev@spark.apache.org>; Fri, 19 Sep 2014 09:19:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Q0afx20IEN72pn7uNYMskDdoGNP+XPF5BGEpMM73B4M=;
        b=e2RzXccb2X8P7VTAeAna/rPM55wXsTV+n6zdh+9yvxHtLt9GphSzdKp1gkVtmXCzUp
         4B2kwlEAGl3rn3Bn1bjdGjUtb9ZBVhl2ym65YQpxtlkBnURFkB3ZxB9wJfa3txsa4Zp0
         mP3hBZmn5ZrO3SohumYxGszXAhQRtAcGbVNFdn+dUEnDMl1dliCmDpO8oZYiTtpLE3iG
         /ZQSZy0WNBUgRy37DuXpQKICMI2HXrVjrEMS0mRDu/SfwXXqhP41FcDj4W4kA8R+QhRy
         1B95E4kFb/PCXMq4hxA7wpU6fIZKNf+xEhJwfSxgNg93vStmIsvX+truDS2LN9IKb8/+
         INyw==
MIME-Version: 1.0
X-Received: by 10.152.203.167 with SMTP id kr7mr7932657lac.9.1411143543089;
 Fri, 19 Sep 2014 09:19:03 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Fri, 19 Sep 2014 09:19:03 -0700 (PDT)
In-Reply-To: <CAJgQjQ9YQzHnxN+HEN4FGbQe=4Pgq1NkU4+oyodYE7e547FKaw@mail.gmail.com>
References: <49229E870391FC49BBBED818C268753D705A644F@SZXEMA501-MBX.china.huawei.com>
	<CAJgQjQ9YQzHnxN+HEN4FGbQe=4Pgq1NkU4+oyodYE7e547FKaw@mail.gmail.com>
Date: Fri, 19 Sep 2014 09:19:03 -0700
Message-ID: <CA+B-+fzHBwAe81Pgyv=kcxdRqxo0Lzd4eZxtcGH_DNVrFfU00A@mail.gmail.com>
Subject: Re: I want to contribute MLlib two quality measures(ARHR and HR) for
 top N recommendation system. Is this meaningful?
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: "Lizhengbing (bing, BIPA)" <zhengbing.li@huawei.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134652e9cee0105036d753b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134652e9cee0105036d753b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Xiangrui,

Could you please point to some reference for calculating prec@k and ndcg@k =
?

prec is precision I suppose but ndcg I have no idea about...

Thanks.
Deb


On Mon, Aug 25, 2014 at 12:28 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> The evaluation metrics are definitely useful. How do they differ from
> traditional IR metrics like prec@k and ndcg@k? -Xiangrui
>
>
> On Mon, Aug 25, 2014 at 2:14 AM, Lizhengbing (bing, BIPA) <
> zhengbing.li@huawei.com> wrote:
>
> >  Hi:
> >
> > In paper =E2=80=9CItem-Based Top-N Recommendation Algorithms=E2=80=9D(
> >
> https://stuyresearch.googlecode.com/hg/blake/resources/10.1.1.102.4451.pd=
f
> ),
> > there are two parameters measuring the quality of recommendation: HR an=
d
> > ARHR.
> >
> > If I use ALS(Implicit) for top-N recommendation system, I want to check
> > it=E2=80=99s quality. ARHR and HR are two good quality measures.
> >
> > I want to contribute them to spark MLlib.  So I want to know whether th=
is
> > is meaningful?
> >
> >
> >
> >
> >
> > (1) If *n *is the total number of customers/users,  the hit-rate of the
> > recommendation algorithm was computed as
> >
> > *hit-rate (HR) *=3D *Number of hits / n*
> >
> >
> >
> > (2)If *h *is the number of hits that occurred at positions *p*1, *p*2, =
*.
> > . . *, *p**h *within the *top-N *lists (i.e., 1 =E2=89=A4 *p**i *=E2=89=
=A4 *N*), then the
> > average reciprocal hit-rank is equal to:
> >
> > *i*
> >
> > *.*
> >
>

--001a1134652e9cee0105036d753b--

From dev-return-9508-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 17:55:22 2014
Return-Path: <dev-return-9508-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DD02911666
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 17:55:22 +0000 (UTC)
Received: (qmail 85188 invoked by uid 500); 19 Sep 2014 17:55:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85101 invoked by uid 500); 19 Sep 2014 17:55:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85084 invoked by uid 99); 19 Sep 2014 17:55:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 17:55:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.178 as permitted sender)
Received: from [209.85.220.178] (HELO mail-vc0-f178.google.com) (209.85.220.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 17:55:17 +0000
Received: by mail-vc0-f178.google.com with SMTP id hy4so2244796vcb.23
        for <dev@spark.apache.org>; Fri, 19 Sep 2014 10:54:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=jTCJwFGP9HiuB4wLpipakkJzP6OtseAprf6XCYqg7Bc=;
        b=OMmHBo1TeZuCvHE/w9JNxDPxM0kEunfYo8MfGh/O7O+PNJnq9qQY6uYFFqp/8vc4as
         Lpg+NFuLaoCOugFzy77CeeIikvOve7IlenyhSGE+gPImA4eGsF7FTEcFghyOsevOBjp3
         4e5dfGweZrH3NIPtQiUdZ9oDFjtBg/tAWxjH5M6hagMAdqdIfv2snabOsAAOyMmVC4hI
         MLIddrbxLz5HDOkj4LKsLSTnTTtIuoo9iRB6cFnePN0kcsmeOYiKMr2CMHEUCkTlbZdv
         SB+qcdNlyjLVuBA4mFEaHQvKpnUsSI6Ndf5NjJST0VXJ2qKzzG/r2NgDzvaBadvxdDn4
         cHDg==
X-Received: by 10.52.163.52 with SMTP id yf20mr717674vdb.40.1411149296010;
 Fri, 19 Sep 2014 10:54:56 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.52.32.225 with HTTP; Fri, 19 Sep 2014 10:54:35 -0700 (PDT)
In-Reply-To: <541BC144.9000401@flytxt.com>
References: <541BBE61.4080608@flytxt.com> <541BC144.9000401@flytxt.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Fri, 19 Sep 2014 10:54:35 -0700
Message-ID: <CABjXkq5ywpAOfFkNMoJjDw7wwATkRjv8CPJb6JadwdELztTCpA@mail.gmail.com>
Subject: Re: Gaussian Mixture Model clustering
To: Meethu Mathew <meethu.mathew@flytxt.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/related; boundary=001a11c2d7b483b87805036ecc2e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2d7b483b87805036ecc2e
Content-Type: multipart/alternative; boundary=001a11c2d7b483b87605036ecc2d

--001a11c2d7b483b87605036ecc2d
Content-Type: text/plain; charset=UTF-8

Hey Meethu - what are you setting "K" to in the benchmarks you show? This
can greatly affect the runtime.

On Thu, Sep 18, 2014 at 10:38 PM, Meethu Mathew <meethu.mathew@flytxt.com>
wrote:

>  Hi all,
> Please find attached the image of benchmark results. The table in the
> previous mail got messed up. Thanks.
>
>
>
> On Friday 19 September 2014 10:55 AM, Meethu Mathew wrote:
>
> Hi all,
>
> We have come up with an initial distributed implementation of Gaussian
> Mixture Model in pyspark where the parameters are estimated using the
> Expectation-Maximization algorithm.Our current implementation considers
> diagonal covariance matrix for each component.
> We did an initial benchmark study on a 2 node Spark standalone cluster
> setup where each node config is 8 Cores,8 GB RAM, the spark version used
> is 1.0.0. We also evaluated python version of k-means available in spark
> on the same datasets.Below are the results from this benchmark study.
> The reported stats are average from 10 runs.Tests were done on multiple
> datasets with varying number of features and instances.
>
>
>           Dataset 	      Gaussian mixture model
> 	               Kmeans(Python)
>
> Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
> 	Avg time per iteration 	Time for 100 iterations
> 0.7million 	13
> 	7s
> 	12min
> 	  13s 	26min
> 1.8million 	11
> 	17s
> 	 29min 	   33s
> 	 53min
> 10 million 	16
> 	1.6min 	2.7hr
> 	  1.2min 	2 hr
>
>
> We are interested in contributing this implementation as a patch to
> SPARK. Does MLLib accept python implementations? If not, can we
> contribute to the pyspark component
> I have created a JIRA for the same https://issues.apache.org/jira/browse/SPARK-3588 .How do I get the
> ticket assigned to myself?
>
> Please review and suggest how to take this forward.
>
>
>
>
>
> --
>
> Regards,
>
>
>
> *Meethu Mathew*
>
> *Engineer*
>
> *Flytxt*
>
> Skype: meethu.mathew7
>
>  F:  +91 471.2700202
>
> www.flytxt.com | Visit our blog <http://blog.flytxt.com/> |  Follow us
> <http://www.twitter.com/flytxt> | *Connect on Linkedin
> <http://www.linkedin.com/home?trk=hb_tab_home_top>*
>
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

--001a11c2d7b483b87605036ecc2d
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hey Meethu - what are you setting &quot;K&quot; to in the =
benchmarks you show? This can greatly affect the runtime.</div><div class=
=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Sep 18, 2014 at 10:=
38 PM, Meethu Mathew <span dir=3D"ltr">&lt;<a href=3D"mailto:meethu.mathew@=
flytxt.com" target=3D"_blank">meethu.mathew@flytxt.com</a>&gt;</span> wrote=
:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-le=
ft:1px #ccc solid;padding-left:1ex">
 =20
   =20
 =20
  <div text=3D"#000000" bgcolor=3D"#FFFFFF">
    Hi all,<br>
    Please find attached the image of benchmark results. The table in
    the previous mail got messed up. Thanks.<br>
    <br>
    <img alt=3D"" src=3D"cid:part1.01070405.00050500@flytxt.com" height=3D"=
220" width=3D"625"><div><div class=3D"h5"><br>
    <br>
    <div>On Friday 19 September 2014 10:55 AM,
      Meethu Mathew wrote:<br>
    </div>
    <blockquote type=3D"cite">
      <pre>Hi all,

We have come up with an initial distributed implementation of Gaussian=20
Mixture Model in pyspark where the parameters are estimated using the=20
Expectation-Maximization algorithm.Our current implementation considers=20
diagonal covariance matrix for each component.
We did an initial benchmark study on a 2 node Spark standalone cluster=20
setup where each node config is 8 Cores,8 GB RAM, the spark version used=20
is 1.0.0. We also evaluated python version of k-means available in spark=20
on the same datasets.Below are the results from this benchmark study.=20
The reported stats are average from 10 runs.Tests were done on multiple=20
datasets with varying number of features and instances.


          Dataset 	      Gaussian mixture model
	               Kmeans(Python)

Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
	Avg time per iteration 	Time for 100 iterations
0.7million 	13
	7s
	12min
	  13s 	26min
1.8million 	11
	17s
	 29min 	   33s
	 53min
10 million 	16
	1.6min 	2.7hr
	  1.2min 	2 hr


We are interested in contributing this implementation as a patch to=20
SPARK. Does MLLib accept python implementations? If not, can we=20
contribute to the pyspark component
I have created a JIRA for the same=20
<a href=3D"https://issues.apache.org/jira/browse/SPARK-3588" target=3D"_bla=
nk">https://issues.apache.org/jira/browse/SPARK-3588</a> .How do I get the=
=20
ticket assigned to myself?

Please review and suggest how to take this forward.



</pre>
    </blockquote>
    <br>
    </div></div><div>-- <br>
     =20
     =20
     =20
     =20
     =20
     =20
     =20
     =20
     =20
     =20
      <div>
        <p class=3D"MsoNormal"><span style=3D"color:#000000">Regards, <u></=
u><u></u>
          </span></p>
        <p class=3D"MsoNormal">=C2=A0</p>
        <p class=3D"MsoNormal"><b><span style=3D"color:black">Meethu Mathew=
<u></u><u></u></span></b></p>
        <p class=3D"MsoNormal"><b><span style=3D"color:#4978bc">Engineer<u>=
</u><u></u></span></b></p>
        <p class=3D"MsoNormal"><b><span style=3D"color:#f78f28">Flytxt</spa=
n></b><span style=3D"color:#f78f28"><u></u><u></u></span></p>
        <p class=3D"MsoNormal"><span style=3D"color:#0d0d0d">Skype: </span>=
<span style=3D"color:#1f497d">meethu.mathew7<span style=3D"color:#0d0d0d"><=
u></u><u></u></span></span></p>
        <p class=3D"MsoNormal"><span><span style=3D"color:#0d0d0d">=C2=A0F:=
=C2=A0
+91
              471.2700202=C2=A0 <u></u><u></u></span></span></p>
        <p class=3D"MsoNormal"><span style=3D"color:#4978bc"><a href=3D"htt=
p://www.flytxt.com" target=3D"_blank"><span style=3D"color:#4978bc">www.fly=
txt.com</span></a>
            | <a href=3D"http://blog.flytxt.com/" target=3D"_blank"><span s=
tyle=3D"color:#4978bc">Visit our blog </span></a>=C2=A0|=C2=A0
            <a href=3D"http://www.twitter.com/flytxt" target=3D"_blank"><sp=
an style=3D"color:#4978bc">Follow us</span></a>=C2=A0|=C2=A0<u><a href=3D"h=
ttp://www.linkedin.com/home?trk=3Dhb_tab_home_top" target=3D"_blank"><span =
style=3D"color:#4978bc">Connect on Linkedin</span></a></u></span> <u></u><u=
></u></p>
        <p class=3D"MsoNormal"><u></u>=C2=A0<u></u></p>
      </div>
    </div>
  </div>

<br><br>
---------------------------------------------------------------------<br>
To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache.org"=
>dev-unsubscribe@spark.apache.org</a><br>
For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apache.or=
g">dev-help@spark.apache.org</a><br></blockquote></div><br></div>

--001a11c2d7b483b87605036ecc2d--
--001a11c2d7b483b87805036ecc2e--

From dev-return-9509-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 20:16:42 2014
Return-Path: <dev-return-9509-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B03E2110FC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 20:16:42 +0000 (UTC)
Received: (qmail 4655 invoked by uid 500); 19 Sep 2014 20:16:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4520 invoked by uid 500); 19 Sep 2014 20:16:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4071 invoked by uid 99); 19 Sep 2014 20:16:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 20:16:35 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of christoph.sawade@googlemail.com designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 20:16:09 +0000
Received: by mail-lb0-f177.google.com with SMTP id z12so3865571lbi.36
        for <dev@spark.apache.org>; Fri, 19 Sep 2014 13:16:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=googlemail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5QsvErmDa3M4SgYq0U1d/a1FR8wWQ+RQK2Nkrr2wG2o=;
        b=pKM6M2fD/54k094RnirykWF6bG3OoeUdfcbXQD+m450/sOJwpNX0GhsbNyCiKUm95a
         nSfZD1QCvDJeu5BVNQy/rozEaKm2lMP03qYlRf/13cORLKO1UynpMd5nbU9IbK/UlBnp
         SgZtMk4stEOGWaVM7/XD3DR/yse4GyoC16mUAFnNkPVut9Yn4Vh8H7fnoD99oLKvcGVB
         U/OECz565TkUgtiINro7wdMmLrgJeS/mmWC3kcvgLnj9tNgMsx5Thzi3pJdnkhfOA6jY
         UPR5O9bymRbx1ucnrlpgXmV+jFtgsTwzTB2jtPmDz7UGtfVXg4Whyc8CtXapPSPHGu1v
         4aDA==
MIME-Version: 1.0
X-Received: by 10.112.199.232 with SMTP id jn8mr8668692lbc.30.1411157768735;
 Fri, 19 Sep 2014 13:16:08 -0700 (PDT)
Received: by 10.114.229.3 with HTTP; Fri, 19 Sep 2014 13:16:08 -0700 (PDT)
In-Reply-To: <CA+B-+fzHBwAe81Pgyv=kcxdRqxo0Lzd4eZxtcGH_DNVrFfU00A@mail.gmail.com>
References: <49229E870391FC49BBBED818C268753D705A644F@SZXEMA501-MBX.china.huawei.com>
	<CAJgQjQ9YQzHnxN+HEN4FGbQe=4Pgq1NkU4+oyodYE7e547FKaw@mail.gmail.com>
	<CA+B-+fzHBwAe81Pgyv=kcxdRqxo0Lzd4eZxtcGH_DNVrFfU00A@mail.gmail.com>
Date: Fri, 19 Sep 2014 22:16:08 +0200
Message-ID: <CAKxiPZPwgvf=X8tNEBhgEYTWXK-Tb85C0=W3EZYpUgreUL7a+g@mail.gmail.com>
Subject: Re: I want to contribute MLlib two quality measures(ARHR and HR) for
 top N recommendation system. Is this meaningful?
From: Christoph Sawade <christoph.sawade@googlemail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, "Lizhengbing (bing, BIPA)" <zhengbing.li@huawei.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2b6ce871209050370c5fe
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2b6ce871209050370c5fe
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hey Deb,

NDCG is the "Normalized Discounted Cumulative Gain" [1]. Another popular
measure is "Expected Reciprocal Rank" (ERR) [2]; it is based on a
probabilistic user model, where the user scans the presented list of search
results or recommendations and chooses the first that is sufficiently
relevant. ERR is the expectation of the reciprocal rank under this model.
Precision@k is the precision at a cut-off k. Often this is used as an
overage over the first n k's; a starting point might by [3].

Hope that helps.

Cheers, Christoph

[1] K. J=C3=A4rvelin and J. Kek=C3=A4l=C3=A4inen. Cumulated gain-based eval=
uation of IR
techniques. ACM Transactions on Information Systems, 20(4):422=E2=80=93446,=
 2002.
[2] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected reciprocal
rank for graded rel- evance. In Proceeding of the Conference on Information
and Knowledge Management, 2009.
[3] http://en.wikipedia.org/wiki/IR_evaluation

--001a11c2b6ce871209050370c5fe--

From dev-return-9510-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 19 20:30:03 2014
Return-Path: <dev-return-9510-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1124D111C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 19 Sep 2014 20:30:03 +0000 (UTC)
Received: (qmail 42953 invoked by uid 500); 19 Sep 2014 20:30:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42886 invoked by uid 500); 19 Sep 2014 20:30:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42873 invoked by uid 99); 19 Sep 2014 20:30:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 20:30:01 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 19 Sep 2014 20:29:36 +0000
Received: by mail-la0-f49.google.com with SMTP id pn19so3794629lab.22
        for <dev@spark.apache.org>; Fri, 19 Sep 2014 13:29:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=GxkSI0XMs1zTYsDZhS/x1CcORMTILefEjpTn8CC+N5s=;
        b=nVrWReRcdyPlWX47zwE3e/hi9OCNVTC4qWprEmYdQZIunm2pH0HX+siET5bvOkOmWx
         /LVmzkaVaIzZrUiAHka8+3EHwS8i7oogauSUQB8ud8plV6FXCfxeQmDfD5RVUfomxNKa
         zZxqn39m5ErVXViQ+Xgn0iBWq68qaubAbwF/3RrKt5oyMrGZMb/6E/4/lsh4xV2PBUWs
         5g0ri4ksWBAHA2AKpBAA4g//a2BgkKSdtqqe9glSMsL7WTDN6VpLaz/MbomrpZBeAtVq
         oRIRjffVlCeH3vFnIqIrC75ro03gWtAM37bdLss9gx8rcYhmbrYdqIrpom5I4CL0WAQ2
         24GA==
MIME-Version: 1.0
X-Received: by 10.112.148.170 with SMTP id tt10mr8722779lbb.61.1411158575643;
 Fri, 19 Sep 2014 13:29:35 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Fri, 19 Sep 2014 13:29:35 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Fri, 19 Sep 2014 13:29:35 -0700 (PDT)
In-Reply-To: <CAKxiPZPwgvf=X8tNEBhgEYTWXK-Tb85C0=W3EZYpUgreUL7a+g@mail.gmail.com>
References: <49229E870391FC49BBBED818C268753D705A644F@SZXEMA501-MBX.china.huawei.com>
	<CAJgQjQ9YQzHnxN+HEN4FGbQe=4Pgq1NkU4+oyodYE7e547FKaw@mail.gmail.com>
	<CA+B-+fzHBwAe81Pgyv=kcxdRqxo0Lzd4eZxtcGH_DNVrFfU00A@mail.gmail.com>
	<CAKxiPZPwgvf=X8tNEBhgEYTWXK-Tb85C0=W3EZYpUgreUL7a+g@mail.gmail.com>
Date: Fri, 19 Sep 2014 13:29:35 -0700
Message-ID: <CA+B-+fzzo+qPL5XK8YXb8UoaJZn8p0NU1hDu8uAt5U-=0_oJGg@mail.gmail.com>
Subject: Re: I want to contribute MLlib two quality measures(ARHR and HR) for
 top N recommendation system. Is this meaningful?
From: Debasish Das <debasish.das83@gmail.com>
To: Christoph Sawade <christoph.sawade@googlemail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, "Lizhengbing (bing, BIPA)" <zhengbing.li@huawei.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a7d8e9f8096050370f595
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a7d8e9f8096050370f595
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks Christoph.

Are these numbers for mllib als implicit and explicit feedback on
movielens/netflix datasets documented on JIRA ?
 On Sep 19, 2014 1:16 PM, "Christoph Sawade" <
christoph.sawade@googlemail.com> wrote:

> Hey Deb,
>
> NDCG is the "Normalized Discounted Cumulative Gain" [1]. Another popular
> measure is "Expected Reciprocal Rank" (ERR) [2]; it is based on a
> probabilistic user model, where the user scans the presented list of sear=
ch
> results or recommendations and chooses the first that is sufficiently
> relevant. ERR is the expectation of the reciprocal rank under this model.
> Precision@k is the precision at a cut-off k. Often this is used as an
> overage over the first n k's; a starting point might by [3].
>
> Hope that helps.
>
> Cheers, Christoph
>
> [1] K. J=C3=A4rvelin and J. Kek=C3=A4l=C3=A4inen. Cumulated gain-based ev=
aluation of IR
> techniques. ACM Transactions on Information Systems, 20(4):422=E2=80=9344=
6, 2002.
> [2] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected
> reciprocal rank for graded rel- evance. In Proceeding of the Conference
> on Information and Knowledge Management, 2009.
> [3] http://en.wikipedia.org/wiki/IR_evaluation
>

--047d7b3a7d8e9f8096050370f595--

From dev-return-9511-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 05:30:43 2014
Return-Path: <dev-return-9511-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D3486110CC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 05:30:42 +0000 (UTC)
Received: (qmail 28484 invoked by uid 500); 20 Sep 2014 05:30:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28415 invoked by uid 500); 20 Sep 2014 05:30:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28404 invoked by uid 99); 20 Sep 2014 05:30:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 05:30:41 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 05:30:36 +0000
Received: by mail-oi0-f42.google.com with SMTP id u20so2327870oif.29
        for <dev@spark.apache.org>; Fri, 19 Sep 2014 22:30:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=2BY8hph3BpeQ21+gvZZgVpmXz9zxXASwYhOtAXVX+es=;
        b=SwmeCLAC7CGtufA4sqLmCk2T3X3Z4VTOO46u4jo3DGWDFNNDgjuYWjZ19Zbo1GN/YO
         Yd2rYwB6easeOrzPo1R4kfLnXCHH0axjwD2Yjs0654bCuw+knqbD9IK1LhmPSrifGco2
         j6FPYYv+n5S/HASOkjmjZmpFrXhG1BDYRsD+NaI9r0MByDhbn+16a4oOhD1MjwlfGssL
         JuN2j8/lxv1gGMduYGjI91/cc75+IGxa4DLU2+JgE/uZoBlg9giena6D/apNxoxHUuKX
         lYdZAMW4pN7QeFaSDhwPfJqaI6WxBDmiscQVgjB6UaigbvxzMlCmMwAbNnVNnwayee+X
         m4eA==
X-Gm-Message-State: ALoCoQkSJ0UUTGxyk2DIF6kPb0X81b9BJb8qpocuf9zfqXVP5UUlzQw250Va6fyOxopq3khhYBAE
MIME-Version: 1.0
X-Received: by 10.60.134.76 with SMTP id pi12mr5771606oeb.51.1411191014744;
 Fri, 19 Sep 2014 22:30:14 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Fri, 19 Sep 2014 22:30:14 -0700 (PDT)
Date: Sat, 20 Sep 2014 00:30:14 -0500
Message-ID: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
Subject: guava version conflicts
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b47201224fb8305037883c0
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b47201224fb8305037883c0
Content-Type: text/plain; charset=UTF-8

After the recent spark project changes to guava shading, I'm seeing issues
with the datastax spark cassandra connector (which depends on guava 15.0)
and the datastax cql driver (which depends on guava 16.0.1)

Building an assembly for a job (with spark marked as provided) that
includes either guava 15.0 or 16.0.1, results in errors like the following:

scala> session.close

scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
failed.
java.lang.IllegalAccessError: tried to access class
org.spark-project.guava.common.base.Absent from class
com.google.common.base.Optional
        at com.google.common.base.Optional.absent(Optional.java:79)
        at com.google.common.base.Optional.fromNullable(Optional.java:94)
        at
com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
        at
com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
        at
com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
        at
com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
        at
com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
        at
com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
        at
com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
        at
com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
        at
com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
        at
com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
        at
com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
        at
com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
        at
com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
        at
com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
        at
com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
        at
com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
        at
com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
        at
com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
        at com.datastax.spark.connector.cql.RefCountedCache.com
$datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
        at
com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
        at
com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
        at
com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
        at
scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at
scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
        at
scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
        at
scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
        at com.datastax.spark.connector.cql.RefCountedCache.com
$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
        at
com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
        at
java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at
java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
        at
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:722)

--047d7b47201224fb8305037883c0--

From dev-return-9512-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 05:39:21 2014
Return-Path: <dev-return-9512-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 082E7110DE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 05:39:20 +0000 (UTC)
Received: (qmail 38540 invoked by uid 500); 20 Sep 2014 05:39:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38472 invoked by uid 500); 20 Sep 2014 05:39:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38460 invoked by uid 99); 20 Sep 2014 05:39:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 05:39:17 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLYTO_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tzhang101@yahoo.com designates 98.138.91.245 as permitted sender)
Received: from [98.138.91.245] (HELO nm23-vm5.bullet.mail.ne1.yahoo.com) (98.138.91.245)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 05:38:48 +0000
Received: from [98.138.226.176] by nm23.bullet.mail.ne1.yahoo.com with NNFMP; 20 Sep 2014 05:38:45 -0000
Received: from [98.138.87.4] by tm11.bullet.mail.ne1.yahoo.com with NNFMP; 20 Sep 2014 05:38:45 -0000
Received: from [127.0.0.1] by omp1004.mail.ne1.yahoo.com with NNFMP; 20 Sep 2014 05:38:45 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 304710.26297.bm@omp1004.mail.ne1.yahoo.com
Received: (qmail 20072 invoked by uid 60001); 20 Sep 2014 05:38:45 -0000
X-YMail-OSG: 4IR8OO0VM1k2MQt6y4YKyjEX9MTs6LlSkpzTGZmVgYFkh1J
 oS8BNftpCScg9.Y8yqNV2BDpQy4L_M4kcxu4zP1Fk6e9jdpIHFExIvQOrz9H
 jytxpOTFumtT8ujbqDCFLMZr3XLTmimU3saSe4ehA1Vn678AQTpJhneQhol9
 iomOalmzDDeSvPH4NnLbchzIj89258Ca3pcOXoPJNxn1o4EETJIH0cNh1phq
 XNH9hz8UXcQ0SxEDarijxtglXzhoMHMI_fX0xfRrUyVITyAWWitBRGYI5Gv8
 XxYGMnTRvkfQ9ww7jlZ3QsUKjN8H5YEeZ3e0QIwX7rJBmwS8BYAkJnBRdyOb
 _zw9dUTGMWbIn.YvA58KkVS5pIKrvfAIXt6Pnup0EBXtLdirQ67dxht31XqP
 xaPzRV.Vwv7mqsucrehIdCg4ji4OvjI8wgjSvOJsHCz.GylHn.Bnf_uVsCYx
 wiiv7DF.51ZBCtAPVHxsFn_rllblbpHNPqfJU8j7b3Kd11EfqTVqMimKLR4L
 nGDlzppoOs04gwIIKIP4kZjaJ0u7wXBGKIuKE4X79reRRkote
Received: from [76.220.50.76] by web125504.mail.ne1.yahoo.com via HTTP; Fri, 19 Sep 2014 22:38:44 PDT
X-Rocket-MIMEInfo: 002.001,CgpIaSwgU3BhcmsgZXhwZXJ0cywKCkkgaGF2ZSB0aGUgZm9sbG93aW5nIGlzc3VlIHdoZW4gdXNpbmcgYXdzIGphdmEgc2RrIGluIG15IHNwYXJrIGFwcGxpY2F0aW9uLiBIZXJlIEkgbmFycm93ZWQgZG93biB0aGUgZm9sbG93aW5nIHN0ZXBzIHRvIHJlcHJvZHVjZSB0aGUgcHJvYmxlbQoKMSkgSSBoYXZlIFNwYXJrIDEuMS4wIHdpdGggaGFkb29wIDIuNCBpbnN0YWxsZWQgb24gMyBub2RlcyBjbHVzdGVyCjIpIGZyb20gdGhlIG1hc3RlciBub2RlLCBJIGRpZCB0aGUgZm9sbG93aW5nIHN0ZXBzLgpzcGFyay0BMAEBAQE-
X-Mailer: YahooMailWebService/0.8.203.696
References: 
Message-ID: <1411191524.83515.YahooMailNeo@web125504.mail.ne1.yahoo.com>
Date: Fri, 19 Sep 2014 22:38:44 -0700
From: tian zhang <tzhang101@yahoo.com.INVALID>
Reply-To: tian zhang <tzhang101@yahoo.com>
Subject: spark 1.1.0 (w/ hadoop 2.4) vs aws java sdk 1.7.2
To: "dev@spark.apache.org" <dev@spark.apache.org>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="318864283-1732209569-1411191524=:83515"
X-Virus-Checked: Checked by ClamAV on apache.org

--318864283-1732209569-1411191524=:83515
Content-Type: text/plain; charset=us-ascii



Hi, Spark experts,

I have the following issue when using aws java sdk in my spark application. Here I narrowed down the following steps to reproduce the problem

1) I have Spark 1.1.0 with hadoop 2.4 installed on 3 nodes cluster
2) from the master node, I did the following steps.
spark-shell --jars  ws-java-sdk-1.7.2.jar 
import com.amazonaws.{Protocol, ClientConfiguration}
import com.amazonaws.auth.BasicAWSCredentials
import com.amazonaws.services.s3.AmazonS3Client
val clientConfiguration = new ClientConfiguration()
val s3accessKey="X"
val s3secretKey="Y"
val credentials = new BasicAWSCredentials(s3accessKey,s3secretKey)
println("CLASSPATH="+System.getenv("CLASSPATH"))
CLASSPATH=::/home/hadoop/spark/conf:/home/hadoop/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar:/home/hadoop/conf:/home/hadoop/conf
println("java.class.path="+System.getProperty("java.class.path"))
java.class.path=::/home/hadoop/spark/conf:/home/hadoop/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar:/home/hadoop/conf:/home/hadoop/conf

So far all look good and normal. But then the following step will fail and it looks like the class loader can't resolve to the right class. Any suggestion
for Spark application that requires aws sdk?

scala> val s3Client = new AmazonS3Client(credentials, clientConfiguration)
java.lang.NoClassDefFoundError: org/apache/http/impl/conn/PoolingClientConnectionManager
at com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:26)
at com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:96)
at com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:155)
at com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
at com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
at com.amazonaws.services.s3.AmazonS3Client.<init>(AmazonS3Client.java:334)
at $iwC$$iwC$$iwC$$iwC.<init>(<console>:21)
at $iwC$$iwC$$iwC.<init>(<console>:26)
at $iwC$$iwC.<init>(<console>:28)
at $iwC.<init>(<console>:30)
at <init>(<console>:32)
at .<init>(<console>:36)
at .<clinit>(<console>)
at .<init>(<console>:7)
at .<clinit>(<console>)
at $print(<console>)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:789)
at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1062)
at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:615)
at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:646)
at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:610)
at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:814)
at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:859)
at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:771)
at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:616)
at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:624)
at org.apache.spark.repl.SparkILoop.loop(SparkILoop.scala:629)
at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:954)
at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:902)
at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:902)
at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:902)
at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:997)
at org.apache.spark.repl.Main$.main(Main.scala:31)
at org.apache.spark.repl.Main.main(Main.scala)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:328)
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.conn.PoolingClientConnectionManager
at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
... 46 more

Thanks.

Tian
--318864283-1732209569-1411191524=:83515--

From dev-return-9513-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 06:17:45 2014
Return-Path: <dev-return-9513-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 038D81118B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 06:17:45 +0000 (UTC)
Received: (qmail 71563 invoked by uid 500); 20 Sep 2014 06:17:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71489 invoked by uid 500); 20 Sep 2014 06:17:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71476 invoked by uid 99); 20 Sep 2014 06:17:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 06:17:43 +0000
X-ASF-Spam-Status: No, hits=4.5 required=10.0
	tests=HTML_MESSAGE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of aniket.bhatnagar@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 06:17:39 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <aniket.bhatnagar@gmail.com>)
	id 1XVDyw-0003po-AK
	for dev@spark.incubator.apache.org; Fri, 19 Sep 2014 23:17:18 -0700
Date: Fri, 19 Sep 2014 23:17:18 -0700 (PDT)
From: Aniket <aniket.bhatnagar@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <CAJOb8bukHxtOvM8yCzygZmGUyHC4rLbX=fbfBXdc4oHiaLfPUA@mail.gmail.com>
In-Reply-To: <1411191524.83515.YahooMailNeo@web125504.mail.ne1.yahoo.com>
References: <1411191524.83515.YahooMailNeo@web125504.mail.ne1.yahoo.com>
Subject: Re: spark 1.1.0 (w/ hadoop 2.4) vs aws java sdk 1.7.2
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_103691_1869557.1411193838313"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_103691_1869557.1411193838313
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Looks like the same issue as
http://mail-archives.apache.org/mod_mbox/spark-dev/201409.mbox/%3CCAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com%3E
On Sep 20, 2014 11:09 AM, "tian zhang [via Apache Spark Developers List]" <
ml-node+s1001551n8481h56@n3.nabble.com> wrote:

>
>
> Hi, Spark experts,
>
> I have the following issue when using aws java sdk in my spark
> application. Here I narrowed down the following steps to reproduce the
> problem
>
> 1) I have Spark 1.1.0 with hadoop 2.4 installed on 3 nodes cluster
> 2) from the master node, I did the following steps.
> spark-shell --jars  ws-java-sdk-1.7.2.jar
> import com.amazonaws.{Protocol, ClientConfiguration}
> import com.amazonaws.auth.BasicAWSCredentials
> import com.amazonaws.services.s3.AmazonS3Client
> val clientConfiguration = new ClientConfiguration()
> val s3accessKey="X"
> val s3secretKey="Y"
> val credentials = new BasicAWSCredentials(s3accessKey,s3secretKey)
> println("CLASSPATH="+System.getenv("CLASSPATH"))
> CLASSPATH=::/home/hadoop/spark/conf:/home/hadoop/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar:/home/hadoop/conf:/home/hadoop/conf
>
> println("java.class.path="+System.getProperty("java.class.path"))
> java.class.path=::/home/hadoop/spark/conf:/home/hadoop/spark/lib/spark-assembly-1.1.0-hadoop2.4.0.jar:/home/hadoop/conf:/home/hadoop/conf
>
>
> So far all look good and normal. But then the following step will fail and
> it looks like the class loader can't resolve to the right class. Any
> suggestion
> for Spark application that requires aws sdk?
>
> scala> val s3Client = new AmazonS3Client(credentials, clientConfiguration)
> java.lang.NoClassDefFoundError:
> org/apache/http/impl/conn/PoolingClientConnectionManager
> at
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:26)
>
> at
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:96)
>
> at com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:155)
> at
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
>
> at
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
>
> at
> com.amazonaws.services.s3.AmazonS3Client.<init>(AmazonS3Client.java:334)
> at $iwC$$iwC$$iwC$$iwC.<init>(<console>:21)
> at $iwC$$iwC$$iwC.<init>(<console>:26)
> at $iwC$$iwC.<init>(<console>:28)
> at $iwC.<init>(<console>:30)
> at <init>(<console>:32)
> at .<init>(<console>:36)
> at .<clinit>(<console>)
> at .<init>(<console>:7)
> at .<clinit>(<console>)
> at $print(<console>)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
>
> at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
>
> at java.lang.reflect.Method.invoke(Method.java:606)
> at
> org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:789)
> at
> org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1062)
> at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:615)
> at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:646)
> at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:610)
> at
> org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:814)
> at
> org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:859)
>
> at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:771)
> at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:616)
> at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:624)
> at org.apache.spark.repl.SparkILoop.loop(SparkILoop.scala:629)
> at
> org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:954)
>
> at
> org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:902)
>
> at
> org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:902)
>
> at
> scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
>
> at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:902)
> at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:997)
> at org.apache.spark.repl.Main$.main(Main.scala:31)
> at org.apache.spark.repl.Main.main(Main.scala)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
>
> at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
>
> at java.lang.reflect.Method.invoke(Method.java:606)
> at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:328)
> at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
> at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
> Caused by: java.lang.ClassNotFoundException:
> org.apache.http.impl.conn.PoolingClientConnectionManager
> at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
> ... 46 more
>
> Thanks.
>
> Tian
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://apache-spark-developers-list.1001551.n3.nabble.com/spark-1-1-0-w-hadoop-2-4-vs-aws-java-sdk-1-7-2-tp8481.html
>  To start a new topic under Apache Spark Developers List, email
> ml-node+s1001551n1h76@n3.nabble.com
> To unsubscribe from Apache Spark Developers List, click here
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=1&code=YW5pa2V0LmJoYXRuYWdhckBnbWFpbC5jb218MXwxMzE3NTAzMzQz>
> .
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/spark-1-1-0-w-hadoop-2-4-vs-aws-java-sdk-1-7-2-tp8481p8482.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_103691_1869557.1411193838313--

From dev-return-9514-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 08:25:05 2014
Return-Path: <dev-return-9514-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 51F0E113B7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 08:25:05 +0000 (UTC)
Received: (qmail 95771 invoked by uid 500); 20 Sep 2014 08:25:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95689 invoked by uid 500); 20 Sep 2014 08:25:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95678 invoked by uid 99); 20 Sep 2014 08:25:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 08:25:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.44] (HELO mail-qa0-f44.google.com) (209.85.216.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 08:25:00 +0000
Received: by mail-qa0-f44.google.com with SMTP id dc16so1741213qab.3
        for <dev@spark.apache.org>; Sat, 20 Sep 2014 01:24:39 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=V/GA+6f4rif1iKEFesyo91n8Z5a0rB6RXiUDMAOLIRM=;
        b=DOPnBegWZvAbTJmMeB80AvvYWVfnf7rp0/VdYiLKE7hX/lu373MOb58EBGDq4YxbTB
         0qL9GH0kbzdvpbXsKPsS0Z8diMKujNTmWQF0njounFXrVtxFxWwFj16kia/I3sQl20dm
         jDBpW5mwzD8CazpkL6ayawSaGTFk8T2NIG0PljKN3t5+bNIQLPzQfeP9UIo1Gas3lI30
         UDFTqMJnmga5YTu7pT5AwReoIPb8yY9PCEEBF0T98h/vfOPVIni+56VZcFD3PZ9KGZt/
         HT/CvSGw2zdLFXx2uRO7kbw6yzetZW0XGIXU/iGEyTLMsPRjSEDmQ6l8WPGk59d6Tgm7
         qfRA==
X-Gm-Message-State: ALoCoQnsheafbG7/je4Q6gcS3uUEH4OBNVI3aVROV/PJG9CLzgdtu5wWk+p3ZFDpMQ8KYRUd/1HT
X-Received: by 10.140.47.137 with SMTP id m9mr351306qga.95.1411201478981; Sat,
 20 Sep 2014 01:24:38 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Sat, 20 Sep 2014 01:24:18 -0700 (PDT)
In-Reply-To: <CAJiQeYJuF79Dt4usg6OH-FAa8ozA+82dOrHVG4Oty48eFXh75w@mail.gmail.com>
References: <CAJiQeYJ=UvuOownStpX+fTxKrZS9Sg7=hSCeD_RJ=-SAX1snWQ@mail.gmail.com>
 <CAJiQeYL9xXFzHKZ-3VjO8xT2DnQR0yfY5Ls9em9JXb2HXZZenw@mail.gmail.com>
 <CANGvG8oR9D40oZGSXPzZ7+M=bE+3zdTCmy+HKNXgTvvRHYnRdQ@mail.gmail.com>
 <CABPQxsuREAO284UkSgK0EoprmPwWqjcACpLOyvC1cnRJnAe6xQ@mail.gmail.com>
 <CAJiQeY+K7Z97hhYFuEuh9VU8_xKs=uNq-NMMXA32752EBBEfew@mail.gmail.com>
 <CAPh_B=bQ3fU3OHKW7+7RN_+cMZrZD1MOidcWsZytKga36VwxSw@mail.gmail.com>
 <CAJiQeYKoo-6r_4q75FmcryKqy_iLcT929LKurP8AEAGgMFJrjg@mail.gmail.com>
 <CAPh_B=aG=oXBLZ=iFhaLumdE0-HT+GKZgvHXQCu4ZOjDJOpEAA@mail.gmail.com>
 <CAJiQeYJ+FRP9WdyvE2yMqde8a8LW=R5+C2537Wbpa1OaGq-6nA@mail.gmail.com>
 <CAPh_B=aJUm3fb06a9mNPtz+ec17YKyXELdvHW-1SwpOnz+6vsA@mail.gmail.com>
 <CAPh_B=bZGzU=zRgNApP5nkdOuh=L36FqJU9zuaU_ZD2jnBAPKw@mail.gmail.com> <CAJiQeYJuF79Dt4usg6OH-FAa8ozA+82dOrHVG4Oty48eFXh75w@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sat, 20 Sep 2014 01:24:18 -0700
Message-ID: <CAPh_B=atJrRPHT46sYch8g9kQBG=xdNBC42+aYVGuSYnh+gvXg@mail.gmail.com>
Subject: Re: Eliminate copy while sending data : any Akka experts here ?
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c165d6dcacc005037af278
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c165d6dcacc005037af278
Content-Type: text/plain; charset=UTF-8

BTW - a partial solution here: https://github.com/apache/spark/pull/2470

This doesn't address the 0 size block problem yet, but makes my large job
on hundreds of terabytes of data much more reliable.


On Fri, Jul 4, 2014 at 2:28 AM, Mridul Muralidharan <mridul@gmail.com>
wrote:

> In our clusters, number of containers we can get is high but memory
> per container is low : which is why avg_nodes_not_hosting data is
> rarely zero for ML tasks :-)
>
> To update - to unblock our current implementation efforts, we went
> with broadcast - since it is intutively easier and minimal change; and
> compress the array as bytes in TaskResult.
> This is then stored in disk backed maps - to remove memory pressure on
> master and workers (else MapOutputTracker becomes a memory hog).
>
> But I agree, compressed bitmap to represent 'large' blocks (anything
> larger that maxBytesInFlight actually) and probably existing to track
> non zero should be fine (we should not really track zero output for
> reducer - just waste of space).
>
>
> Regards,
> Mridul
>
> On Fri, Jul 4, 2014 at 3:43 AM, Reynold Xin <rxin@databricks.com> wrote:
> > Note that in my original proposal, I was suggesting we could track
> whether
> > block size = 0 using a compressed bitmap. That way we can still avoid
> > requests for zero-sized blocks.
> >
> >
> >
> > On Thu, Jul 3, 2014 at 3:12 PM, Reynold Xin <rxin@databricks.com> wrote:
> >
> >> Yes, that number is likely == 0 in any real workload ...
> >>
> >>
> >> On Thu, Jul 3, 2014 at 8:01 AM, Mridul Muralidharan <mridul@gmail.com>
> >> wrote:
> >>
> >>> On Thu, Jul 3, 2014 at 11:32 AM, Reynold Xin <rxin@databricks.com>
> wrote:
> >>> > On Wed, Jul 2, 2014 at 3:44 AM, Mridul Muralidharan <
> mridul@gmail.com>
> >>> > wrote:
> >>> >
> >>> >>
> >>> >> >
> >>> >> > The other thing we do need is the location of blocks. This is
> >>> actually
> >>> >> just
> >>> >> > O(n) because we just need to know where the map was run.
> >>> >>
> >>> >> For well partitioned data, wont this not involve a lot of unwanted
> >>> >> requests to nodes which are not hosting data for a reducer (and lack
> >>> >> of ability to throttle).
> >>> >>
> >>> >
> >>> > Was that a question? (I'm guessing it is). What do you mean exactly?
> >>>
> >>>
> >>> I was not sure if I understood the proposal correctly - hence the
> >>> query : if I understood it right - the number of wasted requests goes
> >>> up by num_reducers * avg_nodes_not_hosting data.
> >>>
> >>> Ofcourse, if avg_nodes_not_hosting data == 0, then we are fine !
> >>>
> >>> Regards,
> >>> Mridul
> >>>
> >>
> >>
>

--001a11c165d6dcacc005037af278--

From dev-return-9515-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 15:50:54 2014
Return-Path: <dev-return-9515-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B649711B15
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 15:50:54 +0000 (UTC)
Received: (qmail 47472 invoked by uid 500); 20 Sep 2014 15:50:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47396 invoked by uid 500); 20 Sep 2014 15:50:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47385 invoked by uid 99); 20 Sep 2014 15:50:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 15:50:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 15:50:47 +0000
Received: by mail-qc0-f178.google.com with SMTP id w7so3886948qcr.9
        for <dev@spark.apache.org>; Sat, 20 Sep 2014 08:50:26 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=LuFo46MDw2//8kyO0S8Tuji5gy7/VXjZRfHP4cknBFs=;
        b=ONPQF1hV7fPL4f+YfQH44P0+sOATDxq3mR06CYOutaIaycydXHZqkc06eqAzFg1BM9
         P0jzpsusTK8pXyHbOBVrqLQp3VXQjcd3LZcbdZph2XbLgEZSrHT0/lUhYWTtET8U6Yge
         98p7omfVYQ/hJQwMk9HvPluSulMPwRBZtjmVyp2sVxDqNfQLVQVl1WtfHoFt5w7tU8wb
         Quux1YEDOpdRYIH8yFmJl7OW6NcXKlo1fC0vKIvd0sLQEA/X1cUwdisw12buD2ShmcIS
         IwKqXRTv/wkR6UPZj6mWC3je6Ip7FZ6OtTvgek+BljTn5bTYstnblnbkhZhL2UtRdVTp
         G5VQ==
X-Gm-Message-State: ALoCoQlPjYnqwt3uubBWdX01WdD7LMDQfmY3NOcjGCRnJ8K3EpubnOkfGrUauom5wPj41rGAy7FK
MIME-Version: 1.0
X-Received: by 10.224.163.8 with SMTP id y8mr2179317qax.60.1411228226319; Sat,
 20 Sep 2014 08:50:26 -0700 (PDT)
Received: by 10.140.42.37 with HTTP; Sat, 20 Sep 2014 08:50:26 -0700 (PDT)
Date: Sat, 20 Sep 2014 11:50:26 -0400
Message-ID: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
Subject: A couple questions about shared variables
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01294f542134320503812d34
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01294f542134320503812d34
Content-Type: text/plain; charset=UTF-8

Hey All,

A couple questions came up about shared variables recently, and I wanted to
confirm my understanding and update the doc to be a little more clear.

*Broadcast variables*
Now that tasks data is automatically broadcast, the only occasions where it
makes sense to explicitly broadcast are:
* You want to use a variable from tasks in multiple stages.
* You want to have the variable stored on the executors in deserialized
form.
* You want tasks to be able to modify the variable and have those
modifications take effect for other tasks running on the same executor
(usually a very bad idea).

Is that right?

*Accumulators*
Values are only counted for successful tasks.  Is that right?  KMeans seems
to use it in this way.  What happens if a node goes away and successful
tasks need to be resubmitted?  Or the stage runs again because a different
job needed it.

thanks,
Sandy

--089e01294f542134320503812d34--

From dev-return-9516-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 20 22:05:29 2014
Return-Path: <dev-return-9516-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 27F73111D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 20 Sep 2014 22:05:29 +0000 (UTC)
Received: (qmail 51010 invoked by uid 500); 20 Sep 2014 22:05:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50938 invoked by uid 500); 20 Sep 2014 22:05:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50927 invoked by uid 99); 20 Sep 2014 22:05:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 22:05:28 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of lsyurd@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 20 Sep 2014 22:05:22 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <lsyurd@gmail.com>)
	id 1XVSm6-00067B-4b
	for dev@spark.incubator.apache.org; Sat, 20 Sep 2014 15:05:02 -0700
Date: Sat, 20 Sep 2014 15:05:02 -0700 (PDT)
From: Seraph <lsyurd@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411250702072-8485.post@n3.nabble.com>
In-Reply-To: <CANJrAvBfzo_9d3TjKv9bQ59A82nau6m_cPrZ3cM9n2XT3YqeZw@mail.gmail.com>
References: <CANJrAvBfzo_9d3TjKv9bQ59A82nau6m_cPrZ3cM9n2XT3YqeZw@mail.gmail.com>
Subject: Re: A Comparison of Platforms for Implementing and Running Very
 Large Scale Machine Learning Algorithms
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I=E2=80=99m also one of the authors of this paper and I am responsible for =
the Spark
experiments in this paper. Thank you for your guys discussion!

(1)

Ignacio Zendejas wrote
> I should rephrase my question as it was poorly phrased: on average, how=
=20
> much faster is Spark v. PySpark (I didn't really mean Scala v. Python)?=
=20
> I've only used Spark and don't have a chance to test this at the moment s=
o=20
> if anybody has these numbers or general estimates (10x, etc), that'd be=
=20
> great.=20


Davies Liu wrote
> A quick comparison by word count on 4.3G text file (local mode),=20
>=20
> Spark:  40 seconds=20
> PySpark: 2 minutes and 16 seconds=20
>=20
> So PySpark is 3.4x slower than Spark.=20

>From my perspective, it is a difficult task to compare the speed between
"scala & python", or "spark & pyspark". Simple examples may not be enough
for us to draw a conclusion on such comparison. We may need more complex
models for testing to obtain more comprehensive ideas. It is possible that
spark is fast in some applications, but it is slower than pyspark in others=
.
So the speed issue should be application specific. It is also one of the
purpose for our paper: shed some light such benchmarks for
platform/performance comparison.

(2)

Matei Zaharia wrote
> Just as a note on this paper, apart from implementing the algorithms in
> naive Python, they also run it in a fairly inefficient way. In particular
> their implementations send the model out with every task closure, which i=
s
> really expensive for a large model, and bring it back with collectAsMap()=
.
> It would be much more efficient to send it e.g. with
> SparkContext.broadcast() or keep it distributed on the cluster throughout
> the computation, instead of making the drive node a bottleneck for
> communication.=20

We have tried our best to write several implementation methods for each
model, in order to pick up the optimal one. Some functions may seem
promising, but they fail when we did our experiments. Broadcast() is a good
idea, and we can try it for our models to see if it can bring much
difference. But as cjermaine said, "broadcast models" should not be a
bottleneck because the models are small int all experiments. Also, we may
change the parameters of models in each iteration, so the "one time
broadcast" may not provide so much help as expected. Moreover, we are reall=
y
careful when we use collect() or collectAsMap(). In our experiments, we do
not collect large sets of data by collectAsMap(), and it does not consume
much time either.=20

Overall, I have no doubt that Spark developers can write more efficient cod=
e
for our models, and it is very welcome that some Spark developers can
provide better implementations for our experiments.

Thanks!




--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/A-Comparison-of-Platforms-for-Implementing-and-Running-Very-La=
rge-Scale-Machine-Learning-Algorithms-tp7823p8485.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9517-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 21 01:38:57 2014
Return-Path: <dev-return-9517-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D845A1140C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 21 Sep 2014 01:38:57 +0000 (UTC)
Received: (qmail 58340 invoked by uid 500); 21 Sep 2014 01:38:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58253 invoked by uid 500); 21 Sep 2014 01:38:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58241 invoked by uid 99); 21 Sep 2014 01:38:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 01:38:56 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.54 as permitted sender)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 01:38:31 +0000
Received: by mail-qa0-f54.google.com with SMTP id v10so4096469qac.41
        for <dev@spark.apache.org>; Sat, 20 Sep 2014 18:38:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=vL3+4keWxTHlrJQGMDdIl5z+LTXkiRBekEuPQ7BzGd0=;
        b=LsYCJyo4/n/OqE/gRj7C7b3Ant1PUq7ORY15pheVtythJRn64pZZm22uR/9FjHzX7b
         uoLJvMhm9ZkrymONC9O+eCmttVR3fFYkk783KX+iOImNBEMRgSnjS5BhCrwulHP/8ouv
         YglSNLoWN8x2Lcfw2G6HvuJo6QrZfMs1Pdd+0en4iW1ogJY92/avFCcwkdCWvaM+JaiL
         K27ffafK2SkdRL65RYxvZv7uVt1ed9hjyprrdVQ3KxOUYhKzWnBxnoo+p4MZYj41Lyuv
         pUY7LHT7CH2OV6D7Qx+Q6lpBqiMIrRR82jmxJmrbhFAC4yM4Xo+P/BSK+H5GmCzmwUJ5
         oYew==
X-Gm-Message-State: ALoCoQmm9RAc8KCTbFJfFUuTZMLRbpUzCHqRQqRSXQj8MLxAviM1g6E6yko2/aLQ38cNdFbEd9gG
MIME-Version: 1.0
X-Received: by 10.140.98.102 with SMTP id n93mr12387213qge.83.1411263509681;
 Sat, 20 Sep 2014 18:38:29 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Sat, 20 Sep 2014 18:38:29 -0700 (PDT)
In-Reply-To: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
Date: Sat, 20 Sep 2014 18:38:29 -0700
Message-ID: <CAAOnQ7skaF+J-5qPSRDV99wihgaejmxBNWay4z9kbX9hw5=i2Q@mail.gmail.com>
Subject: Re: guava version conflicts
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hmm, looks like the hack to maintain backwards compatibility in the
Java API didn't work that well. I'll take a closer look at this when I
get to work on Monday.

On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org> wrote:
> After the recent spark project changes to guava shading, I'm seeing issues
> with the datastax spark cassandra connector (which depends on guava 15.0)
> and the datastax cql driver (which depends on guava 16.0.1)
>
> Building an assembly for a job (with spark marked as provided) that
> includes either guava 15.0 or 16.0.1, results in errors like the following:
>
> scala> session.close
>
> scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
> failed.
> java.lang.IllegalAccessError: tried to access class
> org.spark-project.guava.common.base.Absent from class
> com.google.common.base.Optional
>         at com.google.common.base.Optional.absent(Optional.java:79)
>         at com.google.common.base.Optional.fromNullable(Optional.java:94)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
>         at
> com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
>         at
> com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
>         at
> com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
>         at
> com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
>         at
> com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
>         at
> com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
>         at
> com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
>         at
> com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
>         at
> com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
>         at
> com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>         at com.datastax.spark.connector.cql.RefCountedCache.com
> $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
>         at
> scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
>         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
>         at
> scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
>         at
> scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
>         at scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
>         at
> scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
>         at com.datastax.spark.connector.cql.RefCountedCache.com
> $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
>         at
> java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
>         at
> java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
>         at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
>         at
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
>         at
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
>         at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>         at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>         at java.lang.Thread.run(Thread.java:722)



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9518-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 21 05:10:38 2014
Return-Path: <dev-return-9518-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D5D411642
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 21 Sep 2014 05:10:38 +0000 (UTC)
Received: (qmail 92950 invoked by uid 500); 21 Sep 2014 05:10:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92871 invoked by uid 500); 21 Sep 2014 05:10:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92859 invoked by uid 99); 21 Sep 2014 05:10:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 05:10:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.173 as permitted sender)
Received: from [209.85.192.173] (HELO mail-pd0-f173.google.com) (209.85.192.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 05:10:09 +0000
Received: by mail-pd0-f173.google.com with SMTP id y10so2379350pdj.4
        for <dev@spark.apache.org>; Sat, 20 Sep 2014 22:10:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=gVCLnc4t0jT2y1soN7nICFIjrwVLey89VJqq1nyFOsY=;
        b=fxu2DrrH8XYKlrR8NCMX2NC2GHi3BfB69S1Vk9X6P5LQyOgr52kifbwFeoNwPc58FV
         z8J0JX82jjAhbQq30tQxNJCoYPlidOQyQj0zRagj90+f94rBXW/9Dvy2+3g++1G7PEqk
         0xE1MCUvJpDrVzhgFB2m6tbngLAZ4yFl0zmAKUSayhhZHzWEKajOFWUGckwsQzxBJWEl
         5ep8EizWE6JPxTwHuIA5V8SZMxuqnfRreFRu8BuT7ZXcRZ2TcuALlfly/hBwSWpU7c6w
         9H7CPl6ubgn9l+Kwv48VCvHdMtxTlM7DrJaBbf0xUgZ+K816SheLbxnxCQZ2/pSme0rq
         R7Tg==
X-Received: by 10.68.218.103 with SMTP id pf7mr549949pbc.153.1411276207763;
        Sat, 20 Sep 2014 22:10:07 -0700 (PDT)
Received: from mbp-3.local (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id dl8sm5848950pdb.65.2014.09.20.22.10.06
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 20 Sep 2014 22:10:07 -0700 (PDT)
Date: Sat, 20 Sep 2014 22:10:05 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.541e5dad.4db127f8.c101@mbp-3.local>
In-Reply-To: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
Subject: Re: A couple questions about shared variables
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="541e5dad_216231b_c101"
X-Virus-Checked: Checked by ClamAV on apache.org

--541e5dad_216231b_c101
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hey Sandy,

On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=40cloudera.co=
m) wrote:

Hey All,=C2=A0

A couple questions came up about shared variables recently, and I wanted =
to=C2=A0
confirm my understanding and update the doc to be a little more clear.=C2=
=A0

*Broadcast variables*=C2=A0
Now that tasks data is automatically broadcast, the only occasions where =
it=C2=A0
makes sense to explicitly broadcast are:=C2=A0
* You want to use a variable from tasks in multiple stages.=C2=A0
* You want to have the variable stored on the executors in deserialized=C2=
=A0
form.=C2=A0
* You want tasks to be able to modify the variable and have those=C2=A0
modifications take effect for other tasks running on the same executor=C2=
=A0
(usually a very bad idea).=C2=A0

Is that right=3F=C2=A0
Yeah, pretty much. Reason 1 above is probably the biggest, but 2 also mat=
ters. (We might later factor tasks in a different way to avoid 2, but it'=
s hard due to things like Hadoop JobConf objects in the tasks).


*Accumulators*=C2=A0
Values are only counted for successful tasks. Is that right=3F KMeans see=
ms=C2=A0
to use it in this way. What happens if a node goes away and successful=C2=
=A0
tasks need to be resubmitted=3F Or the stage runs again because a differe=
nt=C2=A0
job needed it.=C2=A0
Accumulators are guaranteed to give a deterministic result if you only in=
crement them in actions. =46or each result stage, the accumulator's updat=
e from each task is only applied once, even if that task runs multiple ti=
mes. If you use accumulators in transformations (i.e. in a stage that may=
 be part of multiple jobs), then you may see multiple updates, from each =
run. This is kind of confusing but it was useful for people who wanted to=
 use these for debugging.

Matei





thanks,=C2=A0
Sandy=C2=A0

--541e5dad_216231b_c101--


From dev-return-9519-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 21 20:11:40 2014
Return-Path: <dev-return-9519-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0EA8111340
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 21 Sep 2014 20:11:40 +0000 (UTC)
Received: (qmail 85846 invoked by uid 500); 21 Sep 2014 20:11:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85774 invoked by uid 500); 21 Sep 2014 20:11:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85762 invoked by uid 99); 21 Sep 2014 20:11:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 20:11:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.176 as permitted sender)
Received: from [209.85.213.176] (HELO mail-ig0-f176.google.com) (209.85.213.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 20:11:34 +0000
Received: by mail-ig0-f176.google.com with SMTP id hn15so1657563igb.3
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 13:11:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=j/HaMLzTucvIz+MM25U8l4yZoZJakOGSYQvU/+QCC1E=;
        b=K86BOSUlOH9hHuBtJD/UEnBLlN+FPfnC/Pt82IaK8q8higN8FhjF6b+2gIz6zLfQVc
         RWJCB6i+uuC3Suhm1pdZDPTbDuS7fwIwwdqqWKMJ2VToLdqoNIjE3gfNl7bvQqoC56Io
         mMwWzibEqmnBR6MFG86HmBEMqglk40WFRN9TKKAEmkGVNpOo+09V+851fA3roqJVpZFv
         ATncNtA6NlETPK2gmzuedLAw5a+7NraINUeHeWT7ZGBOdGTAErQQOPGOZZ/ejSfqahs4
         pn/WJxNzIrAuHSA17hduDigV6UVhNXV9if+0lzAXyrWmveOwewx6Jx7LiLllPhuuJjFZ
         Ih3A==
X-Received: by 10.51.17.66 with SMTP id gc2mr10282267igd.40.1411330273589;
        Sun, 21 Sep 2014 13:11:13 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id e16sm7136502igz.8.2014.09.21.13.11.13
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sun, 21 Sep 2014 13:11:13 -0700 (PDT)
Date: Sun, 21 Sep 2014 16:25:33 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <94DE5E900B054CF487A51DAA4451291C@gmail.com>
In-Reply-To: <etPan.541e5dad.4db127f8.c101@mbp-3.local>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
 <etPan.541e5dad.4db127f8.c101@mbp-3.local>
Subject: Re: A couple questions about shared variables
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="541f343d_12200854_1f0"
X-Virus-Checked: Checked by ClamAV on apache.org

--541f343d_12200854_1f0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi, Matei,  =20

Can you give some hint on how the current implementation guarantee the ac=
cumulator is only applied for once=3F

There is a pending PR trying to achieving this (https://github.com/apache=
/spark/pull/228/files), but from the current implementation, I didn=E2=80=
=99t see this has been done=3F (maybe I missed something)

Best, =20

-- =20
Nan Zhu


On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:

> Hey Sandy,
> =20
> On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=40cloudera.=
com (mailto:sandy.ryza=40cloudera.com)) wrote:
> =20
> Hey All, =20
> =20
> A couple questions came up about shared variables recently, and I wante=
d to =20
> confirm my understanding and update the doc to be a little more clear. =
=20
> =20
> *Broadcast variables* =20
> Now that tasks data is automatically broadcast, the only occasions wher=
e it =20
> makes sense to explicitly broadcast are: =20
> * You want to use a variable from tasks in multiple stages. =20
> * You want to have the variable stored on the executors in deserialized=
 =20
> form. =20
> * You want tasks to be able to modify the variable and have those =20
> modifications take effect for other tasks running on the same executor =
=20
> (usually a very bad idea). =20
> =20
> Is that right=3F =20
> Yeah, pretty much. Reason 1 above is probably the biggest, but 2 also m=
atters. (We might later factor tasks in a different way to avoid 2, but i=
t's hard due to things like Hadoop JobConf objects in the tasks).
> =20
> =20
> *Accumulators* =20
> Values are only counted for successful tasks. Is that right=3F KMeans s=
eems =20
> to use it in this way. What happens if a node goes away and successful =
=20
> tasks need to be resubmitted=3F Or the stage runs again because a diffe=
rent =20
> job needed it. =20
> Accumulators are guaranteed to give a deterministic result if you only =
increment them in actions. =46or each result stage, the accumulator's upd=
ate from each task is only applied once, even if that task runs multiple =
times. If you use accumulators in transformations (i.e. in a stage that m=
ay be part of multiple jobs), then you may see multiple updates, from eac=
h run. This is kind of confusing but it was useful for people who wanted =
to use these for debugging.
> =20
> Matei
> =20
> =20
> =20
> =20
> =20
> thanks, =20
> Sandy =20
> =20
> =20



--541f343d_12200854_1f0--


From dev-return-9520-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 21 22:36:14 2014
Return-Path: <dev-return-9520-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A834115F3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 21 Sep 2014 22:36:14 +0000 (UTC)
Received: (qmail 14143 invoked by uid 500); 21 Sep 2014 22:36:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14071 invoked by uid 500); 21 Sep 2014 22:36:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14059 invoked by uid 99); 21 Sep 2014 22:36:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 22:36:13 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 21 Sep 2014 22:35:47 +0000
Received: by mail-pa0-f50.google.com with SMTP id rd3so1836340pab.9
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 15:35:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=jP1IBKBNK8cj8sAMwtWzASKbpmf5/qBA4UjSUC+VBHA=;
        b=F1yviFXG8AkiKqYcC4MPp0MSiyTMx0JZW+vxd7GJ0bSSaAGCpG7il8fNyOSOsQfDsS
         NdXWCm1uE680aJ3G3gTsbt4a8v06rPSdCDUKh/DskDphbNKpAWd481CnhsBIExglygjm
         O/IDdwq3d0190u6b79ygb0kS4s9syXcHp3At8QcMrLfBegEulKd7tozRxFDTOn5Y6uYO
         2zaHEPntV7p8iagqaqyV+ViKO3+P+v8rbPczyQ8SxOcuJhYzuXdOdnX2bvf5YshzlmQe
         7CJt5czCQhbn5220lb430XwMC0inxCsohjo4dZFQl8kb1bcz0OECFjMeYfhVeWRuywoM
         hY6Q==
X-Received: by 10.67.4.230 with SMTP id ch6mr20930015pad.109.1411338945771;
        Sun, 21 Sep 2014 15:35:45 -0700 (PDT)
Received: from mbp-3 (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id i1sm7536998pdf.46.2014.09.21.15.35.43
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 21 Sep 2014 15:35:43 -0700 (PDT)
Date: Sun, 21 Sep 2014 15:35:42 -0700
From: Matei Zaharia <matei.zaharia@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.541f52be.ded7263.c101@mbp-3>
In-Reply-To: <94DE5E900B054CF487A51DAA4451291C@gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
 <etPan.541e5dad.4db127f8.c101@mbp-3.local>
 <94DE5E900B054CF487A51DAA4451291C@gmail.com>
Subject: Re: A couple questions about shared variables
X-Mailer: Airmail (247)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="541f52be_7fdcc233_c101"
X-Virus-Checked: Checked by ClamAV on apache.org

--541f52be_7fdcc233_c101
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hmm, good point, this seems to have been broken by refactorings of the sc=
heduler, but it worked in the past. Basically the solution is simple -- i=
n a result stage, we should not apply the update for each task ID more th=
an once -- the same way we don't call job.listener.taskSucceeded more tha=
n once. Your PR also tried to avoid this for resubmitted shuffle stages, =
but I don't think we need to do that necessarily (though we could).

Matei

On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill=40gmail.com) w=
rote:

Hi, Matei,=C2=A0

Can you give some hint on how the current implementation guarantee the ac=
cumulator is only=C2=A0applied for once=3F

There is a pending PR trying to achieving this (https://github.com/apache=
/spark/pull/228/files), but from the current implementation, I didn=E2=80=
=99t see this has been done=3F (maybe I missed something)

Best,

--=C2=A0
Nan Zhu
On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:

Hey Sandy,

On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=40cloudera.co=
m) wrote:

Hey All,=C2=A0

A couple questions came up about shared variables recently, and I wanted =
to=C2=A0
confirm my understanding and update the doc to be a little more clear.=C2=
=A0

*Broadcast variables*=C2=A0
Now that tasks data is automatically broadcast, the only occasions where =
it=C2=A0
makes sense to explicitly broadcast are:=C2=A0
* You want to use a variable from tasks in multiple stages.=C2=A0
* You want to have the variable stored on the executors in deserialized=C2=
=A0
form.=C2=A0
* You want tasks to be able to modify the variable and have those=C2=A0
modifications take effect for other tasks running on the same executor=C2=
=A0
(usually a very bad idea).=C2=A0

Is that right=3F=C2=A0
Yeah, pretty much. Reason 1 above is probably the biggest, but 2 also mat=
ters. (We might later factor tasks in a different way to avoid 2, but it'=
s hard due to things like Hadoop JobConf objects in the tasks).


*Accumulators*=C2=A0
Values are only counted for successful tasks. Is that right=3F KMeans see=
ms=C2=A0
to use it in this way. What happens if a node goes away and successful=C2=
=A0
tasks need to be resubmitted=3F Or the stage runs again because a differe=
nt=C2=A0
job needed it.=C2=A0
Accumulators are guaranteed to give a deterministic result if you only in=
crement them in actions. =46or each result stage, the accumulator's updat=
e from each task is only applied once, even if that task runs multiple ti=
mes. If you use accumulators in transformations (i.e. in a stage that may=
 be part of multiple jobs), then you may see multiple updates, from each =
run. This is kind of confusing but it was useful for people who wanted to=
 use these for debugging.

Matei





thanks,=C2=A0
Sandy=C2=A0


--541f52be_7fdcc233_c101--


From dev-return-9521-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 03:41:53 2014
Return-Path: <dev-return-9521-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6238211ABE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 03:41:53 +0000 (UTC)
Received: (qmail 35043 invoked by uid 500); 22 Sep 2014 03:41:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34965 invoked by uid 500); 22 Sep 2014 03:41:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34954 invoked by uid 99); 22 Sep 2014 03:41:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 03:41:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nravi@cloudera.com designates 209.85.213.178 as permitted sender)
Received: from [209.85.213.178] (HELO mail-ig0-f178.google.com) (209.85.213.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 03:41:46 +0000
Received: by mail-ig0-f178.google.com with SMTP id r10so2006418igi.11
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 20:41:26 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=I/28GDGYxrYERird7IOYZRGTnA9UqW98zSI3RzamqEY=;
        b=GLEcFWiuzC21Z8Ac+DL4WgEXUMJsKao3iV88T/yHq+8in94a8SRRUuk1HbrCurqtkA
         4C6sF21YtM5G8Az8JjDs3wUhFKCTu3UNbpe0ijDL+eHHBqoGoPp6OBFyub98MWs5GvFS
         5Gac3nc8aNWcPb0gGWiVrv3mGelEQq/8GruQLbbVrN+VlOKUWq6CazYUBYsPm8R4QW/j
         sJECzWpZcbitcL9n2VoqNvnZEg81fc2BV/aR+mJbTNuUoXfNSWNpS9MC+mnSFE5enM+u
         cSvDTffapOg5uzlSh7nOfNTjdIN7xV/52faXQpFmOFCkfCRbqQzn11c/tT8FlDUzO2Hj
         bR5A==
X-Gm-Message-State: ALoCoQngD17H8I/mcQxjKcqss2wYCtG/SXeS+6o43vJAmaOsAhpBMV5KFNsRUFQ7N2UNgV6yHG2j
X-Received: by 10.42.114.130 with SMTP id g2mr14313950icq.46.1411357286118;
 Sun, 21 Sep 2014 20:41:26 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.166.79 with HTTP; Sun, 21 Sep 2014 20:41:06 -0700 (PDT)
From: Nishkam Ravi <nravi@cloudera.com>
Date: Sun, 21 Sep 2014 20:41:06 -0700
Message-ID: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
Subject: BlockManager issues
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf303bf576b0d16305039f392e
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf303bf576b0d16305039f392e
Content-Type: text/plain; charset=UTF-8

Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of the
workloads. Tried tracing the problem through change set analysis. Looks
like the offending commit is 4fde28c from Aug 4th for PR1707. Please see
SPARK-3633 for more details.

Thanks,
Nishkam

--20cf303bf576b0d16305039f392e--

From dev-return-9522-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 03:46:31 2014
Return-Path: <dev-return-9522-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5884111AD2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 03:46:31 +0000 (UTC)
Received: (qmail 40842 invoked by uid 500); 22 Sep 2014 03:46:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40771 invoked by uid 500); 22 Sep 2014 03:46:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40760 invoked by uid 99); 22 Sep 2014 03:46:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 03:46:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 03:46:03 +0000
Received: by mail-qc0-f169.google.com with SMTP id r5so5673004qcx.14
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 20:46:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=kJX8dnaO/MG25wkkY1RUEMhlai9Pdcq94OM1gFjHbmI=;
        b=LFH1YUgfyGt9Wq7QQ5e8iOmccERQL/zlEciX45y807w4UNHKlLnsVb/4tm1am9ofBO
         1jlhi+l+Nf3ahT3G9RaAGg+hgcEmY37PLe8a3zJMlKIAm9UYKJgHsDPEik5DnbqA4ZLC
         cymKgIfkNzvNT9+MGjIXGoITZMX7VE2Xy5gGLrUDTL+QTyBUH4PcQ5Qo28DJ101KkvNc
         9rFujln4EwmL7ZyadaGQ549k43g/VMkT8Da2mJJCsk8JI7BjnHA1jmq3pOlS+kn3mJFX
         0VDLq9Cl7m3bUDhe7u26A4czWNuoeL/Ahfd1ebY7kOVu4I7IF7pQKJtXenRiZDMfJfYG
         s1Kw==
X-Gm-Message-State: ALoCoQm5Rg8J+4gelOojIVr7WpBVfM54GaX6G/ejynS3AlKVuQ8koOWAxkrBQpFV7/AwacS0GdaI
X-Received: by 10.140.106.4 with SMTP id d4mr17272937qgf.39.1411357561296;
 Sun, 21 Sep 2014 20:46:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Sun, 21 Sep 2014 20:45:41 -0700 (PDT)
In-Reply-To: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 21 Sep 2014 20:45:41 -0700
Message-ID: <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
Subject: Re: BlockManager issues
To: Nishkam Ravi <nravi@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139519617b4e905039f4a6c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139519617b4e905039f4a6c
Content-Type: text/plain; charset=UTF-8

It seems like you just need to raise the ulimit?


On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com> wrote:

> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of the
> workloads. Tried tracing the problem through change set analysis. Looks
> like the offending commit is 4fde28c from Aug 4th for PR1707. Please see
> SPARK-3633 for more details.
>
> Thanks,
> Nishkam
>

--001a1139519617b4e905039f4a6c--

From dev-return-9523-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 05:09:36 2014
Return-Path: <dev-return-9523-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ECDDB11BD2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 05:09:36 +0000 (UTC)
Received: (qmail 14650 invoked by uid 500); 22 Sep 2014 05:09:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14578 invoked by uid 500); 22 Sep 2014 05:09:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14564 invoked by uid 99); 22 Sep 2014 05:09:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:09:34 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_MESSAGE,HTTP_ESCAPED_HOST,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [66.46.182.58] (HELO relay.ihostexchange.net) (66.46.182.58)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:09:29 +0000
Received: from [192.168.125.249] (125.17.228.30) by smtp.ihostexchange.net
 (66.46.182.50) with Microsoft SMTP Server (TLS) id 8.3.348.2; Mon, 22 Sep
 2014 01:09:05 -0400
Message-ID: <541FAEF1.8050505@flytxt.com>
Date: Mon, 22 Sep 2014 10:39:05 +0530
From: Meethu Mathew <meethu.mathew@flytxt.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.1.1
MIME-Version: 1.0
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: Gaussian Mixture Model clustering
References: <541BBE61.4080608@flytxt.com> <541BC144.9000401@flytxt.com> <CABjXkq5ywpAOfFkNMoJjDw7wwATkRjv8CPJb6JadwdELztTCpA@mail.gmail.com>
In-Reply-To: <CABjXkq5ywpAOfFkNMoJjDw7wwATkRjv8CPJb6JadwdELztTCpA@mail.gmail.com>
Content-Type: multipart/alternative;
	boundary="------------090105090507000509080905"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------090105090507000509080905
Content-Type: text/plain; charset="utf-8"; format=flowed
Content-Transfer-Encoding: 7bit

Hi Evan,
Sorry that I forgot to mention about it. I set the value of K as 10 for 
the benchmark study.

On Friday 19 September 2014 11:24 PM, Evan R. Sparks wrote:
> Hey Meethu - what are you setting "K" to in the benchmarks you show? 
> This can greatly affect the runtime.
>
> On Thu, Sep 18, 2014 at 10:38 PM, Meethu Mathew 
> <meethu.mathew@flytxt.com <mailto:meethu.mathew@flytxt.com>> wrote:
>
>     Hi all,
>     Please find attached the image of benchmark results. The table in
>     the previous mail got messed up. Thanks.
>
>
>
>     On Friday 19 September 2014 10:55 AM, Meethu Mathew wrote:
>>     Hi all,
>>
>>     We have come up with an initial distributed implementation of Gaussian
>>     Mixture Model in pyspark where the parameters are estimated using the
>>     Expectation-Maximization algorithm.Our current implementation considers
>>     diagonal covariance matrix for each component.
>>     We did an initial benchmark study on a 2 node Spark standalone cluster
>>     setup where each node config is 8 Cores,8 GB RAM, the spark version used
>>     is 1.0.0. We also evaluated python version of k-means available in spark
>>     on the same datasets.Below are the results from this benchmark study.
>>     The reported stats are average from 10 runs.Tests were done on multiple
>>     datasets with varying number of features and instances.
>>
>>
>>                Dataset 	      Gaussian mixture model
>>     	               Kmeans(Python)
>>
>>     Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
>>     	Avg time per iteration 	Time for 100 iterations
>>     0.7million 	13
>>     	7s
>>     	12min
>>     	  13s 	26min
>>     1.8million 	11
>>     	17s
>>     	 29min 	   33s
>>     	 53min
>>     10 million 	16
>>     	1.6min 	2.7hr
>>     	  1.2min 	2 hr
>>
>>
>>     We are interested in contributing this implementation as a patch to
>>     SPARK. Does MLLib accept python implementations? If not, can we
>>     contribute to the pyspark component
>>     I have created a JIRA for the same
>>     https://issues.apache.org/jira/browse/SPARK-3588  .How do I get the
>>     ticket assigned to myself?
>>
>>     Please review and suggest how to take this forward.
>>
>>
>>
>
>     ---------------------------------------------------------------------
>     To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>     <mailto:dev-unsubscribe@spark.apache.org>
>     For additional commands, e-mail: dev-help@spark.apache.org
>     <mailto:dev-help@spark.apache.org>
>
>

-- 

Regards,

*Meethu Mathew*

*Engineer*

*Flytxt*

www.flytxt.com | Visit our blog <http://blog.flytxt.com/> | Follow us 
<http://www.twitter.com/flytxt> | _Connect on Linkedin 
<http://www.linkedin.com/home?trk=hb_tab_home_top>_


--------------090105090507000509080905
Content-Type: multipart/related;
	boundary="------------010908040709010308010206"

--------------010908040709010308010206
Content-Type: text/html; charset="utf-8"
Content-Transfer-Encoding: 8bit

<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  </head>
  <body text="#000000" bgcolor="#FFFFFF">
    Hi Evan,<br>
    Sorry that I forgot to mention about it. I set the value of K as 10
    for the benchmark study.<br>
    <br>
    <div class="moz-cite-prefix">On Friday 19 September 2014 11:24 PM,
      Evan R. Sparks wrote:<br>
    </div>
    <blockquote
cite="mid:CABjXkq5ywpAOfFkNMoJjDw7wwATkRjv8CPJb6JadwdELztTCpA@mail.gmail.com"
      type="cite">
      <div dir="ltr">Hey Meethu - what are you setting "K" to in the
        benchmarks you show? This can greatly affect the runtime.</div>
      <div class="gmail_extra"><br>
        <div class="gmail_quote">On Thu, Sep 18, 2014 at 10:38 PM,
          Meethu Mathew <span dir="ltr">&lt;<a moz-do-not-send="true"
              href="mailto:meethu.mathew@flytxt.com" target="_blank">meethu.mathew@flytxt.com</a>&gt;</span>
          wrote:<br>
          <blockquote class="gmail_quote" style="margin:0 0 0
            .8ex;border-left:1px #ccc solid;padding-left:1ex">
            <div text="#000000" bgcolor="#FFFFFF"> Hi all,<br>
              Please find attached the image of benchmark results. The
              table in the previous mail got messed up. Thanks.<br>
              <br>
              <img alt="" src="cid:part2.01070607.07080701@flytxt.com"
                height="220" width="625">
              <div>
                <div class="h5"><br>
                  <br>
                  <div>On Friday 19 September 2014 10:55 AM, Meethu
                    Mathew wrote:<br>
                  </div>
                  <blockquote type="cite">
                    <pre>Hi all,

We have come up with an initial distributed implementation of Gaussian 
Mixture Model in pyspark where the parameters are estimated using the 
Expectation-Maximization algorithm.Our current implementation considers 
diagonal covariance matrix for each component.
We did an initial benchmark study on a 2 node Spark standalone cluster 
setup where each node config is 8 Cores,8 GB RAM, the spark version used 
is 1.0.0. We also evaluated python version of k-means available in spark 
on the same datasets.Below are the results from this benchmark study. 
The reported stats are average from 10 runs.Tests were done on multiple 
datasets with varying number of features and instances.


          Dataset 	      Gaussian mixture model
	               Kmeans(Python)

Instances 	Dimensions 	Avg time per iteration 	Time for 100 iterations
	Avg time per iteration 	Time for 100 iterations
0.7million 	13
	7s
	12min
	  13s 	26min
1.8million 	11
	17s
	 29min 	   33s
	 53min
10 million 	16
	1.6min 	2.7hr
	  1.2min 	2 hr


We are interested in contributing this implementation as a patch to 
SPARK. Does MLLib accept python implementations? If not, can we 
contribute to the pyspark component
I have created a JIRA for the same 
<a moz-do-not-send="true" href="https://issues.apache.org/jira/browse/SPARK-3588" target="_blank">https://issues.apache.org/jira/browse/SPARK-3588</a> .How do I get the 
ticket assigned to myself?

Please review and suggest how to take this forward.



</pre>
                  </blockquote>
                </div>
              </div>
            </div>
            <br>
---------------------------------------------------------------------<br>
            To unsubscribe, e-mail: <a moz-do-not-send="true"
              href="mailto:dev-unsubscribe@spark.apache.org">dev-unsubscribe@spark.apache.org</a><br>
            For additional commands, e-mail: <a moz-do-not-send="true"
              href="mailto:dev-help@spark.apache.org">dev-help@spark.apache.org</a><br>
          </blockquote>
        </div>
        <br>
      </div>
    </blockquote>
    <br>
    <div class="moz-signature">-- <br>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="ProgId" content="Word.Document">
      <meta name="Generator" content="Microsoft Word 14">
      <meta name="Originator" content="Microsoft Word 14">
      <link rel="File-List" href="Official%20New_files/filelist.xml">
      <!--[if gte mso 9]><xml>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->
      <link rel="themeData" href="Official%20New_files/themedata.thmx">
      <link rel="colorSchemeMapping"
        href="Official%20New_files/colorschememapping.xml">
      <!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:DoNotShadeFormData/>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]-->
      <style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073786111 1 0 415 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
a:link, span.MsoHyperlink
	{mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	color:blue;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:purple;
	mso-themecolor:followedhyperlink;
	text-decoration:underline;
	text-underline:single;}
p
	{mso-style-noshow:yes;
	mso-style-priority:99;
	mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";
	mso-fareast-font-family:"Times New Roman";}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:11.0pt;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;}
</style>
<![endif]-->
      <div class="WordSection1">
        <p class="MsoNormal"><span
            style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
Calibri;color:#000000;mso-themecolor:accent1;mso-themeshade:191;mso-bidi-font-weight:
            bold">Regards, <o:p></o:p>
          </span></p>
        <p class="MsoNormal"></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:black">Meethu Mathew<o:p></o:p></span></b></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:#4978BC">Engineer<o:p></o:p></span></b></p>
        <p class="MsoNormal"><b><span
              style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
              Calibri;color:#F78F28">Flytxt</span></b><span
            style="mso-ascii-font-family:
            Calibri;mso-hansi-font-family:Calibri;color:#F78F28"><o:p></o:p></span></p>
        <span style="mso-ascii-font-family:Calibri;
          mso-hansi-font-family:Calibri"><span style="color:#0D0D0D"><o:p></o:p></span></span>
        <p class="MsoNormal"><span
            style="mso-ascii-font-family:Calibri;mso-hansi-font-family:
            Calibri;color:#4978BC"><a href="www.flytxt.com"><span
                style="color:#4978BC">www.flytxt.com</span></a>
            | <a href="http://blog.flytxt.com/"><span
                style="color:#4978BC">Visit our blog </span></a>|
            <a href="http://www.twitter.com/flytxt"><span
                style="color:#4978BC">Follow us</span></a>|<u><a
                href="http://www.linkedin.com/home?trk=hb_tab_home_top"><span
                  style="color:
                  #4978BC">Connect on Linkedin</span></a></u></span> <o:p></o:p></p>
        <p class="MsoNormal"><o:p></o:p></p>
      </div>
    </div>
  </body>
</html>

--------------010908040709010308010206
Content-Type: image/png
Content-Transfer-Encoding: base64
Content-ID: <part2.01070607.07080701@flytxt.com>
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--------------010908040709010308010206--

--------------090105090507000509080905--

From dev-return-9524-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 05:30:06 2014
Return-Path: <dev-return-9524-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED72411C27
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 05:30:05 +0000 (UTC)
Received: (qmail 39104 invoked by uid 500); 22 Sep 2014 05:30:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39026 invoked by uid 500); 22 Sep 2014 05:30:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39014 invoked by uid 99); 22 Sep 2014 05:30:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:30:04 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:29:39 +0000
Received: by mail-oi0-f47.google.com with SMTP id e131so3084714oig.20
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 22:29:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=gJTp31pk+EJ1uT4U8yiP2M75rKXM6alwlz2Q2PWrksg=;
        b=CwEu8vDcyLYmaorbcr7XNGQaiCuElsGjSgXYlTcJsIid6lcdX6d/v5dV58qc4QAbnv
         NNqxt+s+IxOF/cyRKUhZgIu0yt1oitUpz7/6p2IHsFy6SsOkv4U93rqrMl0HHQSjEuPQ
         0blo4WQSAOEW8uzguNcohAnZxiJnm0nG4hRskwUcs4u95Hyag9LvFDToD3KWLw0btf52
         Wb2zyj7xGnJAs67k/1CfN5KKrdB8kiiKDTqjPWEnPDs0XIWhgULbwLyNs0SlGng7ACOL
         bwlfeBz1VqFZMLGwXBsI0/sZ1VJ6zkb+fRDNge6GTU8r60lfoac6gjR1+JPjmiKYnkdq
         IhVw==
MIME-Version: 1.0
X-Received: by 10.182.142.67 with SMTP id ru3mr25220160obb.15.1411363778485;
 Sun, 21 Sep 2014 22:29:38 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Sun, 21 Sep 2014 22:29:38 -0700 (PDT)
In-Reply-To: <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
	<CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
Date: Sun, 21 Sep 2014 22:29:38 -0700
Message-ID: <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
Subject: Re: BlockManager issues
From: Patrick Wendell <pwendell@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Nishkam Ravi <nravi@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey the numbers you mentioned don't quite line up - did you mean PR 2711?

On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com> wrote:
> It seems like you just need to raise the ulimit?
>
>
> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com> wrote:
>
>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of the
>> workloads. Tried tracing the problem through change set analysis. Looks
>> like the offending commit is 4fde28c from Aug 4th for PR1707. Please see
>> SPARK-3633 for more details.
>>
>> Thanks,
>> Nishkam
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9525-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 05:32:51 2014
Return-Path: <dev-return-9525-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 806DC11C33
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 05:32:51 +0000 (UTC)
Received: (qmail 43369 invoked by uid 500); 22 Sep 2014 05:32:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43288 invoked by uid 500); 22 Sep 2014 05:32:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43276 invoked by uid 99); 22 Sep 2014 05:32:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:32:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:32:46 +0000
Received: by mail-ob0-f177.google.com with SMTP id va2so1865256obc.8
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 22:32:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=bbjxTBoqFo71hqpV72Yk25nhEfVxy5nfwFERJ1doFhU=;
        b=ecGkSArJ85M9QCb7jXOtl1qvUi8wznLGokDKod/aup9FhNRM7ydxCn5NgsKRBN2BK9
         PTcA1WCxUbsRakxNg247LAyu5cuvCANKovRaE2rhUaiiWniSRc11ArGjXXOFzX5Zle/W
         tp98+HsOo33TWElk9uPaPq7nBy3qq5yfEhtM4kpAysRi1kk6bOCd5vlAFUMzu3oysDXM
         EtL8Pt2Kgn/Vyo5c+DUeLIfJg8Ynq6Ua5iv3iaAFY3XN4bfsyON7XOUJrEAJDvI2mLhG
         biv7l1ftEwKILY201w2YhfukNZ1Xk3buZJ97rHXd67F+e2z3mEiiZJSBtbwC2I/fGKTn
         EuMw==
MIME-Version: 1.0
X-Received: by 10.182.191.39 with SMTP id gv7mr24181815obc.14.1411363945730;
 Sun, 21 Sep 2014 22:32:25 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Sun, 21 Sep 2014 22:32:25 -0700 (PDT)
In-Reply-To: <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
	<CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
	<CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
Date: Sun, 21 Sep 2014 22:32:25 -0700
Message-ID: <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
Subject: Re: BlockManager issues
From: Patrick Wendell <pwendell@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Nishkam Ravi <nravi@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
that you are just having more spilling as a result of the patch and so
the filesystem is opening more files. I would try increasing the
ulimit.

How much memory do your executors have?

- Patrick

On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hey the numbers you mentioned don't quite line up - did you mean PR 2711?
>
> On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com> wrote:
>> It seems like you just need to raise the ulimit?
>>
>>
>> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com> wrote:
>>
>>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of the
>>> workloads. Tried tracing the problem through change set analysis. Looks
>>> like the offending commit is 4fde28c from Aug 4th for PR1707. Please see
>>> SPARK-3633 for more details.
>>>
>>> Thanks,
>>> Nishkam
>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9526-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 05:57:37 2014
Return-Path: <dev-return-9526-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C1D4311CD0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 05:57:37 +0000 (UTC)
Received: (qmail 82498 invoked by uid 500); 22 Sep 2014 05:57:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82426 invoked by uid 500); 22 Sep 2014 05:57:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82415 invoked by uid 99); 22 Sep 2014 05:57:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:57:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nravi@cloudera.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 05:57:09 +0000
Received: by mail-ie0-f178.google.com with SMTP id at20so6819821iec.37
        for <dev@spark.apache.org>; Sun, 21 Sep 2014 22:57:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=qn9dycU8tNsNsrQieJaPS7+VHSBcQIQC0HsgAyCtgsA=;
        b=Dw7h/6N4r0Krd219T+AcLKXZj+hz3GhfOrQorDG2o5CwsmeMV3Vg8vrM88rqMY9sLX
         B8nVRakioiA6LnO1ENo69QU4mZHNZY8iIyOVnk7YJz0tMcDt6YIarJPOQMrHSEyiu+Qm
         qlSTecMqfY4Sgazrj+SfAtUv0TEd0Vb0WqlKvMUrSDLVsnmpdoD4ZOfwcZWIJ5k0m2zR
         62waQGm/h8MLzfmtYkQB6ScOY+rbM1/xBZae8F7p4POstjoIaBnKe3TJZKbul99Wy9gx
         7kHVD40PGe4sGbmnBuScdgLDyHCXNDqpjBfkxyRYN2kh5vtt4CPY3z/FgtlHSoxhRHH0
         CxBw==
X-Gm-Message-State: ALoCoQmQMsn+09t8OIakcMjChshofv3yDbNPKWL/Fw2YvtiAQUj6mO92yK5NaCOMFhMq95WaKIGf
X-Received: by 10.50.33.100 with SMTP id q4mr12188722igi.8.1411365428030; Sun,
 21 Sep 2014 22:57:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.166.79 with HTTP; Sun, 21 Sep 2014 22:56:47 -0700 (PDT)
In-Reply-To: <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
 <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
 <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com> <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
From: Nishkam Ravi <nravi@cloudera.com>
Date: Sun, 21 Sep 2014 22:56:47 -0700
Message-ID: <CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
Subject: Re: BlockManager issues
To: Patrick Wendell <pwendell@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b034fc86070503a11e4f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b034fc86070503a11e4f
Content-Type: text/plain; charset=UTF-8

Thanks for the quick follow up Reynold and Patrick. Tried a run with
significantly higher ulimit, doesn't seem to help. The executors have 35GB
each. Btw, with a recent version of the branch, the error message is "fetch
failures" as opposed to "too many open files". Not sure if they are
related.  Please note that the workload runs fine with head set to 066765d.
In case you want to reproduce the problem: I'm running slightly modified
ScalaPageRank (with KryoSerializer and persistence level
memory_and_disk_ser) on a 30GB input dataset and a 6-node cluster.

Thanks,
Nishkam

On Sun, Sep 21, 2014 at 10:32 PM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
> that you are just having more spilling as a result of the patch and so
> the filesystem is opening more files. I would try increasing the
> ulimit.
>
> How much memory do your executors have?
>
> - Patrick
>
> On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hey the numbers you mentioned don't quite line up - did you mean PR 2711?
> >
> > On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >> It seems like you just need to raise the ulimit?
> >>
> >>
> >> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com>
> wrote:
> >>
> >>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of
> the
> >>> workloads. Tried tracing the problem through change set analysis. Looks
> >>> like the offending commit is 4fde28c from Aug 4th for PR1707. Please
> see
> >>> SPARK-3633 for more details.
> >>>
> >>> Thanks,
> >>> Nishkam
> >>>
>

--089e0158b034fc86070503a11e4f--

From dev-return-9527-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 07:24:50 2014
Return-Path: <dev-return-9527-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F06D411EC6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 07:24:50 +0000 (UTC)
Received: (qmail 9250 invoked by uid 500); 22 Sep 2014 07:24:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9172 invoked by uid 500); 22 Sep 2014 07:24:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9161 invoked by uid 99); 22 Sep 2014 07:24:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 07:24:49 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zzhang@hortonworks.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 07:24:45 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so4466067pad.35
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 00:24:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to:content-type;
        bh=KHiTmxjIR10m56nbQPKsKDuVU6gPl0gF3KVmSvk3tDk=;
        b=gAlsjE6xLyBGuqdiWwem4LZoPynV9PmPUG6X8/F9hX9xVDWP2ZCdJkIMXy0ALv8tNk
         USYw0OF8FT8VGEFWLg/SE6pMS0Cz/auRilReLCALRxXek7aeimQYWTzzX13BwJMW0w7K
         FWuK0DU79CU+uKDiDzVazCbEuT2hL677756YQ7xF08AKxwalbJkly2tQWA87keor0T5Q
         XwXuLl99Mvkn1mpT1BG72vJWIWmMBvJ9RVxyliVi8bIamSNpd+AqsnWBtEW3Ujavswb1
         KnjrMgcgkL5LbQJHZjWz64j2zRsVGC//P7JVRdM76X2zFZqrKHS7MKoeGOJYcEnN/z3f
         YLTQ==
X-Gm-Message-State: ALoCoQmin14MGe2N+6nKJzNOzt++t660iwV+Ae+ZDP5ocY16cmhJt1OJ4ZV9BlgeAznBtKbeQFbDQmG42iWGOyCqGykKFthTtfgDBp9ra/coqEIWalmPciA=
X-Received: by 10.68.134.130 with SMTP id pk2mr2361755pbb.133.1411370664811;
        Mon, 22 Sep 2014 00:24:24 -0700 (PDT)
Received: from [192.168.0.22] (c-24-6-100-89.hsd1.ca.comcast.net. [24.6.100.89])
        by mx.google.com with ESMTPSA id pk1sm1437265pbc.0.2014.09.22.00.24.23
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 22 Sep 2014 00:24:23 -0700 (PDT)
Mime-Version: 1.0 (1.0)
Subject: Re: BlockManager issues
From: Hortonworks <zzhang@hortonworks.com>
X-Mailer: iPhone Mail (12A365)
In-Reply-To: <CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
Date: Mon, 22 Sep 2014 00:24:19 -0700
Cc: Patrick Wendell <pwendell@gmail.com>,
 Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Message-Id: <829BEA51-5B46-4E85-A7C8-8948F77D2DBB@hortonworks.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com> <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com> <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com> <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com> <CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
To: Nishkam Ravi <nravi@cloudera.com>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Actually I met similar issue when doing groupByKey and then count if the shuffle size is big e.g. 1tb.

Thanks.

Zhan Zhang

Sent from my iPhone

> On Sep 21, 2014, at 10:56 PM, Nishkam Ravi <nravi@cloudera.com> wrote:
> 
> Thanks for the quick follow up Reynold and Patrick. Tried a run with
> significantly higher ulimit, doesn't seem to help. The executors have 35GB
> each. Btw, with a recent version of the branch, the error message is "fetch
> failures" as opposed to "too many open files". Not sure if they are
> related.  Please note that the workload runs fine with head set to 066765d.
> In case you want to reproduce the problem: I'm running slightly modified
> ScalaPageRank (with KryoSerializer and persistence level
> memory_and_disk_ser) on a 30GB input dataset and a 6-node cluster.
> 
> Thanks,
> Nishkam
> 
> On Sun, Sep 21, 2014 at 10:32 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> 
>> Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
>> that you are just having more spilling as a result of the patch and so
>> the filesystem is opening more files. I would try increasing the
>> ulimit.
>> 
>> How much memory do your executors have?
>> 
>> - Patrick
>> 
>> On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>> Hey the numbers you mentioned don't quite line up - did you mean PR 2711?
>>> 
>>> On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com>
>> wrote:
>>>> It seems like you just need to raise the ulimit?
>>>> 
>>>> 
>>>> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com>
>> wrote:
>>>> 
>>>>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of
>> the
>>>>> workloads. Tried tracing the problem through change set analysis. Looks
>>>>> like the offending commit is 4fde28c from Aug 4th for PR1707. Please
>> see
>>>>> SPARK-3633 for more details.
>>>>> 
>>>>> Thanks,
>>>>> Nishkam
>> 

-- 
CONFIDENTIALITY NOTICE
NOTICE: This message is intended for the use of the individual or entity to 
which it is addressed and may contain information that is confidential, 
privileged and exempt from disclosure under applicable law. If the reader 
of this message is not the intended recipient, you are hereby notified that 
any printing, copying, dissemination, distribution, disclosure or 
forwarding of this communication is strictly prohibited. If you have 
received this communication in error, please contact the sender immediately 
and delete it from your system. Thank You.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9528-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 09:30:57 2014
Return-Path: <dev-return-9528-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A66D111FE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 09:30:57 +0000 (UTC)
Received: (qmail 22927 invoked by uid 500); 22 Sep 2014 09:30:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22856 invoked by uid 500); 22 Sep 2014 09:30:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22840 invoked by uid 99); 22 Sep 2014 09:30:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 09:30:55 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gofiri@gmail.com designates 209.85.219.49 as permitted sender)
Received: from [209.85.219.49] (HELO mail-oa0-f49.google.com) (209.85.219.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 09:30:29 +0000
Received: by mail-oa0-f49.google.com with SMTP id jd19so3655375oac.22
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 02:30:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=3aacgB7s1qukjW9lM6+13+c6zzJcG9ZRKPmu3Ch6rLE=;
        b=g0eKyu32XYAyhlXCcRf1fM8Po/EqddwIgKibTxDObYZfK6/x0ZvQh6THB2h0OJs5/2
         GySJdllCM4GHX5nqmh+g3JKzPpe6TlnxUUD87uKn1LvzWl993URRSeyXxD0n1VbKbDEH
         Dmh3Iaqomupz/b55cvK8384qJt6OZnJbjspUAB9MycTX3r++sGfON0aUbXcxmg32CMRl
         4nhcEqK5BerbwVH2x/R79EPr2SlIzgs4bltQ0B5PcKPU9Nnx/wHj8EisXe+9T2vsf3+1
         R4dJ1hcr6aTYjG1GHlWLTEbLv6oCOGe9fyIzCvmbfNaG8YcXIfdBCm8n3WsyF0p7ZCJU
         hSlw==
MIME-Version: 1.0
X-Received: by 10.60.47.13 with SMTP id z13mr1554365oem.71.1411378228116; Mon,
 22 Sep 2014 02:30:28 -0700 (PDT)
Received: by 10.76.88.41 with HTTP; Mon, 22 Sep 2014 02:30:28 -0700 (PDT)
In-Reply-To: <CAJOb8bv8HqtdhEuHMvQ4CiRMU4neg7w2OGoMY1t364E6m2YyKw@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
	<CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
	<CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
	<CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
	<CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
	<CALte62yLoTaw4u2M7=G=zLXkaXAMNEs8zOJB9ogs6+1hyRQZtQ@mail.gmail.com>
	<CAJOb8bv8HqtdhEuHMvQ4CiRMU4neg7w2OGoMY1t364E6m2YyKw@mail.gmail.com>
Date: Mon, 22 Sep 2014 18:30:28 +0900
Message-ID: <CA+45J9P+OF-enYPU_Re259tyEWFHX4H=EfFROEGu7NtJ89eE1A@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
From: =?UTF-8?B?7J207J246recKGluUSk=?= <gofiri@gmail.com>
To: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Cc: Ted Yu <yuzhihong@gmail.com>, Tathagata Das <tathagata.das1565@gmail.com>, 
	Koert Kuipers <koert@tresata.com>, Felix Garcia Borrego <fborrego@gilt.com>, Sean Owen <sowen@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c20a9eee43a90503a4190d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c20a9eee43a90503a4190d
Content-Type: text/plain; charset=UTF-8

Hello,

In my case, I manually deleted org/apache/http directory in the
spark-assembly jar file..
I think if we use the latest version of httpclient (httpcore) library, we
can resolve the problem.
How about upgrading httpclient? (or jets3t?)

2014-09-11 19:09 GMT+09:00 Aniket Bhatnagar <aniket.bhatnagar@gmail.com>:

> Thanks everyone for weighing in on this.
>
> I had backported kinesis module from master to spark 1.0.2 so just to
> confirm if I am not missing anything, I did a dependency graph compare of
> my spark build with spark-master
> and org.apache.httpcomponents:httpclient:jar does seem to resolve to 4.1.2
> dependency.
>
> I need Hive so, I can't really do a build without it. Even if I
> exclude httpclient
> dependency from my project's build, it will not solve the problem because
> AWS SDK has been compiled with a greater version of http client. My spark
> stream project does not uses http client directly. AWS SDK will look for
>  class org.apache.http.impl.conn.DefaultClientConnectionOperator and it
> will be loaded from spark-assembly jar regardless of how I package my
> project (unless I am missing something?). I enabled verbosed classloading
> to confirm that the class is indeed loading from spark-assembly jar.
>
> spark.files.userClassPathFirst option doesn't seem to be working on my
> spark 1.0.2 build (not sure why).
>
> I was only left custom building spark and forcingly introduce latest
> httpclient's latest version as dependency.
>
> Finally, I tested this on 1.1.0-RC4 today and it has the same issue. Has
> anyone ever been able to get the Kinesis example work with spark-hadoop2.4
> (with hive and yarn) build? I feel like this is a bug that exists even in
> 1.1.0.
>
> I still believe we need a better solution to address the dependency hell
> problem. If OSGi is deemed too over the top, what are the solutions being
> investigated?
>
> On 6 September 2014 04:44, Ted Yu <yuzhihong@gmail.com> wrote:
>
> > From output of dependency:tree:
> >
> > [INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @
> > spark-streaming_2.10 ---
> > [INFO] org.apache.spark:spark-streaming_2.10:jar:1.1.0-SNAPSHOT
> > INFO] +- org.apache.spark:spark-core_2.10:jar:1.1.0-SNAPSHOT:compile
> > [INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.4.0:compile
> > ...
> > [INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile
> > [INFO] |  |  +- commons-codec:commons-codec:jar:1.5:compile
> > [INFO] |  |  +- org.apache.httpcomponents:httpclient:jar:4.1.2:compile
> > [INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.1.2:compile
> >
> > bq. excluding httpclient from spark-streaming dependency in your
> > sbt/maven project
> >
> > This should work.
> >
> >
> > On Fri, Sep 5, 2014 at 3:14 PM, Tathagata Das <
> tathagata.das1565@gmail.com
> > > wrote:
> >
> >> If httpClient dependency is coming from Hive, you could build Spark
> >> without
> >> Hive. Alternatively, have you tried excluding httpclient from
> >> spark-streaming dependency in your sbt/maven project?
> >>
> >> TD
> >>
> >>
> >>
> >> On Thu, Sep 4, 2014 at 6:42 AM, Koert Kuipers <koert@tresata.com>
> wrote:
> >>
> >> > custom spark builds should not be the answer. at least not if spark
> ever
> >> > wants to have a vibrant community for spark apps.
> >> >
> >> > spark does support a user-classpath-first option, which would deal
> with
> >> > some of these issues, but I don't think it works.
> >> > On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com>
> >> wrote:
> >> >
> >> > > Hi,
> >> > > I run into the same issue and apart from the ideas Aniket said, I
> only
> >> > > could find a nasty workaround. Add my custom
> >> > PoolingClientConnectionManager
> >> > > to my classpath.
> >> > >
> >> > >
> >> > >
> >> >
> >>
> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-running-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
> >> > >
> >> > >
> >> > >
> >> > > On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com>
> >> wrote:
> >> > >
> >> > > > Dumb question -- are you using a Spark build that includes the
> >> Kinesis
> >> > > > dependency? that build would have resolved conflicts like this for
> >> > > > you. Your app would need to use the same version of the Kinesis
> >> client
> >> > > > SDK, ideally.
> >> > > >
> >> > > > All of these ideas are well-known, yes. In cases of super-common
> >> > > > dependencies like Guava, they are already shaded. This is a
> >> > > > less-common source of conflicts so I don't think http-client is
> >> > > > shaded, especially since it is not used directly by Spark. I think
> >> > > > this is a case of your app conflicting with a third-party
> >> dependency?
> >> > > >
> >> > > > I think OSGi is deemed too over the top for things like this.
> >> > > >
> >> > > > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
> >> > > > <aniket.bhatnagar@gmail.com> wrote:
> >> > > > > I am trying to use Kinesis as source to Spark Streaming and have
> >> run
> >> > > > into a
> >> > > > > dependency issue that can't be resolved without making my own
> >> custom
> >> > > > Spark
> >> > > > > build. The issue is that Spark is transitively dependent
> >> > > > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think
> >> because of
> >> > > > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is
> >> > dependent
> >> > > > > on org.apache.httpcomponents:httpclient:jar:4.2. When I package
> >> and
> >> > run
> >> > > > > Spark Streaming application, I get the following:
> >> > > > >
> >> > > > > Caused by: java.lang.NoSuchMethodError:
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/apache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectionOperator(PoolingClientConnectionManager.java:140)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:114)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingClientConnectionManager.java:99)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManager(ConnectionManagerFactory.java:29)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.java:97)
> >> > > > >         at
> >> > > > >
> >> com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:119)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:103)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:136)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisClient.java:117)
> >> > > > >         at
> >> > > > >
> >> > > >
> >> > >
> >> >
> >>
> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKinesisAsyncClient.java:132)
> >> > > > >
> >> > > > > I can create a custom Spark build with
> >> > > > > org.apache.httpcomponents:httpclient:jar:4.2 included in the
> >> assembly
> >> > > > but I
> >> > > > > was wondering if this is something Spark devs have noticed and
> are
> >> > > > looking
> >> > > > > to resolve in near releases. Here are my thoughts on this issue:
> >> > > > >
> >> > > > > Containers that allow running custom user code have to often
> >> resolve
> >> > > > > dependency issues in case of conflicts between framework's and
> >> user
> >> > > > code's
> >> > > > > dependency. Here is how I have seen some frameworks resolve the
> >> > issue:
> >> > > > > 1. Provide a child-first class loader: Some JEE containers
> >> provided a
> >> > > > > child-first class loader that allowed for loading classes from
> >> user
> >> > > code
> >> > > > > first. I don't think this approach completely solves the problem
> >> as
> >> > the
> >> > > > > framework is then susceptible to class mismatch errors.
> >> > > > > 2. Fold in all dependencies in a sub-package: This approach
> >> involves
> >> > > > > folding all dependencies in a project specific sub-package (like
> >> > > > > spark.dependencies). This approach is tedious because it
> involves
> >> > > > building
> >> > > > > custom version of all dependencies (and their transitive
> >> > dependencies)
> >> > > > > 3. Use something like OSGi: Some frameworks has successfully
> used
> >> > OSGi
> >> > > to
> >> > > > > manage dependencies between the modules. The challenge in this
> >> > approach
> >> > > > is
> >> > > > > to OSGify the framework and hide OSGi complexities from end
> user.
> >> > > > >
> >> > > > > My personal preference is OSGi (or atleast some support for
> OSGi)
> >> > but I
> >> > > > > would love to hear what Spark devs are thinking in terms of
> >> resolving
> >> > > the
> >> > > > > problem.
> >> > > > >
> >> > > > > Thanks,
> >> > > > > Aniket
> >> > > >
> >> > > >
> >> ---------------------------------------------------------------------
> >> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> > > > For additional commands, e-mail: dev-help@spark.apache.org
> >> > > >
> >> > > >
> >> > >
> >> >
> >>
> >
> >
>

--001a11c20a9eee43a90503a4190d--

From dev-return-9529-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 10:03:02 2014
Return-Path: <dev-return-9529-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A8BF5112CF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 10:03:02 +0000 (UTC)
Received: (qmail 82611 invoked by uid 500); 22 Sep 2014 10:02:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82539 invoked by uid 500); 22 Sep 2014 10:02:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82525 invoked by uid 99); 22 Sep 2014 10:02:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:02:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of christoph.sawade@googlemail.com designates 209.85.217.182 as permitted sender)
Received: from [209.85.217.182] (HELO mail-lb0-f182.google.com) (209.85.217.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:02:52 +0000
Received: by mail-lb0-f182.google.com with SMTP id u10so6245603lbd.41
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 03:02:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=googlemail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Cjt6NKUqLsjn+eg8QjFOroAw+0t4FN28xXmKQlJ3Nmw=;
        b=1A+KktAi8rDIuo/N0t5euDjBiwTAtwqoxXLJFd3YlEnjwfZ/MsyizSKfwDQU3BcFi6
         3eLr+Pr80D6A8Niw+fvJcT06b0vgVmZFm8g1WyX3wU2DkPwRWgrrBQMaOmsr+Dd0DbLP
         XaoayXqwch5z8mhgM8WHFQI36G0lkKJ/NGFm3HLLwsbACLVi16Lp2yGyTA4s/1NNS+kQ
         VnkTjkaZG/Mv0+HcKDdqpSzhdFlxUKVWH8uvP2j3f8OCfzteONefDuNVFnwciJEojOAa
         ibf5PoPjnTPI6EHU3ZHF+q+aoppD03F4zATo/A9tvucm+CAj1TJRr8ceuWobF7Tq7dk1
         Brcg==
MIME-Version: 1.0
X-Received: by 10.152.43.50 with SMTP id t18mr24730300lal.25.1411380151291;
 Mon, 22 Sep 2014 03:02:31 -0700 (PDT)
Received: by 10.114.229.3 with HTTP; Mon, 22 Sep 2014 03:02:31 -0700 (PDT)
In-Reply-To: <829BEA51-5B46-4E85-A7C8-8948F77D2DBB@hortonworks.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
	<CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
	<CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
	<CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
	<CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
	<829BEA51-5B46-4E85-A7C8-8948F77D2DBB@hortonworks.com>
Date: Mon, 22 Sep 2014 12:02:31 +0200
Message-ID: <CAKxiPZPYLzcCLsV1J5JyGfjpQgdoOOWtqQadiu3=MDP7QheUsA@mail.gmail.com>
Subject: Re: BlockManager issues
From: Christoph Sawade <christoph.sawade@googlemail.com>
To: Hortonworks <zzhang@hortonworks.com>
Cc: Nishkam Ravi <nravi@cloudera.com>, Patrick Wendell <pwendell@gmail.com>, 
	Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c239d08f92300503a48ce9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c239d08f92300503a48ce9
Content-Type: text/plain; charset=UTF-8

Hey all. We had also the same problem described by Nishkam almost in the
same big data setting. We fixed the fetch failure by increasing the timeout
for acks in the driver:

set("spark.core.connection.ack.wait.timeout", "600") // 10 minutes timeout
for acks between nodes

Cheers, Christoph

2014-09-22 9:24 GMT+02:00 Hortonworks <zzhang@hortonworks.com>:

> Actually I met similar issue when doing groupByKey and then count if the
> shuffle size is big e.g. 1tb.
>
> Thanks.
>
> Zhan Zhang
>
> Sent from my iPhone
>
> > On Sep 21, 2014, at 10:56 PM, Nishkam Ravi <nravi@cloudera.com> wrote:
> >
> > Thanks for the quick follow up Reynold and Patrick. Tried a run with
> > significantly higher ulimit, doesn't seem to help. The executors have
> 35GB
> > each. Btw, with a recent version of the branch, the error message is
> "fetch
> > failures" as opposed to "too many open files". Not sure if they are
> > related.  Please note that the workload runs fine with head set to
> 066765d.
> > In case you want to reproduce the problem: I'm running slightly modified
> > ScalaPageRank (with KryoSerializer and persistence level
> > memory_and_disk_ser) on a 30GB input dataset and a 6-node cluster.
> >
> > Thanks,
> > Nishkam
> >
> > On Sun, Sep 21, 2014 at 10:32 PM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> >
> >> Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
> >> that you are just having more spilling as a result of the patch and so
> >> the filesystem is opening more files. I would try increasing the
> >> ulimit.
> >>
> >> How much memory do your executors have?
> >>
> >> - Patrick
> >>
> >> On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >>> Hey the numbers you mentioned don't quite line up - did you mean PR
> 2711?
> >>>
> >>> On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com>
> >> wrote:
> >>>> It seems like you just need to raise the ulimit?
> >>>>
> >>>>
> >>>> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com>
> >> wrote:
> >>>>
> >>>>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one of
> >> the
> >>>>> workloads. Tried tracing the problem through change set analysis.
> Looks
> >>>>> like the offending commit is 4fde28c from Aug 4th for PR1707. Please
> >> see
> >>>>> SPARK-3633 for more details.
> >>>>>
> >>>>> Thanks,
> >>>>> Nishkam
> >>
>
> --
> CONFIDENTIALITY NOTICE
> NOTICE: This message is intended for the use of the individual or entity to
> which it is addressed and may contain information that is confidential,
> privileged and exempt from disclosure under applicable law. If the reader
> of this message is not the intended recipient, you are hereby notified that
> any printing, copying, dissemination, distribution, disclosure or
> forwarding of this communication is strictly prohibited. If you have
> received this communication in error, please contact the sender immediately
> and delete it from your system. Thank You.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c239d08f92300503a48ce9--

From dev-return-9530-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 10:37:19 2014
Return-Path: <dev-return-9530-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6845F114B3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 10:37:19 +0000 (UTC)
Received: (qmail 32104 invoked by uid 500); 22 Sep 2014 10:37:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32031 invoked by uid 500); 22 Sep 2014 10:37:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32019 invoked by uid 99); 22 Sep 2014 10:37:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:37:18 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of davidrowe@gmail.com designates 209.85.192.52 as permitted sender)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:36:52 +0000
Received: by mail-qg0-f52.google.com with SMTP id j5so1714390qga.39
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 03:36:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=j7Jqvrey7i/E8esYLuRAr7dKI0SjLVMJ8gM0p34sPNw=;
        b=xsbgNpfSKIQESk0yeSUhw0aqNay0o+sfnJe4fTnro+8SyDiCVA6DdRvdNrFcXVQ9v/
         8Q6OGsdDP0Kj+FHq4QkUKerd7oAEKTdv/1xxAuNjMEERYzWVQOS5CHdfX5M3cJ3iP/av
         4E65J5SSo7gICveBRzV1NOQWuzyGDpK8rB8GpUG1Xs/z9LexWbKkexr4bDFIeHz7gn2S
         lUbx6DpPfTev3I+EsxksgPXHYjyRYRxLkqhZfN8YxmCQLcaYK3ncUj2rANdhD8bfc8ei
         J6kylpoqrVg25//DUm22MC9VLWCH53gC/az0EjkW5L3E+nNVqVLkpEcPtKWu2pwVjNGo
         Aqjw==
X-Received: by 10.224.99.7 with SMTP id s7mr20264175qan.73.1411382211578; Mon,
 22 Sep 2014 03:36:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.93.85 with HTTP; Mon, 22 Sep 2014 03:36:31 -0700 (PDT)
In-Reply-To: <CAKxiPZPYLzcCLsV1J5JyGfjpQgdoOOWtqQadiu3=MDP7QheUsA@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
 <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
 <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
 <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
 <CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
 <829BEA51-5B46-4E85-A7C8-8948F77D2DBB@hortonworks.com> <CAKxiPZPYLzcCLsV1J5JyGfjpQgdoOOWtqQadiu3=MDP7QheUsA@mail.gmail.com>
From: David Rowe <davidrowe@gmail.com>
Date: Mon, 22 Sep 2014 20:36:31 +1000
Message-ID: <CAAdRV=PwZvwtfHvORkpJHaxoAFaUrccpum3-G6CRP7kYFQkTUA@mail.gmail.com>
Subject: Re: BlockManager issues
To: Christoph Sawade <christoph.sawade@googlemail.com>
Cc: Hortonworks <zzhang@hortonworks.com>, Nishkam Ravi <nravi@cloudera.com>, 
	Patrick Wendell <pwendell@gmail.com>, Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c239485d14f80503a50752
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c239485d14f80503a50752
Content-Type: text/plain; charset=UTF-8

I've run into this with large shuffles - I assumed that there was
contention between the shuffle output files and the JVM for memory.
Whenever we start getting these fetch failures, it corresponds with high
load on the machines the blocks are being fetched from, and in some cases
complete unresponsiveness (no ssh etc). Setting the timeout higher, or the
JVM heap lower (as a percentage of total machine memory) seemed to help..



On Mon, Sep 22, 2014 at 8:02 PM, Christoph Sawade <
christoph.sawade@googlemail.com> wrote:

> Hey all. We had also the same problem described by Nishkam almost in the
> same big data setting. We fixed the fetch failure by increasing the timeout
> for acks in the driver:
>
> set("spark.core.connection.ack.wait.timeout", "600") // 10 minutes timeout
> for acks between nodes
>
> Cheers, Christoph
>
> 2014-09-22 9:24 GMT+02:00 Hortonworks <zzhang@hortonworks.com>:
>
> > Actually I met similar issue when doing groupByKey and then count if the
> > shuffle size is big e.g. 1tb.
> >
> > Thanks.
> >
> > Zhan Zhang
> >
> > Sent from my iPhone
> >
> > > On Sep 21, 2014, at 10:56 PM, Nishkam Ravi <nravi@cloudera.com> wrote:
> > >
> > > Thanks for the quick follow up Reynold and Patrick. Tried a run with
> > > significantly higher ulimit, doesn't seem to help. The executors have
> > 35GB
> > > each. Btw, with a recent version of the branch, the error message is
> > "fetch
> > > failures" as opposed to "too many open files". Not sure if they are
> > > related.  Please note that the workload runs fine with head set to
> > 066765d.
> > > In case you want to reproduce the problem: I'm running slightly
> modified
> > > ScalaPageRank (with KryoSerializer and persistence level
> > > memory_and_disk_ser) on a 30GB input dataset and a 6-node cluster.
> > >
> > > Thanks,
> > > Nishkam
> > >
> > > On Sun, Sep 21, 2014 at 10:32 PM, Patrick Wendell <pwendell@gmail.com>
> > > wrote:
> > >
> > >> Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
> > >> that you are just having more spilling as a result of the patch and so
> > >> the filesystem is opening more files. I would try increasing the
> > >> ulimit.
> > >>
> > >> How much memory do your executors have?
> > >>
> > >> - Patrick
> > >>
> > >> On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <pwendell@gmail.com
> >
> > >> wrote:
> > >>> Hey the numbers you mentioned don't quite line up - did you mean PR
> > 2711?
> > >>>
> > >>> On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com>
> > >> wrote:
> > >>>> It seems like you just need to raise the ulimit?
> > >>>>
> > >>>>
> > >>>> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com>
> > >> wrote:
> > >>>>
> > >>>>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one
> of
> > >> the
> > >>>>> workloads. Tried tracing the problem through change set analysis.
> > Looks
> > >>>>> like the offending commit is 4fde28c from Aug 4th for PR1707.
> Please
> > >> see
> > >>>>> SPARK-3633 for more details.
> > >>>>>
> > >>>>> Thanks,
> > >>>>> Nishkam
> > >>
> >
> > --
> > CONFIDENTIALITY NOTICE
> > NOTICE: This message is intended for the use of the individual or entity
> to
> > which it is addressed and may contain information that is confidential,
> > privileged and exempt from disclosure under applicable law. If the reader
> > of this message is not the intended recipient, you are hereby notified
> that
> > any printing, copying, dissemination, distribution, disclosure or
> > forwarding of this communication is strictly prohibited. If you have
> > received this communication in error, please contact the sender
> immediately
> > and delete it from your system. Thank You.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a11c239485d14f80503a50752--

From dev-return-9531-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 10:41:02 2014
Return-Path: <dev-return-9531-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C3AAA114C7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 10:41:02 +0000 (UTC)
Received: (qmail 37205 invoked by uid 500); 22 Sep 2014 10:41:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37135 invoked by uid 500); 22 Sep 2014 10:41:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37124 invoked by uid 99); 22 Sep 2014 10:41:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:41:01 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 10:40:33 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CFD652.0A8585BE"
Subject: FW: Spark SQL 1.1.0: NPE when join two cached table
Date: Mon, 22 Sep 2014 18:40:29 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F13AADC@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Spark SQL 1.1.0: NPE when join two cached table
Thread-Index: Ac/WQBKICgSscsrASDGfH52mQlH4mwAEYd7Q
From: "Haopu Wang" <HWang@qilinsoft.com>
To: <dev@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CFD652.0A8585BE
Content-Type: text/plain;
	charset="GB2312"
Content-Transfer-Encoding: quoted-printable

FWD to dev mail list for helps

=20

________________________________

From: Haopu Wang=20
Sent: 2014=C4=EA9=D4=C222=C8=D5 16:35
To: user@spark.apache.org
Subject: Spark SQL 1.1.0: NPE when join two cached table

=20

I have two data sets and want to join them on each first field. Sample =
data are below:

=20

data set 1:

  id2,name1,2,300.0

=20

data set 2:

  id1,aaaaaaaaaaaa

=20

The code is something like below:

=20

    val sparkConf =3D new SparkConf().setAppName("JoinInScala")

    val sc =3D new SparkContext(sparkConf)

    val sqlContext =3D new SQLContext(sc)

    sqlContext.setConf("spark.sql.inMemoryColumnarStorage.compressed", =
"true")

    import org.apache.spark.sql._  =20

   =20

    val testdata =3D sc.textFile(args(0) + "data.txt").map(_.split(","))

      .map(p =3D> Row(p(0), p(1).trim, p(2).trim.toLong, =
p(3).trim.toDouble))

     =20

    val fields =3D new Array[StructField](4)

    fields(0) =3D StructField("id", StringType, false);

    fields(1) =3D StructField("name", StringType, false);

    fields(2) =3D StructField("agg1", LongType, false);

    fields(3) =3D StructField("agg2", DoubleType, false);   =20

    val schema =3D StructType(fields);

=20

    val data =3D sqlContext.applySchema(testdata, schema)

   =20

    data.registerTempTable("datatable")

    sqlContext.cacheTable("datatable")

=20

    val refdata =3D sc.textFile(args(0) + "ref.txt").map(_.split(","))

      .map(p =3D> Row(p(0), p(1).trim))

     =20

    val reffields =3D new Array[StructField](2)

    reffields(0) =3D StructField("id", StringType, false);

    reffields(1) =3D StructField("data", StringType, true);

    val refschema =3D StructType(reffields);

=20

    val refschemardd =3D sqlContext.applySchema(refdata, refschema)

    refschemardd.registerTempTable("ref")

    sqlContext.cacheTable("ref")

   =20

   val results =3D sqlContext.sql("SELECT =
d.id,d.name,d.agg1,d.agg2,ref.data FROM datatable as d join ref on =
d.id=3Dref.id")

    results.foreach(T =3D> Unit);

=20

But I got below NullPointerException. If I comment out the two =
"cacheTable()" calls, the program run well. Please shed some lights, =
thank you!

=20

Exception in thread "main" java.lang.NullPointerException

        at =
org.apache.spark.sql.columnar.InMemoryRelation.statistics$lzycompute(InMe=
moryColumnarTableScan.scala:43)

        at =
org.apache.spark.sql.columnar.InMemoryRelation.statistics(InMemoryColumna=
rTableScan.scala:42)

        at =
org.apache.spark.sql.execution.SparkStrategies$HashJoin$.apply(SparkStrat=
egies.scala:83)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(Quer=
yPlanner.scala:58)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(Quer=
yPlanner.scala:58)

        at =
scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.sc=
ala:59)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanne=
r.scala:54)

        at =
org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(Spar=
kStrategies.scala:268)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(Quer=
yPlanner.scala:58)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(Quer=
yPlanner.scala:58)

        at =
scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)

        at =
org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.sc=
ala:59)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLCo=
ntext.scala:402)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala=
:400)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQ=
LContext.scala:406)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.sc=
ala:406)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContex=
t.scala:409)

        at =
org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:409=
)

        at =
org.apache.spark.sql.SchemaRDD.getDependencies(SchemaRDD.scala:120)

        at =
org.apache.spark.rdd.RDD$$anonfun$dependencies$2.apply(RDD.scala:191)

        at =
org.apache.spark.rdd.RDD$$anonfun$dependencies$2.apply(RDD.scala:189)

        at scala.Option.getOrElse(Option.scala:120)

        at org.apache.spark.rdd.RDD.dependencies(RDD.scala:189)

        at org.apache.spark.rdd.RDD.firstParent(RDD.scala:1233)

        at =
org.apache.spark.sql.SchemaRDD.getPartitions(SchemaRDD.scala:117)

        at =
org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:204)

        at =
org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:202)

        at scala.Option.getOrElse(Option.scala:120)

        at org.apache.spark.rdd.RDD.partitions(RDD.scala:202)

        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1135)

        at org.apache.spark.rdd.RDD.foreach(RDD.scala:759)

        at Join$$anonfun$main$1.apply$mcVI$sp(Join.scala:44)

        at =
scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)

        at Join$.main(Join.scala:42)

        at Join.main(Join.scala)

        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

        at =
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java=
:57)

        at =
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI=
mpl.java:43)

        at java.lang.reflect.Method.invoke(Method.java:606)

        at =
org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:328)

        at =
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)

        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

=20

=20

=20

=20

=20


------_=_NextPart_001_01CFD652.0A8585BE--

From dev-return-9532-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 11:08:36 2014
Return-Path: <dev-return-9532-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CFA78115F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 11:08:36 +0000 (UTC)
Received: (qmail 81099 invoked by uid 500); 22 Sep 2014 11:08:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81024 invoked by uid 500); 22 Sep 2014 11:08:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81012 invoked by uid 99); 22 Sep 2014 11:08:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:08:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.180] (HELO mail-vc0-f180.google.com) (209.85.220.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:08:09 +0000
Received: by mail-vc0-f180.google.com with SMTP id hq11so3744183vcb.25
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 04:08:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=w1/QZYSRY0p/SdnC3YagRB0eFDcNs/G9QKhu+Ugw7Z8=;
        b=hMtMfuDW7VglsoqcdtsQgKFAWmoWeCNbVEJPhlVf/ad4fGVVuw1ZFVcyfBS4thb0rB
         UvFIqL/KZKI3jFZ8sFof7bzQ+EAfKZ/c/juUvFbmYtw0U6uRruoacIzj+E+zoJfzclQG
         EV0HdxqvvaWsKQpVPW9YZf5sSGOfS3EAmc0IA0Bgmvs1hvymnXq2qedHgEVpcb0I89sg
         o4DtFkFcwdC9IQE1AMOFHRIqdZTuOVFmmAYyZOZYjRcWh/HOljvBWyTc5UUGQTbF8BPi
         5a4a1Abs4AUIrZmFpLRHpjZrCVgSo30lDd+15smyxF9r/ZBygaiUn49Y16NmPDpYikKf
         tutA==
X-Gm-Message-State: ALoCoQm+h6Xc8MVlJOQAgVTdfgbYQ3mGfDDE9qSE9YjiOv/WMf8eI+CfxGIJgoPHWKVdZY/xkfTf
X-Received: by 10.52.165.97 with SMTP id yx1mr11722094vdb.15.1411384087948;
        Mon, 22 Sep 2014 04:08:07 -0700 (PDT)
Received: from mail-vc0-f170.google.com (mail-vc0-f170.google.com [209.85.220.170])
        by mx.google.com with ESMTPSA id tz3sm1801506vdb.24.2014.09.22.04.08.06
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 22 Sep 2014 04:08:06 -0700 (PDT)
Received: by mail-vc0-f170.google.com with SMTP id ij19so1561808vcb.15
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 04:08:06 -0700 (PDT)
X-Received: by 10.221.57.68 with SMTP id wf4mr6308517vcb.55.1411384086330;
 Mon, 22 Sep 2014 04:08:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.17.197 with HTTP; Mon, 22 Sep 2014 04:07:46 -0700 (PDT)
In-Reply-To: <CAAdRV=PwZvwtfHvORkpJHaxoAFaUrccpum3-G6CRP7kYFQkTUA@mail.gmail.com>
References: <CACfA1zV8QCDdNLdQjH5=gqBP_Asf3_iDtayZdbXFq3HiUWA61A@mail.gmail.com>
 <CAPh_B=bb292upsddzBnBCZNW5X6Qdn4_p4NK4aGF28uhBKg7hA@mail.gmail.com>
 <CABPQxssU48ijKwQiDQLVNFbR5b8kmoHy=Nbn-jAoWMZBTRqkJg@mail.gmail.com>
 <CABPQxss8OMzD=xt1DBGrdx-q1bAsU7E=MynbMAkUuq-q3=3-Aw@mail.gmail.com>
 <CACfA1zWOd+djvoAKPCt+ScRNirBKdZsQw-bYJZwd_M5oYy7HDw@mail.gmail.com>
 <829BEA51-5B46-4E85-A7C8-8948F77D2DBB@hortonworks.com> <CAKxiPZPYLzcCLsV1J5JyGfjpQgdoOOWtqQadiu3=MDP7QheUsA@mail.gmail.com>
 <CAAdRV=PwZvwtfHvORkpJHaxoAFaUrccpum3-G6CRP7kYFQkTUA@mail.gmail.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Mon, 22 Sep 2014 04:07:46 -0700
Message-ID: <CA+-p3AEfz45C=wvtjQzsEETMog83BXkz-B=UCEynNVpgR6YUOw@mail.gmail.com>
Subject: Re: BlockManager issues
To: David Rowe <davidrowe@gmail.com>
Cc: Christoph Sawade <christoph.sawade@googlemail.com>, Hortonworks <zzhang@hortonworks.com>, 
	Nishkam Ravi <nravi@cloudera.com>, Patrick Wendell <pwendell@gmail.com>, 
	Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113377fc1b85d10503a577ba
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113377fc1b85d10503a577ba
Content-Type: text/plain; charset=UTF-8

Another data point on the 1.1.0 FetchFailures:

Running this SQL command works on 1.0.2 but fails on 1.1.0 due to the
exceptions mentioned earlier in this thread: "SELECT stringCol,
SUM(doubleCol) FROM parquetTable GROUP BY stringCol"

The FetchFailure exception has the remote block manager that failed to
produce the shuffle.  I enabled GC logging and repeated, and the
CoarseGrainedExecutorBackend JVM is just pounding in full GCs:

943.047: [Full GC [PSYoungGen: 5708288K->5536188K(8105472K)] [ParOldGen:
20971043K->20971202K(20971520K)] 26679331K->26507390K(29076992K)
[PSPermGen: 52897K->52897K(57344K)], 48.4514680 secs] [Times: user=602.38
sys=4.43, real=48.44 secs]
991.591: [Full GC [PSYoungGen: 5708288K->5591884K(8105472K)] [ParOldGen:
20971202K->20971044K(20971520K)] 26679490K->26562928K(29076992K)
[PSPermGen: 52897K->52897K(56832K)], 51.8109380 secs] [Times: user=645.44
sys=5.03, real=51.81 secs]
1043.431: [Full GC [PSYoungGen: 5708288K->5606238K(8105472K)] [ParOldGen:
20971044K->20971100K(20971520K)] 26679332K->26577339K(29076992K)
[PSPermGen: 52908K->52908K(56320K)], 85.9367800 secs] [Times: user=1074.29
sys=9.49, real=85.92 secs]
1129.419: [Full GC [PSYoungGen: 5708288K->5634246K(8105472K)] [ParOldGen:
20971100K->20971471K(20971520K)] 26679388K->26605717K(29076992K)
[PSPermGen: 52912K->52912K(55808K)], 52.2114100 secs] [Times: user=652.29
sys=4.94, real=52.21 secs]
1181.671: [Full GC [PSYoungGen: 5708288K->5656389K(8105472K)] [ParOldGen:
20971471K->20971125K(20971520K)] 26679759K->26627514K(29076992K)
[PSPermGen: 52961K->52961K(55296K)], 65.3284620 secs] [Times: user=818.58
sys=6.71, real=65.31 secs]
1247.034: [Full GC [PSYoungGen: 5708288K->5672356K(8105472K)] [ParOldGen:
20971125K->20971417K(20971520K)] 26679413K->26643774K(29076992K)
[PSPermGen: 52982K->52982K(54784K)], 91.2656940 secs] [Times: user=1146.94
sys=9.83, real=91.25 secs]
1338.318: [Full GC [PSYoungGen: 5708288K->5683177K(8105472K)] [ParOldGen:
20971417K->20971364K(20971520K)] 26679705K->26654541K(29076992K)
[PSPermGen: 52982K->52982K(54784K)], 68.9840690 secs] [Times: user=866.72
sys=7.31, real=68.97 secs]
1407.319: [Full GC [PSYoungGen: 5708288K->5691352K(8105472K)] [ParOldGen:
20971364K->20971041K(20971520K)] 26679652K->26662394K(29076992K)
[PSPermGen: 52985K->52985K(54272K)], 58.2522860 secs] [Times: user=724.33
sys=5.74, real=58.24 secs]
1465.572: [Full GC [PSYoungGen: 5708288K->5691382K(8105472K)] [ParOldGen:
20971041K->20971041K(20971520K)] 26679329K->26662424K(29076992K)
[PSPermGen: 52986K->52986K(54272K)], 17.8034740 secs] [Times: user=221.43
sys=0.72, real=17.80 secs]
1483.377: [Full GC [PSYoungGen: 5708288K->5691383K(8105472K)] [ParOldGen:
20971041K->20971041K(20971520K)] 26679329K->26662424K(29076992K)
[PSPermGen: 52987K->52987K(54272K)], 64.3194300 secs] [Times: user=800.32
sys=6.65, real=64.31 secs]
1547.700: [Full GC [PSYoungGen: 5708288K->5692228K(8105472K)] [ParOldGen:
20971041K->20971029K(20971520K)] 26679329K->26663257K(29076992K)
[PSPermGen: 52991K->52991K(53760K)], 54.8107170 secs] [Times: user=681.07
sys=5.41, real=54.80 secs]
1602.519: [Full GC [PSYoungGen: 5708288K->5695801K(8105472K)] [ParOldGen:
20971029K->20971401K(20971520K)] 26679317K->26667203K(29076992K)
[PSPermGen: 52993K->52993K(53760K)], 71.7970690 secs] [Times: user=896.22
sys=7.61, real=71.79 secs]



I repeated the job, this time taking jmap -histos as it went along.  The
last histo I was able to get before the JVM locked up (getting a histo on a
JVM in GC storms is very difficult) is here:

 num     #instances         #bytes  class name
----------------------------------------------
   1:      31437598     2779681704  [B
   2:      62794123     1507058952  scala.collection.immutable.$colon$colon
   3:      31387645     1506606960
 org.apache.spark.sql.catalyst.expressions.Cast
   4:      31387645     1506606960
 org.apache.spark.sql.catalyst.expressions.SumFunction
   5:      31387645     1255505800
 org.apache.spark.sql.catalyst.expressions.Literal
   6:      31387645     1255505800
 org.apache.spark.sql.catalyst.expressions.Coalesce
   7:      31387645     1255505800
 org.apache.spark.sql.catalyst.expressions.MutableLiteral
   8:      31387645     1255505800
 org.apache.spark.sql.catalyst.expressions.Add
   9:      31391224     1004519168  java.util.HashMap$Entry
  10:      31402978      756090664  [Ljava.lang.Object;
  11:      31395785      753498840  java.lang.Double
  12:      31387645      753303480
 [Lorg.apache.spark.sql.catalyst.expressions.AggregateFunction;
  13:      31395808      502332928
 org.apache.spark.sql.catalyst.expressions.GenericRow
  14:      31387645      502202320
 org.apache.spark.sql.catalyst.expressions.Cast$$anonfun$castToDouble$5
  15:           772      234947960  [Ljava.util.HashMap$Entry;
  16:           711      106309792  [I
  17:        106747       13673936  <methodKlass>
  18:        106747       12942856  <constMethodKlass>
  19:          8186        9037880  <constantPoolKlass>
  20:          8186        8085000  <instanceKlassKlass>
  21:        222494        5339856  scala.Tuple2
  22:        213731        5129544  java.lang.Long
  23:          6609        4754144  <constantPoolCacheKlass>
  24:         36254        3348992  [C
  25:            73        2393232
 [Lscala.concurrent.forkjoin.ForkJoinTask;
  26:         88787        2130888  org.apache.spark.storage.ShuffleBlockId
  27:          4826        1812216  <methodDataKlass>
  28:          8688        1020352  java.lang.Class
  29:         15957         869016  [[I


For me at least a symptom is large GC storms on the executors.  Is anyone
observing these FetchFailures on a consistent basis that doesn't also see
heavy GC?

Hope this helps with debugging.

Andrew


On Mon, Sep 22, 2014 at 3:36 AM, David Rowe <davidrowe@gmail.com> wrote:

> I've run into this with large shuffles - I assumed that there was
> contention between the shuffle output files and the JVM for memory.
> Whenever we start getting these fetch failures, it corresponds with high
> load on the machines the blocks are being fetched from, and in some cases
> complete unresponsiveness (no ssh etc). Setting the timeout higher, or the
> JVM heap lower (as a percentage of total machine memory) seemed to help..
>
>
>
> On Mon, Sep 22, 2014 at 8:02 PM, Christoph Sawade <
> christoph.sawade@googlemail.com> wrote:
>
> > Hey all. We had also the same problem described by Nishkam almost in the
> > same big data setting. We fixed the fetch failure by increasing the
> timeout
> > for acks in the driver:
> >
> > set("spark.core.connection.ack.wait.timeout", "600") // 10 minutes
> timeout
> > for acks between nodes
> >
> > Cheers, Christoph
> >
> > 2014-09-22 9:24 GMT+02:00 Hortonworks <zzhang@hortonworks.com>:
> >
> > > Actually I met similar issue when doing groupByKey and then count if
> the
> > > shuffle size is big e.g. 1tb.
> > >
> > > Thanks.
> > >
> > > Zhan Zhang
> > >
> > > Sent from my iPhone
> > >
> > > > On Sep 21, 2014, at 10:56 PM, Nishkam Ravi <nravi@cloudera.com>
> wrote:
> > > >
> > > > Thanks for the quick follow up Reynold and Patrick. Tried a run with
> > > > significantly higher ulimit, doesn't seem to help. The executors have
> > > 35GB
> > > > each. Btw, with a recent version of the branch, the error message is
> > > "fetch
> > > > failures" as opposed to "too many open files". Not sure if they are
> > > > related.  Please note that the workload runs fine with head set to
> > > 066765d.
> > > > In case you want to reproduce the problem: I'm running slightly
> > modified
> > > > ScalaPageRank (with KryoSerializer and persistence level
> > > > memory_and_disk_ser) on a 30GB input dataset and a 6-node cluster.
> > > >
> > > > Thanks,
> > > > Nishkam
> > > >
> > > > On Sun, Sep 21, 2014 at 10:32 PM, Patrick Wendell <
> pwendell@gmail.com>
> > > > wrote:
> > > >
> > > >> Ah I see it was SPARK-2711 (and PR1707). In that case, it's possible
> > > >> that you are just having more spilling as a result of the patch and
> so
> > > >> the filesystem is opening more files. I would try increasing the
> > > >> ulimit.
> > > >>
> > > >> How much memory do your executors have?
> > > >>
> > > >> - Patrick
> > > >>
> > > >> On Sun, Sep 21, 2014 at 10:29 PM, Patrick Wendell <
> pwendell@gmail.com
> > >
> > > >> wrote:
> > > >>> Hey the numbers you mentioned don't quite line up - did you mean PR
> > > 2711?
> > > >>>
> > > >>> On Sun, Sep 21, 2014 at 8:45 PM, Reynold Xin <rxin@databricks.com>
> > > >> wrote:
> > > >>>> It seems like you just need to raise the ulimit?
> > > >>>>
> > > >>>>
> > > >>>> On Sun, Sep 21, 2014 at 8:41 PM, Nishkam Ravi <nravi@cloudera.com
> >
> > > >> wrote:
> > > >>>>
> > > >>>>> Recently upgraded to 1.1.0. Saw a bunch of fetch failures for one
> > of
> > > >> the
> > > >>>>> workloads. Tried tracing the problem through change set analysis.
> > > Looks
> > > >>>>> like the offending commit is 4fde28c from Aug 4th for PR1707.
> > Please
> > > >> see
> > > >>>>> SPARK-3633 for more details.
> > > >>>>>
> > > >>>>> Thanks,
> > > >>>>> Nishkam
> > > >>
> > >
> > > --
> > > CONFIDENTIALITY NOTICE
> > > NOTICE: This message is intended for the use of the individual or
> entity
> > to
> > > which it is addressed and may contain information that is confidential,
> > > privileged and exempt from disclosure under applicable law. If the
> reader
> > > of this message is not the intended recipient, you are hereby notified
> > that
> > > any printing, copying, dissemination, distribution, disclosure or
> > > forwarding of this communication is strictly prohibited. If you have
> > > received this communication in error, please contact the sender
> > immediately
> > > and delete it from your system. Thank You.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--001a113377fc1b85d10503a577ba--

From dev-return-9533-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 11:15:35 2014
Return-Path: <dev-return-9533-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 761081161D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 11:15:35 +0000 (UTC)
Received: (qmail 96054 invoked by uid 500); 22 Sep 2014 11:15:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95976 invoked by uid 500); 22 Sep 2014 11:15:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95927 invoked by uid 99); 22 Sep 2014 11:15:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:15:34 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:15:30 +0000
Received: by mail-la0-f50.google.com with SMTP id ty20so6428367lab.23
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 04:15:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8N5JBBosmh6f8D2qdnWqeYTLTm+sbnQdKxJo8lAwnqE=;
        b=k+aXIbGbFoR7KumVEFXooKT7EgY8jFq7xaAi0fPxUy0KJiboITDeHUS70amMxSxkFU
         Xvm9dFFh4zvlOP9pkUauRHy6Pr1sdk+j0AjEhYE/RlZhL/fClayr9UvEGSEowCHbZ0NA
         Y2WtiZ3JpxuOvWymgqx6PjRzOvgpbOkDTijYseFCjIISUV4imkSMZjLpblSA4n9XLshR
         b+uRCysXoDSWS4kCSPcqRC9AKdllcxsVOYm73gFl9cBE9W9ijpzvWUE3BiJ24smq8lRW
         PeFl7QDEAPkSP9S2EpHaPdAAlBsZrqCIpttwRJzgRUmYtzDQmCekz7Lfn8sC8v/Ttxxl
         RXyA==
MIME-Version: 1.0
X-Received: by 10.152.9.132 with SMTP id z4mr25469798laa.8.1411384508689; Mon,
 22 Sep 2014 04:15:08 -0700 (PDT)
Received: by 10.152.37.231 with HTTP; Mon, 22 Sep 2014 04:15:08 -0700 (PDT)
In-Reply-To: <CA+45J9P+OF-enYPU_Re259tyEWFHX4H=EfFROEGu7NtJ89eE1A@mail.gmail.com>
References: <CAJOb8btdXks-7-spJJ5jMNw0XsnrjwDpCQqtjht1hUn6j4zb_g@mail.gmail.com>
	<CAMAsSdLNsk3xVRmgZoEW==5AGV_wDhA3_Mzk4symmi_q+qVntg@mail.gmail.com>
	<CAG4a3dAjT1EPdEiG0gOoO2xOYO-FmKhxz=4K55r6YhoEfrSEOQ@mail.gmail.com>
	<CANx3uAh0XVU-fX_qYPtjX+1CEEfXWHeqdqVTD+d6tzpWHf9osw@mail.gmail.com>
	<CAMwrk0k3+hEwJtVhn=At4Y_iZvx7jU=mbjc2mw0RTWGzom73QA@mail.gmail.com>
	<CALte62yLoTaw4u2M7=G=zLXkaXAMNEs8zOJB9ogs6+1hyRQZtQ@mail.gmail.com>
	<CAJOb8bv8HqtdhEuHMvQ4CiRMU4neg7w2OGoMY1t364E6m2YyKw@mail.gmail.com>
	<CA+45J9P+OF-enYPU_Re259tyEWFHX4H=EfFROEGu7NtJ89eE1A@mail.gmail.com>
Date: Mon, 22 Sep 2014 16:45:08 +0530
Message-ID: <CAJOb8bvwxZhN7ggWAWBZKnhX7-bwwprVz3NnudYMLLOZa2wp+A@mail.gmail.com>
Subject: Re: Dependency hell in Spark applications
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
To: =?UTF-8?B?7J207J246recKGluUSk=?= <gofiri@gmail.com>
Cc: Ted Yu <yuzhihong@gmail.com>, Tathagata Das <tathagata.das1565@gmail.com>, 
	Koert Kuipers <koert@tresata.com>, Felix Garcia Borrego <fborrego@gilt.com>, Sean Owen <sowen@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1132e99a4831870503a590cd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1132e99a4831870503a590cd
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I have submitted a defect in JIRA for this:
https://issues.apache.org/jira/browse/SPARK-3638 and have submitted a PR (
https://github.com/apache/spark/pull/2489) that temporarily fixes the
issue. Users would have to build spark with kinesis-asl to get the
compatible httpclient added to spark assembly jar.

On 22 September 2014 15:00, =EC=9D=B4=EC=9D=B8=EA=B7=9C(inQ) <gofiri@gmail.=
com> wrote:

> Hello,
>
> In my case, I manually deleted org/apache/http directory in the
> spark-assembly jar file..
> I think if we use the latest version of httpclient (httpcore) library, we
> can resolve the problem.
> How about upgrading httpclient? (or jets3t?)
>
> 2014-09-11 19:09 GMT+09:00 Aniket Bhatnagar <aniket.bhatnagar@gmail.com>:
>
>> Thanks everyone for weighing in on this.
>>
>> I had backported kinesis module from master to spark 1.0.2 so just to
>> confirm if I am not missing anything, I did a dependency graph compare o=
f
>> my spark build with spark-master
>> and org.apache.httpcomponents:httpclient:jar does seem to resolve to 4.1=
.2
>> dependency.
>>
>> I need Hive so, I can't really do a build without it. Even if I
>> exclude httpclient
>> dependency from my project's build, it will not solve the problem becaus=
e
>> AWS SDK has been compiled with a greater version of http client. My spar=
k
>> stream project does not uses http client directly. AWS SDK will look for
>>  class org.apache.http.impl.conn.DefaultClientConnectionOperator and it
>> will be loaded from spark-assembly jar regardless of how I package my
>> project (unless I am missing something?). I enabled verbosed classloadin=
g
>> to confirm that the class is indeed loading from spark-assembly jar.
>>
>> spark.files.userClassPathFirst option doesn't seem to be working on my
>> spark 1.0.2 build (not sure why).
>>
>> I was only left custom building spark and forcingly introduce latest
>> httpclient's latest version as dependency.
>>
>> Finally, I tested this on 1.1.0-RC4 today and it has the same issue. Has
>> anyone ever been able to get the Kinesis example work with spark-hadoop2=
.4
>> (with hive and yarn) build? I feel like this is a bug that exists even i=
n
>> 1.1.0.
>>
>> I still believe we need a better solution to address the dependency hell
>> problem. If OSGi is deemed too over the top, what are the solutions bein=
g
>> investigated?
>>
>> On 6 September 2014 04:44, Ted Yu <yuzhihong@gmail.com> wrote:
>>
>> > From output of dependency:tree:
>> >
>> > [INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @
>> > spark-streaming_2.10 ---
>> > [INFO] org.apache.spark:spark-streaming_2.10:jar:1.1.0-SNAPSHOT
>> > INFO] +- org.apache.spark:spark-core_2.10:jar:1.1.0-SNAPSHOT:compile
>> > [INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.4.0:compile
>> > ...
>> > [INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile
>> > [INFO] |  |  +- commons-codec:commons-codec:jar:1.5:compile
>> > [INFO] |  |  +- org.apache.httpcomponents:httpclient:jar:4.1.2:compile
>> > [INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.1.2:compile
>> >
>> > bq. excluding httpclient from spark-streaming dependency in your
>> > sbt/maven project
>> >
>> > This should work.
>> >
>> >
>> > On Fri, Sep 5, 2014 at 3:14 PM, Tathagata Das <
>> tathagata.das1565@gmail.com
>> > > wrote:
>> >
>> >> If httpClient dependency is coming from Hive, you could build Spark
>> >> without
>> >> Hive. Alternatively, have you tried excluding httpclient from
>> >> spark-streaming dependency in your sbt/maven project?
>> >>
>> >> TD
>> >>
>> >>
>> >>
>> >> On Thu, Sep 4, 2014 at 6:42 AM, Koert Kuipers <koert@tresata.com>
>> wrote:
>> >>
>> >> > custom spark builds should not be the answer. at least not if spark
>> ever
>> >> > wants to have a vibrant community for spark apps.
>> >> >
>> >> > spark does support a user-classpath-first option, which would deal
>> with
>> >> > some of these issues, but I don't think it works.
>> >> > On Sep 4, 2014 9:01 AM, "Felix Garcia Borrego" <fborrego@gilt.com>
>> >> wrote:
>> >> >
>> >> > > Hi,
>> >> > > I run into the same issue and apart from the ideas Aniket said, I
>> only
>> >> > > could find a nasty workaround. Add my custom
>> >> > PoolingClientConnectionManager
>> >> > > to my classpath.
>> >> > >
>> >> > >
>> >> > >
>> >> >
>> >>
>> http://stackoverflow.com/questions/24788949/nosuchmethoderror-while-runn=
ing-aws-s3-client-on-spark-while-javap-shows-otherwi/25488955#25488955
>> >> > >
>> >> > >
>> >> > >
>> >> > > On Thu, Sep 4, 2014 at 11:43 AM, Sean Owen <sowen@cloudera.com>
>> >> wrote:
>> >> > >
>> >> > > > Dumb question -- are you using a Spark build that includes the
>> >> Kinesis
>> >> > > > dependency? that build would have resolved conflicts like this
>> for
>> >> > > > you. Your app would need to use the same version of the Kinesis
>> >> client
>> >> > > > SDK, ideally.
>> >> > > >
>> >> > > > All of these ideas are well-known, yes. In cases of super-commo=
n
>> >> > > > dependencies like Guava, they are already shaded. This is a
>> >> > > > less-common source of conflicts so I don't think http-client is
>> >> > > > shaded, especially since it is not used directly by Spark. I
>> think
>> >> > > > this is a case of your app conflicting with a third-party
>> >> dependency?
>> >> > > >
>> >> > > > I think OSGi is deemed too over the top for things like this.
>> >> > > >
>> >> > > > On Thu, Sep 4, 2014 at 11:35 AM, Aniket Bhatnagar
>> >> > > > <aniket.bhatnagar@gmail.com> wrote:
>> >> > > > > I am trying to use Kinesis as source to Spark Streaming and
>> have
>> >> run
>> >> > > > into a
>> >> > > > > dependency issue that can't be resolved without making my own
>> >> custom
>> >> > > > Spark
>> >> > > > > build. The issue is that Spark is transitively dependent
>> >> > > > > on org.apache.httpcomponents:httpclient:jar:4.1.2 (I think
>> >> because of
>> >> > > > > libfb303 coming from hbase and hive-serde) whereas AWS SDK is
>> >> > dependent
>> >> > > > > on org.apache.httpcomponents:httpclient:jar:4.2. When I packa=
ge
>> >> and
>> >> > run
>> >> > > > > Spark Streaming application, I get the following:
>> >> > > > >
>> >> > > > > Caused by: java.lang.NoSuchMethodError:
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> org.apache.http.impl.conn.DefaultClientConnectionOperator.<init>(Lorg/ap=
ache/http/conn/scheme/SchemeRegistry;Lorg/apache/http/conn/DnsResolver;)V
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> org.apache.http.impl.conn.PoolingClientConnectionManager.createConnectio=
nOperator(PoolingClientConnectionManager.java:140)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingC=
lientConnectionManager.java:114)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> org.apache.http.impl.conn.PoolingClientConnectionManager.<init>(PoolingC=
lientConnectionManager.java:99)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.http.ConnectionManagerFactory.createPoolingClientConnManag=
er(ConnectionManagerFactory.java:29)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.http.HttpClientFactory.createHttpClient(HttpClientFactory.=
java:97)
>> >> > > > >         at
>> >> > > > >
>> >> com.amazonaws.http.AmazonHttpClient.<init>(AmazonHttpClient.java:181)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:=
119)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.AmazonWebServiceClient.<init>(AmazonWebServiceClient.java:=
103)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisC=
lient.java:136)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.services.kinesis.AmazonKinesisClient.<init>(AmazonKinesisC=
lient.java:117)
>> >> > > > >         at
>> >> > > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> com.amazonaws.services.kinesis.AmazonKinesisAsyncClient.<init>(AmazonKin=
esisAsyncClient.java:132)
>> >> > > > >
>> >> > > > > I can create a custom Spark build with
>> >> > > > > org.apache.httpcomponents:httpclient:jar:4.2 included in the
>> >> assembly
>> >> > > > but I
>> >> > > > > was wondering if this is something Spark devs have noticed an=
d
>> are
>> >> > > > looking
>> >> > > > > to resolve in near releases. Here are my thoughts on this
>> issue:
>> >> > > > >
>> >> > > > > Containers that allow running custom user code have to often
>> >> resolve
>> >> > > > > dependency issues in case of conflicts between framework's an=
d
>> >> user
>> >> > > > code's
>> >> > > > > dependency. Here is how I have seen some frameworks resolve t=
he
>> >> > issue:
>> >> > > > > 1. Provide a child-first class loader: Some JEE containers
>> >> provided a
>> >> > > > > child-first class loader that allowed for loading classes fro=
m
>> >> user
>> >> > > code
>> >> > > > > first. I don't think this approach completely solves the
>> problem
>> >> as
>> >> > the
>> >> > > > > framework is then susceptible to class mismatch errors.
>> >> > > > > 2. Fold in all dependencies in a sub-package: This approach
>> >> involves
>> >> > > > > folding all dependencies in a project specific sub-package
>> (like
>> >> > > > > spark.dependencies). This approach is tedious because it
>> involves
>> >> > > > building
>> >> > > > > custom version of all dependencies (and their transitive
>> >> > dependencies)
>> >> > > > > 3. Use something like OSGi: Some frameworks has successfully
>> used
>> >> > OSGi
>> >> > > to
>> >> > > > > manage dependencies between the modules. The challenge in thi=
s
>> >> > approach
>> >> > > > is
>> >> > > > > to OSGify the framework and hide OSGi complexities from end
>> user.
>> >> > > > >
>> >> > > > > My personal preference is OSGi (or atleast some support for
>> OSGi)
>> >> > but I
>> >> > > > > would love to hear what Spark devs are thinking in terms of
>> >> resolving
>> >> > > the
>> >> > > > > problem.
>> >> > > > >
>> >> > > > > Thanks,
>> >> > > > > Aniket
>> >> > > >
>> >> > > >
>> >> ---------------------------------------------------------------------
>> >> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> > > > For additional commands, e-mail: dev-help@spark.apache.org
>> >> > > >
>> >> > > >
>> >> > >
>> >> >
>> >>
>> >
>> >
>>
>
>

--001a1132e99a4831870503a590cd--

From dev-return-9534-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 11:41:37 2014
Return-Path: <dev-return-9534-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D0F66116C7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 11:41:37 +0000 (UTC)
Received: (qmail 29456 invoked by uid 500); 22 Sep 2014 11:41:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29391 invoked by uid 500); 22 Sep 2014 11:41:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29366 invoked by uid 99); 22 Sep 2014 11:41:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:41:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 11:41:31 +0000
Received: by mail-ig0-f182.google.com with SMTP id hn15so2496722igb.3
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 04:41:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=qbHS5V2vnzOdb7fhMAxKNrOrtp5/rSIhW9uBRp76ULI=;
        b=s85fgB3HtIFI6yLOzks4aD0FXBadlfIuHYi/cTukjy1fvpGGJNL2X26dCrdfJZBO9c
         rdUKBwVztVFZvdlrPWgyftwnvbp6dKtJIom2zfpS/vFzt99ebopiKvhWTbTJcu4qgFRv
         +qKVNqvul8w0ivUg8CPZ0O+Na5XHlGpRtT9gpudOQv4H+RMJexBHEOX9prp2W6Mc6R3E
         UyEq25T3KrfrOE9qlWqJln+y9vasCvUzzTQY+K33RA3I8UBBmLFxY5y2ghnVOcpx98HA
         vJe9T71P/xQfhdwD5pgX64faMd4iT/+uWt0YJim98gpAJzqwCgoJFfHopc8C1psEAgCq
         FZrw==
X-Received: by 10.42.46.81 with SMTP id j17mr7033833icf.54.1411386071290;
        Mon, 22 Sep 2014 04:41:11 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id z2sm8589890igl.16.2014.09.22.04.41.10
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Mon, 22 Sep 2014 04:41:10 -0700 (PDT)
Date: Mon, 22 Sep 2014 07:55:31 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
In-Reply-To: <etPan.541f52be.ded7263.c101@mbp-3>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
 <etPan.541e5dad.4db127f8.c101@mbp-3.local>
 <94DE5E900B054CF487A51DAA4451291C@gmail.com>
 <etPan.541f52be.ded7263.c101@mbp-3>
Subject: Re: A couple questions about shared variables
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54200e33_7bd3ee7b_1f0"
X-Virus-Checked: Checked by ClamAV on apache.org

--54200e33_7bd3ee7b_1f0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

If you think it as necessary to fix, I would like to resubmit that PR (se=
ems to have some conflicts with the current DAGScheduler) =20

My suggestion is to make it as an option in accumulator, e.g. some algori=
thms utilizing accumulator for result calculation, it needs a determinist=
ic accumulator, while others implementing something like Hadoop counters =
may need the current implementation (count everything happened, including=
 the duplications)

Your thoughts=3F =20

-- =20
Nan Zhu


On Sunday, September 21, 2014 at 6:35 PM, Matei Zaharia wrote:

> Hmm, good point, this seems to have been broken by refactorings of the =
scheduler, but it worked in the past. Basically the solution is simple --=
 in a result stage, we should not apply the update for each task ID more =
than once -- the same way we don't call job.listener.taskSucceeded more t=
han once. Your PR also tried to avoid this for resubmitted shuffle stages=
, but I don't think we need to do that necessarily (though we could).
> =20
> Matei =20
> =20
> On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill=40gmail.com =
(mailto:zhunanmcgill=40gmail.com)) wrote:
> =20
> > Hi, Matei, =20
> > =20
> > Can you give some hint on how the current implementation guarantee th=
e accumulator is only applied for once=3F =20
> > =20
> > There is a pending PR trying to achieving this (https://github.com/ap=
ache/spark/pull/228/files), but from the current implementation, I didn=E2=
=80=99t see this has been done=3F (maybe I missed something) =20
> > =20
> > Best, =20
> > =20
> > --  =20
> > Nan Zhu
> > =20
> > =20
> > On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:
> > =20
> > > Hey Sandy,
> > > =20
> > > On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=40cloud=
era.com (mailto:sandy.ryza=40cloudera.com)) wrote: =20
> > > =20
> > > Hey All,  =20
> > > =20
> > > A couple questions came up about shared variables recently, and I w=
anted to  =20
> > > confirm my understanding and update the doc to be a little more cle=
ar. =20
> > > =20
> > > *Broadcast variables*  =20
> > > Now that tasks data is automatically broadcast, the only occasions =
where it =20
> > > makes sense to explicitly broadcast are: =20
> > > * You want to use a variable from tasks in multiple stages. =20
> > > * You want to have the variable stored on the executors in deserial=
ized =20
> > > form. =20
> > > * You want tasks to be able to modify the variable and have those =20
> > > modifications take effect for other tasks running on the same execu=
tor =20
> > > (usually a very bad idea). =20
> > > =20
> > > Is that right=3F  =20
> > > Yeah, pretty much. Reason 1 above is probably the biggest, but 2 al=
so matters. (We might later factor tasks in a different way to avoid 2, b=
ut it's hard due to things like Hadoop JobConf objects in the tasks).
> > > =20
> > > =20
> > > *Accumulators*  =20
> > > Values are only counted for successful tasks. Is that right=3F KMea=
ns seems =20
> > > to use it in this way. What happens if a node goes away and success=
ful =20
> > > tasks need to be resubmitted=3F Or the stage runs again because a d=
ifferent =20
> > > job needed it. =20
> > > Accumulators are guaranteed to give a deterministic result if you o=
nly increment them in actions. =46or each result stage, the accumulator's=
 update from each task is only applied once, even if that task runs multi=
ple times. If you use accumulators in transformations (i.e. in a stage th=
at may be part of multiple jobs), then you may see multiple updates, from=
 each run. This is kind of confusing but it was useful for people who wan=
ted to use these for debugging.
> > > =20
> > > Matei =20
> > > =20
> > > =20
> > > =20
> > > =20
> > > =20
> > > thanks,  =20
> > > Sandy =20
> > > =20
> > > =20
> > > =20
> > =20
> > =20


--54200e33_7bd3ee7b_1f0--


From dev-return-9535-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 14:16:34 2014
Return-Path: <dev-return-9535-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7908711D6E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 14:16:34 +0000 (UTC)
Received: (qmail 87941 invoked by uid 500); 22 Sep 2014 14:16:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87871 invoked by uid 500); 22 Sep 2014 14:16:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87859 invoked by uid 99); 22 Sep 2014 14:16:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 14:16:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 14:16:27 +0000
Received: by mail-ob0-f171.google.com with SMTP id wp4so588134obc.2
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 07:16:07 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=idwtGeIzaZ+07JESkx0vkaVxsi24r/or1UtstqCs3T8=;
        b=gjhvCLWIXlxODz6VvLnCNe1307FsOB3foNI8Q2oZFhnRuxCJFOuU1az45aWIREGJ31
         cW91NcPByuHC9SNHonT9gomGNAjw6Hyr9IEcoMNu3scahRZYutNTcDapbzKdkidB9rcU
         jvTlfK52IRk+I7t/HMpdFBHIyeI9MJAL5Wxq5JKLyJKcWVL8ftzf9Pet/+kCUGSkfBOe
         7wAoY8TQPEJ2TD0Pk76PK949WYvQ+p8yw8lN3mEfVoO7ou1gJDyzARHQPy/DPQNE0Bws
         z43kvZ4jq1plYTeHmqjRXA+bUJqS4Hj/Yf3iShojjvy6A1YjXeWCgQ2S+H3KSrTcTVUm
         goWA==
X-Gm-Message-State: ALoCoQlPUZE9msxYkmrHO2ntQUCKVF8hOVoyPtMomAbFiXZE10DPQwHLUZjnASShawzbefW2dovh
MIME-Version: 1.0
X-Received: by 10.60.174.3 with SMTP id bo3mr19546587oec.31.1411395366871;
 Mon, 22 Sep 2014 07:16:06 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 22 Sep 2014 07:16:06 -0700 (PDT)
Date: Mon, 22 Sep 2014 09:16:06 -0500
Message-ID: <CAKWX9VXstLZ6hQRTyxMFvU77QC7ACisRJaatXFuGMjJuAsbYiw@mail.gmail.com>
Subject: hash vs sort shuffle
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011844ce7b4e6d0503a81711
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011844ce7b4e6d0503a81711
Content-Type: text/plain; charset=UTF-8

Just as a heads up, we deployed 471e6a3a of master (in order to get some
sql fixes), and were seeing jobs fail until we set

spark.shuffle.manager=HASH

I'd be reluctant to change the default to sort for the 1.1.1 release

--089e011844ce7b4e6d0503a81711--

From dev-return-9536-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 15:54:29 2014
Return-Path: <dev-return-9536-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 28F51110D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 15:54:29 +0000 (UTC)
Received: (qmail 27045 invoked by uid 500); 22 Sep 2014 15:54:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26968 invoked by uid 500); 22 Sep 2014 15:54:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26957 invoked by uid 99); 22 Sep 2014 15:54:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 15:54:28 +0000
X-ASF-Spam-Status: No, hits=5.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 15:54:02 +0000
Received: by mail-qa0-f51.google.com with SMTP id j7so309952qaq.10
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 08:54:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=lFVp+uLAVJ0ULgbzm8jvLar1jbizluDoF2VLQh+UyJg=;
        b=dusGIbmBrfMHUrVNkrsKTK7R1V6qlFHtMJZUH5FWc0iMTih8W8NyL2SOpXLd3kYb1r
         +1TrSM/mQMolkPzPL/QhAYslihwS2Fnx2wurpBEoEU6q3dbYkP3u2udI+qMAxlT7LI9X
         PfeYHaED7Rdng+kaUlNkcE6petJo1ssK28azw+wetCO89uqJO1DZutJcqFZZmHwmPMre
         AvfltenjroqgZs8XZ8mP+y+dIGbp94AIdaiDct+6zsjily61s007xMJKNoOmVLvIY2dj
         5vkUE2rGELnXwhF7csRcJ8OsDKXWKSOVomwOISCR+09guheEWbTX2uTjFgxhx1Z984J4
         BwXQ==
X-Gm-Message-State: ALoCoQm610bnUTIFMc40j/92Uj2Mo2wS2khU7K+VMDBLfWZT7MWBt2NSFokQ/r4xjHUl/RsZ7vlQ
MIME-Version: 1.0
X-Received: by 10.229.100.68 with SMTP id x4mr5508322qcn.29.1411401241217;
 Mon, 22 Sep 2014 08:54:01 -0700 (PDT)
Received: by 10.140.40.199 with HTTP; Mon, 22 Sep 2014 08:54:01 -0700 (PDT)
In-Reply-To: <CAKWX9VXstLZ6hQRTyxMFvU77QC7ACisRJaatXFuGMjJuAsbYiw@mail.gmail.com>
References: <CAKWX9VXstLZ6hQRTyxMFvU77QC7ACisRJaatXFuGMjJuAsbYiw@mail.gmail.com>
Date: Mon, 22 Sep 2014 08:54:01 -0700
Message-ID: <CACBYxKJ1B_fiMTYcytOFs4yTEZ2VfBJv4V4LuDoUnqOvpNuvxg@mail.gmail.com>
Subject: Re: hash vs sort shuffle
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113373929e70570503a97585
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113373929e70570503a97585
Content-Type: text/plain; charset=UTF-8

Thanks for the heads up Cody.  Any indication of what was going wrong?

On Mon, Sep 22, 2014 at 7:16 AM, Cody Koeninger <cody@koeninger.org> wrote:

> Just as a heads up, we deployed 471e6a3a of master (in order to get some
> sql fixes), and were seeing jobs fail until we set
>
> spark.shuffle.manager=HASH
>
> I'd be reluctant to change the default to sort for the 1.1.1 release
>

--001a113373929e70570503a97585--

From dev-return-9537-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 16:08:30 2014
Return-Path: <dev-return-9537-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 038F11118B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 16:08:30 +0000 (UTC)
Received: (qmail 71799 invoked by uid 500); 22 Sep 2014 16:08:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71727 invoked by uid 500); 22 Sep 2014 16:08:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71712 invoked by uid 99); 22 Sep 2014 16:08:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:08:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.170 as permitted sender)
Received: from [209.85.216.170] (HELO mail-qc0-f170.google.com) (209.85.216.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:08:24 +0000
Received: by mail-qc0-f170.google.com with SMTP id c9so305569qcz.1
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 09:08:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=2G6Kk/MHCc6bv6z5jUYNWowtNsGdYzBSj1fVJSG7r3I=;
        b=QX2CB1KGvnf6wbglkWn0rmYw+eHky+z0FI3+VdeSYHg1eVs1jAJoI0+IRUFjZhf7Q4
         QyTWlP+19z/QQNnJBUeHXkLBh2RmhmGi2z/Oq4vqRli5KSELJ7wd+1rySZFyzLF/sLNh
         AtrayHL9Upp8Q7+9MLpgUuzgFlwf0KS2byHYtnmp2qDpHylzwp10defbxBHFYLrMovNc
         qN6dYb3iMVEKIXKRVOaivse6E49feO0CUzE8BEGE4jvfoBMpA10sRh/VZOsCyY/g7YXp
         q9l3T7Htt2FJDoWW9uZifKmrL51tcc3HX3xXQmncmVaR6ebfAUTX+nI1PQ4zQjPzK4Sr
         nSmQ==
X-Gm-Message-State: ALoCoQn/A/86csCQjtIFXRRGjnhEMa0JALYNIjrM1Lio5RlOpqEdCw5D+dut+2TNi+/0w19kPhLv
MIME-Version: 1.0
X-Received: by 10.140.96.45 with SMTP id j42mr21432462qge.5.1411402083729;
 Mon, 22 Sep 2014 09:08:03 -0700 (PDT)
Received: by 10.140.40.199 with HTTP; Mon, 22 Sep 2014 09:08:03 -0700 (PDT)
In-Reply-To: <C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
	<etPan.541e5dad.4db127f8.c101@mbp-3.local>
	<94DE5E900B054CF487A51DAA4451291C@gmail.com>
	<etPan.541f52be.ded7263.c101@mbp-3>
	<C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
Date: Mon, 22 Sep 2014 09:08:03 -0700
Message-ID: <CACBYxKJUHW0271LPD1g+wsa2mw_7w+5Q4-OtMdXh1EmBnM9PeA@mail.gmail.com>
Subject: Re: A couple questions about shared variables
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113b3572d632fc0503a9a735
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113b3572d632fc0503a9a735
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

MapReduce counters do not count duplications.  In MapReduce, if a task
needs to be re-run, the value of the counter from the second task
overwrites the value from the first task.

-Sandy

On Mon, Sep 22, 2014 at 4:55 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  If you think it as necessary to fix, I would like to resubmit that PR
> (seems to have some conflicts with the current DAGScheduler)
>
> My suggestion is to make it as an option in accumulator, e.g. some
> algorithms utilizing accumulator for result calculation, it needs a
> deterministic accumulator, while others implementing something like Hadoo=
p
> counters may need the current implementation (count everything happened,
> including the duplications)
>
> Your thoughts?
>
> --
> Nan Zhu
>
> On Sunday, September 21, 2014 at 6:35 PM, Matei Zaharia wrote:
>
> Hmm, good point, this seems to have been broken by refactorings of the
> scheduler, but it worked in the past. Basically the solution is simple --
> in a result stage, we should not apply the update for each task ID more
> than once -- the same way we don't call job.listener.taskSucceeded more
> than once. Your PR also tried to avoid this for resubmitted shuffle stage=
s,
> but I don't think we need to do that necessarily (though we could).
>
> Matei
>
> On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill@gmail.com)
> wrote:
>
> Hi, Matei,
>
> Can you give some hint on how the current implementation guarantee the
> accumulator is only applied for once?
>
> There is a pending PR trying to achieving this (
> https://github.com/apache/spark/pull/228/files), but from the current
> implementation, I didn=E2=80=99t see this has been done? (maybe I missed =
something)
>
> Best,
>
> --
> Nan Zhu
>
> On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:
>
>  Hey Sandy,
>
> On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza@cloudera.com)
> wrote:
>
> Hey All,
>
> A couple questions came up about shared variables recently, and I wanted
> to
> confirm my understanding and update the doc to be a little more clear.
>
> *Broadcast variables*
> Now that tasks data is automatically broadcast, the only occasions where
> it
> makes sense to explicitly broadcast are:
> * You want to use a variable from tasks in multiple stages.
> * You want to have the variable stored on the executors in deserialized
> form.
> * You want tasks to be able to modify the variable and have those
> modifications take effect for other tasks running on the same executor
> (usually a very bad idea).
>
> Is that right?
> Yeah, pretty much. Reason 1 above is probably the biggest, but 2 also
> matters. (We might later factor tasks in a different way to avoid 2, but
> it's hard due to things like Hadoop JobConf objects in the tasks).
>
>
> *Accumulators*
> Values are only counted for successful tasks. Is that right? KMeans seems
> to use it in this way. What happens if a node goes away and successful
> tasks need to be resubmitted? Or the stage runs again because a different
> job needed it.
> Accumulators are guaranteed to give a deterministic result if you only
> increment them in actions. For each result stage, the accumulator's updat=
e
> from each task is only applied once, even if that task runs multiple time=
s.
> If you use accumulators in transformations (i.e. in a stage that may be
> part of multiple jobs), then you may see multiple updates, from each run.
> This is kind of confusing but it was useful for people who wanted to use
> these for debugging.
>
> Matei
>
>
>
>
>
> thanks,
> Sandy
>
>
>
>

--001a113b3572d632fc0503a9a735--

From dev-return-9538-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 16:08:41 2014
Return-Path: <dev-return-9538-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 287451118C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 16:08:41 +0000 (UTC)
Received: (qmail 73050 invoked by uid 500); 22 Sep 2014 16:08:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72976 invoked by uid 500); 22 Sep 2014 16:08:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72965 invoked by uid 99); 22 Sep 2014 16:08:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:08:39 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:08:34 +0000
Received: by mail-oi0-f43.google.com with SMTP id v63so3607906oia.16
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 09:08:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=+MoGDyZvUV6in6zqaHXywYzlZnmnUFfXolg6X63YoL8=;
        b=bssXeuZ+fqGtfiSGvs3hXfJ2NiB+89sVBr0JXyNQrnfMNFzwFqgA2z3RgCPGit1A6k
         gvT0DVxfLHK1MFvgLq/yo6I2WC8tbFXMIl+67/qjJbO+Hpw9mN6irs8EkIA8I+0OtQpC
         owaXPZrZa6PI0a2pTwE1gqbda0VWWpb79qNGEYax2XOM8AY29SEh4HtJfMous1uKRuG+
         HrLM6kdXm6blcUOn8HXPd9leIZI3LP9RBgKTepRu2gccVwy209XwJybvDR1TNCtQw5FW
         WvS8U/LUW5AZ5M/NLN/ljfNrYSGWyjQRqNTBUTZWCGTtGpR0fAdAzp9b2EJ2RldMZT9+
         YXUg==
X-Gm-Message-State: ALoCoQmrn9BspEctSSEHszz9QrGDgLJJ8W+AguyqKWlYDMx559pTuNicjW1nsK/hy8Fks2wzzE17
MIME-Version: 1.0
X-Received: by 10.182.128.34 with SMTP id nl2mr28252621obb.44.1411402093455;
 Mon, 22 Sep 2014 09:08:13 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 22 Sep 2014 09:08:13 -0700 (PDT)
In-Reply-To: <CACBYxKJ1B_fiMTYcytOFs4yTEZ2VfBJv4V4LuDoUnqOvpNuvxg@mail.gmail.com>
References: <CAKWX9VXstLZ6hQRTyxMFvU77QC7ACisRJaatXFuGMjJuAsbYiw@mail.gmail.com>
	<CACBYxKJ1B_fiMTYcytOFs4yTEZ2VfBJv4V4LuDoUnqOvpNuvxg@mail.gmail.com>
Date: Mon, 22 Sep 2014 11:08:13 -0500
Message-ID: <CAKWX9VWSw-HpTh4zdcvT91kaSLdRL0sP-SK5eipOYNQZ0OL0tA@mail.gmail.com>
Subject: Re: hash vs sort shuffle
From: Cody Koeninger <cody@koeninger.org>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8ff254626a81c30503a9a86e
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8ff254626a81c30503a9a86e
Content-Type: text/plain; charset=UTF-8

Unfortunately we were somewhat rushed to get things working again and did
not keep the exact stacktraces, but one of the issues we saw was similar to
that reported in

https://issues.apache.org/jira/browse/SPARK-3032

We also saw FAILED_TO_UNCOMPRESS errors from snappy when reading the
shuffle file.



On Mon, Sep 22, 2014 at 10:54 AM, Sandy Ryza <sandy.ryza@cloudera.com>
wrote:

> Thanks for the heads up Cody.  Any indication of what was going wrong?
>
> On Mon, Sep 22, 2014 at 7:16 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
>> Just as a heads up, we deployed 471e6a3a of master (in order to get some
>> sql fixes), and were seeing jobs fail until we set
>>
>> spark.shuffle.manager=HASH
>>
>> I'd be reluctant to change the default to sort for the 1.1.1 release
>>
>
>

--e89a8ff254626a81c30503a9a86e--

From dev-return-9539-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 16:15:58 2014
Return-Path: <dev-return-9539-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B42811201
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 16:15:58 +0000 (UTC)
Received: (qmail 94992 invoked by uid 500); 22 Sep 2014 16:15:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94923 invoked by uid 500); 22 Sep 2014 16:15:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94909 invoked by uid 99); 22 Sep 2014 16:15:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:15:57 +0000
X-ASF-Spam-Status: No, hits=5.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of malouf.gary@gmail.com designates 209.85.216.182 as permitted sender)
Received: from [209.85.216.182] (HELO mail-qc0-f182.google.com) (209.85.216.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:15:53 +0000
Received: by mail-qc0-f182.google.com with SMTP id m20so322386qcx.13
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 09:15:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=S2/ioPP4DQH3lo5imaq9ZtPeegeUeGw1x0cpM3dKRpM=;
        b=IEnN2eYDLju77OlCZyhT+cVc3zBzkI7u5poTlBL6FdU/FWrFLs5uexnIH4d/o8ZjJD
         d+NozHyYKzRT6VYsOnTS5vBNqB4GpTkQRNW7EWPscQA2IAYyrqkF3c/UmzmioFYjebBs
         cqPXpk2WlYlFKIIFXFlCIJ22Y0CY8FCZayHAYeufCcD7J1QF3MI7LREon8vbYCg6eXpl
         pPuvBtnIejq4r0PPpLtlq3lwohpd6VijsUPBJ4DbSJcYQtxMQqudb1oPJ6d5DzHGeOR1
         +wGEE2XRBJzGefE29tIZypkHueHg21XIZXtjmGxxzN+f6TDWtv2Y8i+HOm0uTfO98prJ
         WqsQ==
MIME-Version: 1.0
X-Received: by 10.229.62.129 with SMTP id x1mr31886434qch.16.1411402532765;
 Mon, 22 Sep 2014 09:15:32 -0700 (PDT)
Received: by 10.140.29.102 with HTTP; Mon, 22 Sep 2014 09:15:32 -0700 (PDT)
In-Reply-To: <CAAOnQ7skaF+J-5qPSRDV99wihgaejmxBNWay4z9kbX9hw5=i2Q@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
	<CAAOnQ7skaF+J-5qPSRDV99wihgaejmxBNWay4z9kbX9hw5=i2Q@mail.gmail.com>
Date: Mon, 22 Sep 2014 12:15:32 -0400
Message-ID: <CAGOvqirdSzUf8hwfDHo1MrXBENfqOru5UpUoKFTwq0R+4iRtCw@mail.gmail.com>
Subject: Re: guava version conflicts
From: Gary Malouf <malouf.gary@gmail.com>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: Cody Koeninger <cody@koeninger.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c251de99c4d80503a9c247
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c251de99c4d80503a9c247
Content-Type: text/plain; charset=UTF-8

Hi Marcelo,

Interested to hear the approach to be taken.  Shading guava itself seems
extreme, but that might make sense.

Gary

On Sat, Sep 20, 2014 at 9:38 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Hmm, looks like the hack to maintain backwards compatibility in the
> Java API didn't work that well. I'll take a closer look at this when I
> get to work on Monday.
>
> On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org>
> wrote:
> > After the recent spark project changes to guava shading, I'm seeing
> issues
> > with the datastax spark cassandra connector (which depends on guava 15.0)
> > and the datastax cql driver (which depends on guava 16.0.1)
> >
> > Building an assembly for a job (with spark marked as provided) that
> > includes either guava 15.0 or 16.0.1, results in errors like the
> following:
> >
> > scala> session.close
> >
> > scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
> > failed.
> > java.lang.IllegalAccessError: tried to access class
> > org.spark-project.guava.common.base.Absent from class
> > com.google.common.base.Optional
> >         at com.google.common.base.Optional.absent(Optional.java:79)
> >         at com.google.common.base.Optional.fromNullable(Optional.java:94)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
> >         at
> >
> com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
> >         at
> >
> com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
> >         at
> >
> com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
> >         at
> >
> com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
> >         at
> > com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
> >         at
> > com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
> >         at
> >
> com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
> >         at
> >
> com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
> >         at
> >
> com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
> >         at
> > com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >
> $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
> >         at
> >
> scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
> >         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
> >         at
> > scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
> >         at
> > scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
> >         at scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
> >         at
> >
> scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >
> $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
> >         at
> > java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
> >         at
> >
> java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
> >         at
> java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
> >         at
> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
> >         at
> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
> >         at
> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >         at
> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >         at java.lang.Thread.run(Thread.java:722)
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c251de99c4d80503a9c247--

From dev-return-9540-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 16:57:16 2014
Return-Path: <dev-return-9540-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 452FC113D6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 16:57:16 +0000 (UTC)
Received: (qmail 49600 invoked by uid 500); 22 Sep 2014 16:57:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49538 invoked by uid 500); 22 Sep 2014 16:57:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49522 invoked by uid 99); 22 Sep 2014 16:57:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:57:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of advancedxy@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 16:57:09 +0000
Received: by mail-pa0-f44.google.com with SMTP id eu11so3982853pac.31
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 09:56:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:subject:mime-version:content-type;
        bh=0+UK2emFaehRggAWiR1j+8D2Ub+VB2EBeSpoe/a995A=;
        b=Y4FxT1nd8dXQWucFZ+mUmS4gH9s2TqS08z1pEyoRL3DZGA6ghlmxXAMbwhu/HnzJL1
         SCGqUzfZct7v+CKGlc+My3wZyITrsRDhDpMhPdBnIVeOwDzOLKgbuFxEBqjEP24kWA4R
         Ktiaue4J/44HQsXi5ov1Hhc5C9+DIluyaEClqFTpvN5/K8V5oeCqt1tNKRBGXwzhWkzx
         Ej9265wCHgOE9stoGMhnfDFos+zFpiMCRPqyxmoxogqo2zbYVuHwfqH71qv7quvh2X/i
         WDvdRSSpGCSWaVOJDlO1XF7x8sjt5JKq0QmJ6Qr8zXOoDhAb0kblwSAKY8GVhSs/dCi8
         pWmQ==
X-Received: by 10.70.54.193 with SMTP id l1mr6014105pdp.160.1411405009170;
        Mon, 22 Sep 2014 09:56:49 -0700 (PDT)
Received: from [172.16.100.217] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id y1sm9796801pbt.74.2014.09.22.09.56.47
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Mon, 22 Sep 2014 09:56:48 -0700 (PDT)
Date: Tue, 23 Sep 2014 00:56:43 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
Subject: spark_classpath in core/pom.xml and yarn/porm.xml
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="542054cb_333ab105_29e"
X-Virus-Checked: Checked by ClamAV on apache.org

--542054cb_333ab105_29e
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Hi:
    I notice the scalatest-maven-plugin set SPARK_CLASSPATH environment variable for testing. But in the SparkConf.scala, this is deprecated in Spark 1.0+.
    So what this variable for? should we just remove this variable?
    

-- 
Ye Xianjin
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)


--542054cb_333ab105_29e--


From dev-return-9541-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 17:22:11 2014
Return-Path: <dev-return-9541-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F124A11542
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 17:22:11 +0000 (UTC)
Received: (qmail 46300 invoked by uid 500); 22 Sep 2014 17:22:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46225 invoked by uid 500); 22 Sep 2014 17:22:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46213 invoked by uid 99); 22 Sep 2014 17:22:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 17:22:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 17:21:43 +0000
Received: by mail-ig0-f182.google.com with SMTP id hn15so3122733igb.15
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 10:21:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=N49eyOy0oO+9OvKzgtuEcvHkY7YBNtB8BoFWVki8Kcs=;
        b=cXrB/HU3JS6TdeWHDgoYDTvNAokQU1oDopu3fEXT03pYRUzNZh5G3ADrSFl6slNVUy
         I2NC3Cssx5VflxuKt4CcztSae9iURpXIgcT1erSCfTrS7w6Tx4ucgL+it4Nd/4kF9af9
         RFRUR/JVN2riB+0H2h6TMEKTMLUKUT+q5/sDPdDy8NdB8ty59fV13aRqywqE3eOU04i8
         6MI4FhFcs95w7fAB8cH21g9I+q09/8pUa9xDGL45iYtZpMgNZwYmxENV6PXRohat7iaF
         rO7CeWDYcx7TEDCEYO9Avvlavv3zNDKwoE1u3b1AhCZ7VrUNoXhBsPkv363cAamy+kYK
         Vt3w==
X-Received: by 10.43.68.206 with SMTP id xz14mr17858728icb.33.1411406501923;
        Mon, 22 Sep 2014 10:21:41 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id j4sm9223099igx.20.2014.09.22.10.21.41
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Mon, 22 Sep 2014 10:21:41 -0700 (PDT)
Date: Mon, 22 Sep 2014 13:36:05 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <3B040748EC1A4B788E19D44230A80671@gmail.com>
In-Reply-To: <CACBYxKJUHW0271LPD1g+wsa2mw_7w+5Q4-OtMdXh1EmBnM9PeA@mail.gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
 <etPan.541e5dad.4db127f8.c101@mbp-3.local>
 <94DE5E900B054CF487A51DAA4451291C@gmail.com>
 <etPan.541f52be.ded7263.c101@mbp-3>
 <C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
 <CACBYxKJUHW0271LPD1g+wsa2mw_7w+5Q4-OtMdXh1EmBnM9PeA@mail.gmail.com>
Subject: Re: A couple questions about shared variables
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54205e05_97e1b4e_1f0"
X-Virus-Checked: Checked by ClamAV on apache.org

--54205e05_97e1b4e_1f0
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I see, thanks for pointing this out =20


-- =20
Nan Zhu


On Monday, September 22, 2014 at 12:08 PM, Sandy Ryza wrote:

> MapReduce counters do not count duplications.  In MapReduce, if a task =
needs to be re-run, the value of the counter from the second task overwri=
tes the value from the first task.
> =20
> -Sandy
> =20
> On Mon, Sep 22, 2014 at 4:55 AM, Nan Zhu <zhunanmcgill=40gmail.com (mai=
lto:zhunanmcgill=40gmail.com)> wrote:
> > If you think it as necessary to fix, I would like to resubmit that PR=
 (seems to have some conflicts with the current DAGScheduler) =20
> > =20
> > My suggestion is to make it as an option in accumulator, e.g. some al=
gorithms utilizing accumulator for result calculation, it needs a determi=
nistic accumulator, while others implementing something like Hadoop count=
ers may need the current implementation (count everything happened, inclu=
ding the duplications)
> > =20
> > Your thoughts=3F =20
> > =20
> > -- =20
> > Nan Zhu
> > =20
> > =20
> > On Sunday, September 21, 2014 at 6:35 PM, Matei Zaharia wrote:
> > =20
> > > Hmm, good point, this seems to have been broken by refactorings of =
the scheduler, but it worked in the past. Basically the solution is simpl=
e -- in a result stage, we should not apply the update for each task ID m=
ore than once -- the same way we don't call job.listener.taskSucceeded mo=
re than once. Your PR also tried to avoid this for resubmitted shuffle st=
ages, but I don't think we need to do that necessarily (though we could).=

> > > =20
> > > Matei =20
> > > =20
> > > On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill=40gmail.=
com (mailto:zhunanmcgill=40gmail.com)) wrote:
> > > =20
> > > > Hi, Matei, =20
> > > > =20
> > > > Can you give some hint on how the current implementation guarante=
e the accumulator is only applied for once=3F =20
> > > > =20
> > > > There is a pending PR trying to achieving this (https://github.co=
m/apache/spark/pull/228/files), but from the current implementation, I di=
dn=E2=80=99t see this has been done=3F (maybe I missed something) =20
> > > > =20
> > > > Best, =20
> > > > =20
> > > > --  =20
> > > > Nan Zhu
> > > > =20
> > > > =20
> > > > On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:
> > > > =20
> > > > > Hey Sandy,
> > > > > =20
> > > > > On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=40c=
loudera.com (mailto:sandy.ryza=40cloudera.com)) wrote: =20
> > > > > =20
> > > > > Hey All,  =20
> > > > > =20
> > > > > A couple questions came up about shared variables recently, and=
 I wanted to  =20
> > > > > confirm my understanding and update the doc to be a little more=
 clear. =20
> > > > > =20
> > > > > *Broadcast variables*  =20
> > > > > Now that tasks data is automatically broadcast, the only occasi=
ons where it =20
> > > > > makes sense to explicitly broadcast are: =20
> > > > > * You want to use a variable from tasks in multiple stages. =20
> > > > > * You want to have the variable stored on the executors in dese=
rialized =20
> > > > > form. =20
> > > > > * You want tasks to be able to modify the variable and have tho=
se =20
> > > > > modifications take effect for other tasks running on the same e=
xecutor =20
> > > > > (usually a very bad idea). =20
> > > > > =20
> > > > > Is that right=3F  =20
> > > > > Yeah, pretty much. Reason 1 above is probably the biggest, but =
2 also matters. (We might later factor tasks in a different way to avoid =
2, but it's hard due to things like Hadoop JobConf objects in the tasks).=

> > > > > =20
> > > > > =20
> > > > > *Accumulators*  =20
> > > > > Values are only counted for successful tasks. Is that right=3F =
KMeans seems =20
> > > > > to use it in this way. What happens if a node goes away and suc=
cessful =20
> > > > > tasks need to be resubmitted=3F Or the stage runs again because=
 a different =20
> > > > > job needed it. =20
> > > > > Accumulators are guaranteed to give a deterministic result if y=
ou only increment them in actions. =46or each result stage, the accumulat=
or's update from each task is only applied once, even if that task runs m=
ultiple times. If you use accumulators in transformations (i.e. in a stag=
e that may be part of multiple jobs), then you may see multiple updates, =
from each run. This is kind of confusing but it was useful for people who=
 wanted to use these for debugging.
> > > > > =20
> > > > > Matei =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > > thanks,  =20
> > > > > Sandy =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > > =20
> > =20
> =20


--54205e05_97e1b4e_1f0--


From dev-return-9542-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 18:43:21 2014
Return-Path: <dev-return-9542-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 963A311A1D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 18:43:21 +0000 (UTC)
Received: (qmail 17932 invoked by uid 500); 22 Sep 2014 18:43:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17861 invoked by uid 500); 22 Sep 2014 18:43:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17850 invoked by uid 99); 22 Sep 2014 18:43:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 18:43:20 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.54 as permitted sender)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 18:43:16 +0000
Received: by mail-qa0-f54.google.com with SMTP id n8so551036qaq.27
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 11:42:55 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=/QrYlRVdPC1xY0WXzyxIln66Ke1SJmf6lZlGMRbw4Y4=;
        b=i47pgTggePiDOLoFgqz0rQ9IZknykVd3ubecp+S1wDVoigaNLvB9x3usbWK06r68Pd
         0eYGMwiAf2mA5pmAof/4OrX7Yh+Y20pHOyOAjiRtXLrWL+W4jhHHWhgDweGujj6XYDVi
         aIpKcvLOoliMqQ9UNLlSUM1TLjd0YjQXIion9gAbsPt5aeiOpuOckNRosAFhRIJPzJa7
         R60iQzqk2jDzGVGr968MgBNi6VgkBjeNjcnml0YmcGO3xP2A0Y7slPpaIoDrsPfH8BFd
         fXmxhwjTbRaZ+R24r4gC1BNyNJijMshe1L9KUEhdFWzW/uYKoW+Q4fzRZJpRwdyTv0jT
         wbEA==
X-Gm-Message-State: ALoCoQll5IihrkuzdrizdfhnnO9TBiW+J6zYSuaEENEADdRgO2q4VAKalrCSeIVNYFqO0yVSPX8U
MIME-Version: 1.0
X-Received: by 10.140.42.246 with SMTP id c109mr25697274qga.9.1411411375463;
 Mon, 22 Sep 2014 11:42:55 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Mon, 22 Sep 2014 11:42:55 -0700 (PDT)
In-Reply-To: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
Date: Mon, 22 Sep 2014 11:42:55 -0700
Message-ID: <CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
Subject: Re: guava version conflicts
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Cody,

I'm still writing a test to make sure I understood exactly what's
going on here, but from looking at the stack trace, it seems like the
newer Guava library is picking up the "Optional" class from the Spark
assembly.

Could you try one of the options that put the user's classpath before
the Spark assembly? (spark.files.userClassPathFirst or
spark.yarn.user.classpath.first depending on which master you're
running)

People seem to have run into issues with those options in the past,
but if they work for you, then Guava should pick its own Optional
class (instead of the one shipped with Spark) and things should then
work.

I'll investigate a way to fix it in Spark in the meantime.


On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org> wrote:
> After the recent spark project changes to guava shading, I'm seeing issues
> with the datastax spark cassandra connector (which depends on guava 15.0)
> and the datastax cql driver (which depends on guava 16.0.1)
>
> Building an assembly for a job (with spark marked as provided) that
> includes either guava 15.0 or 16.0.1, results in errors like the following:
>
> scala> session.close
>
> scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
> failed.
> java.lang.IllegalAccessError: tried to access class
> org.spark-project.guava.common.base.Absent from class
> com.google.common.base.Optional
>         at com.google.common.base.Optional.absent(Optional.java:79)
>         at com.google.common.base.Optional.fromNullable(Optional.java:94)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
>         at
> com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
>         at
> com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
>         at
> com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
>         at
> com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
>         at
> com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
>         at
> com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
>         at
> com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
>         at
> com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
>         at
> com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
>         at
> com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
>         at
> com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>         at
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>         at com.datastax.spark.connector.cql.RefCountedCache.com
> $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
>         at
> scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
>         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
>         at
> scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
>         at
> scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
>         at scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
>         at
> scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
>         at com.datastax.spark.connector.cql.RefCountedCache.com
> $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
>         at
> com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
>         at
> java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
>         at
> java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
>         at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
>         at
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
>         at
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
>         at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>         at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>         at java.lang.Thread.run(Thread.java:722)



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9543-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 18:56:31 2014
Return-Path: <dev-return-9543-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EA90F11B0C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 18:56:30 +0000 (UTC)
Received: (qmail 67944 invoked by uid 500); 22 Sep 2014 18:56:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67870 invoked by uid 500); 22 Sep 2014 18:56:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67859 invoked by uid 99); 22 Sep 2014 18:56:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 18:56:29 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 18:56:25 +0000
Received: by mail-la0-f46.google.com with SMTP id q1so6878670lam.33
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 11:56:03 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=BJfu6nspxk3RMkvbDVGOw41HzgQy8RtXfSVhF8SCca8=;
        b=Vzkf1jhCUKlpQ0jIuXllXje47vfWb985YfrPPdxmMfjax5Kjek49UnrtjQEq8SfAlh
         GkAg9jaZfTEKruWf7tuHQiKA7QlDxTOUSJU5odTooAc7r3DDP1CWQd3/2/jqw360JP0E
         TilI7kVQ/ZrUif7lYoKagZzLutq42xWFXXNr8FS2Gwq20LGtA3dkJNP7/sWnMu4WScBg
         g5qDrflJ8YsyuJMtYnYigqpl/KzH4ydLzbnpZyu1SGm6pg71QU095L8WIR690dUDwOVz
         WL5CUfMQU7l+z04ba/TAvTSomCKwpI5fuC4y7vdZAZnarQ14fAS62Y2u0d631w7FlZBW
         pHDA==
X-Gm-Message-State: ALoCoQmPqDBoiDFNTkL7aaVwZhBFvZZKyMMx7aOSmG597glOM3ZCOF+yqqycTNvfMXcH3nVkFhiz
X-Received: by 10.152.7.193 with SMTP id l1mr25446130laa.62.1411412163459;
 Mon, 22 Sep 2014 11:56:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.66 with HTTP; Mon, 22 Sep 2014 11:55:43 -0700 (PDT)
In-Reply-To: <CAKWX9VV4R73ae239ZEFtLR1WXPOCAKwXaEEUeZT8fz3GrhiC0A@mail.gmail.com>
References: <CAKWX9VV4R73ae239ZEFtLR1WXPOCAKwXaEEUeZT8fz3GrhiC0A@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Mon, 22 Sep 2014 11:55:43 -0700
Message-ID: <CAAswR-7qPemUBGJd1CNCd_8sR0hGaxnLsnvtMd_tbbq5pwkPmA@mail.gmail.com>
Subject: Re: Support for Hive buckets
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c23dbca28b410503ac0069
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c23dbca28b410503ac0069
Content-Type: text/plain; charset=UTF-8

Hi Cody,

There are currently no concrete plans for adding buckets to Spark SQL, but
thats mostly due to lack of resources / demand for this feature.  Adding
full support is probably a fair amount of work since you'd have to make
changes throughout parsing/optimization/execution.  That said, there are
probably some smaller tasks that could be easier (for example, you might be
able to avoid a shuffle when doing joins on tables that are already
bucketed by exposing more metastore information to the planner).

Michael

On Sun, Sep 14, 2014 at 3:10 PM, Cody Koeninger <cody@koeninger.org> wrote:

> I noticed that the release notes for 1.1.0 said that spark doesn't support
> Hive buckets "yet".  I didn't notice any jira issues related to adding
> support.
>
> Broadly speaking, what would be involved in supporting buckets, especially
> the bucketmapjoin and sortedmerge optimizations?
>

--001a11c23dbca28b410503ac0069--

From dev-return-9544-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 19:46:35 2014
Return-Path: <dev-return-9544-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7251911D41
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 19:46:35 +0000 (UTC)
Received: (qmail 26677 invoked by uid 500); 22 Sep 2014 19:46:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26609 invoked by uid 500); 22 Sep 2014 19:46:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26597 invoked by uid 99); 22 Sep 2014 19:46:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 19:46:34 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 19:46:09 +0000
Received: by mail-ob0-f181.google.com with SMTP id wo20so4319081obc.12
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 12:46:07 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=t58J9jgvl1+g8J1OHppjXFXLjdhczMZ35Serv8qBApw=;
        b=XZaQQ9R/qLCrrRIWDmH1gn2ISKRbaiJBeCINhxrcxgOb4Vc+kNXybd38wTqESVtzc8
         1JJzTZYSSlGYjdyUujEddHT5SEGRDE2AsVBrQlCWcxEWUsdw7p5+2/8YpUUvhjUnHkTr
         S9r3fmmjQhsC4nY+SWR8edbk4anNhlku9+VN+ZpCcTvWrPsEHHVtc3ON9XlHshJA4dEh
         tfgUpiSf97JvekzmBmrkDhJLfDeoUhg/egtuYz7jh9D4A/81VFwyhKYtn71dNfu+jX5o
         kz8tVIgA1JwpYtGEOq/mNf3A1E5jVgvqN+BCOr+W+Ke4GID4CRpA+LkGfWNqsLU9/Kqv
         Id3A==
X-Gm-Message-State: ALoCoQlJArB+y8gbQW4XH/7tSzYUnOQy4KWCi/mocz0/n8cdC4Iap4aF6fQsystESpYpeAYWv3gw
MIME-Version: 1.0
X-Received: by 10.182.181.3 with SMTP id ds3mr28738532obc.11.1411415167477;
 Mon, 22 Sep 2014 12:46:07 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 22 Sep 2014 12:46:07 -0700 (PDT)
In-Reply-To: <CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
	<CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
Date: Mon, 22 Sep 2014 14:46:07 -0500
Message-ID: <CAKWX9VWQ-KEWOwCj4F5duzU+OP8qN3DkomzOz1tbrHhR-VcTdA@mail.gmail.com>
Subject: Re: guava version conflicts
From: Cody Koeninger <cody@koeninger.org>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01182856b043d20503acb300
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01182856b043d20503acb300
Content-Type: text/plain; charset=UTF-8

We're using Mesos, is there a reasonable expectation that
spark.files.userClassPathFirst will actually work?

On Mon, Sep 22, 2014 at 1:42 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Hi Cody,
>
> I'm still writing a test to make sure I understood exactly what's
> going on here, but from looking at the stack trace, it seems like the
> newer Guava library is picking up the "Optional" class from the Spark
> assembly.
>
> Could you try one of the options that put the user's classpath before
> the Spark assembly? (spark.files.userClassPathFirst or
> spark.yarn.user.classpath.first depending on which master you're
> running)
>
> People seem to have run into issues with those options in the past,
> but if they work for you, then Guava should pick its own Optional
> class (instead of the one shipped with Spark) and things should then
> work.
>
> I'll investigate a way to fix it in Spark in the meantime.
>
>
> On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org>
> wrote:
> > After the recent spark project changes to guava shading, I'm seeing
> issues
> > with the datastax spark cassandra connector (which depends on guava 15.0)
> > and the datastax cql driver (which depends on guava 16.0.1)
> >
> > Building an assembly for a job (with spark marked as provided) that
> > includes either guava 15.0 or 16.0.1, results in errors like the
> following:
> >
> > scala> session.close
> >
> > scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
> > failed.
> > java.lang.IllegalAccessError: tried to access class
> > org.spark-project.guava.common.base.Absent from class
> > com.google.common.base.Optional
> >         at com.google.common.base.Optional.absent(Optional.java:79)
> >         at com.google.common.base.Optional.fromNullable(Optional.java:94)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
> >         at
> >
> com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
> >         at
> >
> com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
> >         at
> >
> com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
> >         at
> >
> com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
> >         at
> >
> com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
> >         at
> > com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
> >         at
> > com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
> >         at
> >
> com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
> >         at
> >
> com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
> >         at
> >
> com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
> >         at
> > com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >         at
> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >
> $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
> >         at
> >
> scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
> >         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
> >         at
> > scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
> >         at
> > scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
> >         at scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
> >         at
> >
> scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >
> $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
> >         at
> >
> com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
> >         at
> > java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
> >         at
> >
> java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
> >         at
> java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
> >         at
> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
> >         at
> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
> >         at
> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >         at
> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >         at java.lang.Thread.run(Thread.java:722)
>
>
>
> --
> Marcelo
>

--089e01182856b043d20503acb300--

From dev-return-9545-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 20:13:58 2014
Return-Path: <dev-return-9545-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0DB0011E62
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 20:13:58 +0000 (UTC)
Received: (qmail 98823 invoked by uid 500); 22 Sep 2014 20:13:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98751 invoked by uid 500); 22 Sep 2014 20:13:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98739 invoked by uid 99); 22 Sep 2014 20:13:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 20:13:56 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.180 as permitted sender)
Received: from [209.85.216.180] (HELO mail-qc0-f180.google.com) (209.85.216.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 20:13:31 +0000
Received: by mail-qc0-f180.google.com with SMTP id l6so307246qcy.39
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 13:13:30 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=DAG2LeIuzq7/jvaObc+/y4UaA48/SgcPbnx/9A67ldg=;
        b=CQbK8cXyy9sq0xUf5E62hyZ+Nxek3g34R4xuSKdgGZGRTO4DKHqzimlWpoQkLSGPwo
         6pcEXOpxz4Tt9s0edmIfexUxUAbXyV5Z5pVpa+O/jI3uBfT/td8Di/ebQtunkBOYq9Dk
         UCtajV1SE99v/JOzBDYLOddnS3GsmdJglbjvPTnBGgJyRypOb8/bx88BM7d7KSy60kZD
         KVfngHvn1gTuq3A+LOhY9A3oZLdBOjrr7iRn7gJBB7tnzqLcsEPyrWXIlmv7/CIB6f8b
         BFAi4lFjg3U2ZkzEndJKFvqCWlYsJrqr2hlKZ7upYz5OcpZ/rEzOvBETbaXJal0hELS4
         OoAw==
X-Gm-Message-State: ALoCoQmUNg5ubAnbEsKonG9JRG1jjcI3onNPuBG+tTttkl1SolDgeTcjqIomdyYliY18ka9o5SC3
MIME-Version: 1.0
X-Received: by 10.140.102.149 with SMTP id w21mr7176270qge.29.1411416810132;
 Mon, 22 Sep 2014 13:13:30 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Mon, 22 Sep 2014 13:13:30 -0700 (PDT)
In-Reply-To: <CAKWX9VWQ-KEWOwCj4F5duzU+OP8qN3DkomzOz1tbrHhR-VcTdA@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
	<CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
	<CAKWX9VWQ-KEWOwCj4F5duzU+OP8qN3DkomzOz1tbrHhR-VcTdA@mail.gmail.com>
Date: Mon, 22 Sep 2014 13:13:30 -0700
Message-ID: <CAAOnQ7vD1QDsRJgCwRNRYgdbUo9EERtA-dRBWR--EQHcrgADow@mail.gmail.com>
Subject: Re: guava version conflicts
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hmmm, a quick look at the code indicates this should work for
executors, but not for the driver... (maybe this deserves a bug being
filed, if there isn't one already?)

If it's feasible for you, you could remove the Optional.class file
from the Spark assembly you're using.

On Mon, Sep 22, 2014 at 12:46 PM, Cody Koeninger <cody@koeninger.org> wrote:
> We're using Mesos, is there a reasonable expectation that
> spark.files.userClassPathFirst will actually work?
>
> On Mon, Sep 22, 2014 at 1:42 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
>>
>> Hi Cody,
>>
>> I'm still writing a test to make sure I understood exactly what's
>> going on here, but from looking at the stack trace, it seems like the
>> newer Guava library is picking up the "Optional" class from the Spark
>> assembly.
>>
>> Could you try one of the options that put the user's classpath before
>> the Spark assembly? (spark.files.userClassPathFirst or
>> spark.yarn.user.classpath.first depending on which master you're
>> running)
>>
>> People seem to have run into issues with those options in the past,
>> but if they work for you, then Guava should pick its own Optional
>> class (instead of the one shipped with Spark) and things should then
>> work.
>>
>> I'll investigate a way to fix it in Spark in the meantime.
>>
>>
>> On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>> > After the recent spark project changes to guava shading, I'm seeing
>> > issues
>> > with the datastax spark cassandra connector (which depends on guava
>> > 15.0)
>> > and the datastax cql driver (which depends on guava 16.0.1)
>> >
>> > Building an assembly for a job (with spark marked as provided) that
>> > includes either guava 15.0 or 16.0.1, results in errors like the
>> > following:
>> >
>> > scala> session.close
>> >
>> > scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
>> > failed.
>> > java.lang.IllegalAccessError: tried to access class
>> > org.spark-project.guava.common.base.Absent from class
>> > com.google.common.base.Optional
>> >         at com.google.common.base.Optional.absent(Optional.java:79)
>> >         at
>> > com.google.common.base.Optional.fromNullable(Optional.java:94)
>> >         at
>> >
>> > com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
>> >         at
>> >
>> > com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
>> >         at
>> >
>> > com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
>> >         at
>> >
>> > com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
>> >         at
>> >
>> > com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
>> >         at
>> >
>> > com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
>> >         at
>> >
>> > com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
>> >         at
>> >
>> > com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
>> >         at
>> >
>> > com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
>> >         at
>> > com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
>> >         at
>> > com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
>> >         at
>> >
>> > com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
>> >         at
>> >
>> > com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
>> >         at
>> >
>> > com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
>> >         at
>> > com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>> >         at com.datastax.spark.connector.cql.RefCountedCache.com
>> >
>> > $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
>> >         at
>> >
>> > scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
>> >         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
>> >         at
>> > scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
>> >         at
>> > scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
>> >         at
>> > scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
>> >         at
>> >
>> > scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
>> >         at com.datastax.spark.connector.cql.RefCountedCache.com
>> >
>> > $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
>> >         at
>> >
>> > com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
>> >         at
>> > java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
>> >         at
>> >
>> > java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
>> >         at
>> > java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
>> >         at
>> >
>> > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
>> >         at
>> >
>> > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
>> >         at
>> >
>> > java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>> >         at
>> >
>> > java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>> >         at java.lang.Thread.run(Thread.java:722)
>>
>>
>>
>> --
>> Marcelo
>
>



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9546-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 20:28:35 2014
Return-Path: <dev-return-9546-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF0A611F16
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 20:28:35 +0000 (UTC)
Received: (qmail 48406 invoked by uid 500); 22 Sep 2014 20:28:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48338 invoked by uid 500); 22 Sep 2014 20:28:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48323 invoked by uid 99); 22 Sep 2014 20:28:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 20:28:34 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.219.52] (HELO mail-oa0-f52.google.com) (209.85.219.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 20:28:09 +0000
Received: by mail-oa0-f52.google.com with SMTP id o6so2041670oag.25
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 13:28:07 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=b2S4ID8N/EPyFrhiS0l69mitlrpVw4ZWUOpCLrFzDyM=;
        b=lyALdOLFd+3XXkngORV2zSk110p5Gxiy0hgQVhp82yyQ0mlxXCZ6DehK04fKW3y25g
         uIC1TWH4/6Q9+E1mEVthnO10KoCSF1mQtdc63/bLz/3SxCeiXR4gnTPdbasdDj/CQno5
         zDb9Cy/8U3XigPyuhvrWUDt7MkIrFrSudzSuxC+oBEpR3qPcKfj7AB1QItR9NHp/VuaD
         qQ2hMWEqs5gF9R3nOCgKa2f1YDDoqNzAbQqJFG7Ld1A9YZBIYkIX4m8KqVHzk3+E15cw
         Rt+dXrkMl0tHmPeyzh9/A/LCsUlNOpqJrt3ovRcQqR8uWMGNmyNxVke9+VukgTwmZvGK
         JWzw==
X-Gm-Message-State: ALoCoQn79JJ1fSYQF8s2c3JbDSYhP2W/+AioXYQYV4ldxPblWvZ+sGnnqLbTBx0HtZu5J9TUYfe/
MIME-Version: 1.0
X-Received: by 10.182.24.101 with SMTP id t5mr28714448obf.31.1411417687422;
 Mon, 22 Sep 2014 13:28:07 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 22 Sep 2014 13:28:07 -0700 (PDT)
In-Reply-To: <CAAOnQ7vD1QDsRJgCwRNRYgdbUo9EERtA-dRBWR--EQHcrgADow@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
	<CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
	<CAKWX9VWQ-KEWOwCj4F5duzU+OP8qN3DkomzOz1tbrHhR-VcTdA@mail.gmail.com>
	<CAAOnQ7vD1QDsRJgCwRNRYgdbUo9EERtA-dRBWR--EQHcrgADow@mail.gmail.com>
Date: Mon, 22 Sep 2014 15:28:07 -0500
Message-ID: <CAKWX9VVB2bJQKBnAXYGRx-75TDV+bHojF=9E1AbD_hMcipS7Mg@mail.gmail.com>
Subject: Re: guava version conflicts
From: Cody Koeninger <cody@koeninger.org>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2a1d4e393f10503ad49a6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2a1d4e393f10503ad49a6
Content-Type: text/plain; charset=UTF-8

We've worked around it for the meantime by excluding guava from transitive
dependencies in the job assembly and specifying the same version of guava
14 that spark is using.  Obviously things break whenever a guava 15 / 16
feature is used at runtime, so a long term solution is needed.

On Mon, Sep 22, 2014 at 3:13 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Hmmm, a quick look at the code indicates this should work for
> executors, but not for the driver... (maybe this deserves a bug being
> filed, if there isn't one already?)
>
> If it's feasible for you, you could remove the Optional.class file
> from the Spark assembly you're using.
>
> On Mon, Sep 22, 2014 at 12:46 PM, Cody Koeninger <cody@koeninger.org>
> wrote:
> > We're using Mesos, is there a reasonable expectation that
> > spark.files.userClassPathFirst will actually work?
> >
> > On Mon, Sep 22, 2014 at 1:42 PM, Marcelo Vanzin <vanzin@cloudera.com>
> wrote:
> >>
> >> Hi Cody,
> >>
> >> I'm still writing a test to make sure I understood exactly what's
> >> going on here, but from looking at the stack trace, it seems like the
> >> newer Guava library is picking up the "Optional" class from the Spark
> >> assembly.
> >>
> >> Could you try one of the options that put the user's classpath before
> >> the Spark assembly? (spark.files.userClassPathFirst or
> >> spark.yarn.user.classpath.first depending on which master you're
> >> running)
> >>
> >> People seem to have run into issues with those options in the past,
> >> but if they work for you, then Guava should pick its own Optional
> >> class (instead of the one shipped with Spark) and things should then
> >> work.
> >>
> >> I'll investigate a way to fix it in Spark in the meantime.
> >>
> >>
> >> On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org>
> >> wrote:
> >> > After the recent spark project changes to guava shading, I'm seeing
> >> > issues
> >> > with the datastax spark cassandra connector (which depends on guava
> >> > 15.0)
> >> > and the datastax cql driver (which depends on guava 16.0.1)
> >> >
> >> > Building an assembly for a job (with spark marked as provided) that
> >> > includes either guava 15.0 or 16.0.1, results in errors like the
> >> > following:
> >> >
> >> > scala> session.close
> >> >
> >> > scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
> >> > failed.
> >> > java.lang.IllegalAccessError: tried to access class
> >> > org.spark-project.guava.common.base.Absent from class
> >> > com.google.common.base.Optional
> >> >         at com.google.common.base.Optional.absent(Optional.java:79)
> >> >         at
> >> > com.google.common.base.Optional.fromNullable(Optional.java:94)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
> >> >         at
> >> >
> >> >
> com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
> >> >         at
> >> >
> com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
> >> >         at
> >> > com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
> >> >         at
> >> >
> >> >
> com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
> >> >         at
> >> >
> >> >
> com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
> >> >         at
> >> >
> >> >
> com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
> >> >         at
> >> > com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
> >> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >> >
> >> >
> $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
> >> >         at
> >> >
> >> >
> scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
> >> >         at scala.collection.Iterator$class.foreach(Iterator.scala:727)
> >> >         at
> >> > scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
> >> >         at
> >> > scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
> >> >         at
> >> > scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
> >> >         at
> >> >
> >> >
> scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
> >> >         at com.datastax.spark.connector.cql.RefCountedCache.com
> >> >
> >> >
> $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
> >> >         at
> >> >
> >> >
> com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
> >> >         at
> >> >
> java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
> >> >         at
> >> >
> >> >
> java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
> >> >         at
> >> > java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
> >> >         at
> >> >
> >> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
> >> >         at
> >> >
> >> >
> java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
> >> >         at
> >> >
> >> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >> >         at
> >> >
> >> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >> >         at java.lang.Thread.run(Thread.java:722)
> >>
> >>
> >>
> >> --
> >> Marcelo
> >
> >
>
>
>
> --
> Marcelo
>

--001a11c2a1d4e393f10503ad49a6--

From dev-return-9547-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 21:10:54 2014
Return-Path: <dev-return-9547-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25EAB11232
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 21:10:54 +0000 (UTC)
Received: (qmail 7052 invoked by uid 500); 22 Sep 2014 21:10:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6983 invoked by uid 500); 22 Sep 2014 21:10:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6971 invoked by uid 99); 22 Sep 2014 21:10:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 21:10:53 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.179 as permitted sender)
Received: from [209.85.216.179] (HELO mail-qc0-f179.google.com) (209.85.216.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 21:10:49 +0000
Received: by mail-qc0-f179.google.com with SMTP id l6so462310qcy.10
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 14:10:28 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=553f/f1iEodwXSVhEcrwFlCTyfDodH+p7JTDSuqxjso=;
        b=TB40MU7DMSLcgRee7igsEOz1IZSgVGj9wAh9yykc0WpnXeAo9f1Wb6sthQaPrhigXu
         4EhEGcsAZa9EOfzPs+ohde/vhSx6e36z3nbweRhDbZ3ck7iEVSvo+9IH604+bp4oFZB3
         Rai4ye62jvPAFJQsgEWYYgkZKgylgy+496trolukBqKNFkKye+WmHMHf8UR8T5YYF4ka
         H1YljJ0YP6NerH1OwxkVx4oOjp9omJqCbuqONNiY34Q/QG6/CQiNxVI4zc7i017Bhg+p
         mx5z7TJdS9WJB/na6gI3a8vr5w5pBrhGQ4usnG7CV1PKx+kH0ST2W3ZprjRyp6titOMt
         1d4g==
X-Gm-Message-State: ALoCoQnAH1129Z7/jP6E7LiVA0KGsbf7H5Mg9Q1jt8JQt4A8CFPG9DeiyDUTS3/IGpfzzvFF+aml
MIME-Version: 1.0
X-Received: by 10.140.102.149 with SMTP id w21mr7388036qge.29.1411420228559;
 Mon, 22 Sep 2014 14:10:28 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Mon, 22 Sep 2014 14:10:28 -0700 (PDT)
In-Reply-To: <CAKWX9VVB2bJQKBnAXYGRx-75TDV+bHojF=9E1AbD_hMcipS7Mg@mail.gmail.com>
References: <CAKWX9VUn23Bg6ZQXY1p-WALnqw8OUxE-7jRVJ7+KOpdV25mfbA@mail.gmail.com>
	<CAAOnQ7sNaF2J9aVKR2M10ok+i4eWpOh4G0zDanRRLVkL_8YFVQ@mail.gmail.com>
	<CAKWX9VWQ-KEWOwCj4F5duzU+OP8qN3DkomzOz1tbrHhR-VcTdA@mail.gmail.com>
	<CAAOnQ7vD1QDsRJgCwRNRYgdbUo9EERtA-dRBWR--EQHcrgADow@mail.gmail.com>
	<CAKWX9VVB2bJQKBnAXYGRx-75TDV+bHojF=9E1AbD_hMcipS7Mg@mail.gmail.com>
Date: Mon, 22 Sep 2014 14:10:28 -0700
Message-ID: <CAAOnQ7t_dSeM4eu_ziJOPnYHTR8gt_bh+6CuV3eOb9HmGdHJxg@mail.gmail.com>
Subject: Re: guava version conflicts
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

FYI I filed SPARK-3647 to track the fix (some people internally have
bumped into this also).

On Mon, Sep 22, 2014 at 1:28 PM, Cody Koeninger <cody@koeninger.org> wrote:
> We've worked around it for the meantime by excluding guava from transitive
> dependencies in the job assembly and specifying the same version of guava 14
> that spark is using.  Obviously things break whenever a guava 15 / 16
> feature is used at runtime, so a long term solution is needed.
>
> On Mon, Sep 22, 2014 at 3:13 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
>>
>> Hmmm, a quick look at the code indicates this should work for
>> executors, but not for the driver... (maybe this deserves a bug being
>> filed, if there isn't one already?)
>>
>> If it's feasible for you, you could remove the Optional.class file
>> from the Spark assembly you're using.
>>
>> On Mon, Sep 22, 2014 at 12:46 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>> > We're using Mesos, is there a reasonable expectation that
>> > spark.files.userClassPathFirst will actually work?
>> >
>> > On Mon, Sep 22, 2014 at 1:42 PM, Marcelo Vanzin <vanzin@cloudera.com>
>> > wrote:
>> >>
>> >> Hi Cody,
>> >>
>> >> I'm still writing a test to make sure I understood exactly what's
>> >> going on here, but from looking at the stack trace, it seems like the
>> >> newer Guava library is picking up the "Optional" class from the Spark
>> >> assembly.
>> >>
>> >> Could you try one of the options that put the user's classpath before
>> >> the Spark assembly? (spark.files.userClassPathFirst or
>> >> spark.yarn.user.classpath.first depending on which master you're
>> >> running)
>> >>
>> >> People seem to have run into issues with those options in the past,
>> >> but if they work for you, then Guava should pick its own Optional
>> >> class (instead of the one shipped with Spark) and things should then
>> >> work.
>> >>
>> >> I'll investigate a way to fix it in Spark in the meantime.
>> >>
>> >>
>> >> On Fri, Sep 19, 2014 at 10:30 PM, Cody Koeninger <cody@koeninger.org>
>> >> wrote:
>> >> > After the recent spark project changes to guava shading, I'm seeing
>> >> > issues
>> >> > with the datastax spark cassandra connector (which depends on guava
>> >> > 15.0)
>> >> > and the datastax cql driver (which depends on guava 16.0.1)
>> >> >
>> >> > Building an assembly for a job (with spark marked as provided) that
>> >> > includes either guava 15.0 or 16.0.1, results in errors like the
>> >> > following:
>> >> >
>> >> > scala> session.close
>> >> >
>> >> > scala> s[14/09/20 04:56:35 ERROR Futures$CombinedFuture: input future
>> >> > failed.
>> >> > java.lang.IllegalAccessError: tried to access class
>> >> > org.spark-project.guava.common.base.Absent from class
>> >> > com.google.common.base.Optional
>> >> >         at com.google.common.base.Optional.absent(Optional.java:79)
>> >> >         at
>> >> > com.google.common.base.Optional.fromNullable(Optional.java:94)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.Futures$CombinedFuture.setOneValue(Futures.java:1608)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.Futures$CombinedFuture.access$400(Futures.java:1470)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.Futures$CombinedFuture$2.run(Futures.java:1548)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.ExecutionList.add(ExecutionList.java:101)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:170)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.Futures$CombinedFuture.init(Futures.java:1545)
>> >> >         at
>> >> >
>> >> >
>> >> > com.google.common.util.concurrent.Futures$CombinedFuture.<init>(Futures.java:1491)
>> >> >         at
>> >> >
>> >> > com.google.common.util.concurrent.Futures.listFuture(Futures.java:1640)
>> >> >         at
>> >> > com.google.common.util.concurrent.Futures.allAsList(Futures.java:983)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.driver.core.CloseFuture$Forwarding.<init>(CloseFuture.java:73)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.driver.core.HostConnectionPool.closeAsync(HostConnectionPool.java:398)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.driver.core.SessionManager.closeAsync(SessionManager.java:157)
>> >> >         at
>> >> >
>> >> > com.datastax.driver.core.SessionManager.close(SessionManager.java:172)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$destroySession(CassandraConnector.scala:180)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.CassandraConnector$$anonfun$5.apply(CassandraConnector.scala:151)
>> >> >         at com.datastax.spark.connector.cql.RefCountedCache.com
>> >> >
>> >> >
>> >> > $datastax$spark$connector$cql$RefCountedCache$$releaseImmediately(RefCountedCache.scala:86)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.RefCountedCache$ReleaseTask.run(RefCountedCache.scala:26)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:150)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.RefCountedCache$$anonfun$com$datastax$spark$connector$cql$RefCountedCache$$processPendingReleases$2.apply(RefCountedCache.scala:147)
>> >> >         at
>> >> >
>> >> >
>> >> > scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
>> >> >         at
>> >> > scala.collection.Iterator$class.foreach(Iterator.scala:727)
>> >> >         at
>> >> >
>> >> > scala.collection.concurrent.TrieMapIterator.foreach(TrieMap.scala:922)
>> >> >         at
>> >> > scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
>> >> >         at
>> >> > scala.collection.concurrent.TrieMap.foreach(TrieMap.scala:632)
>> >> >         at
>> >> >
>> >> >
>> >> > scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
>> >> >         at com.datastax.spark.connector.cql.RefCountedCache.com
>> >> >
>> >> >
>> >> > $datastax$spark$connector$cql$RefCountedCache$$processPendingReleases(RefCountedCache.scala:147)
>> >> >         at
>> >> >
>> >> >
>> >> > com.datastax.spark.connector.cql.RefCountedCache$$anon$1.run(RefCountedCache.scala:157)
>> >> >         at
>> >> >
>> >> > java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
>> >> >         at
>> >> >
>> >> >
>> >> > java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
>> >> >         at
>> >> > java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
>> >> >         at
>> >> >
>> >> >
>> >> > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
>> >> >         at
>> >> >
>> >> >
>> >> > java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
>> >> >         at
>> >> >
>> >> >
>> >> > java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>> >> >         at
>> >> >
>> >> >
>> >> > java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>> >> >         at java.lang.Thread.run(Thread.java:722)
>> >>
>> >>
>> >>
>> >> --
>> >> Marcelo
>> >
>> >
>>
>>
>>
>> --
>> Marcelo
>
>



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9548-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 21:35:13 2014
Return-Path: <dev-return-9548-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9BAE1131B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 21:35:13 +0000 (UTC)
Received: (qmail 78411 invoked by uid 500); 22 Sep 2014 21:35:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78333 invoked by uid 500); 22 Sep 2014 21:35:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78318 invoked by uid 99); 22 Sep 2014 21:35:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 21:35:12 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.219.43] (HELO mail-oa0-f43.google.com) (209.85.219.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 21:35:07 +0000
Received: by mail-oa0-f43.google.com with SMTP id m19so4414544oag.2
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 14:34:46 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=MRw0V/KTULRo1NpXZEkhcWRnB8rBZpjkmjvVa4CVsUo=;
        b=XKpQoD3Y/A22Q7iQt5fEx1U+AsLZVTUvquVdAVvRz3p+fV+N7R5mUbvv8VbFTTW3Hd
         pzrrRVzvkaPFBcnHNGjAgvzkCTOQZjXsSP8Ga4KRalsn6BjjNGLlY568rjEKS3l5DZfa
         c4PAwYOwGqGc8iWXuF4/xHBzI4TkzIhNLxkNVQWwXsPfDeQqf/m1zS9aVAnv/aWlPovS
         QTuRizOq8eGkI0u8DqlUfZ6NnsA5jmIuR/38HF30DnjaHoP4DgDGPSy6BDKrplOf+tav
         d/URmh62wA2ZEMfshO/RnZA3wMoxaQqsJpX33nUkOpiYYNXJxBZGXemEe02VxDAiuegN
         dLgA==
X-Gm-Message-State: ALoCoQmOvdboF761KrtOLWdXvjn/19FQ5gIFnupG31KwEzufU6IqegpsLRgvuQGziGp6pfVUc8ja
MIME-Version: 1.0
X-Received: by 10.182.233.132 with SMTP id tw4mr9329911obc.25.1411421685860;
 Mon, 22 Sep 2014 14:34:45 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 22 Sep 2014 14:34:45 -0700 (PDT)
Date: Mon, 22 Sep 2014 16:34:45 -0500
Message-ID: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
Subject: OutOfMemoryError on parquet SnappyDecompressor
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2fa1836e8620503ae38a1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2fa1836e8620503ae38a1
Content-Type: text/plain; charset=UTF-8

After commit 8856c3d8 switched from gzip to snappy as default parquet
compression codec, I'm seeing the following when trying to read parquet
files saved using the new default (same schema and roughly same size as
files that were previously working):

java.lang.OutOfMemoryError: Direct buffer memory
        java.nio.Bits.reserveMemory(Bits.java:658)
        java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
        java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)

parquet.hadoop.codec.SnappyDecompressor.setInput(SnappyDecompressor.java:99)

parquet.hadoop.codec.NonBlockedDecompressorStream.read(NonBlockedDecompressorStream.java:43)
        java.io.DataInputStream.readFully(DataInputStream.java:195)
        java.io.DataInputStream.readFully(DataInputStream.java:169)

parquet.bytes.BytesInput$StreamBytesInput.toByteArray(BytesInput.java:201)

parquet.column.impl.ColumnReaderImpl.readPage(ColumnReaderImpl.java:521)

parquet.column.impl.ColumnReaderImpl.checkRead(ColumnReaderImpl.java:493)

parquet.column.impl.ColumnReaderImpl.consume(ColumnReaderImpl.java:546)

parquet.column.impl.ColumnReaderImpl.<init>(ColumnReaderImpl.java:339)

parquet.column.impl.ColumnReadStoreImpl.newMemColumnReader(ColumnReadStoreImpl.java:63)

parquet.column.impl.ColumnReadStoreImpl.getColumnReader(ColumnReadStoreImpl.java:58)

parquet.io.RecordReaderImplementation.<init>(RecordReaderImplementation.java:265)
        parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:60)
        parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:74)

parquet.hadoop.InternalParquetRecordReader.checkRead(InternalParquetRecordReader.java:110)

parquet.hadoop.InternalParquetRecordReader.nextKeyValue(InternalParquetRecordReader.java:172)

parquet.hadoop.ParquetRecordReader.nextKeyValue(ParquetRecordReader.java:130)

org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:139)

org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
        scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
        scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        scala.collection.Iterator$class.isEmpty(Iterator.scala:256)
        scala.collection.AbstractIterator.isEmpty(Iterator.scala:1157)

org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:220)

org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:219)
        org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
        org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)

org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
        org.apache.spark.scheduler.Task.run(Task.scala:54)

org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)

java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)

java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.Thread.run(Thread.java:722)

--001a11c2fa1836e8620503ae38a1--

From dev-return-9549-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 22 23:30:53 2014
Return-Path: <dev-return-9549-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 60797116E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 22 Sep 2014 23:30:53 +0000 (UTC)
Received: (qmail 8896 invoked by uid 500); 22 Sep 2014 23:30:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8828 invoked by uid 500); 22 Sep 2014 23:30:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8816 invoked by uid 99); 22 Sep 2014 23:30:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 23:30:52 +0000
X-ASF-Spam-Status: No, hits=3.3 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.53 as permitted sender)
Received: from [209.85.219.53] (HELO mail-oa0-f53.google.com) (209.85.219.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 22 Sep 2014 23:30:48 +0000
Received: by mail-oa0-f53.google.com with SMTP id eb12so4351370oac.26
        for <dev@spark.apache.org>; Mon, 22 Sep 2014 16:30:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/PMrpkqy/zlqqGc9gzJyNhu1imtW+bZhOpnFH9pmHUk=;
        b=vNynFNBZz6BWpIVxUcilMQtbgiiSxSunE9ZXCXYtYsXPub/xMe5ONfyBHSUSdXWFdC
         JyZ0xDuRqMrPIkJkFL6G58825ttyTd/YgX6oMAQgBZEJ826TXOFdb7upOVnv1pSUgeqt
         3Sat7cmcWstl/Cr3GPW+fDZ/o0l/H9SUiGqiTXBYdMND4Bk9xDZC5RV7Znz0SOsvqpaK
         Wje90GjaOrnPZwknItySI7JirBAJcBO8+GiPYDEi1tnbOGeoj6krf/rFHi6yv7V6zAkq
         IfWqtUlEptmJbqYzeUQhfwt0ytCghDobAvh5MyQYzMCYBY4soLOHIeaScR2GnkLyO49k
         23CA==
MIME-Version: 1.0
X-Received: by 10.60.142.165 with SMTP id rx5mr22935723oeb.5.1411428627610;
 Mon, 22 Sep 2014 16:30:27 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Mon, 22 Sep 2014 16:30:27 -0700 (PDT)
In-Reply-To: <CAKWX9VWSw-HpTh4zdcvT91kaSLdRL0sP-SK5eipOYNQZ0OL0tA@mail.gmail.com>
References: <CAKWX9VXstLZ6hQRTyxMFvU77QC7ACisRJaatXFuGMjJuAsbYiw@mail.gmail.com>
	<CACBYxKJ1B_fiMTYcytOFs4yTEZ2VfBJv4V4LuDoUnqOvpNuvxg@mail.gmail.com>
	<CAKWX9VWSw-HpTh4zdcvT91kaSLdRL0sP-SK5eipOYNQZ0OL0tA@mail.gmail.com>
Date: Mon, 22 Sep 2014 16:30:27 -0700
Message-ID: <CABPQxsu45SbzJhoJegwd4+kWFVZ5mj3i2hDWb9cLejJaLCBKew@mail.gmail.com>
Subject: Re: hash vs sort shuffle
From: Patrick Wendell <pwendell@gmail.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Cody,

In terms of Spark 1.1.1 - we wouldn't change a default value in a spot
release. Changing this to default is slotted for 1.2.0:

https://issues.apache.org/jira/browse/SPARK-3280

- Patrick

On Mon, Sep 22, 2014 at 9:08 AM, Cody Koeninger <cody@koeninger.org> wrote:
> Unfortunately we were somewhat rushed to get things working again and did
> not keep the exact stacktraces, but one of the issues we saw was similar to
> that reported in
>
> https://issues.apache.org/jira/browse/SPARK-3032
>
> We also saw FAILED_TO_UNCOMPRESS errors from snappy when reading the
> shuffle file.
>
>
>
> On Mon, Sep 22, 2014 at 10:54 AM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> Thanks for the heads up Cody.  Any indication of what was going wrong?
>>
>> On Mon, Sep 22, 2014 at 7:16 AM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>>> Just as a heads up, we deployed 471e6a3a of master (in order to get some
>>> sql fixes), and were seeing jobs fail until we set
>>>
>>> spark.shuffle.manager=HASH
>>>
>>> I'd be reluctant to change the default to sort for the 1.1.1 release
>>>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9550-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 07:47:52 2014
Return-Path: <dev-return-9550-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 536DC11438
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 07:47:52 +0000 (UTC)
Received: (qmail 36429 invoked by uid 500); 23 Sep 2014 07:47:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36355 invoked by uid 500); 23 Sep 2014 07:47:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36343 invoked by uid 99); 23 Sep 2014 07:47:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 07:47:51 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.192.177 as permitted sender)
Received: from [209.85.192.177] (HELO mail-pd0-f177.google.com) (209.85.192.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 07:47:44 +0000
Received: by mail-pd0-f177.google.com with SMTP id v10so4177760pde.8
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 00:47:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-type:content-transfer-encoding:date:subject:to
         :message-id:mime-version;
        bh=OV7eLp7CPUjexLK9jruCntvPaqOmyVSmsKdrZ3zllSg=;
        b=JgFYNqvAzkdvgS2F902cN9aWztfDpbYiR9U6PSw/38M8rk4qaDO9CPZtpYyPYNNtM/
         9q2GWKUPJLx9WwzGQE1GBjJ98OVls60fxCPWRvi+jwiZ+d9NCZtJ+rvVvF7lkHoFPzwv
         RBWMgeg8CcvbLSkUpzErifXZ3Q9D9utPaZDwwjRRiQoctopH4rkGH8vLglfwRztUxVfi
         FC27QyE0Epuyk0Q3RfUsS2xEkjjfE5ktkFMg2l+y6iyVaNAmLAzuobeSjV2t+GUyH8DZ
         HcogGBo0E9M2AYhm1sIrRSwzfkNswtExOajLapwisJgVoZi55QbeMW6OSufK8KLJ1vMT
         M+IQ==
X-Received: by 10.66.237.206 with SMTP id ve14mr32711777pac.40.1411458444141;
        Tue, 23 Sep 2014 00:47:24 -0700 (PDT)
Received: from [10.1.51.19] ([202.85.218.126])
        by mx.google.com with ESMTPSA id e5sm7102853pdn.62.2014.09.23.00.47.21
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 23 Sep 2014 00:47:23 -0700 (PDT)
From: Yi Tian <tianyi.asiainfo@gmail.com>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Date: Tue, 23 Sep 2014 15:47:17 +0800
Subject: Question about SparkSQL and Hive-on-Spark
To: dev@spark.apache.org
Message-Id: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I have some questions about the SparkSQL and Hive-on-Spark

Will SparkSQL support all the hive feature in the future? or just making =
hive as a datasource of Spark?

=46rom Spark 1.1.0 , we have thrift-server support running hql on spark. =
Will this feature be replaced by Hive on Spark?

The reason for asking these questions is that we found some hive =
functions are not  running well on SparkSQL ( like window function, cube =
and rollup function)

Is it worth for making effort on implement these functions with =
SparkSQL? Could you guys give some advices ?=20

thank you.


Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com





---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9551-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 07:50:42 2014
Return-Path: <dev-return-9551-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 861A811447
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 07:50:42 +0000 (UTC)
Received: (qmail 41783 invoked by uid 500); 23 Sep 2014 07:50:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41712 invoked by uid 500); 23 Sep 2014 07:50:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41700 invoked by uid 99); 23 Sep 2014 07:50:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 07:50:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 07:50:12 +0000
Received: by mail-qa0-f51.google.com with SMTP id j7so1281721qaq.10
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 00:50:10 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=DJmJSqluUkmHzi3PZExbA2ziuQWLpoVmgR3g/aWI97c=;
        b=apgqzDGIxOsi16IcJ90ksIrsAGLX0ifDaeWKPE1B47EcHV5cY2eMrqoa+2YI8Yz9QI
         N75Zb5JYlB0ZVJ+mUe1undS/FF3p+eNawogu89S21nvKR36uLTTjTRW6nEuEb6rI8Q3q
         wO/jioGzS3sImPMOw2/FETsPJc8ALNevKirWvrKyuDe+3D/ecjnvERrBPHJ5V19AMxHP
         lQc6j0AWn/C9pCH0PverVbNrm/3krxZk42xRavEmyHwkC2zdrmoasWE9PxXsoNpi1JMl
         72pFg1v0tSAscEjwUWsGkPkP/s7LnzKLIS/umuz5Tao6h1cDOV8/08LnJlPnj42c4uQP
         HmKw==
X-Gm-Message-State: ALoCoQm5tdjK9jVyHXHCBY5P6TpTTeq61S4e0UrSMh1tWAqOt+Mwjp1ub1bPazr6GsWWhWz84wTQ
X-Received: by 10.140.47.137 with SMTP id m9mr9386482qga.95.1411458610697;
 Tue, 23 Sep 2014 00:50:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Tue, 23 Sep 2014 00:49:49 -0700 (PDT)
In-Reply-To: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 23 Sep 2014 00:49:49 -0700
Message-ID: <CAPh_B=bG6zd3-fW8zsoZS4R7ga61LR=2TmMUUk5cXjgPTFaLPA@mail.gmail.com>
Subject: Re: Question about SparkSQL and Hive-on-Spark
To: Yi Tian <tianyi.asiainfo@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c165d61b31970503b6d1e2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c165d61b31970503b6d1e2
Content-Type: text/plain; charset=UTF-8

On Tue, Sep 23, 2014 at 12:47 AM, Yi Tian <tianyi.asiainfo@gmail.com> wrote:

> Hi all,
>
> I have some questions about the SparkSQL and Hive-on-Spark
>
> Will SparkSQL support all the hive feature in the future? or just making
> hive as a datasource of Spark?
>

Most likely not *ALL* Hive features, but almost all common features.


>
> From Spark 1.1.0 , we have thrift-server support running hql on spark.
> Will this feature be replaced by Hive on Spark?
>

No.


>
> The reason for asking these questions is that we found some hive functions
> are not  running well on SparkSQL ( like window function, cube and rollup
> function)


> Is it worth for making effort on implement these functions with SparkSQL?
> Could you guys give some advices ?
>

Yes absolutely.


>
> thank you.
>
>
> Best Regards,
>
> Yi Tian
> tianyi.asiainfo@gmail.com
>
>
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c165d61b31970503b6d1e2--

From dev-return-9552-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 08:03:34 2014
Return-Path: <dev-return-9552-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 84ED1114A1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 08:03:34 +0000 (UTC)
Received: (qmail 60882 invoked by uid 500); 23 Sep 2014 08:03:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60813 invoked by uid 500); 23 Sep 2014 08:03:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60800 invoked by uid 99); 23 Sep 2014 08:03:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 08:03:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of kartheek.mbms@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 08:03:27 +0000
Received: by mail-wi0-f182.google.com with SMTP id d1so4473091wiv.9
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 01:03:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=wlqrhaMCH01v0XOt2pn1WD3Cc38bJN7fUPyRIIX9lJk=;
        b=sJxZC5pmSeTCWIhB7MkXi83LDBANBQ2VDMxn6fTXzFiMp/7GhzipUgmD3XBp02E+j1
         /3nlo1ARIUBiZ6a8X+/N/4+AkBATqoFGVBUI2/565+sAFqvs5ebv2MXy8j5q4eMJTLew
         V1IdSEqqIwmxpgRK+2I4AiKpRAAZfAvRfojm6ZnJ4BcISJjlPg2C44BabZZje20N4Pnj
         OI0xgtslxJj5qZxA+eq6FxgSenZhtcFrYAGHgDqyW34ZaY2/gdbVdvW/BCLw4uzLztKd
         9LXfa+UlCGqOWKpc4n/fctTQ4dqVQZobUAdJbPXwx/TTghqDGjv4BY5gc0BlQVzApxhF
         XXvQ==
MIME-Version: 1.0
X-Received: by 10.194.23.69 with SMTP id k5mr25532961wjf.31.1411459386627;
 Tue, 23 Sep 2014 01:03:06 -0700 (PDT)
Received: by 10.194.165.136 with HTTP; Tue, 23 Sep 2014 01:03:06 -0700 (PDT)
Date: Tue, 23 Sep 2014 13:33:06 +0530
Message-ID: <CAAbaoBAjxxJhip74NqxpuPEUuMLVvyANEGaj-=5X6v1vStJWLw@mail.gmail.com>
Subject: resources allocated for an application
From: rapelly kartheek <kartheek.mbms@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7b41cba05adc7b0503b6ffc6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b41cba05adc7b0503b6ffc6
Content-Type: text/plain; charset=UTF-8

Hi,

I am trying to find out where exactly in the spark code are the resources
getting allocated for a newly submitted spark application.

I have a stand-alone spark cluster. Can someone please direct me to the
right part of the code.

regards

--047d7b41cba05adc7b0503b6ffc6--

From dev-return-9553-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 12:26:33 2014
Return-Path: <dev-return-9553-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 544F211C72
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 12:26:33 +0000 (UTC)
Received: (qmail 52575 invoked by uid 500); 23 Sep 2014 12:26:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52499 invoked by uid 500); 23 Sep 2014 12:26:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51284 invoked by uid 99); 23 Sep 2014 12:26:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 12:26:30 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saisai.shao@intel.com designates 134.134.136.20 as permitted sender)
Received: from [134.134.136.20] (HELO mga02.intel.com) (134.134.136.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 12:26:25 +0000
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by orsmga101.jf.intel.com with ESMTP; 23 Sep 2014 05:26:04 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.04,579,1406617200"; 
   d="scan'208,217";a="577510449"
Received: from fmsmsx108.amr.corp.intel.com ([10.18.124.206])
  by orsmga001.jf.intel.com with ESMTP; 23 Sep 2014 05:26:03 -0700
Received: from fmsmsx102.amr.corp.intel.com (10.18.124.200) by
 FMSMSX108.amr.corp.intel.com (10.18.124.206) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Tue, 23 Sep 2014 05:26:03 -0700
Received: from shsmsx103.ccr.corp.intel.com (10.239.4.69) by
 FMSMSX102.amr.corp.intel.com (10.18.124.200) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Tue, 23 Sep 2014 05:26:03 -0700
Received: from shsmsx104.ccr.corp.intel.com ([169.254.5.230]) by
 SHSMSX103.ccr.corp.intel.com ([169.254.4.204]) with mapi id 14.03.0195.001;
 Tue, 23 Sep 2014 20:25:55 +0800
From: "Shao, Saisai" <saisai.shao@intel.com>
To: Priya Ch <learnings.chitturi@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: spark.local.dir and spark.worker.dir not used
Thread-Topic: spark.local.dir and spark.worker.dir not used
Thread-Index: AQHP1xmk50vGnj/fKkerAy00sFBZrJwOo0ug
Date: Tue, 23 Sep 2014 12:25:54 +0000
Message-ID: <64474308D680D540A4D8151B0F7C03F7027227CE@SHSMSX104.ccr.corp.intel.com>
References: <CABXsDPr=pjEX0C7Pbe6g=+qKn3yZr8mHBeUZiDLw1ZYF60HKig@mail.gmail.com>
In-Reply-To: <CABXsDPr=pjEX0C7Pbe6g=+qKn3yZr8mHBeUZiDLw1ZYF60HKig@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: multipart/alternative;
	boundary="_000_64474308D680D540A4D8151B0F7C03F7027227CESHSMSX104ccrcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_64474308D680D540A4D8151B0F7C03F7027227CESHSMSX104ccrcor_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64

SGksDQoNClNwYXJrLmxvY2FsLmRpciBpcyB0aGUgb25lIHVzZWQgdG8gd3JpdGUgbWFwIG91dHB1
dCBkYXRhIGFuZCBwZXJzaXN0ZW50IFJERCBibG9ja3MsIGJ1dCB0aGUgcGF0aCBvZiAgZmlsZSBo
YXMgYmVlbiBoYXNoZWQsIHNvIHlvdSBjYW5ub3QgZGlyZWN0bHkgZmluZCB0aGUgcGVyc2lzdGVu
dCByZGQgYmxvY2sgZmlsZXMsIGJ1dCBkZWZpbml0ZWx5IGl0IHdpbGwgYmUgaW4gdGhpcyBmb2xk
ZXJzIG9uIHlvdXIgd29ya2VyIG5vZGUuDQoNClRoYW5rcw0KSmVycnkNCg0KRnJvbTogUHJpeWEg
Q2ggW21haWx0bzpsZWFybmluZ3MuY2hpdHR1cmlAZ21haWwuY29tXQ0KU2VudDogVHVlc2RheSwg
U2VwdGVtYmVyIDIzLCAyMDE0IDY6MzEgUE0NClRvOiB1c2VyQHNwYXJrLmFwYWNoZS5vcmc7IGRl
dkBzcGFyay5hcGFjaGUub3JnDQpTdWJqZWN0OiBzcGFyay5sb2NhbC5kaXIgYW5kIHNwYXJrLndv
cmtlci5kaXIgbm90IHVzZWQNCg0KSGksDQoNCkkgYW0gdXNpbmcgc3BhcmsgMS4wLjAuIEluIG15
IHNwYXJrIGNvZGUgaSBtIHRyeWluZyB0byBwZXJzaXN0IGFuIHJkZCB0byBkaXNrIGFzIHJyZC5w
ZXJzaXN0KERJU0tfT05MWSkuIEJ1dCB1bmZvcnR1bmF0ZWx5IGNvdWxkbid0IGZpbmQgdGhlIGxv
Y2F0aW9uIHdoZXJlIHRoZSByZGQgaGFzIGJlZW4gd3JpdHRlbiB0byBkaXNrLiBJIHNwZWNpZmll
ZCBTUEFSS19MT0NBTF9ESVJTIGFuZCBTUEFSS19XT1JLRVJfRElSIHRvIHNvbWUgb3RoZXIgbG9j
YXRpb24gcmF0aGVyIHRoYW4gdXNpbmcgdGhlIGRlZmF1bHQgL3RtcCBkaXJlY3RvcnksIGJ1dCBz
dGlsbCBjb3VsZG50IHNlZSBhbnl0aGluZyBpbiB3b3JrZXIgZGlyZWN0b3J5IGFuZHNwYXJrIG9j
YWwgZGlyZWN0b3J5Lg0KDQpJIGFsc28gdHJpZWQgc3BlY2lmeWluZyB0aGUgbG9jYWwgZGlyIGFu
ZCB3b3JrZXIgZGlyIGZyb20gdGhlIHNwYXJrIGNvZGUgd2hpbGUgZGVmaW5pbmcgdGhlIFNwYXJr
Q29uZiBhcyBjb25mLnNldCgic3BhcmsubG9jYWwuZGlyIiwgIi9ob21lL3BhZG1hL3NwYXJrZGly
IikgYnV0IHRoZSBkaXJlY3RvcmllcyBhcmUgbm90IHVzZWQuDQoNCg0KSW4gZ2VuZXJhbCB3aGlj
aCBkaXJlY3RvcmllcyBzcGFyayB3b3VsZCBiZSB1c2luZyBmb3IgbWFwIG91dHB1dCBmaWxlcywg
aW50ZXJtZWRpYXRlIHdyaXRlcyBhbmQgcGVyc2lzdGluZyByZGQgdG8gZGlzayA/DQoNCg0KVGhh
bmtzLA0KUGFkbWEgQ2gNCg==

--_000_64474308D680D540A4D8151B0F7C03F7027227CESHSMSX104ccrcor_--

From dev-return-9554-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 14:56:31 2014
Return-Path: <dev-return-9554-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D70AD111F1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 14:56:31 +0000 (UTC)
Received: (qmail 40133 invoked by uid 500); 23 Sep 2014 14:40:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40082 invoked by uid 500); 23 Sep 2014 14:40:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40029 invoked by uid 99); 23 Sep 2014 14:40:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 14:40:24 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.219.54] (HELO mail-oa0-f54.google.com) (209.85.219.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 14:39:37 +0000
Received: by mail-oa0-f54.google.com with SMTP id m19so5120591oag.13
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 07:39:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=0+vTAAEyCLf7degPQc4JQpa+9QMs91Y0HZ03O27ToL4=;
        b=dGIme2oHYs+sfyTdoO8D6TFZo8tkCB0/9toC69rmV6jGC1Je1wkjMtZRypwtngXKhI
         CiNDXggTiszeN6bkXA3k9mgDpnTrbdq6w3lndTcfDjE4AwELo79V5o2z5OIP1CUCREJP
         2cAYcygF9oKrYFyGbvdUeyoGiTrD6nEJKRWbeQK0HPW+kFLzK0DU5cJIohmz6vtrzi1o
         cNAA/l07PlzCC3Cx0asIG4hTYLcV3I5itO2siIlh/TCTmFEUveg/cg05cZcyrJHvA4u9
         pbdHWj3kA0IshsbLk2Ha28OWIi/SMGT3pP5GLUNpdxkt46cIH+VTjV97soNlgmOhaV/I
         YI2Q==
X-Gm-Message-State: ALoCoQlTRzc10hcxbbTAkninT5T3L+q1xMSJygO6yUDGBPaJbrK/DutN4klVYEVa8lDaFtIMtefc
MIME-Version: 1.0
X-Received: by 10.182.44.135 with SMTP id e7mr183906obm.18.1411483175455; Tue,
 23 Sep 2014 07:39:35 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Tue, 23 Sep 2014 07:39:35 -0700 (PDT)
In-Reply-To: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
References: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
Date: Tue, 23 Sep 2014 09:39:35 -0500
Message-ID: <CAKWX9VWK+Lf1cCcnOfL50_7nfkaXAV7yzfmgkd4ONyh0ag0=CQ@mail.gmail.com>
Subject: Re: OutOfMemoryError on parquet SnappyDecompressor
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3075c47a50f0503bc89fa
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3075c47a50f0503bc89fa
Content-Type: text/plain; charset=UTF-8

So as a related question, is there any reason the settings in SQLConf
aren't read from the spark context's conf?  I understand why the sql conf
is mutable, but it's not particularly user friendly to have most spark
configuration set via e.g. defaults.conf or --properties-file, but for
spark sql to ignore those.

On Mon, Sep 22, 2014 at 4:34 PM, Cody Koeninger <cody@koeninger.org> wrote:

> After commit 8856c3d8 switched from gzip to snappy as default parquet
> compression codec, I'm seeing the following when trying to read parquet
> files saved using the new default (same schema and roughly same size as
> files that were previously working):
>
> java.lang.OutOfMemoryError: Direct buffer memory
>         java.nio.Bits.reserveMemory(Bits.java:658)
>         java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
>         java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
>
> parquet.hadoop.codec.SnappyDecompressor.setInput(SnappyDecompressor.java:99)
>
> parquet.hadoop.codec.NonBlockedDecompressorStream.read(NonBlockedDecompressorStream.java:43)
>         java.io.DataInputStream.readFully(DataInputStream.java:195)
>         java.io.DataInputStream.readFully(DataInputStream.java:169)
>
> parquet.bytes.BytesInput$StreamBytesInput.toByteArray(BytesInput.java:201)
>
> parquet.column.impl.ColumnReaderImpl.readPage(ColumnReaderImpl.java:521)
>
> parquet.column.impl.ColumnReaderImpl.checkRead(ColumnReaderImpl.java:493)
>
> parquet.column.impl.ColumnReaderImpl.consume(ColumnReaderImpl.java:546)
>
> parquet.column.impl.ColumnReaderImpl.<init>(ColumnReaderImpl.java:339)
>
> parquet.column.impl.ColumnReadStoreImpl.newMemColumnReader(ColumnReadStoreImpl.java:63)
>
> parquet.column.impl.ColumnReadStoreImpl.getColumnReader(ColumnReadStoreImpl.java:58)
>
> parquet.io.RecordReaderImplementation.<init>(RecordReaderImplementation.java:265)
>         parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:60)
>         parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:74)
>
> parquet.hadoop.InternalParquetRecordReader.checkRead(InternalParquetRecordReader.java:110)
>
> parquet.hadoop.InternalParquetRecordReader.nextKeyValue(InternalParquetRecordReader.java:172)
>
> parquet.hadoop.ParquetRecordReader.nextKeyValue(ParquetRecordReader.java:130)
>
> org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:139)
>
> org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
>         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>         scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
>         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>         scala.collection.Iterator$class.isEmpty(Iterator.scala:256)
>         scala.collection.AbstractIterator.isEmpty(Iterator.scala:1157)
>
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:220)
>
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:219)
>         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
>         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
>
> org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
>         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
>         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
>         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
>         org.apache.spark.scheduler.Task.run(Task.scala:54)
>
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>         java.lang.Thread.run(Thread.java:722)
>
>
>

--001a11c3075c47a50f0503bc89fa--

From dev-return-9555-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 15:39:57 2014
Return-Path: <dev-return-9555-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB12E114AB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 15:39:57 +0000 (UTC)
Received: (qmail 88426 invoked by uid 500); 23 Sep 2014 15:39:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88356 invoked by uid 500); 23 Sep 2014 15:39:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88344 invoked by uid 99); 23 Sep 2014 15:39:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 15:39:56 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wibenton@redhat.com designates 209.132.183.39 as permitted sender)
Received: from [209.132.183.39] (HELO mx6-phx2.redhat.com) (209.132.183.39)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 15:39:51 +0000
Received: from zmail14.collab.prod.int.phx2.redhat.com (zmail14.collab.prod.int.phx2.redhat.com [10.5.83.16])
	by mx6-phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s8NFdS6I003044;
	Tue, 23 Sep 2014 11:39:28 -0400
Date: Tue, 23 Sep 2014 11:39:27 -0400 (EDT)
From: Will Benton <willb@redhat.com>
To: Yi Tian <tianyi.asiainfo@gmail.com>
Cc: dev@spark.apache.org
Message-ID: <1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com>
In-Reply-To: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
Subject: Re: Question about SparkSQL and Hive-on-Spark
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.6]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - FF31 (Mac)/8.0.6_GA_5922)
Thread-Topic: Question about SparkSQL and Hive-on-Spark
Thread-Index: sm1p8gQfIR1q39dz5rB55tLIWlEOuQ==
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Yi,

I've had some interest in implementing windowing and rollup in particular for some of my applications but haven't had them on the front of my plate yet.  If you need them as well, I'm happy to start taking a look this week.


best,
wb


----- Original Message -----
> From: "Yi Tian" <tianyi.asiainfo@gmail.com>
> To: dev@spark.apache.org
> Sent: Tuesday, September 23, 2014 2:47:17 AM
> Subject: Question about SparkSQL and Hive-on-Spark
> 
> Hi all,
> 
> I have some questions about the SparkSQL and Hive-on-Spark
> 
> Will SparkSQL support all the hive feature in the future? or just making hive
> as a datasource of Spark?
> 
> From Spark 1.1.0 , we have thrift-server support running hql on spark. Will
> this feature be replaced by Hive on Spark?
> 
> The reason for asking these questions is that we found some hive functions
> are not  running well on SparkSQL ( like window function, cube and rollup
> function)
> 
> Is it worth for making effort on implement these functions with SparkSQL?
> Could you guys give some advices ?
> 
> thank you.
> 
> 
> Best Regards,
> 
> Yi Tian
> tianyi.asiainfo@gmail.com
> 
> 
> 
> 
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9556-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 16:05:18 2014
Return-Path: <dev-return-9556-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 18ED6115B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 16:05:18 +0000 (UTC)
Received: (qmail 52472 invoked by uid 500); 23 Sep 2014 16:05:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52410 invoked by uid 500); 23 Sep 2014 16:05:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52398 invoked by uid 99); 23 Sep 2014 16:05:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 16:05:16 +0000
X-ASF-Spam-Status: No, hits=3.2 required=10.0
	tests=FORGED_YAHOO_RCVD,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tgraves_cs@yahoo.com designates 98.139.212.189 as permitted sender)
Received: from [98.139.212.189] (HELO nm30.bullet.mail.bf1.yahoo.com) (98.139.212.189)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 16:05:11 +0000
DomainKey-Signature: a=rsa-sha1; q=dns; c=nofws; s=s2048; d=yahoo.com;
	b=rqk3q3cG7wTKCcgXt8nbdnnFQ4kNbbE6/4MJv4Tffz0Hm8mZDTWoQeMd20c5/XS3tg6JOcdR6PZHq4E0TqtL1ePWVYkxwaiFEsIZe/PLfiA5PAxcxPtpfVSes6vxjrrvkv4kgr7QlJ2KlLaMdtbm6TuP1d7GlMnwGjf3tNtqNyu7FWsWdythBIxklpykBRt7Mmx4Ra8W5voheQqzjDqQhvIwbHSBVnTnSe0z/IH6tdlKb9FlDYX666LP2mfP3R2e1LGo/kRmA3ptQDpPYsiDBgRX7PmOvRUcWfoKwbqWSGe0D3nn/bwxZmXvC7cAzclpNqhSq1FKzbEnasmxauK23g==;
Received: from [98.139.215.141] by nm30.bullet.mail.bf1.yahoo.com with NNFMP; 23 Sep 2014 16:04:50 -0000
Received: from [98.139.212.196] by tm12.bullet.mail.bf1.yahoo.com with NNFMP; 23 Sep 2014 16:04:50 -0000
Received: from [127.0.0.1] by omp1005.mail.bf1.yahoo.com with NNFMP; 23 Sep 2014 16:04:50 -0000
X-Yahoo-Newman-Property: ymail-5
X-Yahoo-Newman-Id: 259349.23730.bm@omp1005.mail.bf1.yahoo.com
Date: Tue, 23 Sep 2014 16:04:48 +0000 (UTC)
From: Tom Graves <tgraves_cs@yahoo.com.INVALID>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
To: Chester Chen <chester@alpinenow.com>, Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Message-ID: <27889487.1262.1411488289082.JavaMail.yahoo@jws10601b.mail.bf1.yahoo.com>
In-Reply-To: <CAPYnQ0UW2H3MgvPQR6cLzEpJmWPr69pKoLtaLtq6-jJEmDdRLg@mail.gmail.com>
References: <CAPYnQ0UW2H3MgvPQR6cLzEpJmWPr69pKoLtaLtq6-jJEmDdRLg@mail.gmail.com>
Subject: Re: RFC: Deprecating YARN-alpha API's
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_1261_875487588.1411488289073"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_1261_875487588.1411488289073
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Any other comments or objections on this?
Thanks,Tom 

     On Tuesday, September 9, 2014 4:39 PM, Chester Chen <chester@alpinenow.com> wrote:
   

 We were using it until recently, we are talking to our customers and see if
we can get off it.

Chester
Alpine Data Labs



On Tue, Sep 9, 2014 at 10:59 AM, Sean Owen <sowen@cloudera.com> wrote:

> FWIW consensus from Cloudera folk seems to be that there's no need or
> demand on this end for YARN alpha. It wouldn't have an impact if it
> were removed sooner even.
>
> It will be a small positive to reduce complexity by removing this
> support, making it a little easier to develop for current YARN APIs.
>
> On Tue, Sep 9, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hi Everyone,
> >
> > This is a call to the community for comments on SPARK-3445 [1]. In a
> > nutshell, we are trying to figure out timelines for deprecation of the
> > YARN-alpha API's as Yahoo is now moving off of them. It's helpful for
> > us to have a sense of whether anyone else uses these.
> >
> > Please comment on the JIRA if you have feeback, thanks!
> >
> > [1] https://issues.apache.org/jira/browse/SPARK-3445
> >
> > - Patrick
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


    
------=_Part_1261_875487588.1411488289073--

From dev-return-9557-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 16:19:20 2014
Return-Path: <dev-return-9557-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E703B11670
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 16:19:20 +0000 (UTC)
Received: (qmail 95802 invoked by uid 500); 23 Sep 2014 16:19:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95732 invoked by uid 500); 23 Sep 2014 16:19:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95719 invoked by uid 99); 23 Sep 2014 16:19:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 16:19:19 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 16:18:54 +0000
Received: by mail-lb0-f181.google.com with SMTP id b6so3760289lbj.26
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 09:18:52 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=8J4EG+34mxpiL4jm36iD7ySpb+mwVAUtfL4uH0/A3hU=;
        b=nNHrLiV3UxcOM5z4S5ekRJkMNMuVMptrUqjdylVMNKtMvVr1NiC5R5x7mnQ9cA92xM
         j68oyyXCqIfWeNrQ4uUfNT/4+bvRT4/CYzFJkECg6fKn0/Bjq5NxvOT/PYTR2OIH8P/a
         2zDMur8eEq7SHEqB8b3GsAHtDPy2wqDqUj0odNx9PAnuSZQ0eKnoCT58Xe87PZz3ejzo
         qUu4k7O4hSZlgQ6oYeGb2RvRFxaREomGQ+YnLFryeLMzkkxjY3joY6Ntl0fB9Sq0ZmWJ
         nfyidBT55pn7mD8mWb+E4JXlFdQxe9zQZ4uKCFStB00WmC+GbGOy228+ToxZPG+RnhF0
         e7JQ==
X-Gm-Message-State: ALoCoQmtTQ+KsStmdPtZ2T4V5D3XyTXjZCjlCg1Gmvf245Q4LdUDQ64Ztow+fYRZxY0byBYSmYCM
X-Received: by 10.112.149.2 with SMTP id tw2mr568936lbb.21.1411489132342; Tue,
 23 Sep 2014 09:18:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.66 with HTTP; Tue, 23 Sep 2014 09:18:32 -0700 (PDT)
In-Reply-To: <CAKWX9VWK+Lf1cCcnOfL50_7nfkaXAV7yzfmgkd4ONyh0ag0=CQ@mail.gmail.com>
References: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
 <CAKWX9VWK+Lf1cCcnOfL50_7nfkaXAV7yzfmgkd4ONyh0ag0=CQ@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Tue, 23 Sep 2014 09:18:32 -0700
Message-ID: <CAAswR-4sbdEOiXSB=xcbxLMpCUHCfZO+FSra2shs1r3j4375MA@mail.gmail.com>
Subject: Re: OutOfMemoryError on parquet SnappyDecompressor
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b342f4a5699cf0503bdec3f
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b342f4a5699cf0503bdec3f
Content-Type: text/plain; charset=UTF-8

I actually submitted a patch to do this yesterday:
https://github.com/apache/spark/pull/2493

Can you tell us more about your configuration.  In particular how much
memory/cores do the executors have and what does the schema of your data
look like?

On Tue, Sep 23, 2014 at 7:39 AM, Cody Koeninger <cody@koeninger.org> wrote:

> So as a related question, is there any reason the settings in SQLConf
> aren't read from the spark context's conf?  I understand why the sql conf
> is mutable, but it's not particularly user friendly to have most spark
> configuration set via e.g. defaults.conf or --properties-file, but for
> spark sql to ignore those.
>
> On Mon, Sep 22, 2014 at 4:34 PM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
> > After commit 8856c3d8 switched from gzip to snappy as default parquet
> > compression codec, I'm seeing the following when trying to read parquet
> > files saved using the new default (same schema and roughly same size as
> > files that were previously working):
> >
> > java.lang.OutOfMemoryError: Direct buffer memory
> >         java.nio.Bits.reserveMemory(Bits.java:658)
> >         java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
> >         java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
> >
> >
> parquet.hadoop.codec.SnappyDecompressor.setInput(SnappyDecompressor.java:99)
> >
> >
> parquet.hadoop.codec.NonBlockedDecompressorStream.read(NonBlockedDecompressorStream.java:43)
> >         java.io.DataInputStream.readFully(DataInputStream.java:195)
> >         java.io.DataInputStream.readFully(DataInputStream.java:169)
> >
> >
> parquet.bytes.BytesInput$StreamBytesInput.toByteArray(BytesInput.java:201)
> >
> > parquet.column.impl.ColumnReaderImpl.readPage(ColumnReaderImpl.java:521)
> >
> > parquet.column.impl.ColumnReaderImpl.checkRead(ColumnReaderImpl.java:493)
> >
> > parquet.column.impl.ColumnReaderImpl.consume(ColumnReaderImpl.java:546)
> >
> > parquet.column.impl.ColumnReaderImpl.<init>(ColumnReaderImpl.java:339)
> >
> >
> parquet.column.impl.ColumnReadStoreImpl.newMemColumnReader(ColumnReadStoreImpl.java:63)
> >
> >
> parquet.column.impl.ColumnReadStoreImpl.getColumnReader(ColumnReadStoreImpl.java:58)
> >
> >
> parquet.io.RecordReaderImplementation.<init>(RecordReaderImplementation.java:265)
> >
>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:60)
> >
>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:74)
> >
> >
> parquet.hadoop.InternalParquetRecordReader.checkRead(InternalParquetRecordReader.java:110)
> >
> >
> parquet.hadoop.InternalParquetRecordReader.nextKeyValue(InternalParquetRecordReader.java:172)
> >
> >
> parquet.hadoop.ParquetRecordReader.nextKeyValue(ParquetRecordReader.java:130)
> >
> > org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:139)
> >
> >
> org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >         scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >         scala.collection.Iterator$class.isEmpty(Iterator.scala:256)
> >         scala.collection.AbstractIterator.isEmpty(Iterator.scala:1157)
> >
> >
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:220)
> >
> >
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:219)
> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
> >
> > org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
> >         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> >         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> >
>  org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
> >         org.apache.spark.scheduler.Task.run(Task.scala:54)
> >
> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
> >
> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >
> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >         java.lang.Thread.run(Thread.java:722)
> >
> >
> >
>

--047d7b342f4a5699cf0503bdec3f--

From dev-return-9558-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 17:13:35 2014
Return-Path: <dev-return-9558-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA94211949
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 17:13:35 +0000 (UTC)
Received: (qmail 64675 invoked by uid 500); 23 Sep 2014 17:13:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64592 invoked by uid 500); 23 Sep 2014 17:13:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64571 invoked by uid 99); 23 Sep 2014 17:13:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 17:13:33 +0000
X-ASF-Spam-Status: No, hits=6.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 17:13:07 +0000
Received: by mail-ob0-f175.google.com with SMTP id m8so5198388obr.6
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 10:13:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=Wh9BU7MpqOEtmCMKoobv45F/L2ueDtGqugDnPMqicwc=;
        b=LDUF8FGaqLYq+r4MkzqvDbCUPOmpLQoc1B+82B9Q4KKIrDNnp2ATHqqmHH+6gdcFLb
         GUXBk+gm/RNK2VPgbiS/ejL8zAvRgb8rsJ6ytePSx5pUKF9rvOicrtRbQkSGsC49wH/8
         lCSjd6CRW+xhtWIsBDwkHCl4A/CADEI+TcCBfAEHv033cslLKHQConopGfg8NttUYj58
         XuVAjpFzJtOnC8lBO4C255zFNVLN+8CWY5SjiTbIWq2+yUUkANrKlp7AY7e99Cn5yeOB
         v7vFS95Y1WZZwhfSDO1ZozD1OBXDfvzAWSdjTIXV5oJCdU2uu2pwtZvVH6ZfU1/zCNh3
         tqLw==
X-Gm-Message-State: ALoCoQmyZP7ClsDsiReb8ECrk3vuvRUV8ReKHE/xbhwKZgvIsLHBsFkBT85h2PImlMUFRQv4eSq1
MIME-Version: 1.0
X-Received: by 10.60.51.5 with SMTP id g5mr1111316oeo.19.1411492384511; Tue,
 23 Sep 2014 10:13:04 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Tue, 23 Sep 2014 10:13:04 -0700 (PDT)
In-Reply-To: <CAAswR-4sbdEOiXSB=xcbxLMpCUHCfZO+FSra2shs1r3j4375MA@mail.gmail.com>
References: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
	<CAKWX9VWK+Lf1cCcnOfL50_7nfkaXAV7yzfmgkd4ONyh0ag0=CQ@mail.gmail.com>
	<CAAswR-4sbdEOiXSB=xcbxLMpCUHCfZO+FSra2shs1r3j4375MA@mail.gmail.com>
Date: Tue, 23 Sep 2014 12:13:04 -0500
Message-ID: <CAKWX9VUHWFiWK7J-Qr1j6Ym14FOZaLO3KQBsCzY2KqqBZ7p+Ug@mail.gmail.com>
Subject: Re: OutOfMemoryError on parquet SnappyDecompressor
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c30caa2eb1b40503beaee3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c30caa2eb1b40503beaee3
Content-Type: text/plain; charset=UTF-8

Cool, that's pretty much what I was thinking as far as configuration goes.

Running on Mesos.  Worker nodes are amazon xlarge, so 4 core / 15g.  I've
tried executor memory sizes as high as 6G
Default hdfs block size 64m, about 25G of total data written by a job with
128 partitions.  The exception comes when trying to read the data (all
columns).

Schema looks like this:

case class A(
  a: Long,
  b: Long,
  c: Byte,
  d: Option[Long],
  e: Option[Long],
  f: Option[Long],
  g: Option[Long],
  h: Option[Int],
  i: Long,
  j: Option[Int],
  k: Seq[Int],
  l: Seq[Int],
  m: Seq[Int]
)

We're just going back to gzip for now, but might be nice to help someone
else avoid running into this.

On Tue, Sep 23, 2014 at 11:18 AM, Michael Armbrust <michael@databricks.com>
wrote:

> I actually submitted a patch to do this yesterday:
> https://github.com/apache/spark/pull/2493
>
> Can you tell us more about your configuration.  In particular how much
> memory/cores do the executors have and what does the schema of your data
> look like?
>
> On Tue, Sep 23, 2014 at 7:39 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
>
>> So as a related question, is there any reason the settings in SQLConf
>> aren't read from the spark context's conf?  I understand why the sql conf
>> is mutable, but it's not particularly user friendly to have most spark
>> configuration set via e.g. defaults.conf or --properties-file, but for
>> spark sql to ignore those.
>>
>> On Mon, Sep 22, 2014 at 4:34 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>> > After commit 8856c3d8 switched from gzip to snappy as default parquet
>> > compression codec, I'm seeing the following when trying to read parquet
>> > files saved using the new default (same schema and roughly same size as
>> > files that were previously working):
>> >
>> > java.lang.OutOfMemoryError: Direct buffer memory
>> >         java.nio.Bits.reserveMemory(Bits.java:658)
>> >         java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
>> >         java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
>> >
>> >
>> parquet.hadoop.codec.SnappyDecompressor.setInput(SnappyDecompressor.java:99)
>> >
>> >
>> parquet.hadoop.codec.NonBlockedDecompressorStream.read(NonBlockedDecompressorStream.java:43)
>> >         java.io.DataInputStream.readFully(DataInputStream.java:195)
>> >         java.io.DataInputStream.readFully(DataInputStream.java:169)
>> >
>> >
>> parquet.bytes.BytesInput$StreamBytesInput.toByteArray(BytesInput.java:201)
>> >
>> > parquet.column.impl.ColumnReaderImpl.readPage(ColumnReaderImpl.java:521)
>> >
>> >
>> parquet.column.impl.ColumnReaderImpl.checkRead(ColumnReaderImpl.java:493)
>> >
>> > parquet.column.impl.ColumnReaderImpl.consume(ColumnReaderImpl.java:546)
>> >
>> > parquet.column.impl.ColumnReaderImpl.<init>(ColumnReaderImpl.java:339)
>> >
>> >
>> parquet.column.impl.ColumnReadStoreImpl.newMemColumnReader(ColumnReadStoreImpl.java:63)
>> >
>> >
>> parquet.column.impl.ColumnReadStoreImpl.getColumnReader(ColumnReadStoreImpl.java:58)
>> >
>> >
>> parquet.io.RecordReaderImplementation.<init>(RecordReaderImplementation.java:265)
>> >
>>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:60)
>> >
>>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:74)
>> >
>> >
>> parquet.hadoop.InternalParquetRecordReader.checkRead(InternalParquetRecordReader.java:110)
>> >
>> >
>> parquet.hadoop.InternalParquetRecordReader.nextKeyValue(InternalParquetRecordReader.java:172)
>> >
>> >
>> parquet.hadoop.ParquetRecordReader.nextKeyValue(ParquetRecordReader.java:130)
>> >
>> >
>> org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:139)
>> >
>> >
>> org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
>> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>> >         scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
>> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
>> >         scala.collection.Iterator$class.isEmpty(Iterator.scala:256)
>> >         scala.collection.AbstractIterator.isEmpty(Iterator.scala:1157)
>> >
>> >
>> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:220)
>> >
>> >
>> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:219)
>> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
>> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
>> >
>> > org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
>> >         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
>> >         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
>> >
>>  org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
>> >         org.apache.spark.scheduler.Task.run(Task.scala:54)
>> >
>> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
>> >
>> >
>> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>> >
>> >
>> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>> >         java.lang.Thread.run(Thread.java:722)
>> >
>> >
>> >
>>
>
>

--001a11c30caa2eb1b40503beaee3--

From dev-return-9559-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 18:04:05 2014
Return-Path: <dev-return-9559-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED49011CC9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 18:04:04 +0000 (UTC)
Received: (qmail 17787 invoked by uid 500); 23 Sep 2014 18:03:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17679 invoked by uid 500); 23 Sep 2014 18:03:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16833 invoked by uid 99); 23 Sep 2014 18:03:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 18:03:55 +0000
X-ASF-Spam-Status: No, hits=5.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_SBL
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ilikerps@gmail.com designates 209.85.216.182 as permitted sender)
Received: from [209.85.216.182] (HELO mail-qc0-f182.google.com) (209.85.216.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 18:03:30 +0000
Received: by mail-qc0-f182.google.com with SMTP id m20so2197848qcx.27
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 11:03:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=KXlo0z5M56Nu/V4sdjs/bbtRCgx5WleFzDJbBcEUmxc=;
        b=OV3BT2yXu349FNkFDSj77/ugbJxXF3npYZnERJ5UvhAjav0Lfr00wkRBbRvXMyXBaE
         VUkhx7+mY9zbdevXQHHR5bovSdyj81N+cZJmXrILmzUZkfypFXnQbVrUJjXF7oqAvhKl
         sohLP+jcEbdNZPpbhjx/dplwnzGwr1R6oeiijGwGha5wGqSJxQlEb5WAWtkVU8t3SGRd
         Vi6ykHGOHqhbbybLDggRa9KO7j+SZ46NK/T/rfQpd1q1HeZRca+IL698V3g5ivWMeuiq
         UJ6pVdP1wA8vDri4pQvJt7qi5b3nH5st8JajdFRXUTNMymLLyZd3YyFo+gbVwp9SSSSJ
         d7jQ==
X-Received: by 10.140.32.228 with SMTP id h91mr1320097qgh.49.1411495408647;
 Tue, 23 Sep 2014 11:03:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.96.197 with HTTP; Tue, 23 Sep 2014 11:03:08 -0700 (PDT)
In-Reply-To: <CAKWX9VUHWFiWK7J-Qr1j6Ym14FOZaLO3KQBsCzY2KqqBZ7p+Ug@mail.gmail.com>
References: <CAKWX9VXTHC9M927ibtVjLGBzrDWkH_mRtmwKVEh7KNDUx2pFNg@mail.gmail.com>
 <CAKWX9VWK+Lf1cCcnOfL50_7nfkaXAV7yzfmgkd4ONyh0ag0=CQ@mail.gmail.com>
 <CAAswR-4sbdEOiXSB=xcbxLMpCUHCfZO+FSra2shs1r3j4375MA@mail.gmail.com> <CAKWX9VUHWFiWK7J-Qr1j6Ym14FOZaLO3KQBsCzY2KqqBZ7p+Ug@mail.gmail.com>
From: Aaron Davidson <ilikerps@gmail.com>
Date: Tue, 23 Sep 2014 11:03:08 -0700
Message-ID: <CANGvG8q501O+hd8MBairnNUQwKFAAeLvDheBLBE8kK9CcT_aaA@mail.gmail.com>
Subject: Re: OutOfMemoryError on parquet SnappyDecompressor
To: Cody Koeninger <cody@koeninger.org>
Cc: Michael Armbrust <michael@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139a72a6f45010503bf6201
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139a72a6f45010503bf6201
Content-Type: text/plain; charset=UTF-8

This may be related: https://github.com/Parquet/parquet-mr/issues/211

Perhaps if we change our configuration settings for Parquet it would get
better, but the performance characteristics of Snappy are pretty bad here
under some circumstances.

On Tue, Sep 23, 2014 at 10:13 AM, Cody Koeninger <cody@koeninger.org> wrote:

> Cool, that's pretty much what I was thinking as far as configuration goes.
>
> Running on Mesos.  Worker nodes are amazon xlarge, so 4 core / 15g.  I've
> tried executor memory sizes as high as 6G
> Default hdfs block size 64m, about 25G of total data written by a job with
> 128 partitions.  The exception comes when trying to read the data (all
> columns).
>
> Schema looks like this:
>
> case class A(
>   a: Long,
>   b: Long,
>   c: Byte,
>   d: Option[Long],
>   e: Option[Long],
>   f: Option[Long],
>   g: Option[Long],
>   h: Option[Int],
>   i: Long,
>   j: Option[Int],
>   k: Seq[Int],
>   l: Seq[Int],
>   m: Seq[Int]
> )
>
> We're just going back to gzip for now, but might be nice to help someone
> else avoid running into this.
>
> On Tue, Sep 23, 2014 at 11:18 AM, Michael Armbrust <michael@databricks.com
> >
> wrote:
>
> > I actually submitted a patch to do this yesterday:
> > https://github.com/apache/spark/pull/2493
> >
> > Can you tell us more about your configuration.  In particular how much
> > memory/cores do the executors have and what does the schema of your data
> > look like?
> >
> > On Tue, Sep 23, 2014 at 7:39 AM, Cody Koeninger <cody@koeninger.org>
> > wrote:
> >
> >> So as a related question, is there any reason the settings in SQLConf
> >> aren't read from the spark context's conf?  I understand why the sql
> conf
> >> is mutable, but it's not particularly user friendly to have most spark
> >> configuration set via e.g. defaults.conf or --properties-file, but for
> >> spark sql to ignore those.
> >>
> >> On Mon, Sep 22, 2014 at 4:34 PM, Cody Koeninger <cody@koeninger.org>
> >> wrote:
> >>
> >> > After commit 8856c3d8 switched from gzip to snappy as default parquet
> >> > compression codec, I'm seeing the following when trying to read
> parquet
> >> > files saved using the new default (same schema and roughly same size
> as
> >> > files that were previously working):
> >> >
> >> > java.lang.OutOfMemoryError: Direct buffer memory
> >> >         java.nio.Bits.reserveMemory(Bits.java:658)
> >> >         java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:123)
> >> >         java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)
> >> >
> >> >
> >>
> parquet.hadoop.codec.SnappyDecompressor.setInput(SnappyDecompressor.java:99)
> >> >
> >> >
> >>
> parquet.hadoop.codec.NonBlockedDecompressorStream.read(NonBlockedDecompressorStream.java:43)
> >> >         java.io.DataInputStream.readFully(DataInputStream.java:195)
> >> >         java.io.DataInputStream.readFully(DataInputStream.java:169)
> >> >
> >> >
> >>
> parquet.bytes.BytesInput$StreamBytesInput.toByteArray(BytesInput.java:201)
> >> >
> >> >
> parquet.column.impl.ColumnReaderImpl.readPage(ColumnReaderImpl.java:521)
> >> >
> >> >
> >>
> parquet.column.impl.ColumnReaderImpl.checkRead(ColumnReaderImpl.java:493)
> >> >
> >> >
> parquet.column.impl.ColumnReaderImpl.consume(ColumnReaderImpl.java:546)
> >> >
> >> > parquet.column.impl.ColumnReaderImpl.<init>(ColumnReaderImpl.java:339)
> >> >
> >> >
> >>
> parquet.column.impl.ColumnReadStoreImpl.newMemColumnReader(ColumnReadStoreImpl.java:63)
> >> >
> >> >
> >>
> parquet.column.impl.ColumnReadStoreImpl.getColumnReader(ColumnReadStoreImpl.java:58)
> >> >
> >> >
> >>
> parquet.io.RecordReaderImplementation.<init>(RecordReaderImplementation.java:265)
> >> >
> >>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:60)
> >> >
> >>  parquet.io.MessageColumnIO.getRecordReader(MessageColumnIO.java:74)
> >> >
> >> >
> >>
> parquet.hadoop.InternalParquetRecordReader.checkRead(InternalParquetRecordReader.java:110)
> >> >
> >> >
> >>
> parquet.hadoop.InternalParquetRecordReader.nextKeyValue(InternalParquetRecordReader.java:172)
> >> >
> >> >
> >>
> parquet.hadoop.ParquetRecordReader.nextKeyValue(ParquetRecordReader.java:130)
> >> >
> >> >
> >>
> org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:139)
> >> >
> >> >
> >>
> org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
> >> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >> >         scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
> >> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >> >         scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
> >> >         scala.collection.Iterator$class.isEmpty(Iterator.scala:256)
> >> >         scala.collection.AbstractIterator.isEmpty(Iterator.scala:1157)
> >> >
> >> >
> >>
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:220)
> >> >
> >> >
> >>
> org.apache.spark.sql.execution.ExistingRdd$$anonfun$productToRowRdd$1.apply(basicOperators.scala:219)
> >> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
> >> >         org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
> >> >
> >> >
> org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
> >> >
>  org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> >> >         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> >> >
> >>  org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
> >> >         org.apache.spark.scheduler.Task.run(Task.scala:54)
> >> >
> >> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
> >> >
> >> >
> >>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >> >
> >> >
> >>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >> >         java.lang.Thread.run(Thread.java:722)
> >> >
> >> >
> >> >
> >>
> >
> >
>

--001a1139a72a6f45010503bf6201--

From dev-return-9560-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 19:10:09 2014
Return-Path: <dev-return-9560-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A52B711024
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 19:10:09 +0000 (UTC)
Received: (qmail 10915 invoked by uid 500); 23 Sep 2014 19:10:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10843 invoked by uid 500); 23 Sep 2014 19:10:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 41961 invoked by uid 99); 23 Sep 2014 10:31:42 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of learnings.chitturi@gmail.com designates 209.85.192.49 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=34P6BomY6NrsZDMkWu6YauSHsg4bpTUhjdgCxIsU6Po=;
        b=DCuwd1nC4NaFZ2WuLXsUPkDNGu0U79MO35XU1Xfy3OsDngIdnaTeYPKGJErsP+K2VH
         NYYWxUeAkbdUA/K5w9WfCprm5WDMmLTOoTMDpNDmpJnDfvBOGX0EcqF2R6NjfkqsB3sj
         zr+tkKMmeoEYaAG4/egr8drsMk9D/7Av+uGXFV6RGrvfxyrqXmW4wqgnWEtnsL8eHdl5
         JxnArcj7CU8Eh9d5FO4KU/LdW7XWC0DF8+zhxHjS0BkITu6fALC87SQP8auRcahTIQ/M
         8cz5f37C96P9QSM2kHzBmoasct0onx/wL0BEcFSTZFh5vc+cOd4F0d1zLQNVsanQTwCW
         07LA==
MIME-Version: 1.0
X-Received: by 10.140.23.17 with SMTP id 17mr30894619qgo.30.1411468275186;
 Tue, 23 Sep 2014 03:31:15 -0700 (PDT)
Date: Tue, 23 Sep 2014 16:01:15 +0530
Message-ID: <CABXsDPr=pjEX0C7Pbe6g=+qKn3yZr8mHBeUZiDLw1ZYF60HKig@mail.gmail.com>
Subject: spark.local.dir and spark.worker.dir not used
From: Priya Ch <learnings.chitturi@gmail.com>
To: user@spark.apache.org, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c12aca2782100503b91105
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c12aca2782100503b91105
Content-Type: text/plain; charset=UTF-8

Hi,

I am using spark 1.0.0. In my spark code i m trying to persist an rdd to
disk as rrd.persist(DISK_ONLY). But unfortunately couldn't find the
location where the rdd has been written to disk. I specified
SPARK_LOCAL_DIRS and SPARK_WORKER_DIR to some other location rather than
using the default /tmp directory, but still couldnt see anything in worker
directory andspark ocal directory.

I also tried specifying the local dir and worker dir from the spark code
while defining the SparkConf as conf.set("spark.local.dir",
"/home/padma/sparkdir") but the directories are not used.


In general which directories spark would be using for map output files,
intermediate writes and persisting rdd to disk ?


Thanks,
Padma Ch

--001a11c12aca2782100503b91105--

From dev-return-9561-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 20:25:12 2014
Return-Path: <dev-return-9561-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8D3F211448
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 20:25:12 +0000 (UTC)
Received: (qmail 96833 invoked by uid 500); 23 Sep 2014 20:25:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96755 invoked by uid 500); 23 Sep 2014 20:25:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96743 invoked by uid 99); 23 Sep 2014 20:25:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 20:25:11 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.52] (HELO mail-qa0-f52.google.com) (209.85.216.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 20:24:46 +0000
Received: by mail-qa0-f52.google.com with SMTP id dc16so2242533qab.11
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 13:24:44 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=OPlsG6V/Yos5LS8wM/gYQdk1oYHWRYNiQH86oLUS1R0=;
        b=EqdzOwTGgZA0QxAtxgh3RhK3SrYFrH0dZtovma1yaUg/t+2gSyChdmqldmW+ka46sm
         w7A1KeiFxPMRj3kh5e0e44MSqkRTnnREay3X47DiZfOMxr/2KXUrHDJIeeoH6XWqWdTe
         n911R+bGBO7oldSg+PyernmsS5lPi/tNfelVtlDsZHygS9gbYpm4dCSsXI44SXnRb59H
         9Hz84zn//q1pCtaI5tGq85sGjJXfa7Yb2Wt0Rc8jDoLYg645dUidc9boNDDlUjvb3bCh
         /g2eeDsJcgPBh10j98RH0MLwwkqvH4J4WvXXwIcCu6VO9IW+8V9gV8oTLIR28icNye8c
         nzxA==
X-Gm-Message-State: ALoCoQlrSwKpMJwcofa2yjHflymH209ae20Tg3NvmhspZAkOa1JjDrtYO/cqAMz2l84sDYNN+BE2
MIME-Version: 1.0
X-Received: by 10.140.91.46 with SMTP id y43mr2297908qgd.58.1411503884581;
 Tue, 23 Sep 2014 13:24:44 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.12.73 with HTTP; Tue, 23 Sep 2014 13:24:44 -0700 (PDT)
In-Reply-To: <1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
	<1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com>
Date: Tue, 23 Sep 2014 13:24:44 -0700
X-Google-Sender-Auth: dzUGLZZUfl10k0bvypWaPeS8HMI
Message-ID: <CAEYYnxYwbXgO31D24DnzwWxxEvqhf-G=9xQVnbJD7yBSAK=0RA@mail.gmail.com>
Subject: Re: Question about SparkSQL and Hive-on-Spark
From: DB Tsai <dbtsai@dbtsai.com>
To: Will Benton <willb@redhat.com>
Cc: Yi Tian <tianyi.asiainfo@gmail.com>, dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Will,

We're also very interested in windowing support in SparkSQL. Let's us
know once this is available for testing. Thanks.

Sincerely,

DB Tsai
-------------------------------------------------------
My Blog: https://www.dbtsai.com
LinkedIn: https://www.linkedin.com/in/dbtsai


On Tue, Sep 23, 2014 at 8:39 AM, Will Benton <willb@redhat.com> wrote:
> Hi Yi,
>
> I've had some interest in implementing windowing and rollup in particular for some of my applications but haven't had them on the front of my plate yet.  If you need them as well, I'm happy to start taking a look this week.
>
>
> best,
> wb
>
>
> ----- Original Message -----
>> From: "Yi Tian" <tianyi.asiainfo@gmail.com>
>> To: dev@spark.apache.org
>> Sent: Tuesday, September 23, 2014 2:47:17 AM
>> Subject: Question about SparkSQL and Hive-on-Spark
>>
>> Hi all,
>>
>> I have some questions about the SparkSQL and Hive-on-Spark
>>
>> Will SparkSQL support all the hive feature in the future? or just making hive
>> as a datasource of Spark?
>>
>> From Spark 1.1.0 , we have thrift-server support running hql on spark. Will
>> this feature be replaced by Hive on Spark?
>>
>> The reason for asking these questions is that we found some hive functions
>> are not  running well on SparkSQL ( like window function, cube and rollup
>> function)
>>
>> Is it worth for making effort on implement these functions with SparkSQL?
>> Could you guys give some advices ?
>>
>> thank you.
>>
>>
>> Best Regards,
>>
>> Yi Tian
>> tianyi.asiainfo@gmail.com
>>
>>
>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9562-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 23 20:28:52 2014
Return-Path: <dev-return-9562-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5E9E711468
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 23 Sep 2014 20:28:52 +0000 (UTC)
Received: (qmail 5535 invoked by uid 500); 23 Sep 2014 20:28:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5463 invoked by uid 500); 23 Sep 2014 20:28:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5451 invoked by uid 99); 23 Sep 2014 20:28:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 20:28:50 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kumar.soumitra@gmail.com designates 209.85.216.179 as permitted sender)
Received: from [209.85.216.179] (HELO mail-qc0-f179.google.com) (209.85.216.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 23 Sep 2014 20:28:24 +0000
Received: by mail-qc0-f179.google.com with SMTP id l6so1960659qcy.38
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 13:28:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:subject:mime-version
         :content-type:content-transfer-encoding;
        bh=Hj/Sk/W/d7mtAGf+ynTjWoLs4we9tIkO6ZU2+ljQGf0=;
        b=LkHe4FCb/l2hearbaEdZf6h4j7mYdiu9yZnNgLEHWsh+Q6gdVfzgF19maH0CxyvGHR
         Q6s3iUACU847SH5I7Rcx2D11t5cgD51JYUYc9RtXonQfvn8yDd8PVpREwLsjodNpuU9d
         7b9FuperOoO0Et8DW3XTOpeinfTOWt1EZRA1tO2E4m6EJ7p9k2t/ESf9YA7huu18/m8h
         GpfxVhafpM3IBN4Om8yKWwigrid7tqDOE8UK2XpB3FRxB2OMa8YbAEGZBDk/wEEqccK5
         sy10jOaaYbkGBzHbdPg5NW0orh0h/ADmJzIJimH+ZHWYBIIm1m+RdnkOf9H7yWtuLPM6
         mtPQ==
X-Received: by 10.229.94.135 with SMTP id z7mr3130186qcm.26.1411504103370;
        Tue, 23 Sep 2014 13:28:23 -0700 (PDT)
Received: from localhost (99-90-64-194.lightspeed.sntcca.sbcglobal.net. [99.90.64.194])
        by mx.google.com with ESMTPSA id l4sm8002079qao.33.2014.09.23.13.28.22
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 23 Sep 2014 13:28:22 -0700 (PDT)
Date: Tue, 23 Sep 2014 13:28:21 -0700 (PDT)
From: Soumitra Kumar <kumar.soumitra@gmail.com>
To: dev@spark.apache.org
Message-ID: <954579.172.1411504097809.JavaMail.soumitra@tharthari>
In-Reply-To: <13418864.168.1411503842321.JavaMail.soumitra@tharthari>
Subject: SPARK-3660 : Initial RDD for updateStateByKey transformation
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello fellow developers,

Thanks TD for relevant pointers.

I have created an issue :
https://issues.apache.org/jira/browse/SPARK-3660

Copying the description from JIRA:
"
How to initialize state tranformation updateStateByKey?

I have word counts from previous spark-submit run, and want to load that in next spark-submit job to start counting over that.

One proposal is to add following argument to updateStateByKey methods.
initial : Option [RDD [(K, S)]] = None

This will maintain the backward compatibility as well.

I have a working code as well.

This thread started on spark-user list at:
http://apache-spark-user-list.1001560.n3.nabble.com/How-to-initialize-updateStateByKey-operation-td14772.html
"

Please let me know if I shall add a parameter "initial : Option [RDD [(K, S)]] = None" to all updateStateByKey methods or create new ones?

Thanks,
-Soumitra.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9563-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 01:06:58 2014
Return-Path: <dev-return-9563-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D091F11EAF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 01:06:58 +0000 (UTC)
Received: (qmail 207 invoked by uid 500); 24 Sep 2014 01:06:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 143 invoked by uid 500); 24 Sep 2014 01:06:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 132 invoked by uid 99); 24 Sep 2014 01:06:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 01:06:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.48 as permitted sender)
Received: from [209.85.216.48] (HELO mail-qa0-f48.google.com) (209.85.216.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 01:06:31 +0000
Received: by mail-qa0-f48.google.com with SMTP id k15so2489216qaq.35
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 18:06:30 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=j3/+5m3QV1wChUk3dxTICiIZjTd9H93fdGIaej7IUzA=;
        b=YqiViwuOji4mjLoUXAf/ZSvttNRpbYMs454616bxkCaSpbC2yYIsm4LSnq9eC2kCBe
         3sQBoZQXHzAL35F5v8xoqJ4zL+bsuwHbIznzp55jsRQ/N7DKNr0sS3TiLtmSJXzL9ID0
         qs7LC2DLYbp2bkMc3nI+Zs+MRsRzhFvfo2OlHBPHqsltsUGeZdgUqaHaD3wHQ7LipWS+
         p6AnkKQmSG43yv44LCMFhYlxssjvARG2doiTFW5WBLZ6iV3Q7dLr1CwCyk+U38EN+HEh
         SeVnqKw+BUgIUTnGPnS2QRoaAZOvkeTSIomMzB9JsZv1q24rBDs+MXirKHbL1c+rDoiD
         9RXQ==
X-Gm-Message-State: ALoCoQnBcTFpGfufCqvp0RRGOuTVi269pIWMM8z62MQakAwzK06AhNu8OSI85XoYtlVQPRO7rAPd
MIME-Version: 1.0
X-Received: by 10.140.80.180 with SMTP id c49mr5135220qgd.98.1411520790260;
 Tue, 23 Sep 2014 18:06:30 -0700 (PDT)
Received: by 10.140.40.199 with HTTP; Tue, 23 Sep 2014 18:06:30 -0700 (PDT)
In-Reply-To: <3B040748EC1A4B788E19D44230A80671@gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
	<etPan.541e5dad.4db127f8.c101@mbp-3.local>
	<94DE5E900B054CF487A51DAA4451291C@gmail.com>
	<etPan.541f52be.ded7263.c101@mbp-3>
	<C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
	<CACBYxKJUHW0271LPD1g+wsa2mw_7w+5Q4-OtMdXh1EmBnM9PeA@mail.gmail.com>
	<3B040748EC1A4B788E19D44230A80671@gmail.com>
Date: Tue, 23 Sep 2014 18:06:30 -0700
Message-ID: <CACBYxKKTMz45txvUUjvoYetxuE0qugO9smyUDpvhG7tqSd4peA@mail.gmail.com>
Subject: Re: A couple questions about shared variables
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c127d24c25d70503c54bd0
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c127d24c25d70503c54bd0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Filed https://issues.apache.org/jira/browse/SPARK-3642 for documenting
these nuances.

-Sandy

On Mon, Sep 22, 2014 at 10:36 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  I see, thanks for pointing this out
>
>
> --
> Nan Zhu
>
> On Monday, September 22, 2014 at 12:08 PM, Sandy Ryza wrote:
>
> MapReduce counters do not count duplications.  In MapReduce, if a task
> needs to be re-run, the value of the counter from the second task
> overwrites the value from the first task.
>
> -Sandy
>
> On Mon, Sep 22, 2014 at 4:55 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
>  If you think it as necessary to fix, I would like to resubmit that PR
> (seems to have some conflicts with the current DAGScheduler)
>
> My suggestion is to make it as an option in accumulator, e.g. some
> algorithms utilizing accumulator for result calculation, it needs a
> deterministic accumulator, while others implementing something like Hadoo=
p
> counters may need the current implementation (count everything happened,
> including the duplications)
>
> Your thoughts?
>
> --
> Nan Zhu
>
> On Sunday, September 21, 2014 at 6:35 PM, Matei Zaharia wrote:
>
> Hmm, good point, this seems to have been broken by refactorings of the
> scheduler, but it worked in the past. Basically the solution is simple --
> in a result stage, we should not apply the update for each task ID more
> than once -- the same way we don't call job.listener.taskSucceeded more
> than once. Your PR also tried to avoid this for resubmitted shuffle stage=
s,
> but I don't think we need to do that necessarily (though we could).
>
> Matei
>
> On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill@gmail.com)
> wrote:
>
> Hi, Matei,
>
> Can you give some hint on how the current implementation guarantee the
> accumulator is only applied for once?
>
> There is a pending PR trying to achieving this (
> https://github.com/apache/spark/pull/228/files), but from the current
> implementation, I didn=E2=80=99t see this has been done? (maybe I missed =
something)
>
> Best,
>
> --
> Nan Zhu
>
> On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote:
>
>  Hey Sandy,
>
> On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza@cloudera.com)
> wrote:
>
> Hey All,
>
> A couple questions came up about shared variables recently, and I wanted
> to
> confirm my understanding and update the doc to be a little more clear.
>
> *Broadcast variables*
> Now that tasks data is automatically broadcast, the only occasions where
> it
> makes sense to explicitly broadcast are:
> * You want to use a variable from tasks in multiple stages.
> * You want to have the variable stored on the executors in deserialized
> form.
> * You want tasks to be able to modify the variable and have those
> modifications take effect for other tasks running on the same executor
> (usually a very bad idea).
>
> Is that right?
> Yeah, pretty much. Reason 1 above is probably the biggest, but 2 also
> matters. (We might later factor tasks in a different way to avoid 2, but
> it's hard due to things like Hadoop JobConf objects in the tasks).
>
>
> *Accumulators*
> Values are only counted for successful tasks. Is that right? KMeans seems
> to use it in this way. What happens if a node goes away and successful
> tasks need to be resubmitted? Or the stage runs again because a different
> job needed it.
> Accumulators are guaranteed to give a deterministic result if you only
> increment them in actions. For each result stage, the accumulator's updat=
e
> from each task is only applied once, even if that task runs multiple time=
s.
> If you use accumulators in transformations (i.e. in a stage that may be
> part of multiple jobs), then you may see multiple updates, from each run.
> This is kind of confusing but it was useful for people who wanted to use
> these for debugging.
>
> Matei
>
>
>
>
>
> thanks,
> Sandy
>
>
>
>
>
>

--001a11c127d24c25d70503c54bd0--

From dev-return-9564-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 04:02:34 2014
Return-Path: <dev-return-9564-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B1F8F1132A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 04:02:34 +0000 (UTC)
Received: (qmail 49263 invoked by uid 500); 24 Sep 2014 04:02:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49191 invoked by uid 500); 24 Sep 2014 04:02:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49179 invoked by uid 99); 24 Sep 2014 04:02:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 04:02:33 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.192.182 as permitted sender)
Received: from [209.85.192.182] (HELO mail-pd0-f182.google.com) (209.85.192.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 04:02:06 +0000
Received: by mail-pd0-f182.google.com with SMTP id p10so7523473pdj.41
        for <dev@spark.apache.org>; Tue, 23 Sep 2014 21:02:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=JKaLHO6Op4Ou2oE0LaOESQtQw+zJiq8V8x3IEkoY/SE=;
        b=J0yI6oBWSba5kSLKfrI4E/XUFS4mU36nnKIzKa0BzzAIGeqUwaP1B59Jf+R9ERW0eG
         /KwDraqoY/eD1amZEazXsJjsJJWlebXH6uaOQ0tF1oIx3DeLCZL7TjMyd4Lr91i0BtEO
         8vY7MUk+WrCRJDDUbxfoEvv6JWrJfKwcJX/hAe7KLfubEnklOS3ehnlgJ3KDAmAtVUjj
         M5gED84f19Bm9kt9Ci15piJ+JgpbGA4gFSL+1yETo2FJ+mifEl/XjBUd93qt1Obee76R
         QihRcqQVg/rOGZgV+CXBppxqt4o8Q6+jnmML1BPbAp9qrLv7kv9gnzudeEakO/VoEUwl
         3/lg==
X-Received: by 10.66.121.232 with SMTP id ln8mr5302327pab.152.1411531324368;
        Tue, 23 Sep 2014 21:02:04 -0700 (PDT)
Received: from [10.1.51.139] ([202.85.218.126])
        by mx.google.com with ESMTPSA id fr7sm13407054pdb.79.2014.09.23.21.02.02
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 23 Sep 2014 21:02:03 -0700 (PDT)
Subject: Re: Question about SparkSQL and Hive-on-Spark
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Content-Type: text/plain; charset=us-ascii
From: Yi Tian <tianyi.asiainfo@gmail.com>
In-Reply-To: <1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com>
Date: Wed, 24 Sep 2014 12:01:57 +0800
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <0CC9EC1D-136A-4CF2-85EE-A151486D8A73@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com> <1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com>
To: Will Benton <willb@redhat.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, Will

We are planning to start implementing these functions.

We hope that we could make a general design in following week.



Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com




On Sep 23, 2014, at 23:39, Will Benton <willb@redhat.com> wrote:

> Hi Yi,
>=20
> I've had some interest in implementing windowing and rollup in =
particular for some of my applications but haven't had them on the front =
of my plate yet.  If you need them as well, I'm happy to start taking a =
look this week.
>=20
>=20
> best,
> wb
>=20
>=20
> ----- Original Message -----
>> From: "Yi Tian" <tianyi.asiainfo@gmail.com>
>> To: dev@spark.apache.org
>> Sent: Tuesday, September 23, 2014 2:47:17 AM
>> Subject: Question about SparkSQL and Hive-on-Spark
>>=20
>> Hi all,
>>=20
>> I have some questions about the SparkSQL and Hive-on-Spark
>>=20
>> Will SparkSQL support all the hive feature in the future? or just =
making hive
>> as a datasource of Spark?
>>=20
>> =46rom Spark 1.1.0 , we have thrift-server support running hql on =
spark. Will
>> this feature be replaced by Hive on Spark?
>>=20
>> The reason for asking these questions is that we found some hive =
functions
>> are not  running well on SparkSQL ( like window function, cube and =
rollup
>> function)
>>=20
>> Is it worth for making effort on implement these functions with =
SparkSQL?
>> Could you guys give some advices ?
>>=20
>> thank you.
>>=20
>>=20
>> Best Regards,
>>=20
>> Yi Tian
>> tianyi.asiainfo@gmail.com
>>=20
>>=20
>>=20
>>=20
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9565-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 07:28:16 2014
Return-Path: <dev-return-9565-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DD6BA118AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 07:28:16 +0000 (UTC)
Received: (qmail 96079 invoked by uid 500); 24 Sep 2014 07:28:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96000 invoked by uid 500); 24 Sep 2014 07:28:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95988 invoked by uid 99); 24 Sep 2014 07:28:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 07:28:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.220.46 as permitted sender)
Received: from [209.85.220.46] (HELO mail-pa0-f46.google.com) (209.85.220.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 07:28:10 +0000
Received: by mail-pa0-f46.google.com with SMTP id kx10so8157014pab.19
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 00:27:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=koOTy8H+FNDHBLfzQozF97ROlZLuXmySwmZARoe7n00=;
        b=d8x4ThDbySJw/mR51JeSSvdLiDa/NGaBD1h7L/D6KGa09NB60wJPUr/aZYsC2PZ79H
         PqRwiDe4DlUaXmth6nB3YSNEzo4jZOrdyF570e3Lc2h+AHfuHWErR13nnCOWDIHoQHx1
         BzOBrMCqqEsxFP+8WPqrL9xKLOsG5CxpYNmXZjVQxDVjTFAEw44LnR9Rv9FXiahAlYll
         2Eslx5yl+Rp888d9Utx1LzkmW2lieVwMZYc4smKKygdJgobxyWYjzZLNF1/yY9UbOixq
         6CXqFjtg5ZL2f50kYvOcKLpZDeZxGPAceuOfCGjxkOJ2QrEsNVpbPd8Ocjg2iv9uP/jH
         YNXw==
X-Received: by 10.66.65.202 with SMTP id z10mr6900314pas.20.1411543670469;
        Wed, 24 Sep 2014 00:27:50 -0700 (PDT)
Received: from [10.1.51.139] ([202.85.218.126])
        by mx.google.com with ESMTPSA id ro7sm14016347pab.25.2014.09.24.00.27.48
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 24 Sep 2014 00:27:49 -0700 (PDT)
Subject: Re: Question about SparkSQL and Hive-on-Spark
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Content-Type: multipart/alternative; boundary="Apple-Mail=_32AC19AA-1EEE-42B9-AD17-F2B023A3B77E"
From: Yi Tian <tianyi.asiainfo@gmail.com>
In-Reply-To: <CAPh_B=bG6zd3-fW8zsoZS4R7ga61LR=2TmMUUk5cXjgPTFaLPA@mail.gmail.com>
Date: Wed, 24 Sep 2014 15:27:44 +0800
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Message-Id: <25EA8C4A-75A5-4A8C-AE84-DE49B195EA02@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com> <CAPh_B=bG6zd3-fW8zsoZS4R7ga61LR=2TmMUUk5cXjgPTFaLPA@mail.gmail.com>
To: Reynold Xin <rxin@databricks.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_32AC19AA-1EEE-42B9-AD17-F2B023A3B77E
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=us-ascii

Hi Reynold!

Will sparkSQL strictly obey the HQL syntax ?

For example, the cube function.

In other words, the hiveContext of sparkSQL should only implement the =
subset of HQL features?


Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com




On Sep 23, 2014, at 15:49, Reynold Xin <rxin@databricks.com> wrote:

>=20
> On Tue, Sep 23, 2014 at 12:47 AM, Yi Tian <tianyi.asiainfo@gmail.com> =
wrote:
> Hi all,
>=20
> I have some questions about the SparkSQL and Hive-on-Spark
>=20
> Will SparkSQL support all the hive feature in the future? or just =
making hive as a datasource of Spark?
>=20
> Most likely not *ALL* Hive features, but almost all common features.
> =20
>=20
> =46rom Spark 1.1.0 , we have thrift-server support running hql on =
spark. Will this feature be replaced by Hive on Spark?
>=20
> No.
> =20
>=20
> The reason for asking these questions is that we found some hive =
functions are not  running well on SparkSQL ( like window function, cube =
and rollup function)=20
>=20
> Is it worth for making effort on implement these functions with =
SparkSQL? Could you guys give some advices ?
>=20
> Yes absolutely.
> =20
>=20
> thank you.
>=20
>=20
> Best Regards,
>=20
> Yi Tian
> tianyi.asiainfo@gmail.com
>=20
>=20
>=20
>=20
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20
>=20


--Apple-Mail=_32AC19AA-1EEE-42B9-AD17-F2B023A3B77E--

From dev-return-9566-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 09:15:25 2014
Return-Path: <dev-return-9566-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9FB4E11C5B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 09:15:25 +0000 (UTC)
Received: (qmail 83998 invoked by uid 500); 24 Sep 2014 09:15:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83928 invoked by uid 500); 24 Sep 2014 09:15:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83914 invoked by uid 99); 24 Sep 2014 09:15:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 09:15:24 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.43 as permitted sender)
Received: from [209.85.192.43] (HELO mail-qg0-f43.google.com) (209.85.192.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 09:15:19 +0000
Received: by mail-qg0-f43.google.com with SMTP id f51so5775230qge.16
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 02:14:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=y9eQz+CHMj2cauRVd6qcacUTckE0K/Nb6/bL3PtZrcI=;
        b=QVfEg9hdGtqxyhuVNXTtOGzEbsYZkFIcIa0qyjRuCgYTTlj8rAI01I+RRpyKsVyXA0
         IDTRWyaO6KxfTVNV80/JP+LWNedkKy3CR8SwnhqaLSi6SWjCGabeezc2lwbQ47rSXtq9
         TSbpFFnsYgCSDLHPwtxUrd4XjibYhfdAzz2JWpqdpBYJJq5GDWHMwtpw5Qoo9zs+8MNZ
         88GxdpaGZ/3P4Y4YZ9YoMqORdXwmquzLv37FWYLYWypP51BgEoaf7x/d1RiOBL3gxZJS
         tV5hygrwmro4AJwC+1NXqNmPMqxByO3cjO3IV9YCew4wordcZAiYZAIl8BxQgXkF9+BQ
         jKzA==
X-Received: by 10.224.37.134 with SMTP id x6mr7258835qad.39.1411550099221;
 Wed, 24 Sep 2014 02:14:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.100.197 with HTTP; Wed, 24 Sep 2014 02:14:39 -0700 (PDT)
In-Reply-To: <25EA8C4A-75A5-4A8C-AE84-DE49B195EA02@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com>
 <CAPh_B=bG6zd3-fW8zsoZS4R7ga61LR=2TmMUUk5cXjgPTFaLPA@mail.gmail.com> <25EA8C4A-75A5-4A8C-AE84-DE49B195EA02@gmail.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Wed, 24 Sep 2014 17:14:39 +0800
Message-ID: <CAA_qdLooY1cA2pEhXz4chdWHDvLw6Viq1hV9U+RE2e0zGpPXbQ@mail.gmail.com>
Subject: Re: Question about SparkSQL and Hive-on-Spark
To: Yi Tian <tianyi.asiainfo@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1f4a23f35560503cc1ed3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1f4a23f35560503cc1ed3
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I don=E2=80=99t think so. For example, we=E2=80=99ve already added extended=
 syntax like CACHE
TABLE.
=E2=80=8B

On Wed, Sep 24, 2014 at 3:27 PM, Yi Tian <tianyi.asiainfo@gmail.com> wrote:

> Hi Reynold!
>
> Will sparkSQL strictly obey the HQL syntax ?
>
> For example, the cube function.
>
> In other words, the hiveContext of sparkSQL should only implement the
> subset of HQL features?
>
>
> Best Regards,
>
> Yi Tian
> tianyi.asiainfo@gmail.com
>
>
>
>
> On Sep 23, 2014, at 15:49, Reynold Xin <rxin@databricks.com> wrote:
>
> >
> > On Tue, Sep 23, 2014 at 12:47 AM, Yi Tian <tianyi.asiainfo@gmail.com>
> wrote:
> > Hi all,
> >
> > I have some questions about the SparkSQL and Hive-on-Spark
> >
> > Will SparkSQL support all the hive feature in the future? or just makin=
g
> hive as a datasource of Spark?
> >
> > Most likely not *ALL* Hive features, but almost all common features.
> >
> >
> > From Spark 1.1.0 , we have thrift-server support running hql on spark.
> Will this feature be replaced by Hive on Spark?
> >
> > No.
> >
> >
> > The reason for asking these questions is that we found some hive
> functions are not  running well on SparkSQL ( like window function, cube
> and rollup function)
> >
> > Is it worth for making effort on implement these functions with
> SparkSQL? Could you guys give some advices ?
> >
> > Yes absolutely.
> >
> >
> > thank you.
> >
> >
> > Best Regards,
> >
> > Yi Tian
> > tianyi.asiainfo@gmail.com
> >
> >
> >
> >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>
>

--001a11c1f4a23f35560503cc1ed3--

From dev-return-9567-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 10:23:30 2014
Return-Path: <dev-return-9567-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9A8EA11E64
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 10:23:30 +0000 (UTC)
Received: (qmail 15717 invoked by uid 500); 24 Sep 2014 10:23:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15650 invoked by uid 500); 24 Sep 2014 10:23:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15633 invoked by uid 99); 24 Sep 2014 10:23:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 10:23:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dibyendu.bhattachary@gmail.com designates 209.85.220.172 as permitted sender)
Received: from [209.85.220.172] (HELO mail-vc0-f172.google.com) (209.85.220.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 10:23:24 +0000
Received: by mail-vc0-f172.google.com with SMTP id hy10so6554099vcb.3
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 03:23:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=+58TXu8YmAYu1Nmp9rovGj2h/Ej9eMsMoRr10jWQWlk=;
        b=yA912t8UBLlmBCkBK75M06ksJkTDZBY5trudLF4EfDjAY0v33aqG/yEPF3AAQ0YpwR
         iFBcUp96CAPW2KRLAXWYphfp9DBn6qY+3Nddhf2HWXF1HAqYLI6VwAsWmPqRRWQGnuqw
         sKSTJHdH+FaKiSlf8D1X4JZoor4P32+YUH0Lxl/8PVQ+qMFChY2cGDZlVJmCLdJQV7up
         dnNbBcJRZhRsm0fJAVfhSr6+H0G/XAOcTbWCkw2imLOTlAs7LQwDZym92SOawbU/JgTj
         pZ0+TYCrMRXbDHaYU302kiNmf+39M1mnhimdy9PkVHc4JOziKFxGsagReVSHvCPFOBAi
         0UZA==
MIME-Version: 1.0
X-Received: by 10.52.178.98 with SMTP id cx2mr4309841vdc.62.1411554184099;
 Wed, 24 Sep 2014 03:23:04 -0700 (PDT)
Received: by 10.31.168.214 with HTTP; Wed, 24 Sep 2014 03:23:04 -0700 (PDT)
In-Reply-To: <CAPH-c_McUhJSnQrDuOfDhDnHU4UH=JjszuNWk5-mNWh74j9U8w@mail.gmail.com>
References: <CAPH-c_McUhJSnQrDuOfDhDnHU4UH=JjszuNWk5-mNWh74j9U8w@mail.gmail.com>
Date: Wed, 24 Sep 2014 15:53:04 +0530
Message-ID: <CAFiYKR-okAs9K4K8rk0qnJMzfGvCWaNFc8Xy6Cb4+sHNgxOQKw@mail.gmail.com>
Subject: Re: All-time stream re-processing
From: Dibyendu Bhattacharya <dibyendu.bhattachary@gmail.com>
To: Tobias Pfeiffer <tgp@preferred.jp>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf3071cd0cb980b50503cd11dd
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3071cd0cb980b50503cd11dd
Content-Type: text/plain; charset=UTF-8

So you have a single Kafka topic which has very high retention period (
that decides the storage capacity of a given Kafka topic) and you want to
process all historical data first using Camus and then start the streaming
process ?

The challenge is, Camus and Spark are two different consumer for Kafka
topic and both maintains their own consumed offset different way. Camus
stores offset in HDFS, and Spark Consumer in ZK. What I understand, you
need something which identify till which point Camus pulled ( for a given
partitions of topic) and want to start Spark receiver from there ?


Dib

On Wed, Sep 24, 2014 at 2:29 PM, Tobias Pfeiffer <tgp@preferred.jp> wrote:

> Hi,
>
> I have a setup (in mind) where data is written to Kafka and this data is
> persisted in HDFS (e.g., using camus) so that I have an all-time archive of
> all stream data ever received. Now I want to process that all-time archive
> and when I am done with that, continue with the live stream, using Spark
> Streaming. (In a perfect world, Kafka would have infinite storage and I
> would always use the Kafka receiver, starting from offset 0.)
> Does anyone have an idea how to realize such a setup? Would I write a
> custom receiver that first reads the HDFS file and then connects to Kafka?
> Is there an existing solution for that use case?
>
> Thanks
> Tobias
>
>

--20cf3071cd0cb980b50503cd11dd--

From dev-return-9568-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 13:37:41 2014
Return-Path: <dev-return-9568-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 56A1A114E9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 13:37:41 +0000 (UTC)
Received: (qmail 48257 invoked by uid 500); 24 Sep 2014 13:37:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48187 invoked by uid 500); 24 Sep 2014 13:37:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48159 invoked by uid 99); 24 Sep 2014 13:37:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 13:37:40 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wibenton@redhat.com designates 209.132.183.25 as permitted sender)
Received: from [209.132.183.25] (HELO mx4-phx2.redhat.com) (209.132.183.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 13:37:14 +0000
Received: from zmail14.collab.prod.int.phx2.redhat.com (zmail14.collab.prod.int.phx2.redhat.com [10.5.83.16])
	by mx4-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s8ODb9vJ028187;
	Wed, 24 Sep 2014 09:37:09 -0400
Date: Wed, 24 Sep 2014 09:37:08 -0400 (EDT)
From: Will Benton <willb@redhat.com>
To: Yi Tian <tianyi.asiainfo@gmail.com>
Cc: dev@spark.apache.org
Message-ID: <2065576098.9928914.1411565828775.JavaMail.zimbra@redhat.com>
In-Reply-To: <0CC9EC1D-136A-4CF2-85EE-A151486D8A73@gmail.com>
References: <0BCDB942-F687-44C5-99E7-5FD64CAB3A22@gmail.com> <1713586889.9160403.1411486767521.JavaMail.zimbra@redhat.com> <0CC9EC1D-136A-4CF2-85EE-A151486D8A73@gmail.com>
Subject: Re: Question about SparkSQL and Hive-on-Spark
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.6]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - FF31 (Mac)/8.0.6_GA_5922)
Thread-Topic: Question about SparkSQL and Hive-on-Spark
Thread-Index: ItEJmfk6qNRPixJ0tdM+mf3M+ekfzg==
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Yi,

So I've been thinking about implementing windowing for some time and started working on it in earnest yesterday.  There is already a PR for ROLLUP and CUBE; you may want to look at it and see if you can help the author out or provide some test cases:  https://github.com/apache/spark/pull/1567

As far as windowing, I'll be developing my own test cases but would appreciate it if you could also share some kinds of queries you're interested in so that I can incorporate them as well.


best,
wb


----- Original Message -----
> From: "Yi Tian" <tianyi.asiainfo@gmail.com>
> To: "Will Benton" <willb@redhat.com>
> Cc: dev@spark.apache.org
> Sent: Tuesday, September 23, 2014 11:01:57 PM
> Subject: Re: Question about SparkSQL and Hive-on-Spark
> 
> Hi, Will
> 
> We are planning to start implementing these functions.
> 
> We hope that we could make a general design in following week.
> 
> 
> 
> Best Regards,
> 
> Yi Tian
> tianyi.asiainfo@gmail.com
> 
> 
> 
> 
> On Sep 23, 2014, at 23:39, Will Benton <willb@redhat.com> wrote:
> 
> > Hi Yi,
> > 
> > I've had some interest in implementing windowing and rollup in particular
> > for some of my applications but haven't had them on the front of my plate
> > yet.  If you need them as well, I'm happy to start taking a look this
> > week.
> > 
> > 
> > best,
> > wb
> > 
> > 
> > ----- Original Message -----
> >> From: "Yi Tian" <tianyi.asiainfo@gmail.com>
> >> To: dev@spark.apache.org
> >> Sent: Tuesday, September 23, 2014 2:47:17 AM
> >> Subject: Question about SparkSQL and Hive-on-Spark
> >> 
> >> Hi all,
> >> 
> >> I have some questions about the SparkSQL and Hive-on-Spark
> >> 
> >> Will SparkSQL support all the hive feature in the future? or just making
> >> hive
> >> as a datasource of Spark?
> >> 
> >> From Spark 1.1.0 , we have thrift-server support running hql on spark.
> >> Will
> >> this feature be replaced by Hive on Spark?
> >> 
> >> The reason for asking these questions is that we found some hive functions
> >> are not  running well on SparkSQL ( like window function, cube and rollup
> >> function)
> >> 
> >> Is it worth for making effort on implement these functions with SparkSQL?
> >> Could you guys give some advices ?
> >> 
> >> thank you.
> >> 
> >> 
> >> Best Regards,
> >> 
> >> Yi Tian
> >> tianyi.asiainfo@gmail.com
> >> 
> >> 
> >> 
> >> 
> >> 
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >> 
> >> 
> 
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9569-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Sep 24 18:50:54 2014
Return-Path: <dev-return-9569-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7290C11298
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 24 Sep 2014 18:50:54 +0000 (UTC)
Received: (qmail 370 invoked by uid 500); 24 Sep 2014 18:50:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 299 invoked by uid 500); 24 Sep 2014 18:50:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 287 invoked by uid 99); 24 Sep 2014 18:50:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 18:50:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 24 Sep 2014 18:50:47 +0000
Received: by mail-ig0-f175.google.com with SMTP id h18so7106010igc.14
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 11:50:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=jrKWyDmB7XdsKmNJxKSys/GhItO+1YwyFhth/Cy4O6o=;
        b=sRNAeHc+5H1tArep7kwIp5k8lKqlYIJVgL37CcI7sVS/fzGVOkB7iCE4AM/HBFQu+Z
         2nQR8f1Y7cq+UvL4Wb0fdlY8wmJXJWXgWipn9EXHQPMq62wadLnO1eQP6MpF5S+s9jLd
         BTpRJAw1UIP2rKKg6XvvtStj4WU+T1V9KwelJzlRkWGKUiWoBk14FBq1YNb9T2DhENZU
         3bP1NryuqNwEUfjpMwwyrzRKJOyVYrKa+9yaCq8vSielAPEslSTd9t+PRDc1LcOFXnXD
         hBe+BplcM+bXeq1sVkcZxr67IvqR4BorZ/0fFEQbnDZUl5846orIf/1MfZ1RLwE3XWcL
         gWhQ==
X-Received: by 10.43.155.13 with SMTP id lg13mr13371856icc.15.1411584627020;
        Wed, 24 Sep 2014 11:50:27 -0700 (PDT)
Received: from [142.157.43.132] (wpa043132.Wireless.McGill.CA. [142.157.43.132])
        by mx.google.com with ESMTPSA id e16sm478768igz.8.2014.09.24.11.50.23
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 24 Sep 2014 11:50:26 -0700 (PDT)
Date: Wed, 24 Sep 2014 15:04:55 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <734ACEFF578D4EACB7841717736AD4EE@gmail.com>
In-Reply-To: <CACBYxKKTMz45txvUUjvoYetxuE0qugO9smyUDpvhG7tqSd4peA@mail.gmail.com>
References: <CACBYxK+35mxEL+De_ig5-JwLUz1pP6bjgZGDNrSavMTGCOUvsw@mail.gmail.com>
 <etPan.541e5dad.4db127f8.c101@mbp-3.local>
 <94DE5E900B054CF487A51DAA4451291C@gmail.com>
 <etPan.541f52be.ded7263.c101@mbp-3>
 <C278CAAAD2FA4864B5124450DDB94A6D@gmail.com>
 <CACBYxKJUHW0271LPD1g+wsa2mw_7w+5Q4-OtMdXh1EmBnM9PeA@mail.gmail.com>
 <3B040748EC1A4B788E19D44230A80671@gmail.com>
 <CACBYxKKTMz45txvUUjvoYetxuE0qugO9smyUDpvhG7tqSd4peA@mail.gmail.com>
Subject: Re: A couple questions about shared variables
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="542315d7_769a091f_214"
X-Virus-Checked: Checked by ClamAV on apache.org

--542315d7_769a091f_214
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I proposed a fix https://github.com/apache/spark/pull/2524 =20

Glad to receive feedbacks =20

-- =20
Nan Zhu


On Tuesday, September 23, 2014 at 9:06 PM, Sandy Ryza wrote:

> =46iled https://issues.apache.org/jira/browse/SPARK-3642 for documentin=
g these nuances.
> =20
> -Sandy
> =20
> On Mon, Sep 22, 2014 at 10:36 AM, Nan Zhu <zhunanmcgill=40gmail.com (ma=
ilto:zhunanmcgill=40gmail.com)> wrote:
> > I see, thanks for pointing this out =20
> > =20
> > =20
> > -- =20
> > Nan Zhu
> > =20
> > =20
> > On Monday, September 22, 2014 at 12:08 PM, Sandy Ryza wrote:
> > =20
> > > MapReduce counters do not count duplications.  In MapReduce, if a t=
ask needs to be re-run, the value of the counter from the second task ove=
rwrites the value from the first task.
> > > =20
> > > -Sandy
> > > =20
> > > On Mon, Sep 22, 2014 at 4:55 AM, Nan Zhu <zhunanmcgill=40gmail.com =
(mailto:zhunanmcgill=40gmail.com)> wrote:
> > > > If you think it as necessary to fix, I would like to resubmit tha=
t PR (seems to have some conflicts with the current DAGScheduler) =20
> > > > =20
> > > > My suggestion is to make it as an option in accumulator, e.g. som=
e algorithms utilizing accumulator for result calculation, it needs a det=
erministic accumulator, while others implementing something like Hadoop c=
ounters may need the current implementation (count everything happened, i=
ncluding the duplications)
> > > > =20
> > > > Your thoughts=3F =20
> > > > =20
> > > > -- =20
> > > > Nan Zhu
> > > > =20
> > > > =20
> > > > On Sunday, September 21, 2014 at 6:35 PM, Matei Zaharia wrote:
> > > > =20
> > > > > Hmm, good point, this seems to have been broken by refactorings=
 of the scheduler, but it worked in the past. Basically the solution is s=
imple -- in a result stage, we should not apply the update for each task =
ID more than once -- the same way we don't call job.listener.taskSucceede=
d more than once. Your PR also tried to avoid this for resubmitted shuffl=
e stages, but I don't think we need to do that necessarily (though we cou=
ld).
> > > > > =20
> > > > > Matei =20
> > > > > =20
> > > > > On September 21, 2014 at 1:11:13 PM, Nan Zhu (zhunanmcgill=40gm=
ail.com (mailto:zhunanmcgill=40gmail.com)) wrote:
> > > > > =20
> > > > > > Hi, Matei, =20
> > > > > > =20
> > > > > > Can you give some hint on how the current implementation guar=
antee the accumulator is only applied for once=3F =20
> > > > > > =20
> > > > > > There is a pending PR trying to achieving this (https://githu=
b.com/apache/spark/pull/228/files), but from the current implementation, =
I didn=E2=80=99t see this has been done=3F (maybe I missed something) =20
> > > > > > =20
> > > > > > Best, =20
> > > > > > =20
> > > > > > --  =20
> > > > > > Nan Zhu
> > > > > > =20
> > > > > > =20
> > > > > > On Sunday, September 21, 2014 at 1:10 AM, Matei Zaharia wrote=
:
> > > > > > =20
> > > > > > > Hey Sandy,
> > > > > > > =20
> > > > > > > On September 20, 2014 at 8:50:54 AM, Sandy Ryza (sandy.ryza=
=40cloudera.com (mailto:sandy.ryza=40cloudera.com)) wrote: =20
> > > > > > > =20
> > > > > > > Hey All,  =20
> > > > > > > =20
> > > > > > > A couple questions came up about shared variables recently,=
 and I wanted to  =20
> > > > > > > confirm my understanding and update the doc to be a little =
more clear. =20
> > > > > > > =20
> > > > > > > *Broadcast variables*  =20
> > > > > > > Now that tasks data is automatically broadcast, the only oc=
casions where it =20
> > > > > > > makes sense to explicitly broadcast are: =20
> > > > > > > * You want to use a variable from tasks in multiple stages.=
 =20
> > > > > > > * You want to have the variable stored on the executors in =
deserialized =20
> > > > > > > form. =20
> > > > > > > * You want tasks to be able to modify the variable and have=
 those =20
> > > > > > > modifications take effect for other tasks running on the sa=
me executor =20
> > > > > > > (usually a very bad idea). =20
> > > > > > > =20
> > > > > > > Is that right=3F  =20
> > > > > > > Yeah, pretty much. Reason 1 above is probably the biggest, =
but 2 also matters. (We might later factor tasks in a different way to av=
oid 2, but it's hard due to things like Hadoop JobConf objects in the tas=
ks).
> > > > > > > =20
> > > > > > > =20
> > > > > > > *Accumulators*  =20
> > > > > > > Values are only counted for successful tasks. Is that right=
=3F KMeans seems =20
> > > > > > > to use it in this way. What happens if a node goes away and=
 successful =20
> > > > > > > tasks need to be resubmitted=3F Or the stage runs again bec=
ause a different =20
> > > > > > > job needed it. =20
> > > > > > > Accumulators are guaranteed to give a deterministic result =
if you only increment them in actions. =46or each result stage, the accum=
ulator's update from each task is only applied once, even if that task ru=
ns multiple times. If you use accumulators in transformations (i.e. in a =
stage that may be part of multiple jobs), then you may see multiple updat=
es, from each run. This is kind of confusing but it was useful for people=
 who wanted to use these for debugging.
> > > > > > > =20
> > > > > > > Matei =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > thanks,  =20
> > > > > > > Sandy =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > =20
> > > =20
> > =20
> =20


--542315d7_769a091f_214--


From dev-return-9570-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 00:59:19 2014
Return-Path: <dev-return-9570-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CF60811323
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 00:59:19 +0000 (UTC)
Received: (qmail 48934 invoked by uid 500); 25 Sep 2014 00:59:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48829 invoked by uid 500); 25 Sep 2014 00:59:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47690 invoked by uid 99); 25 Sep 2014 00:59:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 00:59:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 216.145.54.172 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 00:59:11 +0000
Received: from GQ1-EX10-CAHT03.y.corp.yahoo.com (gq1-ex10-caht03.corp.gq1.yahoo.com [10.73.118.82])
	by mrout2.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8P0wagF072894
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Wed, 24 Sep 2014 17:58:36 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT03.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Wed, 24
 Sep 2014 17:58:35 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: Spark SQL use of alias in where clause
Thread-Topic: Spark SQL use of alias in where clause
Thread-Index: AQHP2FvVaCbOntVorkivB4Yu9g5cQg==
Date: Thu, 25 Sep 2014 00:58:34 +0000
Message-ID: <D048B6CA.3E74%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D048B6CA3E74liduyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D048B6CA3E74liduyahooinccom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

Hi,

The following query does not work in Shark nor in the new Spark SQLContext =
or HiveContext.
SELECT key, value, concat(key, value) as combined from src where combined l=
ike =9211%=92;

The following tweak of syntax works fine although a bit ugly.
SELECT key, value, concat(key, value) as combined from src where concat(key=
,value) like =9211%=92 order by combined;

Are you going to support alias in where clause soon?

Thanks,
Du

--_000_D048B6CA3E74liduyahooinccom_--

From dev-return-9571-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 01:30:30 2014
Return-Path: <dev-return-9571-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0281711417
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 01:30:30 +0000 (UTC)
Received: (qmail 9317 invoked by uid 500); 25 Sep 2014 01:30:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9247 invoked by uid 500); 25 Sep 2014 01:30:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9235 invoked by uid 99); 25 Sep 2014 01:30:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 01:30:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 01:30:00 +0000
Received: by mail-ig0-f172.google.com with SMTP id a13so7632544igq.5
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 18:29:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:subject:mime-version:content-type;
        bh=qm6s8w8tOn38p9N52dz7o3stz3P3BsUlGN30LzS+tPM=;
        b=sGOtWuzBzna/BqXD00DgAsbEsFQet/ydYv3ZIhrsZnKkuP+71d/VbR3XqjdPfhahmV
         JU9zpCbpH6HOQwcm1ZCie5OsILQcxYU2Vt0lWz/ZAhyzF+8FE24Gq0nSe3kCXPEuldIU
         Md4UW81SFOnArVKoFp0cl5abUKkfMB93Ck/ms942z9ixdXnLl9a4Tg84DYIp/6LOH/4m
         /TZ1j/2DLW5SqyrCXb/4UO0aalf1H6uXB7kLZm+sY82ZFKNb5OrKbLaqj/BqViult7kQ
         XurljD1rFPoKBH4pbF7E6Jx+rXa+GAPZf0hP9w4jozNvCG8sFm1koEDFvkb2RtXzZnr8
         gKDw==
X-Received: by 10.42.81.78 with SMTP id y14mr14480920ick.79.1411608599127;
        Wed, 24 Sep 2014 18:29:59 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id an1sm5804481igc.8.2014.09.24.18.29.58
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 24 Sep 2014 18:29:58 -0700 (PDT)
Date: Wed, 24 Sep 2014 21:44:31 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: dev@spark.apache.org
Message-ID: <A60E3962126148228353AB835E22CCDB@gmail.com>
Subject: do MIMA checking before all test cases start?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5423737f_1c0ca67c_214"
X-Virus-Checked: Checked by ClamAV on apache.org

--5423737f_1c0ca67c_214
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi, all =20

It seems that, currently, Jenkins makes MIMA checking after all test case=
s have finished, IIRC, during the first months we introduced MIMA, we do =
the MIMA checking before running test cases

What=E2=80=99s the motivation to adjust this behaviour=3F

In my opinion, if you have some binary compatibility issues, you just nee=
d to do some minor changes, but in the current environment, you can only =
get if your change works after all test cases finished (1 hour later=E2=80=
=A6)

Best, =20

-- =20
Nan Zhu


--5423737f_1c0ca67c_214--


From dev-return-9572-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 03:33:06 2014
Return-Path: <dev-return-9572-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEF53116B3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 03:33:06 +0000 (UTC)
Received: (qmail 65406 invoked by uid 500); 25 Sep 2014 03:33:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65242 invoked by uid 500); 25 Sep 2014 03:33:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64301 invoked by uid 99); 25 Sep 2014 03:33:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 03:33:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yanbohappy@gmail.com designates 209.85.212.175 as permitted sender)
Received: from [209.85.212.175] (HELO mail-wi0-f175.google.com) (209.85.212.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 03:32:37 +0000
Received: by mail-wi0-f175.google.com with SMTP id r20so8086487wiv.14
        for <multiple recipients>; Wed, 24 Sep 2014 20:32:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=fbiq2Tao99hZf5pUNyFNNeV6ArjYJv3Xwwc7SHUCZk4=;
        b=DbF+KpeS9nhUZj/HRqMwz1t11tIMIYsL/eGmcH5KDpH2CSuSc5gjHpaBKFlJhEnI2X
         meERA9LTTt3hLdEP37sNd1Ogim66ztmxEuJ4ORxoHy9pZpWAgDj+CNiq2fBmuiK5xDod
         bzMtnNpHlCH/D1PPpJb4idnTh5/dN6HLITxEbRNiCntZxS2FaTzseXHPoScf54EmKujM
         vBfvl21KeaH3n84cdPllNRjjBBP5+l1ct5Ubb2RPf0iGcDyvm3M4NJtZ5yQRQrttFiPY
         X8+vpu/sKtsFqYqNKODLHkgnTSPSmo0bY5+rkUSTsY2jhX+//C8A/qeFLZCUJ/JOH2KH
         Vk3w==
MIME-Version: 1.0
X-Received: by 10.194.206.103 with SMTP id ln7mr12566692wjc.30.1411615957215;
 Wed, 24 Sep 2014 20:32:37 -0700 (PDT)
Received: by 10.217.107.135 with HTTP; Wed, 24 Sep 2014 20:32:37 -0700 (PDT)
In-Reply-To: <D048B6CA.3E74%lidu@yahoo-inc.com>
References: <D048B6CA.3E74%lidu@yahoo-inc.com>
Date: Thu, 25 Sep 2014 11:32:37 +0800
Message-ID: <CALDQvdevCy_x1SHL9OC9QKMkoWdkKnSTyjArycfWjXxJiZaoiw@mail.gmail.com>
Subject: Re: Spark SQL use of alias in where clause
From: Yanbo Liang <yanbohappy@gmail.com>
To: Du Li <lidu@yahoo-inc.com.invalid>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bb708e0b0740a0503db7367
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bb708e0b0740a0503db7367
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Maybe it's the way SQL works.
The select part is executed after the where filter is applied, so you
cannot use alias declared in select part in where clause.
Hive and Oracle behavior the same as Spark SQL.

2014-09-25 8:58 GMT+08:00 Du Li <lidu@yahoo-inc.com.invalid>:

>   Hi,
>
>  The following query does not work in Shark nor in the new Spark
> SQLContext or HiveContext.
> SELECT key, value, concat(key, value) as combined from src where combined
> like =E2=80=9911%=E2=80=99;
>
>  The following tweak of syntax works fine although a bit ugly.
> SELECT key, value, concat(key, value) as combined from src where
> concat(key,value) like =E2=80=9911%=E2=80=99 order by combined;
>
>  Are you going to support alias in where clause soon?
>
>  Thanks,
> Du
>

--047d7bb708e0b0740a0503db7367--

From dev-return-9573-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 04:05:05 2014
Return-Path: <dev-return-9573-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA7F811728
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 04:05:05 +0000 (UTC)
Received: (qmail 97070 invoked by uid 500); 25 Sep 2014 04:05:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96991 invoked by uid 500); 25 Sep 2014 04:05:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96978 invoked by uid 99); 25 Sep 2014 04:05:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 04:05:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.169 as permitted sender)
Received: from [209.85.214.169] (HELO mail-ob0-f169.google.com) (209.85.214.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 04:04:35 +0000
Received: by mail-ob0-f169.google.com with SMTP id uy5so4804569obc.14
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 21:04:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=TBxurqe135tZKVXYZK0OcvSPSnQkP5NARWHU0WV8N3w=;
        b=OnoqsiJU7eICOcVpXd0kIhQp0JR3LbasXwXXHFuYC/AJouacOL7DFyjtK1pOQ7jGpu
         cXWmywoIBlDt0nITbVV6G4sIH62Kd2kjgJqhx78SMeTY+44S09cbVj94XpGc/9rvhMxq
         8ZY3uJzIggWUl8aP0eM/qzT39YufbbXpdcSzRVkgY4CbvmfLl7bxlw6edWS2nsLsXh8o
         c1g1zmSHUZsrHXCOdlooHJ/6f6qPJ4pF3fwQAmhsaTYWQKmHGwA2pEF8QJPGXFraxiq4
         HPo4TuSX4cEm+wMTWKFZNeX+2nN3aQPZyVacVg2WyhTY0l4aizbo032yXR/GisMnijDb
         veQQ==
MIME-Version: 1.0
X-Received: by 10.60.51.5 with SMTP id g5mr10841908oeo.19.1411617873730; Wed,
 24 Sep 2014 21:04:33 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Wed, 24 Sep 2014 21:04:33 -0700 (PDT)
In-Reply-To: <A60E3962126148228353AB835E22CCDB@gmail.com>
References: <A60E3962126148228353AB835E22CCDB@gmail.com>
Date: Wed, 24 Sep 2014 21:04:33 -0700
Message-ID: <CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
Subject: Re: do MIMA checking before all test cases start?
From: Patrick Wendell <pwendell@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Have you considered running the mima checks locally? We prefer people
not use Jenkins for very frequent checks since it takes resources away
from other people trying to run tests.

On Wed, Sep 24, 2014 at 6:44 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
> Hi, all
>
> It seems that, currently, Jenkins makes MIMA checking after all test cases have finished, IIRC, during the first months we introduced MIMA, we do the MIMA checking before running test cases
>
> What's the motivation to adjust this behaviour?
>
> In my opinion, if you have some binary compatibility issues, you just need to do some minor changes, but in the current environment, you can only get if your change works after all test cases finished (1 hour later...)
>
> Best,
>
> --
> Nan Zhu
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9574-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 04:11:49 2014
Return-Path: <dev-return-9574-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 98D1611753
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 04:11:49 +0000 (UTC)
Received: (qmail 8750 invoked by uid 500); 25 Sep 2014 04:11:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8676 invoked by uid 500); 25 Sep 2014 04:11:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8664 invoked by uid 99); 25 Sep 2014 04:11:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 04:11:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.169 as permitted sender)
Received: from [209.85.223.169] (HELO mail-ie0-f169.google.com) (209.85.223.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 04:11:41 +0000
Received: by mail-ie0-f169.google.com with SMTP id rp18so10925158iec.14
        for <dev@spark.apache.org>; Wed, 24 Sep 2014 21:11:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=Sgrue5cgrRbU+AMAu0p2GRn0zCLh1RcTmAQDJVBQtDI=;
        b=IoVdwoPgzNsDMkiGzDONWwzvCywr1JTenQsSzt1HWiCyQkf0oMHNHtOBzC3I5ShMhL
         jcI0cwasAv8BkSIMqCy0X+1NRPIghrvLPJyQJJQcSvli2eSlG5LbAHi+cSaUi9hU4Pdn
         KVTmMx0XSKLgoUzpKyeLxyvBUyhmEhBYbbKO3gzESuJOvLmA8UeGctO3jHvDmbNmz/TB
         i7uvNaFYTdiojBp8eWz2Rnbm+wX/WaXywNavmNaLp/fPbwyqOhnVaPP35gK9o/2R1uWu
         sYb4YI5AvOGGY504oxEqa84SLGtdLz7FlJsx6eIwEfIsx2/2K8MJOA1YswbwGeor1Wyz
         wc7Q==
X-Received: by 10.50.117.65 with SMTP id kc1mr18767928igb.34.1411618280538;
        Wed, 24 Sep 2014 21:11:20 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id lr8sm6123719igb.5.2014.09.24.21.11.19
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 24 Sep 2014 21:11:19 -0700 (PDT)
Date: Thu, 25 Sep 2014 00:25:52 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <D5A0AF46FBB34F69A738DD802768718D@gmail.com>
In-Reply-To: <CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
References: <A60E3962126148228353AB835E22CCDB@gmail.com>
 <CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
Subject: Re: do MIMA checking before all test cases start?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54239950_70ec11b2_214"
X-Virus-Checked: Checked by ClamAV on apache.org

--54239950_70ec11b2_214
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

yeah, I tried that, but there is always an issue when I ran dev/mima, =20

it always gives me some binary compatibility error on Java API part=E2=80=
=A6.

so I have to wait for Jenkins=E2=80=99 result when fixing MIMA issues

-- =20
Nan Zhu


On Thursday, September 25, 2014 at 12:04 AM, Patrick Wendell wrote:

> Have you considered running the mima checks locally=3F We prefer people=

> not use Jenkins for very frequent checks since it takes resources away
> from other people trying to run tests.
> =20
> On Wed, Sep 24, 2014 at 6:44 PM, Nan Zhu <zhunanmcgill=40gmail.com (mai=
lto:zhunanmcgill=40gmail.com)> wrote:
> > Hi, all
> > =20
> > It seems that, currently, Jenkins makes MIMA checking after all test =
cases have finished, IIRC, during the first months we introduced MIMA, we=
 do the MIMA checking before running test cases
> > =20
> > What's the motivation to adjust this behaviour=3F
> > =20
> > In my opinion, if you have some binary compatibility issues, you just=
 need to do some minor changes, but in the current environment, you can o=
nly get if your change works after all test cases finished (1 hour later.=
..)
> > =20
> > Best,
> > =20
> > --
> > Nan Zhu
> > =20
> =20
> =20
> =20



--54239950_70ec11b2_214--


From dev-return-9575-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 08:59:42 2014
Return-Path: <dev-return-9575-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9A7C0110A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 08:59:42 +0000 (UTC)
Received: (qmail 29436 invoked by uid 500); 25 Sep 2014 08:59:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29368 invoked by uid 500); 25 Sep 2014 08:59:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29356 invoked by uid 99); 25 Sep 2014 08:59:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 08:59:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of advancedxy@gmail.com designates 209.85.220.41 as permitted sender)
Received: from [209.85.220.41] (HELO mail-pa0-f41.google.com) (209.85.220.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 08:59:14 +0000
Received: by mail-pa0-f41.google.com with SMTP id fa1so2104202pad.0
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 01:59:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=alVkXLFpVLkBifJtURX1qCgY6kPrZyiMqalJ4nNw0po=;
        b=KPCDw8sWyCoJRhiJo5i8anHJRyZQ7ylz4udzj6J0VjhhkCYZdnNfw+EEHSTSo88h6a
         qlKgPsznRJAJDBKIFj2cQ20+GA+6oHpmQP214WySqo8IlR+MB9DfdBxaP7+GzS0JboBs
         S6SPWfgTksltSRAn/s62jiIQd4woSf3BWEzLy/cKo6GXC+rR3dJzSicUIdgiLr+Ws9ek
         S7BGY/DOdk3yJS/nVx4AqkOGcNYTsBCN5K/NpMtqMun1Hv3F1TgGZ5mHjYffTM3pTQ3V
         m/6l2ULmHaqQuACQ3zzeptWOXeZVY0RvhlbWuLWY/AvpUotT5npMtv7jJDkWdlKHq/g3
         yivg==
X-Received: by 10.70.9.129 with SMTP id z1mr3973111pda.37.1411635553106;
        Thu, 25 Sep 2014 01:59:13 -0700 (PDT)
Received: from [172.16.100.217] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id pb1sm1503918pdb.74.2014.09.25.01.59.11
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Thu, 25 Sep 2014 01:59:12 -0700 (PDT)
Date: Thu, 25 Sep 2014 16:59:08 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Cc: sandyryza@gmail.com
Message-ID: <690632FF3B9C4A7D9308C3ABBFCAAAF1@gmail.com>
In-Reply-To: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
References: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
Subject: Re: spark_classpath in core/pom.xml and yarn/porm.xml
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5423d95c_57e4ccaf_fe"
X-Virus-Checked: Checked by ClamAV on apache.org

--5423d95c_57e4ccaf_fe
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

hi, Sandy Ryza:
     I believe It's you originally added the SPARK_CLASSPATH in core/pom.xml in the org.scalatest section. Does this still needed in 1.1?
     I noticed this setting because when I looked into the unit-tests.log, It shows something below:
> 14/09/24 23:57:19.246 WARN SparkConf:
> SPARK_CLASSPATH was detected (set to 'null').
> This is deprecated in Spark 1.0+.
> 
> Please instead use:
>  - ./spark-submit with --driver-class-path to augment the driver classpath
>  - spark.executor.extraClassPath to augment the executor classpath
> 
> 14/09/24 23:57:19.246 WARN SparkConf: Setting 'spark.executor.extraClassPath' to 'null' as a work-around.
> 14/09/24 23:57:19.247 WARN SparkConf: Setting 'spark.driver.extraClassPath' to 'null' as a work-around.

However I didn't set SPARK_CLASSPATH env variable. And looked into the SparkConf.scala, If user actually set extraClassPath,  the SparkConf will throw SparkException.
-- 
Ye Xianjin
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)


On Tuesday, September 23, 2014 at 12:56 AM, Ye Xianjin wrote:

> Hi:
>     I notice the scalatest-maven-plugin set SPARK_CLASSPATH environment variable for testing. But in the SparkConf.scala, this is deprecated in Spark 1.0+.
>     So what this variable for? should we just remove this variable?
>     
> 
> -- 
> Ye Xianjin
> Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
> 


--5423d95c_57e4ccaf_fe--


From dev-return-9576-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 13:10:08 2014
Return-Path: <dev-return-9576-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5713D17328
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 13:10:08 +0000 (UTC)
Received: (qmail 4059 invoked by uid 500); 25 Sep 2014 13:10:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3971 invoked by uid 500); 25 Sep 2014 13:10:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3960 invoked by uid 99); 25 Sep 2014 13:10:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:10:07 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:10:00 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id E8E2FDEF
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 15:09:38 +0200 (CEST)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id q+El7jBwSNMU for <dev@spark.apache.org>;
	Thu, 25 Sep 2014 15:09:38 +0200 (CEST)
Received: from [172.21.60.38] (uhh-wlan-fo-134-100-17-1.rrz.uni-hamburg.de [134.100.17.1])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id 90099DEE
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 15:09:38 +0200 (CEST)
Message-ID: <5424140C.1080704@informatik.uni-hamburg.de>
Date: Thu, 25 Sep 2014 15:09:32 +0200
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: MLlib enable extension of the LabeledPoint class
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Spark developers,

I try to implement a framework with Spark and MLlib to do duplicate
detection. I'm not familiar with Spark and Scala so please be patient
with me. In order to enrich the LabeledPoint class with some information
I tried to extend it and added some properties.
But the ML algorithms (in my case DecisionTree) don't accept my new
ExtendedLabeledPoint class. They just accept the type RDD[LabeledPoint].
Would it be possible to extract a LabeledPoint interface / trait or to
change the type to something covariant like
def train[A <: LabeledPoint]( RDD[A], ... )

I hope it's a usefull idea and it's possible.

Thanks in advance,
Niklas

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9577-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 13:40:44 2014
Return-Path: <dev-return-9577-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D69E174A9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 13:40:44 +0000 (UTC)
Received: (qmail 73426 invoked by uid 500); 25 Sep 2014 13:40:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73349 invoked by uid 500); 25 Sep 2014 13:40:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73337 invoked by uid 99); 25 Sep 2014 13:40:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:40:43 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.170 as permitted sender)
Received: from [74.125.82.170] (HELO mail-we0-f170.google.com) (74.125.82.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:40:16 +0000
Received: by mail-we0-f170.google.com with SMTP id x48so6528955wes.15
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 06:40:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=lz8DjDM0B7GmXB70iE5XSujmF45IOSd1CENi6zkmBtI=;
        b=j4S7ibY0Awo/ev41dybcvi2ErVjp/TtiOBslAwNi6bGfaRHNk4Y3xWp8YZBxre7lD6
         wY5+88aMKKj7Dk7cSoNYU8oe2pHElAn1wJBWD8u0NGX9mx0e18OPeMwEHrchaXwlZt96
         hBgzTHybDvy8Hvnoxm0KlQoGZ/BWuDGwr1ckKweH32SlHyfcDAUlu4vEj8XNUodPsXA+
         GNWZ6odjEhhtiSgUU4RzPBu6X7VR42YN3lR3lBHYsDCpO0ThYIXN12JQL14FHBjmV8wl
         OhqS2MYeoAiPArL840GIm68/2RsIlz0/Jxb7aojyd+ggMWvuq+7+Z+wxJm+VXCgqHdOu
         FADg==
X-Received: by 10.180.77.193 with SMTP id u1mr19561404wiw.45.1411652415918;
 Thu, 25 Sep 2014 06:40:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Thu, 25 Sep 2014 06:39:35 -0700 (PDT)
In-Reply-To: <D5A0AF46FBB34F69A738DD802768718D@gmail.com>
References: <A60E3962126148228353AB835E22CCDB@gmail.com> <CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
 <D5A0AF46FBB34F69A738DD802768718D@gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 25 Sep 2014 09:39:35 -0400
Message-ID: <CAOhmDzfUW_QL2qk-nMVSFv5WxK8ABBywoQHtJYHfSbf2Dtk57A@mail.gmail.com>
Subject: Re: do MIMA checking before all test cases start?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043d6759cc18120503e3f038
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043d6759cc18120503e3f038
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

It might still make sense to make this change if MIMA checks are always
relatively quick, for the same reason we do style checks first.

On Thu, Sep 25, 2014 at 12:25 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> yeah, I tried that, but there is always an issue when I ran dev/mima,
>
> it always gives me some binary compatibility error on Java API part=E2=80=
=A6.
>
> so I have to wait for Jenkins=E2=80=99 result when fixing MIMA issues
>
> --
> Nan Zhu
>
>
> On Thursday, September 25, 2014 at 12:04 AM, Patrick Wendell wrote:
>
> > Have you considered running the mima checks locally? We prefer people
> > not use Jenkins for very frequent checks since it takes resources away
> > from other people trying to run tests.
> >
> > On Wed, Sep 24, 2014 at 6:44 PM, Nan Zhu <zhunanmcgill@gmail.com
> (mailto:zhunanmcgill@gmail.com)> wrote:
> > > Hi, all
> > >
> > > It seems that, currently, Jenkins makes MIMA checking after all test
> cases have finished, IIRC, during the first months we introduced MIMA, we
> do the MIMA checking before running test cases
> > >
> > > What's the motivation to adjust this behaviour?
> > >
> > > In my opinion, if you have some binary compatibility issues, you just
> need to do some minor changes, but in the current environment, you can on=
ly
> get if your change works after all test cases finished (1 hour later...)
> > >
> > > Best,
> > >
> > > --
> > > Nan Zhu
> > >
> >
> >
> >
>
>
>

--f46d043d6759cc18120503e3f038--

From dev-return-9578-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 13:44:33 2014
Return-Path: <dev-return-9578-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 29318174BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 13:44:33 +0000 (UTC)
Received: (qmail 83883 invoked by uid 500); 25 Sep 2014 13:44:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83803 invoked by uid 500); 25 Sep 2014 13:44:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82691 invoked by uid 99); 25 Sep 2014 13:44:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:44:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 13:44:02 +0000
Received: by mail-wg0-f51.google.com with SMTP id z12so4124372wgg.10
        for <multiple recipients>; Thu, 25 Sep 2014 06:44:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=MrD3QGHlFt6zmebOE8e2eeF3bmB9JM1Qc27Gstt5Ixg=;
        b=lfkB6wQOcDu68gWM5uN3YyTTNz+/y5LEfyqOP5pI6WOIrPglB8CWaDior7EJx/TLXz
         W1eJaonMePhN12U1uxnZ7bhdczXGbIZ0wNkd9Dp/Uks3w8Ga4NDSPrQ/Vr93xzMkZmoN
         +eP0XVcf078cxqFjosa7DE7NHnN+KMWRV0QlsnpWpzZlzxq+xcv5Oc1gO9xmo7jd7ezI
         l/BtacvvYiYtAuUA2Qg0+X9KK6WgrDzlFPX8xdtQtxxo4aLf/vBfgGYe4ND3v5nJb3Kx
         F1A0chK5mz8CtlyD4VsJbTsxaAtkzrkQZMaSfo2p5KtLs1Ib26B+HiBzKIH7y+PDDfaq
         9eTg==
X-Received: by 10.194.209.207 with SMTP id mo15mr15483471wjc.6.1411652641870;
 Thu, 25 Sep 2014 06:44:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Thu, 25 Sep 2014 06:43:21 -0700 (PDT)
In-Reply-To: <CALDQvdevCy_x1SHL9OC9QKMkoWdkKnSTyjArycfWjXxJiZaoiw@mail.gmail.com>
References: <D048B6CA.3E74%lidu@yahoo-inc.com> <CALDQvdevCy_x1SHL9OC9QKMkoWdkKnSTyjArycfWjXxJiZaoiw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 25 Sep 2014 09:43:21 -0400
Message-ID: <CAOhmDzd6FL91nSdJMPeQHOO+NM+CM0-SwLn8h5Yqf07_ARiOZw@mail.gmail.com>
Subject: Re: Spark SQL use of alias in where clause
To: Yanbo Liang <yanbohappy@gmail.com>
Cc: Du Li <lidu@yahoo-inc.com.invalid>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a831443dc4f0503e3fe76
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a831443dc4f0503e3fe76
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

That is correct. Aliases in the SELECT clause can only be referenced in the
ORDER BY and HAVING clauses. Otherwise, you'll have to just repeat the
statement, like concat() in this case.

A more elegant alternative, which is probably not available in Spark SQL
yet, is to use Common Table Expressions
<http://technet.microsoft.com/en-us/library/ms190766(v=3Dsql.105).aspx>.

On Wed, Sep 24, 2014 at 11:32 PM, Yanbo Liang <yanbohappy@gmail.com> wrote:

> Maybe it's the way SQL works.
> The select part is executed after the where filter is applied, so you
> cannot use alias declared in select part in where clause.
> Hive and Oracle behavior the same as Spark SQL.
>
> 2014-09-25 8:58 GMT+08:00 Du Li <lidu@yahoo-inc.com.invalid>:
>
>>   Hi,
>>
>>  The following query does not work in Shark nor in the new Spark
>> SQLContext or HiveContext.
>> SELECT key, value, concat(key, value) as combined from src where combine=
d
>> like =E2=80=9911%=E2=80=99;
>>
>>  The following tweak of syntax works fine although a bit ugly.
>> SELECT key, value, concat(key, value) as combined from src where
>> concat(key,value) like =E2=80=9911%=E2=80=99 order by combined;
>>
>>  Are you going to support alias in where clause soon?
>>
>>  Thanks,
>> Du
>>
>
>

--047d7b3a831443dc4f0503e3fe76--

From dev-return-9579-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 14:02:38 2014
Return-Path: <dev-return-9579-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A1BCF17542
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 14:02:38 +0000 (UTC)
Received: (qmail 34425 invoked by uid 500); 25 Sep 2014 14:02:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34353 invoked by uid 500); 25 Sep 2014 14:02:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34342 invoked by uid 99); 25 Sep 2014 14:02:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:02:37 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:02:33 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XX9ca-0001DU-D1
	for dev@spark.incubator.apache.org; Thu, 25 Sep 2014 07:02:12 -0700
Date: Thu, 25 Sep 2014 07:02:12 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411653732352-8549.post@n3.nabble.com>
In-Reply-To: <5424140C.1080704@informatik.uni-hamburg.de>
References: <5424140C.1080704@informatik.uni-hamburg.de>
Subject: Re: MLlib enable extension of the LabeledPoint class
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Niklas Wilcke,

As you said, it is difficult to extend LabeledPoint class in
mllib.regression.
Do you want to extend LabeledPoint class in order to use any other type
exclude Double type?
If you have your code on Github, could you show us it? I want to know what
you want to do.

> Community
By the way, I think LabeledPoint class is very useful exclude
mllib.regression package.
Especially, some estimation algorithms should use a type for the labels
exclude Double type, 
such as String type. The common generics labeled-point class would be useful
in MLlib.
I'd like to get your thoughts on it.

For example,
```
abstract class LabeledPoint[T](label: T, features: Vector)
```

thanks






-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8549.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9580-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 14:23:17 2014
Return-Path: <dev-return-9580-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 836CF17603
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 14:23:17 +0000 (UTC)
Received: (qmail 97166 invoked by uid 500); 25 Sep 2014 14:23:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97097 invoked by uid 500); 25 Sep 2014 14:23:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97085 invoked by uid 99); 25 Sep 2014 14:23:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:23:16 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.42 as permitted sender)
Received: from [209.85.216.42] (HELO mail-qa0-f42.google.com) (209.85.216.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:23:11 +0000
Received: by mail-qa0-f42.google.com with SMTP id dc16so4678270qab.29
        for <dev@spark.incubator.apache.org>; Thu, 25 Sep 2014 07:22:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5YRdHTEDM00lQ4iUqNT7tZmCrQUblVDIhMp85Z4gIjw=;
        b=PQpOueHUQ5LfIrOO9o8S5JKvj0Y5eY2oVLhoIyVfpLhoVrHyFuNPQM4ThTCI7TM3Az
         Zx9+ivZ5uAE/aTUaG2d0QYo2cwAtAx8qF86KT/agzYhQS0Z2iIMdBtrZBsDLmPudcVhR
         bBOj7aE79r7kvBnOziH4nUaf2Cvasxvvb08JLtehUcjqSg5p9jNSo/DT0rWU++L3oEI4
         /T1NjGfkBTgYliiBDQFVvDVbNlGbZhGSAdtP05sc5aXXczthzfHR1zdDBdFY3i2/t+FN
         ZkPBSLryCNJqv4ZXgHJ1EyvlD1xGZrRlMT7nDf7m9iwPKbcKAR3vv6Gmn5j6TFnf7afc
         qreg==
MIME-Version: 1.0
X-Received: by 10.140.93.230 with SMTP id d93mr20970172qge.53.1411654971014;
 Thu, 25 Sep 2014 07:22:51 -0700 (PDT)
Received: by 10.140.40.243 with HTTP; Thu, 25 Sep 2014 07:22:50 -0700 (PDT)
In-Reply-To: <1411653732352-8549.post@n3.nabble.com>
References: <5424140C.1080704@informatik.uni-hamburg.de>
	<1411653732352-8549.post@n3.nabble.com>
Date: Thu, 25 Sep 2014 18:22:50 +0400
Message-ID: <CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com>
Subject: Re: MLlib enable extension of the LabeledPoint class
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1139623617c41b0503e48980
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139623617c41b0503e48980
Content-Type: text/plain; charset=UTF-8

@Yu Ishikawa,

*I think the right place for such discussion -
 https://issues.apache.org/jira/browse/SPARK-3573
<https://issues.apache.org/jira/browse/SPARK-3573>*


2014-09-25 18:02 GMT+04:00 Yu Ishikawa <yuu.ishikawa+spark@gmail.com>:

> Hi Niklas Wilcke,
>
> As you said, it is difficult to extend LabeledPoint class in
> mllib.regression.
> Do you want to extend LabeledPoint class in order to use any other type
> exclude Double type?
> If you have your code on Github, could you show us it? I want to know what
> you want to do.
>
> > Community
> By the way, I think LabeledPoint class is very useful exclude
> mllib.regression package.
> Especially, some estimation algorithms should use a type for the labels
> exclude Double type,
> such as String type. The common generics labeled-point class would be
> useful
> in MLlib.
> I'd like to get your thoughts on it.
>
> For example,
> ```
> abstract class LabeledPoint[T](label: T, features: Vector)
> ```
>
> thanks
>
>
>
>
>
>
> -----
> -- Yu Ishikawa
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8549.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a1139623617c41b0503e48980--

From dev-return-9581-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 14:26:20 2014
Return-Path: <dev-return-9581-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EFA4317615
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 14:26:20 +0000 (UTC)
Received: (qmail 2476 invoked by uid 500); 25 Sep 2014 14:26:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2405 invoked by uid 500); 25 Sep 2014 14:26:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2393 invoked by uid 99); 25 Sep 2014 14:26:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:26:19 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:26:14 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XX9zV-0002ob-Pg
	for dev@spark.incubator.apache.org; Thu, 25 Sep 2014 07:25:54 -0700
Date: Thu, 25 Sep 2014 07:25:53 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411655153778-8551.post@n3.nabble.com>
In-Reply-To: <CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com>
References: <5424140C.1080704@informatik.uni-hamburg.de> <1411653732352-8549.post@n3.nabble.com> <CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com>
Subject: Re: MLlib enable extension of the LabeledPoint class
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Egor Pahomov, 

Thank you for your comment!



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8551.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9582-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 14:27:56 2014
Return-Path: <dev-return-9582-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 310D61762C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 14:27:56 +0000 (UTC)
Received: (qmail 17643 invoked by uid 500); 25 Sep 2014 14:27:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17570 invoked by uid 500); 25 Sep 2014 14:27:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17558 invoked by uid 99); 25 Sep 2014 14:27:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:27:54 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.170 as permitted sender)
Received: from [209.85.216.170] (HELO mail-qc0-f170.google.com) (209.85.216.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:27:50 +0000
Received: by mail-qc0-f170.google.com with SMTP id c9so5157140qcz.1
        for <dev@spark.incubator.apache.org>; Thu, 25 Sep 2014 07:27:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=RvSE/ZE75qVqkyV/dE7qZ2Lj+vo/SUsHV8rU+wZENVc=;
        b=N1M82fnAcb6+3UqKp9Fpa5hZ/5FNFtTjLX5gEGYTxG7wXTV1LgHXikmW9pwO34Fahb
         0TsZGozzLTkSqjiykr0s9igS138ti2e89Wl+IgltSzR2DgS1rWedQ1/QzoLNm4ER6ZF8
         fTXS6SzU8Triuk7bg8+m2T71YNWgv3kQx1zO5wQiFR/3/fbulHw2FNDw0o50U7mvr4g/
         avC59edycdFmQv35wUVg5S16GXeCHAJN7gk2jp9C17tO2aRePwnOLE+Mt2gJTAQXG1Z3
         kGgLykICAiYBUb482qOQibGrwcARNgI6gATklX1UwCRAuinHe+LwyOkkmYd2F2gXhdtm
         MnQg==
MIME-Version: 1.0
X-Received: by 10.140.31.194 with SMTP id f60mr8135157qgf.34.1411655249566;
 Thu, 25 Sep 2014 07:27:29 -0700 (PDT)
Received: by 10.140.40.243 with HTTP; Thu, 25 Sep 2014 07:27:29 -0700 (PDT)
In-Reply-To: <CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com>
References: <5424140C.1080704@informatik.uni-hamburg.de>
	<1411653732352-8549.post@n3.nabble.com>
	<CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com>
Date: Thu, 25 Sep 2014 18:27:29 +0400
Message-ID: <CAMrx5DwDSywpWj+xjmdfaUUem-XyLcQtSiXC4JAEKm0r1uS=nQ@mail.gmail.com>
Subject: Re: MLlib enable extension of the LabeledPoint class
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a113a7ad4b23d1a0503e499ab
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a7ad4b23d1a0503e499ab
Content-Type: text/plain; charset=UTF-8

I agree with Yu, that you should tell more about your intentions, but
possible dirty workaround is create wrapper class for LabeledPoint with all
additional information you need and unwrap values before train, and wrap
them again after. (look at zipWithIndex - it helps match back additional
information after unwrapping)

But I would rather patch my spark with method signature chagnes you
suggested.

2014-09-25 18:22 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:

> @Yu Ishikawa,
>
> *I think the right place for such discussion -
>  https://issues.apache.org/jira/browse/SPARK-3573
> <https://issues.apache.org/jira/browse/SPARK-3573>*
>
>
> 2014-09-25 18:02 GMT+04:00 Yu Ishikawa <yuu.ishikawa+spark@gmail.com>:
>
>> Hi Niklas Wilcke,
>>
>> As you said, it is difficult to extend LabeledPoint class in
>> mllib.regression.
>> Do you want to extend LabeledPoint class in order to use any other type
>> exclude Double type?
>> If you have your code on Github, could you show us it? I want to know what
>> you want to do.
>>
>> > Community
>> By the way, I think LabeledPoint class is very useful exclude
>> mllib.regression package.
>> Especially, some estimation algorithms should use a type for the labels
>> exclude Double type,
>> such as String type. The common generics labeled-point class would be
>> useful
>> in MLlib.
>> I'd like to get your thoughts on it.
>>
>> For example,
>> ```
>> abstract class LabeledPoint[T](label: T, features: Vector)
>> ```
>>
>> thanks
>>
>>
>>
>>
>>
>>
>> -----
>> -- Yu Ishikawa
>> --
>> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8549.html
>> Sent from the Apache Spark Developers List mailing list archive at
>> Nabble.com.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>
>
> --
>
>
>
> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>



-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a113a7ad4b23d1a0503e499ab--

From dev-return-9583-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 14:53:29 2014
Return-Path: <dev-return-9583-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B66FB176D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 14:53:29 +0000 (UTC)
Received: (qmail 94875 invoked by uid 500); 25 Sep 2014 14:53:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94806 invoked by uid 500); 25 Sep 2014 14:53:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94795 invoked by uid 99); 25 Sep 2014 14:53:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:53:26 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 14:53:00 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id 86E0C95F
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 16:52:59 +0200 (CEST)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 4nPE2QEOMgU9 for <dev@spark.apache.org>;
	Thu, 25 Sep 2014 16:52:58 +0200 (CEST)
Received: from [172.21.60.38] (uhh-wlan-fo-134-100-17-1.rrz.uni-hamburg.de [134.100.17.1])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id A94D695E
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 16:52:58 +0200 (CEST)
Message-ID: <54242C48.5040107@informatik.uni-hamburg.de>
Date: Thu, 25 Sep 2014 16:52:56 +0200
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: MLlib enable extension of the LabeledPoint class
References: <5424140C.1080704@informatik.uni-hamburg.de> <1411653732352-8549.post@n3.nabble.com>
In-Reply-To: <1411653732352-8549.post@n3.nabble.com>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Yu Ishikawa,

I'm sorry but I can't share my code via github at the moment. Hopefully
in some months I can.
I don't want to change the type of the label but that would be also a
very nice improvement.

Making LabeledPoint abstract is exactly what I need. That enables me to
create a class like

    LabeledPointTuplePair(label: Double, features: Vector, tuplePair: (Tuple, Tuple)) extends LabeledPoint

and use it in combination of the existing ML algorithms.

In my limited understanding of the MLlib I agree with your proposal of
the LabeledPoint interface

    abstract class LabeledPoint[T](label: T, features: Vector)

In my opinion making LabeledPoint abstract is necessary and introducing
a generic label would be nice to have.
Just to clarify my priorities.

Kind Regards,
Niklas Wilcke


On 25.09.2014 16:02, Yu Ishikawa wrote:
> Hi Niklas Wilcke,
>
> As you said, it is difficult to extend LabeledPoint class in
> mllib.regression.
> Do you want to extend LabeledPoint class in order to use any other type
> exclude Double type?
> If you have your code on Github, could you show us it? I want to know what
> you want to do.
>
>> Community
> By the way, I think LabeledPoint class is very useful exclude
> mllib.regression package.
> Especially, some estimation algorithms should use a type for the labels
> exclude Double type, 
> such as String type. The common generics labeled-point class would be useful
> in MLlib.
> I'd like to get your thoughts on it.
>
> For example,
> ```
> abstract class LabeledPoint[T](label: T, features: Vector)
> ```
>
> thanks
>
>
>
>
>
>
> -----
> -- Yu Ishikawa
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8549.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9584-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 15:04:59 2014
Return-Path: <dev-return-9584-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED74A17731
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 15:04:59 +0000 (UTC)
Received: (qmail 24763 invoked by uid 500); 25 Sep 2014 15:04:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24689 invoked by uid 500); 25 Sep 2014 15:04:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24673 invoked by uid 99); 25 Sep 2014 15:04:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 15:04:57 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 15:04:52 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id 9D2C9AE6
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 17:04:30 +0200 (CEST)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id xRt6gYrIxAk6 for <dev@spark.apache.org>;
	Thu, 25 Sep 2014 17:04:29 +0200 (CEST)
Received: from [172.21.60.38] (uhh-wlan-fo-134-100-17-1.rrz.uni-hamburg.de [134.100.17.1])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id 9B4FCAE5
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 17:04:29 +0200 (CEST)
Message-ID: <54242EFB.109@informatik.uni-hamburg.de>
Date: Thu, 25 Sep 2014 17:04:27 +0200
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: MLlib enable extension of the LabeledPoint class
References: <5424140C.1080704@informatik.uni-hamburg.de>	<1411653732352-8549.post@n3.nabble.com>	<CAMrx5DwSgrNNTYQ08K_kOrMr7sX_zwthyfWkbWOSKXUY7WVmOQ@mail.gmail.com> <CAMrx5DwDSywpWj+xjmdfaUUem-XyLcQtSiXC4JAEKm0r1uS=nQ@mail.gmail.com>
In-Reply-To: <CAMrx5DwDSywpWj+xjmdfaUUem-XyLcQtSiXC4JAEKm0r1uS=nQ@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Egor Pahomov,

thanks for your suggestions. I think I will do the dirty workaround
because I don't want to maintain my own version of spark for now. Maybe
I will do later when I feel ready to contribute to the project.

Kind Regards,
Niklas Wilcke

On 25.09.2014 16:27, Egor Pahomov wrote:
> I agree with Yu, that you should tell more about your intentions, but
> possible dirty workaround is create wrapper class for LabeledPoint with all
> additional information you need and unwrap values before train, and wrap
> them again after. (look at zipWithIndex - it helps match back additional
> information after unwrapping)
>
> But I would rather patch my spark with method signature chagnes you
> suggested.
>
> 2014-09-25 18:22 GMT+04:00 Egor Pahomov <pahomov.egor@gmail.com>:
>
>> @Yu Ishikawa,
>>
>> *I think the right place for such discussion -
>>  https://issues.apache.org/jira/browse/SPARK-3573
>> <https://issues.apache.org/jira/browse/SPARK-3573>*
>>
>>
>> 2014-09-25 18:02 GMT+04:00 Yu Ishikawa <yuu.ishikawa+spark@gmail.com>:
>>
>>> Hi Niklas Wilcke,
>>>
>>> As you said, it is difficult to extend LabeledPoint class in
>>> mllib.regression.
>>> Do you want to extend LabeledPoint class in order to use any other type
>>> exclude Double type?
>>> If you have your code on Github, could you show us it? I want to know what
>>> you want to do.
>>>
>>>> Community
>>> By the way, I think LabeledPoint class is very useful exclude
>>> mllib.regression package.
>>> Especially, some estimation algorithms should use a type for the labels
>>> exclude Double type,
>>> such as String type. The common generics labeled-point class would be
>>> useful
>>> in MLlib.
>>> I'd like to get your thoughts on it.
>>>
>>> For example,
>>> ```
>>> abstract class LabeledPoint[T](label: T, features: Vector)
>>> ```
>>>
>>> thanks
>>>
>>>
>>>
>>>
>>>
>>>
>>> -----
>>> -- Yu Ishikawa
>>> --
>>> View this message in context:
>>> http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-enable-extension-of-the-LabeledPoint-class-tp8546p8549.html
>>> Sent from the Apache Spark Developers List mailing list archive at
>>> Nabble.com.
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>>
>> --
>>
>>
>>
>> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
>>
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9585-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 16:01:15 2014
Return-Path: <dev-return-9585-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF5381792B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 16:01:15 +0000 (UTC)
Received: (qmail 88100 invoked by uid 500); 25 Sep 2014 16:01:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87980 invoked by uid 500); 25 Sep 2014 16:01:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87103 invoked by uid 99); 25 Sep 2014 16:01:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 16:01:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 216.145.54.172 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 16:00:48 +0000
Received: from GQ1-EX10-CAHT12.y.corp.yahoo.com (gq1-ex10-caht12.corp.gq1.yahoo.com [10.73.119.193])
	by mrout2.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8PFxT5H051495
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Thu, 25 Sep 2014 08:59:29 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT12.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Thu, 25
 Sep 2014 08:59:28 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: Nicholas Chammas <nicholas.chammas@gmail.com>,
        Yanbo Liang
	<yanbohappy@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>,
        "user@spark.apache.org"
	<user@spark.apache.org>
Subject: Re: Spark SQL use of alias in where clause
Thread-Topic: Spark SQL use of alias in where clause
Thread-Index: AQHP2FvVaCbOntVorkivB4Yu9g5cQpwRp1WAgACqo4D//7CugA==
Date: Thu, 25 Sep 2014 15:59:28 +0000
Message-ID: <D0498990.3ECC%lidu@yahoo-inc.com>
References: <D048B6CA.3E74%lidu@yahoo-inc.com>
 <CALDQvdevCy_x1SHL9OC9QKMkoWdkKnSTyjArycfWjXxJiZaoiw@mail.gmail.com>
 <CAOhmDzd6FL91nSdJMPeQHOO+NM+CM0-SwLn8h5Yqf07_ARiOZw@mail.gmail.com>
In-Reply-To: <CAOhmDzd6FL91nSdJMPeQHOO+NM+CM0-SwLn8h5Yqf07_ARiOZw@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D04989903ECCliduyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D04989903ECCliduyahooinccom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

Thanks, Yanbo and Nicholas. Now it makes more sense =97 query optimization =
is the answer. /Du

From: Nicholas Chammas <nicholas.chammas@gmail.com<mailto:nicholas.chammas@=
gmail.com>>
Date: Thursday, September 25, 2014 at 6:43 AM
To: Yanbo Liang <yanbohappy@gmail.com<mailto:yanbohappy@gmail.com>>
Cc: Du Li <lidu@yahoo-inc.com.invalid<mailto:lidu@yahoo-inc.com.invalid>>, =
"dev@spark.apache.org<mailto:dev@spark.apache.org>" <dev@spark.apache.org<m=
ailto:dev@spark.apache.org>>, "user@spark.apache.org<mailto:user@spark.apac=
he.org>" <user@spark.apache.org<mailto:user@spark.apache.org>>
Subject: Re: Spark SQL use of alias in where clause

That is correct. Aliases in the SELECT clause can only be referenced in the=
 ORDER BY and HAVING clauses. Otherwise, you'll have to just repeat the sta=
tement, like concat() in this case.

A more elegant alternative, which is probably not available in Spark SQL ye=
t, is to use Common Table Expressions<http://technet.microsoft.com/en-us/li=
brary/ms190766(v=3Dsql.105).aspx>.

On Wed, Sep 24, 2014 at 11:32 PM, Yanbo Liang <yanbohappy@gmail.com<mailto:=
yanbohappy@gmail.com>> wrote:
Maybe it's the way SQL works.
The select part is executed after the where filter is applied, so you canno=
t use alias declared in select part in where clause.
Hive and Oracle behavior the same as Spark SQL.

2014-09-25 8:58 GMT+08:00 Du Li <lidu@yahoo-inc.com.invalid<mailto:lidu@yah=
oo-inc.com.invalid>>:
Hi,

The following query does not work in Shark nor in the new Spark SQLContext =
or HiveContext.
SELECT key, value, concat(key, value) as combined from src where combined l=
ike =9211%=92;

The following tweak of syntax works fine although a bit ugly.
SELECT key, value, concat(key, value) as combined from src where concat(key=
,value) like =9211%=92 order by combined;

Are you going to support alias in where clause soon?

Thanks,
Du



--_000_D04989903ECCliduyahooinccom_--

From dev-return-9586-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 16:41:46 2014
Return-Path: <dev-return-9586-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4DAA317BE9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 16:41:46 +0000 (UTC)
Received: (qmail 11059 invoked by uid 500); 25 Sep 2014 16:41:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10982 invoked by uid 500); 25 Sep 2014 16:41:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10071 invoked by uid 99); 25 Sep 2014 16:41:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 16:41:42 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of xiaodi@sjtu.edu.cn designates 202.112.26.52 as permitted sender)
Received: from [202.112.26.52] (HELO proxy01.sjtu.edu.cn) (202.112.26.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 16:41:35 +0000
Received: from proxy03.sjtu.edu.cn (unknown [202.121.179.33])
	by proxy01.sjtu.edu.cn (Postfix) with ESMTP id F24552600C0;
	Fri, 26 Sep 2014 00:41:12 +0800 (CST)
Received: from localhost (localhost [127.0.0.1])
	by proxy03.sjtu.edu.cn (Postfix) with ESMTP id E3473260E14;
	Fri, 26 Sep 2014 00:41:12 +0800 (GMT-8)
X-Virus-Scanned: amavisd-new at 
Received: from proxy03.sjtu.edu.cn ([127.0.0.1])
	by localhost (proxy03.sjtu.edu.cn [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id aW86g6Pk5PJO; Fri, 26 Sep 2014 00:41:12 +0800 (GMT-8)
Received: from Loca.local (unknown [59.78.3.8])
	(Authenticated sender: xiaodi)
	by proxy03.sjtu.edu.cn (Postfix) with ESMTPSA id B3F01260BFA;
	Fri, 26 Sep 2014 00:41:12 +0800 (GMT-8)
Message-ID: <542445A8.3000005@sjtu.edu.cn>
Date: Fri, 26 Sep 2014 00:41:12 +0800
From: Larry Xiao <xiaodi@sjtu.edu.cn>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.1
MIME-Version: 1.0
To: dev@spark.apache.org, user@spark.apache.org
CC: xiaodi@sjtu.edu.cn
Subject: VertexRDD partition imbalance
Content-Type: multipart/alternative;
 boundary="------------010807040009060509060807"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------010807040009060509060807
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit

Hi all

VertexRDD is partitioned with HashPartitioner, and it exhibits some 
imbalance of tasks.
For example, Connected Components with partition strategy Edge2D:


        Aggregated Metrics by Executor

Executor ID 	Task Time 	Total Tasks 	Failed Tasks 	Succeeded Tasks 
Input 	Shuffle Read 	Shuffle Write 	Shuffle Spill (Memory) 	Shuffle 
Spill (Disk)
1 	10 s 	10 	0 	10 	234.6 MB 	0.0 B 	43.2 MB 	0.0 B 	0.0 B
2 	3 s 	3 	0 	3 	70.4 MB 	0.0 B 	13.0 MB 	0.0 B 	0.0 B
3 	6 s 	6 	0 	6 	140.7 MB 	0.0 B 	25.9 MB 	0.0 B 	0.0 B
4 	9 s 	8 	0 	8 	187.9 MB 	0.0 B 	34.6 MB 	0.0 B 	0.0 B
5 	10 s 	9 	0 	9 	211.4 MB 	0.0 B 	38.9 MB 	0.0 B 	0.0 B

For a stage on mapPartitions at VertexRDD.scala:347
343
344   /** Generates an RDD of vertex attributes suitable for shipping to 
the edge partitions. */
345   private[graphx] def shipVertexAttributes(
346       shipSrc: Boolean, shipDst: Boolean): RDD[(PartitionID, 
VertexAttributeBlock[VD])] = {
347 
partitionsRDD.mapPartitions(_.flatMap(_.shipVertexAttributes(shipSrc, 
shipDst)))
348   }
349

This is executed for every iteration in Pregel, so the imbalance is bad 
for performance.

However, when run PageRank with Edge2D, the tasks are even across 
executors. (all finish 6 tasks)
Our configuration is 6 node, 36 partitions.

My questions is:

    What decides the number of tasks for different executors? And how to
    make it balance?

Thanks!
Larry


--------------010807040009060509060807--

From dev-return-9587-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 17:55:24 2014
Return-Path: <dev-return-9587-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EC2EA17E75
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 17:55:23 +0000 (UTC)
Received: (qmail 8247 invoked by uid 500); 25 Sep 2014 17:55:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8176 invoked by uid 500); 25 Sep 2014 17:55:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8164 invoked by uid 99); 25 Sep 2014 17:55:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 17:55:22 +0000
X-ASF-Spam-Status: No, hits=0.7 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_HELO_PASS,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [157.56.110.144] (HELO na01-bn1-obe.outbound.protection.outlook.com) (157.56.110.144)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 17:54:54 +0000
Received: from BLUPR02CA024.namprd02.prod.outlook.com (25.160.23.142) by
 BN1PR02MB199.namprd02.prod.outlook.com (10.242.214.154) with Microsoft SMTP
 Server (TLS) id 15.0.1034.13; Thu, 25 Sep 2014 17:54:50 +0000
Received: from BN1AFFO11FD024.protection.gbl (2a01:111:f400:7c10::170) by
 BLUPR02CA024.outlook.office365.com (2a01:111:e400:8ad::14) with Microsoft
 SMTP Server (TLS) id 15.0.1039.15 via Frontend Transport; Thu, 25 Sep 2014
 17:54:50 +0000
Received: from atltwp01.amd.com (165.204.84.221) by
 BN1AFFO11FD024.mail.protection.outlook.com (10.58.52.84) with Microsoft SMTP
 Server id 15.0.1029.15 via Frontend Transport; Thu, 25 Sep 2014 17:54:50
 +0000
X-WSS-ID: 0NCGXRC-07-G1X-02
X-M-MSG:
Received: from satlvexedge01.amd.com (satlvexedge01.amd.com [10.177.96.28])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by atltwp01.amd.com (Axway MailGate 5.3.1) with ESMTPS id 2E8DDCAE81A
	for <dev@spark.apache.org>; Thu, 25 Sep 2014 12:54:48 -0500 (CDT)
Received: from SATLEXDAG01.amd.com (10.181.40.3) by satlvexedge01.amd.com
 (10.177.96.28) with Microsoft SMTP Server (TLS) id 14.3.195.1; Thu, 25 Sep
 2014 12:55:03 -0500
Received: from SATLEXDAG02.amd.com ([fe80::9be:3efa:c185:761d]) by
 SATLEXDAG01.amd.com ([fe80::8d49:ab4e:6950:d9b4%23]) with mapi id
 14.03.0195.001; Thu, 25 Sep 2014 13:54:48 -0400
From: "Mozumder, Monir" <Monir.Mozumder@amd.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Code reading tips Spark source
Thread-Topic: Code reading tips Spark source
Thread-Index: Ac/Y6cvaeceK3LdSSdul66R2DZ3LjA==
Date: Thu, 25 Sep 2014 17:54:49 +0000
Message-ID: <FEFA2B6480B5BA42A32321F1A0399EA84D360649@SATLEXDAG02.amd.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.180.168.240]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-EOPAttributedMessage: 0
X-Forefront-Antispam-Report:
	CIP:165.204.84.221;CTRY:US;IPV:NLI;EFV:NLI;SFV:NSPM;SFS:(10019020)(6009001)(428002)(189002)(199003)(76482002)(83072002)(92726001)(92566001)(101416001)(50466002)(50986999)(229853001)(2351001)(107046002)(107886001)(77982003)(77096002)(86362001)(47776003)(99396003)(105586002)(64706001)(20776003)(120916001)(33656002)(31966008)(23676002)(2656002)(81542003)(106466001)(55846006)(87936001)(53416004)(84676001)(44976005)(97736003)(74662003)(95666004)(46102003)(85306004)(81342003)(54356999)(90102001)(68736004)(83322001)(74502003)(4396001)(85852003)(21056001)(10300001)(2501002)(79102003)(80022003)(110136001);DIR:OUT;SFP:1102;SCL:1;SRVR:BN1PR02MB199;H:atltwp01.amd.com;FPR:;MLV:sfv;PTR:InfoDomainNonexistent;MX:1;A:1;LANG:en;
X-Microsoft-Antispam: UriScan:;
X-Microsoft-Antispam: BCL:0;PCL:0;RULEID:;SRVR:BN1PR02MB199;
X-Forefront-PRVS: 0345CFD558
Received-SPF: None (protection.outlook.com: amd.com does not designate
 permitted sender hosts)
Authentication-Results: spf=none (sender IP is 165.204.84.221)
 smtp.mailfrom=Monir.Mozumder@amd.com; 
X-OriginatorOrg: amd4.onmicrosoft.com
X-Virus-Checked: Checked by ClamAV on apache.org

Rm9sa3MsDQoNCkkgYW0gc3RhcnRpbmcgdG8gZXhwbG9yZSBTcGFyayBmcmFtZXdvcmsgYW5kIGhv
cGVmdWxseSBjb250cmlidXRlIHRvIGl0IGluIGZ1dHVyZS4gSSB3YXMgd29uZGVyaW5nIGlmIHlv
dSBoYXZlIGFueSBkb2N1bWVudGF0aW9uIG9yIHRpcHMgdG8gZ2V0IHVuZGVyc3RhbmRpbmcgdGhl
IGlubmVyIHdvcmtpbmdzIG9mIHRoZSBjb2RlIHF1aWNrbHkuIA0KDQpJIGFtIG5ldyB0byBib3Ro
IFNwYXJrIGFuZCBTY2FsYSBhbmQgYW0gdGFraW5nIGEgbG9vayBhdCB0aGUgKlJkZCouc2NhbGEg
ZmlsZXMgaW4gdGhlIHNvdXJjZSB0cmVlLg0KDQpNeSB1bHRpbWF0ZSBnb2FsIGlzIHRvIG9mZmxv
YWQgc29tZSBvZiB0aGUgY29tcHV0ZSBkb25lIG9uIGEgcGFydGl0aW9uIHRvIHRoZSBHUFUgY29y
ZXMgYXZhaWxhYmxlIG9uIHRoZSBub2RlLiBBbnkgcHJpb3IgYXR0ZW1wdCBvciBkZXNpZ24gZGlz
Y3Vzc2lvbiBkb25lIG9uIHRoYXQgYXNwZWN0Pw0KDQpCZXN0cywNCi1Nb25pcg0KDQoNCg==
DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9588-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 22:07:15 2014
Return-Path: <dev-return-9588-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31CA217AE7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 22:07:15 +0000 (UTC)
Received: (qmail 25985 invoked by uid 500); 25 Sep 2014 22:07:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25914 invoked by uid 500); 25 Sep 2014 22:07:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25895 invoked by uid 99); 25 Sep 2014 22:07:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:07:13 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:07:08 +0000
Received: by mail-oi0-f44.google.com with SMTP id v63so8026073oia.31
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 15:06:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=CMWk9HESPxR7jAKar4LUshtnt18Oij66kLSfYQJ7NSc=;
        b=jWqEM1B1tF5GISWeBmNC5b8K4YLiPVuldnBSPUaK9u4lfzUKxuQkwQBkMKUdFlYCI1
         moNyNl5I5NZKbHcKqTeTLhpIKW8jstSBozO2AVzYS0Fp5Msd6L9uxIImiTTC8q+5l592
         ClsMcgdAWD5sCacnv82AIaSh+16IKeJr2yzCvYB/QoMmHVZWPRy0DISwwuHcXRQW5dt0
         Ve4E4gBhwpeoyB50VpvN+CLTopZXpvPvh7AzNZAdjZX1Mkl4ukHOsAFQR9WkGh8t2xS+
         GCp/XdcuiIXiVfZzYvkR8q6+fGz2ih82fSNyzqistYeoeDu2ARM3pdPm9NswzSq7UGoF
         uI1g==
MIME-Version: 1.0
X-Received: by 10.60.51.227 with SMTP id n3mr16935999oeo.52.1411682807880;
 Thu, 25 Sep 2014 15:06:47 -0700 (PDT)
Received: by 10.202.56.197 with HTTP; Thu, 25 Sep 2014 15:06:47 -0700 (PDT)
In-Reply-To: <CAOhmDzfUW_QL2qk-nMVSFv5WxK8ABBywoQHtJYHfSbf2Dtk57A@mail.gmail.com>
References: <A60E3962126148228353AB835E22CCDB@gmail.com>
	<CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
	<D5A0AF46FBB34F69A738DD802768718D@gmail.com>
	<CAOhmDzfUW_QL2qk-nMVSFv5WxK8ABBywoQHtJYHfSbf2Dtk57A@mail.gmail.com>
Date: Thu, 25 Sep 2014 15:06:47 -0700
Message-ID: <CABPQxsuD1KRpcyqb-BTLVe3jK341d9Go2+SJapf-Z3BeUk1UBg@mail.gmail.com>
Subject: Re: do MIMA checking before all test cases start?
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Yeah we can also move it first. Wouldn't hurt.

On Thu, Sep 25, 2014 at 6:39 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> It might still make sense to make this change if MIMA checks are always
> relatively quick, for the same reason we do style checks first.
>
> On Thu, Sep 25, 2014 at 12:25 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>>
>> yeah, I tried that, but there is always an issue when I ran dev/mima,
>>
>> it always gives me some binary compatibility error on Java API part....
>>
>> so I have to wait for Jenkins' result when fixing MIMA issues
>>
>> --
>> Nan Zhu
>>
>>
>> On Thursday, September 25, 2014 at 12:04 AM, Patrick Wendell wrote:
>>
>> > Have you considered running the mima checks locally? We prefer people
>> > not use Jenkins for very frequent checks since it takes resources away
>> > from other people trying to run tests.
>> >
>> > On Wed, Sep 24, 2014 at 6:44 PM, Nan Zhu <zhunanmcgill@gmail.com
>> > (mailto:zhunanmcgill@gmail.com)> wrote:
>> > > Hi, all
>> > >
>> > > It seems that, currently, Jenkins makes MIMA checking after all test
>> > > cases have finished, IIRC, during the first months we introduced MIMA, we do
>> > > the MIMA checking before running test cases
>> > >
>> > > What's the motivation to adjust this behaviour?
>> > >
>> > > In my opinion, if you have some binary compatibility issues, you just
>> > > need to do some minor changes, but in the current environment, you can only
>> > > get if your change works after all test cases finished (1 hour later...)
>> > >
>> > > Best,
>> > >
>> > > --
>> > > Nan Zhu
>> > >
>> >
>> >
>> >
>>
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9589-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 22:30:05 2014
Return-Path: <dev-return-9589-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BE65517B62
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 22:30:05 +0000 (UTC)
Received: (qmail 60862 invoked by uid 500); 25 Sep 2014 22:30:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60783 invoked by uid 500); 25 Sep 2014 22:30:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60768 invoked by uid 99); 25 Sep 2014 22:30:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:30:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.216.182 as permitted sender)
Received: from [209.85.216.182] (HELO mail-qc0-f182.google.com) (209.85.216.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:29:57 +0000
Received: by mail-qc0-f182.google.com with SMTP id x3so2947107qcv.13
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 15:29:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=wDpoAiZo4cj50SRHEMN9Bt6AJlhpEuIIaHnPdDZWRn0=;
        b=a0w465v+yOkmYM3Z14NVmzmFDtGvUBHrh7RsZskOmnpJi4KbriyJY3nksAiLZxpi+P
         2dxggh0xO4hOlrtDCkPEj9OvXKgXxbjk/Bu25AaMOo1eokB5EY4dGBfimvrHH9XPKlXa
         WZumkWz+xGmbkjD9CeHR1892YakYbZD5aH1Jo9q6ErxGV64oWMjAawP0JGaMdSDcv6Rb
         qn5qPp56OUGDlCDH9AAh9UrvOa7oxpw7vtks6yun+bs6pPQq4jpfurTmyKjzb9546NJ+
         1TrFZANMILKAKwGYuQmUHvZ+4D4rHtEGZd3Jn8HBtcYSn4yTY/L6ue2WgZt4b2VN+EWv
         J5xg==
X-Gm-Message-State: ALoCoQnoYeFAHmKbmPge/3xDGUQ+Pgc7Y5ANlSpNdCwJktVh6LjFZBOFnCM1HaaiznZU6KFX80LS
MIME-Version: 1.0
X-Received: by 10.224.23.131 with SMTP id r3mr23449907qab.90.1411684177323;
 Thu, 25 Sep 2014 15:29:37 -0700 (PDT)
Received: by 10.140.40.199 with HTTP; Thu, 25 Sep 2014 15:29:37 -0700 (PDT)
In-Reply-To: <690632FF3B9C4A7D9308C3ABBFCAAAF1@gmail.com>
References: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
	<690632FF3B9C4A7D9308C3ABBFCAAAF1@gmail.com>
Date: Thu, 25 Sep 2014 15:29:37 -0700
Message-ID: <CACBYxKKaSiaYoz2wy29WLLN-5OYitSXMc6HkLhfs137avcwYEg@mail.gmail.com>
Subject: Re: spark_classpath in core/pom.xml and yarn/porm.xml
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Ye Xianjin <advancedxy@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Sandy Ryza <sandyryza@gmail.com>
Content-Type: multipart/alternative; boundary=001a11c2c5c2ece3270503eb5557
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c5c2ece3270503eb5557
Content-Type: text/plain; charset=UTF-8

Hi Ye,

I think git blame shows me because I fixed the formatting in core/pom.xml,
but I don't actually know the original reason for setting SPARK_CLASSPATH
there.

Do the tests run OK if you take it out?

-Sandy


On Thu, Sep 25, 2014 at 1:59 AM, Ye Xianjin <advancedxy@gmail.com> wrote:

> hi, Sandy Ryza:
>      I believe It's you originally added the SPARK_CLASSPATH in
> core/pom.xml in the org.scalatest section. Does this still needed in 1.1?
>      I noticed this setting because when I looked into the unit-tests.log,
> It shows something below:
> > 14/09/24 23:57:19.246 WARN SparkConf:
> > SPARK_CLASSPATH was detected (set to 'null').
> > This is deprecated in Spark 1.0+.
> >
> > Please instead use:
> >  - ./spark-submit with --driver-class-path to augment the driver
> classpath
> >  - spark.executor.extraClassPath to augment the executor classpath
> >
> > 14/09/24 23:57:19.246 WARN SparkConf: Setting
> 'spark.executor.extraClassPath' to 'null' as a work-around.
> > 14/09/24 23:57:19.247 WARN SparkConf: Setting
> 'spark.driver.extraClassPath' to 'null' as a work-around.
>
> However I didn't set SPARK_CLASSPATH env variable. And looked into the
> SparkConf.scala, If user actually set extraClassPath,  the SparkConf will
> throw SparkException.
> --
> Ye Xianjin
> Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
>
>
> On Tuesday, September 23, 2014 at 12:56 AM, Ye Xianjin wrote:
>
> > Hi:
> >     I notice the scalatest-maven-plugin set SPARK_CLASSPATH environment
> variable for testing. But in the SparkConf.scala, this is deprecated in
> Spark 1.0+.
> >     So what this variable for? should we just remove this variable?
> >
> >
> > --
> > Ye Xianjin
> > Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
> >
>
>

--001a11c2c5c2ece3270503eb5557--

From dev-return-9590-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Sep 25 22:36:59 2014
Return-Path: <dev-return-9590-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 467F417B86
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 25 Sep 2014 22:36:59 +0000 (UTC)
Received: (qmail 74192 invoked by uid 500); 25 Sep 2014 22:36:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74120 invoked by uid 500); 25 Sep 2014 22:36:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74109 invoked by uid 99); 25 Sep 2014 22:36:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:36:57 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.180 as permitted sender)
Received: from [209.85.216.180] (HELO mail-qc0-f180.google.com) (209.85.216.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 25 Sep 2014 22:36:32 +0000
Received: by mail-qc0-f180.google.com with SMTP id l6so5540797qcy.39
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 15:36:30 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=t6TbqF+kIQjXFqdW2oEjKrjX12LRxpy0yiNTiINRQf0=;
        b=LGNUyzDFv4zsb+8Zf7b3WWPX2/RaOg9tnA63htNJUzFp93Fp3Y7IM0AomSX31VC/tW
         /n+grd4Yt5YhtoD+/KdFShWVmObwrgsUA2bSZGsDi4pyChF+qQBp0lRfGwOvh+xCJPGs
         1t550AjGymQTKvy6l9rBtolMSr0aVPMGWMKbhJiUrymQvJ+pMehHlevT8LAhNv/Ux0Fp
         aRSnZBE5QBzi2O4ygv8GRa+W/vCV26jfvvUKbFR6Pu61mbgmRI9FmQVCBKRnMgtKU1+B
         VbkDnXWzL+G+4PrJe1kxIfMeyd7D/52rz+jPFc6afP3yA8GZ+p4rHpiESy94TgMg55j7
         LNxA==
X-Gm-Message-State: ALoCoQmTWA1elgE5cM5+SAEtlyHtUaaWBkFq1FutnPDPK/5gnXlweF4raTO15jd5IXcHfyibMVBg
MIME-Version: 1.0
X-Received: by 10.229.140.70 with SMTP id h6mr22417857qcu.3.1411684589558;
 Thu, 25 Sep 2014 15:36:29 -0700 (PDT)
Received: by 10.229.154.201 with HTTP; Thu, 25 Sep 2014 15:36:29 -0700 (PDT)
In-Reply-To: <CACBYxKKaSiaYoz2wy29WLLN-5OYitSXMc6HkLhfs137avcwYEg@mail.gmail.com>
References: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
	<690632FF3B9C4A7D9308C3ABBFCAAAF1@gmail.com>
	<CACBYxKKaSiaYoz2wy29WLLN-5OYitSXMc6HkLhfs137avcwYEg@mail.gmail.com>
Date: Thu, 25 Sep 2014 15:36:29 -0700
Message-ID: <CAAOnQ7vYxVmRzz53N+yV81uqjT9dVxGJ-to_Pcv1VAeFzC8Lcg@mail.gmail.com>
Subject: Re: spark_classpath in core/pom.xml and yarn/porm.xml
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: Ye Xianjin <advancedxy@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Sandy Ryza <sandyryza@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

BTW I removed it from the yarn pom since it was not used (and actually
interfered with a test I was writing).

I did not touch the core pom, but I wouldn't be surprised if it's not
needed there either.

On Thu, Sep 25, 2014 at 3:29 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:
> Hi Ye,
>
> I think git blame shows me because I fixed the formatting in core/pom.xml,
> but I don't actually know the original reason for setting SPARK_CLASSPATH
> there.
>
> Do the tests run OK if you take it out?
>
> -Sandy
>
>
> On Thu, Sep 25, 2014 at 1:59 AM, Ye Xianjin <advancedxy@gmail.com> wrote:
>
>> hi, Sandy Ryza:
>>      I believe It's you originally added the SPARK_CLASSPATH in
>> core/pom.xml in the org.scalatest section. Does this still needed in 1.1?
>>      I noticed this setting because when I looked into the unit-tests.log,
>> It shows something below:
>> > 14/09/24 23:57:19.246 WARN SparkConf:
>> > SPARK_CLASSPATH was detected (set to 'null').
>> > This is deprecated in Spark 1.0+.
>> >
>> > Please instead use:
>> >  - ./spark-submit with --driver-class-path to augment the driver
>> classpath
>> >  - spark.executor.extraClassPath to augment the executor classpath
>> >
>> > 14/09/24 23:57:19.246 WARN SparkConf: Setting
>> 'spark.executor.extraClassPath' to 'null' as a work-around.
>> > 14/09/24 23:57:19.247 WARN SparkConf: Setting
>> 'spark.driver.extraClassPath' to 'null' as a work-around.
>>
>> However I didn't set SPARK_CLASSPATH env variable. And looked into the
>> SparkConf.scala, If user actually set extraClassPath,  the SparkConf will
>> throw SparkException.
>> --
>> Ye Xianjin
>> Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
>>
>>
>> On Tuesday, September 23, 2014 at 12:56 AM, Ye Xianjin wrote:
>>
>> > Hi:
>> >     I notice the scalatest-maven-plugin set SPARK_CLASSPATH environment
>> variable for testing. But in the SparkConf.scala, this is deprecated in
>> Spark 1.0+.
>> >     So what this variable for? should we just remove this variable?
>> >
>> >
>> > --
>> > Ye Xianjin
>> > Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
>> >
>>
>>



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9591-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 02:07:56 2014
Return-Path: <dev-return-9591-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D2B61731D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 02:07:56 +0000 (UTC)
Received: (qmail 57282 invoked by uid 500); 26 Sep 2014 02:07:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57207 invoked by uid 500); 26 Sep 2014 02:07:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57195 invoked by uid 99); 26 Sep 2014 02:07:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 02:07:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of advancedxy@gmail.com designates 209.85.192.175 as permitted sender)
Received: from [209.85.192.175] (HELO mail-pd0-f175.google.com) (209.85.192.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 02:07:28 +0000
Received: by mail-pd0-f175.google.com with SMTP id v10so10607229pde.34
        for <dev@spark.apache.org>; Thu, 25 Sep 2014 19:07:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=dD79LE5z4Lcjxu0xlELUEGkze/9n466FA8Co5zTGJ4A=;
        b=IK1BXiSP7V6VGKKn64Mgw6RZAQq2HAhgtDsShmbxPzLdroD2B0su9PSb4fYQl0LS1c
         2ncL15W1E5k7BPWocE/tXFGLqJmwXLXCwovaz49mgNhUXjs2hfn3fv3ZnBFUzhGli6xA
         gbDG7gcKFAhCUaYAhP6HK4fV9LGprNFrZ0M9IvrcLOA6CkEh/NlIyPSph7KzTn1MABOC
         7WSiFlQofHlj7hCKPq5uNyRv4GyQj+xek/9KNlHMVEUQHDIS6GVTWwzshwtY3bLseV+T
         DPIWSz83A8kAl0sfsjds4vA/3beGpxHKnSslWXxpmWfiSChmpRR329Ojfsl7XM1QsWmd
         R4ZA==
X-Received: by 10.66.190.169 with SMTP id gr9mr24396321pac.3.1411697246893;
        Thu, 25 Sep 2014 19:07:26 -0700 (PDT)
Received: from [172.16.100.217] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id fr7sm3329907pdb.79.2014.09.25.19.07.24
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Thu, 25 Sep 2014 19:07:26 -0700 (PDT)
Date: Fri, 26 Sep 2014 10:07:21 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: Sandy Ryza <sandy.ryza@cloudera.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Marcelo
 Vanzin <vanzin@cloudera.com>
Message-ID: <6C4E1D51765642FCAB57990AAEC3C2D3@gmail.com>
In-Reply-To: <CACBYxKKaSiaYoz2wy29WLLN-5OYitSXMc6HkLhfs137avcwYEg@mail.gmail.com>
References: <4F75170EFB374DB2A5437870097FBEBA@gmail.com>
 <690632FF3B9C4A7D9308C3ABBFCAAAF1@gmail.com>
 <CACBYxKKaSiaYoz2wy29WLLN-5OYitSXMc6HkLhfs137avcwYEg@mail.gmail.com>
Subject: Re: spark_classpath in core/pom.xml and yarn/pom.xml
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5424ca59_25413bec_9ea"
X-Virus-Checked: Checked by ClamAV on apache.org

--5424ca59_25413bec_9ea
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Hi Sandy, 

Sorry for the bothering. 

The tests run ok even the SPARK_CLASS setting is there now, but It gives a config warning and will potential interfere other settings like Marcelo said. The warning goes away if I remove it out.

And Marcelo, I believe the setting in core/pom should not be used any more. But I don't think it's worthy to file a JIRA for such small change. Maybe put it into other related JIRA. It's a pity that your pr
already got merged.
     

-- 
Ye Xianjin
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)


On Friday, September 26, 2014 at 6:29 AM, Sandy Ryza wrote:

> Hi Ye,
> 
> I think git blame shows me because I fixed the formatting in core/pom.xml, but I don't actually know the original reason for setting SPARK_CLASSPATH there.
> 
> Do the tests run OK if you take it out?
> 
> -Sandy
> 
> 
> On Thu, Sep 25, 2014 at 1:59 AM, Ye Xianjin <advancedxy@gmail.com (mailto:advancedxy@gmail.com)> wrote:
> > hi, Sandy Ryza:
> >      I believe It's you originally added the SPARK_CLASSPATH in core/pom.xml in the org.scalatest section. Does this still needed in 1.1?
> >      I noticed this setting because when I looked into the unit-tests.log, It shows something below:
> > > 14/09/24 23:57:19.246 WARN SparkConf:
> > > SPARK_CLASSPATH was detected (set to 'null').
> > > This is deprecated in Spark 1.0+.
> > >
> > > Please instead use:
> > >  - ./spark-submit with --driver-class-path to augment the driver classpath
> > >  - spark.executor.extraClassPath to augment the executor classpath
> > >
> > > 14/09/24 23:57:19.246 WARN SparkConf: Setting 'spark.executor.extraClassPath' to 'null' as a work-around.
> > > 14/09/24 23:57:19.247 WARN SparkConf: Setting 'spark.driver.extraClassPath' to 'null' as a work-around.
> > 
> > However I didn't set SPARK_CLASSPATH env variable. And looked into the SparkConf.scala, If user actually set extraClassPath,  the SparkConf will throw SparkException.
> > --
> > Ye Xianjin
> > Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
> > 
> > 
> > On Tuesday, September 23, 2014 at 12:56 AM, Ye Xianjin wrote:
> > 
> > > Hi:
> > >     I notice the scalatest-maven-plugin set SPARK_CLASSPATH environment variable for testing. But in the SparkConf.scala, this is deprecated in Spark 1.0+.
> > >     So what this variable for? should we just remove this variable?
> > >
> > >
> > > --
> > > Ye Xianjin
> > > Sent with Sparrow (http://www.sparrowmailapp.com/?sig)
> > >
> > 
> 


--5424ca59_25413bec_9ea--


From dev-return-9592-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 10:09:31 2014
Return-Path: <dev-return-9592-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0EBA717D03
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 10:09:31 +0000 (UTC)
Received: (qmail 48806 invoked by uid 500); 26 Sep 2014 10:09:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48733 invoked by uid 500); 26 Sep 2014 10:09:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48720 invoked by uid 99); 26 Sep 2014 10:09:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 10:09:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yanbohappy@gmail.com designates 209.85.213.47 as permitted sender)
Received: from [209.85.213.47] (HELO mail-yh0-f47.google.com) (209.85.213.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 10:09:02 +0000
Received: by mail-yh0-f47.google.com with SMTP id 29so168689yhl.20
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 03:09:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=UdoNndWp4sX+bX2+I7WQboZBbCOvVMv246u+qVaa1Vc=;
        b=Ni/cKsTd5DbE1D31HCj1NGFkCeHQ7B7dQnNaueqkyiGA1RIsfNXWU1YJNKuF3GoAc7
         M2oZ4qVt51xwuJe0+n4FDWqPf0u8crrBGk6BWdnnfyfY3huhn7sehkJbvgx78rucjK6s
         G43tBxF0qWxgHn4HC+8jcPRQy36ZaGbYHjXYXCM+8o73DIZ6OA9LjRj7uNA0UGw5+O7H
         B+d5SibUgkPzBLpgTRCl0MGHwstA3UoC+2KekNnBgoDhH9w/4fmNOI+yQ0Xl7eAszGOt
         ZB4y4Qr6TBKhNddYnq0b0YaeuKNvbJK8z0uXD3FM8Blgwjrz2Apnqv27VFa0AvuwROqW
         8t0g==
MIME-Version: 1.0
X-Received: by 10.236.92.107 with SMTP id i71mr15500014yhf.89.1411726141196;
 Fri, 26 Sep 2014 03:09:01 -0700 (PDT)
Received: by 10.170.82.215 with HTTP; Fri, 26 Sep 2014 03:09:01 -0700 (PDT)
In-Reply-To: <CAP4y_1r04Xq-fG3z8BgNy++720OC7rvU-d9bNTzRmgBiJiCX_g@mail.gmail.com>
References: <CAP4y_1r04Xq-fG3z8BgNy++720OC7rvU-d9bNTzRmgBiJiCX_g@mail.gmail.com>
Date: Fri, 26 Sep 2014 18:09:01 +0800
Message-ID: <CALDQvde2zJRvQVGGZckE_ZrtY6ZThhPRSoEj4E5DDLq0++RJFg@mail.gmail.com>
Subject: Re: A Spark Compilation Question
From: Yanbo Liang <yanbohappy@gmail.com>
To: Hansu GU <guhansu@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=14dae9d2f45e2a91460503f51b16
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae9d2f45e2a91460503f51b16
Content-Type: text/plain; charset=UTF-8

Hi Hansu,

I have encountered the same problem. Maven compiled avro file and generated
corresponding Java file in new directory which is not source file directory
of the project.

I have modified pom.xml file and it can be work.
The line marked as red is added, you can add them to your
spark-*.*.*/external/flume-sink/pom.xml.

    <plugin>
        <groupId>org.apache.avro</groupId>
        <artifactId>avro-maven-plugin</artifactId>
        <version>${avro.version}</version>
        <configuration>
          <!-- Generate the output in the same directory as the
sbt-avro-plugin -->

<outputDirectory>${project.basedir}/target/scala-${scala.binary.version}/src_managed/main/compiled_avro</outputDirectory>
  <outputDirectory>${project.basedir}/src/main/java</outputDirectory>
        </configuration>
        <executions>
          <execution>
            <phase>generate-sources</phase>
            <goals>
              <goal>idl-protocol</goal>
            </goals>
          </execution>
        </executions>
      </plugin>

    <plugin>
    <groupId>org.codehaus.mojo</groupId>
<artifactId>build-helper-maven-plugin</artifactId>
<version>1.9.1</version>
<executions>
  <execution>
<id>add-source</id>
<phase>generate-sources</phase>
<goals>
  <goal>add-source</goal>
</goals>
    <configuration>
      <sources>
  <source>${project.basedir}/src/main/java</source>
  </sources>
    </configuration>
  </execution>
    </executions>
  </plugin>




2014-09-13 2:45 GMT+08:00 Hansu GU <guhansu@gmail.com>:

> I downloaded the source and imported it into IntelliJ 13.1 as a Maven
> project.
>
> When I used IntelliJ Build -> make Project, I encountered:
>
> Error:(44, 66) not found: type SparkFlumeProtocol val
> transactionTimeout: Int, val backOffInterval: Int) extends
> SparkFlumeProtocol with Logging {
>
> I think there are some avro generated files missing but I am not sure.
> Could anyone help me understand this in order to successfully compile
> the source?
>
> Thanks,
> Hansu
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--14dae9d2f45e2a91460503f51b16--

From dev-return-9593-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 12:02:32 2014
Return-Path: <dev-return-9593-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 70F8717FB1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 12:02:32 +0000 (UTC)
Received: (qmail 7640 invoked by uid 500); 26 Sep 2014 12:02:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7529 invoked by uid 500); 26 Sep 2014 12:02:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6592 invoked by uid 99); 26 Sep 2014 12:02:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:02:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of praveen.seluka@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:02:03 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so879036pdj.17
        for <multiple recipients>; Fri, 26 Sep 2014 05:02:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=in+ipb+cErVoUxDE8GxOZKyUBbQsYHmATEgwL84mxLI=;
        b=B4HtJ5X8AlOC2CHSrA5UGgXmEDpIIlJoPkaX0J/W3wC5m12U7FDaNoivN+qs7oItmC
         LtOsE7abVc8WQnJr09eiygtatt4QoSKWthAys3S9KKPsGs9BTuKf78A5tSOvs3r8qN5c
         DKT4s7P6mfHVzIx76Ns81IpVyxOC0DjdBoZXBJDMvH0BpdRWI74n4bwk5PXnpeKE0HO2
         WFaRZgf/SswFSYm8rBHnIeQdBzpwlQBgN0Qry4aXPhSKkTUy5B5ApIeKYI2vKsisanBL
         vOwHanO+jtVPNyTj97di5/biGuLoYHV6uyUYrpKVjzurOt435fFmr/YrRMW0R0LGS9bl
         VmMg==
MIME-Version: 1.0
X-Received: by 10.70.123.42 with SMTP id lx10mr19660636pdb.90.1411732921365;
 Fri, 26 Sep 2014 05:02:01 -0700 (PDT)
Received: by 10.70.76.38 with HTTP; Fri, 26 Sep 2014 05:02:01 -0700 (PDT)
Date: Fri, 26 Sep 2014 17:32:01 +0530
Message-ID: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
Subject: executorAdded event to DAGScheduler
From: praveen seluka <praveen.seluka@gmail.com>
To: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3bdf84bbad80503f6af74
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3bdf84bbad80503f6af74
Content-Type: text/plain; charset=UTF-8

Can someone explain the motivation behind passing executorAdded event to
DAGScheduler ? *DAGScheduler *does *submitWaitingStages *when *executorAdded
*method is called by *TaskSchedulerImpl*. I see some issue in the below
code,

*TaskSchedulerImpl.scala code*
if (!executorsByHost.contains(o.host)) {
        executorsByHost(o.host) = new HashSet[String]()
        executorAdded(o.executorId, o.host)
        newExecAvail = true
      }

Note that executorAdded is called only when there is a new host and not for
every new executor. For instance, there can be two executors in the same
host and in this case. (But DAGScheduler executorAdded is notified only for
new host - so only once in this case). If this is indeed an issue, I would
like to submit a patch for this quickly. [cc Andrew Or]

- Praveen

--001a11c3bdf84bbad80503f6af74--

From dev-return-9594-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 12:03:47 2014
Return-Path: <dev-return-9594-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA6B817FBD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 12:03:47 +0000 (UTC)
Received: (qmail 12043 invoked by uid 500); 26 Sep 2014 12:03:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11934 invoked by uid 500); 26 Sep 2014 12:03:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11007 invoked by uid 99); 26 Sep 2014 12:03:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:03:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of praveen.seluka@gmail.com designates 209.85.192.177 as permitted sender)
Received: from [209.85.192.177] (HELO mail-pd0-f177.google.com) (209.85.192.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:03:19 +0000
Received: by mail-pd0-f177.google.com with SMTP id v10so10901137pde.22
        for <multiple recipients>; Fri, 26 Sep 2014 05:03:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=8P+Lmxn6mdR7qhFA3Ri6Guy+1OqS9jeDT8ChOmsba/E=;
        b=lGplnzYRBGGd3/elZBSs4e3tYnTwx7TT5ySgmK2fgnS1JTwPPrOb/iBVTxraeGKMBe
         +mDRQpY3CAjOojOhZb1rmo6czJ4ykdj9/+5wkx6bA15S5JGY1MOeiq/1864c9aNPSg+F
         /BnJ4a8mVn3mdZAtDHTIP9pwH1bOU10qttISiDaCMiaA+9ZObGdyMpu5xbDhRFrgWRZZ
         EHi44WkM49ZPm0V2CoHG7ltbhJ4HMWgMSwCgHJaOAfXlA3tWjEKfN6NzwEJIzVL+J/Zf
         /XVJA1c1Gs7h5Jb8+H/niWvTdQ+Rlo18E7C+ntjDWnJAGBxgWTVG+vMU24P/ys9SuiYw
         z0+w==
MIME-Version: 1.0
X-Received: by 10.67.15.172 with SMTP id fp12mr12395196pad.4.1411732998023;
 Fri, 26 Sep 2014 05:03:18 -0700 (PDT)
Received: by 10.70.76.38 with HTTP; Fri, 26 Sep 2014 05:03:17 -0700 (PDT)
In-Reply-To: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
References: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
Date: Fri, 26 Sep 2014 17:33:17 +0530
Message-ID: <CAPNBaQ6zF=8goqO0RL3RsyhcT0Hg6baGbs5KW=u=WMhHgXKgFg@mail.gmail.com>
Subject: Re: executorAdded event to DAGScheduler
From: praveen seluka <praveen.seluka@gmail.com>
To: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11361bc0dd71c90503f6b3fa
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11361bc0dd71c90503f6b3fa
Content-Type: text/plain; charset=UTF-8

Some corrections.

On Fri, Sep 26, 2014 at 5:32 PM, praveen seluka <praveen.seluka@gmail.com>
wrote:

> Can someone explain the motivation behind passing executorAdded event to
> DAGScheduler ? *DAGScheduler *does *submitWaitingStages *when *executorAdded
> *method is called by *TaskSchedulerImpl*. I see some issue in the below
> code,
>
> *TaskSchedulerImpl.scala code*
> if (!executorsByHost.contains(o.host)) {
>         executorsByHost(o.host) = new HashSet[String]()
>         executorAdded(o.executorId, o.host)
>         newExecAvail = true
>       }
>
> Note that executorAdded is called only when there is a new host and not
> for every new executor. For instance, there can be two executors in the
> same host and in this case the DAGscheduler is notified only once. If this
> is indeed an issue, I would like to submit a patch for this quickly. [cc
> Andrew Or]
>
> - Praveen
>
>
>

--001a11361bc0dd71c90503f6b3fa--

From dev-return-9595-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 12:21:37 2014
Return-Path: <dev-return-9595-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 246D5171E5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 12:21:37 +0000 (UTC)
Received: (qmail 43304 invoked by uid 500); 26 Sep 2014 12:21:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43215 invoked by uid 500); 26 Sep 2014 12:21:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42133 invoked by uid 99); 26 Sep 2014 12:21:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:21:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:21:28 +0000
Received: by mail-ie0-f175.google.com with SMTP id y20so731077ier.6
        for <multiple recipients>; Fri, 26 Sep 2014 05:21:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=u7w+XmP6qOsrHX6cLS2WUFQHx+DA26NmpkZ1YeDASic=;
        b=twwSbE+21NV1RjJ0mpQU4qCUaL6lAiUiZtC45jW64V01tBI/cTCtTXQW+2Rnx3KuCs
         ICzxA0D7vwcecfpUup4ruR3wZQg388jaw9l4IORjxcA0IW0AGi5py4U6TodcWRUiTMsD
         mxTqQ/k5BY3pZ8WB3SSxyRCm7Itw1ODWvB7Wf4kNAfQK/pQ+bqJwM36evkCjDZTRX5zn
         Ho/+qUhUkmn8yil6U0PXQCklY9P40iIpzC9GIc1+K9UOPlwH3dCinZnjHmrcSNLh5lzp
         EdU7R2iAa/rCx6+U5L3xxI/szx8rnXdje9bGsuoV2x3AdrGSUbGdfmqQWUqozCYTiUp4
         EN3A==
X-Received: by 10.42.104.144 with SMTP id r16mr26720351ico.65.1411734067539;
        Fri, 26 Sep 2014 05:21:07 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id z2sm1651866igl.16.2014.09.26.05.21.07
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 26 Sep 2014 05:21:07 -0700 (PDT)
Date: Fri, 26 Sep 2014 08:35:42 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: praveen seluka <praveen.seluka@gmail.com>
Cc: dev@spark.apache.org, user@spark.apache.org
Message-ID: <A68B8424D5654850ACB5855A72C17600@gmail.com>
In-Reply-To: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
References: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
Subject: Re: executorAdded event to DAGScheduler
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54255d9e_280e6897_214"
X-Virus-Checked: Checked by ClamAV on apache.org

--54255d9e_280e6897_214
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

just a quick reply, we cannot start two executors in the same host for a =
single application in the standard deployment (one worker per machine) =20

I=E2=80=99m not sure if it will create an issue when you have multiple wo=
rkers in the same host, as submitWaitingStages is called everywhere and I=
 never try such a deployment mode

Best, =20

-- =20
Nan Zhu


On =46riday, September 26, 2014 at 8:02 AM, praveen seluka wrote:

> Can someone explain the motivation behind passing executorAdded event t=
o DAGScheduler =3F DAGScheduler does submitWaitingStages when executorAdd=
ed method is called by TaskSchedulerImpl. I see some issue in the below c=
ode,
> =20
> TaskSchedulerImpl.scala code
> if (=21executorsByHost.contains(o.host)) =7B
>         executorsByHost(o.host) =3D new HashSet=5BString=5D()
>         executorAdded(o.executorId, o.host)
>         newExecAvail =3D true
>       =7D
> =20
> =20
> Note that executorAdded is called only when there is a new host and not=
 for every new executor. =46or instance, there can be two executors in th=
e same host and in this case. (But DAGScheduler executorAdded is notified=
 only for new host - so only once in this case). If this is indeed an iss=
ue, I would like to submit a patch for this quickly. =5Bcc Andrew Or=5D
> =20
> - Praveen
> =20
> =20


--54255d9e_280e6897_214--


From dev-return-9596-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 12:26:36 2014
Return-Path: <dev-return-9596-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F3EFD17200
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 12:26:35 +0000 (UTC)
Received: (qmail 52545 invoked by uid 500); 26 Sep 2014 12:26:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52484 invoked by uid 500); 26 Sep 2014 12:26:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51330 invoked by uid 99); 26 Sep 2014 12:26:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:26:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of praveen.seluka@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 12:26:22 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so911484pdj.31
        for <multiple recipients>; Fri, 26 Sep 2014 05:26:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/0Izu7JToTwDgSm1nYUcr9cd+4gKeP23aCgAJGtUaxU=;
        b=FTjTvyHD4nZN+82IjJnT0hvi4wE+Uchx0zjd3EvfM70OMHTH5p7+96H23k5pGi/6Zy
         78OE8jM6TXg0Gd/ahp8e+VFzS1rb0OIUWDjCKdHnOieGizYGu+L+219XSCyF/ZfjHou1
         uR9WGuLH7fEwpPCsf1M4HMvWsF62ptutEos4pjVcanj7YHpW0qdzfDfDe9p19eIOdkji
         lKACPdkl/2Mc855G7o6FwPri/8nHXQVYpzD+DQqTZjkaNvteYtzc2pPMhN6OP7FpqETm
         bHWwrRQ1w07JAEJ5e6Czh8RPUvVct7ExNiHlXRUKSYeEDJ1CzgnC/IXUCBGsECRDwGMp
         FQrQ==
MIME-Version: 1.0
X-Received: by 10.70.123.42 with SMTP id lx10mr19930060pdb.90.1411734361775;
 Fri, 26 Sep 2014 05:26:01 -0700 (PDT)
Received: by 10.70.76.38 with HTTP; Fri, 26 Sep 2014 05:26:01 -0700 (PDT)
In-Reply-To: <A68B8424D5654850ACB5855A72C17600@gmail.com>
References: <CAPNBaQ5C6Wn26aH1STq6_2vw-KUpsmQ_uXZbOPYz+xsEL6kb6w@mail.gmail.com>
	<A68B8424D5654850ACB5855A72C17600@gmail.com>
Date: Fri, 26 Sep 2014 17:56:01 +0530
Message-ID: <CAPNBaQ7J5UyCaPDS5F2uTzo2fxRfJhpBHO5eB4gcnA7GmqhDCg@mail.gmail.com>
Subject: Re: executorAdded event to DAGScheduler
From: praveen seluka <praveen.seluka@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3bdf826a4b30503f70531
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3bdf826a4b30503f70531
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

In Yarn, we can easily  have multiple containers allocated in the same node=
.

On Fri, Sep 26, 2014 at 6:05 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  just a quick reply, we cannot start two executors in the same host for a
> single application in the standard deployment (one worker per machine)
>
> I=E2=80=99m not sure if it will create an issue when you have multiple wo=
rkers in
> the same host, as submitWaitingStages is called everywhere and I never
> try such a deployment mode
>
> Best,
>
> --
> Nan Zhu
>
> On Friday, September 26, 2014 at 8:02 AM, praveen seluka wrote:
>
> Can someone explain the motivation behind passing executorAdded event to
> DAGScheduler ? *DAGScheduler *does *submitWaitingStages *when *executorAd=
ded
> *method is called by *TaskSchedulerImpl*. I see some issue in the below
> code,
>
> *TaskSchedulerImpl.scala code*
> if (!executorsByHost.contains(o.host)) {
>         executorsByHost(o.host) =3D new HashSet[String]()
>         executorAdded(o.executorId, o.host)
>         newExecAvail =3D true
>       }
>
> Note that executorAdded is called only when there is a new host and not
> for every new executor. For instance, there can be two executors in the
> same host and in this case. (But DAGScheduler executorAdded is notified
> only for new host - so only once in this case). If this is indeed an issu=
e,
> I would like to submit a patch for this quickly. [cc Andrew Or]
>
> - Praveen
>
>
>
>

--001a11c3bdf826a4b30503f70531--

From dev-return-9597-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 19:59:44 2014
Return-Path: <dev-return-9597-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 094B41754A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 19:59:44 +0000 (UTC)
Received: (qmail 36211 invoked by uid 500); 26 Sep 2014 19:59:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36137 invoked by uid 500); 26 Sep 2014 19:59:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36125 invoked by uid 99); 26 Sep 2014 19:59:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 19:59:42 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of aahuja11@gmail.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 19:59:16 +0000
Received: by mail-wi0-f180.google.com with SMTP id q5so173725wiv.1
        for <dev@spark.incubator.apache.org>; Fri, 26 Sep 2014 12:59:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=iqpMIPg4NrmocOhMaAyA4woNdvI9sNGmhVQB27BcGgk=;
        b=0aGHxy1Mv+FfQfYaOaDWRnwAObRBl32lvcA4L7eu77B3ZAN5Nqrh0Krp857bqucBzr
         utjm3q1iM/BGE7IgSp/CVdcHg4+lL1OcDzV4bUBMSzdhRHAF9FwVFyOs/RAXbbupv1fE
         tEtlq8OMan7mBKG9Q+cFf6VgyJo3qU5fC/J0Pv7G99EeKV1MlI1MVvgqzE3BduR58ufG
         BLbb9j8BeXIcyPXs4SB00Yi3aDCm1ZS90tJ8z6txYV2tvSxuQO4K2ZST8K2dFX/wHt96
         HjDwL/8huGL6CKDGWgEIbo9dnR4jmPOowCQglCjGL/2lgYdKnik6L2IdqKulgiQ11e1M
         xGmQ==
X-Received: by 10.180.73.6 with SMTP id h6mr29519934wiv.65.1411761556165; Fri,
 26 Sep 2014 12:59:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.217.129.137 with HTTP; Fri, 26 Sep 2014 12:58:56 -0700 (PDT)
In-Reply-To: <1410832622860-8433.post@n3.nabble.com>
References: <1408655692487-7944.post@n3.nabble.com> <CA+-p3AE4fRQVVwkymAx_fyzE8BPyO7ARjPuL80GHLXvvCV0+Dw@mail.gmail.com>
 <1410832622860-8433.post@n3.nabble.com>
From: Arun Ahuja <aahuja11@gmail.com>
Date: Fri, 26 Sep 2014 15:58:56 -0400
Message-ID: <CAEaWm8VJfBSUzbqPV+=Q0gCNjXmrpdvduFrpVj=cGcwocQw8Dw@mail.gmail.com>
Subject: Re: PARSING_ERROR from kryo
To: npanj <nitinpanj@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d043c7f04101b0c0503fd5ab6
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c7f04101b0c0503fd5ab6
Content-Type: text/plain; charset=UTF-8

I am seeing the same error as well since upgrading to Spark1.1:

14/09/26 15:35:05 ERROR executor.Executor: Exception in task 1032.0 in
stage 5.1 (TID 22449)
com.esotericsoftware.kryo.KryoException: java.io.IOException: failed to
uncompress the chunk: PARSING_ERROR(2)
        at com.esotericsoftware.kryo.io.Input.fill(Input.java:142)
        at com.esotericsoftware.kryo.io.Input.require(Input.java:155)
        at com.esotericsoftware.kryo.io.Input.readInt(Input.java:337)
        at
com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:109)
        at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:610)
        at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:721)
        at
org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:133)
        at
org.apache.spark.serializer.DeserializationStream$$anon$1.getNext(Serializer.scala:133)
        at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:71)
        at
org.apache.spark.storage.BlockManager$LazyProxyIterator$1.hasNext(BlockManager.scala:1082)
        at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
        at
org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
        at
org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)

Out of 6000 tasks 5000 something finish fine, so I don't believe there are
any issues with the serialization and some other datasets everything works
fine. Also the same code, same dataset worked fine with Spark 1.0.2

On Mon, Sep 15, 2014 at 9:57 PM, npanj <nitinpanj@gmail.com> wrote:

> Hi Andrew,
>
> No I could not figure out the root cause. This seems to be
> non-deterministic
> error... I didn't see same error after rerunning same program. But I
> noticed
> same error on a different program.
>
> First I thought that this may be related to SPARK-2878, but @Graham replied
> that this looks irrelevant.
>
>
>
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/PARSING-ERROR-from-kryo-tp7944p8433.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--f46d043c7f04101b0c0503fd5ab6--

From dev-return-9598-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 20:20:35 2014
Return-Path: <dev-return-9598-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 673DF175FC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 20:20:35 +0000 (UTC)
Received: (qmail 83292 invoked by uid 500); 26 Sep 2014 20:20:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83217 invoked by uid 500); 26 Sep 2014 20:20:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83035 invoked by uid 99); 26 Sep 2014 20:20:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:20:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:20:28 +0000
Received: by mail-oi0-f52.google.com with SMTP id a141so8846504oig.11
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 13:20:08 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=64zEESbz/H6bVVrr/daTQ5/IpBbH+nK08IXa9Odl10k=;
        b=AWIGaCPyIXuoenjvlriz2PA/AmNcmuT+o4XUFCxZlaHvSgqGyWCbtUHNX0ayGjnyrb
         MUOoVMi4+ImJtqB9H8V/OQht9YLpamu166+9VW+l1ZeOIxZwk4mLpTULRul3rsXWpp99
         SurHR/7Khh75aQwXDZjl34JuR6nf6t9/iF6XElEPw3D+ud/PW3CtbcTr+cS1Q9aIjVhw
         Y9JTA9473mRbd00rgyyEnt8u635kW77HzZXuZA8oy30SUZ5Mrb1iNM+C5AsW8nTUPhhm
         fCUA25xagb7ySjJrD8mtcZdhUmocixKKYpeQMW3I99z5P7uD+gFyKW8jv1ECfNsB63uX
         8uCw==
X-Gm-Message-State: ALoCoQko6qmeFTIlxRrqyZDEWrpsAwInnF6AVQ9GO3HxQfmjqof9Jj75hMMm/troJCj+X/6i0eJQ
X-Received: by 10.60.175.228 with SMTP id cd4mr13177555oec.83.1411762807907;
 Fri, 26 Sep 2014 13:20:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.202.210.141 with HTTP; Fri, 26 Sep 2014 13:19:47 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 26 Sep 2014 13:19:47 -0700
Message-ID: <CACdU-dSmp+K3rVOOqf0Tpr+h4H9sw3CA3yaEqEd7KEnf91U5oA@mail.gmail.com>
Subject: FYI: jenkins systems patched to fix bash exploit
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bd6b820ac342d0503fda485
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd6b820ac342d0503fda485
Content-Type: text/plain; charset=UTF-8

all of our systems were affected by the shellshock bug, and i've just
patched everything w/the latest fix from redhat:

https://access.redhat.com/articles/1200223

we're not running bash.x86_64 0:4.1.2-15.el6_5.2 on all of our systems.

shane

--047d7bd6b820ac342d0503fda485--

From dev-return-9599-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 20:36:27 2014
Return-Path: <dev-return-9599-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 85D351766C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 20:36:27 +0000 (UTC)
Received: (qmail 11559 invoked by uid 500); 26 Sep 2014 20:36:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11481 invoked by uid 500); 26 Sep 2014 20:36:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11470 invoked by uid 99); 26 Sep 2014 20:36:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:36:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.214.169 as permitted sender)
Received: from [209.85.214.169] (HELO mail-ob0-f169.google.com) (209.85.214.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:36:21 +0000
Received: by mail-ob0-f169.google.com with SMTP id uz6so539956obc.28
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 13:36:00 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=Ig0Tu5OClss6T3LmNIcDM70epwrF53hO2vuyWtbz/x4=;
        b=kV9WR3nmwPXXOOwRKdZ6EcUKY8/P9ESJPIy/zrp0x+fo7XE8wyzJvmK3yKNVb6Jey9
         SKfIxXiVOzvkskHVChAYlctL+nMP5YgtMSjMDvP+sY40F73mcj8sou3O/+6nB17smYHE
         EnozOw54RqHKWvGNhIk3qAroo/HivnJoclMOmM1FJ3tpgD717Y4o5G3sqzjRbrdGLRde
         VElzq0B6oH+L3uNU83ScfNJqoKYoP4mKIbwJhr18vi+W4kjhALQhE2V5pYdIE46rk7rC
         3JpQJw58DxiOqrfTvcXmnh/HCH33CCcAAEbmjpO6an6vue5nLWFnE2bFHtE/pVx9B4Ww
         6m5A==
X-Gm-Message-State: ALoCoQkoD4etdKcRqrtKITorSQXuhpQ7iaTpGt6D8WxD4fqHhzSW9FRNiSvRdAiD+v1wl1r7jPkP
X-Received: by 10.60.142.202 with SMTP id ry10mr13130333oeb.79.1411763760354;
 Fri, 26 Sep 2014 13:36:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.202.210.141 with HTTP; Fri, 26 Sep 2014 13:35:40 -0700 (PDT)
In-Reply-To: <CACdU-dSmp+K3rVOOqf0Tpr+h4H9sw3CA3yaEqEd7KEnf91U5oA@mail.gmail.com>
References: <CACdU-dSmp+K3rVOOqf0Tpr+h4H9sw3CA3yaEqEd7KEnf91U5oA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 26 Sep 2014 13:35:40 -0700
Message-ID: <CACdU-dQNNX6jfYa6zMAM=kqH7gcSQyXUYL7rL1-eOBirxPXhwQ@mail.gmail.com>
Subject: Re: FYI: jenkins systems patched to fix bash exploit
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b47223e7168c60503fddda3
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b47223e7168c60503fddda3
Content-Type: text/plain; charset=UTF-8

>
>
> we're not running bash.x86_64 0:4.1.2-15.el6_5.2 on all of our systems.
>
> s/not/now

:)

--047d7b47223e7168c60503fddda3--

From dev-return-9600-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 20:51:45 2014
Return-Path: <dev-return-9600-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C7124176CE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 20:51:45 +0000 (UTC)
Received: (qmail 45371 invoked by uid 500); 26 Sep 2014 20:51:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45301 invoked by uid 500); 26 Sep 2014 20:51:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45289 invoked by uid 99); 26 Sep 2014 20:51:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:51:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:51:18 +0000
Received: by mail-wg0-f41.google.com with SMTP id k14so10270143wgh.0
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 13:51:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=5XiZm78a6nz9HfkVbMpWf8tBRkkdb8eAUDanKB8PGxM=;
        b=MRwFOWY48oWtIwwyayIbCiwHJOFuehHjtvu78e4K5vLG3Hx1npfMVlLs9yNh1Zm1tl
         GsS/Gh4+Cwh3ghWi8Go++jbrhVdDt0zGdCINQpc27TJJY9H8TeSL8eGijVz9oBSeUWjO
         b4JxAUTw6khZgOxt6hWUlJ4fEsLy0rFiMGfFsksirl0aD9tGVjVKzG1inE0ZrBpbpsUs
         h3F6c+iHpPwaoGhPkYerXnOJsdU7GGHZ7XxacKBxBr5VvuaP693qzPiAz9xbA8hgvjwy
         f1nA48b9lECQtANZfQbucaUvfAeUdRjAPKI5bqSwaGPdqKmWuq8gBrNp3qDS+DSmxc7G
         VWWg==
X-Received: by 10.180.96.36 with SMTP id dp4mr29090063wib.33.1411764678137;
 Fri, 26 Sep 2014 13:51:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Fri, 26 Sep 2014 13:50:38 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 26 Sep 2014 16:50:38 -0400
Message-ID: <CAOhmDzex6UBqUPZ+RXwaJujhAAoc_Axh6Q=TjJ7pH+_LHwvqRw@mail.gmail.com>
Subject: thank you for reviewing our patches
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d04448121259dca0503fe148c
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04448121259dca0503fe148c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I recently came across this mailing list post by Linus Torvalds
<https://lkml.org/lkml/2004/12/20/255> about the value of reviewing even
=E2=80=9Ctrivial=E2=80=9D patches. The following passages stood out to me:

I think that much more important than the patch is the fact that people get
used to the notion that they can change the kernel

=E2=80=A6

So please don=E2=80=99t stop. Yes, those trivial patches *are* a bother. Da=
mn, they
are *horrible*. But at the same time, the devil is in the detail, and they
are needed in the long run. Both the patches themselves, and the people
that grew up on them.

Spark is the first (and currently only) open source project I contribute
regularly to. My first several PRs against the project, as simple as they
were, were definitely patches that I =E2=80=9Cgrew up on=E2=80=9D.

I appreciate the time and effort all the reviewers I=E2=80=99ve interacted =
with
have taken to work with me on my PRs, even when they are =E2=80=9Ctrivial=
=E2=80=9D. And I=E2=80=99m
sure that as I continue to contribute to this project there will be many
more patches that I will =E2=80=9Cgrow up on=E2=80=9D.

Thank you Patrick, Reynold, Josh, Davies, Michael, and everyone else who=E2=
=80=99s
taken time to review one of my patches. I appreciate it!

Nick
=E2=80=8B

--f46d04448121259dca0503fe148c--

From dev-return-9601-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 20:55:29 2014
Return-Path: <dev-return-9601-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 96C05176D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 20:55:29 +0000 (UTC)
Received: (qmail 50621 invoked by uid 500); 26 Sep 2014 20:55:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50547 invoked by uid 500); 26 Sep 2014 20:55:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50536 invoked by uid 99); 26 Sep 2014 20:55:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:55:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 20:55:23 +0000
Received: by mail-ie0-f177.google.com with SMTP id x19so16464375ier.36
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 13:55:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=RiopBrw+D2gw7CnqpCySuP1H4obXDexcevbBsE30o0A=;
        b=FtuBBzhLvH3E+cojehMteUuUjc1oZGwtiKYveRp6Zp4xr1EskA3sHhoau1MbT0tQBo
         TxWKPebwTihQbdWCi638KimdO+EKr5YgxBVvjU+Mb4sW1gS6xHc+qYut+99UZC/v3dcI
         Eqzgb3Pdt3exuuejviWuKXP/30dyowBQbRE06R+M2V8Oli8vV80OYyImv7GUSbM3cvc1
         wsUPyuIOeCX79L0Y74MlCtdRHJZDY68Ob55+EGeFOJUxIl+kL4WgJ3BBA8Ox8EM23Duf
         vhbSoUdq4zB4P5+oZpbtmDJM2ZneNY3JXcGekbLFSHzABsMQESsclD1TNQW8WDUJZV/9
         6JmA==
X-Gm-Message-State: ALoCoQmcjxoKImnNtrXWtXaQSK3mRnKusG/TeMHidj+d+d4tnxsV07DYKwqyd3ODwjsWY9WSVl8C
X-Received: by 10.43.1.135 with SMTP id nq7mr5780968icb.95.1411764902030; Fri,
 26 Sep 2014 13:55:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.163.78 with HTTP; Fri, 26 Sep 2014 13:54:41 -0700 (PDT)
In-Reply-To: <CAOhmDzex6UBqUPZ+RXwaJujhAAoc_Axh6Q=TjJ7pH+_LHwvqRw@mail.gmail.com>
References: <CAOhmDzex6UBqUPZ+RXwaJujhAAoc_Axh6Q=TjJ7pH+_LHwvqRw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Fri, 26 Sep 2014 13:54:41 -0700
Message-ID: <CAPh_B=Zmznv5kLZHtwLmH1S=4SdXYt_uko=ZqbsHaz_kuKb_7A@mail.gmail.com>
Subject: Re: thank you for reviewing our patches
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec50fe6cd7e0c520503fe218d
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec50fe6cd7e0c520503fe218d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Keep the patches coming :)


On Fri, Sep 26, 2014 at 1:50 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I recently came across this mailing list post by Linus Torvalds
> <https://lkml.org/lkml/2004/12/20/255> about the value of reviewing even
> =E2=80=9Ctrivial=E2=80=9D patches. The following passages stood out to me=
:
>
> I think that much more important than the patch is the fact that people g=
et
> used to the notion that they can change the kernel
>
> =E2=80=A6
>
> So please don=E2=80=99t stop. Yes, those trivial patches *are* a bother. =
Damn, they
> are *horrible*. But at the same time, the devil is in the detail, and the=
y
> are needed in the long run. Both the patches themselves, and the people
> that grew up on them.
>
> Spark is the first (and currently only) open source project I contribute
> regularly to. My first several PRs against the project, as simple as they
> were, were definitely patches that I =E2=80=9Cgrew up on=E2=80=9D.
>
> I appreciate the time and effort all the reviewers I=E2=80=99ve interacte=
d with
> have taken to work with me on my PRs, even when they are =E2=80=9Ctrivial=
=E2=80=9D. And I=E2=80=99m
> sure that as I continue to contribute to this project there will be many
> more patches that I will =E2=80=9Cgrow up on=E2=80=9D.
>
> Thank you Patrick, Reynold, Josh, Davies, Michael, and everyone else who=
=E2=80=99s
> taken time to review one of my patches. I appreciate it!
>
> Nick
> =E2=80=8B
>

--bcaec50fe6cd7e0c520503fe218d--

From dev-return-9602-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Sep 26 23:49:34 2014
Return-Path: <dev-return-9602-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D97BC17C7C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 26 Sep 2014 23:49:34 +0000 (UTC)
Received: (qmail 56153 invoked by uid 500); 26 Sep 2014 23:49:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56097 invoked by uid 500); 26 Sep 2014 23:49:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54973 invoked by uid 99); 26 Sep 2014 23:49:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 23:49:31 +0000
X-ASF-Spam-Status: No, hits=0.7 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 98.139.253.105 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [98.139.253.105] (HELO mrout2-b.corp.bf1.yahoo.com) (98.139.253.105)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 26 Sep 2014 23:49:06 +0000
Received: from GQ1-EX10-CAHT18.y.corp.yahoo.com (gq1-ex10-caht18.corp.gq1.yahoo.com [10.73.119.199])
	by mrout2-b.corp.bf1.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8QNmZmZ054206
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Fri, 26 Sep 2014 16:48:36 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT18.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Fri, 26
 Sep 2014 16:48:35 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: SparkSQL: map type MatchError when inserting into Hive table
Thread-Topic: SparkSQL: map type MatchError when inserting into Hive table
Thread-Index: AQHP2eRiBxW/iS7Sl0GSscAsh1RIMA==
Date: Fri, 26 Sep 2014 23:48:34 +0000
Message-ID: <D04B4960.3FBA%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: text/plain; charset="Windows-1252"
Content-ID: <21C3B3FEFC8D4E4B9D50CF570454A266@yforest.corp.yahoo.com>
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 775316004
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I was loading data into a partitioned table on Spark 1.1.0
beeline-thriftserver. The table has complex data types such as map<string,
string> and array<map<string,string>>. The query is like =B3insert overwrit=
e
table a partition (=8A) select =8A=B2 and the select clause worked if run
separately. However, when running the insert query, there was an error as
follows.

The source code of Cast.scala seems to only handle the primitive data
types, which is perhaps why the MatchError was thrown.

I just wonder if this is still work in progress, or I should do it
differently.

Thanks,
Du


----
scala.MatchError: MapType(StringType,StringType,true) (of class
org.apache.spark.sql.catalyst.types.MapType)
       =20
org.apache.spark.sql.catalyst.expressions.Cast.cast$lzycompute(Cast.scala:2
47)
        org.apache.spark.sql.catalyst.expressions.Cast.cast(Cast.scala:247)
        org.apache.spark.sql.catalyst.expressions.Cast.eval(Cast.scala:263)
       =20
org.apache.spark.sql.catalyst.expressions.Alias.eval(namedExpressions.scala
:84)
       =20
org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
y(Projection.scala:66)
       =20
org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
y(Projection.scala:50)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
       =20
org.apache.spark.sql.hive.execution.InsertIntoHiveTable.org$apache$spark$sq
l$hive$execution$InsertIntoHiveTable$$writeToFile$1(InsertIntoHiveTable.sca
la:149)
       =20
org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
File$1.apply(InsertIntoHiveTable.scala:158)
       =20
org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
File$1.apply(InsertIntoHiveTable.scala:158)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
        org.apache.spark.scheduler.Task.run(Task.scala:54)
       =20
org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
       =20
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1
145)
       =20
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:
615)
        java.lang.Thread.run(Thread.java:722)






---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9603-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 01:25:42 2014
Return-Path: <dev-return-9603-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2603717ED0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 01:25:42 +0000 (UTC)
Received: (qmail 97067 invoked by uid 500); 27 Sep 2014 01:25:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96946 invoked by uid 500); 27 Sep 2014 01:25:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96074 invoked by uid 99); 27 Sep 2014 01:25:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 01:25:40 +0000
X-ASF-Spam-Status: No, hits=0.7 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 98.139.253.104 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [98.139.253.104] (HELO mrout1-b.corp.bf1.yahoo.com) (98.139.253.104)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 01:25:14 +0000
Received: from GQ1-EX10-CAHT19.y.corp.yahoo.com (gq1-ex10-caht19.corp.gq1.yahoo.com [10.73.119.200])
	by mrout1-b.corp.bf1.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8R1Odsa051014
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Fri, 26 Sep 2014 18:24:40 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT19.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Fri, 26
 Sep 2014 18:24:38 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: Re: SparkSQL: map type MatchError when inserting into Hive table
Thread-Topic: SparkSQL: map type MatchError when inserting into Hive table
Thread-Index: AQHP2eRiBxW/iS7Sl0GSscAsh1RIMJwUL9GA
Date: Sat, 27 Sep 2014 01:24:38 +0000
Message-ID: <D04B5F4D.3FBF%lidu@yahoo-inc.com>
References: <D04B4960.3FBA%lidu@yahoo-inc.com>
In-Reply-To: <D04B4960.3FBA%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: text/plain; charset="utf-8"
Content-ID: <E6FDE6DC4FCA4A41960F6BCFF8CF7D8C@yforest.corp.yahoo.com>
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 781080000
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9604-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 03:06:50 2014
Return-Path: <dev-return-9604-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 381E21726C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 03:06:50 +0000 (UTC)
Received: (qmail 74178 invoked by uid 500); 27 Sep 2014 03:06:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74108 invoked by uid 500); 27 Sep 2014 03:06:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73015 invoked by uid 99); 27 Sep 2014 03:06:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 03:06:48 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 03:06:41 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so2082331pdj.31
        for <multiple recipients>; Fri, 26 Sep 2014 20:06:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=kAVpxWx6oC+5aQ4iQjTSZc6P5ARrUS4rRMAOGPy2WYU=;
        b=DPvf+pD/44grZox+YBORMBwWz91jjg8OX16CQBdCgfj24u1N9uoSBNvsOFP4uNhqwM
         FWkcgD3KmI4PMT3JC7+M4d9J9/1iy4HH2gVotCN6KB5Q03wHKFn3ePSdzb1h67qUGupJ
         6A+Sti9fTW4qYqN7qHD6q0AoETy9P5kghITLEeT7BHwkcLt+WEd+Y9EkaKU6hkoDyaP8
         ESwcNeMyEvvY6/wwezpKXM4HOPkTP1nDA7x+SWQp1KUHMLYDZY+SC3hPZBE3YuMs1fAK
         qCVqx37TX2L7cuZuAklec/TtzJhEJ7kkKHj3oPxu9T2/S8SAuw7dYzkGoWnu+rcrZp3X
         oZWw==
X-Received: by 10.68.209.169 with SMTP id mn9mr37245438pbc.37.1411787181552;
        Fri, 26 Sep 2014 20:06:21 -0700 (PDT)
Received: from lian-laptop.local ([116.251.221.75])
        by mx.google.com with ESMTPSA id xr10sm6213121pab.35.2014.09.26.20.06.18
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 26 Sep 2014 20:06:20 -0700 (PDT)
Message-ID: <542629A8.5090406@gmail.com>
Date: Sat, 27 Sep 2014 11:06:16 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: Du Li <lidu@yahoo-inc.com.INVALID>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: Re: SparkSQL: map type MatchError when inserting into Hive table
References: <D04B4960.3FBA%lidu@yahoo-inc.com>
In-Reply-To: <D04B4960.3FBA%lidu@yahoo-inc.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Would you mind to provide the DDL of this partitioned table together 
with the query you tried? The stacktrace suggests that the query was 
trying to cast a map into something else, which is not supported in 
Spark SQL. And I doubt whether Hive support casting a complex type to 
some other type.

On 9/27/14 7:48 AM, Du Li wrote:
> Hi,
>
> I was loading data into a partitioned table on Spark 1.1.0
> beeline-thriftserver. The table has complex data types such as map<string,
> string> and array<map<string,string>>. The query is like insert overwrite
> table a partition () select  and the select clause worked if run
> separately. However, when running the insert query, there was an error as
> follows.
>
> The source code of Cast.scala seems to only handle the primitive data
> types, which is perhaps why the MatchError was thrown.
>
> I just wonder if this is still work in progress, or I should do it
> differently.
>
> Thanks,
> Du
>
>
> ----
> scala.MatchError: MapType(StringType,StringType,true) (of class
> org.apache.spark.sql.catalyst.types.MapType)
>          
> org.apache.spark.sql.catalyst.expressions.Cast.cast$lzycompute(Cast.scala:2
> 47)
>          org.apache.spark.sql.catalyst.expressions.Cast.cast(Cast.scala:247)
>          org.apache.spark.sql.catalyst.expressions.Cast.eval(Cast.scala:263)
>          
> org.apache.spark.sql.catalyst.expressions.Alias.eval(namedExpressions.scala
> :84)
>          
> org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
> y(Projection.scala:66)
>          
> org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
> y(Projection.scala:50)
>          scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
>          scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
>          
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable.org$apache$spark$sq
> l$hive$execution$InsertIntoHiveTable$$writeToFile$1(InsertIntoHiveTable.sca
> la:149)
>          
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
> File$1.apply(InsertIntoHiveTable.scala:158)
>          
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
> File$1.apply(InsertIntoHiveTable.scala:158)
>          org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
>          org.apache.spark.scheduler.Task.run(Task.scala:54)
>          
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
>          
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1
> 145)
>          
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:
> 615)
>          java.lang.Thread.run(Thread.java:722)
>
>
>
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9605-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 03:09:00 2014
Return-Path: <dev-return-9605-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C2A1B17277
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 03:09:00 +0000 (UTC)
Received: (qmail 79895 invoked by uid 500); 27 Sep 2014 03:08:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79787 invoked by uid 500); 27 Sep 2014 03:08:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78768 invoked by uid 99); 27 Sep 2014 03:08:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 03:08:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 03:08:31 +0000
Received: by mail-pd0-f170.google.com with SMTP id y13so13805972pdi.15
        for <multiple recipients>; Fri, 26 Sep 2014 20:08:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=kAVpxWx6oC+5aQ4iQjTSZc6P5ARrUS4rRMAOGPy2WYU=;
        b=j5WNK8V7BRA4BcBko5Koh3Z7vwrC1PzmHlhZObd4sihxq3QOxDJ5rMNEJ3stfZptLg
         EcOi95jZsXsk+MS/me9AR1cKem7iy3GUQXEhu1TtyZGpz0eiVc+p4JXnhyaMvq6w5Yf5
         DohEn5qfncxpE5qlA5BEJWqLzhlYSkAwjQQaffUHOyoC+ZqNrSAQU+KSJsFbCjGrTgb3
         7Y82KESuVQ013sN4NgzS0IF/l9CWzyiNsJnzXtviZR3Bbu7WF/qG0EYECPmKFCK8wY2n
         gLILD9H4gPdnDL6C3j+aqEyrR7rt2Cfqa5av7a5SYYhhvJD0ncTaluTtCjwTXWzA48Gb
         DFGw==
X-Received: by 10.69.18.139 with SMTP id gm11mr25513300pbd.94.1411787309832;
        Fri, 26 Sep 2014 20:08:29 -0700 (PDT)
Received: from lian-laptop.local ([116.251.221.75])
        by mx.google.com with ESMTPSA id x3sm6170702pdp.53.2014.09.26.20.08.26
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 26 Sep 2014 20:08:28 -0700 (PDT)
Message-ID: <54262A28.3090504@gmail.com>
Date: Sat, 27 Sep 2014 11:08:24 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: Du Li <lidu@yahoo-inc.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: Re: SparkSQL: map type MatchError when inserting into Hive table
References: <D04B4960.3FBA%lidu@yahoo-inc.com>
In-Reply-To: <D04B4960.3FBA%lidu@yahoo-inc.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Would you mind to provide the DDL of this partitioned table together 
with the query you tried? The stacktrace suggests that the query was 
trying to cast a map into something else, which is not supported in 
Spark SQL. And I doubt whether Hive support casting a complex type to 
some other type.

On 9/27/14 7:48 AM, Du Li wrote:
> Hi,
>
> I was loading data into a partitioned table on Spark 1.1.0
> beeline-thriftserver. The table has complex data types such as map<string,
> string> and array<map<string,string>>. The query is like insert overwrite
> table a partition () select  and the select clause worked if run
> separately. However, when running the insert query, there was an error as
> follows.
>
> The source code of Cast.scala seems to only handle the primitive data
> types, which is perhaps why the MatchError was thrown.
>
> I just wonder if this is still work in progress, or I should do it
> differently.
>
> Thanks,
> Du
>
>
> ----
> scala.MatchError: MapType(StringType,StringType,true) (of class
> org.apache.spark.sql.catalyst.types.MapType)
>
> org.apache.spark.sql.catalyst.expressions.Cast.cast$lzycompute(Cast.scala:2
> 47)
>          org.apache.spark.sql.catalyst.expressions.Cast.cast(Cast.scala:247)
>          org.apache.spark.sql.catalyst.expressions.Cast.eval(Cast.scala:263)
>
> org.apache.spark.sql.catalyst.expressions.Alias.eval(namedExpressions.scala
> :84)
>
> org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
> y(Projection.scala:66)
>
> org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.appl
> y(Projection.scala:50)
>          scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
>          scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
>
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable.org$apache$spark$sq
> l$hive$execution$InsertIntoHiveTable$$writeToFile$1(InsertIntoHiveTable.sca
> la:149)
>
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
> File$1.apply(InsertIntoHiveTable.scala:158)
>
> org.apache.spark.sql.hive.execution.InsertIntoHiveTable$$anonfun$saveAsHive
> File$1.apply(InsertIntoHiveTable.scala:158)
>          org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
>          org.apache.spark.scheduler.Task.run(Task.scala:54)
>
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1
> 145)
>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:
> 615)
>          java.lang.Thread.run(Thread.java:722)
>
>
>
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9606-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 06:50:27 2014
Return-Path: <dev-return-9606-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 102531762F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 06:50:27 +0000 (UTC)
Received: (qmail 34973 invoked by uid 500); 27 Sep 2014 06:50:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34901 invoked by uid 500); 27 Sep 2014 06:50:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34889 invoked by uid 99); 27 Sep 2014 06:50:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 06:50:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of advancedxy@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 06:49:58 +0000
Received: by mail-pa0-f51.google.com with SMTP id eu11so13059187pac.38
        for <dev@spark.apache.org>; Fri, 26 Sep 2014 23:49:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=ZuW+olQISpHamAbvV1cSWLKAnJG2orwRuFEi8RbS8BI=;
        b=LQKuWMm7KubLkyI6ugziTAnDcsKV/NPOQ1RaiEPVIdj4fK/0l7qYRL0p30tLjIK4Es
         7vXdbceqy7cLeEKAK9lAHYjUQ1PwsG6qdPv8xvipAgwZmeOQ+0KCbCosu0i0Wky7L31Q
         tivMy6TPQ7/RBQcf81RH82dAoT7dcPb3F1JGun5f7c59hVlCerKinQNrzWBOiyndwDHt
         toXPsHRsq9KOyVCqk5b/MNVoxGG8aCbewwNTbpcvuvKQOGWV9G3+WrCy3x3DLWfcOY9r
         KkpJTOINSceBbu5E//957kkqaykEvlwtQAQexy0V5pfpTN7tvVICxuYsRKfF+rgm1GnD
         pyew==
X-Received: by 10.70.103.145 with SMTP id fw17mr1112764pdb.169.1411800596592;
        Fri, 26 Sep 2014 23:49:56 -0700 (PDT)
Received: from [172.16.100.217] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id df9sm6628596pdb.66.2014.09.26.23.49.54
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 26 Sep 2014 23:49:56 -0700 (PDT)
Date: Sat, 27 Sep 2014 14:49:50 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Message-ID: <D3E237CA3ABB40D199BF4373E23B0E9A@gmail.com>
In-Reply-To: <CAOhmDzex6UBqUPZ+RXwaJujhAAoc_Axh6Q=TjJ7pH+_LHwvqRw@mail.gmail.com>
References: <CAOhmDzex6UBqUPZ+RXwaJujhAAoc_Axh6Q=TjJ7pH+_LHwvqRw@mail.gmail.com>
Subject: Re: thank you for reviewing our patches
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54265e0e_4e6afb66_838"
X-Virus-Checked: Checked by ClamAV on apache.org

--54265e0e_4e6afb66_838
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline




On Saturday, September 27, 2014 at 4:50 AM, Nicholas Chammas wrote:

> =20
> Spark is the first (and currently only) open source project I contribut=
e
> regularly to. My first several PRs against the project, as simple as th=
ey
> were, were definitely patches that I =E2=80=9Cgrew up on=E2=80=9D

 Yeah, me too. I think I will keep patching. =20
> I appreciate the time and effort all the reviewers I=E2=80=99ve interac=
ted with
> have taken to work with me on my PRs, even when they are =E2=80=9Ctrivi=
al=E2=80=9D. And I=E2=80=99m
> sure that as I continue to contribute to this project there will be man=
y
> more patches that I will =E2=80=9Cgrow up on=E2=80=9D.
> =20
> Thank you Patrick, Reynold, Josh, Davies, Michael, and everyone else wh=
o=E2=80=99s
> taken time to review one of my patches. I appreciate it=21
> =20
> Nick
> =E2=80=8B
> =20
> =20

And yes, the reviewer are very nice and responsive. It's a pleasure commu=
nicating with  =20
the reviewers, Thank you for your time. =20

--54265e0e_4e6afb66_838--


From dev-return-9607-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 21:27:34 2014
Return-Path: <dev-return-9607-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0E40B174F7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 21:27:34 +0000 (UTC)
Received: (qmail 89788 invoked by uid 500); 27 Sep 2014 21:27:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89714 invoked by uid 500); 27 Sep 2014 21:27:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89703 invoked by uid 99); 27 Sep 2014 21:27:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 21:27:32 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 21:27:07 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XXzWD-0007AL-Bl
	for dev@spark.incubator.apache.org; Sat, 27 Sep 2014 14:27:05 -0700
Date: Sat, 27 Sep 2014 14:27:05 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411853225288-8577.post@n3.nabble.com>
Subject: Spark memory regions
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

As I've told before, I am currently writing my master's thesis on storage and
memory usage in Spark. I am currently specifically looking at the different
fractions of memory:

I was able to find 3 memory regions, but it seems to leave some unaccounted
for:
1. spark.shuffle.memoryFraction: 20%
2. spark.storage.memoryFraction: 60%
3. spark.storage.unrollFraction: 20% of spark.storage.memoryFraction = 12%

4a. Unaccounted: 100-(20+60+12)=8%
or, if unrollFraction is not only proportional to, but also resides in
storage.memoryFraction:
4b. Unaccounted: 100-(20+0.8*60+0.2*60)=20%

Question 1: How big is the unaccounted fraction, and what is this used for? 
(Expected answer: Spark environment)

Question 2: What is stored into spark.storage.memoryFraction?
>From the log messages, with all RDDs cached:
14/09/23 10:56:56 INFO MemoryStore: Block broadcast_0 stored as values in
memory (estimated size 184.7 KB, free 47.1 GB)
14/09/23 13:13:11 INFO MemoryStore: Block rdd_1_1 stored as values in memory
(estimated size 1458.0 MB, free 47.1 GB)
Expected answer: broadcast variables, cached RDDs, potentially unrolled
blocks (although not seen in the messages, and not noticeable in the size
reduction in these logmessages)
Remark: If there is nothing else that resides in this area, then in the case
that the user would not use .cache() or .persist(MEMORY), a lot of memory is
kept unused, since the broadcast is connectible small, and unroll, if stored
here, takes a max of 20% of the 60%, right?

Question 3: Which RDDs are not only instantiated, but also actually filled
with data?
I am trying to estimate the dataset I have. I know that because of lazy
evaluation, we can never be certain, but it should be possible to estimate a
minimum. Is it safe to assume that at least the RDDs that are the output of
a sort/shuffle stage, and the ones that the user calls
{cache(),persist(MEMORY),collect()} on, are not only instantiated, but also
filled with data? And are there any other assumptions we can make, for
instance about the other RDDs?

Question 4a: Where is intermediate data between stages stored? 
Question 4b: Where is intermediate data during stages stored? 
When I do not use rdd.cache(), I do not see the memory in
storage.memoryFraction go up. Therefore, I think we can eliminate this
fraction.
The intermediate data from a sort/shuffle uses the ExternalSorter or the
ExternalAppendOnlyMap, which relates to the shuffle portion. Is this data
moved & removed at the end of the stage, or does the next stage retrieve it
from here?
Is there any more intermediate data?
If only RDDs that relate to a sort/shuffle are filled, then I expect it to
be in this area, but it might also be possible that these are moved once the
particular shuffle finishes?

Question 5: If I have sufficient memory (256G), will there be a difference
in execution time between caching no RDDs and caching all RDDs?
I did not expect it, but my intermediate results show a 1.5 to 2x
difference. 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-memory-regions-tp8577.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9608-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 22:00:31 2014
Return-Path: <dev-return-9608-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D8F1C17569
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 22:00:31 +0000 (UTC)
Received: (qmail 19832 invoked by uid 500); 27 Sep 2014 22:00:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19761 invoked by uid 500); 27 Sep 2014 22:00:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19750 invoked by uid 99); 27 Sep 2014 22:00:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 22:00:30 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 22:00:04 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XY027-00084A-2U
	for dev@spark.incubator.apache.org; Sat, 27 Sep 2014 15:00:03 -0700
Date: Sat, 27 Sep 2014 15:00:03 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411855203065-8578.post@n3.nabble.com>
In-Reply-To: <64474308D680D540A4D8151B0F7C03F7027227CE@SHSMSX104.ccr.corp.intel.com>
References: <CABXsDPr=pjEX0C7Pbe6g=+qKn3yZr8mHBeUZiDLw1ZYF60HKig@mail.gmail.com> <64474308D680D540A4D8151B0F7C03F7027227CE@SHSMSX104.ccr.corp.intel.com>
Subject: RE: spark.local.dir and spark.worker.dir not used
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Also, if I am not mistaken, this data is automatically removed after your
run. Be sure to check it while running your program.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/spark-local-dir-and-spark-worker-dir-not-used-tp8529p8578.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9609-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Sep 27 22:08:04 2014
Return-Path: <dev-return-9609-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DFF7D17591
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 27 Sep 2014 22:08:04 +0000 (UTC)
Received: (qmail 25895 invoked by uid 500); 27 Sep 2014 22:08:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25817 invoked by uid 500); 27 Sep 2014 22:08:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25806 invoked by uid 99); 27 Sep 2014 22:08:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 22:08:03 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 27 Sep 2014 22:07:37 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XY09Q-00006o-BP
	for dev@spark.incubator.apache.org; Sat, 27 Sep 2014 15:07:36 -0700
Date: Sat, 27 Sep 2014 15:07:36 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411855656339-8579.post@n3.nabble.com>
In-Reply-To: <CAHc8ag3Vdr845dg9iDwiY9PFVHaLBRp+E5NSdrfU0MJSb8-LoQ@mail.gmail.com>
References: <CAHc8ag2DyArZTLA7dwMVBqcg4_YocOmQ827Wp47k=JuAw0M9qQ@mail.gmail.com> <CABPQxst2HNsdUTNXYqQ=w4rgQ-Qnvo6nJa90ONWEhSvDznCoJQ@mail.gmail.com> <CAHc8ag1HGLawDqJ4cPTKixF9-pxRDt8ibdGbDd9K0z2jO+0t5g@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A0E9AE375@SHSMSX101.ccr.corp.intel.com> <CAHc8ag24FUwgRZ=KKv=q+H00LMOZDp9t2Zp1f8fBD8QrUCqh-Q@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A0E9AE454@SHSMSX101.ccr.corp.intel.com> <CAHc8ag3Vdr845dg9iDwiY9PFVHaLBRp+E5NSdrfU0MJSb8-LoQ@mail.gmail.com>
Subject: Re: memory size for caching RDD
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Use unpersist(), even when not persisted before. 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/memory-size-for-caching-RDD-tp8256p8579.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9610-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 03:26:16 2014
Return-Path: <dev-return-9610-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7111E17A90
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 03:26:16 +0000 (UTC)
Received: (qmail 81486 invoked by uid 500); 28 Sep 2014 03:26:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81356 invoked by uid 500); 28 Sep 2014 03:26:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80564 invoked by uid 99); 28 Sep 2014 03:26:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 03:26:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of xiaodi@sjtu.edu.cn designates 202.112.26.52 as permitted sender)
Received: from [202.112.26.52] (HELO proxy01.sjtu.edu.cn) (202.112.26.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 03:26:05 +0000
Received: from proxy03.sjtu.edu.cn (unknown [202.121.179.33])
	by proxy01.sjtu.edu.cn (Postfix) with ESMTP id BBC262600BA;
	Sun, 28 Sep 2014 11:25:42 +0800 (CST)
Received: from localhost (localhost [127.0.0.1])
	by proxy03.sjtu.edu.cn (Postfix) with ESMTP id A9D93260F53;
	Sun, 28 Sep 2014 11:25:42 +0800 (GMT-8)
X-Virus-Scanned: amavisd-new at 
Received: from proxy03.sjtu.edu.cn ([127.0.0.1])
	by localhost (proxy03.sjtu.edu.cn [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id d5nPKPYAF4HQ; Sun, 28 Sep 2014 11:25:42 +0800 (GMT-8)
Received: from loca.ipads-lab.se.sjtu.edu.cn (unknown [202.120.40.83])
	(Authenticated sender: xiaodi)
	by proxy03.sjtu.edu.cn (Postfix) with ESMTPSA id 284BA260BEB;
	Sun, 28 Sep 2014 11:25:42 +0800 (GMT-8)
Message-ID: <54277FB3.4000301@sjtu.edu.cn>
Date: Sun, 28 Sep 2014 11:25:39 +0800
From: Larry Xiao <xiaodi@sjtu.edu.cn>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.1
MIME-Version: 1.0
To: user@spark.apache.org, dev@spark.apache.org
CC: xiaodi@sjtu.edu.cn
Subject: PageRank execution imbalance, might hurt performance by 6x
Content-Type: multipart/alternative;
 boundary="------------050601090107020201090805"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------050601090107020201090805
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hi all!

I'm running PageRank on GraphX, and I find on some tasks on one machine 
can spend 5~6 times more time than on others, others are perfectly 
balance (around 1 second to finish).
And since time for a stage (iteration) is determined by the slowest 
task, the performance is undesirable.

I don't know if there's any internals that might make execution 
unstable? Like scheduling, garbage collection 

A stage for mapPartitions at GraphImpl.scala:409
> in mapReduceTriplets
> 408     // Map and combine.
> 409     val preAgg = view.edges.partitionsRDD.mapPartitions(_.flatMap {
> 410       case (pid, edgePartition) =>
> 411         // Choose scan method
looks like this:


        Tasks

Index 	ID 	Attempt 	Status 	Locality Level 	Executor 	Launch Time 
Duration  	GC Time 	Accumulators 	Input 	Shuffle Read 	Write Time 
Shuffle Write 	Errors
21 	787 	0 	SUCCESS 	PROCESS_LOCAL 	brick0 	2014/09/28 03:04:42 	7 s 	
	
	333.3 MB (memory) 	4.9 MB 	1 ms 	652.3 KB 	
0 	768 	0 	SUCCESS 	PROCESS_LOCAL 	brick2 	2014/09/28 03:04:42 	7 s 	
	
	531.5 MB (memory) 	8.0 MB 	2 ms 	1321.5 KB 	
9 	775 	0 	SUCCESS 	PROCESS_LOCAL 	brick0 	2014/09/28 03:04:42 	6 s 	
	
	270.4 MB (memory) 	4.1 MB 	1 ms 	659.3 KB 	
15 	781 	0 	SUCCESS 	PROCESS_LOCAL 	brick0 	2014/09/28 03:04:42 	6 s 	
	
	272.7 MB (memory) 	4.3 MB 	1 ms 	658.9 KB 	
3 	769 	0 	SUCCESS 	PROCESS_LOCAL 	brick0 	2014/09/28 03:04:42 	6 s 	
	
	285.5 MB (memory) 	4.4 MB 	1 ms 	658.5 KB 	
6 	774 	0 	SUCCESS 	PROCESS_LOCAL 	brick2 	2014/09/28 03:04:42 	6 s 	
	
	346.8 MB (memory) 	4.6 MB 	1 ms 	657.0 KB 	
12 	780 	0 	SUCCESS 	PROCESS_LOCAL 	brick2 	2014/09/28 03:04:42 	6 s 	
	
	313.2 MB (memory) 	4.4 MB 	1 ms 	645.5 KB 	
18 	786 	0 	SUCCESS 	PROCESS_LOCAL 	brick2 	2014/09/28 03:04:42 	6 s 	
	
	281.7 MB (memory) 	4.2 MB 	1 ms 	660.1 KB 	
1 	771 	0 	SUCCESS 	PROCESS_LOCAL 	brick3 	2014/09/28 03:04:42 	2 s 	
	
	339.1 MB (memory) 	5.1 MB 	1 ms 	657.4 KB 	
7 	777 	0 	SUCCESS 	PROCESS_LOCAL 	brick3 	2014/09/28 03:04:42 	2 s 	
	
	322.8 MB (memory) 	4.9 MB 	1 ms 	654.5 KB 	
13 	783 	0 	SUCCESS 	PROCESS_LOCAL 	brick3 	2014/09/28 03:04:42 	2 s 	
	
	279.8 MB (memory) 	4.6 MB 	1 ms 	655.4 KB 	
19 	789 	0 	SUCCESS 	PROCESS_LOCAL 	brick3 	2014/09/28 03:04:42 	2 s 	
	
	268.4 MB (memory) 	4.4 MB 	1 ms 	658.5 KB 	
16 	784 	0 	SUCCESS 	PROCESS_LOCAL 	brick4 	2014/09/28 03:04:42 	1 s 	
	
	339.1 MB (memory) 	5.1 MB 	1 ms 	660.1 KB 	
11 	776 	0 	SUCCESS 	PROCESS_LOCAL 	brick1 	2014/09/28 03:04:42 	1 s 	
	
	341.0 MB (memory) 	5.3 MB 	1 ms 	655.4 KB 	
2 	773 	0 	SUCCESS 	PROCESS_LOCAL 	brick5 	2014/09/28 03:04:42 	1 s 	
	
	320.9 MB (memory) 	4.9 MB 	1 ms 	655.3 KB 	
22 	790 	0 	SUCCESS 	PROCESS_LOCAL 	brick4 	2014/09/28 03:04:42 	1 s 	
	
	301.7 MB (memory) 	4.9 MB 	1 ms 	659.5 KB 	
17 	782 	0 	SUCCESS 	PROCESS_LOCAL 	brick1 	2014/09/28 03:04:42 	1 s 	
	
	317.1 MB (memory) 	5.2 MB 	1 ms 	653.7 KB 	
23 	788 	0 	SUCCESS 	PROCESS_LOCAL 	brick1 	2014/09/28 03:04:42 	1 s 	
	
	268.3 MB (memory) 	4.9 MB 	1 ms 	664.3 KB 	
8 	779 	0 	SUCCESS 	PROCESS_LOCAL 	brick5 	2014/09/28 03:04:42 	1 s 	
	
	291.3 MB (memory) 	4.6 MB 	1 ms 	660.6 KB 	
20 	791 	0 	SUCCESS 	PROCESS_LOCAL 	brick5 	2014/09/28 03:04:42 	1 s 	
	
	272.7 MB (memory) 	4.5 MB 	1 ms 	661.7 KB 	
10 	778 	0 	SUCCESS 	PROCESS_LOCAL 	brick4 	2014/09/28 03:04:42 	1 s 	
	
	276.5 MB (memory) 	4.4 MB 	1 ms 	656.4 KB 	
4 	772 	0 	SUCCESS 	PROCESS_LOCAL 	brick4 	2014/09/28 03:04:42 	1 s 	
	
	260.8 MB (memory) 	4.4 MB 	1 ms 	661.7 KB 	
14 	785 	0 	SUCCESS 	PROCESS_LOCAL 	brick5 	2014/09/28 03:04:42 	1 s 	
	
	262.7 MB (memory) 	4.3 MB 	1 ms 	651.7 KB 	
5 	770 	0 	SUCCESS 	PROCESS_LOCAL 	brick1 	2014/09/28 03:04:42 	1 s 	
	
	276.5 MB (memory) 	4.7 MB 	1 ms 	655.1 KB 	


Thanks!
Larry

--------------050601090107020201090805--

From dev-return-9611-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 09:25:12 2014
Return-Path: <dev-return-9611-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 20774171E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 09:25:12 +0000 (UTC)
Received: (qmail 75426 invoked by uid 500); 28 Sep 2014 09:25:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75350 invoked by uid 500); 28 Sep 2014 09:25:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75338 invoked by uid 99); 28 Sep 2014 09:25:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:25:10 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.220.49 as permitted sender)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:25:04 +0000
Received: by mail-pa0-f49.google.com with SMTP id lf10so15782327pab.8
        for <dev@spark.apache.org>; Sun, 28 Sep 2014 02:24:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=W9WxGCtrnhF8YmrqZuRnKi0XnETZliMHAi4yeAAtJeY=;
        b=q8pLKd//eVbwxptnvFVe0++35MAMipkxaRffp6i+BVYoW8b7NpM/krGXVj/LKj+tBK
         kibZl13ie+JznJdJFyRWiSe0k+44ZvGaSz1z5exWZcZzb7YQLe408vAh/WqtFkqkC0hW
         gXOVtXoONtHqUvPrRTVs7ynjxb05vNGZckW6lHSN1jOFpcXDC7f7imRAPz51soqEXqS1
         JxuE/fbdAlyskgu8Cheu8YY13rOG0r6CGGv28jlnE6KYEWh0ArgQrEbcOhUT493lwRhL
         1OG9yg4ZAEeh4BB9ZhL7SRL5npbSxRtVgc3Lhp2KF+FzNYU4qqDrlA0UrJ3k9HCnTHM1
         sUDg==
X-Received: by 10.70.123.42 with SMTP id lx10mr38664277pdb.90.1411896282598;
        Sun, 28 Sep 2014 02:24:42 -0700 (PDT)
Received: from [192.168.1.151] ([221.0.15.60])
        by mx.google.com with ESMTPSA id xq4sm9411612pac.21.2014.09.28.02.24.38
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 28 Sep 2014 02:24:41 -0700 (PDT)
Subject: Re: A Spark Compilation Question
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Content-Type: text/plain; charset=us-ascii
From: Yi Tian <tianyi.asiainfo@gmail.com>
In-Reply-To: <CALDQvde2zJRvQVGGZckE_ZrtY6ZThhPRSoEj4E5DDLq0++RJFg@mail.gmail.com>
Date: Sun, 28 Sep 2014 17:24:28 +0800
Cc: Hansu GU <guhansu@gmail.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <E794F018-7A2D-4F81-B058-1577F419D814@gmail.com>
References: <CAP4y_1r04Xq-fG3z8BgNy++720OC7rvU-d9bNTzRmgBiJiCX_g@mail.gmail.com> <CALDQvde2zJRvQVGGZckE_ZrtY6ZThhPRSoEj4E5DDLq0++RJFg@mail.gmail.com>
To: Yanbo Liang <yanbohappy@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

I think you should modify the module settings in IDEA instead of pom.xml


Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com




On Sep 26, 2014, at 18:09, Yanbo Liang <yanbohappy@gmail.com> wrote:

> Hi Hansu,
>=20
> I have encountered the same problem. Maven compiled avro file and =
generated
> corresponding Java file in new directory which is not source file =
directory
> of the project.
>=20
> I have modified pom.xml file and it can be work.
> The line marked as red is added, you can add them to your
> spark-*.*.*/external/flume-sink/pom.xml.
>=20
>    <plugin>
>        <groupId>org.apache.avro</groupId>
>        <artifactId>avro-maven-plugin</artifactId>
>        <version>${avro.version}</version>
>        <configuration>
>          <!-- Generate the output in the same directory as the
> sbt-avro-plugin -->
>=20
> =
<outputDirectory>${project.basedir}/target/scala-${scala.binary.version}/s=
rc_managed/main/compiled_avro</outputDirectory>
>  <outputDirectory>${project.basedir}/src/main/java</outputDirectory>
>        </configuration>
>        <executions>
>          <execution>
>            <phase>generate-sources</phase>
>            <goals>
>              <goal>idl-protocol</goal>
>            </goals>
>          </execution>
>        </executions>
>      </plugin>
>=20
>    <plugin>
>    <groupId>org.codehaus.mojo</groupId>
> <artifactId>build-helper-maven-plugin</artifactId>
> <version>1.9.1</version>
> <executions>
>  <execution>
> <id>add-source</id>
> <phase>generate-sources</phase>
> <goals>
>  <goal>add-source</goal>
> </goals>
>    <configuration>
>      <sources>
>  <source>${project.basedir}/src/main/java</source>
>  </sources>
>    </configuration>
>  </execution>
>    </executions>
>  </plugin>
>=20
>=20
>=20
>=20
> 2014-09-13 2:45 GMT+08:00 Hansu GU <guhansu@gmail.com>:
>=20
>> I downloaded the source and imported it into IntelliJ 13.1 as a Maven
>> project.
>>=20
>> When I used IntelliJ Build -> make Project, I encountered:
>>=20
>> Error:(44, 66) not found: type SparkFlumeProtocol val
>> transactionTimeout: Int, val backOffInterval: Int) extends
>> SparkFlumeProtocol with Logging {
>>=20
>> I think there are some avro generated files missing but I am not =
sure.
>> Could anyone help me understand this in order to successfully compile
>> the source?
>>=20
>> Thanks,
>> Hansu
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9612-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 09:49:09 2014
Return-Path: <dev-return-9612-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C06B517277
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 09:49:09 +0000 (UTC)
Received: (qmail 5443 invoked by uid 500); 28 Sep 2014 09:49:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5293 invoked by uid 500); 28 Sep 2014 09:49:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4312 invoked by uid 99); 28 Sep 2014 09:49:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:49:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yanbohappy@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:48:40 +0000
Received: by mail-wg0-f48.google.com with SMTP id x13so8583588wgg.7
        for <multiple recipients>; Sun, 28 Sep 2014 02:48:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=ElK7FtZW0YzQKDJsGDFaw/UJLXU0XU+QJhro9Xal8HA=;
        b=QBgRaMZT1j63E5SD+WpXEyYKpOQFcIJ+M8TdDwSjlCYKlpJFTC7J1ME+nlq2O7CHja
         vkmGE7hST4x4YZQ/e2W0Px/o+31g1oOmoPg9T/dlRkEcvSAml/wYEBHhl0hzyCGavlrO
         K8zbhRgNgOwUGGSHxY58r8FKxEv/uhpCPm4j/dWc2qHZv7nbdIqw/zE5GwM5QGDVKyrc
         hjY0WeJzSkgAan8b761qwkr9eS/vqBbqQwt/M+QX44ZPIDLFG6OfuWegHGNLIh5/7e3V
         UGDsVttdnAbJpQZfB6doc6hGZJVEno9wTECmaqkBZtNNujbol3YiJmSF5pa0oZkY506Q
         TzSQ==
MIME-Version: 1.0
X-Received: by 10.194.133.135 with SMTP id pc7mr26320881wjb.54.1411897719635;
 Sun, 28 Sep 2014 02:48:39 -0700 (PDT)
Received: by 10.217.107.135 with HTTP; Sun, 28 Sep 2014 02:48:39 -0700 (PDT)
Date: Sun, 28 Sep 2014 17:48:39 +0800
Message-ID: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
Subject: [MLlib] LogisticRegressionWithSGD and LogisticRegressionWithLBFGS
 converge with different weights.
From: Yanbo Liang <yanbohappy@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>, DB Tsai <dbtsai@dbtsai.com>
Content-Type: multipart/alternative; boundary=089e0122978a09c6e005041d0ea7
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122978a09c6e005041d0ea7
Content-Type: text/plain; charset=UTF-8

Hi

We have used LogisticRegression with two different optimization method SGD
and LBFGS in MLlib.
With the same dataset and the same training and test split, but get
different weights vector.

For example, we use
spark-1.1.0/data/mllib/sample_binary_classification_data.txt
as our training and test dataset.
With LogisticRegressionWithSGD and LogisticRegressionWithLBFGS as training
method and the same other parameters.

The precisions of these two methods almost near 100% and AUCs are also near
1.0.
As far as I know, the convex optimization problem will converge to the
global minimum value. (We use SGD with mini batch fraction as 1.0)
But I got two different weights vector? Is this expectation or make sense?

--089e0122978a09c6e005041d0ea7--

From dev-return-9613-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 09:59:43 2014
Return-Path: <dev-return-9613-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C6EDA172AD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 09:59:43 +0000 (UTC)
Received: (qmail 14166 invoked by uid 500); 28 Sep 2014 09:59:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14082 invoked by uid 500); 28 Sep 2014 09:59:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14069 invoked by uid 99); 28 Sep 2014 09:59:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:59:42 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of myasuka@live.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 09:59:16 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <myasuka@live.com>)
	id 1XYBG7-0008WA-Mg
	for dev@spark.incubator.apache.org; Sun, 28 Sep 2014 02:59:15 -0700
Date: Sun, 28 Sep 2014 02:59:15 -0700 (PDT)
From: myasuka <myasuka@live.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411898355683-8583.post@n3.nabble.com>
Subject: How to use multi thread in RDD map function ?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, everyone
    I come across with a problem about increasing the concurency. In a
program, after shuffle write, each node should fetch 16 pair matrices to do
matrix multiplication. such as:

*import breeze.linalg.{DenseMatrix => BDM}

pairs.map(t => {
        val b1 = t._2._1.asInstanceOf[BDM[Double]]
        val b2 = t._2._2.asInstanceOf[BDM[Double]]
     
        val c = (b1 * b2).asInstanceOf[BDM[Double]]

        (new BlockID(t._1.row, t._1.column), c)
      })*
 
    Each node has 16 cores. However, no matter I set 16 tasks or more on
each node, the concurrency cannot be higher than 60%, which means not every
core on the node is computing. Then I check the running log on the WebUI,
according to the amount of shuffle read and write in every task, I see some
task do once matrix multiplication, some do twice while some do none.

    Thus, I think of using java multi thread to increase the concurrency. I
wrote a program in scala which calls java multi thread without Spark on a
single node, by watch the 'top' monitor, I find this program can use CPU up
to 1500% ( means nearly every core are computing). But I have no idea how to
use Java multi thread in RDD transformation.

    Is there any one can provide some example code to use Java multi thread
in RDD transformation, or give any idea to increase the concurrency ?

Thanks for all




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9614-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 11:12:19 2014
Return-Path: <dev-return-9614-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6500017385
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 11:12:19 +0000 (UTC)
Received: (qmail 65849 invoked by uid 500); 28 Sep 2014 11:12:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65779 invoked by uid 500); 28 Sep 2014 11:12:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65767 invoked by uid 99); 28 Sep 2014 11:12:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 11:12:18 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 11:11:52 +0000
Received: by mail-pa0-f54.google.com with SMTP id ey11so4177803pad.41
        for <dev@spark.incubator.apache.org>; Sun, 28 Sep 2014 04:11:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:mime-version:content-type:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=yEkNfyLewyg4DHYOHMRtr707KVDrSqLUNz3rpiR+oiA=;
        b=Qxbf/OdFj/ISKn5WVeTY9MjnN6fk86fXYWDChMUDXpGAFv9cIN2UL1/y3hRbQJC8eC
         x4Y9qfQwJQ7TspU5hfNHoJK8bncNbGm480NkPLH9vhc5bzEA2p7YUS7u3aUYZhN7TxjO
         hg828rxkl2eG0FwTurEOoiAlYPSCdHL5IeboM/4e2oevt/a/FD5hh7+a+X16Hzx1fYSO
         QFIA0er6QS+vtmZ4FciH4DgHFMeQxKueEOVJQa4f5ZXL/vTEoGoYTLeXa9763fb3Q1Yq
         MQPnzQ6DuqpC7CvB05iypi8XSAsRSuQ29ZPbdU14nPgpO7ivG2Cfx7F6LyZlimxedbCH
         gusA==
X-Received: by 10.66.182.227 with SMTP id eh3mr50348323pac.68.1411902710423;
        Sun, 28 Sep 2014 04:11:50 -0700 (PDT)
Received: from [192.168.1.151] ([221.0.15.60])
        by mx.google.com with ESMTPSA id yh3sm9527745pbb.38.2014.09.28.04.11.46
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 28 Sep 2014 04:11:49 -0700 (PDT)
Subject: Re: How to use multi thread in RDD map function ?
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Content-Type: multipart/alternative; boundary="Apple-Mail=_D73159E8-458D-4C2F-8B5A-3BAD5557E21D"
From: Yi Tian <tianyi.asiainfo@gmail.com>
In-Reply-To: <1411898355683-8583.post@n3.nabble.com>
Date: Sun, 28 Sep 2014 19:11:41 +0800
Cc: dev@spark.incubator.apache.org
Message-Id: <D586FA82-26EC-42EA-B02F-BC5EA3F071F9@gmail.com>
References: <1411898355683-8583.post@n3.nabble.com>
To: myasuka <myasuka@live.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_D73159E8-458D-4C2F-8B5A-3BAD5557E21D
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=us-ascii

for yarn-client mode:
=20
SPARK_EXECUTOR_CORES * SPARK_EXECUTOR_INSTANCES =3D 2(or 3) * =
TotalCoresOnYourCluster

for standlone mode:

SPARK_WORKER_INSTANCES * SPARK_WORKER_CORES =3D 2(or 3) * =
TotalCoresOnYourCluster



Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com




On Sep 28, 2014, at 17:59, myasuka <myasuka@live.com> wrote:

> Hi, everyone
>    I come across with a problem about increasing the concurency. In a
> program, after shuffle write, each node should fetch 16 pair matrices =
to do
> matrix multiplication. such as:
>=20
> *import breeze.linalg.{DenseMatrix =3D> BDM}
>=20
> pairs.map(t =3D> {
>        val b1 =3D t._2._1.asInstanceOf[BDM[Double]]
>        val b2 =3D t._2._2.asInstanceOf[BDM[Double]]
>=20
>        val c =3D (b1 * b2).asInstanceOf[BDM[Double]]
>=20
>        (new BlockID(t._1.row, t._1.column), c)
>      })*
>=20
>    Each node has 16 cores. However, no matter I set 16 tasks or more =
on
> each node, the concurrency cannot be higher than 60%, which means not =
every
> core on the node is computing. Then I check the running log on the =
WebUI,
> according to the amount of shuffle read and write in every task, I see =
some
> task do once matrix multiplication, some do twice while some do none.
>=20
>    Thus, I think of using java multi thread to increase the =
concurrency. I
> wrote a program in scala which calls java multi thread without Spark =
on a
> single node, by watch the 'top' monitor, I find this program can use =
CPU up
> to 1500% ( means nearly every core are computing). But I have no idea =
how to
> use Java multi thread in RDD transformation.
>=20
>    Is there any one can provide some example code to use Java multi =
thread
> in RDD transformation, or give any idea to increase the concurrency ?
>=20
> Thanks for all
>=20
>=20
>=20
>=20
> --
> View this message in context: =
http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi=
-thread-in-RDD-map-function-tp8583.html
> Sent from the Apache Spark Developers List mailing list archive at =
Nabble.com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


--Apple-Mail=_D73159E8-458D-4C2F-8B5A-3BAD5557E21D--

From dev-return-9615-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 15:45:04 2014
Return-Path: <dev-return-9615-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B99117632
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 15:45:04 +0000 (UTC)
Received: (qmail 37673 invoked by uid 500); 28 Sep 2014 15:45:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37596 invoked by uid 500); 28 Sep 2014 15:45:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37584 invoked by uid 99); 28 Sep 2014 15:45:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 15:45:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pahomov.egor@gmail.com designates 209.85.216.52 as permitted sender)
Received: from [209.85.216.52] (HELO mail-qa0-f52.google.com) (209.85.216.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 15:44:59 +0000
Received: by mail-qa0-f52.google.com with SMTP id dc16so1847910qab.11
        for <dev@spark.apache.org>; Sun, 28 Sep 2014 08:44:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ITtZy2kgJaUdlvXtsdllIObzSI1SOv/xCvK0TqP0Khc=;
        b=O+twCzNkg2+hZpDFTcaZLI6FJ8PNRtZYxnIzhdQbW6GVO27XyGQmBtf1bPr0jZm723
         IYESjMbL/eq+JxInAhOC8aZ6xuk2e2Zh3DtfId9Mqeit+Y4Y/A24ONVSvnXwboyfRMJ2
         9h3RlW806jI/b5InIiSHpOr2/QsKcv3Neg31wOunX1m64Rs+DS4409QA/DOexVtALhuW
         kHt/gpOyy+TGLdLAgeyHnjW/tiLhLUfxCUy685fTiT4XMSPyNmdbK8frM1Jkj+hzA42c
         WI309hoIPqLft96CxWhZLnZh7jA8l05pdLfHePJzxWOATItGCCCd8Z/DYPf446ysGbSL
         2JOQ==
MIME-Version: 1.0
X-Received: by 10.224.55.201 with SMTP id v9mr46554048qag.36.1411919078766;
 Sun, 28 Sep 2014 08:44:38 -0700 (PDT)
Received: by 10.140.40.243 with HTTP; Sun, 28 Sep 2014 08:44:38 -0700 (PDT)
In-Reply-To: <CAPh_B=YKSX9EzjDb2Pf+tgikPEPyenU3BjTZE9PYyGmbXtY5YA@mail.gmail.com>
References: <CAMrx5Dz9kCR9w_asL8cEAnSh6=ejas8HSSxFQM7d6Rrw7M6QPA@mail.gmail.com>
	<CAPh_B=bKbxfwLxiup3Bbkm6aD_7q3Noi7z-YcV3ph-yCU=JTCQ@mail.gmail.com>
	<CAMrx5Dzxd18Hk9nTeNUyo5TwMuD-964qSCUypixYu0rLEDknWg@mail.gmail.com>
	<CAAsvFPkg1T3ATmbEjbrPN812LU4joFB433pVF47J_Nh0=bNg8w@mail.gmail.com>
	<CAMrx5DxOUJit8P-dLM7mousdMQxzZB=9shoLoK+yomnRhpE9gQ@mail.gmail.com>
	<CAPh_B=YKSX9EzjDb2Pf+tgikPEPyenU3BjTZE9PYyGmbXtY5YA@mail.gmail.com>
Date: Sun, 28 Sep 2014 19:44:38 +0400
Message-ID: <CAMrx5DxDWssZTMjLZCb4=TYF+Ay5e0AO1=2Jcg2nEH3RAMXHWA@mail.gmail.com>
Subject: Re: Workflow Scheduler for Spark
From: Egor Pahomov <pahomov.egor@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Mark Hamstra <mark@clearstorydata.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c30c342442a205042207de
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c30c342442a205042207de
Content-Type: text/plain; charset=UTF-8

I created Jira <https://issues.apache.org/jira/browse/SPARK-3714> and design
doc
<https://docs.google.com/document/d/1q2Q8Ux-6uAkH7wtLJpc3jz-GfrDEjlbWlXtf20hvguk/edit?usp=sharing>
on
this matter.

2014-09-17 22:28 GMT+04:00 Reynold Xin <rxin@databricks.com>:

> There might've been some misunderstanding. I was referring to the MLlib
> pipeline design doc when I said the design doc was posted, in response to
> the first paragraph of your original email.
>
>
> On Wed, Sep 17, 2014 at 2:47 AM, Egor Pahomov <pahomov.egor@gmail.com>
> wrote:
>
> > It's doc about MLLib pipeline functionality. What about oozie-like
> > workflow?
> >
> > 2014-09-17 13:08 GMT+04:00 Mark Hamstra <mark@clearstorydata.com>:
> >
> > > See https://issues.apache.org/jira/browse/SPARK-3530 and this doc,
> > > referenced in that JIRA:
> > >
> > >
> > >
> >
> https://docs.google.com/document/d/1rVwXRjWKfIb-7PI6b86ipytwbUH7irSNLF1_6dLmh8o/edit?usp=sharing
> > >
> > > On Wed, Sep 17, 2014 at 2:00 AM, Egor Pahomov <pahomov.egor@gmail.com>
> > > wrote:
> > >
> > >> I have problems using Oozie. For example it doesn't sustain spark
> > context
> > >> like ooyola job server does. Other than GUI interfaces like HUE it's
> > hard
> > >> to work with - scoozie stopped in development year ago(I spoke with
> > >> creator) and oozie xml very hard to write.
> > >> Oozie still have all documentation and code in MR model rather than in
> > >> yarn
> > >> model. And based on it's current speed of development I can't expect
> > >> radical changes in nearest future. There is no "Databricks" for oozie,
> > >> which would have people on salary to develop this kind of radical
> > changes.
> > >> It's dinosaur.
> > >>
> > >> Reunold, can you help finding this doc? Do you mean just pipelining
> > spark
> > >> code or additional logic of persistence tasks, job server, task retry,
> > >> data
> > >> availability and extra?
> > >>
> > >>
> > >> 2014-09-17 11:21 GMT+04:00 Reynold Xin <rxin@databricks.com>:
> > >>
> > >> > Hi Egor,
> > >> >
> > >> > I think the design doc for the pipeline feature has been posted.
> > >> >
> > >> > For the workflow, I believe Oozie actually works fine with Spark if
> > you
> > >> > want some external workflow system. Do you have any trouble using
> > that?
> > >> >
> > >> >
> > >> > On Tue, Sep 16, 2014 at 11:45 PM, Egor Pahomov <
> > pahomov.egor@gmail.com>
> > >> > wrote:
> > >> >
> > >> >> There are two things we(Yandex) miss in Spark: MLlib good
> > abstractions
> > >> and
> > >> >> good workflow job scheduler. From threads "Adding abstraction in
> > MlLib"
> > >> >> and
> > >> >> "[mllib] State of Multi-Model training" I got the idea, that
> > databricks
> > >> >> working on it and we should wait until first post doc, which would
> > lead
> > >> >> us.
> > >> >> What about workflow scheduler? Is there anyone already working on
> it?
> > >> Does
> > >> >> anyone have a plan on doing it?
> > >> >>
> > >> >> P.S. We thought that MLlib abstractions about multiple algorithms
> run
> > >> with
> > >> >> same data would need such scheduler, which would rerun algorithm in
> > >> case
> > >> >> of
> > >> >> failure. I understand, that spark provide fault tolerance out of
> the
> > >> box,
> > >> >> but we found some "Ooozie-like" scheduler more reliable for such
> long
> > >> >> living workflows.
> > >> >>
> > >> >> --
> > >> >>
> > >> >>
> > >> >>
> > >> >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> > >> >>
> > >> >
> > >> >
> > >>
> > >>
> > >> --
> > >>
> > >>
> > >>
> > >> *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> > >>
> > >
> > >
> >
> >
> > --
> >
> >
> >
> > *Sincerely yoursEgor PakhomovScala Developer, Yandex*
> >
>



-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*

--001a11c30c342442a205042207de--

From dev-return-9616-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 17:35:09 2014
Return-Path: <dev-return-9616-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 85CB3177DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 17:35:09 +0000 (UTC)
Received: (qmail 31613 invoked by uid 500); 28 Sep 2014 17:35:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31442 invoked by uid 500); 28 Sep 2014 17:35:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30855 invoked by uid 99); 28 Sep 2014 17:35:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 17:35:06 +0000
X-ASF-Spam-Status: No, hits=0.7 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 98.139.253.105 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [98.139.253.105] (HELO mrout2-b.corp.bf1.yahoo.com) (98.139.253.105)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 17:34:41 +0000
Received: from GQ1-EX10-CAHT07.y.corp.yahoo.com (gq1-ex10-caht07.corp.gq1.yahoo.com [10.73.118.86])
	by mrout2-b.corp.bf1.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8SHY3U6045934
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Sun, 28 Sep 2014 10:34:04 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT07.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Sun, 28
 Sep 2014 10:34:02 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: Cheng Lian <lian.cs.zju@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: Re: SparkSQL: map type MatchError when inserting into Hive table
Thread-Topic: SparkSQL: map type MatchError when inserting into Hive table
Thread-Index: AQHP2eRiBxW/iS7Sl0GSscAsh1RIMJwUwikAgAIO1QA=
Date: Sun, 28 Sep 2014 17:34:02 +0000
Message-ID: <D04D9384.402C%lidu@yahoo-inc.com>
References: <D04B4960.3FBA%lidu@yahoo-inc.com> <54262A28.3090504@gmail.com>
In-Reply-To: <54262A28.3090504@gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.74.245.26]
Content-Type: text/plain; charset="utf-8"
Content-ID: <C66348C550EC714399B09D540A3FE91F@yforest.corp.yahoo.com>
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 925644002
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9617-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 19:00:12 2014
Return-Path: <dev-return-9617-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BBFF417920
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 19:00:12 +0000 (UTC)
Received: (qmail 1350 invoked by uid 500); 28 Sep 2014 19:00:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1288 invoked by uid 500); 28 Sep 2014 19:00:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 966 invoked by uid 99); 28 Sep 2014 19:00:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:00:04 +0000
X-ASF-Spam-Status: No, hits=2.9 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 98.139.253.105 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [98.139.253.105] (HELO mrout2-b.corp.bf1.yahoo.com) (98.139.253.105)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 18:59:39 +0000
Received: from GQ1-EX10-CAHT06.y.corp.yahoo.com (gq1-ex10-caht06.corp.gq1.yahoo.com [10.73.118.85])
	by mrout2-b.corp.bf1.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8SIxABF082536
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Sun, 28 Sep 2014 11:59:11 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT06.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Sun, 28
 Sep 2014 11:59:10 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: view not supported in spark thrift server?
Thread-Topic: view not supported in spark thrift server?
Thread-Index: AQHP205JzJuFDO47XUasTAIR0XFWrQ==
Date: Sun, 28 Sep 2014 18:59:10 +0000
Message-ID: <D04DA88C.407C%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.74.245.26]
Content-Type: multipart/alternative;
	boundary="_000_D04DA88C407Cliduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 930751001
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D04DA88C407Cliduyahooinccom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable


Can anybody confirm whether or not view is currently supported in spark? I =
found =93create view translate=94 in the blacklist of HiveCompatibilitySuit=
e.scala and also the following scenario threw NullPointerException on beeli=
ne/thriftserver (1.1.0). Any plan to support it soon?


> create table src(k string, v string);

> load data local inpath '/home/y/share/yspark/examples/src/main/resources/=
kv1.txt' into table src;

> create view kv as select k, v from src;

> select * from kv;

Error: java.lang.NullPointerException (state=3D,code=3D0)

--_000_D04DA88C407Cliduyahooinccom_--

From dev-return-9618-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 19:14:33 2014
Return-Path: <dev-return-9618-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C55217974
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 19:14:33 +0000 (UTC)
Received: (qmail 17187 invoked by uid 500); 28 Sep 2014 19:14:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17107 invoked by uid 500); 28 Sep 2014 19:14:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16056 invoked by uid 99); 28 Sep 2014 19:14:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:14:30 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:14:03 +0000
Received: by mail-la0-f43.google.com with SMTP id gb8so7210725lab.2
        for <dev@spark.apache.org>; Sun, 28 Sep 2014 12:14:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=YNrE0eCZVa5tXpjKA5gSxM2nMUJDTBmuB7vTN4kgVPU=;
        b=XMqlk16U1bilCub8lAGy/9jnOw45SbxVGCHXivaJ3yRSarKARqVqLI7A8TQ8XsPCrr
         zyNxz4yhkkCfu/9V/4o4okCxDN+OEVAJJfSdcuRjMnGHyh2htL2aFn5S64wSZumSrnkl
         atcYdDnJYkDibS+uYrk3fLCdgwCdHUdQwmy+WFB4WCDe3q/mfcGU1Q8bkBMX7Gpt5PIZ
         y92fbdl17NsPoa4g4zAnSmuOQK/keshs2sJ6A0ATHgVmsT64tHxsM95fla7k+6xtqFLr
         dfRCRFtxKksVsTCSZ1D3k80kW8XcqN+AEw8HLYK6rKNcDTf/0x+WWF9TIzTH3hxjVUZw
         oMHA==
X-Gm-Message-State: ALoCoQnC+EbDN4/GL3F43LohWNH3NKeu8/GSgCIDbqVi+V0eXEzry8G5AlAien8ZKo2+LAyMqsHl
X-Received: by 10.152.87.193 with SMTP id ba1mr4695259lab.83.1411931642531;
 Sun, 28 Sep 2014 12:14:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.66 with HTTP; Sun, 28 Sep 2014 12:13:42 -0700 (PDT)
In-Reply-To: <D04DA88C.407C%lidu@yahoo-inc.com>
References: <D04DA88C.407C%lidu@yahoo-inc.com>
From: Michael Armbrust <michael@databricks.com>
Date: Sun, 28 Sep 2014 12:13:42 -0700
Message-ID: <CAAswR-4q0crVnnGB_Hf+xbhhuaxWR+Naqr8HiqFckdH1u6Y7nA@mail.gmail.com>
Subject: Re: view not supported in spark thrift server?
To: Du Li <lidu@yahoo-inc.com.invalid>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c345c2002456050424f4cc
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c345c2002456050424f4cc
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Views are not supported yet.  Its not currently on the near term roadmap,
but that can change if there is sufficient demand or someone in the
community is interested in implementing them.  I do not think it would be
very hard.

Michael

On Sun, Sep 28, 2014 at 11:59 AM, Du Li <lidu@yahoo-inc.com.invalid> wrote:

>
>  Can anybody confirm whether or not view is currently supported in spark?
> I found =E2=80=9Ccreate view translate=E2=80=9D in the blacklist of
> HiveCompatibilitySuite.scala and also the following scenario threw
> NullPointerException on beeline/thriftserver (1.1.0). Any plan to support
> it soon?
>
>  > create table src(k string, v string);
>
> > load data local inpath
> '/home/y/share/yspark/examples/src/main/resources/kv1.txt' into table src=
;
>
> > create view kv as select k, v from src;
>
> > select * from kv;
>
> Error: java.lang.NullPointerException (state=3D,code=3D0)
>

--001a11c345c2002456050424f4cc--

From dev-return-9619-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 19:50:40 2014
Return-Path: <dev-return-9619-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 66848179C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 19:50:40 +0000 (UTC)
Received: (qmail 41042 invoked by uid 500); 28 Sep 2014 19:50:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40979 invoked by uid 500); 28 Sep 2014 19:50:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39884 invoked by uid 99); 28 Sep 2014 19:50:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:50:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 216.145.54.173 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [216.145.54.173] (HELO mrout3.yahoo.com) (216.145.54.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:50:12 +0000
Received: from GQ1-EX10-CAHT16.y.corp.yahoo.com (gq1-ex10-caht16.corp.gq1.yahoo.com [10.73.119.197])
	by mrout3.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s8SJnKSI051742
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Sun, 28 Sep 2014 12:49:21 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT16.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Sun, 28
 Sep 2014 12:49:21 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: Michael Armbrust <michael@databricks.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>,
        "user@spark.apache.org"
	<user@spark.apache.org>
Subject: Re: view not supported in spark thrift server?
Thread-Topic: view not supported in spark thrift server?
Thread-Index: AQHP205JzJuFDO47XUasTAIR0XFWrZwXX14A//+UmQA=
Date: Sun, 28 Sep 2014 19:49:20 +0000
Message-ID: <D04DB385.4080%lidu@yahoo-inc.com>
References: <D04DA88C.407C%lidu@yahoo-inc.com>
 <CAAswR-4q0crVnnGB_Hf+xbhhuaxWR+Naqr8HiqFckdH1u6Y7nA@mail.gmail.com>
In-Reply-To: <CAAswR-4q0crVnnGB_Hf+xbhhuaxWR+Naqr8HiqFckdH1u6Y7nA@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.74.245.26]
Content-Type: multipart/alternative;
	boundary="_000_D04DB3854080liduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 933761000
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D04DB3854080liduyahooinccom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

Thanks, Michael, for your quick response.

View is critical for my project that is migrating from shark to spark SQL. =
I have implemented and tested everything else. It would be perfect if view =
could be implemented soon.

Du


From: Michael Armbrust <michael@databricks.com<mailto:michael@databricks.co=
m>>
Date: Sunday, September 28, 2014 at 12:13 PM
To: Du Li <lidu@yahoo-inc.com.invalid<mailto:lidu@yahoo-inc.com.invalid>>
Cc: "dev@spark.apache.org<mailto:dev@spark.apache.org>" <dev@spark.apache.o=
rg<mailto:dev@spark.apache.org>>, "user@spark.apache.org<mailto:user@spark.=
apache.org>" <user@spark.apache.org<mailto:user@spark.apache.org>>
Subject: Re: view not supported in spark thrift server?

Views are not supported yet.  Its not currently on the near term roadmap, b=
ut that can change if there is sufficient demand or someone in the communit=
y is interested in implementing them.  I do not think it would be very hard=
.

Michael

On Sun, Sep 28, 2014 at 11:59 AM, Du Li <lidu@yahoo-inc.com.invalid<mailto:=
lidu@yahoo-inc.com.invalid>> wrote:

Can anybody confirm whether or not view is currently supported in spark? I =
found =93create view translate=94 in the blacklist of HiveCompatibilitySuit=
e.scala and also the following scenario threw NullPointerException on beeli=
ne/thriftserver (1.1.0). Any plan to support it soon?


> create table src(k string, v string);

> load data local inpath '/home/y/share/yspark/examples/src/main/resources/=
kv1.txt' into table src;

> create view kv as select k, v from src;

> select * from kv;

Error: java.lang.NullPointerException (state=3D,code=3D0)


--_000_D04DB3854080liduyahooinccom_--

From dev-return-9620-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Sep 28 19:57:23 2014
Return-Path: <dev-return-9620-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AE266179DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 28 Sep 2014 19:57:23 +0000 (UTC)
Received: (qmail 49380 invoked by uid 500); 28 Sep 2014 19:57:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49301 invoked by uid 500); 28 Sep 2014 19:57:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49288 invoked by uid 99); 28 Sep 2014 19:57:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:57:21 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 28 Sep 2014 19:57:17 +0000
Received: by mail-ie0-f182.google.com with SMTP id tp5so13167950ieb.41
        for <dev@spark.apache.org>; Sun, 28 Sep 2014 12:56:56 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=725Au0sAs4Li0UkT8Fmik5szueK5U+w1WNyEhSTr2gU=;
        b=HVIZA3eEB8jC1X/ko06glxDscvfLDIKtnTNVbuuuqPMuCf/VSC/xS7VzN0+AByCogn
         mHu1AIuO2wSAD2+79YPeo4zZx9nLYeo6wZiXc0qszzfmf8SbjCIYnUQdRsyy01qakxJ/
         aLgOp3lbtTnrzVHd+SJiE5MwQaLzw0+YUx1Y872HfmQnPVIEs7JFDpxozdXuclU6mBKk
         LSEl7gZe8vK96335DtKz9zqKeYEa3o/cSLDQGSBmNVKRfp21V28czl5tmryPASNCN3aA
         hnNTjsajOifsAVhxL6lkx6oyIOQkhjyhUtyshEt/A1JTwSFXq7leXm/ugvCSJxkkerKl
         s0BA==
X-Gm-Message-State: ALoCoQknllGboGt3vushjrZ9Jb9QWd3IWoF/Ez6vWQEztHgiAoZcAg+U1ja4lGi5MAgwyx3JJ3/+
X-Received: by 10.50.122.99 with SMTP id lr3mr29412394igb.10.1411934215886;
 Sun, 28 Sep 2014 12:56:55 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.163.78 with HTTP; Sun, 28 Sep 2014 12:56:34 -0700 (PDT)
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 28 Sep 2014 12:56:35 -0700
Message-ID: <CAPh_B=bAL6yXKT5kzX3XsDnG5iM47rn_YOuZoX_Ly-_DM42PuA@mail.gmail.com>
Subject: Spark meetup on Oct 15 in NYC
To: "dev@spark.apache.org" <dev@spark.apache.org>, user@spark.apache.org
Content-Type: multipart/alternative; boundary=089e0153835a6261430504258d39
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0153835a6261430504258d39
Content-Type: text/plain; charset=UTF-8

Hi Spark users and developers,

Some of the most active Spark developers (including Matei Zaharia, Michael
Armbrust, Joseph Bradley, TD, Paco Nathan, and me) will be in NYC for
Strata NYC. We are working with the Spark NYC meetup group and Bloomberg to
host a meetup event. This might be the event with the highest committer to
user ratio in the history of user meetups. Look forward to meeting more
users in NYC.

You can sign up for that here:
http://www.meetup.com/Spark-NYC/events/209271842/

Cheers.

--089e0153835a6261430504258d39--

From dev-return-9621-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 07:21:51 2014
Return-Path: <dev-return-9621-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7C1AA17565
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 07:21:51 +0000 (UTC)
Received: (qmail 75109 invoked by uid 500); 29 Sep 2014 07:21:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75017 invoked by uid 500); 29 Sep 2014 07:21:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73902 invoked by uid 99); 29 Sep 2014 07:21:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 07:21:48 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.171 as permitted sender)
Received: from [209.85.213.171] (HELO mail-ig0-f171.google.com) (209.85.213.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 07:21:42 +0000
Received: by mail-ig0-f171.google.com with SMTP id h3so2532407igd.16
        for <multiple recipients>; Mon, 29 Sep 2014 00:21:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=QLwlxWRimkhxrWqqCnu7D4e3XrnV9fy/GlD+VpOOMsY=;
        b=Zw0/o4EG657FraMn7+jLf+2WONV4rA0te8+R1puS3LGU5lm11Xd05npgwyUQuze8Aq
         UZWHPUTz6Zpzs+OBHtGA48ZRNSFI8t9mqoecEMM6MWed+xbcX6RyXBlDuE9G7hujTbP/
         M/Z3//RXS6PDC03RG0eJ/+lkVuR469Tzo5tiPeHnIspDtHhas2F2qpifRx7YDZWS1ADL
         IMMFWheuM8MYvE2MK3b8CQENgi2LLIm/bRe4O1TOKzvWdaasw/JVnZe08GBFXutJLa9P
         qt0uYXALSuyvDEzcI6dsT02MHV7X4/eTH8+yi7XMfyafVI9qKwV891lXNK4XahG/GzwO
         t3Aw==
MIME-Version: 1.0
X-Received: by 10.50.117.65 with SMTP id kc1mr50544053igb.34.1411975282184;
 Mon, 29 Sep 2014 00:21:22 -0700 (PDT)
Received: by 10.107.152.3 with HTTP; Mon, 29 Sep 2014 00:21:22 -0700 (PDT)
In-Reply-To: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
References: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
Date: Mon, 29 Sep 2014 00:21:22 -0700
Message-ID: <CAJgQjQ-f6+nsXbBdLs-Mz-uXtJopLbVBSSBS_UHzO8K12-_aNw@mail.gmail.com>
Subject: Re: [MLlib] LogisticRegressionWithSGD and LogisticRegressionWithLBFGS
 converge with different weights.
From: Xiangrui Meng <mengxr@gmail.com>
To: Yanbo Liang <yanbohappy@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>, 
	DB Tsai <dbtsai@dbtsai.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

The test accuracy doesn't mean the total loss. All points between (-1,
1) can separate points -1 and +1 and give you 1.0 accuracy, but their
coressponding loss are different. -Xiangrui

On Sun, Sep 28, 2014 at 2:48 AM, Yanbo Liang <yanbohappy@gmail.com> wrote:
> Hi
>
> We have used LogisticRegression with two different optimization method SGD
> and LBFGS in MLlib.
> With the same dataset and the same training and test split, but get
> different weights vector.
>
> For example, we use
> spark-1.1.0/data/mllib/sample_binary_classification_data.txt as our training
> and test dataset.
> With LogisticRegressionWithSGD and LogisticRegressionWithLBFGS as training
> method and the same other parameters.
>
> The precisions of these two methods almost near 100% and AUCs are also near
> 1.0.
> As far as I know, the convex optimization problem will converge to the
> global minimum value. (We use SGD with mini batch fraction as 1.0)
> But I got two different weights vector? Is this expectation or make sense?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9622-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 08:06:01 2014
Return-Path: <dev-return-9622-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 73B0717618
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 08:06:01 +0000 (UTC)
Received: (qmail 24520 invoked by uid 500); 29 Sep 2014 08:06:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24442 invoked by uid 500); 29 Sep 2014 08:06:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24431 invoked by uid 99); 29 Sep 2014 08:06:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 08:06:00 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.47] (HELO mail-qa0-f47.google.com) (209.85.216.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 08:05:56 +0000
Received: by mail-qa0-f47.google.com with SMTP id i13so8307037qae.34
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 01:05:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=s0d8sn3Gw8lHk2NsGX6BdLbiTLkIrYoRVXbrmhrhszQ=;
        b=Uv0K+kz3XqSD+MtF0M3t4E3YxLY5OzuEkr6A7hRIpxUG6TMlDYaH/H/tsr6wGEmMIe
         5jJ3pDN3vASyQ7WNsgpMmMogHf/DcM8Izd5Yj83OpLpt6jpuhniwBD2SxiNPnra8cxl6
         SqO3hjQ7jELkrYBPT0CQVOEB+poAxMos/9gJTGCKlGthfKRh4Ew2OJjGz+BWh8nTRsUw
         7i4S+VA6i4jqdqcvD8UneQiIY1H0ACS8Zchq5w+3kdBj3JfYIXGP0Y1zWLaQfeCfoI5V
         LGnQAZXXNqE+4aqF1aOEbKeq3gY6UHsc3agIjGy9fwPJ/jOOsbxz0EKYIOA9CkSxjPLA
         +3/A==
X-Gm-Message-State: ALoCoQnD1mYnox5sBb7vYxvefvtzjIlMhkUjxYJKNMF9navP/roQia+KtZky4M90K/hLkrePhV3V
MIME-Version: 1.0
X-Received: by 10.224.63.140 with SMTP id b12mr32919831qai.22.1411977934902;
 Mon, 29 Sep 2014 01:05:34 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.12.73 with HTTP; Mon, 29 Sep 2014 01:05:34 -0700 (PDT)
In-Reply-To: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
References: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
Date: Mon, 29 Sep 2014 10:05:34 +0200
X-Google-Sender-Auth: hF9_wd7cWCZbMgG5hoiM1eSOhDg
Message-ID: <CAEYYnxbe1siwZKGizuOtw=uDBePxU9etf9UMYxi7pHXHK7Fu0A@mail.gmail.com>
Subject: Re: [MLlib] LogisticRegressionWithSGD and LogisticRegressionWithLBFGS
 converge with different weights.
From: DB Tsai <dbtsai@dbtsai.com>
To: Yanbo Liang <yanbohappy@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Can you check the loss of both LBFGS and SGD implementation? One
reason maybe SGD doesn't converge well and you can see that by
comparing both log-likelihoods. One other potential reason maybe the
label of your training data is totally separable, so you can always
increase the log-likelihood by multiply a constant to the weights.

Sincerely,

DB Tsai
-------------------------------------------------------
My Blog: https://www.dbtsai.com
LinkedIn: https://www.linkedin.com/in/dbtsai


On Sun, Sep 28, 2014 at 11:48 AM, Yanbo Liang <yanbohappy@gmail.com> wrote:
> Hi
>
> We have used LogisticRegression with two different optimization method SGD
> and LBFGS in MLlib.
> With the same dataset and the same training and test split, but get
> different weights vector.
>
> For example, we use
> spark-1.1.0/data/mllib/sample_binary_classification_data.txt as our training
> and test dataset.
> With LogisticRegressionWithSGD and LogisticRegressionWithLBFGS as training
> method and the same other parameters.
>
> The precisions of these two methods almost near 100% and AUCs are also near
> 1.0.
> As far as I know, the convex optimization problem will converge to the
> global minimum value. (We use SGD with mini batch fraction as 1.0)
> But I got two different weights vector? Is this expectation or make sense?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9623-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 09:45:48 2014
Return-Path: <dev-return-9623-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB5C91783D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 09:45:48 +0000 (UTC)
Received: (qmail 312 invoked by uid 500); 29 Sep 2014 09:45:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 251 invoked by uid 500); 29 Sep 2014 09:45:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99078 invoked by uid 99); 29 Sep 2014 09:45:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 09:45:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yanbohappy@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 09:45:41 +0000
Received: by mail-wg0-f51.google.com with SMTP id b13so4030671wgh.22
        for <multiple recipients>; Mon, 29 Sep 2014 02:45:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=x9zA3xV1TsL0hzy49xkO5foDZS4lgz6Y8+f9ZjRHHQk=;
        b=w3tk0l3/l8VjP9oAqB5ra06g1RoJQ/xv3+h9xPkdxPmE1EkD+g4rYVyf3QXbq4cBLi
         Uv0XmS6BVJXjPj2741UFx4QYweMjTD6UqVAYJhg6TEudJNksqGsxB/dcIBHwbDLCsj/l
         TccG6j4VgCM7lVLgguLU10Pt4lWxLfqQjkYJZkhDgWBbn1OdidiKjDELHj6ciiVZeuJ/
         ULlLAoh5Ti1ljP/SP+ga99lsOs1LhrNjPjn+OIBepN0+Af86a3vVkiUJobvBxYsAt5Y4
         eFQx9J7iGWtCPwgaL64m8ApJ5hM4W5tUkRndtn1clBUWXJVlL4DwdgRKwhkL2FXdQiFH
         tjpA==
MIME-Version: 1.0
X-Received: by 10.194.249.199 with SMTP id yw7mr1193250wjc.135.1411983920640;
 Mon, 29 Sep 2014 02:45:20 -0700 (PDT)
Received: by 10.217.107.135 with HTTP; Mon, 29 Sep 2014 02:45:20 -0700 (PDT)
In-Reply-To: <CAEYYnxbe1siwZKGizuOtw=uDBePxU9etf9UMYxi7pHXHK7Fu0A@mail.gmail.com>
References: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
	<CAEYYnxbe1siwZKGizuOtw=uDBePxU9etf9UMYxi7pHXHK7Fu0A@mail.gmail.com>
Date: Mon, 29 Sep 2014 17:45:20 +0800
Message-ID: <CALDQvdf7q_T=_=OAEkTZesoT7VTmNSJ+Pn0DDnYWA8yBf0nWeA@mail.gmail.com>
Subject: Re: [MLlib] LogisticRegressionWithSGD and LogisticRegressionWithLBFGS
 converge with different weights.
From: Yanbo Liang <yanbohappy@gmail.com>
To: DB Tsai <dbtsai@dbtsai.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: multipart/alternative; boundary=001a11c29b1404ba450504312020
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c29b1404ba450504312020
Content-Type: text/plain; charset=UTF-8

Thank you for all your patient response.

I can conclude that if the data is totally separable or over-fit occurs,
weights may be different.
And it also consistent with my experiment.

I have evaluate two different dataset and the result as followed:
Loss function: LogisticGradient
Regularizer: L2
regParam: 1.0
numIterations: 10000 (SGD)

Dataset 1: spark-1.1.0/data/mllib/sample_binary_classification_data.txt
# of classes: 2
# of samples: 100
# of features: 692
areaUnderROC of both SGD and LBFGS can reach nearly 1.0
Loss function of both optimization method converge
nearly 1.7147811767900675E-5 (very very small)
Weights of each optimization method is different but looks like multiple
relationship (not very strict) just as what DB Tsai mention above.  It
might be the dataset is totally separable.

Dataset 2:
http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#german.numer
# of classes: 2
# of samples: 1000
# of features: 24
areaUnderROC of both SGD and LBFGS both are nearly 0.8
Loss function of both optimization method converge nearly 0.5367041390107519
Weights of each optimization method is just the same.



2014-09-29 16:05 GMT+08:00 DB Tsai <dbtsai@dbtsai.com>:

> Can you check the loss of both LBFGS and SGD implementation? One
> reason maybe SGD doesn't converge well and you can see that by
> comparing both log-likelihoods. One other potential reason maybe the
> label of your training data is totally separable, so you can always
> increase the log-likelihood by multiply a constant to the weights.
>
> Sincerely,
>
> DB Tsai
> -------------------------------------------------------
> My Blog: https://www.dbtsai.com
> LinkedIn: https://www.linkedin.com/in/dbtsai
>
>
> On Sun, Sep 28, 2014 at 11:48 AM, Yanbo Liang <yanbohappy@gmail.com>
> wrote:
> > Hi
> >
> > We have used LogisticRegression with two different optimization method
> SGD
> > and LBFGS in MLlib.
> > With the same dataset and the same training and test split, but get
> > different weights vector.
> >
> > For example, we use
> > spark-1.1.0/data/mllib/sample_binary_classification_data.txt as our
> training
> > and test dataset.
> > With LogisticRegressionWithSGD and LogisticRegressionWithLBFGS as
> training
> > method and the same other parameters.
> >
> > The precisions of these two methods almost near 100% and AUCs are also
> near
> > 1.0.
> > As far as I know, the convex optimization problem will converge to the
> > global minimum value. (We use SGD with mini batch fraction as 1.0)
> > But I got two different weights vector? Is this expectation or make
> sense?
>

--001a11c29b1404ba450504312020--

From dev-return-9624-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 13:06:59 2014
Return-Path: <dev-return-9624-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3F46D17D21
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 13:06:59 +0000 (UTC)
Received: (qmail 46092 invoked by uid 500); 29 Sep 2014 13:06:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46026 invoked by uid 500); 29 Sep 2014 13:06:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46014 invoked by uid 99); 29 Sep 2014 13:06:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 13:06:58 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of myasuka@live.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 13:06:32 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <myasuka@live.com>)
	id 1XYaet-0004nv-9P
	for dev@spark.incubator.apache.org; Mon, 29 Sep 2014 06:06:31 -0700
Date: Mon, 29 Sep 2014 06:06:31 -0700 (PDT)
From: myasuka <myasuka@live.com>
To: dev@spark.incubator.apache.org
Message-ID: <1411995991265-8594.post@n3.nabble.com>
In-Reply-To: <D586FA82-26EC-42EA-B02F-BC5EA3F071F9@gmail.com>
References: <1411898355683-8583.post@n3.nabble.com> <D586FA82-26EC-42EA-B02F-BC5EA3F071F9@gmail.com>
Subject: Re: How to use multi thread in RDD map function ?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Our cluster is a standalone cluster with 16 computing nodes, each node has 16
cores. I set SPARK_WORKER_INSTANCES to 1, and set SPARK_WORKER_CORES to 32,
we give 512 tasks all together, this situation can help increase the
concurrency. But if I  set SPARK_WORKER_INSTANCES to 2, SPARK_WORKER_CORES
to 16, this dosen't work well.

Thank you for your reply.


Yi Tian wrote
> for yarn-client mode:
>  
> SPARK_EXECUTOR_CORES * SPARK_EXECUTOR_INSTANCES = 2(or 3) *
> TotalCoresOnYourCluster
> 
> for standlone mode:
> 
> SPARK_WORKER_INSTANCES * SPARK_WORKER_CORES = 2(or 3) *
> TotalCoresOnYourCluster
> 
> 
> 
> Best Regards,
> 
> Yi Tian

> tianyi.asiainfo@

> 
> 
> 
> 
> On Sep 28, 2014, at 17:59, myasuka &lt;

> myasuka@

> &gt; wrote:
> 
>> Hi, everyone
>>    I come across with a problem about increasing the concurency. In a
>> program, after shuffle write, each node should fetch 16 pair matrices to
>> do
>> matrix multiplication. such as:
>> 
>> *import breeze.linalg.{DenseMatrix => BDM}
>> 
>> pairs.map(t => {
>>        val b1 = t._2._1.asInstanceOf[BDM[Double]]
>>        val b2 = t._2._2.asInstanceOf[BDM[Double]]
>> 
>>        val c = (b1 * b2).asInstanceOf[BDM[Double]]
>> 
>>        (new BlockID(t._1.row, t._1.column), c)
>>      })*
>> 
>>    Each node has 16 cores. However, no matter I set 16 tasks or more on
>> each node, the concurrency cannot be higher than 60%, which means not
>> every
>> core on the node is computing. Then I check the running log on the WebUI,
>> according to the amount of shuffle read and write in every task, I see
>> some
>> task do once matrix multiplication, some do twice while some do none.
>> 
>>    Thus, I think of using java multi thread to increase the concurrency.
>> I
>> wrote a program in scala which calls java multi thread without Spark on a
>> single node, by watch the 'top' monitor, I find this program can use CPU
>> up
>> to 1500% ( means nearly every core are computing). But I have no idea how
>> to
>> use Java multi thread in RDD transformation.
>> 
>>    Is there any one can provide some example code to use Java multi
>> thread
>> in RDD transformation, or give any idea to increase the concurrency ?
>> 
>> Thanks for all
>> 
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583.html
>> Sent from the Apache Spark Developers List mailing list archive at
>> Nabble.com.
>> 
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: 

> dev-unsubscribe@.apache

>> For additional commands, e-mail: 

> dev-help@.apache

>>





--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583p8594.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9625-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 13:44:43 2014
Return-Path: <dev-return-9625-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B04A217DD5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 13:44:43 +0000 (UTC)
Received: (qmail 11240 invoked by uid 500); 29 Sep 2014 13:44:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11167 invoked by uid 500); 29 Sep 2014 13:44:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11155 invoked by uid 99); 29 Sep 2014 13:44:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 13:44:41 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.220.49 as permitted sender)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 13:44:37 +0000
Received: by mail-pa0-f49.google.com with SMTP id lj1so1564474pab.8
        for <dev@spark.incubator.apache.org>; Mon, 29 Sep 2014 06:44:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=fTfVHVXoYnCgjwj8FVQTlWU7D6O8BDLN1d6ynyIg2os=;
        b=ayVs5AmTQXgpIw7zRQhWVlUHr8Br23o9G5kEzOltZHGtCe2kMtaTJIap95qwJyHIZQ
         7PrIDzYzAu2kqoOIT1VcXlq/+2lvO7HYreNOcP+5JqEKGt+08hUOJslh/+oeZU1Vflkq
         IIu1DWsYaQ+v+JLxd3e89OptgTUDQ1QXCoo3lYBfRqwnYUdopkSW1ln5nRWDxJe0wfPH
         ACSsHeGUAA7y/oHPz8PcWw8Uh3AbkbeCheBhdykTCCXEskyJOIrU7fCx5zq3eFJ6QV9r
         xPMphrB7dFRKlCZZKwK6bPi3h2965+pZwfbAmeQX9xZuJPPRJae3xKRUILLySwJSi7Yf
         B+AQ==
X-Received: by 10.70.13.193 with SMTP id j1mr23863178pdc.51.1411998256338;
        Mon, 29 Sep 2014 06:44:16 -0700 (PDT)
Received: from [192.168.65.158] ([58.56.7.234])
        by mx.google.com with ESMTPSA id ki1sm12413196pdb.59.2014.09.29.06.44.12
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 29 Sep 2014 06:44:15 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_A6717B62-70DB-48E2-A494-7CA238479D2C"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: How to use multi thread in RDD map function ?
From: Yi Tian <tianyi.asiainfo@gmail.com>
In-Reply-To: <1411995991265-8594.post@n3.nabble.com>
Date: Mon, 29 Sep 2014 21:44:01 +0800
Cc: dev@spark.incubator.apache.org
Message-Id: <25F1FC13-A56B-46CB-B299-6277CE06C60E@gmail.com>
References: <1411898355683-8583.post@n3.nabble.com> <D586FA82-26EC-42EA-B02F-BC5EA3F071F9@gmail.com> <1411995991265-8594.post@n3.nabble.com>
To: myasuka <myasuka@live.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_A6717B62-70DB-48E2-A494-7CA238479D2C
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=us-ascii

Hi, myasuka

Have you checked the jvm gc time of each executor?=20

I think you should increase the SPARK_EXECUTOR_CORES or =
SPARK_EXECUTOR_INSTANCES until you get the enough concurrency.

Here is my recommend config:

SPARK_EXECUTOR_CORES=3D8
SPARK_EXECUTOR_INSTANCES=3D4
SPARK_WORKER_MEMORY=3D8G

note: make sure you got enough memory on each node, more than =
SPARK_EXECUTOR_INSTANCES * SPARK_WORKER_MEMORY

Best Regards,

Yi Tian
tianyi.asiainfo@gmail.com




On Sep 29, 2014, at 21:06, myasuka <myasuka@live.com> wrote:

> Our cluster is a standalone cluster with 16 computing nodes, each node =
has 16
> cores. I set SPARK_WORKER_INSTANCES to 1, and set SPARK_WORKER_CORES =
to 32,
> we give 512 tasks all together, this situation can help increase the
> concurrency. But if I  set SPARK_WORKER_INSTANCES to 2, =
SPARK_WORKER_CORES
> to 16, this dosen't work well.
>=20
> Thank you for your reply.
>=20
>=20
> Yi Tian wrote
>> for yarn-client mode:
>>=20
>> SPARK_EXECUTOR_CORES * SPARK_EXECUTOR_INSTANCES =3D 2(or 3) *
>> TotalCoresOnYourCluster
>>=20
>> for standlone mode:
>>=20
>> SPARK_WORKER_INSTANCES * SPARK_WORKER_CORES =3D 2(or 3) *
>> TotalCoresOnYourCluster
>>=20
>>=20
>>=20
>> Best Regards,
>>=20
>> Yi Tian
>=20
>> tianyi.asiainfo@
>=20
>>=20
>>=20
>>=20
>>=20
>> On Sep 28, 2014, at 17:59, myasuka &lt;
>=20
>> myasuka@
>=20
>> &gt; wrote:
>>=20
>>> Hi, everyone
>>>   I come across with a problem about increasing the concurency. In a
>>> program, after shuffle write, each node should fetch 16 pair =
matrices to
>>> do
>>> matrix multiplication. such as:
>>>=20
>>> *import breeze.linalg.{DenseMatrix =3D> BDM}
>>>=20
>>> pairs.map(t =3D> {
>>>       val b1 =3D t._2._1.asInstanceOf[BDM[Double]]
>>>       val b2 =3D t._2._2.asInstanceOf[BDM[Double]]
>>>=20
>>>       val c =3D (b1 * b2).asInstanceOf[BDM[Double]]
>>>=20
>>>       (new BlockID(t._1.row, t._1.column), c)
>>>     })*
>>>=20
>>>   Each node has 16 cores. However, no matter I set 16 tasks or more =
on
>>> each node, the concurrency cannot be higher than 60%, which means =
not
>>> every
>>> core on the node is computing. Then I check the running log on the =
WebUI,
>>> according to the amount of shuffle read and write in every task, I =
see
>>> some
>>> task do once matrix multiplication, some do twice while some do =
none.
>>>=20
>>>   Thus, I think of using java multi thread to increase the =
concurrency.
>>> I
>>> wrote a program in scala which calls java multi thread without Spark =
on a
>>> single node, by watch the 'top' monitor, I find this program can use =
CPU
>>> up
>>> to 1500% ( means nearly every core are computing). But I have no =
idea how
>>> to
>>> use Java multi thread in RDD transformation.
>>>=20
>>>   Is there any one can provide some example code to use Java multi
>>> thread
>>> in RDD transformation, or give any idea to increase the concurrency =
?
>>>=20
>>> Thanks for all
>>>=20
>>>=20
>>>=20
>>>=20
>>> --
>>> View this message in context:
>>> =
http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi=
-thread-in-RDD-map-function-tp8583.html
>>> Sent from the Apache Spark Developers List mailing list archive at
>>> Nabble.com.
>>>=20
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail:=20
>=20
>> dev-unsubscribe@.apache
>=20
>>> For additional commands, e-mail:=20
>=20
>> dev-help@.apache
>=20
>>>=20
>=20
>=20
>=20
>=20
>=20
> --
> View this message in context: =
http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi=
-thread-in-RDD-map-function-tp8583p8594.html
> Sent from the Apache Spark Developers List mailing list archive at =
Nabble.com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org


--Apple-Mail=_A6717B62-70DB-48E2-A494-7CA238479D2C--

From dev-return-9626-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 18:32:27 2014
Return-Path: <dev-return-9626-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6369B17C2B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 18:32:27 +0000 (UTC)
Received: (qmail 34289 invoked by uid 500); 29 Sep 2014 18:32:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34220 invoked by uid 500); 29 Sep 2014 18:32:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34129 invoked by uid 99); 29 Sep 2014 18:32:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 18:32:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yuzhihong@gmail.com designates 209.85.160.175 as permitted sender)
Received: from [209.85.160.175] (HELO mail-yk0-f175.google.com) (209.85.160.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 18:31:58 +0000
Received: by mail-yk0-f175.google.com with SMTP id 131so701824ykp.6
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 11:31:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=NKzu4D9Ir0AWoOLUidZEEHt5XSwLNoZSDfW4b3+/y8o=;
        b=AD9TyydHXkrb4y+qUN/W3set6/PENq67ByyvLrf0vjgpGvwVPcjAepQ1h542YeMMLR
         DwKOtxJCwjOMXugCg67SQKDh7j8kRAQnkb9m+htvDZmE3/2y7xc6umnfeb4csMoorbvX
         DnVWEj3m2zx8U8kzllFv5GyTTHrynMT9Ah7kHRcNqrbBQ8s9ytimMCzZbJ/5wzRqv1ED
         KuA2fjaVdvLFNK9bg+6SSP/P3X4NOLRnT/3N+UKopCcI9fiKntnh3Qvu0McZtnZy/v66
         SMJCnkyM56gSfqtgt8lYrGHtPXuvVo71gq+4O1rzDwiXecUZNKAJBzedgk4eOucDN9/i
         ZGuw==
MIME-Version: 1.0
X-Received: by 10.236.85.104 with SMTP id t68mr203397yhe.183.1412015516734;
 Mon, 29 Sep 2014 11:31:56 -0700 (PDT)
Received: by 10.170.163.70 with HTTP; Mon, 29 Sep 2014 11:31:56 -0700 (PDT)
Date: Mon, 29 Sep 2014 11:31:56 -0700
Message-ID: <CALte62zBf0bQxFrLVi_q+gmtu-jErF3Cw9LRSyDpKPPEmM+5cw@mail.gmail.com>
Subject: BasicOperationsSuite failing ?
From: Ted Yu <yuzhihong@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf300e518f4adbb10504387b14
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf300e518f4adbb10504387b14
Content-Type: text/plain; charset=UTF-8

Hi,
Running test suite in trunk, I got:

^[[32mBasicOperationsSuite:^[[0m
^[[32m- map^[[0m
^[[32m- flatMap^[[0m
^[[32m- filter^[[0m
^[[32m- glom^[[0m
^[[32m- mapPartitions^[[0m
^[[32m- repartition (more partitions)^[[0m
^[[32m- repartition (fewer partitions)^[[0m
^[[32m- groupByKey^[[0m
^[[32m- reduceByKey^[[0m
^[[32m- reduce^[[0m
^[[32m- count^[[0m
^[[32m- countByValue^[[0m
^[[32m- mapValues^[[0m
^[[32m- flatMapValues^[[0m
^[[32m- union^[[0m
^[[32m- StreamingContext.union^[[0m
^[[32m- transform^[[0m
^[[32m- transformWith^[[0m
^[[32m- StreamingContext.transform^[[0m
^[[32m- cogroup^[[0m
^[[32m- join^[[0m
^[[32m- leftOuterJoin^[[0m
^[[32m- rightOuterJoin^[[0m
^[[32m- fullOuterJoin^[[0m
^[[32m- updateStateByKey^[[0m
^[[32m- updateStateByKey - object lifecycle^[[0m
^[[32m- slice^[[0m
^[[32m- slice - has not been initialized^[[0m
^[[32m- rdd cleanup - map and window^[[0m
^[[32m- rdd cleanup - updateStateByKey^[[0m
^[[31m- rdd cleanup - input blocks and persisted RDDs *** FAILED ***^[[0m
^[[31m  org.scalatest.exceptions.TestFailedException was thrown.
(BasicOperationsSuite.scala:528)^[[0m

However, using sbt for this testsuite, it seemed to pass:

[info] - slice - has not been initialized
[info] - rdd cleanup - map and window
[info] - rdd cleanup - updateStateByKey
Exception in thread "Thread-561" org.apache.spark.SparkException: Job
cancelled because SparkContext was shut down
at
org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:701)
at
org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:700)
at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
at
org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:700)
at
org.apache.spark.scheduler.DAGSchedulerEventProcessActor.postStop(DAGScheduler.scala:1406)
at
akka.actor.dungeon.FaultHandling$class.akka$actor$dungeon$FaultHandling$$finishTerminate(FaultHandling.scala:201)
at akka.actor.dungeon.FaultHandling$class.terminate(FaultHandling.scala:163)
at akka.actor.ActorCell.terminate(ActorCell.scala:338)
at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:431)
at akka.actor.ActorCell.systemInvoke(ActorCell.scala:447)
at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:262)
at akka.dispatch.Mailbox.run(Mailbox.scala:218)
at
akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
at
scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
at
scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
[info] - rdd cleanup - input blocks and persisted RDDs
[info] ScalaTest
[info] Run completed in 1 minute, 1 second.
[info] Total number of tests run: 31
[info] Suites: completed 1, aborted 0
[info] Tests: succeeded 31, failed 0, canceled 0, ignored 0, pending 0
[info] All tests passed.
[info] Passed: Total 31, Failed 0, Errors 0, Passed 31
java.lang.AssertionError: assertion failed: List(object package$DebugNode,
object package$DebugNode)
at scala.reflect.internal.Symbols$Symbol.suchThat(Symbols.scala:1678)
at
scala.reflect.internal.Symbols$ClassSymbol.companionModule0(Symbols.scala:2988)
at
scala.reflect.internal.Symbols$ClassSymbol.companionModule(Symbols.scala:2991)
at
scala.tools.nsc.backend.jvm.GenASM$JPlainBuilder.genClass(GenASM.scala:1371)
at scala.tools.nsc.backend.jvm.GenASM$AsmPhase.run(GenASM.scala:120)
at scala.tools.nsc.Global$Run.compileUnitsInternal(Global.scala:1583)
at scala.tools.nsc.Global$Run.compileUnits(Global.scala:1557)
at scala.tools.nsc.Global$Run.compileSources(Global.scala:1553)
at scala.tools.nsc.Global$Run.compile(Global.scala:1662)
at xsbt.CachedCompiler0.run(CompilerInterface.scala:123)
at xsbt.CachedCompiler0.run(CompilerInterface.scala:99)
at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at sbt.compiler.AnalyzingCompiler.call(AnalyzingCompiler.scala:102)
at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:48)
at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:41)
at
sbt.compiler.AggressiveCompile$$anonfun$3$$anonfun$compileScala$1$1.apply$mcV$sp(AggressiveCompile.scala:99)
at
sbt.compiler.AggressiveCompile$$anonfun$3$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:99)
at
sbt.compiler.AggressiveCompile$$anonfun$3$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:99)
at
sbt.compiler.AggressiveCompile.sbt$compiler$AggressiveCompile$$timed(AggressiveCompile.scala:166)
at
sbt.compiler.AggressiveCompile$$anonfun$3.compileScala$1(AggressiveCompile.scala:98)
at
sbt.compiler.AggressiveCompile$$anonfun$3.apply(AggressiveCompile.scala:143)
at
sbt.compiler.AggressiveCompile$$anonfun$3.apply(AggressiveCompile.scala:87)
at sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:39)

Any comment ?

Thanks

--20cf300e518f4adbb10504387b14--

From dev-return-9627-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 20:44:37 2014
Return-Path: <dev-return-9627-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 255771743A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 20:44:37 +0000 (UTC)
Received: (qmail 77297 invoked by uid 500); 29 Sep 2014 20:44:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77229 invoked by uid 500); 29 Sep 2014 20:44:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77218 invoked by uid 99); 29 Sep 2014 20:44:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 20:44:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.170 as permitted sender)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 20:44:26 +0000
Received: by mail-lb0-f170.google.com with SMTP id n15so7019005lbi.1
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 13:44:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=gvr9tbEMyTHiJfh8/H3iS9qxVPY+JSWzFMnhltVkUgg=;
        b=PMkE6NW66B0HWPx+rKX85085hbSVcLliFEYV7St6E0ZXkYe5byUdZdQMcdvJAEAweZ
         ibR6nsmK+Y9eGwoW/VSJFgwo1hsLbgdv2xhtnNIm4GqVa002/O6G6SPUbIYHiusDmERK
         VojlMBKBMyURrY9v5742yWQNK8hq2PZt3+P+rTQvb87m17PpNt710gdFc5HjK6hi7b5V
         ghy/A6X8xkXLttDtOD3dryPUl2+GXgwvq45LRvy57TdP+sadmD1yzCje+HZ4rxemd6b6
         PalxAt98sD2DxV9hCGUPpLmS1wZPYA6nZGEayPyGPJ79KbTTKYXvCD3gw1kP0ek/oBr6
         up2g==
X-Gm-Message-State: ALoCoQl06PvJ3rLmd65F/wH533TsrtLAQFtfRTn3chM537g146KzYfMLwO8dp4wTGvMYP/fk91l3
X-Received: by 10.112.184.161 with SMTP id ev1mr38628804lbc.82.1412023444405;
 Mon, 29 Sep 2014 13:44:04 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Mon, 29 Sep 2014 13:43:44 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 29 Sep 2014 13:43:44 -0700
Message-ID: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
Subject: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c31d0ed18cda05043a534c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c31d0ed18cda05043a534c
Content-Type: text/plain; charset=UTF-8

happy monday, everyone!

remember a few weeks back when i upgraded jenkins, and unwittingly began
DOSing our system due to massive log spam?

well, that bug has been fixed w/the current release and i'd like to get our
logging levels back to something more verbose that we have now.

downtime will be from 730am-1000am PDT (i do expect this to be done well
before 1000am)

the update will be from 1.578 -> 1.582

changelog here:  http://jenkins-ci.org/changelog

please let me know if there are any questions or concerns.  thanks!

shane, your friendly devops engineer

--001a11c31d0ed18cda05043a534c--

From dev-return-9628-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 21:20:57 2014
Return-Path: <dev-return-9628-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F87A1760B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 21:20:57 +0000 (UTC)
Received: (qmail 519 invoked by uid 500); 29 Sep 2014 21:20:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 454 invoked by uid 500); 29 Sep 2014 21:20:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 309 invoked by uid 99); 29 Sep 2014 21:20:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:20:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.171 as permitted sender)
Received: from [209.85.217.171] (HELO mail-lb0-f171.google.com) (209.85.217.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:20:51 +0000
Received: by mail-lb0-f171.google.com with SMTP id z12so276620lbi.16
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 14:20:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=PG4wsatJ/jzBzdLtTw/RJ/wXsxr6knWCMpEss7wlQWY=;
        b=kWxSf/PmMkmYOR+vZeoW1TgpAjVgf3uSY/yLzCMOiBqtGTczKxRZMLKuM+B/4EMU8U
         P9lkR0vwgs8apuCPWdPOZM3o+A8AlO613CHQ6ZRcf9NO3kSBGUjggAvTufXYF0lb9xAf
         Me8OwiVBIoOszhFegEpz7k0MJLaQ6hlHQIm3QLPaNtrCoV7yaIqRwWfLBdgl0sfDceOV
         UUgo+9aHH8E6xj57ekWWuXy7hJyEJ/oVE33sL9jpQQ2N2T+26E2qoVbrvDJmnYwVyssn
         ze1qtSc2b/UNEogqyURsCWuTTnj12Qc4GGPTsIhFS3lZw5oILLNx19coYqfIdmC8ZXpa
         0JQA==
X-Gm-Message-State: ALoCoQlC2oLz/EZTxQv+KV406hF1GCdKEsyOmBe3Qhcg1DtcTrRDScd8ghry2KMF42WTs9c6W3cI
X-Received: by 10.152.202.135 with SMTP id ki7mr38382338lac.16.1412025629394;
 Mon, 29 Sep 2014 14:20:29 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Mon, 29 Sep 2014 14:20:09 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 29 Sep 2014 14:20:09 -0700
Message-ID: <CACdU-dR5dH=Uw3RjNjwB_sAanPxX9VN2enm5hc5vFYs_2iyv6Q@mail.gmail.com>
Subject: FYI: i've doubled the jenkins executors for every build node
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1135fb420dde5e05043ad6af
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fb420dde5e05043ad6af
Content-Type: text/plain; charset=UTF-8

we were running at 8 executors per node, and BARELY even stressing the
machines (32 cores, ~230G RAM).

in the interest of actually using system resources, and giving ourselves
some headroom, i upped the executors to 16 per node.  i'll be keeping an
eye on ganglia for the rest of the week to make sure everything's cool.

i hope you all enjoy your freshly allocated capacity!  :)

shane

--001a1135fb420dde5e05043ad6af--

From dev-return-9629-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 21:26:03 2014
Return-Path: <dev-return-9629-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25C5017633
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 21:26:03 +0000 (UTC)
Received: (qmail 15860 invoked by uid 500); 29 Sep 2014 21:26:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15786 invoked by uid 500); 29 Sep 2014 21:26:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15768 invoked by uid 99); 29 Sep 2014 21:26:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:26:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.50] (HELO mail-qg0-f50.google.com) (209.85.192.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:25:57 +0000
Received: by mail-qg0-f50.google.com with SMTP id q107so12378073qgd.37
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 14:25:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=napAgyzU1vproR3OYVth1c2k1BAS61Ba8zHcxx/nI+g=;
        b=ZIjatbEtHUrINAMtQkuo4ijDEJGrx6NCn7fmeV1eQdeHNsrdzrDqJ6fJB+iPouMHdJ
         WE3/MOzH+Yn5NHmIcq2cHu3H5WW38lAQxJiuhiKI7R39f2UR/DOSEcIWthpIpziyGQTa
         hH2JYplo3+fpJLaAkjD4zoDiyj5nlVUmxA2hQJWeg2p5Q4wcnkBs8YRp52WVCzSvBtaE
         BrQwxjVKY4/YOrVw9+3hesYSwZ+THnLP7zK391EJGXFFWLKfEzyznllVioERlM7bL6xF
         uzK3J5w38hn2FlX+H3MwfC3T0X/iicj6GnHAIoBxulGyfXIj8yHh9/7aAPLJDS16l6b8
         IW+w==
X-Gm-Message-State: ALoCoQnlXYz/FNlQRoAeakc9vZcYdOR/H8vdjx1GXHtHX2mJ3Mj7G3fYw+N/qLdT3Cm+ggMZj3ZT
X-Received: by 10.140.82.197 with SMTP id h63mr9091147qgd.44.1412025935841;
 Mon, 29 Sep 2014 14:25:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.41.34 with HTTP; Mon, 29 Sep 2014 14:25:15 -0700 (PDT)
In-Reply-To: <CACdU-dR5dH=Uw3RjNjwB_sAanPxX9VN2enm5hc5vFYs_2iyv6Q@mail.gmail.com>
References: <CACdU-dR5dH=Uw3RjNjwB_sAanPxX9VN2enm5hc5vFYs_2iyv6Q@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 29 Sep 2014 14:25:15 -0700
Message-ID: <CAPh_B=YzoPmKP_eThDaL3=maBTrVvf-4RPUaP2Wrx5KsPhiecw@mail.gmail.com>
Subject: Re: FYI: i've doubled the jenkins executors for every build node
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1356c51e49a05043ae859
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1356c51e49a05043ae859
Content-Type: text/plain; charset=UTF-8

Thanks. We might see more failures due to contention on resources. Fingers
acrossed ... At some point it might make sense to run the tests in a VM or
container.


On Mon, Sep 29, 2014 at 2:20 PM, shane knapp <sknapp@berkeley.edu> wrote:

> we were running at 8 executors per node, and BARELY even stressing the
> machines (32 cores, ~230G RAM).
>
> in the interest of actually using system resources, and giving ourselves
> some headroom, i upped the executors to 16 per node.  i'll be keeping an
> eye on ganglia for the rest of the week to make sure everything's cool.
>
> i hope you all enjoy your freshly allocated capacity!  :)
>
> shane
>

--001a11c1356c51e49a05043ae859--

From dev-return-9630-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Sep 29 21:32:34 2014
Return-Path: <dev-return-9630-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5B7AE1765E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 29 Sep 2014 21:32:34 +0000 (UTC)
Received: (qmail 34200 invoked by uid 500); 29 Sep 2014 21:32:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34120 invoked by uid 500); 29 Sep 2014 21:32:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34106 invoked by uid 99); 29 Sep 2014 21:32:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:32:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.43 as permitted sender)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 29 Sep 2014 21:32:08 +0000
Received: by mail-la0-f43.google.com with SMTP id gb8so9224795lab.2
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 14:32:07 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=4QKNLZ7vVeYixTlGiYdZ+SPq3Qzb/f9Yw+O5EpBA2gE=;
        b=lZ0tQ9YgR6d9xUw/Xb5rbumglq+tt315nUVRboGzkl1Sry60kqFzd/SfBGrE2DOmTW
         MwYZnq6xQ+2+XxjX0YV8+2vltjyjmkFoQRKDxdQJIlR6J7GvUpKuphPJek5vk0v3MdDk
         mPat8WWU84XyPH0zE4FtjAVmvuYT0lv4cUCiUubBAN8eUbx/KYtWimhEn2NqXJZoFoH+
         43/KGYEtp58eDrHMEuWUMKKYl8jgqvbOpscmrQCUomVMgLf6d6/TZlOTQUNlC67EoQvH
         JHLqC8knrasG1a+9fH3sjdBcjrgE7mrCpFcuyx+eUC8vljvGEkRi1WLmJaDGUJsNw0iM
         YVfw==
X-Gm-Message-State: ALoCoQnQGQOaTXl8iQuAMGmQk7w4fP73s5SViZF0EtdBdQLeGMdGoo64SpMP3mwv9nmGBXYOXHwi
X-Received: by 10.152.6.202 with SMTP id d10mr2439461laa.69.1412026326888;
 Mon, 29 Sep 2014 14:32:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Mon, 29 Sep 2014 14:31:46 -0700 (PDT)
In-Reply-To: <CAPh_B=YzoPmKP_eThDaL3=maBTrVvf-4RPUaP2Wrx5KsPhiecw@mail.gmail.com>
References: <CACdU-dR5dH=Uw3RjNjwB_sAanPxX9VN2enm5hc5vFYs_2iyv6Q@mail.gmail.com>
 <CAPh_B=YzoPmKP_eThDaL3=maBTrVvf-4RPUaP2Wrx5KsPhiecw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 29 Sep 2014 14:31:46 -0700
Message-ID: <CACdU-dQmwu3S2m9YvK6pLmvdJQLYupmi=Rs=Zp-h5V46rTgADg@mail.gmail.com>
Subject: Re: FYI: i've doubled the jenkins executors for every build node
To: Reynold Xin <rxin@databricks.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01419b1ca0c2ba05043aff72
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01419b1ca0c2ba05043aff72
Content-Type: text/plain; charset=UTF-8

yeah, this is why i'm gonna keep a close eye on things this week...

as for VMs vs containers, please do the latter more than the former.  one
of our longer-term plans here at the lab is to move most of our jenkins
infra to VMs, and running tests w/nested VMs is Bad[tm].

On Mon, Sep 29, 2014 at 2:25 PM, Reynold Xin <rxin@databricks.com> wrote:

> Thanks. We might see more failures due to contention on resources. Fingers
> acrossed ... At some point it might make sense to run the tests in a VM or
> container.
>
>
> On Mon, Sep 29, 2014 at 2:20 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> we were running at 8 executors per node, and BARELY even stressing the
>> machines (32 cores, ~230G RAM).
>>
>> in the interest of actually using system resources, and giving ourselves
>> some headroom, i upped the executors to 16 per node.  i'll be keeping an
>> eye on ganglia for the rest of the week to make sure everything's cool.
>>
>> i hope you all enjoy your freshly allocated capacity!  :)
>>
>> shane
>>
>
>

--089e01419b1ca0c2ba05043aff72--

From dev-return-9631-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 02:46:29 2014
Return-Path: <dev-return-9631-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 99A34171D0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 02:46:29 +0000 (UTC)
Received: (qmail 988 invoked by uid 500); 30 Sep 2014 02:46:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 912 invoked by uid 500); 30 Sep 2014 02:46:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 898 invoked by uid 99); 30 Sep 2014 02:46:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:46:28 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lochanac@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:46:21 +0000
Received: by mail-pa0-f50.google.com with SMTP id kx10so4580328pab.9
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 19:46:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject
         :content-type:content-transfer-encoding;
        bh=+BS8ZmZpUY1JYMvLif+muBrRNZ9XL9vZQLIwhT6nA6Q=;
        b=M3ftPaaX/sLMO1krl7fSFQxDrOB4dNtc28bq+BW0fd3hejDYk8iEjaKmVoOc4d11cX
         FsJ9R6EY5YQJKqzWPbYixmIZGtEJATeFsumFqzHJg3Wh+l3vWc8AP4kFVP2DIJUFeP7h
         G/oKEpB4c45c7b6Z1GU7mmVbwcu5zw+knpl+tOrnVSGc9nh+TyHWG7DlfcpOz+xDNor3
         5tTSLYFZvC626l5qsbj9VFeazzwwTnj4pC1Xot9Q3uB8mTrHXDf6d8nMu1gllIps7Xcd
         0OG1FCebqN9qVFvonC3T8QxIRF1Vf8RJ4aPzbsbV8PvM5f1RezORJCfd2ChofB8kKo6k
         mc7g==
X-Received: by 10.70.133.133 with SMTP id pc5mr19927542pdb.135.1412045161716;
        Mon, 29 Sep 2014 19:46:01 -0700 (PDT)
Received: from Lochanas-MacBook-Pro.local ([203.94.95.4])
        by mx.google.com with ESMTPSA id nd6sm13613288pbc.28.2014.09.29.19.46.00
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 29 Sep 2014 19:46:01 -0700 (PDT)
Message-ID: <542A1966.6020104@gmail.com>
Date: Tue, 30 Sep 2014 08:15:58 +0530
From: Lochana Menikarachchi <lochanac@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Hyper Parameter Optimization Algorithms
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

Is there anyone who works on hyper parameter optimization algorithms? If 
not, is there any interest on the subject. We are thinking about 
implementing some of these algorithms and contributing to spark? thoughts?

Lochana

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9632-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 02:46:40 2014
Return-Path: <dev-return-9632-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 542E0171D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 02:46:40 +0000 (UTC)
Received: (qmail 3158 invoked by uid 500); 30 Sep 2014 02:46:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3081 invoked by uid 500); 30 Sep 2014 02:46:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3067 invoked by uid 99); 30 Sep 2014 02:46:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:46:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:46:11 +0000
Received: by mail-ig0-f182.google.com with SMTP id hn18so4679424igb.9
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 19:46:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=xJgpml1JnatzKSj6W7Eau/MzW1HrLvTLmkXZ3ZScOaY=;
        b=PBV+QkCR7XrSIChrCqotvSS1DDa4H6OlLkkXwKwTrj83GQQDP2naqDd7ZE2PqjgO+k
         bIYxzSFEI63718qfxQOVG0b5Tc0yYDHA2ZocgDEIXaoPEkzUGD5QsSJXVZaNeMEhRKMc
         BE+m4me2kNObbU5pnpPDpv1R5j0DzuQM830u9tJiO+TDediAu+bS5Pl3G1VS2IPMIsUj
         PLSdXW06ZVHddtca9lhxh9pZIO1nO+j83BFYZUfQlRu+NPlKzBBrTakx1C92yZZ5q6+x
         4LBdDIG2JzoIwnlksHYCbKhdArwjRjQh/3x6b31nbE2BVlqaVdDBnJLh3hAEr0FgVdsA
         mmkg==
X-Received: by 10.42.233.75 with SMTP id jx11mr47281383icb.22.1412045170206;
        Mon, 29 Sep 2014 19:46:10 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167940830.dsl.bell.ca. [69.157.92.222])
        by mx.google.com with ESMTPSA id v2sm12060090igs.11.2014.09.29.19.46.09
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Mon, 29 Sep 2014 19:46:09 -0700 (PDT)
Date: Mon, 29 Sep 2014 23:00:59 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Message-ID: <8E629B87D9B941CC97EDC8DE5CC946D0@gmail.com>
In-Reply-To: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am
 PDT
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="542a1ceb_507ed7ab_cc8"
X-Virus-Checked: Checked by ClamAV on apache.org

--542a1ceb_507ed7ab_cc8
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Just noticed these lines in the jenkins log 

========================================================================= Running Apache RAT checks ========================================================================= Attempting to fetch rat Launching rat from /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar Error: Invalid or corrupt jarfile /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar RAT checks passed.

Something wrong?

Best, 

-- 
Nan Zhu


On Monday, September 29, 2014 at 4:43 PM, shane knapp wrote:

> happy monday, everyone!
> 
> remember a few weeks back when i upgraded jenkins, and unwittingly began
> DOSing our system due to massive log spam?
> 
> well, that bug has been fixed w/the current release and i'd like to get our
> logging levels back to something more verbose that we have now.
> 
> downtime will be from 730am-1000am PDT (i do expect this to be done well
> before 1000am)
> 
> the update will be from 1.578 -> 1.582
> 
> changelog here: http://jenkins-ci.org/changelog
> 
> please let me know if there are any questions or concerns. thanks!
> 
> shane, your friendly devops engineer 


--542a1ceb_507ed7ab_cc8--


From dev-return-9633-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 02:48:58 2014
Return-Path: <dev-return-9633-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C4F68171E3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 02:48:58 +0000 (UTC)
Received: (qmail 6235 invoked by uid 500); 30 Sep 2014 02:48:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6166 invoked by uid 500); 30 Sep 2014 02:48:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6154 invoked by uid 99); 30 Sep 2014 02:48:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:48:57 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.53 as permitted sender)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 02:48:31 +0000
Received: by mail-la0-f53.google.com with SMTP id gq15so1508998lab.40
        for <dev@spark.apache.org>; Mon, 29 Sep 2014 19:48:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IPTKkOgTl8RZ1z53kidu0sruF35HkU3Mn2+i1Zs4c1o=;
        b=qxuD2q0/i12KKXH1HF3o9OvcwVSg2P5LyGIuNrvzdkVn6aOPqQw00878Hm+M/CR6qk
         PXc9FpKp3MQzWFZc/7NShXmlwSaPgvH7cbkXtrdF+4hvM14DzaIxzJawcasVlgcezP+L
         HvQH1YRBy1Bw+iRwGz4Vz3WMkf+Lsb4DrRUqsm5J+If+erwtD/bptvfVUlLDk3SFAahH
         HHhkZpZBEBzPY+UzZ30s8ren84E7uqZwH4XHTzMUDEHfd9F0Q6VAls1YmJkoDml+ROm7
         J8LkSwIbclPe0SKJRPsS0PmenxoSIzBRxwxm/HAVEn3twcLf5w/Dthm134HVTsMIUVdD
         yltA==
MIME-Version: 1.0
X-Received: by 10.112.55.102 with SMTP id r6mr40635457lbp.23.1412045310442;
 Mon, 29 Sep 2014 19:48:30 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Mon, 29 Sep 2014 19:48:30 -0700 (PDT)
In-Reply-To: <542A1966.6020104@gmail.com>
References: <542A1966.6020104@gmail.com>
Date: Mon, 29 Sep 2014 19:48:30 -0700
Message-ID: <CA+B-+fxcccZNsbmLnshA5Bu5n+einZx-fJEBBE0=TnAEL3iALQ@mail.gmail.com>
Subject: Re: Hyper Parameter Optimization Algorithms
From: Debasish Das <debasish.das83@gmail.com>
To: Lochana Menikarachchi <lochanac@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133d0b222c1f605043f6bd9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133d0b222c1f605043f6bd9
Content-Type: text/plain; charset=UTF-8

You should look into Evan Spark's talk from Spark Summit 2014

http://spark-summit.org/2014/talk/model-search-at-scale

I am not sure if some of it is already open sourced through MLBase...

On Mon, Sep 29, 2014 at 7:45 PM, Lochana Menikarachchi <lochanac@gmail.com>
wrote:

> Hi,
>
> Is there anyone who works on hyper parameter optimization algorithms? If
> not, is there any interest on the subject. We are thinking about
> implementing some of these algorithms and contributing to spark? thoughts?
>
> Lochana
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1133d0b222c1f605043f6bd9--

From dev-return-9634-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 04:06:28 2014
Return-Path: <dev-return-9634-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C1E2317309
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 04:06:28 +0000 (UTC)
Received: (qmail 60758 invoked by uid 500); 30 Sep 2014 03:43:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60665 invoked by uid 500); 30 Sep 2014 03:43:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60640 invoked by uid 99); 30 Sep 2014 03:43:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 03:43:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 03:37:05 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Subject: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Date: Tue, 30 Sep 2014 11:36:55 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC31@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Thread-Index: Ac/cX8hnlK7990DKT66lSmsS9x92vA==
From: "Haopu Wang" <HWang@qilinsoft.com>
To: <dev@spark.apache.org>
Cc: <user@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

I take a look at HashOuterJoin and it's building a Hashtable for both
sides.

This consumes quite a lot of memory when the partition is big. And it
doesn't reduce the iteration on streamed relation, right?

Thanks!

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9635-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 04:31:52 2014
Return-Path: <dev-return-9635-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 32DEF173D8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 04:31:52 +0000 (UTC)
Received: (qmail 26447 invoked by uid 500); 30 Sep 2014 04:31:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26295 invoked by uid 500); 30 Sep 2014 04:31:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25347 invoked by uid 99); 30 Sep 2014 04:31:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 04:31:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of liquanpei@gmail.com designates 74.125.82.175 as permitted sender)
Received: from [74.125.82.175] (HELO mail-we0-f175.google.com) (74.125.82.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 04:31:23 +0000
Received: by mail-we0-f175.google.com with SMTP id q59so3013581wes.6
        for <multiple recipients>; Mon, 29 Sep 2014 21:31:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=UPZLI1KIzqZLduL8bxy1t5CEa6BeMfupPTTkEiTA67U=;
        b=lDP7UZbznDiHfSlOIximCtMBLuUwMLsTQy2HxDspy2JswCT9BvmjbmNvdu3BUmrvCw
         L0H2OU1WzMnVsnmDAcGWaAPskNm0DnZHvqnTgJMs+PuSqk0Cp/vfz17qmHhbsVqrn58U
         LqmfBlVUVclOApD9CSuhcgi94qHaFXch6+egWZmcuTfzT4EShergzmlhMrjlewf3hgcD
         QnmzKuZ3Lw8EzweN13PGHpqINIAhX9qIswjSeRuD65ojkMC/B2ednVmS/0HoX4oDjqrZ
         ahgzQIVUJOEAtio0EuNrjkRKNnjDf5cvNFy4zKWc3xfphXi9bhpgerj5A6uTevhUj3/s
         KnFA==
MIME-Version: 1.0
X-Received: by 10.180.79.34 with SMTP id g2mr2662547wix.10.1412051483125; Mon,
 29 Sep 2014 21:31:23 -0700 (PDT)
Received: by 10.27.13.17 with HTTP; Mon, 29 Sep 2014 21:31:23 -0700 (PDT)
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC31@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC31@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Date: Mon, 29 Sep 2014 21:31:23 -0700
Message-ID: <CAJmC80-nJ329AjGoaaFPSdQA87PePoMuMA59sBzq86=wdYLy=w@mail.gmail.com>
Subject: Re: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
From: Liquan Pei <liquanpei@gmail.com>
To: Haopu Wang <HWang@qilinsoft.com>
Cc: dev@spark.apache.org, user <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d041825d80e6f01050440db66
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d041825d80e6f01050440db66
Content-Type: text/plain; charset=UTF-8

Hi Haopu,

My understanding is that the hashtable on both left and right side is used
for including null values in result in an efficient manner. If hash table
is only built on one side, let's say left side and we perform a left outer
join, for each row in left side, a scan over the right side is needed to
make sure that no matching tuples for that row on left side.

Hope this helps!
Liquan

On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> wrote:

> I take a look at HashOuterJoin and it's building a Hashtable for both
> sides.
>
> This consumes quite a lot of memory when the partition is big. And it
> doesn't reduce the iteration on streamed relation, right?
>
> Thanks!
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>


-- 
Liquan Pei
Department of Physics
University of Massachusetts Amherst

--f46d041825d80e6f01050440db66--

From dev-return-9636-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 06:48:14 2014
Return-Path: <dev-return-9636-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DF5E11772B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 06:48:14 +0000 (UTC)
Received: (qmail 1019 invoked by uid 500); 30 Sep 2014 06:48:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 964 invoked by uid 500); 30 Sep 2014 06:48:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99851 invoked by uid 99); 30 Sep 2014 06:48:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 06:48:10 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 06:47:43 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CFDC7A.D78848AC"
Subject: RE: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Date: Tue, 30 Sep 2014 14:47:37 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC35@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
In-Reply-To: <CAJmC80-nJ329AjGoaaFPSdQA87PePoMuMA59sBzq86=wdYLy=w@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Thread-Index: Ac/cZ9BjJbB2AHn3Re+t08P95aIXSgAEhNAQ
From: "Haopu Wang" <HWang@qilinsoft.com>
To: "Liquan Pei" <liquanpei@gmail.com>
Cc: <dev@spark.apache.org>,
	"user" <user@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CFDC7A.D78848AC
Content-Type: text/plain;
	charset="GB2312"
Content-Transfer-Encoding: quoted-printable

Hi, Liquan, thanks for the response.

=20

In your example, I think the hash table should be built on the "right" =
side, so Spark can iterate through the left side and find matches in the =
right side from the hash table efficiently. Please comment and suggest, =
thanks again!

=20

________________________________

From: Liquan Pei [mailto:liquanpei@gmail.com]=20
Sent: 2014=C4=EA9=D4=C230=C8=D5 12:31
To: Haopu Wang
Cc: dev@spark.apache.org; user
Subject: Re: Spark SQL question: why build hashtable for both sides in =
HashOuterJoin?

=20

Hi Haopu,

=20

My understanding is that the hashtable on both left and right side is =
used for including null values in result in an efficient manner. If hash =
table is only built on one side, let's say left side and we perform a =
left outer join, for each row in left side, a scan over the right side =
is needed to make sure that no matching tuples for that row on left =
side.=20

=20

Hope this helps!

Liquan

=20

On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> wrote:

I take a look at HashOuterJoin and it's building a Hashtable for both
sides.

This consumes quite a lot of memory when the partition is big. And it
doesn't reduce the iteration on streamed relation, right?

Thanks!

---------------------------------------------------------------------
To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
For additional commands, e-mail: user-help@spark.apache.org





=20

--=20
Liquan Pei=20
Department of Physics=20
University of Massachusetts Amherst=20


------_=_NextPart_001_01CFDC7A.D78848AC--

From dev-return-9637-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 08:25:31 2014
Return-Path: <dev-return-9637-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E3A0017B25
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 08:25:30 +0000 (UTC)
Received: (qmail 99191 invoked by uid 500); 30 Sep 2014 08:25:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99024 invoked by uid 500); 30 Sep 2014 08:25:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98794 invoked by uid 99); 30 Sep 2014 08:25:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 08:25:28 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 08:25:23 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so1932961lab.27
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 01:25:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=FNrIFqR33rGDGFL1lFVNAjlVDiQOkj8ezXIh/Z9zG4w=;
        b=tm9Mzj69ymBEbvqQ9xWG5bBqHsPwD+Ck6SiO4PruNIun46DGbRBtLeGCSc4NjK3OxL
         sHpZ5gm3MPbW50WBj6hicxpM7VkSZ3amzgAAWdaufdZ+rvMAG/mTvxdOmd7hBfhsiZNy
         /vTQ4bcZP7zEi3TSlBwFsqHdzYhxT459y+ihgURLmZPMlKwfYr1Ct0YinHbONramlCYw
         h2CaVaj0pUzZ9xCSU8j5Lpk63VPBs8z8NXuPEEtzEdwQHnohRAHFZyO+YiDI6DOR6VNR
         kIooeShwKJurWuyDL8WiPvO7yqVCqBsnxgSs4qUw5d7gDQDLXlnDqRmeE00M6gR3/x4R
         TiZg==
MIME-Version: 1.0
X-Received: by 10.112.148.170 with SMTP id tt10mr43644023lbb.61.1412065501975;
 Tue, 30 Sep 2014 01:25:01 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Tue, 30 Sep 2014 01:25:01 -0700 (PDT)
Date: Tue, 30 Sep 2014 01:25:01 -0700
Message-ID: <CA+B-+fyXuHOJD86YBAxydojhYuHvQW50Ny=kZZNr8sKayy_Y4Q@mail.gmail.com>
Subject: Cluster tests failing
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a7d8ea51a870504441eb7
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a7d8ea51a870504441eb7
Content-Type: text/plain; charset=UTF-8

Hi,

Inside mllib I am running tests using:

mvn -Dhadoop.version=2.3.0-cdh5.1.0 -Phadoop-2.3 -Pyarn install

The locat tests run fine but cluster tests are failing..

LBFGSClusterSuite:

- task size should be small *** FAILED ***

  org.apache.spark.SparkException: Job aborted due to stage failure: Master
removed our application: FAILED

Do I need to start a localhost spark cluster first before running these
tests that has ClusterSuite in them ?

Thanks.

Deb

--047d7b3a7d8ea51a870504441eb7--

From dev-return-9638-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 09:38:23 2014
Return-Path: <dev-return-9638-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8138C17E1B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 09:38:23 +0000 (UTC)
Received: (qmail 68323 invoked by uid 500); 30 Sep 2014 09:38:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68253 invoked by uid 500); 30 Sep 2014 09:38:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68242 invoked by uid 99); 30 Sep 2014 09:38:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 09:38:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wangfei1@huawei.com designates 119.145.14.66 as permitted sender)
Received: from [119.145.14.66] (HELO szxga03-in.huawei.com) (119.145.14.66)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 09:38:16 +0000
Received: from 172.24.2.119 (EHLO szxeml421-hub.china.huawei.com) ([172.24.2.119])
	by szxrg03-dlp.huawei.com (MOS 4.4.3-GA FastPath queued)
	with ESMTP id AVA88223;
	Tue, 30 Sep 2014 17:37:54 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml421-hub.china.huawei.com
 (10.82.67.160) with Microsoft SMTP Server id 14.3.158.1; Tue, 30 Sep 2014
 17:37:52 +0800
Message-ID: <542A79F1.9030705@huawei.com>
Date: Tue, 30 Sep 2014 17:37:53 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: <dev@spark.apache.org>
Subject: Re: Cluster tests failing
References: <CA+B-+fyXuHOJD86YBAxydojhYuHvQW50Ny=kZZNr8sKayy_Y4Q@mail.gmail.com>
In-Reply-To: <CA+B-+fyXuHOJD86YBAxydojhYuHvQW50Ny=kZZNr8sKayy_Y4Q@mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Mirapoint-Virus-RAPID-Raw: score=unknown(0),
	refid=str=0001.0A020204.542A79F2.0101,ss=1,re=0.000,recu=0.000,reip=0.000,cl=1,cld=1,fgs=0,
	ip=0.0.0.0,
	so=2013-05-26 15:14:31,
	dmn=2013-03-21 17:37:32
X-Mirapoint-Loop-Id: ba2b656c51ee1c6e84366b6de4e5661a
X-Virus-Checked: Checked by ClamAV on apache.org

first run cmd mvn clean, then try again

On 2014/9/30 16:25, Debasish Das wrote:
>    org.apache.spark.SparkException: Job aborted due to stage failure: Master



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9639-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 10:34:30 2014
Return-Path: <dev-return-9639-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8F8BA17F62
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 10:34:30 +0000 (UTC)
Received: (qmail 74797 invoked by uid 500); 30 Sep 2014 10:34:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74732 invoked by uid 500); 30 Sep 2014 10:34:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73590 invoked by uid 99); 30 Sep 2014 10:34:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 10:34:27 +0000
X-ASF-Spam-Status: No, hits=1.8 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of liquanpei@gmail.com designates 209.85.218.46 as permitted sender)
Received: from [209.85.218.46] (HELO mail-oi0-f46.google.com) (209.85.218.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 10:34:01 +0000
Received: by mail-oi0-f46.google.com with SMTP id h136so3381354oig.5
        for <multiple recipients>; Tue, 30 Sep 2014 03:34:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=9EgmnZ9OxrL1+GKRdUbfrpEbNP+CfAFeF0BpD6vic2I=;
        b=pGwiiA1cVP8w5n25F4DbyCFLj2eRpA5o4iwWEh9LTrkJoIYDIzRBiBz1a1Sl33o43E
         a8y8h9odjF5OP/AP2S8UWj5qvSedrZOSdS2NuMcktDVgZObCyH2UKbArbsLExwOVgJtW
         JDpZxdJ3WuF+0hVgOt9GumZiP4gaGQW+gNGdQZ2WD6OuRXAyCi17ctmloqPHJl0blG31
         lxBkPrqQ9pB9gPThlkfgfZhSU4CaOkgi1oaiRq8sTKnmBfSrrc88Axq5uEiizr0VrQXh
         G/yEl53d0z649rZtfQU/aUWyy5DbZzKjc8Lm5KkRmFJ7xcHy36L5LAgwm4u3AfP8//2G
         e9kw==
MIME-Version: 1.0
X-Received: by 10.182.52.197 with SMTP id v5mr2000887obo.85.1412073239967;
 Tue, 30 Sep 2014 03:33:59 -0700 (PDT)
Received: by 10.76.128.75 with HTTP; Tue, 30 Sep 2014 03:33:59 -0700 (PDT)
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC35@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <CAJmC80-nJ329AjGoaaFPSdQA87PePoMuMA59sBzq86=wdYLy=w@mail.gmail.com>
	<2EB23AF5EEEA2140946B8F292EB2EB9F13AC35@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Date: Tue, 30 Sep 2014 03:33:59 -0700
Message-ID: <CAJmC80-Tk-paEsq94DUJubq2CRO7A7Y1Yia4frwfLkD3ug8nsg@mail.gmail.com>
Subject: Re: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
From: Liquan Pei <liquanpei@gmail.com>
To: Haopu Wang <HWang@qilinsoft.com>
Cc: dev@spark.apache.org, user <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b0d8dd7caa050445ebdf
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b0d8dd7caa050445ebdf
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Haopu,

How about full outer join? One hash table may not be efficient for this
case.

Liquan

On Mon, Sep 29, 2014 at 11:47 PM, Haopu Wang <HWang@qilinsoft.com> wrote:

>        Hi, Liquan, thanks for the response.
>
>
>
> In your example, I think the hash table should be built on the "right"
> side, so Spark can iterate through the left side and find matches in the
> right side from the hash table efficiently. Please comment and suggest,
> thanks again!
>
>
>  ------------------------------
>
> *From:* Liquan Pei [mailto:liquanpei@gmail.com]
> *Sent:* 2014=E5=B9=B49=E6=9C=8830=E6=97=A5 12:31
> *To:* Haopu Wang
> *Cc:* dev@spark.apache.org; user
> *Subject:* Re: Spark SQL question: why build hashtable for both sides in
> HashOuterJoin?
>
>
>
> Hi Haopu,
>
>
>
> My understanding is that the hashtable on both left and right side is use=
d
> for including null values in result in an efficient manner. If hash table
> is only built on one side, let's say left side and we perform a left oute=
r
> join, for each row in left side, a scan over the right side is needed to
> make sure that no matching tuples for that row on left side.
>
>
>
> Hope this helps!
>
> Liquan
>
>
>
> On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> wrote:
>
> I take a look at HashOuterJoin and it's building a Hashtable for both
> sides.
>
> This consumes quite a lot of memory when the partition is big. And it
> doesn't reduce the iteration on streamed relation, right?
>
> Thanks!
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>
>
>
>
> --
> Liquan Pei
> Department of Physics
> University of Massachusetts Amherst
>



--=20
Liquan Pei
Department of Physics
University of Massachusetts Amherst

--089e0158b0d8dd7caa050445ebdf--

From dev-return-9640-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 15:24:01 2014
Return-Path: <dev-return-9640-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B8AE179B5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 15:24:01 +0000 (UTC)
Received: (qmail 24947 invoked by uid 500); 30 Sep 2014 15:24:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24880 invoked by uid 500); 30 Sep 2014 15:24:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24859 invoked by uid 99); 30 Sep 2014 15:24:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 15:23:59 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 15:23:54 +0000
Received: by mail-lb0-f172.google.com with SMTP id b6so4790587lbj.3
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 08:23:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=gN3csL/XmpAR4QE+v8pXqrPoCItTPkV7tATF1NTBNFI=;
        b=V/gLJZFCvm1gKydVLAiltueLVolvqoT13eFHZkjT9usE37U/5qeTS9ri7aFItfbKG5
         +Ykaos+LoSiBsCG4JgkJxTbX4dOC6zhzehPwNhzEpmT8YKMb8cSQmFDTFdrTbxaG7ahA
         j8jR2z8moTRBB0C5KtAb6Uc/dW9ZF0FrgRk8QKWBzImD7yp2EjSCbEfvRzIky8pkdgHr
         qTOIZcdsdaD7buBv9BBXjcuBKWimCNj+ZPy4p3YgACSTj0L3SFZKRgjvMAI8vRBmdlQf
         68uDZm+fNLosiCN/ywbWoQmwqwjIC1RHrjcsOxtAnH2h7PePM+gvXFPlN0DAJe5BcG+c
         8GgA==
MIME-Version: 1.0
X-Received: by 10.152.28.74 with SMTP id z10mr49226726lag.10.1412090612586;
 Tue, 30 Sep 2014 08:23:32 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Tue, 30 Sep 2014 08:23:32 -0700 (PDT)
In-Reply-To: <542A79F1.9030705@huawei.com>
References: <CA+B-+fyXuHOJD86YBAxydojhYuHvQW50Ny=kZZNr8sKayy_Y4Q@mail.gmail.com>
	<542A79F1.9030705@huawei.com>
Date: Tue, 30 Sep 2014 08:23:32 -0700
Message-ID: <CA+B-+fzbFqtck806YOOM+haWMo1QzQz1qfqvoqan4-vkPg1P-A@mail.gmail.com>
Subject: Re: Cluster tests failing
From: Debasish Das <debasish.das83@gmail.com>
To: scwf <wangfei1@huawei.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160b81e5a9f93050449f79f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160b81e5a9f93050449f79f
Content-Type: text/plain; charset=UTF-8

I have done mvn clean several times...

Consistently all the mllib tests that are using
LocalClusterSparkContext.scala, they fail !

--089e0160b81e5a9f93050449f79f--

From dev-return-9641-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 17:12:03 2014
Return-Path: <dev-return-9641-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C04A517D85
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 17:12:03 +0000 (UTC)
Received: (qmail 92164 invoked by uid 500); 30 Sep 2014 17:12:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92100 invoked by uid 500); 30 Sep 2014 17:12:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92078 invoked by uid 99); 30 Sep 2014 17:12:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:12:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.178 as permitted sender)
Received: from [209.85.213.178] (HELO mail-ig0-f178.google.com) (209.85.213.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:11:56 +0000
Received: by mail-ig0-f178.google.com with SMTP id l13so4376735iga.11
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 10:11:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=QBwBtWz8biH0EndQrmA/ObJGiTHshpg2YRo+NzXxj9I=;
        b=z8kBibEBvT0jmj7/9u4aAJ9euXwsAK0WS2D6ey3l/ctRXqwb0qqRSOUI93lnYLc9So
         ZzzjEEtxQ9885NgruUXpei9GhmnaMNvEMsZvRugdmJWobSUCHgDNj4RTjXZHtZnYrnMs
         XwUQmEBaz22GaGzqmwsISfmNs9cF/89/WM9jVXV7UONQaRtv+DedIktE2fzuX0hLD6wk
         hLXxeAgB4fkYLlPtKK4cPxRjOn5r1l4z41P2oMt9b9URkin46YxLs925CImbrzj/85RC
         QOj8tAdtjqjdZU6msRU9OwswTOk4OlW7LLuu1M7Xd7Knsm54NT7FOMJ9jdr2L/z+iqwW
         MtRA==
MIME-Version: 1.0
X-Received: by 10.42.90.80 with SMTP id j16mr52695520icm.27.1412097096050;
 Tue, 30 Sep 2014 10:11:36 -0700 (PDT)
Received: by 10.107.152.3 with HTTP; Tue, 30 Sep 2014 10:11:35 -0700 (PDT)
In-Reply-To: <CA+B-+fzbFqtck806YOOM+haWMo1QzQz1qfqvoqan4-vkPg1P-A@mail.gmail.com>
References: <CA+B-+fyXuHOJD86YBAxydojhYuHvQW50Ny=kZZNr8sKayy_Y4Q@mail.gmail.com>
	<542A79F1.9030705@huawei.com>
	<CA+B-+fzbFqtck806YOOM+haWMo1QzQz1qfqvoqan4-vkPg1P-A@mail.gmail.com>
Date: Tue, 30 Sep 2014 10:11:35 -0700
Message-ID: <CAJgQjQ_6yYZtDW2iwA-7OJ4OYk_ib6Nvo8Qx0713iEqbskFkJg@mail.gmail.com>
Subject: Re: Cluster tests failing
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: scwf <wangfei1@huawei.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Try to build the assembly jar first. ClusterSuite uses local-cluster
mode, which requires the assembly jar. -Xiangrui

On Tue, Sep 30, 2014 at 8:23 AM, Debasish Das <debasish.das83@gmail.com> wrote:
> I have done mvn clean several times...
>
> Consistently all the mllib tests that are using
> LocalClusterSparkContext.scala, they fail !

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9642-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 17:23:21 2014
Return-Path: <dev-return-9642-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1BD6217DE9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 17:23:21 +0000 (UTC)
Received: (qmail 24413 invoked by uid 500); 30 Sep 2014 17:23:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24341 invoked by uid 500); 30 Sep 2014 17:23:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24330 invoked by uid 99); 30 Sep 2014 17:23:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:23:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:23:13 +0000
Received: by mail-la0-f45.google.com with SMTP id q1so9085655lam.18
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 10:22:52 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=+cEHKePm0oy6qJB0SPIIBZmGCrOSRHjTajNJGtfK05A=;
        b=FJQj9fBpxFpD5u5osnsAImObm3smw2QCWFMVaMvpjIyf02IYQ3HzDqZ4ytOLa7qjqm
         Y5hU73PmYGNXh5Fx7+226nIMiHz+4a7tnsd5T3LlsCA6Nv5FYPVqvRWbHwNT8gnYQfqQ
         mbPzr/06k1CbAknRn8TWsVD5y+UdxViYtL6y9rs0E6a2n+Rctgvb0fDRp8QASWWq/EXt
         PR9pQ4twkpnOJp0TFPGy+X3jeYN57L2TSUTOgQS1AjhDdpdoYxwqgPm838jW3GYZkhbt
         BshKJzxII5nUDglyTPts8O+bG1CHp7PVD+csKDez07jJd15Qmxz0LPx+h1anbKMRmOHi
         MVOw==
X-Gm-Message-State: ALoCoQk/koJjGeuOO1RQ6uwfI69Xw/5bo55x7btuLvCf4+72RCrfDxtjRx8yoHzh7rKyRL+i9M/e
X-Received: by 10.112.146.1 with SMTP id sy1mr45174480lbb.77.1412097771595;
 Tue, 30 Sep 2014 10:22:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Tue, 30 Sep 2014 10:22:31 -0700 (PDT)
In-Reply-To: <8E629B87D9B941CC97EDC8DE5CC946D0@gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
 <8E629B87D9B941CC97EDC8DE5CC946D0@gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 30 Sep 2014 10:22:31 -0700
Message-ID: <CACdU-dQdvMM2DK-mh1hXXmxEZk9gG2Rt67OmYYa4Gb9inpjxZw@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a85d01076d005044ba21c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a85d01076d005044ba21c
Content-Type: text/plain; charset=UTF-8

(this time, reply to all)

nice catch.  there's a bug in spark/dev/check-license, which i've confirmed
from the CLI.  i'll open a bug and PR to fix it.

On Mon, Sep 29, 2014 at 8:00 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  Just noticed these lines in the jenkins log
>
> =========================================================================
> Running Apache RAT checks
> =========================================================================
> Attempting to fetch rat
> Launching rat from /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar
> Error: Invalid or corrupt jarfile /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar
> RAT checks passed.
>
>
> Something wrong?
>
>
> Best,
>
>
> --
> Nan Zhu
>
> On Monday, September 29, 2014 at 4:43 PM, shane knapp wrote:
>
> happy monday, everyone!
>
> remember a few weeks back when i upgraded jenkins, and unwittingly began
> DOSing our system due to massive log spam?
>
> well, that bug has been fixed w/the current release and i'd like to get our
> logging levels back to something more verbose that we have now.
>
> downtime will be from 730am-1000am PDT (i do expect this to be done well
> before 1000am)
>
> the update will be from 1.578 -> 1.582
>
> changelog here: http://jenkins-ci.org/changelog
>
> please let me know if there are any questions or concerns. thanks!
>
> shane, your friendly devops engineer
>
>
>

--047d7b3a85d01076d005044ba21c--

From dev-return-9643-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 17:35:28 2014
Return-Path: <dev-return-9643-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 516DD17E68
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 17:35:28 +0000 (UTC)
Received: (qmail 60983 invoked by uid 500); 30 Sep 2014 17:35:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60916 invoked by uid 500); 30 Sep 2014 17:35:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60894 invoked by uid 99); 30 Sep 2014 17:35:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:35:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 17:35:22 +0000
Received: by mail-lb0-f176.google.com with SMTP id p9so4858077lbv.21
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 10:35:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=CFNANLoDfTlxcBESaIUIUi+EHbkTG2NPZZcs8G156a0=;
        b=cq1uML7xMiHW0wtGtosf46z0pIsMbuR95KVIJ3w9Yb0zKIj47dGh+xhfCcoEi/amB+
         RmBHLmk9bQDilaMjiXK2L96dv4uSOmoWuSYDHMOrXXX9w4+rc61sURz7PrMUFeGVJQ5f
         jukZ5X4u4h98U/vs76cOSEvlCVBVc28IQuZiZ25exznMOWK8E0xKFZ1ZeSF9r0vrBuXX
         E1tHpdQCP9acDcV40oCmDaPJHHiHgeIlSBQ5fTrE68tI7PhXVzOHsBx2KtZEHX9039JZ
         DNK1Vo+uYjanmgCXwnnQKx+g/iKbJC/Ar8xn4osC+FwWh2ErzPoF8pd6X1OIgjh/mqBt
         /Dvw==
X-Gm-Message-State: ALoCoQkuXlXSsnegqZIh5AMcql9yMZNmbi4S3TwJ/osnMOpVj0+1H/HF/ky+ThkBvifQzpH27VSm
X-Received: by 10.152.25.129 with SMTP id c1mr49976169lag.14.1412098500622;
 Tue, 30 Sep 2014 10:35:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Tue, 30 Sep 2014 10:34:40 -0700 (PDT)
In-Reply-To: <CACdU-dQdvMM2DK-mh1hXXmxEZk9gG2Rt67OmYYa4Gb9inpjxZw@mail.gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
 <8E629B87D9B941CC97EDC8DE5CC946D0@gmail.com> <CACdU-dQdvMM2DK-mh1hXXmxEZk9gG2Rt67OmYYa4Gb9inpjxZw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 30 Sep 2014 10:34:40 -0700
Message-ID: <CACdU-dRU9Y0pHe=ohSu6ugLnhDfnh5HciUyAHg8nEGbJsQGymw@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160bcb4848a0905044bcdd3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160bcb4848a0905044bcdd3
Content-Type: text/plain; charset=UTF-8

https://issues.apache.org/jira/browse/SPARK-3745

On Tue, Sep 30, 2014 at 10:22 AM, shane knapp <sknapp@berkeley.edu> wrote:

> (this time, reply to all)
>
> nice catch.  there's a bug in spark/dev/check-license, which i've
> confirmed from the CLI.  i'll open a bug and PR to fix it.
>
> On Mon, Sep 29, 2014 at 8:00 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
>>  Just noticed these lines in the jenkins log
>>
>> =========================================================================
>> Running Apache RAT checks
>> =========================================================================
>> Attempting to fetch rat
>> Launching rat from /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar
>> Error: Invalid or corrupt jarfile /home/jenkins/workspace/SparkPullRequestBuilder/lib/apache-rat-0.10.jar
>> RAT checks passed.
>>
>>
>> Something wrong?
>>
>>
>> Best,
>>
>>
>> --
>> Nan Zhu
>>
>> On Monday, September 29, 2014 at 4:43 PM, shane knapp wrote:
>>
>> happy monday, everyone!
>>
>> remember a few weeks back when i upgraded jenkins, and unwittingly began
>> DOSing our system due to massive log spam?
>>
>> well, that bug has been fixed w/the current release and i'd like to get
>> our
>> logging levels back to something more verbose that we have now.
>>
>> downtime will be from 730am-1000am PDT (i do expect this to be done well
>> before 1000am)
>>
>> the update will be from 1.578 -> 1.582
>>
>> changelog here: http://jenkins-ci.org/changelog
>>
>> please let me know if there are any questions or concerns. thanks!
>>
>> shane, your friendly devops engineer
>>
>>
>>
>

--089e0160bcb4848a0905044bcdd3--

From dev-return-9644-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 21:36:36 2014
Return-Path: <dev-return-9644-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6806D17999
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 21:36:36 +0000 (UTC)
Received: (qmail 74538 invoked by uid 500); 30 Sep 2014 21:36:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74469 invoked by uid 500); 30 Sep 2014 21:36:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74444 invoked by uid 99); 30 Sep 2014 21:36:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 21:36:34 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of atalwalkar@gmail.com designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 21:36:09 +0000
Received: by mail-lb0-f177.google.com with SMTP id w7so4101919lbi.36
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 14:36:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=BG8n9es5ccPm7+9wdQv5+g5attT6Sdm8QZEmpXqoR6I=;
        b=WNcDlfOZX+kyC4gIQ9BM4rHm7LeipPmmPj2K0wTVrpD2+c1aZySP/xRPIAsRx+5I3A
         BTm3WTvnYIQtpzOuceHBkq29N++6k4+TyL1b0anDMKjOdBb2t71LuFwu1XiIh8Fxyshg
         nlXb+synhQAhXrqZI/dx7+59MvS9pWoVU7DIqdN4z796fgk14VTlccU1SWsg/GSPXg+x
         FAyn6yOIlUh3h3SPcwDxFFdRCVZFvvXkodvSLf05N7ipcu4m3kltQPPfY4FLoxTZYCtO
         2NfXYImrOW8Dow5Nwv5A6N3VFNtLn26zE+Dgxabw5cxHF7wA6U60AXVot3/EARbeOA6L
         dTJA==
X-Received: by 10.152.23.199 with SMTP id o7mr50647461laf.26.1412112968070;
 Tue, 30 Sep 2014 14:36:08 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.64.8 with HTTP; Tue, 30 Sep 2014 14:35:48 -0700 (PDT)
In-Reply-To: <CA+B-+fxcccZNsbmLnshA5Bu5n+einZx-fJEBBE0=TnAEL3iALQ@mail.gmail.com>
References: <542A1966.6020104@gmail.com> <CA+B-+fxcccZNsbmLnshA5Bu5n+einZx-fJEBBE0=TnAEL3iALQ@mail.gmail.com>
From: Ameet Talwalkar <atalwalkar@gmail.com>
Date: Tue, 30 Sep 2014 14:35:48 -0700
Message-ID: <CAH3_EVPsBzkL2omXYxRjObUGu7ZxitZRM97Z-nun_6oQCZhjFg@mail.gmail.com>
Subject: Re: Hyper Parameter Optimization Algorithms
To: Debasish Das <debasish.das83@gmail.com>
Cc: Lochana Menikarachchi <lochanac@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158c95ad83c5605044f2b8c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158c95ad83c5605044f2b8c
Content-Type: text/plain; charset=UTF-8

Hi Lochana,

We are indeed working on hyperparameter optimization as part of the MLbase
<http://www.mlbase.org/> project.  We are writing a paper about this work
right now, and also plan to eventually open-source our code.

-Ameet

On Mon, Sep 29, 2014 at 7:48 PM, Debasish Das <debasish.das83@gmail.com>
wrote:

> You should look into Evan Spark's talk from Spark Summit 2014
>
> http://spark-summit.org/2014/talk/model-search-at-scale
>
> I am not sure if some of it is already open sourced through MLBase...
>
> On Mon, Sep 29, 2014 at 7:45 PM, Lochana Menikarachchi <lochanac@gmail.com
> >
> wrote:
>
> > Hi,
> >
> > Is there anyone who works on hyper parameter optimization algorithms? If
> > not, is there any interest on the subject. We are thinking about
> > implementing some of these algorithms and contributing to spark?
> thoughts?
> >
> > Lochana
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--089e0158c95ad83c5605044f2b8c--

From dev-return-9645-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Sep 30 21:41:39 2014
Return-Path: <dev-return-9645-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CC45E179D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 30 Sep 2014 21:41:39 +0000 (UTC)
Received: (qmail 91840 invoked by uid 500); 30 Sep 2014 21:41:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91772 invoked by uid 500); 30 Sep 2014 21:41:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91760 invoked by uid 99); 30 Sep 2014 21:41:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 21:41:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 30 Sep 2014 21:41:34 +0000
Received: by mail-la0-f42.google.com with SMTP id mk6so4847596lab.1
        for <dev@spark.apache.org>; Tue, 30 Sep 2014 14:41:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=SusvBnxc8SqUcvA3GHMj6rnmhIq48xaEyAUFPIp8LOE=;
        b=OqMc/eClN9MM0tjh6z5/4X84TkyrnBN3h2WAjLLrtYP46QM/H0zDaiUTKeQOiNN0ho
         wsvEQDh7/Y+gnrq+trem8SvD59ynpE/V4YvAMpLgAKXrlXHuU04VSmGzW4t0g8d19UQg
         mcfSwqBuoZF7Z0rJ+qdrv/caldAv9EIChvC1Xc5gosDLzvXWOSOaeYx+EXI6OBJLcMhi
         8bgwGMrlWm5z/6+snqOVXbNI/c+QisCaKTLTTPzURX509JwHaAxPGDrydk3ZkWN/0pSk
         Qm/9N5BIKJbcHNLYMMmHEBRHns8pzEBJ3grRmcp+6ffBZla1H3m/icbxyQOgQa+5Ozfx
         pC4A==
X-Gm-Message-State: ALoCoQkYm8tCTdzEdL6KSaNwbo3zNDNbZfNq4YVqTmUFSJxtPE+FCZG+vPx6ylA+N3xg44pGdAtP
X-Received: by 10.112.160.163 with SMTP id xl3mr47256528lbb.80.1412113273174;
 Tue, 30 Sep 2014 14:41:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Tue, 30 Sep 2014 14:40:52 -0700 (PDT)
In-Reply-To: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 30 Sep 2014 14:40:52 -0700
Message-ID: <CACdU-dSK1K8VHvg25GJ4sEfBbUDB95aRG_gZuohTezmZbchDpg@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3426207caab05044f3e0e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3426207caab05044f3e0e
Content-Type: text/plain; charset=UTF-8

reminder:  this is happening tomorrow morning.  i will be putting jenkins
in to quiet mode at ~7am, and then doing the upgrade once any stray builds
finish.

On Mon, Sep 29, 2014 at 1:43 PM, shane knapp <sknapp@berkeley.edu> wrote:

> happy monday, everyone!
>
> remember a few weeks back when i upgraded jenkins, and unwittingly began
> DOSing our system due to massive log spam?
>
> well, that bug has been fixed w/the current release and i'd like to get
> our logging levels back to something more verbose that we have now.
>
> downtime will be from 730am-1000am PDT (i do expect this to be done well
> before 1000am)
>
> the update will be from 1.578 -> 1.582
>
> changelog here:  http://jenkins-ci.org/changelog
>
> please let me know if there are any questions or concerns.  thanks!
>
> shane, your friendly devops engineer
>

--001a11c3426207caab05044f3e0e--


From dev-return-796-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  1 23:10:16 2013
Return-Path: <dev-return-796-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BF52110E01
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Dec 2013 23:10:16 +0000 (UTC)
Received: (qmail 97600 invoked by uid 500); 1 Dec 2013 23:10:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97493 invoked by uid 500); 1 Dec 2013 23:10:16 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 97485 invoked by uid 99); 1 Dec 2013 23:10:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Dec 2013 23:10:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of umarj.javed@gmail.com designates 209.85.220.179 as permitted sender)
Received: from [209.85.220.179] (HELO mail-vc0-f179.google.com) (209.85.220.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Dec 2013 23:10:05 +0000
Received: by mail-vc0-f179.google.com with SMTP id ie18so8042440vcb.10
        for <dev@spark.incubator.apache.org>; Sun, 01 Dec 2013 15:09:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=Sru24OjT6ECAtz8/pHjXTiMOKlkpsJ9/caE/ycdywS8=;
        b=TnZe+65dH2zKFFMpaC/ggQ8gtRERSzdOoOdSYu7ydwuEJSdq5wnPEOx7ONatJIOk3F
         XdKgcR3cOW2y2tpSmAZRqb068ZYHV/qY8Cc+vCrSYY1Py2zR6dvA8Q5qZVyg9DkVnlUD
         P0r3zXepMT387coMYkCtFccc/dx2d3AqlKJSqHVrRJj90tg7RoIIJ4yiu8tuoEbPLYVF
         TLgo5hM2HDEYB6ya5tmzs10FiQzjgV7prs7xicnYfen/tLLHgfuLgPAqOrJ3CmnOgfSa
         HCriDFpy+2hgKjw7+8AG9t8c/+/aGpK0//1H0f+hj1j5Tk/z6dVHGOVyznkSduq0O0tr
         5GFQ==
MIME-Version: 1.0
X-Received: by 10.220.58.1 with SMTP id e1mr50534185vch.0.1385939384610; Sun,
 01 Dec 2013 15:09:44 -0800 (PST)
Received: by 10.220.72.73 with HTTP; Sun, 1 Dec 2013 15:09:44 -0800 (PST)
Date: Sun, 1 Dec 2013 15:09:44 -0800
Message-ID: <CACwKa9eD=ru3_WkDGep9_bFhhjfCp5iP4LoLvP3nzr52xh0sKA@mail.gmail.com>
Subject: compiling a new RDD
From: Umar Javed <umarj.javed@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c2c7dab3344f04ec8128eb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c7dab3344f04ec8128eb
Content-Type: text/plain; charset=ISO-8859-1

Hi,

I want to write a new RDD. For testing, I just copied and pasted
HadoopRDD.scala into the file newRDD.scala with the appropriate
replacements of "HadoopRDD'.
It compiles fine at this stage. Now I create newRDD() in SparkContext and
the compiler is giving me a type not found error:

.../incubator-spark/core/src/main/scala/org/apache/spark/SparkContext.scala:413:
not found: type newRDD

    new newRDD(
           ^

I must be missing something trivial here. Any ideas?

thanks!

--001a11c2c7dab3344f04ec8128eb--

From dev-return-797-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 17:14:42 2013
Return-Path: <dev-return-797-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C4C3110ABD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 17:14:42 +0000 (UTC)
Received: (qmail 47276 invoked by uid 500); 2 Dec 2013 17:10:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46285 invoked by uid 500); 2 Dec 2013 17:10:36 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 45994 invoked by uid 99); 2 Dec 2013 17:10:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 17:10:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 17:10:21 +0000
Received: by mail-ob0-f174.google.com with SMTP id wn1so12933566obc.5
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 09:09:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:cc:content-type;
        bh=hrIe5KVXwlq6cM3qJUwJNsxL3AVKgv8Y2VitB+iOKDI=;
        b=cD5PBqmiDRTk93+bDGG1GxyuVRdiICjPYuj9dR6YKjy0Q4e8LGryvs+g6baNVkxsk8
         EsXaq+/tWt5bxLui+z9ahy8uCWnR+F1WhfRxAR4OP5AgW+DCo/JeoroTR5l0Znn8hh1D
         qQ3jdzJ71GBWe29n1xAe/x0e0xjXftnM8UkrnYnPa+cs2xYATd0Nmwd/D9PowZWVUdeL
         Wb7zMt8yALDb/M7dHXKNfNLO+anXaxsEpKSl4rbhMC0GeeTfVjAIn3Or+IRRurib4N8D
         x7eo0P+3e7aIySwfSpNvQa0/E+EwgZZTRD7Osy9SeEduq1uEcTceltMPSaPtImItlqdG
         VAJA==
MIME-Version: 1.0
X-Received: by 10.182.117.195 with SMTP id kg3mr55746815obb.17.1386004199755;
 Mon, 02 Dec 2013 09:09:59 -0800 (PST)
Received: by 10.182.95.103 with HTTP; Mon, 2 Dec 2013 09:09:59 -0800 (PST)
Date: Mon, 2 Dec 2013 19:09:59 +0200
Message-ID: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
Subject: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Cc: Olivier Grisel <olivier.grisel@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=089e0149c506fbe48e04ec903fe6
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149c506fbe48e04ec903fe6
Content-Type: text/plain; charset=ISO-8859-1

Hi Spark Devs

An idea developed recently out of a scikit-learn mailing list discussion (
http://sourceforge.net/mailarchive/forum.php?thread_name=CAFvE7K5HGKYH9Myp7imrJ-nU%3DpJgeGqcCn3JC0m4MmGWZi35Hw%40mail.gmail.com&forum_name=scikit-learn-general)
to have a coding sprint around Strata in Feb, focused on integration
between scikit-learn and PySpark for large-scale machine learning tasks.

Cloudera has kindly agreed to host the sprint, most likely in San
Francisco. Ideally it would be focused and capped at around 10 people. The
idea is not meant to be a teaching workshop for
newcomers but more as a prototyping session, so ideally it would be great
to have developers and users with deep knowledge of PySpark (Josh
especially :) and/or scikit-learn, attend.

Hopefully we can get some people from the Spark community involved, and
Olivier will drum up support from the scikit-learn community.

All the best and hope to see you there (though likely I will only be able
to join remotely).
Nick

--089e0149c506fbe48e04ec903fe6--

From dev-return-798-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 21:13:24 2013
Return-Path: <dev-return-798-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BBDE01055E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 21:13:24 +0000 (UTC)
Received: (qmail 14434 invoked by uid 500); 2 Dec 2013 21:13:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14396 invoked by uid 500); 2 Dec 2013 21:13:24 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 14388 invoked by uid 99); 2 Dec 2013 21:13:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:13:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.170 as permitted sender)
Received: from [74.125.82.170] (HELO mail-we0-f170.google.com) (74.125.82.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:13:17 +0000
Received: by mail-we0-f170.google.com with SMTP id w61so12747760wes.15
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 13:12:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=oRX/sNxdL2lBH/fle73avygLWzh7K313CrXtqXKSQ08=;
        b=UBx6iiPTGaH/HtP1mqyJ/9hkXtdJMnTUmJeNHmGXAjHKzp7DCBPafdBzi5DFG/UfcS
         g0pPD8uh8o5rR6R3hX+QJIT3HNftWmL8iHs4D077yOC8nx+o035GSOSxJjCgS5T4RIiW
         fElt/hubddBcSIyBdb3STRb0ZeqRVIPXH0utWlTfPiJYk4M02/l1vaFNAoZobK+WUiQD
         UpE3lMea3qzu7FSFmiTf5BYYYjq7l0k0kBKaa3I27kdbPuXm//vlOk9JCUJnXVTDxuSO
         pPfP+un8mbe1dkZjVItRiGk48FzOCrtfUqHoBp0RW/kWFGeVC2D0+4Cini6wAqVsXsOp
         HS0Q==
X-Received: by 10.180.39.177 with SMTP id q17mr20074595wik.16.1386018777181;
 Mon, 02 Dec 2013 13:12:57 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Mon, 2 Dec 2013 13:12:37 -0800 (PST)
In-Reply-To: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Mon, 2 Dec 2013 22:12:37 +0100
X-Google-Sender-Auth: ktAbqAiBuop_8sP-I4MRIf5KnBY
Message-ID: <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Nick Pentreath <nick.pentreath@gmail.com>
Cc: dev@spark.incubator.apache.org, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

Just a quick reply to say that I would be glad to meet some of you to
hack on some prototype scikit-learn / PySpark integration.

Cloudera just confirmed that we have a room for us at their San
Fransisco offices on Friday Feb 14 (right after Strata).

Hope to see you there or at Strata,

-- 
Olivier

From dev-return-799-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 21:23:02 2013
Return-Path: <dev-return-799-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BF3D1105AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 21:23:02 +0000 (UTC)
Received: (qmail 31040 invoked by uid 500); 2 Dec 2013 21:23:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30993 invoked by uid 500); 2 Dec 2013 21:23:02 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 30985 invoked by uid 99); 2 Dec 2013 21:23:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:23:02 +0000
X-ASF-Spam-Status: No, hits=-1997.8 required=5.0
	tests=ALL_TRUSTED,HTML_MESSAGE,RP_MATCHES_RCVD
X-Spam-Check-By: apache.org
Received: from [140.211.11.3] (HELO mail.apache.org) (140.211.11.3)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 02 Dec 2013 21:22:59 +0000
Received: (qmail 30704 invoked by uid 99); 2 Dec 2013 21:22:37 -0000
Received: from minotaur.apache.org (HELO minotaur.apache.org) (140.211.11.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:22:37 +0000
Received: from localhost (HELO mail-vb0-f46.google.com) (127.0.0.1)
  (smtp-auth username rxin, mechanism plain)
  by minotaur.apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:22:37 +0000
Received: by mail-vb0-f46.google.com with SMTP id i12so8844780vbh.19
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 13:22:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=yh2h64F+a4jmj4cC+u+w0irgQWrw2RQTj+Kw9RhUKRI=;
        b=TgpBTAhyqV2KKDqvuvQCme5m1GtYgHf3+fgxZAxlb4sdw/p9OdzMMms/LY98LPgWfF
         yLIIq/+XfyGsUSSW4MuZbQwJq1/jjtaVRHKnis52dNd/xbS5Fol2Hklt//Nt4yzkuWc6
         NH0d+4hqUFag30B54dOvONJgtQV4g0O7/WbTIgEv+Ajc0qkk4KueSZrJQBSB9r+jv9Hs
         BaHOTEMDRd66Jy4inOuHKVR+1XupFpyBm6/IRwWc1gw7L02HZjuTFu/dp5o9LQxuHqHR
         AeQbgBdTDPJxAXsH3YGW6lrSqKs0OJ7Was0jndRtzURBHSEfNve/r6eFr2GlnYWDb1w6
         HU6Q==
X-Received: by 10.52.165.43 with SMTP id yv11mr766821vdb.64.1386019356060;
 Mon, 02 Dec 2013 13:22:36 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.109.135 with HTTP; Mon, 2 Dec 2013 13:22:15 -0800 (PST)
In-Reply-To: <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
From: Reynold Xin <rxin@apache.org>
Date: Mon, 2 Dec 2013 13:22:15 -0800
Message-ID: <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Cc: Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=001a11c208285eb66a04ec93c7f6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c208285eb66a04ec93c7f6
Content-Type: text/plain; charset=UTF-8

Olivier,

Do you want us to create a Spark user meetup event for this hackathon?

On Mon, Dec 2, 2013 at 1:12 PM, Olivier Grisel <olivier.grisel@ensta.org>wrote:

> Hi all,
>
> Just a quick reply to say that I would be glad to meet some of you to
> hack on some prototype scikit-learn / PySpark integration.
>
> Cloudera just confirmed that we have a room for us at their San
> Fransisco offices on Friday Feb 14 (right after Strata).
>
> Hope to see you there or at Strata,
>
> --
> Olivier
>

--001a11c208285eb66a04ec93c7f6--

From dev-return-800-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 21:24:22 2013
Return-Path: <dev-return-800-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E35DE105B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 21:24:21 +0000 (UTC)
Received: (qmail 32109 invoked by uid 500); 2 Dec 2013 21:24:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32061 invoked by uid 500); 2 Dec 2013 21:24:21 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 32053 invoked by uid 99); 2 Dec 2013 21:24:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:24:21 +0000
X-ASF-Spam-Status: No, hits=-1997.8 required=5.0
	tests=ALL_TRUSTED,HTML_MESSAGE,RP_MATCHES_RCVD
X-Spam-Check-By: apache.org
Received: from [140.211.11.3] (HELO mail.apache.org) (140.211.11.3)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 02 Dec 2013 21:24:19 +0000
Received: (qmail 31665 invoked by uid 99); 2 Dec 2013 21:23:57 -0000
Received: from minotaur.apache.org (HELO minotaur.apache.org) (140.211.11.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:23:57 +0000
Received: from localhost (HELO mail-vc0-f170.google.com) (127.0.0.1)
  (smtp-auth username rxin, mechanism plain)
  by minotaur.apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:23:56 +0000
Received: by mail-vc0-f170.google.com with SMTP id ht10so9120956vcb.29
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 13:23:55 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=+5IaCU5iNIVfSGlGDuuQ655b7Fko1yqfrRH2gcCz4z0=;
        b=Sly12ztrJk5drD+5/cEvbHaLuXK/0bnrMCkWS6zUi1aGLPRedomNx61gPV0jgW4jSr
         2TNvaISIPCvehLWbcCTER6XmHx62VauW9rDBwm77s2S7E5Vx64404S+RyeZc0WKYdUXj
         BHLCXPTJBh2hRdNy35in12MN5HG4VcHrwtOGPnNQndPcmd7EhpSJd8RB5+jPKR5nuQgo
         Fof6NJ7ODQBDrwYzDBtp3Yc1Sg+ETOFD8ZnCs1wleJs9afL1v8mv6ZGzMJnkSFWVGI08
         Z0yiyEdw9hSdaGAprCZlR57pINYoU4PA8D28ki8rMsrYdFgTuYlZxq50R4HldlvOAIrn
         FaTw==
X-Received: by 10.58.188.42 with SMTP id fx10mr936380vec.51.1386019435776;
 Mon, 02 Dec 2013 13:23:55 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.109.135 with HTTP; Mon, 2 Dec 2013 13:23:35 -0800 (PST)
In-Reply-To: <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com> <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
From: Reynold Xin <rxin@apache.org>
Date: Mon, 2 Dec 2013 13:23:35 -0800
Message-ID: <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Reynold Xin <rxin@apache.org>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=089e013a27a61f15ba04ec93cc60
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013a27a61f15ba04ec93cc60
Content-Type: text/plain; charset=UTF-8

Including the link to the meetup group: http://www.meetup.com/spark-users/


On Mon, Dec 2, 2013 at 1:22 PM, Reynold Xin <rxin@apache.org> wrote:

> Olivier,
>
> Do you want us to create a Spark user meetup event for this hackathon?
>
> On Mon, Dec 2, 2013 at 1:12 PM, Olivier Grisel <olivier.grisel@ensta.org>wrote:
>
>> Hi all,
>>
>> Just a quick reply to say that I would be glad to meet some of you to
>> hack on some prototype scikit-learn / PySpark integration.
>>
>> Cloudera just confirmed that we have a room for us at their San
>> Fransisco offices on Friday Feb 14 (right after Strata).
>>
>> Hope to see you there or at Strata,
>>
>> --
>> Olivier
>>
>
>

--089e013a27a61f15ba04ec93cc60--

From dev-return-801-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 21:44:07 2013
Return-Path: <dev-return-801-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7755C1063B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 21:44:07 +0000 (UTC)
Received: (qmail 65004 invoked by uid 500); 2 Dec 2013 21:44:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64972 invoked by uid 500); 2 Dec 2013 21:44:07 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 64964 invoked by uid 99); 2 Dec 2013 21:44:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:44:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:44:03 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so10846202wgh.29
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 13:43:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=qkiPtAZADZzlIxeTaL9mmB2J7PcEPYzakSjbiWMFS2k=;
        b=qSy5t3rGPU/R+Fc8l0SDtW1JJ9l51rNOEz0EmlcaVNJmyZaq6o7Lfi64rrys3b/Wvi
         CGJDg43oDLkLFqf7eKyP/dZtI42bvl2S3YZ+yE0NX6hypH/rt/22RkSsbo1YJwkL0I6o
         t0Vx4v048mOjI/3nqrLRFE95WaYRr+XVlthk/z7dcscpLnTCXfVT030Q7IEAA4a5Boor
         hNEixmp+dxJLar5LwdL8MfuQl8nQUL2e9J+eO0lrrAZbxWLWiiwZkfpTXi2qS77kx2Je
         nS4bVWmpJTT/GOUeoExAigDw9zp+GDJON2K/i9jNfAf22mTkNljuSgzCAarnX/7sZWYP
         wYww==
X-Received: by 10.180.90.114 with SMTP id bv18mr20168560wib.16.1386020621753;
 Mon, 02 Dec 2013 13:43:41 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Mon, 2 Dec 2013 13:43:21 -0800 (PST)
In-Reply-To: <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com> <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Mon, 2 Dec 2013 22:43:21 +0100
X-Google-Sender-Auth: yGn916JrtnDIFQ2M74UtcLxy2AY
Message-ID: <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: dev@spark.incubator.apache.org
Cc: Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>, Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

2013/12/2 Reynold Xin <rxin@apache.org>:
> Including the link to the meetup group: http://www.meetup.com/spark-users/

I am not opposed to it but I am wondering if people will not confuse
it with a traditional meetup if we do so.

-- 
Olivier

From dev-return-802-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  2 21:46:40 2013
Return-Path: <dev-return-802-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 17FB610653
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Dec 2013 21:46:40 +0000 (UTC)
Received: (qmail 73285 invoked by uid 500); 2 Dec 2013 21:46:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73240 invoked by uid 500); 2 Dec 2013 21:46:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 73232 invoked by uid 99); 2 Dec 2013 21:46:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:46:39 +0000
X-ASF-Spam-Status: No, hits=-1997.8 required=5.0
	tests=ALL_TRUSTED,HTML_MESSAGE,RP_MATCHES_RCVD
X-Spam-Check-By: apache.org
Received: from [140.211.11.3] (HELO mail.apache.org) (140.211.11.3)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 02 Dec 2013 21:46:37 +0000
Received: (qmail 69712 invoked by uid 99); 2 Dec 2013 21:46:15 -0000
Received: from minotaur.apache.org (HELO minotaur.apache.org) (140.211.11.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:46:15 +0000
Received: from localhost (HELO mail-ve0-f178.google.com) (127.0.0.1)
  (smtp-auth username rxin, mechanism plain)
  by minotaur.apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Dec 2013 21:46:14 +0000
Received: by mail-ve0-f178.google.com with SMTP id c14so9640561vea.9
        for <dev@spark.incubator.apache.org>; Mon, 02 Dec 2013 13:46:13 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=McQ9ypvkKC1aQYFrK2rXVoYnA8izvQ1bE91jy54I2qY=;
        b=Jj5g9BaftlC+hppygeKTmSqqHOnl0qGa2VcoR8HJuMcSHM2vHrmRkrwm9iSLw1UZp3
         vTkq1+BKLwBqk2YF6pCbARBdcsLMQU/FDONZWeBh9KkjJbqXRxaHazIxVKIhFdEUToMc
         hdhJTF91tHdHSWK7yCYX2tkN+pc/hmQdfgpjMK3wu85+8RuQJm/GWPpi73gDZhH0nDIy
         KqfXSLKnwTW3jkty3FfhGCg1eqyqVSad9/2UuFcvswyRMpYjnsWtXcVfn3vfngzLnuiV
         pk5/MkXt4AJXpv5IMs5E2XI8xYh6XsjdlBXZetLIcdzHTTa5pGA9vdukx9MNveQ+dcfu
         Qddg==
X-Received: by 10.221.29.200 with SMTP id rz8mr1887480vcb.33.1386020773393;
 Mon, 02 Dec 2013 13:46:13 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.109.135 with HTTP; Mon, 2 Dec 2013 13:45:53 -0800 (PST)
In-Reply-To: <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com> <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
From: Reynold Xin <rxin@apache.org>
Date: Mon, 2 Dec 2013 13:45:53 -0800
Message-ID: <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Olivier Grisel <olivier.grisel@ensta.org>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=001a11339f3cd97e8f04ec941bab
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11339f3cd97e8f04ec941bab
Content-Type: text/plain; charset=UTF-8

Definitely some people will get confused. It's up to you. If we post it, we
can mark it in the title that this is a hackathon.


On Mon, Dec 2, 2013 at 1:43 PM, Olivier Grisel <olivier.grisel@ensta.org>wrote:

> 2013/12/2 Reynold Xin <rxin@apache.org>:
> > Including the link to the meetup group:
> http://www.meetup.com/spark-users/
>
> I am not opposed to it but I am wondering if people will not confuse
> it with a traditional meetup if we do so.
>
> --
> Olivier
>

--001a11339f3cd97e8f04ec941bab--

From dev-return-803-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec  3 17:30:54 2013
Return-Path: <dev-return-803-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 30ADA108DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Dec 2013 17:30:54 +0000 (UTC)
Received: (qmail 30262 invoked by uid 500); 3 Dec 2013 17:30:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30006 invoked by uid 500); 3 Dec 2013 17:30:48 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29985 invoked by uid 99); 3 Dec 2013 17:30:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Dec 2013 17:30:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of horia.fsf@gmail.com designates 209.85.160.49 as permitted sender)
Received: from [209.85.160.49] (HELO mail-pb0-f49.google.com) (209.85.160.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Dec 2013 17:30:41 +0000
Received: by mail-pb0-f49.google.com with SMTP id jt11so21457934pbb.22
        for <dev@spark.incubator.apache.org>; Tue, 03 Dec 2013 09:30:20 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:reply-to:sender:in-reply-to:references:date:message-id
         :subject:from:to:cc:content-type;
        bh=Rb82lOm459SzQV++qIPmLaOdLHzPisg/57Uh7lTSnZI=;
        b=mKQmC/YW2XlXmQk7DeR4GwkP2jCmDKzSMn3S2d+RS2mVLMWSyv2MLJe8eKwEHNF6+X
         LO/VZ/+GDUDQH/1JfsAminfdQrVKKNRgLUpI4Z81aiNIKDouuMfrvGMuyX6F5pGtrdxe
         1zb1eNTTj1ob1CbT4OB04Yx6jY3vYyqSWtOnA5215WKG9nggMznJDTmc3+7Mg+8yWk0s
         Xr0b0cac6Q4RGi+QsIpfn3MMl8tWZevE9Rx2FFQIIXIBN46zmpL5VnZq6CnGsRlh1TTl
         9CFK0DeNArSJsWDT3kDiNM3IBP6+1PSWj8rDrsIx0kd0hGqTKx96UuPZiHgffZN8rUCP
         vYOg==
MIME-Version: 1.0
X-Received: by 10.68.130.39 with SMTP id ob7mr40390957pbb.63.1386091820039;
 Tue, 03 Dec 2013 09:30:20 -0800 (PST)
Reply-To: horia@alum.berkeley.edu
Sender: horia.fsf@gmail.com
Received: by 10.70.102.202 with HTTP; Tue, 3 Dec 2013 09:30:19 -0800 (PST)
In-Reply-To: <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
	<CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
	<CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
	<CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
	<CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
	<CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
Date: Tue, 3 Dec 2013 09:30:19 -0800
X-Google-Sender-Auth: LpRKmp4aV4n63XeUcHDM2Gdx_PU
Message-ID: <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
From: Horia <horia@alum.berkeley.edu>
To: dev@spark.incubator.apache.org
Cc: Olivier Grisel <olivier.grisel@ensta.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=047d7b10d06b8f5d7804eca4a62c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10d06b8f5d7804eca4a62c
Content-Type: text/plain; charset=ISO-8859-1

I am very interested in this and will most definitely participate!

Please share the event sign-up list and location details when all the
organizational hurdles have been resolved :-)



On Mon, Dec 2, 2013 at 1:45 PM, Reynold Xin <rxin@apache.org> wrote:

> Definitely some people will get confused. It's up to you. If we post it, we
> can mark it in the title that this is a hackathon.
>
>
> On Mon, Dec 2, 2013 at 1:43 PM, Olivier Grisel <olivier.grisel@ensta.org
> >wrote:
>
> > 2013/12/2 Reynold Xin <rxin@apache.org>:
> > > Including the link to the meetup group:
> > http://www.meetup.com/spark-users/
> >
> > I am not opposed to it but I am wondering if people will not confuse
> > it with a traditional meetup if we do so.
> >
> > --
> > Olivier
> >
>

--047d7b10d06b8f5d7804eca4a62c--

From dev-return-804-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 14:01:09 2013
Return-Path: <dev-return-804-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B3009101B5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 14:01:09 +0000 (UTC)
Received: (qmail 37699 invoked by uid 500); 4 Dec 2013 14:01:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37480 invoked by uid 500); 4 Dec 2013 14:01:00 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 37470 invoked by uid 99); 4 Dec 2013 14:00:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:00:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of olivier.grisel@gmail.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:00:54 +0000
Received: by mail-wi0-f180.google.com with SMTP id hn9so3812393wib.7
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 06:00:33 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=W/OjlJ+8de61txnW7fSyG/A8+X7cyS/o5J+qRWQ60W4=;
        b=Ya94aN3LB/9WEAdFOClV88G/t1SUOqdG+b0sgbAHxxnH6Tb6OVNlZdws7AuRzt1OF2
         qmzYKWkdrQhPWQEARVDFGXdH8N3wwv8WLDkTmiMaJrkVnnoD/Vh4/aYT5LJgXxFFj2KU
         t+RnLXr4lS3VK7tx+j2Io1Sg7sCP89/ZTh0LKy4UMCFtrU9eJPOm6QUeujAXTNsYGex2
         LEBvkS5gd3DKEvV6yqsJM0paatAl9Q9eizp/Frb4kfe9Bw/aHthQEWR4ccHAy56iy7E8
         rO0wyPlJ4/bBY7WKh/VtsAj7ucdk+taLAmd+2+yMZ0XWzbLg9bxdcKhuOft3p+ndw6W4
         60tA==
X-Received: by 10.180.82.161 with SMTP id j1mr7316450wiy.23.1386165633640;
 Wed, 04 Dec 2013 06:00:33 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 4 Dec 2013 06:00:13 -0800 (PST)
In-Reply-To: <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com> <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Wed, 4 Dec 2013 15:00:13 +0100
X-Google-Sender-Auth: rCuG55IusouQiROH7HiFz7GcQos
Message-ID: <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: horia@alum.berkeley.edu
Cc: dev <dev@spark.incubator.apache.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

2013/12/3 Horia <horia@alum.berkeley.edu>:
> I am very interested in this and will most definitely participate!
>
> Please share the event sign-up list and location details when all the
> organizational hurdles have been resolved :-)

Great! I just created a new entry for this sprint on the scikit-learn wiki:

  https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events#scikit-learn--pyspark-integration-sprint---friday-14-february-2014

Please feel free to register there.

-- 
Olivier
http://twitter.com/ogrisel - http://github.com/ogrisel

From dev-return-805-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 14:02:24 2013
Return-Path: <dev-return-805-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 22624101C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 14:02:24 +0000 (UTC)
Received: (qmail 40077 invoked by uid 500); 4 Dec 2013 14:02:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40047 invoked by uid 500); 4 Dec 2013 14:02:20 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 40039 invoked by uid 99); 4 Dec 2013 14:02:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:02:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.43 as permitted sender)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:02:15 +0000
Received: by mail-wg0-f43.google.com with SMTP id k14so12279448wgh.34
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 06:01:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=R181g5+0mFm2vykLxMI6rHAQ1f/O6ZFS/ihCJmMZoH0=;
        b=wTj+MZRPwu9VSqS/xHpRBnkehHE2ZLUhWN6zBVuzadBuQjXKSfBF+3BjJvI9pFyNNv
         Nbb4kNLGzITU+c3r7XlDiHR1iotAJqda7QHRwV/fOWOZs8eN2N82e3VBR7o5pmDechj6
         mLRR9BMcIZ6QZKNSkyi+Jwqg4yfiX+cxCV5g+CMPpHqYdJBYsHysy+rc5ZUHwwPiVRED
         O6oRQ4WnyeZSE3er9j+d1+Xlz3cTzefFTffCTsdgIb/EmqGMzD6th30Pu0hctvyQ7+Po
         gq5KIQZWmRPIVCdRzVT3Sg7XOdGJqK+AwnLTB3/iC+RYEgRM/WHN7wtqIXWNkn0GNMNB
         oR4w==
X-Received: by 10.180.90.114 with SMTP id bv18mr7468834wib.16.1386165714018;
 Wed, 04 Dec 2013 06:01:54 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 4 Dec 2013 06:01:33 -0800 (PST)
In-Reply-To: <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com> <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Wed, 4 Dec 2013 15:01:33 +0100
X-Google-Sender-Auth: -UITOr6PjU6Zq8WctkKfLf0TxK8
Message-ID: <CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: horia <horia@alum.berkeley.edu>
Cc: dev <dev@spark.incubator.apache.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Oops. I got something wrong with the markup. Let me fix it first.

-- 
Olivier

From dev-return-806-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 14:05:43 2013
Return-Path: <dev-return-806-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31403101D2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 14:05:43 +0000 (UTC)
Received: (qmail 41950 invoked by uid 500); 4 Dec 2013 14:05:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41914 invoked by uid 500); 4 Dec 2013 14:05:32 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 41903 invoked by uid 99); 4 Dec 2013 14:05:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:05:30 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:05:24 +0000
Received: by mail-wg0-f48.google.com with SMTP id z12so15161992wgg.27
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 06:05:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=NJraCjAH2MjeaF8y3URqxhRiRh9WgK5UzHv52yVHf3s=;
        b=IzXrD1RbjTkJglxD1kXDpcpz2l+Hf9qIDn0Ps+mhcnmAnB3uaAyWW47CEa6whqOpnQ
         ORIZloIMbkJZ/Os9krwSkVCUvKT/Un+0lmh/xXWPf34Her5I+LgHJ/GYDwtK9Bk7hYRn
         Yg5Dnjr/D5MhI4faJoXX4AcJMcybzmxzbgSjE1LjC3HjeVhAriHGNyaZ7QfsCA6eZpv0
         A6YROgdXTW9Jvr26RxHRMNkQneHMC1QF6bdbFw3AivbMmkE7AxmJf5uydg90UQGRQuCv
         cgpA5EtnNSS1zvXL3ydyu65odiVVqXidNT9PlxQQQtO8uqPyuYI1Wc4q+Lsk+yrIObTE
         Xlug==
X-Received: by 10.180.36.105 with SMTP id p9mr7308322wij.58.1386165903639;
 Wed, 04 Dec 2013 06:05:03 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 4 Dec 2013 06:04:43 -0800 (PST)
In-Reply-To: <CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
 <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com> <CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Wed, 4 Dec 2013 15:04:43 +0100
X-Google-Sender-Auth: mnUKifgLLQb5kvxFMtwH5lPQgk0
Message-ID: <CAFvE7K7YcZ2XBNDht-fPq5nrSSnJ4ruuX6hxoBOdCbPKyCA2Nw@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: horia <horia@alum.berkeley.edu>
Cc: dev <dev@spark.incubator.apache.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

That should be fixed but only if nobody clicks on the previous URL...
Use the following instead:

https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events

That's a weird github bug...

-- 
Olivier

From dev-return-807-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 14:09:23 2013
Return-Path: <dev-return-807-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 33819101E5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 14:09:23 +0000 (UTC)
Received: (qmail 49355 invoked by uid 500); 4 Dec 2013 14:08:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49264 invoked by uid 500); 4 Dec 2013 14:08:49 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 49208 invoked by uid 99); 4 Dec 2013 14:08:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:08:41 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 14:08:35 +0000
Received: by mail-wg0-f45.google.com with SMTP id y10so13513952wgg.24
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 06:08:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=elTMML+xZXrudwvt8VAXWmO4uXKf64/EjSVaOH1B5UY=;
        b=Xv0f6SRC3vcV/+k7HH1GjK+3Pe0+Lxip9NDcOTT20PhCD3NJ3L/npnH1hSsLKdrlsj
         LdKDH0QGvWfRaOWwBppwyToXXLX597J2v4Tu5INdE49ZqczUgvboRxBuBnSK2717vJOP
         a7zFFFBmXXW9iA/2SA8F0i1603nX7VrZ1C+EIxi3W+jADOv+cUFvhhqrk0v4Q2GXxpC3
         KPecvWg5xvFvtQbf46Kmgy0P9dsxjdoh0vaR+J1roKaQoIk2GQmKzamP7lOfsHMZc1Iw
         iv68uAzCRPanwvpOi24Dt2WuW8NK/eN/7f7NiCo7YVRDWsr2jI6Gn0+ibdGTgLKUqUtn
         FjEQ==
X-Received: by 10.180.82.161 with SMTP id j1mr7350683wiy.23.1386166095368;
 Wed, 04 Dec 2013 06:08:15 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 4 Dec 2013 06:07:55 -0800 (PST)
In-Reply-To: <CAFvE7K7YcZ2XBNDht-fPq5nrSSnJ4ruuX6hxoBOdCbPKyCA2Nw@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
 <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
 <CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com> <CAFvE7K7YcZ2XBNDht-fPq5nrSSnJ4ruuX6hxoBOdCbPKyCA2Nw@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Wed, 4 Dec 2013 15:07:55 +0100
X-Google-Sender-Auth: AdefOz0P_mc5JyMGcwB_pTaXQtA
Message-ID: <CAFvE7K65r48JvGAHRZbYyYBQFJKRR_q08WvXEfBKq-_=u-SxdA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: horia <horia@alum.berkeley.edu>
Cc: dev <dev@spark.incubator.apache.org>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

2013/12/4 Olivier Grisel <olivier.grisel@ensta.org>:
> That should be fixed but only if nobody clicks on the previous URL...
> Use the following instead:
>
> https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events
>
> That's a weird github bug...

I switched the rendering to markdown and the page is stable now. Sorry for that.

-- 
Olivier
http://twitter.com/ogrisel - http://github.com/ogrisel

From dev-return-808-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 19:33:39 2013
Return-Path: <dev-return-808-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9F88A10E2E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 19:33:39 +0000 (UTC)
Received: (qmail 78875 invoked by uid 500); 4 Dec 2013 19:33:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78739 invoked by uid 500); 4 Dec 2013 19:33:38 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 78731 invoked by uid 99); 4 Dec 2013 19:33:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 19:33:38 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chris.mattmann@gmail.com designates 209.85.192.173 as permitted sender)
Received: from [209.85.192.173] (HELO mail-pd0-f173.google.com) (209.85.192.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 19:33:32 +0000
Received: by mail-pd0-f173.google.com with SMTP id p10so22999296pdj.18
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 11:33:12 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=user-agent:date:subject:from:to:message-id:thread-topic
         :mime-version:content-type:content-transfer-encoding;
        bh=EupfNSITfEIn/NMS9d6vPaZAelp7Qp85d3HNhQEC4SE=;
        b=mliAmL8M02ysizJx+MCEFbyT9+YQaj2TzpIrAPFScmKnITXSL/LK5Bs9fsi8z+mvrj
         Q0Bqcvy10yrO6lgrwnZw23KQqtU3YVcP0DOOSLmIwdDvLpm9r4MzjURDZajR4TZK3Jst
         TMoyNHaGl0kuPz8Q/JxgTwB27CyQrZqrWDg7uAoVW0Xvkzkug2bGcGDIPR3gcZgtqugC
         Tz6yhJzCAPAXcO80/bzIIZNbm5etl02+8VaD4E8h0m0Bf+t/4D3BTHFm24cwAMoPCCjs
         B4DGGC+byVQr53jLnDVeqslCoJYWY0nVdcaI7HqWVS/ZQ/7wlht8rCinNRYPMlljKpdu
         xLtg==
X-Received: by 10.68.204.193 with SMTP id la1mr19640345pbc.159.1386185591905;
        Wed, 04 Dec 2013 11:33:11 -0800 (PST)
Received: from [192.168.52.119] (70.90.174.173-BusName-CA.sfba.comcast.net.hfc.comcastbusiness.net. [70.90.174.173])
        by mx.google.com with ESMTPSA id er3sm139223502pbb.40.2013.12.04.11.33.07
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 04 Dec 2013 11:33:10 -0800 (PST)
User-Agent: Microsoft-MacOutlook/14.3.9.131030
Date: Wed, 04 Dec 2013 11:32:52 -0800
Subject: Sorry about business lately and general unavailability
From: Chris Mattmann <mattmann@apache.org>
To: <dev@spark.incubator.apache.org>
Message-ID: <CEC4C364.121208%mattmann@apache.org>
Thread-Topic: Sorry about business lately and general unavailability
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Guys,

Just wanted to apologize for the general lack of my availability
lately. I thought moving from Rancho Cucamonga, to Pasadena, CA
(over 50+ miles) wouldn't affect my productivity, and with that
and the holidays, and all the house work and moving stuff I've had
to do, coupled with $dayjob it's been tough.

I'm slowly catching up and coming out of the fog though so just
wanted to let you all know I'm going to be around and get back
to helping out as a mentor. Amazing thing though is that you guys
have really been kicking ass largely without me like you always do
and operating like a great ASF project.

I'd say you are headed for an early graduation and I will closely
monitor things like adding more PPMC members and committers (saw
you guys have been doing this), and also things like releases
(that too), and just keep doing what you're doing and you'll be
an ASF TLP shortly!

Cheers mates and rock on.

-Chris "Champion in abenstia but back now" Mattmann






From dev-return-809-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 22:48:53 2013
Return-Path: <dev-return-809-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 021C11071C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 22:48:53 +0000 (UTC)
Received: (qmail 3859 invoked by uid 500); 4 Dec 2013 22:48:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3749 invoked by uid 500); 4 Dec 2013 22:48:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 3740 invoked by uid 99); 4 Dec 2013 22:48:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 22:48:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.160.54 as permitted sender)
Received: from [209.85.160.54] (HELO mail-pb0-f54.google.com) (209.85.160.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 22:48:48 +0000
Received: by mail-pb0-f54.google.com with SMTP id un15so24547317pbc.13
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 14:48:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=XBeSpef8NIVhxWvfvMMK6YFfTisBF9kyhKF0CTq/2SE=;
        b=Qax0EdNRHfduToREKkTcnbpb4OOWrHz7lfu6jPQr90qry/sHgoeD2iWCMb/NATc1g5
         RFzJ2Ay8Bmhyq8WvZ/cHBPJsVCCbFjnipn+a98Qy7R56bjsEW8sRImp7ICcqh099iqn+
         k+yP5e5Q1uwznCDkVoPDu320LOGDGjN+zbA0hEo97KO30DbE6gTk34Mj4YO8YaJi4geh
         g2MWxPQQtb5bWiKRlhgBzhpcePRbwgBkUDZmbIYRXhp676kFjO2EdJ/sQeBMiA8hoZWO
         vKDcY2IrqnMKYgOui510RckrZW6swbivRzu0v5b2VQxGAT9qlJDAhc4LtBg/Q+I7xuNl
         aA3A==
MIME-Version: 1.0
X-Received: by 10.66.246.229 with SMTP id xz5mr59727071pac.128.1386197307840;
 Wed, 04 Dec 2013 14:48:27 -0800 (PST)
Received: by 10.70.24.3 with HTTP; Wed, 4 Dec 2013 14:48:27 -0800 (PST)
In-Reply-To: <CAFvE7K65r48JvGAHRZbYyYBQFJKRR_q08WvXEfBKq-_=u-SxdA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
	<CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
	<CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
	<CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
	<CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
	<CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
	<CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
	<CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
	<CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com>
	<CAFvE7K7YcZ2XBNDht-fPq5nrSSnJ4ruuX6hxoBOdCbPKyCA2Nw@mail.gmail.com>
	<CAFvE7K65r48JvGAHRZbYyYBQFJKRR_q08WvXEfBKq-_=u-SxdA@mail.gmail.com>
Date: Wed, 4 Dec 2013 14:48:27 -0800
Message-ID: <CAOEPXP6NLKYuBRshKY-7GpU5+wMKCPq6KoRm3m6TS2DGSxwApg@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
From: Josh Rosen <rosenville@gmail.com>
To: "Spark Dev (Apache Incubator)" <dev@spark.incubator.apache.org>
Cc: horia <horia@alum.berkeley.edu>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: multipart/alternative; boundary=047d7b15acc91f65df04ecbd36d4
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b15acc91f65df04ecbd36d4
Content-Type: text/plain; charset=ISO-8859-1

Thanks for organizing this!  I'll definitely be attending.

- Josh


On Wed, Dec 4, 2013 at 6:07 AM, Olivier Grisel <olivier.grisel@ensta.org>wrote:

> 2013/12/4 Olivier Grisel <olivier.grisel@ensta.org>:
> > That should be fixed but only if nobody clicks on the previous URL...
> > Use the following instead:
> >
> > https://github.com/scikit-learn/scikit-learn/wiki/Upcoming-events
> >
> > That's a weird github bug...
>
> I switched the rendering to markdown and the page is stable now. Sorry for
> that.
>
> --
> Olivier
> http://twitter.com/ogrisel - http://github.com/ogrisel
>

--047d7b15acc91f65df04ecbd36d4--

From dev-return-810-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec  4 23:37:40 2013
Return-Path: <dev-return-810-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A8E08108EA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Dec 2013 23:37:40 +0000 (UTC)
Received: (qmail 2908 invoked by uid 500); 4 Dec 2013 23:37:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2869 invoked by uid 500); 4 Dec 2013 23:37:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 2861 invoked by uid 99); 4 Dec 2013 23:37:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 23:37:40 +0000
X-ASF-Spam-Status: No, hits=-1997.8 required=5.0
	tests=ALL_TRUSTED,HTML_MESSAGE,RP_MATCHES_RCVD
X-Spam-Check-By: apache.org
Received: from [140.211.11.3] (HELO mail.apache.org) (140.211.11.3)
    by apache.org (qpsmtpd/0.29) with SMTP; Wed, 04 Dec 2013 23:37:37 +0000
Received: (qmail 2780 invoked by uid 99); 4 Dec 2013 23:37:15 -0000
Received: from minotaur.apache.org (HELO minotaur.apache.org) (140.211.11.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 23:37:15 +0000
Received: from localhost (HELO mail-ve0-f177.google.com) (127.0.0.1)
  (smtp-auth username rxin, mechanism plain)
  by minotaur.apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Dec 2013 23:37:15 +0000
Received: by mail-ve0-f177.google.com with SMTP id db12so12575948veb.8
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 15:37:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=WF3MhufjIN8t/iALbRPsTb+vVSFBZ06uHkPaRv5UR5E=;
        b=TINOCwwcllfAB+OD2CiKjoOXiRUOHo/EdCowgyuB63DM7Fzr7+ti84jLqU7bgRynV5
         W6zpUI13n5Lb1Da7H7pWJ/PiquCPYKzJtKApqb8qhTKfZQzXxWurE3G3t7D9stzUZfQx
         lBhttyHV1TF7UeJ93iqXjw9IsIiCZfUDq12kApI7JvAXacXAsEINuFyd7Dvzq2LfjDJk
         9WkYmHRnay8CYcSRXSPwvEg6lojGbEVvN3GdiluMNX3d4sZiS7vHHjHWKdIUj5lJ+tVV
         hzPW5mc1pcVVc9cf1NYiP7wSCSwd28r+ifZnEMCFKPKiRt8Ym9sXUb6N6r3s7Q8idguI
         U/Gg==
X-Received: by 10.58.248.198 with SMTP id yo6mr126399vec.40.1386200234333;
 Wed, 04 Dec 2013 15:37:14 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.109.135 with HTTP; Wed, 4 Dec 2013 15:36:54 -0800 (PST)
In-Reply-To: <CEC4C364.121208%mattmann@apache.org>
References: <CEC4C364.121208%mattmann@apache.org>
From: Reynold Xin <rxin@apache.org>
Date: Wed, 4 Dec 2013 15:36:54 -0800
Message-ID: <CAC1ssC5ej+ogjW_GJz1dJQtZdgCgtREv7MFdT89qTPcxKZaf_w@mail.gmail.com>
Subject: Re: Sorry about business lately and general unavailability
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc8f1a8e83c004ecbde465
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc8f1a8e83c004ecbde465
Content-Type: text/plain; charset=UTF-8

Thanks for the update Chris.

We do need to graduate soon. People have been asking me does "incubating"
means the project is very immature. :(

One thing we need to do is to import the JIRA tickets from AMPLab's JIRA.
That INFRA ticket hasn't moved much along. Can you help push that?



On Wed, Dec 4, 2013 at 11:32 AM, Chris Mattmann <mattmann@apache.org> wrote:

> Hey Guys,
>
> Just wanted to apologize for the general lack of my availability
> lately. I thought moving from Rancho Cucamonga, to Pasadena, CA
> (over 50+ miles) wouldn't affect my productivity, and with that
> and the holidays, and all the house work and moving stuff I've had
> to do, coupled with $dayjob it's been tough.
>
> I'm slowly catching up and coming out of the fog though so just
> wanted to let you all know I'm going to be around and get back
> to helping out as a mentor. Amazing thing though is that you guys
> have really been kicking ass largely without me like you always do
> and operating like a great ASF project.
>
> I'd say you are headed for an early graduation and I will closely
> monitor things like adding more PPMC members and committers (saw
> you guys have been doing this), and also things like releases
> (that too), and just keep doing what you're doing and you'll be
> an ASF TLP shortly!
>
> Cheers mates and rock on.
>
> -Chris "Champion in abenstia but back now" Mattmann
>
>
>
>
>
>

--047d7bdc8f1a8e83c004ecbde465--

From dev-return-811-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 01:40:25 2013
Return-Path: <dev-return-811-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 03EA810E7B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 01:40:25 +0000 (UTC)
Received: (qmail 27285 invoked by uid 500); 5 Dec 2013 01:40:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27237 invoked by uid 500); 5 Dec 2013 01:40:24 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 27229 invoked by uid 99); 5 Dec 2013 01:40:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 01:40:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.160.43 as permitted sender)
Received: from [209.85.160.43] (HELO mail-pb0-f43.google.com) (209.85.160.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 01:40:18 +0000
Received: by mail-pb0-f43.google.com with SMTP id rq2so24837186pbb.30
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 17:39:58 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=Q+tyv63YwgCAG6p9lsWizTKTHrAaLdwwnCIxLgdrZsQ=;
        b=fvhIuGmLgmtWQHqt0X5r4+CrrMdDXF/PVtPQXjfTEKTJANJitJHMOqtGal+B5ECe2o
         Tqslo12JEyPuUpsLjOnrd2uH9qqGKfWcqOfs9teS30Bn3ZT9KOIPlTd9wOvzyO/1GoPi
         Euy0L6AZqzfE0nS+TZ8VyusV7oWl4Gle2uS+NvbC1uKGAXuH25g8qCNh4Ya/oLa1vLar
         SjO+Iy7ZoD8P8CJMY72ID8p7lULqKKl5UT0bQ1Gaz/rIkcjJD0Dky74BvdpY4dplcyvV
         xEkJjIKOE4HHGlamWxTCzZLvB7IeFaZNbZTPPf9u50ZHeIGorTEk4e2q+AZ6kene/ofz
         7NPQ==
X-Received: by 10.68.242.4 with SMTP id wm4mr48726756pbc.77.1386207597953;
        Wed, 04 Dec 2013 17:39:57 -0800 (PST)
Received: from [192.168.1.106] (c-24-7-114-112.hsd1.ca.comcast.net. [24.7.114.112])
        by mx.google.com with ESMTPSA id ki1sm140506222pbd.1.2013.12.04.17.39.56
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 04 Dec 2013 17:39:57 -0800 (PST)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: Sorry about business lately and general unavailability
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAC1ssC5ej+ogjW_GJz1dJQtZdgCgtREv7MFdT89qTPcxKZaf_w@mail.gmail.com>
Date: Wed, 4 Dec 2013 17:39:54 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <8B606EE8-3266-4C18-9F68-7F0FA59196DC@gmail.com>
References: <CEC4C364.121208%mattmann@apache.org> <CAC1ssC5ej+ogjW_GJz1dJQtZdgCgtREv7MFdT89qTPcxKZaf_w@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

No worries Chris! Apart from the JIRA thing, we also plan another =
release or two soon.

Matei

On Dec 4, 2013, at 3:36 PM, Reynold Xin <rxin@apache.org> wrote:

> Thanks for the update Chris.
>=20
> We do need to graduate soon. People have been asking me does =
"incubating"
> means the project is very immature. :(
>=20
> One thing we need to do is to import the JIRA tickets from AMPLab's =
JIRA.
> That INFRA ticket hasn't moved much along. Can you help push that?
>=20
>=20
>=20
> On Wed, Dec 4, 2013 at 11:32 AM, Chris Mattmann <mattmann@apache.org> =
wrote:
>=20
>> Hey Guys,
>>=20
>> Just wanted to apologize for the general lack of my availability
>> lately. I thought moving from Rancho Cucamonga, to Pasadena, CA
>> (over 50+ miles) wouldn't affect my productivity, and with that
>> and the holidays, and all the house work and moving stuff I've had
>> to do, coupled with $dayjob it's been tough.
>>=20
>> I'm slowly catching up and coming out of the fog though so just
>> wanted to let you all know I'm going to be around and get back
>> to helping out as a mentor. Amazing thing though is that you guys
>> have really been kicking ass largely without me like you always do
>> and operating like a great ASF project.
>>=20
>> I'd say you are headed for an early graduation and I will closely
>> monitor things like adding more PPMC members and committers (saw
>> you guys have been doing this), and also things like releases
>> (that too), and just keep doing what you're doing and you'll be
>> an ASF TLP shortly!
>>=20
>> Cheers mates and rock on.
>>=20
>> -Chris "Champion in abenstia but back now" Mattmann
>>=20
>>=20
>>=20
>>=20
>>=20
>>=20


From dev-return-812-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 03:47:05 2013
Return-Path: <dev-return-812-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EFA5F10214
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 03:47:05 +0000 (UTC)
Received: (qmail 70111 invoked by uid 500); 5 Dec 2013 03:47:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70077 invoked by uid 500); 5 Dec 2013 03:47:01 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 70066 invoked by uid 99); 5 Dec 2013 03:46:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 03:46:58 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of shaposhnik@gmail.com designates 209.85.219.54 as permitted sender)
Received: from [209.85.219.54] (HELO mail-oa0-f54.google.com) (209.85.219.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 03:46:51 +0000
Received: by mail-oa0-f54.google.com with SMTP id h16so18022067oag.27
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 19:46:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:content-type;
        bh=ekBVmmfO9yLnkrgbBScOQVUG0R+LalZE3TL7wJtx4uQ=;
        b=Yqwdks3O0Phxv3r9t7GKuLGUN+AlqT/wwG8SAOTu1VSjzS2fsxvNOKEGGbSwEEalnS
         U1KW4xwcLi9QtwPcSs8rxM4GvbGS7BzRVDw7U9CHyiwjpXG9+ThiB+Kds0W0S32VHHwh
         /LJvxk7ICXrhBE4J5gN67RM8hhI9qtqe/9kSt2pCsAI35XerW7Q5jvlWJtjzvRtqu57p
         iWCdi+0AHETFHgl60tonqHR3s0yDMZ+/XS3LXH0R8hDd2503q/wAnu3QD6QOVzvpAzJm
         kZRtcTXBKN+CU9wuOUvrEJvC++MIIFj4RKHqKcRzhUAZKd7+vPaenBYL7e4l0BE/6Br4
         eVoQ==
MIME-Version: 1.0
X-Received: by 10.60.74.37 with SMTP id q5mr24807220oev.3.1386215190072; Wed,
 04 Dec 2013 19:46:30 -0800 (PST)
Sender: shaposhnik@gmail.com
Received: by 10.182.133.101 with HTTP; Wed, 4 Dec 2013 19:46:30 -0800 (PST)
In-Reply-To: <CAC1ssC5ej+ogjW_GJz1dJQtZdgCgtREv7MFdT89qTPcxKZaf_w@mail.gmail.com>
References: <CEC4C364.121208%mattmann@apache.org>
	<CAC1ssC5ej+ogjW_GJz1dJQtZdgCgtREv7MFdT89qTPcxKZaf_w@mail.gmail.com>
Date: Wed, 4 Dec 2013 19:46:30 -0800
X-Google-Sender-Auth: dLsATO2WI8hIzszgFi_MO7qr5fo
Message-ID: <CA+ULb+uYBCQKPPHXnRvqqW3YAr+FvTo6B3LN_2qrCTucZG-AAw@mail.gmail.com>
Subject: Re: Sorry about business lately and general unavailability
From: Roman Shaposhnik <rvs@apache.org>
To: dev@spark.incubator.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Dec 4, 2013 at 3:36 PM, Reynold Xin <rxin@apache.org> wrote:
> Thanks for the update Chris.
>
> We do need to graduate soon.

I think important thing to realize is that there's no rush
and the project should graduate whenever the community
has demonstrated its capacity for functioning under the
principles of the Apache Way.

Graduation has absolutely nothing to do with how polished
the code is. Remember ASF's motto: "community over code".

> People have been asking me does "incubating"
> means the project is very immature. :(

I think this is one of the misconceptions that we all need to actively
take part in clearing: the projects in the incubator can be extremely
mature as far as the software goes. You don't have to search for
example too hard: OpenOffice and CloudStack readily come to mind.
Both were extremely well established and respected pieces of software
when they entered the incubator.

Once again -- the quality of your code is important, but WAY less important
than the quality of your community. There's plenty of excellent, beautifully
crafted software projects on GitHub.

Thanks,
Roman.

From dev-return-813-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 04:32:59 2013
Return-Path: <dev-return-813-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 27BA51033D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 04:32:59 +0000 (UTC)
Received: (qmail 16561 invoked by uid 500); 5 Dec 2013 04:32:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16506 invoked by uid 500); 5 Dec 2013 04:32:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 16492 invoked by uid 99); 5 Dec 2013 04:32:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 04:32:49 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.192.177 as permitted sender)
Received: from [209.85.192.177] (HELO mail-pd0-f177.google.com) (209.85.192.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 04:32:41 +0000
Received: by mail-pd0-f177.google.com with SMTP id q10so23488249pdj.8
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 20:32:20 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=/RcXp8+Sao5sU2Nj+U69krfwM5fGadzn/5YbBCPFd70=;
        b=LgZB32uAP37xk84Qv9mV6r5BMlDIdUqCXkrZR6oRKmEHzxpjqI0oJuxeTf4QqtvDXh
         zIFp5Siof/wABSiFIj72KQ2C3NuOOqJ0MGqrhrsWeZkyajyp1EXt1fiPHVkPNBSxYCaq
         XnYloT/rj5qtPgzfv4HMVxF0dmS/kXBN/8Uz7oWjXmsg7dj4/NmvqTuv+S0jWHx0aliU
         ruK7W8Lo48yzVmnox88OOe2ID+UuBeirZ8fI5blmoShLby5nkUOTJ9ghGJAJXvxTiNSD
         XrJ8PAw2GH2nfvJvwWbo5mDU/+p9h802INkBCFwgZH73M13TnPDAf7v4XUQwCxHrPZ42
         5odg==
X-Gm-Message-State: ALoCoQnYzpXUXg6/GQ8ZyFOGLV7mHGF9OhjbIuOUjkTMqZUfGA6sfSra0HHGb6OrVCxnSiWdBFWr
MIME-Version: 1.0
X-Received: by 10.66.233.69 with SMTP id tu5mr85966308pac.78.1386217940550;
 Wed, 04 Dec 2013 20:32:20 -0800 (PST)
Received: by 10.70.52.2 with HTTP; Wed, 4 Dec 2013 20:32:20 -0800 (PST)
Date: Wed, 4 Dec 2013 20:32:20 -0800
Message-ID: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com>
Subject: Spark streaming quantile?
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: dev@spark.incubator.apache.org, Uri Laserson <laserson@cloudera.com>
Content-Type: multipart/alternative; boundary=047d7b15a473eda4e904ecc203d4
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b15a473eda4e904ecc203d4
Content-Type: text/plain; charset=ISO-8859-1

Hi All,

We're working on a Spark application that could make use of a computing
quantiles in a streaming fashion.  Something in the vein of what DataFu has
for Pig
http://linkedin.github.io/datafu/docs/current/datafu/pig/stats/StreamingQuantile.html
.

Does anything like this exist in the Spark ecosystem?  If not, would there
be a good place to contribute this if we write it?

thanks,
Sandy

--047d7b15a473eda4e904ecc203d4--

From dev-return-814-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 04:42:46 2013
Return-Path: <dev-return-814-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0CADD10367
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 04:42:46 +0000 (UTC)
Received: (qmail 23055 invoked by uid 500); 5 Dec 2013 04:42:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23006 invoked by uid 500); 5 Dec 2013 04:42:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 22994 invoked by uid 99); 5 Dec 2013 04:42:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 04:42:37 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [98.137.12.181] (HELO smtp106.biz.mail.gq1.yahoo.com) (98.137.12.181)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 05 Dec 2013 04:42:32 +0000
Received: (qmail 35928 invoked from network); 5 Dec 2013 04:42:10 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1386218530; bh=mzoHFbMeVWOla0Va6yEoXGxQ88jAeJP12X4dn7ktmpU=; h=X-Yahoo-Newman-Property:X-YMail-OSG:X-Yahoo-SMTP:X-Rocket-Received:Received:X-Google-DKIM-Signature:X-Received:MIME-Version:Received:In-Reply-To:References:From:Date:Message-ID:Subject:To:Cc:Content-Type; b=VNby5e7ieAj0o825aplPyQ9yjmY2n4G0c99wUZ2+yIrSHQLp3A5RYbBtqIIflWi5a7PWiIb+Zl+LVja9Lrhujx1XEGXNOqjNwAXt54ahfr9hBv2IRaxfahOzr9tDSiKI8PdOEMiMTmELvpu/6LW4N5u7cvM58FGAXpxnCssmb88=
X-Yahoo-Newman-Property: ymail-3
X-YMail-OSG: ZyinVnEVM1kfWRmyTNetH3XrbvTl.pNQaf8GiA6Fp_2dEm_
 nu2sngxBuS5XMuSnnzpiNxcchKxdO2tonSeneDQC6a3WMRhUBnS7MRkQqJnX
 ztjtuwF3Va4UclVqYBbCDHd5dfcDhdncv7kqw9oJ8LePEEt5GIRgmMGMbmrF
 3vv5XFKVLZXlDfXj.k6Y2hhEGEWY8GjYFsyQn4xqLudTGcEh8n1Np0ileUZu
 jnQH32H7ynerQnPbYo25LqmYz5MtcCdk.12uqP8.Ksr8FWJk3Pf8wnBMoN5l
 l4D79oIq7TAo2Fcu6iHmOcw0VZHFy.npSP_3S5QZ9Xw4zoriq42AKmYAYXn0
 akW4HFFcx0DbzM_z8e9u_yQbJ5OR8KdpjtxULucAa6xLMKF5M_Wfp9eAoF2R
 3niPJvtbpQZ2yC2vheDGpnkogcI2pFanWnxPrM93Gi15VTB3N5t516wJKMyO
 D3J8aO.nXgHb_GCP1blfSFI9OKf4XeFBRBqK_GwykHG6_f8OinGHYa.W5Lcw
 u4kEUbLEW8l9QG075euG9gSrFtiOa_Zgf6TuJxmERC3XiMI1RL4D58PVJ_3k
 QesNOG83jEE302HtK29LidMGx814_iEmPSmsskvg.s4NKddDHLQEDT21crxH
 fDzfiwqJVcdA3mrf1lG9XBZsiviQ.xwBP1fJwo3tuBI0jfqBMfZPJvxUqOfk
 cn_5k66ekFoAPWQF4vOqz6FltjLllc2BEx5nV4utvWqbpI46wLynaCWJSkOM
 YiiGi_lecCzXjpWcQBWotLvypmjmBcTSH_EzbXC2LkNlrFX57lSKmctId3WY
 MJE8C9cPVhHunExOh3IL7n_pg6JLSZGkwPqPPL2IOuN0ztvMGn0sg7aw-
X-Yahoo-SMTP: 41xGLymswBB1.ONZP3_CfeCMYqYjTw--
X-Rocket-Received: from mail-qa0-f42.google.com (ryan@209.85.216.42 with )
        by smtp106.biz.mail.gq1.yahoo.com with SMTP; 05 Dec 2013 04:42:10 +0000 UTC
Received: by mail-qa0-f42.google.com with SMTP id k4so7338032qaq.1
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 20:42:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=mzoHFbMeVWOla0Va6yEoXGxQ88jAeJP12X4dn7ktmpU=;
        b=g8hTjuBAcqMXGfzDqV+/Y95FXUyGfpHFVW9IbJvy8sP9Eg+Mgk/0Rn3ZB7OTapzAO2
         Zt/d+jjSe5S+7P0fh9qjEKBOhIPyL/bk8MHO++2r3J5SiIcSrq8Gz3TF0zPrpCyCDxbY
         A8AuLoxRxr/QPNfykHF1I+vkmlAlZ1YB6PPdUBZtYJZ5WwbLya3Ao5R8Ed0QyzVWIJG8
         GX6BNJ8etE4h8nNfkJfbhqteE1bEUk3gEXe4L+yd5XmxDmJEJArs9PjSID7OXa1vFQ2D
         nOLnrIsArtaBwRybvyAu6ivHq9UF2TuFIws5eUCFJk973EtLJbtStxDZuZj8lYYbg3EU
         Th0Q==
X-Received: by 10.229.56.200 with SMTP id z8mr142244751qcg.1.1386218529149;
 Wed, 04 Dec 2013 20:42:09 -0800 (PST)
MIME-Version: 1.0
Received: by 10.140.25.200 with HTTP; Wed, 4 Dec 2013 20:41:49 -0800 (PST)
In-Reply-To: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com>
References: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com>
From: Ryan Weald <ryan@weald.com>
Date: Wed, 4 Dec 2013 20:41:49 -0800
Message-ID: <CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
Subject: Re: Spark streaming quantile?
To: dev@spark.incubator.apache.org
Cc: Uri Laserson <laserson@cloudera.com>
Content-Type: multipart/alternative; boundary=001a113308a402d9c304ecc2273e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113308a402d9c304ecc2273e
Content-Type: text/plain; charset=ISO-8859-1

Hi Sandy,
You could take a look at using the Q-Tree data structure that is provided
by Twitter's Algebird<https://github.com/twitter/algebird/blob/develop/algebird-core/src/main/scala/com/twitter/algebird/QTree.scala>.
Due to the associative properties of Algebird's SemiGroup it is ideally
suited for streaming computations.

-Ryan


On Wed, Dec 4, 2013 at 8:32 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> Hi All,
>
> We're working on a Spark application that could make use of a computing
> quantiles in a streaming fashion.  Something in the vein of what DataFu has
> for Pig
>
> http://linkedin.github.io/datafu/docs/current/datafu/pig/stats/StreamingQuantile.html
> .
>
> Does anything like this exist in the Spark ecosystem?  If not, would there
> be a good place to contribute this if we write it?
>
> thanks,
> Sandy
>

--001a113308a402d9c304ecc2273e--

From dev-return-815-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 07:55:27 2013
Return-Path: <dev-return-815-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C8F071081C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 07:55:27 +0000 (UTC)
Received: (qmail 59189 invoked by uid 500); 5 Dec 2013 07:55:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58936 invoked by uid 500); 5 Dec 2013 07:55:20 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 58917 invoked by uid 99); 5 Dec 2013 07:55:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 07:55:19 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of olivier.grisel@gmail.com designates 209.85.212.181 as permitted sender)
Received: from [209.85.212.181] (HELO mail-wi0-f181.google.com) (209.85.212.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 07:55:15 +0000
Received: by mail-wi0-f181.google.com with SMTP id hq4so9387023wib.8
        for <dev@spark.incubator.apache.org>; Wed, 04 Dec 2013 23:54:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=gW1jS4VHiX5RUXtxeHUmwZzyOa8ylitxbTFUV+/HndI=;
        b=yVL/v7la2W5TrX1foE9QwuJVJk0tpa07Sv24jKCkzBUHSHHvBhtUkkeKb7xO7b3tMN
         9XLmJYTjYyY+pW+wVFkyh0w8gCC5hUm2aWHvek7WghzSPfcZkvg4dwyONMRsW3MDiqzt
         JZTMxrXFDGLi8++vSZyjYQdMFnzcsP0NladyGd9I8619KnI6XMHJ+/BRksyO2RdRD3CS
         HFpc9smaoyhqXfagtGfHHo5QONQ2UoI5VwOyxXDmoOippwmWJyI/9hi+TWmG5Y5UojTW
         V4QHGewiUvkkSXYESgWG5StlG2FwOzT523aOZaP3z51jkKjmoIzsj3b7RImZ4CoUpp+s
         bFxg==
X-Received: by 10.180.39.177 with SMTP id q17mr10799787wik.16.1386230094139;
 Wed, 04 Dec 2013 23:54:54 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 4 Dec 2013 23:54:34 -0800 (PST)
In-Reply-To: <CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
References: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com>
 <CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Thu, 5 Dec 2013 08:54:34 +0100
X-Google-Sender-Auth: MS74WjG8sc6SNjdSE9HJ49TgoQ0
Message-ID: <CAFvE7K7NdaR1r9o9P6DO53-8xgTZQw4sHdYQrcihs0ZDev4NxA@mail.gmail.com>
Subject: Re: Spark streaming quantile?
To: dev <dev@spark.incubator.apache.org>
Cc: laserson@cloudera.com
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

You might also want to have a look at Ted Dunning's t-digest:

  https://github.com/tdunning/t-digest

There is a paper with some theory here:

  https://github.com/tdunning/t-digest/blob/master/docs/theory/t-digest-paper/histo.pdf?raw=true

t-digests of partitions can also be merged hence suitable for parallel
implementations.

-- 
Olivier

From dev-return-816-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 08:49:36 2013
Return-Path: <dev-return-816-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4FBED10956
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 08:49:36 +0000 (UTC)
Received: (qmail 35877 invoked by uid 500); 5 Dec 2013 08:49:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35229 invoked by uid 500); 5 Dec 2013 08:49:22 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 35151 invoked by uid 99); 5 Dec 2013 08:49:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 08:49:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 08:49:15 +0000
Received: by mail-we0-f169.google.com with SMTP id w61so10687717wes.14
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 00:48:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=pk1tO2NbXY1fBvXkPHWnKU69T2xx3SazIBAKQkN9qKA=;
        b=TaYzRg8MtjB1cHmMH3zyxDA0QgzvqQGzPUo1kfmmjVPYO5b/amiyjcUQsKPiB7pafc
         2VpLv8gaz9dkiO6a4Y00mmuKBvChlkFFNf2puo48EWXicpR1RxEXRBvnelVbJtWqhnr6
         1aU5km6l/r3a055a8IwaBze7wfz2mT5/bv2TsELEwlY4gPeCFlFdtEOCJVjjRRSzPdWz
         AhnJnEAE3UhPNDbts9c3z/FXmsZZjaAabMxl/N87YM/onNCqr9lQIWCcEiKWw3js1TOw
         qqrz0CoxuFBBbEM+3KUUtT9QWJlMxdt/7c97+tgXbF0d6e6YkfjVkSwRFi3l8EopNM2O
         yQRw==
X-Received: by 10.180.90.114 with SMTP id bv18mr11006052wib.16.1386233334847;
 Thu, 05 Dec 2013 00:48:54 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Thu, 5 Dec 2013 00:48:34 -0800 (PST)
In-Reply-To: <CAOEPXP6NLKYuBRshKY-7GpU5+wMKCPq6KoRm3m6TS2DGSxwApg@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
 <CAFvE7K4dpZmEixkipPVO3oNTL2BJwMkDu6pr-rDp3p9_Mi9tYg@mail.gmail.com>
 <CAFvE7K6TAOOfWbFGxghTBwB3GbQevvLfst8sYt908+2KLvHZgw@mail.gmail.com>
 <CAFvE7K7YcZ2XBNDht-fPq5nrSSnJ4ruuX6hxoBOdCbPKyCA2Nw@mail.gmail.com>
 <CAFvE7K65r48JvGAHRZbYyYBQFJKRR_q08WvXEfBKq-_=u-SxdA@mail.gmail.com> <CAOEPXP6NLKYuBRshKY-7GpU5+wMKCPq6KoRm3m6TS2DGSxwApg@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Thu, 5 Dec 2013 09:48:34 +0100
X-Google-Sender-Auth: HO8oix3bBAWokAymaxKl75YDTm8
Message-ID: <CAFvE7K7sjjPYoqoAXcW5at9oCmXX=FO00uWSiLuU_ST1sxFbQw@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: dev <dev@spark.incubator.apache.org>
Cc: horia <horia@alum.berkeley.edu>, Reynold Xin <rxin@apache.org>, 
	Nick Pentreath <nick.pentreath@gmail.com>, Uri Laserson <Uri.Laserson@gmail.com>, 
	Justin Kestelyn <jkestelyn@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

2013/12/4 Josh Rosen <rosenville@gmail.com>:
> Thanks for organizing this!  I'll definitely be attending.

Great. Looking forward to meet you to.

Uri, you might want to register as well on the wiki :)

-- 
Olivier
http://twitter.com/ogrisel - http://github.com/ogrisel

From dev-return-817-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 12:50:33 2013
Return-Path: <dev-return-817-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8291910F89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 12:50:33 +0000 (UTC)
Received: (qmail 34620 invoked by uid 500); 5 Dec 2013 12:50:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34264 invoked by uid 500); 5 Dec 2013 12:50:23 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 34256 invoked by uid 99); 5 Dec 2013 12:50:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 12:50:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.219.43 as permitted sender)
Received: from [209.85.219.43] (HELO mail-oa0-f43.google.com) (209.85.219.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 12:50:16 +0000
Received: by mail-oa0-f43.google.com with SMTP id i7so18406524oag.30
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 04:49:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=CCrtnedxueGIFg2+Lc3JK/aGZRI6FsWsJqkTQMIaAms=;
        b=IHmt7JudgllKPThHsRrLsZSlmBAFL69ej7EYKSi5boBMJDbMWVMFXyGGeJ2MXu3m/E
         sZjNmmTERFHDikIeBVXo2+VwL0syBZ6bdSraRrd2A0OXGov57/rUQY9eWdeniH9VfpXy
         NYzOswKuanQH9R9g6uOcANMZRI6PlUF+vt3/Jq0zxVb0EscXG1p5h94e/pJUy99ZX0Ol
         zx3Czv1OkcpSIujNBfNEzQ/TFYYSKmDDaE8QBC2u69WcLktSQrcCjyNy3Fj39u4IPySw
         ivnuUon0/oNjfa8XqVoYSDISXrUEfZsBwGAHgyExKh3pefOw3p0iasFTZhPDc81GVrco
         YBpg==
MIME-Version: 1.0
X-Received: by 10.182.112.130 with SMTP id iq2mr1126005obb.57.1386247795768;
 Thu, 05 Dec 2013 04:49:55 -0800 (PST)
Received: by 10.182.95.103 with HTTP; Thu, 5 Dec 2013 04:49:55 -0800 (PST)
Date: Thu, 5 Dec 2013 14:49:55 +0200
Message-ID: <CALD+6GNVJ3UeNcuPgHn+nyQmG0CuNexecYRRYa-k6xRyXJECUg@mail.gmail.com>
Subject: PySpark - Dill serialization
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e01229a06704c1c04ecc8f7e1
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01229a06704c1c04ecc8f7e1
Content-Type: text/plain; charset=ISO-8859-1

Hi devs

I came across Dill (
http://trac.mystic.cacr.caltech.edu/project/pathos/wiki/dill) for Python
serialization. Was wondering if it may be a replacement to the cloudpickle
stuff (and remove that piece of code that needs to be maintained within
PySpark)?

Josh have you looked into Dill? Any thoughts?

N

--089e01229a06704c1c04ecc8f7e1--

From dev-return-818-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec  5 13:01:08 2013
Return-Path: <dev-return-818-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F8AA10FD6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Dec 2013 13:01:08 +0000 (UTC)
Received: (qmail 50768 invoked by uid 500); 5 Dec 2013 13:01:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50744 invoked by uid 500); 5 Dec 2013 13:01:01 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50718 invoked by uid 99); 5 Dec 2013 13:00:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 13:00:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of samkiller@gmail.com designates 209.85.215.173 as permitted sender)
Received: from [209.85.215.173] (HELO mail-ea0-f173.google.com) (209.85.215.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Dec 2013 13:00:52 +0000
Received: by mail-ea0-f173.google.com with SMTP id o10so278362eaj.4
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 05:00:31 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:references:from:content-type:in-reply-to:message-id:date:to
         :content-transfer-encoding:mime-version;
        bh=fblZotfsm8Peuq4aUj6KzN2TolNfooRzD9LvFFxFzRI=;
        b=y5T+OKS8HAeieTwGGaX9R45Ij5IfZr2amMDXBkrnCpfA6nsEc+xp9IykOiE1qlEgkB
         C6XGnrQ2TjFm1z70HgxorYFA3RRtJ5FmfqDDSP49BQ94pXCHQSj9fCYSKAoV11nLWl/B
         b6xeTK2nPzrHbUq9FExwVtQEMWStBpTaFfrhdah2w9VSR3NtbnnswwXsWpGP5zYn3jJt
         iHcN8sQVpiZrYBJG58HELXnGFbWwYY75v+ZmTu6X47pIy3w+Hcpt+O+yp4MQYydK2tit
         EuEyKtj7wU5MKMGXJVQa2zvkXx2Q0HqRCzcZsqw99hk10plZ01Aegt8TIwPPqMu7jiVp
         i2ww==
X-Received: by 10.14.174.129 with SMTP id x1mr20571768eel.19.1386248431867;
        Thu, 05 Dec 2013 05:00:31 -0800 (PST)
Received: from [172.27.100.104] (LCaen-151-91-3-60.w193-251.abo.wanadoo.fr. [193.251.42.60])
        by mx.google.com with ESMTPSA id v1sm27151823eef.9.2013.12.05.05.00.29
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 05 Dec 2013 05:00:29 -0800 (PST)
Subject: Re: Spark streaming quantile?
References: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com> <CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
From: Sam Bessalah <samkiller@gmail.com>
Content-Type: multipart/alternative;
	boundary=Apple-Mail-1FDFDD25-7608-4DDE-B1EF-86C243687C0A
X-Mailer: iPad Mail (11B554a)
In-Reply-To: <CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
Message-Id: <F5B17C19-2CB1-4692-BC10-8CDE9F7F8966@gmail.com>
Date: Thu, 5 Dec 2013 14:00:36 +0100
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (1.0)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-1FDFDD25-7608-4DDE-B1EF-86C243687C0A
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable

Just as stated before Algebird has many data structure to compute those like=
 QTree, or Ted's tvdigest . Or you can look at stream-lib q digest https://g=
ithub.com/addthis/stream-lib/blob/master/src/main/java/com/clearspring/analy=
tics/stream/quantile/QDigest.java=20
Or another one Frugal Streaming well described and with an implementation on=
 the AK blog
http://blog.aggregateknowledge.com/2013/09/16/sketch-of-the-day-frugal-strea=
ming/
There are some example in the Spark streaming sample on how to integrate alg=
ebird .
Sam Bessalah

> On Dec 5, 2013, at 5:41 AM, Ryan Weald <ryan@weald.com> wrote:
>=20
> Hi Sandy,
> You could take a look at using the Q-Tree data structure that is provided
> by Twitter's Algebird<https://github.com/twitter/algebird/blob/develop/alg=
ebird-core/src/main/scala/com/twitter/algebird/QTree.scala>.
> Due to the associative properties of Algebird's SemiGroup it is ideally
> suited for streaming computations.
>=20
> -Ryan
>=20
>=20
>> On Wed, Dec 4, 2013 at 8:32 PM, Sandy Ryza <sandy.ryza@cloudera.com> wrot=
e:
>>=20
>> Hi All,
>>=20
>> We're working on a Spark application that could make use of a computing
>> quantiles in a streaming fashion.  Something in the vein of what DataFu h=
as
>> for Pig
>>=20
>> http://linkedin.github.io/datafu/docs/current/datafu/pig/stats/StreamingQ=
uantile.html
>> .
>>=20
>> Does anything like this exist in the Spark ecosystem?  If not, would ther=
e
>> be a good place to contribute this if we write it?
>>=20
>> thanks,
>> Sandy
>>=20

--Apple-Mail-1FDFDD25-7608-4DDE-B1EF-86C243687C0A--

From dev-return-819-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec  6 03:01:37 2013
Return-Path: <dev-return-819-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A63D10FBB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Dec 2013 03:01:37 +0000 (UTC)
Received: (qmail 3574 invoked by uid 500); 6 Dec 2013 03:01:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3530 invoked by uid 500); 6 Dec 2013 03:01:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 3522 invoked by uid 99); 6 Dec 2013 03:01:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 03:01:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ilikerps@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 03:01:24 +0000
Received: by mail-wi0-f178.google.com with SMTP id bz8so129416wib.11
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 19:01:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=s8YXVGk95QwL0HRVw7HLwpFKvuMc9RD9DGkz7YpjtWI=;
        b=mWzB3TPt7jQ35W4TgPl5W5lDsW9e8r4jRdGBKFHVHJQOyrhTBfWxuvSAyp51QAEACf
         BHshTyuGINne1hT82Jnh97R+4IQZ23W6wwnnJ9sMhjs+uZU/3H+W6erlRLkM0XzoDZwP
         h/irq/t8PNAM8+HeFlxs4fWWIgvUzqvX2N+s4d2SX32L+CVLaIU1B7IiWQ5M0hKRFjLJ
         nu5yXp/EB8QncGRqypQEG3i2EtCzHhFUiUtvaTKC9OEEKMWt/RteuFNEx4jp2DpQGl+3
         8T6vm4TXl8V4UaH0d85JaK+VFLiQgcDYiowmDlVMooUG9rUbwYZvFQLS+mXS1uVmid3D
         9pKw==
X-Received: by 10.194.62.8 with SMTP id u8mr878534wjr.68.1386298862706; Thu,
 05 Dec 2013 19:01:02 -0800 (PST)
MIME-Version: 1.0
Received: by 10.194.119.228 with HTTP; Thu, 5 Dec 2013 19:00:42 -0800 (PST)
From: Aaron Davidson <ilikerps@gmail.com>
Date: Thu, 5 Dec 2013 19:00:42 -0800
Message-ID: <CANGvG8q8XJxBqZpF9H65ApynqaWh+OVvN7kFCqoJC60+JNZxOQ@mail.gmail.com>
Subject: IntelliJ Scala Import Organizer Plugin
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7ba9839843a4fe04ecd4dbea
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7ba9839843a4fe04ecd4dbea
Content-Type: text/plain; charset=ISO-8859-1

Hi guys, just wanted to share a little plugin I wrote for IntelliJ to help
auto-organize Scala imports. Anyone who has submitted a patch to Spark has
probably felt the exhilaration of manually sorting and bucketing your
imports. Well, now you can let your IDE have some fun!

It's in the plugin repository, so you can download it from within IntelliJ.
Just go to *Settings -> Plugins -> Browse repositories...* and type "Scala
Import" and it should show up. Once installed, go to *Settings -> Code
Style -> Scala Imports Organizer *to configure the bucketing rules. Here
are some Matei-approvedTM rules for Spark:

import scala.language.*

import java.*

import scala.*

import *

import org.apache.spark.*


To actually organize imports, just press Ctrl+Shift+O by default (I think
that's Cmd+Shift+O on Macs) or *Tools -> Organize Scala Imports*.

If you find a bug or have a suggestion, please let me know. The IntelliJ
plugin page is here
<http://plugins.jetbrains.com/plugin/7350?pr=idea>(feel free to vote!)
and the Github project is
here <https://github.com/aarondav/scala-imports-organizer>.

Also be sure to have a great day!

--047d7ba9839843a4fe04ecd4dbea--

From dev-return-822-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec  6 06:24:19 2013
Return-Path: <dev-return-822-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0C7061017F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Dec 2013 06:24:19 +0000 (UTC)
Received: (qmail 91168 invoked by uid 500); 6 Dec 2013 05:24:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91120 invoked by uid 500); 6 Dec 2013 05:24:07 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 91098 invoked by uid 99); 6 Dec 2013 05:24:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 05:24:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of imran@quantifind.com designates 209.85.160.41 as permitted sender)
Received: from [209.85.160.41] (HELO mail-pb0-f41.google.com) (209.85.160.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 05:23:58 +0000
Received: by mail-pb0-f41.google.com with SMTP id jt11so409837pbb.0
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 21:23:37 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=tLZc5YBpy/AkNQEuss0TPfyzXO40PE8q3y4yAI9tJ/E=;
        b=H+Vo5ZI1rOfUZcQWm92elRfbTY9OfrC/sZt9PxIAizdH1hN1m4h+7hou86OI4OTOG5
         3MIltBaH7sIopQjEr3iAWjDtTx3jDa9CZxJWqUQP3ZJwfqxPheYdU4gFzJyRxkicHAAw
         z8uTCk9jLGStcC5Wni7Zx9qa1bWx5l5qLBxSxfwbb1r7IPh5WViyv2DAIl0RE8cQnMRG
         2472C9KAnHxGE+oB0jSZDCxxJMOql/sV/BmU0IGCgR78xwQ7X7xJxABjaWloSiToR8Hf
         /2gMvsweOV5GHfrukxqRcIYC5xVrk2mv22CCHrVjewFzanmVTDCWbc1XckopUWc948YM
         zvvg==
X-Gm-Message-State: ALoCoQmm9vUx8LBgYnvURl5m9LsbvITPorO/juohgbVe8czguwYYfW3SIVAgqr9UWkezpekH2PHV
MIME-Version: 1.0
X-Received: by 10.66.170.168 with SMTP id an8mr1851878pac.58.1386307417270;
 Thu, 05 Dec 2013 21:23:37 -0800 (PST)
Received: by 10.66.219.163 with HTTP; Thu, 5 Dec 2013 21:23:37 -0800 (PST)
X-Originating-IP: [71.202.18.82]
In-Reply-To: <CANGvG8q8XJxBqZpF9H65ApynqaWh+OVvN7kFCqoJC60+JNZxOQ@mail.gmail.com>
References: <CANGvG8q8XJxBqZpF9H65ApynqaWh+OVvN7kFCqoJC60+JNZxOQ@mail.gmail.com>
Date: Thu, 5 Dec 2013 21:23:37 -0800
Message-ID: <CAO24D=Rz8hWSt-m-zfei4RBx9O11KJLfbL3pcT3vNsRAvEFzKw@mail.gmail.com>
Subject: Re: IntelliJ Scala Import Organizer Plugin
From: Imran Rashid <imran@quantifind.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bdc9a4828305f04ecd6d943
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc9a4828305f04ecd6d943
Content-Type: text/plain; charset=ISO-8859-1

awesome, thanks.

I've been wanting this even for all my scala projects for a while


On Thu, Dec 5, 2013 at 7:00 PM, Aaron Davidson <ilikerps@gmail.com> wrote:

> Hi guys, just wanted to share a little plugin I wrote for IntelliJ to help
> auto-organize Scala imports. Anyone who has submitted a patch to Spark has
> probably felt the exhilaration of manually sorting and bucketing your
> imports. Well, now you can let your IDE have some fun!
>
> It's in the plugin repository, so you can download it from within IntelliJ.
> Just go to *Settings -> Plugins -> Browse repositories...* and type "Scala
> Import" and it should show up. Once installed, go to *Settings -> Code
> Style -> Scala Imports Organizer *to configure the bucketing rules. Here
> are some Matei-approvedTM rules for Spark:
>
> import scala.language.*
>
> import java.*
>
> import scala.*
>
> import *
>
> import org.apache.spark.*
>
>
> To actually organize imports, just press Ctrl+Shift+O by default (I think
> that's Cmd+Shift+O on Macs) or *Tools -> Organize Scala Imports*.
>
> If you find a bug or have a suggestion, please let me know. The IntelliJ
> plugin page is here
> <http://plugins.jetbrains.com/plugin/7350?pr=idea>(feel free to vote!)
> and the Github project is
> here <https://github.com/aarondav/scala-imports-organizer>.
>
> Also be sure to have a great day!
>

--047d7bdc9a4828305f04ecd6d943--

From dev-return-820-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec  6 06:53:24 2013
Return-Path: <dev-return-820-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 69D5B1055E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Dec 2013 06:53:24 +0000 (UTC)
Received: (qmail 16043 invoked by uid 500); 6 Dec 2013 04:03:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16005 invoked by uid 500); 6 Dec 2013 04:03:16 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 15995 invoked by uid 99); 6 Dec 2013 04:03:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 04:03:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.160.48 as permitted sender)
Received: from [209.85.160.48] (HELO mail-pb0-f48.google.com) (209.85.160.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 04:03:10 +0000
Received: by mail-pb0-f48.google.com with SMTP id md12so288124pbc.35
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 20:02:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=TLdjU/7CcTNBbCrUVq2YMTPg/rmzekeLxti7+hoc06g=;
        b=csZLPf8ny1AMkqk767ATHBaS0S113nXQ9mL689jOyFJKHFaFR0DqPVdXKcMdwf5ilC
         Ki7QiGQINqYXTDoawLSd2uTXkBBXQex/2OKVzYFdWUOpwtn44M5rVr8hPqFBC/j35+G4
         uHhk5djyvhsY3QZqC9DClWB8obLt6BKnocCvFWeWpP6bQSN7S1RF8SeGYK1Nc+TAD5iT
         J7B0KDsSH0/WSqKD4kjz7CL40gXJI1PHCTDTCr1xDH3VKTEM1EXcgbTaUrJCHanBUKAb
         EERRnxBwfG0QVmKH+gvTOm81y2ncr18TfgjJr/9w0tZgMnXHgtYd2d3hO0nasw3muTC1
         Dj4Q==
MIME-Version: 1.0
X-Received: by 10.67.8.102 with SMTP id dj6mr1519073pad.10.1386302569929; Thu,
 05 Dec 2013 20:02:49 -0800 (PST)
Received: by 10.70.24.3 with HTTP; Thu, 5 Dec 2013 20:02:49 -0800 (PST)
In-Reply-To: <CALD+6GNVJ3UeNcuPgHn+nyQmG0CuNexecYRRYa-k6xRyXJECUg@mail.gmail.com>
References: <CALD+6GNVJ3UeNcuPgHn+nyQmG0CuNexecYRRYa-k6xRyXJECUg@mail.gmail.com>
Date: Thu, 5 Dec 2013 20:02:49 -0800
Message-ID: <CAOEPXP71O-x2SqQJBQV=Zd89Mg4W3NjR0pEf2Sut_jEkVZ7LdA@mail.gmail.com>
Subject: Re: PySpark - Dill serialization
From: Josh Rosen <rosenville@gmail.com>
To: "Spark Dev (Apache Incubator)" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e0158c0d43b66a804ecd5b8c8
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158c0d43b66a804ecd5b8c8
Content-Type: text/plain; charset=ISO-8859-1

Thanks for the link!  I wasn't aware of Dill, but it looks like a nice
library.  I like that it's being actively developed:
https://github.com/uqfoundation/dill

It also seems to work correctly for a few edge-cases that cloudpickle
didn't handle properly, such as serializing operator.itemgetter instances
(see https://spark-project.atlassian.net/browse/SPARK-791).

I'll put together a pull request to replace CloudPickle with Dill.  Dill
uses a 3-clause BSD license, so we should be able to package it into an
.egg in the python/lib/ folder like we did for Py4J.  It will be
interesting to see whether the change has any performance impact, although
the recent custom serializers pull request should help with that since it
would let us use Dill for serializing functions and a faster serializer for
serializing data.

- Josh




On Thu, Dec 5, 2013 at 4:49 AM, Nick Pentreath <nick.pentreath@gmail.com>wrote:

> Hi devs
>
> I came across Dill (
> http://trac.mystic.cacr.caltech.edu/project/pathos/wiki/dill) for Python
> serialization. Was wondering if it may be a replacement to the cloudpickle
> stuff (and remove that piece of code that needs to be maintained within
> PySpark)?
>
> Josh have you looked into Dill? Any thoughts?
>
> N
>

--089e0158c0d43b66a804ecd5b8c8--

From dev-return-821-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec  6 07:02:40 2013
Return-Path: <dev-return-821-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 36F5E105BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Dec 2013 07:02:40 +0000 (UTC)
Received: (qmail 30377 invoked by uid 500); 6 Dec 2013 04:15:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29025 invoked by uid 500); 6 Dec 2013 04:15:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 28901 invoked by uid 99); 6 Dec 2013 04:15:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 04:15:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.160.44 as permitted sender)
Received: from [209.85.160.44] (HELO mail-pb0-f44.google.com) (209.85.160.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 04:15:34 +0000
Received: by mail-pb0-f44.google.com with SMTP id rq2so303899pbb.31
        for <dev@spark.incubator.apache.org>; Thu, 05 Dec 2013 20:15:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=rZF6VxtL3ncKPWcdKMKutBISc6N6fMLdZkeIjG/clQU=;
        b=CXzGmVb8hiFPXwSSq1eRDPrdJaxO8pQ6VLQMdZRr82NtAwyv+gN7bTWhWTyg0nQ3XK
         ei4/eCBXxyqKohSpDxrv7115BoR0IcX1xgS87iUUquEFWAO9RvRI60H7lfx2ijjjnujN
         bkfUf9gNEznyC+qtDZRxnoD5ufsW2jYOknQHUqavCMoF3GAZTWi7yJ6neJesCUlusPoT
         SZZHLC+6OpE/8wLcDqUthXX4RTdtVKsI5TiAzBwHxxMnPClNbWn+SJDtGJsxBrQciPsG
         0DBvVVp0+5g7VUWi/kxRkLUCpHgeZ5oWIlhayrXALNGPAeYqdXrw/g79OJLbWMsro9nh
         fS/A==
X-Received: by 10.66.26.106 with SMTP id k10mr1587702pag.136.1386303313844;
        Thu, 05 Dec 2013 20:15:13 -0800 (PST)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id pl1sm148382304pbb.20.2013.12.05.20.15.11
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 05 Dec 2013 20:15:12 -0800 (PST)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: PySpark - Dill serialization
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAOEPXP71O-x2SqQJBQV=Zd89Mg4W3NjR0pEf2Sut_jEkVZ7LdA@mail.gmail.com>
Date: Thu, 5 Dec 2013 20:15:09 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <2603FD46-0C37-4B21-B633-4BE6A18DEEF3@gmail.com>
References: <CALD+6GNVJ3UeNcuPgHn+nyQmG0CuNexecYRRYa-k6xRyXJECUg@mail.gmail.com> <CAOEPXP71O-x2SqQJBQV=Zd89Mg4W3NjR0pEf2Sut_jEkVZ7LdA@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Looks cool! Josh, if you replace CloudPickle with this, make sure to =
also update the LICENSE file, which is supposed to contain third-party =
licenses.

Matei

On Dec 5, 2013, at 8:02 PM, Josh Rosen <rosenville@gmail.com> wrote:

> Thanks for the link!  I wasn't aware of Dill, but it looks like a nice
> library.  I like that it's being actively developed:
> https://github.com/uqfoundation/dill
>=20
> It also seems to work correctly for a few edge-cases that cloudpickle
> didn't handle properly, such as serializing operator.itemgetter =
instances
> (see https://spark-project.atlassian.net/browse/SPARK-791).
>=20
> I'll put together a pull request to replace CloudPickle with Dill.  =
Dill
> uses a 3-clause BSD license, so we should be able to package it into =
an
> .egg in the python/lib/ folder like we did for Py4J.  It will be
> interesting to see whether the change has any performance impact, =
although
> the recent custom serializers pull request should help with that since =
it
> would let us use Dill for serializing functions and a faster =
serializer for
> serializing data.
>=20
> - Josh
>=20
>=20
>=20
>=20
> On Thu, Dec 5, 2013 at 4:49 AM, Nick Pentreath =
<nick.pentreath@gmail.com>wrote:
>=20
>> Hi devs
>>=20
>> I came across Dill (
>> http://trac.mystic.cacr.caltech.edu/project/pathos/wiki/dill) for =
Python
>> serialization. Was wondering if it may be a replacement to the =
cloudpickle
>> stuff (and remove that piece of code that needs to be maintained =
within
>> PySpark)?
>>=20
>> Josh have you looked into Dill? Any thoughts?
>>=20
>> N
>>=20


From dev-return-823-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec  6 19:29:02 2013
Return-Path: <dev-return-823-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2408B10B80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Dec 2013 19:29:02 +0000 (UTC)
Received: (qmail 17107 invoked by uid 500); 6 Dec 2013 19:29:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16956 invoked by uid 500); 6 Dec 2013 19:29:01 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 16948 invoked by uid 99); 6 Dec 2013 19:29:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 19:29:01 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.160.51 as permitted sender)
Received: from [209.85.160.51] (HELO mail-pb0-f51.google.com) (209.85.160.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Dec 2013 19:28:57 +0000
Received: by mail-pb0-f51.google.com with SMTP id up15so1612901pbc.24
        for <dev@spark.incubator.apache.org>; Fri, 06 Dec 2013 11:28:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=lfZKEYMeGzBA3OQb/LqiT/5VaVONhzRBUxI+0hS1sPo=;
        b=ZwEQGuWVVUQ3oZVKiWj/UgZ8mf0qjyS8EkY8eZKJQIZ/EQ/LZtim7/Hh+0m+1vs4cj
         DwfU5+NKw+5Fqicb1I9sqUrEks2Iuc3O6eaLPCynglVM4MKDpXLWdjFwjLhzJoMVLPVd
         gkDtMY2hI2e5BC0g6vH0UFJgiTJbZuIEwdNENXvl/4sau4w0iheABVFIkuYMIFDZhlSI
         51w3Zj2+pf4ACqHIoxrvztf90Cl0GMuejPFuirVz5u2IxBha6yNkXyOFb/Vy9FB5bhiH
         DTwQjpPbdvAjD4UlXognqq1QFsLi5GT06cgLHi6w7CYKeONPm7y3UmcZPBbQfL+AWViJ
         a14w==
MIME-Version: 1.0
X-Received: by 10.66.216.193 with SMTP id os1mr6129860pac.29.1386358116943;
 Fri, 06 Dec 2013 11:28:36 -0800 (PST)
Received: by 10.70.24.3 with HTTP; Fri, 6 Dec 2013 11:28:36 -0800 (PST)
In-Reply-To: <2603FD46-0C37-4B21-B633-4BE6A18DEEF3@gmail.com>
References: <CALD+6GNVJ3UeNcuPgHn+nyQmG0CuNexecYRRYa-k6xRyXJECUg@mail.gmail.com>
	<CAOEPXP71O-x2SqQJBQV=Zd89Mg4W3NjR0pEf2Sut_jEkVZ7LdA@mail.gmail.com>
	<2603FD46-0C37-4B21-B633-4BE6A18DEEF3@gmail.com>
Date: Fri, 6 Dec 2013 11:28:36 -0800
Message-ID: <CAOEPXP5hu-dhGnjQq=RYdT35G-eeEYPVopgqQdf2NFxRB7vA_g@mail.gmail.com>
Subject: Re: PySpark - Dill serialization
From: Josh Rosen <rosenville@gmail.com>
To: "Spark Dev (Apache Incubator)" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d668e178c9d04ece2a7a8
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d668e178c9d04ece2a7a8
Content-Type: text/plain; charset=ISO-8859-1

I tried replacing cloudpickle with Dill (
https://github.com/JoshRosen/incubator-spark/commit/2ac8986f3009f0dc133b11d16887fc8ddb33c3d1)
but I ran into a few issues.

It looks like Dill pickles function closures differently for functions
defined in doctests versus in module code / the shell, which breaks
PySpark's test suite; I opened an issue for this in the Dill repo:
https://github.com/uqfoundation/dill/issues/18.

Its closure cleaning may work differently than cloudpickle's because I've
also encountered some examples that also fail in the shell (accumulators).

Many simple cases, like PySpark's wordcount.py example, work fine, so I'm
hoping we'll be able to make the switch to Dill if those doctest issues are
resolved.


On Thu, Dec 5, 2013 at 8:15 PM, Matei Zaharia <matei.zaharia@gmail.com>wrote:

> Looks cool! Josh, if you replace CloudPickle with this, make sure to also
> update the LICENSE file, which is supposed to contain third-party licenses.
>
> Matei
>
> On Dec 5, 2013, at 8:02 PM, Josh Rosen <rosenville@gmail.com> wrote:
>
> > Thanks for the link!  I wasn't aware of Dill, but it looks like a nice
> > library.  I like that it's being actively developed:
> > https://github.com/uqfoundation/dill
> >
> > It also seems to work correctly for a few edge-cases that cloudpickle
> > didn't handle properly, such as serializing operator.itemgetter instances
> > (see https://spark-project.atlassian.net/browse/SPARK-791).
> >
> > I'll put together a pull request to replace CloudPickle with Dill.  Dill
> > uses a 3-clause BSD license, so we should be able to package it into an
> > .egg in the python/lib/ folder like we did for Py4J.  It will be
> > interesting to see whether the change has any performance impact,
> although
> > the recent custom serializers pull request should help with that since it
> > would let us use Dill for serializing functions and a faster serializer
> for
> > serializing data.
> >
> > - Josh
> >
> >
> >
> >
> > On Thu, Dec 5, 2013 at 4:49 AM, Nick Pentreath <nick.pentreath@gmail.com
> >wrote:
> >
> >> Hi devs
> >>
> >> I came across Dill (
> >> http://trac.mystic.cacr.caltech.edu/project/pathos/wiki/dill) for
> Python
> >> serialization. Was wondering if it may be a replacement to the
> cloudpickle
> >> stuff (and remove that piece of code that needs to be maintained within
> >> PySpark)?
> >>
> >> Josh have you looked into Dill? Any thoughts?
> >>
> >> N
> >>
>
>

--047d7b5d668e178c9d04ece2a7a8--

From dev-return-824-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec  7 12:16:06 2013
Return-Path: <dev-return-824-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C443510498
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  7 Dec 2013 12:16:06 +0000 (UTC)
Received: (qmail 38092 invoked by uid 500); 7 Dec 2013 12:16:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38040 invoked by uid 500); 7 Dec 2013 12:15:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 38031 invoked by uid 99); 7 Dec 2013 12:15:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Dec 2013 12:15:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Dec 2013 12:15:49 +0000
Received: by mail-ob0-f170.google.com with SMTP id wp18so1961915obc.1
        for <dev@spark.incubator.apache.org>; Sat, 07 Dec 2013 04:15:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=UpfrVS4+mhDfbFZshERhLlQUV8AkFH6rrVvQTVQJ/jo=;
        b=S/tw1nktQL6N8CxBF/6SU3APhQTw+sgxWd39eRhDjV+LRE35YQ51A9L57RAPxXUo5a
         EUIFeXdTYIk//OvcZ8b1KmhF7bKqFTz6dcy6RnTExxavctNTwEvM1wfavWRZH8R1vaSx
         ORy+/mrJC4hxlhDt6h0Fa8Nsb+p5cumqlwZxyI0PzWHFj8U7QI6zj9/Vl340jfO+ipxg
         cLeb+SOdUrF6Vdg20yTw1S3R4dhsjgpgR1J2HkzKmnZAWi8SlEER073fzRFVlLmt6APv
         CJyq1DG1Kh9BChR2dv1bmra2FMPLnNmTewMmu58HOe21IME9D431JS0BYz93X976Uo8M
         TrRQ==
MIME-Version: 1.0
X-Received: by 10.183.3.102 with SMTP id bv6mr6308713obd.18.1386418528266;
 Sat, 07 Dec 2013 04:15:28 -0800 (PST)
Received: by 10.182.95.103 with HTTP; Sat, 7 Dec 2013 04:15:28 -0800 (PST)
Date: Sat, 7 Dec 2013 14:15:28 +0200
Message-ID: <CALD+6GPiLTukP3F5JB+t+-80Y4fFpHHCy+CqwdV49+zwp_-xgg@mail.gmail.com>
Subject: Intellij IDEA build issues
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1134a45ce32fb104ecf0b786
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134a45ce32fb104ecf0b786
Content-Type: text/plain; charset=ISO-8859-1

Hi Spark Devs,

Hoping someone cane help me out. No matter what I do, I cannot get Intellij
to build Spark from source. I am using IDEA 13. I run sbt gen-idea and
everything seems to work fine.

When I try to build using IDEA, everything compiles but I get the error
below.

Have any of you come across the same?

======

Internal error: (java.lang.AssertionError)
java/nio/channels/FileChannel$MapMode already declared as
ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
java.lang.AssertionError: java/nio/channels/FileChannel$MapMode already
declared as ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
at
ch.epfl.lamp.fjbg.JInnerClassesAttribute.addEntry(JInnerClassesAttribute.java:74)
at
scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:738)
at
scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:733)
at
scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59)
at scala.collection.immutable.List.foreach(List.scala:76)
at
scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.addInnerClasses(GenJVM.scala:733)
at
scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.emitClass(GenJVM.scala:200)
at
scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.genClass(GenJVM.scala:355)
at
scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
at
scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
at
scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
at
scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
at scala.collection.Iterator$class.foreach(Iterator.scala:772)
at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
at
scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:104)
at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.scala:86)
at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
at xsbt.CachedCompiler0.run(CompilerInterface.scala:123)
at xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:99)
at xsbt.CachedCompiler0.run(CompilerInterface.scala:99)
at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at sbt.compiler.AnalyzingCompiler.call(AnalyzingCompiler.scala:102)
at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:48)
at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:41)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply$mcV$sp(AggressiveCompile.scala:106)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
at
sbt.compiler.AggressiveCompile.sbt$compiler$AggressiveCompile$$timed(AggressiveCompile.scala:173)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:105)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:102)
at scala.Option.foreach(Option.scala:236)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
at
sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
at scala.Option.foreach(Option.scala:236)
at
sbt.compiler.AggressiveCompile$$anonfun$6.compileScala$1(AggressiveCompile.scala:102)
at
sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:151)
at
sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:89)
at sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:39)
at sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:37)
at sbt.inc.Incremental$.cycle(Incremental.scala:75)
at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:34)
at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:33)
at sbt.inc.Incremental$.manageClassfiles(Incremental.scala:42)
at sbt.inc.Incremental$.compile(Incremental.scala:33)
at sbt.inc.IncrementalCompile$.apply(Compile.scala:27)
at sbt.compiler.AggressiveCompile.compile2(AggressiveCompile.scala:164)
at sbt.compiler.AggressiveCompile.compile1(AggressiveCompile.scala:73)
at
org.jetbrains.jps.incremental.scala.local.CompilerImpl.compile(CompilerImpl.scala:61)
at
org.jetbrains.jps.incremental.scala.local.LocalServer.compile(LocalServer.scala:26)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:118)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:100)
at scala.util.Either$RightProjection.map(Either.scala:536)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:100)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:99)
at scala.util.Either$RightProjection.flatMap(Either.scala:523)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:99)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:98)
at scala.util.Either$RightProjection.flatMap(Either.scala:523)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder.doBuild(ScalaBuilder.scala:98)
at
org.jetbrains.jps.incremental.scala.ScalaBuilder.build(ScalaBuilder.scala:68)
at
org.jetbrains.jps.incremental.scala.ScalaBuilderService$ScalaBuilderDecorator.build(ScalaBuilderService.java:42)
at
org.jetbrains.jps.incremental.IncProjectBuilder.runModuleLevelBuilders(IncProjectBuilder.java:1086)
at
org.jetbrains.jps.incremental.IncProjectBuilder.runBuildersForChunk(IncProjectBuilder.java:797)
at
org.jetbrains.jps.incremental.IncProjectBuilder.buildTargetsChunk(IncProjectBuilder.java:845)
at
org.jetbrains.jps.incremental.IncProjectBuilder.buildChunkIfAffected(IncProjectBuilder.java:760)
at
org.jetbrains.jps.incremental.IncProjectBuilder.buildChunks(IncProjectBuilder.java:583)
at
org.jetbrains.jps.incremental.IncProjectBuilder.runBuild(IncProjectBuilder.java:344)
at
org.jetbrains.jps.incremental.IncProjectBuilder.build(IncProjectBuilder.java:184)
at org.jetbrains.jps.cmdline.BuildRunner.runBuild(BuildRunner.java:129)
at org.jetbrains.jps.cmdline.BuildSession.runBuild(BuildSession.java:224)
at org.jetbrains.jps.cmdline.BuildSession.run(BuildSession.java:113)
at
org.jetbrains.jps.cmdline.BuildMain$MyMessageHandler$1.run(BuildMain.java:133)
at
org.jetbrains.jps.service.impl.SharedThreadPoolImpl$1.run(SharedThreadPoolImpl.java:41)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
at java.util.concurrent.FutureTask.run(FutureTask.java:166)
at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:722)

--001a1134a45ce32fb104ecf0b786--

From dev-return-825-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec  7 23:25:25 2013
Return-Path: <dev-return-825-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AD60C10E88
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  7 Dec 2013 23:25:25 +0000 (UTC)
Received: (qmail 48255 invoked by uid 500); 7 Dec 2013 23:25:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48213 invoked by uid 500); 7 Dec 2013 23:25:25 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 48205 invoked by uid 99); 7 Dec 2013 23:25:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Dec 2013 23:25:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.53 as permitted sender)
Received: from [209.85.219.53] (HELO mail-oa0-f53.google.com) (209.85.219.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Dec 2013 23:25:18 +0000
Received: by mail-oa0-f53.google.com with SMTP id m1so2401855oag.40
        for <dev@spark.incubator.apache.org>; Sat, 07 Dec 2013 15:24:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=f20mUMLHK8MxnZpvhjkXtlG/2j4oXDKCVuIv9s146zc=;
        b=BCUX8XTgc34XhLDpeBGdkqAnKXFwy+sP8PL4seyIjAbLwepNigT9UCILVkw7FXV0QO
         VvOa0hsr1+KzMNwt8jPY3DG1KibkM8F6hGcr+2cBQgly5538keZrtKz1oy0yuB/JCeCi
         3CsfkdE7+rkoX7LaH85rGtNGJMDezOy5ZgAz9JrNzD6gW466bXpqUVx1rdzi0rbysPAZ
         klIYCrVLFP8ccSrwq+D5c5QUVsOAqcuZEVBoalbOAzVlW7fBdhjo45GR7c3AlwZ4Dhrs
         /OOjOdWUPP5k1Fw2uAy3Hoh/nR8+zhpO0cCr+n8AacfdIOOFRo3mLmDQWSR+KsSMKMcq
         qjtw==
MIME-Version: 1.0
X-Received: by 10.182.92.231 with SMTP id cp7mr175982obb.82.1386458697117;
 Sat, 07 Dec 2013 15:24:57 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sat, 7 Dec 2013 15:24:57 -0800 (PST)
Date: Sat, 7 Dec 2013 15:24:57 -0800
Message-ID: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Please vote on releasing the following candidate as Apache Spark
(incubating) version 0.8.1.

The tag to be voted on is v0.8.1-incubating (commit fba8738):
https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57

The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
- or -
https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-022/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/

Please vote on releasing this package as Apache Spark 0.8.1-incubating!

The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
a majority of at least 3 +1 PPMC votes are cast.

[ ] +1 Release this package as Apache Spark 0.8.1-incubating
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.incubator.apache.org/

From dev-return-826-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 01:41:46 2013
Return-Path: <dev-return-826-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7DDCB10022
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 01:41:46 +0000 (UTC)
Received: (qmail 96167 invoked by uid 500); 8 Dec 2013 01:41:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96134 invoked by uid 500); 8 Dec 2013 01:41:46 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 96126 invoked by uid 99); 8 Dec 2013 01:41:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 01:41:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.41] (HELO mail-bk0-f41.google.com) (209.85.214.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 01:41:39 +0000
Received: by mail-bk0-f41.google.com with SMTP id v15so863332bkz.28
        for <dev@spark.incubator.apache.org>; Sat, 07 Dec 2013 17:41:18 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=jnjczQzY5FUDt3AWSq2zgbo1aplfleC0vZU8fAITwAs=;
        b=BZj/z707JCKULU2ZxuSRNWD7LwalnKe/Xbqe1Na2VrmagAO0txnrx5ZtNvD7vx4wTn
         s7Lx4hWxOeilkjgbXSV+kZZxiBu+jRT8jqITQspPsqW/VLcC6dLW75WfR9RqG9Le8c8h
         yu3FGcr6L7eoYCN+taxMoeVHfPSEWm8kAbwYNOFYTT9UB+zw7aX+TN6iL8dn81PhzbSy
         kg3d8pd6Kapy0Bi8qzschjIuCViPURv30HRVmOB69+mGoSyfZ3vYUpFcLDYpc+8jvyMo
         B6hFNpr6bkdEDdr0iCb1vXxqShQvxvxZQ+iCz9TxnqY8P/xifbeeq6YTfzVKJxuR7XTr
         B7Dw==
X-Gm-Message-State: ALoCoQlhZH4qKENk4ai74tn4BXXgKYJ06dmzEDg1s+U3jTiVMWpcqi7H51y/w8x76UC1LWZJtJTK
MIME-Version: 1.0
X-Received: by 10.204.202.72 with SMTP id fd8mr37758bkb.65.1386466878218; Sat,
 07 Dec 2013 17:41:18 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sat, 7 Dec 2013 17:41:18 -0800 (PST)
In-Reply-To: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
References: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
Date: Sat, 7 Dec 2013 17:41:18 -0800
Message-ID: <CAAsvFP=bd=19OFvriXRGXQLrnwavETwDGcFWPHgOzu_gB59Q5A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=485b3970d31ec53d0604ecfbf9ab
X-Virus-Checked: Checked by ClamAV on apache.org

--485b3970d31ec53d0604ecfbf9ab
Content-Type: text/plain; charset=ISO-8859-1

Not sure.  I haven't been able to discern any pattern as to what new code
goes into both 0.9 and 0.8 vs. what goes only into 0.8, so I can't really
tell whether 0.8.1 is done or if something has been overlooked and not
cherry-picked from master.


On Sat, Dec 7, 2013 at 3:24 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Please vote on releasing the following candidate as Apache Spark
> (incubating) version 0.8.1.
>
> The tag to be voted on is v0.8.1-incubating (commit fba8738):
>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57
>
> The release files, including signatures, digests, etc can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
> - or -
>
> https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-022/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/
>
> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>
> The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
> a majority of at least 3 +1 PPMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.incubator.apache.org/
>

--485b3970d31ec53d0604ecfbf9ab--

From dev-return-827-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 08:04:04 2013
Return-Path: <dev-return-827-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25CC7105A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 08:04:04 +0000 (UTC)
Received: (qmail 51508 invoked by uid 500); 8 Dec 2013 08:04:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51466 invoked by uid 500); 8 Dec 2013 08:03:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 51300 invoked by uid 99); 8 Dec 2013 08:03:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 08:03:55 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.181 as permitted sender)
Received: from [209.85.192.181] (HELO mail-pd0-f181.google.com) (209.85.192.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 08:03:48 +0000
Received: by mail-pd0-f181.google.com with SMTP id p10so3361945pdj.40
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 00:03:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=aRXBc0IWCkU9Kb61L+nUrqgYZv1TP6De5K4WuDvwNpQ=;
        b=yWjshiL3QbT3Ro7DdlEzXj9/iegsYHnEz0cSFCwiBx7V3M7g/z4WtwyXgcyc/nlRv2
         0/6jCWeUIVR6GzwkM8tbtuqb8jliS//t0kQ4n5CV0SgyVc8TX72o73Rgmn5PpAQ4Redm
         z6Gxn9CrvTAUoUnzsPXQeFITsyuhf5EsWDbXu4nRciIittPdSQDRezlZ3RqkN9HqohUf
         dzqLM6GX9CF54G6THV/v+n4ZD1YPylQ7pSCclhYvZqym5WSVWFV6ioOYklpVqXpZbqgZ
         fMQt9Z9SIiv6mtazpw9UgxCwup+pDvzG87r6UZbXEI+SM5SRdiEBwJwWCecF19hrzPW4
         Obbw==
MIME-Version: 1.0
X-Received: by 10.66.219.233 with SMTP id pr9mr14020371pac.45.1386489807556;
 Sun, 08 Dec 2013 00:03:27 -0800 (PST)
Received: by 10.70.24.3 with HTTP; Sun, 8 Dec 2013 00:03:27 -0800 (PST)
In-Reply-To: <CAAsvFP=bd=19OFvriXRGXQLrnwavETwDGcFWPHgOzu_gB59Q5A@mail.gmail.com>
References: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
	<CAAsvFP=bd=19OFvriXRGXQLrnwavETwDGcFWPHgOzu_gB59Q5A@mail.gmail.com>
Date: Sun, 8 Dec 2013 00:03:27 -0800
Message-ID: <CAOEPXP5N2sZhH9hpHsEmSUcXZL_n9-iabX-9yraENSkfUV-pRA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Josh Rosen <rosenville@gmail.com>
To: "Spark Dev (Apache Incubator)" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d58e476d7f004ed015096
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d58e476d7f004ed015096
Content-Type: text/plain; charset=ISO-8859-1

We can use git log to figure out which changes haven't made it into
branch-0.8.  Here's a quick attempt, which only lists pull requests that
were only merged into one of the branches.  For completeness, this could be
extended to find commits that weren't part of a merge and are only present
in one branch.

*Script:*

MASTER_BRANCH=origin/master
RELEASE_BRANCH=origin/branch-0.8

git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f 2-
-d ' ' | sort > master-prs
git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f 2-
-d ' ' | sort > release-prs

comm -23 master-prs release-prs > master-only
comm -23 release-prs master-prs > release-only


*Master Branch Only:*
Merge pull request #1 from colorant/yarn-client-2.2
Merge pull request #105 from pwendell/doc-fix
Merge pull request #110 from pwendell/master
Merge pull request #146 from JoshRosen/pyspark-custom-serializers
Merge pull request #151 from russellcardullo/add-graphite-sink
Merge pull request #154 from soulmachine/ClusterScheduler
Merge pull request #156 from haoyuan/master
Merge pull request #159 from liancheng/dagscheduler-actor-refine
Merge pull request #16 from pwendell/master
Merge pull request #185 from mkolod/random-number-generator
Merge pull request #187 from aarondav/example-bcast-test
Merge pull request #190 from markhamstra/Stages4Jobs
Merge pull request #198 from ankurdave/zipPartitions-preservesPartitioning
Merge pull request #2 from colorant/yarn-client-2.2
Merge pull request #203 from witgo/master
Merge pull request #204 from rxin/hash
Merge pull request #205 from kayousterhout/logging
Merge pull request #206 from ash211/patch-2
Merge pull request #207 from henrydavidge/master
Merge pull request #209 from pwendell/better-docs
Merge pull request #210 from haitaoyao/http-timeout
Merge pull request #212 from markhamstra/SPARK-963
Merge pull request #216 from liancheng/fix-spark-966
Merge pull request #217 from aarondav/mesos-urls
Merge pull request #22 from GraceH/metrics-naming
Merge pull request #220 from rxin/zippart
Merge pull request #225 from ash211/patch-3
Merge pull request #226 from ash211/patch-4
Merge pull request #233 from hsaputra/changecontexttobackend
Merge pull request #239 from aarondav/nit
Merge pull request #242 from pwendell/master
Merge pull request #3 from aarondav/pv-test
Merge pull request #36 from pwendell/versions
Merge pull request #37 from pwendell/merge-0.8
Merge pull request #39 from pwendell/master
Merge pull request #45 from pwendell/metrics_units
Merge pull request #56 from jerryshao/kafka-0.8-dev
Merge pull request #64 from prabeesh/master
Merge pull request #66 from shivaram/sbt-assembly-deps
Merge pull request #670 from jey/ec2-ssh-improvements
Merge pull request #71 from aarondav/scdefaults
Merge pull request #78 from mosharaf/master
Merge pull request #8 from vchekan/checkpoint-ttl-restore
Merge pull request #80 from rxin/build
Merge pull request #82 from JoshRosen/map-output-tracker-refactoring
Merge pull request #86 from holdenk/master
Merge pull request #938 from ilikerps/master
Merge pull request #940 from ankurdave/clear-port-properties-after-tests
Merge pull request #98 from aarondav/docs
Merge pull request #99 from pwendell/master

*Branch-0.8 Only*
Merge pull request #138 from marmbrus/branch-0.8
Merge pull request #140 from aarondav/merge-75
Merge pull request #231 from pwendell/branch-0.8
Merge pull request #241 from pwendell/branch-0.8
Merge pull request #241 from pwendell/master
Merge pull request #243 from pwendell/branch-0.8
Merge pull request #40 from pwendell/branch-0.8
Merge pull request #47 from xiliu82/branch-0.8
Merge pull request #79 from aarondav/scdefaults0.8
Merge pull request #801 from pwendell/print-launch-command
Merge pull request #918 from pwendell/branch-0.8
Revert "Merge pull request #94 from aarondav/mesos-fix"




On Sat, Dec 7, 2013 at 5:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> Not sure.  I haven't been able to discern any pattern as to what new code
> goes into both 0.9 and 0.8 vs. what goes only into 0.8, so I can't really
> tell whether 0.8.1 is done or if something has been overlooked and not
> cherry-picked from master.
>
>
> On Sat, Dec 7, 2013 at 3:24 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Please vote on releasing the following candidate as Apache Spark
> > (incubating) version 0.8.1.
> >
> > The tag to be voted on is v0.8.1-incubating (commit fba8738):
> >
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57
> >
> > The release files, including signatures, digests, etc can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
> > - or -
> >
> >
> https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-022/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/
> >
> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> >
> > The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
> > a majority of at least 3 +1 PPMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.incubator.apache.org/
> >
>

--047d7b5d58e476d7f004ed015096--

From dev-return-828-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 19:37:52 2013
Return-Path: <dev-return-828-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 67C5D10F89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 19:37:52 +0000 (UTC)
Received: (qmail 31424 invoked by uid 500); 8 Dec 2013 19:37:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31292 invoked by uid 500); 8 Dec 2013 19:37:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 31284 invoked by uid 99); 8 Dec 2013 19:37:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 19:37:51 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 19:37:45 +0000
Received: by mail-wg0-f48.google.com with SMTP id z12so2557856wgg.15
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 11:37:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=7ifb6bo0R9jua3COmki6hDz+QPOCyDREk/VAHNeFFd8=;
        b=HS7zBBkBF4cgybQzE83SIpGzv5H2H4ckoB6pv9oLJSlgJrD81OR0uI5WpggL0Wz7h7
         pUF+PW+9+tsXXjFpLkpaQcWsK9w2aRjSBQtyblvHSp/G6BdxNyeVZDXeg5FoZe0IYEsv
         P2R4kKA947Ag8HxWUU/JNPMYSykszu8kP02VEjkNBiqHOcnlKdltr5obaVPFSniGfSD+
         Q0jetYOueVO5xPfBthDTSdc2g4P1UTrGj+e6MWyB3Pgq2td1shEWU78QaIeEk2mPs9cC
         K2hyKJ+O81AY/PK8ARJ01pvRM8+EzxzOKku08Hbt2+aSWoEXx8PR9edPipdVVROTjW0j
         EfAw==
MIME-Version: 1.0
X-Received: by 10.194.23.201 with SMTP id o9mr2785388wjf.67.1386531445075;
 Sun, 08 Dec 2013 11:37:25 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sun, 8 Dec 2013 11:37:25 -0800 (PST)
Date: Sun, 8 Dec 2013 11:37:25 -0800
Message-ID: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
Subject: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

HI Spark devs,

I have modified the Subject to avoid polluting the VOTE thread since
it related to more info how and which commits merge back to 0.8.*
branch.
Please respond to the previous question to this thread.

Technically the CHANGES.txt [1] file should describe the changes in a
particular release and it is the main requirement needed to cut an ASF
release.


- Henry

[1] https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt

On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com> wrote:
> We can use git log to figure out which changes haven't made it into
> branch-0.8.  Here's a quick attempt, which only lists pull requests that
> were only merged into one of the branches.  For completeness, this could be
> extended to find commits that weren't part of a merge and are only present
> in one branch.
>
> *Script:*
>
> MASTER_BRANCH=origin/master
> RELEASE_BRANCH=origin/branch-0.8
>
> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f 2-
> -d ' ' | sort > master-prs
> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f 2-
> -d ' ' | sort > release-prs
>
> comm -23 master-prs release-prs > master-only
> comm -23 release-prs master-prs > release-only
>
>
> *Master Branch Only:*
> Merge pull request #1 from colorant/yarn-client-2.2
> Merge pull request #105 from pwendell/doc-fix
> Merge pull request #110 from pwendell/master
> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> Merge pull request #151 from russellcardullo/add-graphite-sink
> Merge pull request #154 from soulmachine/ClusterScheduler
> Merge pull request #156 from haoyuan/master
> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> Merge pull request #16 from pwendell/master
> Merge pull request #185 from mkolod/random-number-generator
> Merge pull request #187 from aarondav/example-bcast-test
> Merge pull request #190 from markhamstra/Stages4Jobs
> Merge pull request #198 from ankurdave/zipPartitions-preservesPartitioning
> Merge pull request #2 from colorant/yarn-client-2.2
> Merge pull request #203 from witgo/master
> Merge pull request #204 from rxin/hash
> Merge pull request #205 from kayousterhout/logging
> Merge pull request #206 from ash211/patch-2
> Merge pull request #207 from henrydavidge/master
> Merge pull request #209 from pwendell/better-docs
> Merge pull request #210 from haitaoyao/http-timeout
> Merge pull request #212 from markhamstra/SPARK-963
> Merge pull request #216 from liancheng/fix-spark-966
> Merge pull request #217 from aarondav/mesos-urls
> Merge pull request #22 from GraceH/metrics-naming
> Merge pull request #220 from rxin/zippart
> Merge pull request #225 from ash211/patch-3
> Merge pull request #226 from ash211/patch-4
> Merge pull request #233 from hsaputra/changecontexttobackend
> Merge pull request #239 from aarondav/nit
> Merge pull request #242 from pwendell/master
> Merge pull request #3 from aarondav/pv-test
> Merge pull request #36 from pwendell/versions
> Merge pull request #37 from pwendell/merge-0.8
> Merge pull request #39 from pwendell/master
> Merge pull request #45 from pwendell/metrics_units
> Merge pull request #56 from jerryshao/kafka-0.8-dev
> Merge pull request #64 from prabeesh/master
> Merge pull request #66 from shivaram/sbt-assembly-deps
> Merge pull request #670 from jey/ec2-ssh-improvements
> Merge pull request #71 from aarondav/scdefaults
> Merge pull request #78 from mosharaf/master
> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> Merge pull request #80 from rxin/build
> Merge pull request #82 from JoshRosen/map-output-tracker-refactoring
> Merge pull request #86 from holdenk/master
> Merge pull request #938 from ilikerps/master
> Merge pull request #940 from ankurdave/clear-port-properties-after-tests
> Merge pull request #98 from aarondav/docs
> Merge pull request #99 from pwendell/master
>
> *Branch-0.8 Only*
> Merge pull request #138 from marmbrus/branch-0.8
> Merge pull request #140 from aarondav/merge-75
> Merge pull request #231 from pwendell/branch-0.8
> Merge pull request #241 from pwendell/branch-0.8
> Merge pull request #241 from pwendell/master
> Merge pull request #243 from pwendell/branch-0.8
> Merge pull request #40 from pwendell/branch-0.8
> Merge pull request #47 from xiliu82/branch-0.8
> Merge pull request #79 from aarondav/scdefaults0.8
> Merge pull request #801 from pwendell/print-launch-command
> Merge pull request #918 from pwendell/branch-0.8
> Revert "Merge pull request #94 from aarondav/mesos-fix"
>
>
>
>
> On Sat, Dec 7, 2013 at 5:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:
>
>> Not sure.  I haven't been able to discern any pattern as to what new code
>> goes into both 0.9 and 0.8 vs. what goes only into 0.8, so I can't really
>> tell whether 0.8.1 is done or if something has been overlooked and not
>> cherry-picked from master.
>>
>>
>> On Sat, Dec 7, 2013 at 3:24 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Please vote on releasing the following candidate as Apache Spark
>> > (incubating) version 0.8.1.
>> >
>> > The tag to be voted on is v0.8.1-incubating (commit fba8738):
>> >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57
>> >
>> > The release files, including signatures, digests, etc can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
>> > - or -
>> >
>> >
>> https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/
>> >
>> > Release artifacts are signed with the following key:
>> > https://people.apache.org/keys/committer/pwendell.asc
>> >
>> > The staging repository for this release can be found at:
>> > https://repository.apache.org/content/repositories/orgapachespark-022/
>> >
>> > The documentation corresponding to this release can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/
>> >
>> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>> >
>> > The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
>> > a majority of at least 3 +1 PPMC votes are cast.
>> >
>> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> > [ ] -1 Do not release this package because ...
>> >
>> > To learn more about Apache Spark, please see
>> > http://spark.incubator.apache.org/
>> >
>>

From dev-return-829-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 20:04:06 2013
Return-Path: <dev-return-829-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3420110FF6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 20:04:06 +0000 (UTC)
Received: (qmail 48580 invoked by uid 500); 8 Dec 2013 20:04:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48548 invoked by uid 500); 8 Dec 2013 20:04:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 48540 invoked by uid 99); 8 Dec 2013 20:04:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:04:06 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.44 as permitted sender)
Received: from [209.85.219.44] (HELO mail-oa0-f44.google.com) (209.85.219.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:04:00 +0000
Received: by mail-oa0-f44.google.com with SMTP id m1so2982694oag.17
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 12:03:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=hQDjdv2rVvVRqsvCLwXODWqSqUBQMVLJRaSMOlYjipI=;
        b=GoTCr1bTusl5j98yUPFI4m83+t2yH3Tof2QZGq4y9yqwFCuRG+R2wAh0JohGEZNpXd
         qp6a9iarJ9UuGKDLw/x8CK7C3wpBPVJAwAot68HxpplT/B9DkiCImWYJh19/jX5Docrn
         CgkyaPAaw5Ozf4yNDVtw8aOFWpNBKFheeEXQsi7NJBPQVi2JAXFqQ6NU64ro3BgsP++7
         IS/UNxJa8nGktUYdrSQxMU8nqvXrmZdc0BHRYbn2ZZDHy4P2YW0gl9aZtX4sdQxPHaK0
         SEoZBmEywQOOL3qjegazPOoEzFNL4gg9YAihDY1tIHZ/iDecKfzqwalWDCQlnul/XoyH
         M+Tw==
MIME-Version: 1.0
X-Received: by 10.60.51.161 with SMTP id l1mr322331oeo.69.1386533019406; Sun,
 08 Dec 2013 12:03:39 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 12:03:39 -0800 (PST)
In-Reply-To: <CAOEPXP5N2sZhH9hpHsEmSUcXZL_n9-iabX-9yraENSkfUV-pRA@mail.gmail.com>
References: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
	<CAAsvFP=bd=19OFvriXRGXQLrnwavETwDGcFWPHgOzu_gB59Q5A@mail.gmail.com>
	<CAOEPXP5N2sZhH9hpHsEmSUcXZL_n9-iabX-9yraENSkfUV-pRA@mail.gmail.com>
Date: Sun, 8 Dec 2013 12:03:39 -0800
Message-ID: <CABPQxsv4zjmQWbt7ra9Mc2YZ2ywpd0DZo_9qCEqmmCwQOvXQGg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Guys,

Matei found a few small doc fixes so I'm going to cut a new RC today.
I'll include the release credits and summary in that e-mail so people
know what they are voting in.

- Patrick

On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com> wrote:
> We can use git log to figure out which changes haven't made it into
> branch-0.8.  Here's a quick attempt, which only lists pull requests that
> were only merged into one of the branches.  For completeness, this could be
> extended to find commits that weren't part of a merge and are only present
> in one branch.
>
> *Script:*
>
> MASTER_BRANCH=origin/master
> RELEASE_BRANCH=origin/branch-0.8
>
> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f 2-
> -d ' ' | sort > master-prs
> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f 2-
> -d ' ' | sort > release-prs
>
> comm -23 master-prs release-prs > master-only
> comm -23 release-prs master-prs > release-only
>
>
> *Master Branch Only:*
> Merge pull request #1 from colorant/yarn-client-2.2
> Merge pull request #105 from pwendell/doc-fix
> Merge pull request #110 from pwendell/master
> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> Merge pull request #151 from russellcardullo/add-graphite-sink
> Merge pull request #154 from soulmachine/ClusterScheduler
> Merge pull request #156 from haoyuan/master
> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> Merge pull request #16 from pwendell/master
> Merge pull request #185 from mkolod/random-number-generator
> Merge pull request #187 from aarondav/example-bcast-test
> Merge pull request #190 from markhamstra/Stages4Jobs
> Merge pull request #198 from ankurdave/zipPartitions-preservesPartitioning
> Merge pull request #2 from colorant/yarn-client-2.2
> Merge pull request #203 from witgo/master
> Merge pull request #204 from rxin/hash
> Merge pull request #205 from kayousterhout/logging
> Merge pull request #206 from ash211/patch-2
> Merge pull request #207 from henrydavidge/master
> Merge pull request #209 from pwendell/better-docs
> Merge pull request #210 from haitaoyao/http-timeout
> Merge pull request #212 from markhamstra/SPARK-963
> Merge pull request #216 from liancheng/fix-spark-966
> Merge pull request #217 from aarondav/mesos-urls
> Merge pull request #22 from GraceH/metrics-naming
> Merge pull request #220 from rxin/zippart
> Merge pull request #225 from ash211/patch-3
> Merge pull request #226 from ash211/patch-4
> Merge pull request #233 from hsaputra/changecontexttobackend
> Merge pull request #239 from aarondav/nit
> Merge pull request #242 from pwendell/master
> Merge pull request #3 from aarondav/pv-test
> Merge pull request #36 from pwendell/versions
> Merge pull request #37 from pwendell/merge-0.8
> Merge pull request #39 from pwendell/master
> Merge pull request #45 from pwendell/metrics_units
> Merge pull request #56 from jerryshao/kafka-0.8-dev
> Merge pull request #64 from prabeesh/master
> Merge pull request #66 from shivaram/sbt-assembly-deps
> Merge pull request #670 from jey/ec2-ssh-improvements
> Merge pull request #71 from aarondav/scdefaults
> Merge pull request #78 from mosharaf/master
> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> Merge pull request #80 from rxin/build
> Merge pull request #82 from JoshRosen/map-output-tracker-refactoring
> Merge pull request #86 from holdenk/master
> Merge pull request #938 from ilikerps/master
> Merge pull request #940 from ankurdave/clear-port-properties-after-tests
> Merge pull request #98 from aarondav/docs
> Merge pull request #99 from pwendell/master
>
> *Branch-0.8 Only*
> Merge pull request #138 from marmbrus/branch-0.8
> Merge pull request #140 from aarondav/merge-75
> Merge pull request #231 from pwendell/branch-0.8
> Merge pull request #241 from pwendell/branch-0.8
> Merge pull request #241 from pwendell/master
> Merge pull request #243 from pwendell/branch-0.8
> Merge pull request #40 from pwendell/branch-0.8
> Merge pull request #47 from xiliu82/branch-0.8
> Merge pull request #79 from aarondav/scdefaults0.8
> Merge pull request #801 from pwendell/print-launch-command
> Merge pull request #918 from pwendell/branch-0.8
> Revert "Merge pull request #94 from aarondav/mesos-fix"
>
>
>
>
> On Sat, Dec 7, 2013 at 5:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:
>
>> Not sure.  I haven't been able to discern any pattern as to what new code
>> goes into both 0.9 and 0.8 vs. what goes only into 0.8, so I can't really
>> tell whether 0.8.1 is done or if something has been overlooked and not
>> cherry-picked from master.
>>
>>
>> On Sat, Dec 7, 2013 at 3:24 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Please vote on releasing the following candidate as Apache Spark
>> > (incubating) version 0.8.1.
>> >
>> > The tag to be voted on is v0.8.1-incubating (commit fba8738):
>> >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57
>> >
>> > The release files, including signatures, digests, etc can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
>> > - or -
>> >
>> >
>> https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/
>> >
>> > Release artifacts are signed with the following key:
>> > https://people.apache.org/keys/committer/pwendell.asc
>> >
>> > The staging repository for this release can be found at:
>> > https://repository.apache.org/content/repositories/orgapachespark-022/
>> >
>> > The documentation corresponding to this release can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/
>> >
>> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>> >
>> > The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
>> > a majority of at least 3 +1 PPMC votes are cast.
>> >
>> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> > [ ] -1 Do not release this package because ...
>> >
>> > To learn more about Apache Spark, please see
>> > http://spark.incubator.apache.org/
>> >
>>

From dev-return-830-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 20:05:03 2013
Return-Path: <dev-return-830-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ECC2010FFB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 20:05:03 +0000 (UTC)
Received: (qmail 49172 invoked by uid 500); 8 Dec 2013 20:05:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49136 invoked by uid 500); 8 Dec 2013 20:05:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 49127 invoked by uid 99); 8 Dec 2013 20:05:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:05:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:04:58 +0000
Received: by mail-ob0-f181.google.com with SMTP id uy5so2879997obc.40
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 12:04:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=KupuYsegFsED2dja866bixjEHnleJ4Uxy6iL/5FGW4k=;
        b=FRpVzAHnCDNoi+mcpcqXGmaksRYj72tKvVi8dtLUVIYWRmS9CEpyusHsg6VYtalN3f
         LhE8LawmjsXL2XKXRuUk65i+dlLHKcDg5DRnafQraSd0fSTmThLQwH64UJ6sZ4K/4zPM
         YW2A7u7dfeCp/QkggGtAWvAXcR+mrekckvAHtpoGlYAfPiLFLr+D/C+h4b3XEIYteHJQ
         NclL73UjhwVZYCHhQzlzR4WlfML5XQ2ikhSUL9I26VGQaZVD+seH66tLm28KslIljKIU
         P9fBaRyKH8kGzmgMcG8gV6YkfA1Gk73oMlJGj4BjibCtabkiZlbtu78+H6IXbGMC64YP
         J/QQ==
MIME-Version: 1.0
X-Received: by 10.182.29.66 with SMTP id i2mr10437889obh.23.1386533077343;
 Sun, 08 Dec 2013 12:04:37 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 12:04:37 -0800 (PST)
In-Reply-To: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
Date: Sun, 8 Dec 2013 12:04:37 -0800
Message-ID: <CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Henry,

Are you suggesting we need to change something about or changes file?
Or are you just pointing people to the file?

- Patrick

On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <henry.saputra@gmail.com> wrote:
> HI Spark devs,
>
> I have modified the Subject to avoid polluting the VOTE thread since
> it related to more info how and which commits merge back to 0.8.*
> branch.
> Please respond to the previous question to this thread.
>
> Technically the CHANGES.txt [1] file should describe the changes in a
> particular release and it is the main requirement needed to cut an ASF
> release.
>
>
> - Henry
>
> [1] https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>
> On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com> wrote:
>> We can use git log to figure out which changes haven't made it into
>> branch-0.8.  Here's a quick attempt, which only lists pull requests that
>> were only merged into one of the branches.  For completeness, this could be
>> extended to find commits that weren't part of a merge and are only present
>> in one branch.
>>
>> *Script:*
>>
>> MASTER_BRANCH=origin/master
>> RELEASE_BRANCH=origin/branch-0.8
>>
>> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f 2-
>> -d ' ' | sort > master-prs
>> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f 2-
>> -d ' ' | sort > release-prs
>>
>> comm -23 master-prs release-prs > master-only
>> comm -23 release-prs master-prs > release-only
>>
>>
>> *Master Branch Only:*
>> Merge pull request #1 from colorant/yarn-client-2.2
>> Merge pull request #105 from pwendell/doc-fix
>> Merge pull request #110 from pwendell/master
>> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
>> Merge pull request #151 from russellcardullo/add-graphite-sink
>> Merge pull request #154 from soulmachine/ClusterScheduler
>> Merge pull request #156 from haoyuan/master
>> Merge pull request #159 from liancheng/dagscheduler-actor-refine
>> Merge pull request #16 from pwendell/master
>> Merge pull request #185 from mkolod/random-number-generator
>> Merge pull request #187 from aarondav/example-bcast-test
>> Merge pull request #190 from markhamstra/Stages4Jobs
>> Merge pull request #198 from ankurdave/zipPartitions-preservesPartitioning
>> Merge pull request #2 from colorant/yarn-client-2.2
>> Merge pull request #203 from witgo/master
>> Merge pull request #204 from rxin/hash
>> Merge pull request #205 from kayousterhout/logging
>> Merge pull request #206 from ash211/patch-2
>> Merge pull request #207 from henrydavidge/master
>> Merge pull request #209 from pwendell/better-docs
>> Merge pull request #210 from haitaoyao/http-timeout
>> Merge pull request #212 from markhamstra/SPARK-963
>> Merge pull request #216 from liancheng/fix-spark-966
>> Merge pull request #217 from aarondav/mesos-urls
>> Merge pull request #22 from GraceH/metrics-naming
>> Merge pull request #220 from rxin/zippart
>> Merge pull request #225 from ash211/patch-3
>> Merge pull request #226 from ash211/patch-4
>> Merge pull request #233 from hsaputra/changecontexttobackend
>> Merge pull request #239 from aarondav/nit
>> Merge pull request #242 from pwendell/master
>> Merge pull request #3 from aarondav/pv-test
>> Merge pull request #36 from pwendell/versions
>> Merge pull request #37 from pwendell/merge-0.8
>> Merge pull request #39 from pwendell/master
>> Merge pull request #45 from pwendell/metrics_units
>> Merge pull request #56 from jerryshao/kafka-0.8-dev
>> Merge pull request #64 from prabeesh/master
>> Merge pull request #66 from shivaram/sbt-assembly-deps
>> Merge pull request #670 from jey/ec2-ssh-improvements
>> Merge pull request #71 from aarondav/scdefaults
>> Merge pull request #78 from mosharaf/master
>> Merge pull request #8 from vchekan/checkpoint-ttl-restore
>> Merge pull request #80 from rxin/build
>> Merge pull request #82 from JoshRosen/map-output-tracker-refactoring
>> Merge pull request #86 from holdenk/master
>> Merge pull request #938 from ilikerps/master
>> Merge pull request #940 from ankurdave/clear-port-properties-after-tests
>> Merge pull request #98 from aarondav/docs
>> Merge pull request #99 from pwendell/master
>>
>> *Branch-0.8 Only*
>> Merge pull request #138 from marmbrus/branch-0.8
>> Merge pull request #140 from aarondav/merge-75
>> Merge pull request #231 from pwendell/branch-0.8
>> Merge pull request #241 from pwendell/branch-0.8
>> Merge pull request #241 from pwendell/master
>> Merge pull request #243 from pwendell/branch-0.8
>> Merge pull request #40 from pwendell/branch-0.8
>> Merge pull request #47 from xiliu82/branch-0.8
>> Merge pull request #79 from aarondav/scdefaults0.8
>> Merge pull request #801 from pwendell/print-launch-command
>> Merge pull request #918 from pwendell/branch-0.8
>> Revert "Merge pull request #94 from aarondav/mesos-fix"
>>
>>
>>
>>
>> On Sat, Dec 7, 2013 at 5:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:
>>
>>> Not sure.  I haven't been able to discern any pattern as to what new code
>>> goes into both 0.9 and 0.8 vs. what goes only into 0.8, so I can't really
>>> tell whether 0.8.1 is done or if something has been overlooked and not
>>> cherry-picked from master.
>>>
>>>
>>> On Sat, Dec 7, 2013 at 3:24 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>> > Please vote on releasing the following candidate as Apache Spark
>>> > (incubating) version 0.8.1.
>>> >
>>> > The tag to be voted on is v0.8.1-incubating (commit fba8738):
>>> >
>>> >
>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=720e75581ae5f0c4835513ee06bfa0cb71923c57
>>> >
>>> > The release files, including signatures, digests, etc can be found at:
>>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1/
>>> > - or -
>>> >
>>> >
>>> https://dist.apache.org/repos/dist/dev/incubator/spark/spark-0.8.1-incubating-rc1/
>>> >
>>> > Release artifacts are signed with the following key:
>>> > https://people.apache.org/keys/committer/pwendell.asc
>>> >
>>> > The staging repository for this release can be found at:
>>> > https://repository.apache.org/content/repositories/orgapachespark-022/
>>> >
>>> > The documentation corresponding to this release can be found at:
>>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc1-docs/
>>> >
>>> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>>> >
>>> > The vote is open until Tuesday, December 9th at 21:30 UTC and passes if
>>> > a majority of at least 3 +1 PPMC votes are cast.
>>> >
>>> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>> > [ ] -1 Do not release this package because ...
>>> >
>>> > To learn more about Apache Spark, please see
>>> > http://spark.incubator.apache.org/
>>> >
>>>

From dev-return-831-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 20:37:27 2013
Return-Path: <dev-return-831-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D441D100CD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 20:37:27 +0000 (UTC)
Received: (qmail 67797 invoked by uid 500); 8 Dec 2013 20:37:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67761 invoked by uid 500); 8 Dec 2013 20:37:27 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 67753 invoked by uid 99); 8 Dec 2013 20:37:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:37:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of henry.saputra@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:37:21 +0000
Received: by mail-wi0-f173.google.com with SMTP id hn9so2923713wib.12
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 12:37:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=MYYTKDiEPxJp4GRn3GwRopWjQuFmr/RxGO5cobuHd3A=;
        b=NfZvJ4e03YZobTnOSYNwU37L5ww33rsP8shX/IWUQfAFXNXT70UYJ/IYfTIRSffOoQ
         Um6QDHidANRhkjL5IOWieSk1Lagl1hruAuySD4PcjNHDW4C/db1ksszUMenSbPlYgdpn
         IeMEEcxUcBx1oAjHT+m/cr6zF+ggmIPj0uI2XGeP/hxuYnYqQijRVqbKGuJRrQj95PK9
         rMcE7Th7qKhNvKcBEEMvpFEKzQ9QoR0T+iSLh5tq6aLhbWH700ZXDW2yWIMzpX5Nuu8z
         MeUQ2ggDuZVOEjzgh5LaZiw6FL03Al1deVnqP4a2LTgbw1L0IIpwigKXYRDx1LC2TN2y
         1Kqw==
MIME-Version: 1.0
X-Received: by 10.180.19.201 with SMTP id h9mr10852386wie.36.1386535020943;
 Sun, 08 Dec 2013 12:37:00 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sun, 8 Dec 2013 12:37:00 -0800 (PST)
In-Reply-To: <CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
	<CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 12:37:00 -0800
Message-ID: <CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=bcaec53f37e3645f8d04ed0bd72d
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f37e3645f8d04ed0bd72d
Content-Type: text/plain; charset=UTF-8

Ah, sorry for the confusion Patrick, like you said I was just trying to let
people aware about this file and the purpose of it.

On Sunday, December 8, 2013, Patrick Wendell wrote:

> Hey Henry,
>
> Are you suggesting we need to change something about or changes file?
> Or are you just pointing people to the file?
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <henry.saputra@gmail.com>
> wrote:
> > HI Spark devs,
> >
> > I have modified the Subject to avoid polluting the VOTE thread since
> > it related to more info how and which commits merge back to 0.8.*
> > branch.
> > Please respond to the previous question to this thread.
> >
> > Technically the CHANGES.txt [1] file should describe the changes in a
> > particular release and it is the main requirement needed to cut an ASF
> > release.
> >
> >
> > - Henry
> >
> > [1]
> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >
> > On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com>
> wrote:
> >> We can use git log to figure out which changes haven't made it into
> >> branch-0.8.  Here's a quick attempt, which only lists pull requests that
> >> were only merged into one of the branches.  For completeness, this
> could be
> >> extended to find commits that weren't part of a merge and are only
> present
> >> in one branch.
> >>
> >> *Script:*
> >>
> >> MASTER_BRANCH=origin/master
> >> RELEASE_BRANCH=origin/branch-0.8
> >>
> >> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f
> 2-
> >> -d ' ' | sort > master-prs
> >> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f
> 2-
> >> -d ' ' | sort > release-prs
> >>
> >> comm -23 master-prs release-prs > master-only
> >> comm -23 release-prs master-prs > release-only
> >>
> >>
> >> *Master Branch Only:*
> >> Merge pull request #1 from colorant/yarn-client-2.2
> >> Merge pull request #105 from pwendell/doc-fix
> >> Merge pull request #110 from pwendell/master
> >> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> >> Merge pull request #151 from russellcardullo/add-graphite-sink
> >> Merge pull request #154 from soulmachine/ClusterScheduler
> >> Merge pull request #156 from haoyuan/master
> >> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> >> Merge pull request #16 from pwendell/master
> >> Merge pull request #185 from mkolod/random-number-generator
> >> Merge pull request #187 from aarondav/example-bcast-test
> >> Merge pull request #190 from markhamstra/Stages4Jobs
> >> Merge pull request #198 from
> ankurdave/zipPartitions-preservesPartitioning
> >> Merge pull request #2 from colorant/yarn-client-2.2
> >> Merge pull request #203 from witgo/master
> >> Merge pull request #204 from rxin/hash
> >> Merge pull request #205 from kayousterhout/logging
> >> Merge pull request #206 from ash211/patch-2
> >> Merge pull request #207 from henrydavidge/master
> >> Merge pull request #209 from pwendell/better-docs
> >> Merge pull request #210 from haitaoyao/http-timeout
> >> Merge pull request #212 from markhamstra/SPARK-963
> >> Merge pull request #216 from liancheng/fix-spark-966
> >> Merge pull request #217 from aarondav/mesos-urls
> >> Merge pull request #22 from GraceH/metrics-naming
> >> Merge pull request #220 from rxin/zippart
> >> Merge pull request #225 from ash211/patch-3
> >> Merge pull request #226 from ash211/patch-4
> >> Merge pull request #233 from hsaputra/changecontexttobackend
> >> Merge pull request #239 from aarondav/nit
> >> Merge pull request #242 from pwendell/master
> >> Merge pull request #3 from aarondav/pv-test
> >> Merge pull request #36 from pwendell/versions
> >> Merge pull request #37 from pwendell/merge-0.8
> >> Merge pull request #39 from pwendell/master
> >> Merge pull request #45 from pwendell/metrics_units
> >> Merge pull request #56 from jerryshao/kafka-0.8-dev
> >> Merge pull request #64 from prabeesh/master
> >> Merge pull request #66 from shivaram/sbt-assembly-deps
> >> Merge pull request #670 from jey/ec2-ssh-improvements
> >> Merge pull request #71 from aarondav/scdefaults
> >> Merge pull request #78 from mosharaf/master
> >> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> >> Merge pull request #80 from rxin/build
> >> Merge pull request #82 from JoshRosen/map-output-t

--bcaec53f37e3645f8d04ed0bd72d--

From dev-return-832-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 20:41:49 2013
Return-Path: <dev-return-832-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 365B2100DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 20:41:49 +0000 (UTC)
Received: (qmail 69479 invoked by uid 500); 8 Dec 2013 20:41:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69438 invoked by uid 500); 8 Dec 2013 20:41:49 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 69430 invoked by uid 99); 8 Dec 2013 20:41:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:41:49 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:41:44 +0000
Received: by mail-oa0-f47.google.com with SMTP id k1so2982088oag.20
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 12:41:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=FHcQrAR2kJso+YIro1CiGMyXNun1qNWLUdF0JKnwEls=;
        b=XUGwxOQGoPj+9SiSvw/rAEiv5BBLsR3KYspovkxwSHS2TxSa7WF/1ApYBdlCwzSQJl
         diU/wtxgfK3Q1nNQFEp7rzPbFaP2vZ1mi2Mo6c7V+Yv0ORz7tSLp8BXlHL1+FkVIrBzA
         LekPqrotDCKsZ2Cw/SDV3178otLJhSyZaLYA4z0hjVO0V3WV7V93mYuOOBd2Bskr744z
         8ZijuTftTOfjFcdUYMtTWOg37sMHc5Gv+KW8RF9C8muIPb3A0+D37P9ek1z1mZDOZhZX
         t6auwbqfYLlIyTtQG9CWyi+ZtuWGx31nn9AXvmZeVMrxPnjktNb8zkLjfXv2a36UVsUv
         GY+g==
MIME-Version: 1.0
X-Received: by 10.60.51.102 with SMTP id j6mr10213204oeo.6.1386535283959; Sun,
 08 Dec 2013 12:41:23 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 12:41:23 -0800 (PST)
Date: Sun, 8 Dec 2013 12:41:23 -0800
Message-ID: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/mixed; boundary=001a11c30a681222e204ed0be7bf
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c30a681222e204ed0be7bf
Content-Type: text/plain; charset=ISO-8859-1

Please vote on releasing the following candidate as Apache Spark
(incubating) version 0.8.1.

The tag to be voted on is v0.8.1-incubating (commit bf23794a):
https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203

The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-024/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/

For information about the contents of this release see:
<attached> draft of release notes
<attached> draft of release credits
https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt

Please vote on releasing this package as Apache Spark 0.8.1-incubating!

The vote is open until Wednesday, December 11th at 21:00 UTC and
passes if a majority of at least 3 +1 PPMC votes are cast.

[ ] +1 Release this package as Apache Spark 0.8.1-incubating
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.incubator.apache.org/

--001a11c30a681222e204ed0be7bf
Content-Type: text/plain; charset=UTF-8; name="0.8.1-credits.txt"
Content-Disposition: attachment; filename="0.8.1-credits.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hoyqps5z0
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--001a11c30a681222e204ed0be7bf
Content-Type: text/plain; charset=UTF-8; name="0.8.1-notes.txt"
Content-Disposition: attachment; filename="0.8.1-notes.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hoyr9bfi1
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--001a11c30a681222e204ed0be7bf--

From dev-return-833-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 20:48:03 2013
Return-Path: <dev-return-833-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 883D510109
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 20:48:03 +0000 (UTC)
Received: (qmail 72011 invoked by uid 500); 8 Dec 2013 20:48:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71946 invoked by uid 500); 8 Dec 2013 20:48:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 71938 invoked by uid 99); 8 Dec 2013 20:48:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:48:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.42 as permitted sender)
Received: from [209.85.219.42] (HELO mail-oa0-f42.google.com) (209.85.219.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 20:47:58 +0000
Received: by mail-oa0-f42.google.com with SMTP id i4so3003234oah.15
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 12:47:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=D/OZkD0vDGG31pvzsWTPkfbjdxiI0ZK0YGZIbahnkkY=;
        b=LpOOXuEOEhbF1y6DWqpvPrgTYDBcGd0vYedWS/rdr630NZ8VZ4yOGCwBNUsvUnYdAt
         DAjLRoR1Tcj24e/mu4J/slSO/55QsHyek3e+3etYThcpdzmmsVYp6gNWVdlApNG5nTaw
         hTRj8TfNMD3+CNCOR29cWnvbHsai9MDLryyq8W2CNc8IA+DgMsNpHalQCbMH4tTcAJ/o
         8SVMZ5j2WP7f9kLF0ugkm2gVlHRrRC4gqpEIVKobFTAkQCCGBUC0hi/xpZgMj3zsragC
         EELu1fPuLruMIYBRy/IJK7o/DGTGJd0PZt8/AYzadYu3g0YO0hJg4x3Gjs0HltTf8IAJ
         enUQ==
MIME-Version: 1.0
X-Received: by 10.182.92.231 with SMTP id cp7mr130876obb.82.1386535657401;
 Sun, 08 Dec 2013 12:47:37 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 12:47:37 -0800 (PST)
In-Reply-To: <CABPQxsv4zjmQWbt7ra9Mc2YZ2ywpd0DZo_9qCEqmmCwQOvXQGg@mail.gmail.com>
References: <CABPQxssDN2UqxCeVutoOiGkub=O5fh-7tV=oo+GpoVHqzXANyg@mail.gmail.com>
	<CAAsvFP=bd=19OFvriXRGXQLrnwavETwDGcFWPHgOzu_gB59Q5A@mail.gmail.com>
	<CAOEPXP5N2sZhH9hpHsEmSUcXZL_n9-iabX-9yraENSkfUV-pRA@mail.gmail.com>
	<CABPQxsv4zjmQWbt7ra9Mc2YZ2ywpd0DZo_9qCEqmmCwQOvXQGg@mail.gmail.com>
Date: Sun, 8 Dec 2013 12:47:37 -0800
Message-ID: <CABPQxsvsyic_q15qF=p8AdOaptkuhqRPHX=P8qzhbhU6NF3g6A@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'm cancelling this vote in favor of a vote on rc2. rc2 includes some
documentation clean-up and changes on top of rc1.

I also added (in that thread) more color on the general contents of
this release. 0.8.1 is a maintenance release, but because the
0.8-branch will be the last branch to support scala 2.9, we've elected
to add some larger features and optimizations that otherwise might not
have made the cut. The larger changes (H/A mode for the scheduler and
shuffle file consolidation) are not enabled by default to avoid major
changes for people upgrading from 0.8.0.

- Patrick

From dev-return-834-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 21:31:12 2013
Return-Path: <dev-return-834-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BD5F91020F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 21:31:12 +0000 (UTC)
Received: (qmail 2260 invoked by uid 500); 8 Dec 2013 21:31:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2220 invoked by uid 500); 8 Dec 2013 21:31:12 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 2212 invoked by uid 99); 8 Dec 2013 21:31:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 21:31:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.42] (HELO mail-bk0-f42.google.com) (209.85.214.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 21:31:08 +0000
Received: by mail-bk0-f42.google.com with SMTP id w11so1075861bkz.15
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 13:30:46 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=1e+9uC51Ze0iBZaSMYb8uIGnDfwpaJ28shrfXAWj+/I=;
        b=Hexf+64Le+l+iwAFpk2RTsimQ+HHXqIrnhFoX/H3kRkPS0RGdMrA69CVML93Tw5Z7D
         3wccM/3Ju2M37c2z8CJABSwyWiOtOzRcpW3cgFuT4IHJl4AjhYdkeGtahj6Jp4XXHqW1
         NjmrK+kKAgC+pdvlxR/SlAWCYx5DdpqKdVTyPKokiCqU/3g6YTg8K0Bc5GrHgG+tgui0
         z786e/JG0vO8RnZGY3FtD+4+GcbrmL7x7sspCJKPtQfTjgWQXvOO1mm2p/bH9fO4h9Eo
         1MwvcL4moA0iOpkbDM3aT/5axpauwHs4TGXqxdr0cbczY147La8lpYV30NXrKAGIwPwX
         OZnA==
X-Gm-Message-State: ALoCoQnnfvhSwBURUSRcjHYxpkVpZaC9Z5RQdaxaktgoEMhWk92411YwFwEcNgoircVZ2C0GYIR9
MIME-Version: 1.0
X-Received: by 10.204.176.199 with SMTP id bf7mr1253675bkb.105.1386538246035;
 Sun, 08 Dec 2013 13:30:46 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 13:30:45 -0800 (PST)
In-Reply-To: <CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
	<CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
	<CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
Date: Sun, 8 Dec 2013 13:30:45 -0800
Message-ID: <CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11332a389fc2dd04ed0c97f5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11332a389fc2dd04ed0c97f5
Content-Type: text/plain; charset=ISO-8859-1

I'm aware of the changes file, but it really doesn't address the issue that
I am raising.  The changes file just tells me what has gone into the
release candidate.  In general, it doesn't tell me why those changes went
in or provide any rationale by which to judge whether that is the complete
set of changes that should go in.

I talked some with Matei about related versioning and release issues last
week, and I've raised them in other contexts previously, but I'm taking the
liberty to annoy people again because I really am not happy with our
current versioning and release process, and I really am of the opinion that
we've got to start doing much better before I can vote in favor of a 1.0
release.  I fully realize that this is not a 1.0 release, and that because
we are pre-1.0 we still have a lot of flexibility with releases that break
backward or forward compatibility and with version numbers that have
nothing like the semantic meaning that they will eventually need to have;
but it is not going to be easy to change our process and culture so that we
produce the kind of stability and reliability that Spark users need to be
able to depend upon and version numbers that clearly communicate what those
users expect them to mean.  I think that we should start making those
changes now.  Just because we have flexibility pre-1.0, that doesn't mean
that we shouldn't start training ourselves now to work within the
constraints of post-1.0 Spark.  If I'm to be happy voting for an eventual
1.0 release candidate, I'll need to have seen at least one full development
cycle that already adheres to the post-1.0 constraints, demonstrating the
maturity of our development process.

That demonstration cycle is clearly not this one -- and I understand that
there were some compelling reasons (particularly with regard too getting a
"full" release of Spark based on Scala 2.9.3 before we make the jump to
2.10.  This "patch-level" release breaks binary compatibility and contains
a lot of code that isn't anywhere close to meeting the criterion for
inclusion in a real, post-1.0 patch-level release: essentially "changes
that every, or nearly every, existing Spark user needs (not just wants),
and that work with all existing and future binaries built with the prior
patch-level version of Spark as a dependency."  Like I said, we are clearly
nowhere close to that with the move from 0.8.0 to 0.8.1; but I also haven't
been able to recognize any alternative criterion by which to judge the
quality and completeness of this release candidate.

Maybe there just isn't one, and I'm just going to have to swallow my
concerns while watching 0.8.1 go out the door; but if we don't start doing
better on this kind of thing in the future, you are going to start hearing
more complaining from me. I just hope that it doesn't get to the point
where I feel compelled to actively oppose an eventual 1.0 release
candidate.


On Sun, Dec 8, 2013 at 12:37 PM, Henry Saputra <henry.saputra@gmail.com>wrote:

> Ah, sorry for the confusion Patrick, like you said I was just trying to let
> people aware about this file and the purpose of it.
>
> On Sunday, December 8, 2013, Patrick Wendell wrote:
>
> > Hey Henry,
> >
> > Are you suggesting we need to change something about or changes file?
> > Or are you just pointing people to the file?
> >
> > - Patrick
> >
> > On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <henry.saputra@gmail.com>
> > wrote:
> > > HI Spark devs,
> > >
> > > I have modified the Subject to avoid polluting the VOTE thread since
> > > it related to more info how and which commits merge back to 0.8.*
> > > branch.
> > > Please respond to the previous question to this thread.
> > >
> > > Technically the CHANGES.txt [1] file should describe the changes in a
> > > particular release and it is the main requirement needed to cut an ASF
> > > release.
> > >
> > >
> > > - Henry
> > >
> > > [1]
> > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> > >
> > > On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com>
> > wrote:
> > >> We can use git log to figure out which changes haven't made it into
> > >> branch-0.8.  Here's a quick attempt, which only lists pull requests
> that
> > >> were only merged into one of the branches.  For completeness, this
> > could be
> > >> extended to find commits that weren't part of a merge and are only
> > present
> > >> in one branch.
> > >>
> > >> *Script:*
> > >>
> > >> MASTER_BRANCH=origin/master
> > >> RELEASE_BRANCH=origin/branch-0.8
> > >>
> > >> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f
> > 2-
> > >> -d ' ' | sort > master-prs
> > >> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f
> > 2-
> > >> -d ' ' | sort > release-prs
> > >>
> > >> comm -23 master-prs release-prs > master-only
> > >> comm -23 release-prs master-prs > release-only
> > >>
> > >>
> > >> *Master Branch Only:*
> > >> Merge pull request #1 from colorant/yarn-client-2.2
> > >> Merge pull request #105 from pwendell/doc-fix
> > >> Merge pull request #110 from pwendell/master
> > >> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> > >> Merge pull request #151 from russellcardullo/add-graphite-sink
> > >> Merge pull request #154 from soulmachine/ClusterScheduler
> > >> Merge pull request #156 from haoyuan/master
> > >> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> > >> Merge pull request #16 from pwendell/master
> > >> Merge pull request #185 from mkolod/random-number-generator
> > >> Merge pull request #187 from aarondav/example-bcast-test
> > >> Merge pull request #190 from markhamstra/Stages4Jobs
> > >> Merge pull request #198 from
> > ankurdave/zipPartitions-preservesPartitioning
> > >> Merge pull request #2 from colorant/yarn-client-2.2
> > >> Merge pull request #203 from witgo/master
> > >> Merge pull request #204 from rxin/hash
> > >> Merge pull request #205 from kayousterhout/logging
> > >> Merge pull request #206 from ash211/patch-2
> > >> Merge pull request #207 from henrydavidge/master
> > >> Merge pull request #209 from pwendell/better-docs
> > >> Merge pull request #210 from haitaoyao/http-timeout
> > >> Merge pull request #212 from markhamstra/SPARK-963
> > >> Merge pull request #216 from liancheng/fix-spark-966
> > >> Merge pull request #217 from aarondav/mesos-urls
> > >> Merge pull request #22 from GraceH/metrics-naming
> > >> Merge pull request #220 from rxin/zippart
> > >> Merge pull request #225 from ash211/patch-3
> > >> Merge pull request #226 from ash211/patch-4
> > >> Merge pull request #233 from hsaputra/changecontexttobackend
> > >> Merge pull request #239 from aarondav/nit
> > >> Merge pull request #242 from pwendell/master
> > >> Merge pull request #3 from aarondav/pv-test
> > >> Merge pull request #36 from pwendell/versions
> > >> Merge pull request #37 from pwendell/merge-0.8
> > >> Merge pull request #39 from pwendell/master
> > >> Merge pull request #45 from pwendell/metrics_units
> > >> Merge pull request #56 from jerryshao/kafka-0.8-dev
> > >> Merge pull request #64 from prabeesh/master
> > >> Merge pull request #66 from shivaram/sbt-assembly-deps
> > >> Merge pull request #670 from jey/ec2-ssh-improvements
> > >> Merge pull request #71 from aarondav/scdefaults
> > >> Merge pull request #78 from mosharaf/master
> > >> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> > >> Merge pull request #80 from rxin/build
> > >> Merge pull request #82 from JoshRosen/map-output-t
>

--001a11332a389fc2dd04ed0c97f5--

From dev-return-835-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 22:13:20 2013
Return-Path: <dev-return-835-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 60395103E0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 22:13:20 +0000 (UTC)
Received: (qmail 40191 invoked by uid 500); 8 Dec 2013 22:13:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40157 invoked by uid 500); 8 Dec 2013 22:13:20 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 40149 invoked by uid 99); 8 Dec 2013 22:13:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 22:13:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 22:13:16 +0000
Received: by mail-ob0-f175.google.com with SMTP id uz6so2940771obc.34
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 14:12:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=CsG7czr+fblq59+ro7IvW8vomkYiDPUR+jnJr8T36Lg=;
        b=HqSPHKA2hJ+KDGFThNPfMOcCxlGf1mPQRabDUdrQoThk0qKbsouEXguI0WZbt+FCU8
         TVMcLkKPg0j6X1llI1wHD5jUhxRnmntAd7hTRnQNCg0K2tKDAAwGjPIVrU/tOK/f9APU
         XvoFA3450w8EGYw356WwcCgIpUl2pxQg0OfG1GsQe1n2tppB8a12FBA/7E/5AFyyBIj3
         qwxRdb0G4HDcDa5vLj9dm/XiQvWBd8kKJAXjRzCTe8Ep7eHU/cML28GNTMY34a1/d0WC
         6sQEiamLQlgB2X/tyo3tRhU8lyIdOWRqi4O9H6j2oC77buFsegZzaHJYe4vDJADRuEqN
         3hug==
MIME-Version: 1.0
X-Received: by 10.182.18.102 with SMTP id v6mr540714obd.71.1386540775585; Sun,
 08 Dec 2013 14:12:55 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 14:12:55 -0800 (PST)
In-Reply-To: <CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
	<CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
	<CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
	<CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 14:12:55 -0800
Message-ID: <CABPQxstAuGjE_=gHf5=iUDBtYzDDKEw_=dKoiGHHc5tf8+UyKQ@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mark,

One constructive action you and other people can take to help us
assess the quality and completeness of this release is to download the
release, run the tests, run the release in your dev environment, read
through the documentation, etc. This is one of the main points of
releasing an RC to the community... even if you disagree with some
patches that were merged in, this is still a way you can help validate
the release.

- Patrick

On Sun, Dec 8, 2013 at 1:30 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> I'm aware of the changes file, but it really doesn't address the issue that
> I am raising.  The changes file just tells me what has gone into the
> release candidate.  In general, it doesn't tell me why those changes went
> in or provide any rationale by which to judge whether that is the complete
> set of changes that should go in.
>
> I talked some with Matei about related versioning and release issues last
> week, and I've raised them in other contexts previously, but I'm taking the
> liberty to annoy people again because I really am not happy with our
> current versioning and release process, and I really am of the opinion that
> we've got to start doing much better before I can vote in favor of a 1.0
> release.  I fully realize that this is not a 1.0 release, and that because
> we are pre-1.0 we still have a lot of flexibility with releases that break
> backward or forward compatibility and with version numbers that have
> nothing like the semantic meaning that they will eventually need to have;
> but it is not going to be easy to change our process and culture so that we
> produce the kind of stability and reliability that Spark users need to be
> able to depend upon and version numbers that clearly communicate what those
> users expect them to mean.  I think that we should start making those
> changes now.  Just because we have flexibility pre-1.0, that doesn't mean
> that we shouldn't start training ourselves now to work within the
> constraints of post-1.0 Spark.  If I'm to be happy voting for an eventual
> 1.0 release candidate, I'll need to have seen at least one full development
> cycle that already adheres to the post-1.0 constraints, demonstrating the
> maturity of our development process.
>
> That demonstration cycle is clearly not this one -- and I understand that
> there were some compelling reasons (particularly with regard too getting a
> "full" release of Spark based on Scala 2.9.3 before we make the jump to
> 2.10.  This "patch-level" release breaks binary compatibility and contains
> a lot of code that isn't anywhere close to meeting the criterion for
> inclusion in a real, post-1.0 patch-level release: essentially "changes
> that every, or nearly every, existing Spark user needs (not just wants),
> and that work with all existing and future binaries built with the prior
> patch-level version of Spark as a dependency."  Like I said, we are clearly
> nowhere close to that with the move from 0.8.0 to 0.8.1; but I also haven't
> been able to recognize any alternative criterion by which to judge the
> quality and completeness of this release candidate.
>
> Maybe there just isn't one, and I'm just going to have to swallow my
> concerns while watching 0.8.1 go out the door; but if we don't start doing
> better on this kind of thing in the future, you are going to start hearing
> more complaining from me. I just hope that it doesn't get to the point
> where I feel compelled to actively oppose an eventual 1.0 release
> candidate.
>
>
> On Sun, Dec 8, 2013 at 12:37 PM, Henry Saputra <henry.saputra@gmail.com>wrote:
>
>> Ah, sorry for the confusion Patrick, like you said I was just trying to let
>> people aware about this file and the purpose of it.
>>
>> On Sunday, December 8, 2013, Patrick Wendell wrote:
>>
>> > Hey Henry,
>> >
>> > Are you suggesting we need to change something about or changes file?
>> > Or are you just pointing people to the file?
>> >
>> > - Patrick
>> >
>> > On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <henry.saputra@gmail.com>
>> > wrote:
>> > > HI Spark devs,
>> > >
>> > > I have modified the Subject to avoid polluting the VOTE thread since
>> > > it related to more info how and which commits merge back to 0.8.*
>> > > branch.
>> > > Please respond to the previous question to this thread.
>> > >
>> > > Technically the CHANGES.txt [1] file should describe the changes in a
>> > > particular release and it is the main requirement needed to cut an ASF
>> > > release.
>> > >
>> > >
>> > > - Henry
>> > >
>> > > [1]
>> > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> > >
>> > > On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com>
>> > wrote:
>> > >> We can use git log to figure out which changes haven't made it into
>> > >> branch-0.8.  Here's a quick attempt, which only lists pull requests
>> that
>> > >> were only merged into one of the branches.  For completeness, this
>> > could be
>> > >> extended to find commits that weren't part of a merge and are only
>> > present
>> > >> in one branch.
>> > >>
>> > >> *Script:*
>> > >>
>> > >> MASTER_BRANCH=origin/master
>> > >> RELEASE_BRANCH=origin/branch-0.8
>> > >>
>> > >> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f
>> > 2-
>> > >> -d ' ' | sort > master-prs
>> > >> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f
>> > 2-
>> > >> -d ' ' | sort > release-prs
>> > >>
>> > >> comm -23 master-prs release-prs > master-only
>> > >> comm -23 release-prs master-prs > release-only
>> > >>
>> > >>
>> > >> *Master Branch Only:*
>> > >> Merge pull request #1 from colorant/yarn-client-2.2
>> > >> Merge pull request #105 from pwendell/doc-fix
>> > >> Merge pull request #110 from pwendell/master
>> > >> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
>> > >> Merge pull request #151 from russellcardullo/add-graphite-sink
>> > >> Merge pull request #154 from soulmachine/ClusterScheduler
>> > >> Merge pull request #156 from haoyuan/master
>> > >> Merge pull request #159 from liancheng/dagscheduler-actor-refine
>> > >> Merge pull request #16 from pwendell/master
>> > >> Merge pull request #185 from mkolod/random-number-generator
>> > >> Merge pull request #187 from aarondav/example-bcast-test
>> > >> Merge pull request #190 from markhamstra/Stages4Jobs
>> > >> Merge pull request #198 from
>> > ankurdave/zipPartitions-preservesPartitioning
>> > >> Merge pull request #2 from colorant/yarn-client-2.2
>> > >> Merge pull request #203 from witgo/master
>> > >> Merge pull request #204 from rxin/hash
>> > >> Merge pull request #205 from kayousterhout/logging
>> > >> Merge pull request #206 from ash211/patch-2
>> > >> Merge pull request #207 from henrydavidge/master
>> > >> Merge pull request #209 from pwendell/better-docs
>> > >> Merge pull request #210 from haitaoyao/http-timeout
>> > >> Merge pull request #212 from markhamstra/SPARK-963
>> > >> Merge pull request #216 from liancheng/fix-spark-966
>> > >> Merge pull request #217 from aarondav/mesos-urls
>> > >> Merge pull request #22 from GraceH/metrics-naming
>> > >> Merge pull request #220 from rxin/zippart
>> > >> Merge pull request #225 from ash211/patch-3
>> > >> Merge pull request #226 from ash211/patch-4
>> > >> Merge pull request #233 from hsaputra/changecontexttobackend
>> > >> Merge pull request #239 from aarondav/nit
>> > >> Merge pull request #242 from pwendell/master
>> > >> Merge pull request #3 from aarondav/pv-test
>> > >> Merge pull request #36 from pwendell/versions
>> > >> Merge pull request #37 from pwendell/merge-0.8
>> > >> Merge pull request #39 from pwendell/master
>> > >> Merge pull request #45 from pwendell/metrics_units
>> > >> Merge pull request #56 from jerryshao/kafka-0.8-dev
>> > >> Merge pull request #64 from prabeesh/master
>> > >> Merge pull request #66 from shivaram/sbt-assembly-deps
>> > >> Merge pull request #670 from jey/ec2-ssh-improvements
>> > >> Merge pull request #71 from aarondav/scdefaults
>> > >> Merge pull request #78 from mosharaf/master
>> > >> Merge pull request #8 from vchekan/checkpoint-ttl-restore
>> > >> Merge pull request #80 from rxin/build
>> > >> Merge pull request #82 from JoshRosen/map-output-t
>>

From dev-return-836-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec  8 22:45:57 2013
Return-Path: <dev-return-836-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 11FD110463
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Dec 2013 22:45:57 +0000 (UTC)
Received: (qmail 67428 invoked by uid 500); 8 Dec 2013 22:45:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67391 invoked by uid 500); 8 Dec 2013 22:45:56 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 67383 invoked by uid 99); 8 Dec 2013 22:45:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 22:45:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.51] (HELO mail-bk0-f51.google.com) (209.85.214.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Dec 2013 22:45:50 +0000
Received: by mail-bk0-f51.google.com with SMTP id 6so1084101bkj.38
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 14:45:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=gxJQIvHBE1w5Cvn9jWHC/msar72ypfYnjCMWfy30pdE=;
        b=Kp7IYRsFyh/X7Z3y6VToMCEFvuA2WmeUPbOdOHhlDsiNBZVHBs/tQjZI+FU7PERk0O
         RR2/kJZBwd/w3YjkVPhTLN2SDGGgRnX5rN31v+KrJlM/DJuIlYJa9HmQbl+kF71xQZTk
         USvLpGiGYYZlxgswjYGYFdOL7gh8MA4Thuu/X+xolbSXg1HjzITkc5vEuVIgc5hpj2zl
         DgUcjeZaMVpJ7nA0IgAuNNyRnujcSWTPvJ4b3blLNK4W9t0rlVB1wgK0O1dR2wfcaHVX
         /kC/T7AUzmepM4bDSIF9buo4XRXCKpiQt8/bcY6GarBt5KcjyCfdbVcxRj+IQHmUJS24
         fQRw==
X-Gm-Message-State: ALoCoQkZBVjn741OOK8woHzdbYO8Tlc4sNlQZb1tfx3OzIwx6mgrdw8DhZJZ+O22BT8cm1Ghu8pl
MIME-Version: 1.0
X-Received: by 10.205.65.81 with SMTP id xl17mr1256477bkb.66.1386542729576;
 Sun, 08 Dec 2013 14:45:29 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 14:45:29 -0800 (PST)
In-Reply-To: <CABPQxstAuGjE_=gHf5=iUDBtYzDDKEw_=dKoiGHHc5tf8+UyKQ@mail.gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
	<CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
	<CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
	<CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com>
	<CABPQxstAuGjE_=gHf5=iUDBtYzDDKEw_=dKoiGHHc5tf8+UyKQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 14:45:29 -0800
Message-ID: <CAAsvFPk-3x4kaXEq8Q6+rbnW2V119dUwWwZOErwbZDgQanHQqQ@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec53f2bbddd18de04ed0da2c3
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f2bbddd18de04ed0da2c3
Content-Type: text/plain; charset=ISO-8859-1

Yup, I'm already started on that process.

And it's not that I disagree with any particular change that was merged per
se -- I haven't seen anything merged that most users won't want.  It's more
that I object to the burden that our current development/versioning/release
process puts on Spark users responsible for production code.  For them,
adopting a new patch-level release should be a decision requiring almost no
thinking since the new release should be essentially just bug-fixes that
maintain full binary compatibility.  With our current process, those users
have to suck in a bunch of new, less-tested, less-mature code that may
comprise new features or functionality that the user doesn't want (at least
not right away in production), but that they can't cleanly separate from
the bug-fixes that they do want.  Our process simply has to change if we
place users' desires ahead of Spark developers' desires.


On Sun, Dec 8, 2013 at 2:12 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Mark,
>
> One constructive action you and other people can take to help us
> assess the quality and completeness of this release is to download the
> release, run the tests, run the release in your dev environment, read
> through the documentation, etc. This is one of the main points of
> releasing an RC to the community... even if you disagree with some
> patches that were merged in, this is still a way you can help validate
> the release.
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 1:30 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> > I'm aware of the changes file, but it really doesn't address the issue
> that
> > I am raising.  The changes file just tells me what has gone into the
> > release candidate.  In general, it doesn't tell me why those changes went
> > in or provide any rationale by which to judge whether that is the
> complete
> > set of changes that should go in.
> >
> > I talked some with Matei about related versioning and release issues last
> > week, and I've raised them in other contexts previously, but I'm taking
> the
> > liberty to annoy people again because I really am not happy with our
> > current versioning and release process, and I really am of the opinion
> that
> > we've got to start doing much better before I can vote in favor of a 1.0
> > release.  I fully realize that this is not a 1.0 release, and that
> because
> > we are pre-1.0 we still have a lot of flexibility with releases that
> break
> > backward or forward compatibility and with version numbers that have
> > nothing like the semantic meaning that they will eventually need to have;
> > but it is not going to be easy to change our process and culture so that
> we
> > produce the kind of stability and reliability that Spark users need to be
> > able to depend upon and version numbers that clearly communicate what
> those
> > users expect them to mean.  I think that we should start making those
> > changes now.  Just because we have flexibility pre-1.0, that doesn't mean
> > that we shouldn't start training ourselves now to work within the
> > constraints of post-1.0 Spark.  If I'm to be happy voting for an eventual
> > 1.0 release candidate, I'll need to have seen at least one full
> development
> > cycle that already adheres to the post-1.0 constraints, demonstrating the
> > maturity of our development process.
> >
> > That demonstration cycle is clearly not this one -- and I understand that
> > there were some compelling reasons (particularly with regard too getting
> a
> > "full" release of Spark based on Scala 2.9.3 before we make the jump to
> > 2.10.  This "patch-level" release breaks binary compatibility and
> contains
> > a lot of code that isn't anywhere close to meeting the criterion for
> > inclusion in a real, post-1.0 patch-level release: essentially "changes
> > that every, or nearly every, existing Spark user needs (not just wants),
> > and that work with all existing and future binaries built with the prior
> > patch-level version of Spark as a dependency."  Like I said, we are
> clearly
> > nowhere close to that with the move from 0.8.0 to 0.8.1; but I also
> haven't
> > been able to recognize any alternative criterion by which to judge the
> > quality and completeness of this release candidate.
> >
> > Maybe there just isn't one, and I'm just going to have to swallow my
> > concerns while watching 0.8.1 go out the door; but if we don't start
> doing
> > better on this kind of thing in the future, you are going to start
> hearing
> > more complaining from me. I just hope that it doesn't get to the point
> > where I feel compelled to actively oppose an eventual 1.0 release
> > candidate.
> >
> >
> > On Sun, Dec 8, 2013 at 12:37 PM, Henry Saputra <henry.saputra@gmail.com
> >wrote:
> >
> >> Ah, sorry for the confusion Patrick, like you said I was just trying to
> let
> >> people aware about this file and the purpose of it.
> >>
> >> On Sunday, December 8, 2013, Patrick Wendell wrote:
> >>
> >> > Hey Henry,
> >> >
> >> > Are you suggesting we need to change something about or changes file?
> >> > Or are you just pointing people to the file?
> >> >
> >> > - Patrick
> >> >
> >> > On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <
> henry.saputra@gmail.com>
> >> > wrote:
> >> > > HI Spark devs,
> >> > >
> >> > > I have modified the Subject to avoid polluting the VOTE thread since
> >> > > it related to more info how and which commits merge back to 0.8.*
> >> > > branch.
> >> > > Please respond to the previous question to this thread.
> >> > >
> >> > > Technically the CHANGES.txt [1] file should describe the changes in
> a
> >> > > particular release and it is the main requirement needed to cut an
> ASF
> >> > > release.
> >> > >
> >> > >
> >> > > - Henry
> >> > >
> >> > > [1]
> >> > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >> > >
> >> > > On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com>
> >> > wrote:
> >> > >> We can use git log to figure out which changes haven't made it into
> >> > >> branch-0.8.  Here's a quick attempt, which only lists pull requests
> >> that
> >> > >> were only merged into one of the branches.  For completeness, this
> >> > could be
> >> > >> extended to find commits that weren't part of a merge and are only
> >> > present
> >> > >> in one branch.
> >> > >>
> >> > >> *Script:*
> >> > >>
> >> > >> MASTER_BRANCH=origin/master
> >> > >> RELEASE_BRANCH=origin/branch-0.8
> >> > >>
> >> > >> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  |
> cut -f
> >> > 2-
> >> > >> -d ' ' | sort > master-prs
> >> > >> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH |
> cut -f
> >> > 2-
> >> > >> -d ' ' | sort > release-prs
> >> > >>
> >> > >> comm -23 master-prs release-prs > master-only
> >> > >> comm -23 release-prs master-prs > release-only
> >> > >>
> >> > >>
> >> > >> *Master Branch Only:*
> >> > >> Merge pull request #1 from colorant/yarn-client-2.2
> >> > >> Merge pull request #105 from pwendell/doc-fix
> >> > >> Merge pull request #110 from pwendell/master
> >> > >> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> >> > >> Merge pull request #151 from russellcardullo/add-graphite-sink
> >> > >> Merge pull request #154 from soulmachine/ClusterScheduler
> >> > >> Merge pull request #156 from haoyuan/master
> >> > >> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> >> > >> Merge pull request #16 from pwendell/master
> >> > >> Merge pull request #185 from mkolod/random-number-generator
> >> > >> Merge pull request #187 from aarondav/example-bcast-test
> >> > >> Merge pull request #190 from markhamstra/Stages4Jobs
> >> > >> Merge pull request #198 from
> >> > ankurdave/zipPartitions-preservesPartitioning
> >> > >> Merge pull request #2 from colorant/yarn-client-2.2
> >> > >> Merge pull request #203 from witgo/master
> >> > >> Merge pull request #204 from rxin/hash
> >> > >> Merge pull request #205 from kayousterhout/logging
> >> > >> Merge pull request #206 from ash211/patch-2
> >> > >> Merge pull request #207 from henrydavidge/master
> >> > >> Merge pull request #209 from pwendell/better-docs
> >> > >> Merge pull request #210 from haitaoyao/http-timeout
> >> > >> Merge pull request #212 from markhamstra/SPARK-963
> >> > >> Merge pull request #216 from liancheng/fix-spark-966
> >> > >> Merge pull request #217 from aarondav/mesos-urls
> >> > >> Merge pull request #22 from GraceH/metrics-naming
> >> > >> Merge pull request #220 from rxin/zippart
> >> > >> Merge pull request #225 from ash211/patch-3
> >> > >> Merge pull request #226 from ash211/patch-4
> >> > >> Merge pull request #233 from hsaputra/changecontexttobackend
> >> > >> Merge pull request #239 from aarondav/nit
> >> > >> Merge pull request #242 from pwendell/master
> >> > >> Merge pull request #3 from aarondav/pv-test
> >> > >> Merge pull request #36 from pwendell/versions
> >> > >> Merge pull request #37 from pwendell/merge-0.8
> >> > >> Merge pull request #39 from pwendell/master
> >> > >> Merge pull request #45 from pwendell/metrics_units
> >> > >> Merge pull request #56 from jerryshao/kafka-0.8-dev
> >> > >> Merge pull request #64 from prabeesh/master
> >> > >> Merge pull request #66 from shivaram/sbt-assembly-deps
> >> > >> Merge pull request #670 from jey/ec2-ssh-improvements
> >> > >> Merge pull request #71 from aarondav/scdefaults
> >> > >> Merge pull request #78 from mosharaf/master
> >> > >> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> >> > >> Merge pull request #80 from rxin/build
> >> > >> Merge pull request #82 from JoshRosen/map-output-t
> >>
>

--bcaec53f2bbddd18de04ed0da2c3--

From dev-return-837-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:13:03 2013
Return-Path: <dev-return-837-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A418106F2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:13:03 +0000 (UTC)
Received: (qmail 29602 invoked by uid 500); 9 Dec 2013 00:13:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29564 invoked by uid 500); 9 Dec 2013 00:13:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29553 invoked by uid 99); 9 Dec 2013 00:13:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:13:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of taka.epsilon@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:12:57 +0000
Received: by mail-ob0-f181.google.com with SMTP id uy5so3047793obc.12
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:12:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=dEo18fBkUZN51FepOZ6PZ8HVJeqXP+TSd87EnjlyWbI=;
        b=07hRYEoSkE2FL7t1SjHS9X/cQvQnmsU6G8VzfkV8Da8TUXqtIZSRbUqBeMbiBIcgJW
         p+nRnXoGLX/C0B9tnDinBDRX7jNLOMWH/NgjM1bD3uJgBg2wmmbBu4PeBtHsr4aEQSby
         BnA//t8BR3g8Wzh03JURUCS6MJS6bBCPDtAGwv3LH4DtXQs+uSjS7jr0l7UvKmA23d2b
         IAVuMzmN54HZZgQgumzUJvtcAsIiZg9NMwB0B0yxRiYSNXk4bsslyo+ne6Em5BHCTqKi
         CIKSYExACsGGbpfawC5U7eft4euddPQX0bqJksSk4WGuZV7yCuRSrGoO+xFO7lghYip1
         BoSA==
MIME-Version: 1.0
X-Received: by 10.182.230.135 with SMTP id sy7mr10823580obc.24.1386547956068;
 Sun, 08 Dec 2013 16:12:36 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Sun, 8 Dec 2013 16:12:36 -0800 (PST)
In-Reply-To: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
Date: Sun, 8 Dec 2013 16:12:36 -0800
Message-ID: <CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c3367662baba04ed0eda06
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3367662baba04ed0eda06
Content-Type: text/plain; charset=ISO-8859-1

With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
completing the build process (sbt/sbt assembly) on Macbook. The sbt command
hangs at the last step.

...
...
[info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
[info] Packaging
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
...
[info] SHA-1: 0657a347240266230247693f265a5797d40c326a
[info] Packaging
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
...
(hangs here)
--------------------------


On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I was
able to build it successfully.
..
..
[info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
[info] Packaging
/Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
...
[info] Done packaging.
[success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
--------------------------



On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Please vote on releasing the following candidate as Apache Spark
> (incubating) version 0.8.1.
>
> The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>
> The release files, including signatures, digests, etc can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-024/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>
> For information about the contents of this release see:
> <attached> draft of release notes
> <attached> draft of release credits
> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>
> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>
> The vote is open until Wednesday, December 11th at 21:00 UTC and
> passes if a majority of at least 3 +1 PPMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.incubator.apache.org/
>

--001a11c3367662baba04ed0eda06--

From dev-return-838-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:25:24 2013
Return-Path: <dev-return-838-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EC3BF107C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:25:24 +0000 (UTC)
Received: (qmail 42748 invoked by uid 500); 9 Dec 2013 00:25:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42711 invoked by uid 500); 9 Dec 2013 00:25:24 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 42703 invoked by uid 99); 9 Dec 2013 00:25:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:25:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.45 as permitted sender)
Received: from [209.85.219.45] (HELO mail-oa0-f45.google.com) (209.85.219.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:25:20 +0000
Received: by mail-oa0-f45.google.com with SMTP id o6so3129761oag.4
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:24:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=r4k39CXaXicGlmuhjWL78xfEeA/ArczzYXGYw9vs+0c=;
        b=0SmgjMSOgI0yydZYQ8yfW3CRsfluRgmig/TtUYXFp7hwMalVqJtR9gyjnk4iyQ5d0T
         s8Yi9q7NC+oCglrFSi81ifDH4UEKamS9ughG+ONU5YZb4cGwaDDyXoZ0ckvJB0nvRx34
         9gMp4DvQwK72ZuYv98ePYYeAq3Q3B/qXglEiyaksEtxANP7bQCBlWI5Oa38ZGs9CvIuc
         7fo11VUc6iD5oQRlhWNJ9GfHXmxsI5kA6tnJo0azMKDmib9y/S3s4KrVHNvDAFDpQa0Q
         hIFq39Rf/gXiyHrb+SQwVwfvk+f+2p5+ZQW1nYeF9gx9keBHaMth/ct4panvEO9lu7LV
         mBfQ==
MIME-Version: 1.0
X-Received: by 10.60.63.102 with SMTP id f6mr623871oes.76.1386548699642; Sun,
 08 Dec 2013 16:24:59 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 16:24:59 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 16:24:59 -0800 (PST)
In-Reply-To: <CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
Date: Sun, 8 Dec 2013 16:24:59 -0800
Message-ID: <CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c25532b4c19f04ed0f0643
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25532b4c19f04ed0f0643
Content-Type: text/plain; charset=ISO-8859-1

Hey Take,

Could you start a separate thread to debug your build issue? In that
thread, could you paste the exact build command and entire output? The log
you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
based on the assembly file name it is logging.

---
sent from my phone
On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com> wrote:

> With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
> completing the build process (sbt/sbt assembly) on Macbook. The sbt command
> hangs at the last step.
>
> ...
> ...
> [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> [info] Packaging
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> ...
> [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> [info] Packaging
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> ...
> (hangs here)
> --------------------------
>
>
> On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I was
> able to build it successfully.
> ..
> ..
> [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> [info] Packaging
>
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> ...
> [info] Done packaging.
> [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
> --------------------------
>
>
>
> On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Please vote on releasing the following candidate as Apache Spark
> > (incubating) version 0.8.1.
> >
> > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
> >
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> >
> > The release files, including signatures, digests, etc can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-024/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> >
> > For information about the contents of this release see:
> > <attached> draft of release notes
> > <attached> draft of release credits
> > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >
> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> >
> > The vote is open until Wednesday, December 11th at 21:00 UTC and
> > passes if a majority of at least 3 +1 PPMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.incubator.apache.org/
> >
>

--001a11c25532b4c19f04ed0f0643--

From dev-return-839-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:30:43 2013
Return-Path: <dev-return-839-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E26EA107D8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:30:43 +0000 (UTC)
Received: (qmail 45518 invoked by uid 500); 9 Dec 2013 00:30:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45484 invoked by uid 500); 9 Dec 2013 00:30:43 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 45476 invoked by uid 99); 9 Dec 2013 00:30:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:30:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taka.epsilon@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:30:39 +0000
Received: by mail-ob0-f171.google.com with SMTP id wp18so3037294obc.16
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:30:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=4vrVidzKEMnvCg4ZmqGnXEKfxTdWE9YbG5USswMmtzE=;
        b=nKroK4wkGEaXZQ8QfM9nAnYDhOdMA5WVmMqbqFkIjbSGqK0NIaMheu7Q54cSiNSMPL
         PAThLBbB7+9tvGvKX7CK/m64RCn8xeewtk64aOdbP1a7FLqJ01sn3NbiSaVlYHGpOSYi
         +F7VkrRwSeai6iDvfQeExmpjPRfcvPc/sHygjDWNbp/byolRG61R9KAHzg/4MJS5u6yt
         baJb6Z7x+/huBe+HBSBRjpp1coVgabDJNss2srF+WjlMwKCOhYBKIvbPday/7qYLlreh
         XNl08Q5bDukBYBcqqnmk/TZHc2NDpUT++TfQ4uI7WigDMQoQgGUrIDiT7KbilYSnmrb0
         0fEg==
MIME-Version: 1.0
X-Received: by 10.182.19.132 with SMTP id f4mr10699879obe.14.1386549018794;
 Sun, 08 Dec 2013 16:30:18 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Sun, 8 Dec 2013 16:30:18 -0800 (PST)
In-Reply-To: <CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 16:30:18 -0800
Message-ID: <CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c2aa6abaa11b04ed0f19ce
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2aa6abaa11b04ed0f19ce
Content-Type: text/plain; charset=ISO-8859-1

OK. I will post the entire output via separate email. I just upgraded
Hadoop to 2.2.0 recently. So there might be something I need to
remove/clean up.


On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Take,
>
> Could you start a separate thread to debug your build issue? In that
> thread, could you paste the exact build command and entire output? The log
> you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
> based on the assembly file name it is logging.
>
> ---
> sent from my phone
> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com> wrote:
>
> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
> command
> > hangs at the last step.
> >
> > ...
> > ...
> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> > [info] Packaging
> >
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> > ...
> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> > [info] Packaging
> >
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> > ...
> > (hangs here)
> > --------------------------
> >
> >
> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I was
> > able to build it successfully.
> > ..
> > ..
> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> > [info] Packaging
> >
> >
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> > ...
> > [info] Done packaging.
> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
> > --------------------------
> >
> >
> >
> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> >
> > > Please vote on releasing the following candidate as Apache Spark
> > > (incubating) version 0.8.1.
> > >
> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
> > >
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> > >
> > > The release files, including signatures, digests, etc can be found at:
> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > > https://repository.apache.org/content/repositories/orgapachespark-024/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> > >
> > > For information about the contents of this release see:
> > > <attached> draft of release notes
> > > <attached> draft of release credits
> > > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> > >
> > > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> > >
> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.incubator.apache.org/
> > >
> >
>

--001a11c2aa6abaa11b04ed0f19ce--

From dev-return-840-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:47:14 2013
Return-Path: <dev-return-840-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7AAD11083E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:47:14 +0000 (UTC)
Received: (qmail 57870 invoked by uid 500); 9 Dec 2013 00:47:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57834 invoked by uid 500); 9 Dec 2013 00:47:14 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 57826 invoked by uid 99); 9 Dec 2013 00:47:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:47:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of taka.epsilon@gmail.com designates 209.85.214.173 as permitted sender)
Received: from [209.85.214.173] (HELO mail-ob0-f173.google.com) (209.85.214.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:47:00 +0000
Received: by mail-ob0-f173.google.com with SMTP id gq1so3020183obb.4
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:46:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=BOh4Llv+hsKPsT6m1AfUDZjNFGno5Nh8ydLFgdO2saM=;
        b=uU6LmTxT1opkSK8d6y2mEIMkJnlYSqjer8DWIjS5heb+RnIGOUiIbYc6rMFlKCftfz
         rEmC/Tvl9tJS51hvXqW9giONyDfRqqAhWWXnHshIyHxuXlpA2uLxmMP03Y1KP3Gdcx0h
         igtObpdS1Pbjjma7mdRxRf9XqMm/DK4+2GKdTxG4ziatCBI0N5N7TpZ72h4kyOtVImSw
         uySS4ygJEj6bV3XZ1ChzWiN8hmfMDWmRuctZ4JLDOh7WJlrcnI4zdL//2dx6Z+brqZZ4
         IQ5Co57uOz/aoFtRQrY37//EMWdtGEx9z2LlvP0BLowFGvjNlfJEg9DQrPRkiQz+qJ43
         +dZQ==
MIME-Version: 1.0
X-Received: by 10.182.220.99 with SMTP id pv3mr10712067obc.37.1386549999237;
 Sun, 08 Dec 2013 16:46:39 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Sun, 8 Dec 2013 16:46:39 -0800 (PST)
Date: Sun, 8 Dec 2013 16:46:39 -0800
Message-ID: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
Subject: Spark Build Issue ('sbt/sbt assembly' hangs)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=14dae9399ab92b520904ed0f54c5
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae9399ab92b520904ed0f54c5
Content-Type: text/plain; charset=ISO-8859-1

As I reported in the Spark 0.8-1 RC2 thread, the 'sbt/sbt assembly' hangs
at the last step. It happens on a Macbook with Hadoop 2.2.0 (& Java
1.7.0_45) installed. The build was successful on another system with Hadoop
1.1.1 installed.

Here's the build command and the entire log. Thanks for the help.

---------------------------------------------------------------
$ sbt/sbt assembly
[info] Loading project definition from
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/}default-c4ca6d...
[info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
[info] Done updating.
[info] Compiling 1 Scala source to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/target/scala-2.9.2/sbt-0.12/classes...
[info] Loading project definition from
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/}plugins...
[info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
[info] Done updating.
[info] Compiling 1 Scala source to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/target/scala-2.9.2/sbt-0.12/classes...
[info] Set current project to root (in build
file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/)
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}core...
[info] Resolving org.apache.derby#derby;10.4.2.0 ...
[info] Done updating.
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}streaming...
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}bagel...
[info] Resolving org.scala-lang#scala-library;2.9.3 ...
[info] Done updating.
[info] Resolving org.eclipse.jetty#jetty-util;7.6.8.v20121106 ...
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}mllib...
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}tools...
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}examples...
[info] Resolving org.slf4j#slf4j-api;1.7.2 ...
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}repl...
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[info] Resolving org.apache.httpcomponents#httpcore;4.1 ...
[info] Compiling 285 Scala sources and 18 Java sources to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/target/scala-2.9.3/classes...
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[info] Updating
{file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}assembly...
[info] Resolving org.mockito#mockito-all;1.8.5 ...
[info] Done updating.
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:131:
method cleanupJob in class OutputCommitter is deprecated: see corresponding
Javadoc for more information.
[warn]     getOutputCommitter().cleanupJob(getJobContext())
[warn]                          ^
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1059:
class BitTorrentBroadcast in package broadcast is deprecated: Use
TorrentBroadcast
[warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
[warn]       ^
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1060:
class BitTorrentBroadcast in package broadcast is deprecated: Use
TorrentBroadcast
[warn]     new BitTorrentBroadcast[T](value_, isLocal, id)
[warn]         ^
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:600:
class TreeBroadcast in package broadcast is deprecated: Use TorrentBroadcast
[warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
[warn]       ^
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:601:
class TreeBroadcast in package broadcast is deprecated: Use TorrentBroadcast
[warn]     new TreeBroadcast[T](value_, isLocal, id)
[warn]         ^
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:598:
method cleanupJob in class OutputCommitter is deprecated: see corresponding
Javadoc for more information.
[warn]     jobCommitter.cleanupJob(jobTaskContext)
[warn]                  ^
[warn] 6 warnings found
[warn] warning: [options] bootstrap class path not set in conjunction with
-source 1.5
[warn] Note: Some input files use unchecked or unsafe operations.
[warn] Note: Recompile with -Xlint:unchecked for details.
[warn] 1 warning
[info] Compiling 1 Scala source to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/bagel/target/scala-2.9.3/classes...
[info] Compiling 49 Scala sources to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/streaming/target/scala-2.9.3/classes...
[info] Compiling 25 Scala sources to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/mllib/target/scala-2.9.3/classes...
[info] Compiling 10 Scala sources to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/target/scala-2.9.3/classes...
[warn]
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala:141:
method stop in class Thread is deprecated: see corresponding Javadoc for
more information.
[warn]         line.thread.stop()
[warn]                     ^
[warn] one warning found
[info] Compiling 39 Scala sources and 13 Java sources to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/examples/target/scala-2.9.3/classes...
[info] Compiling 1 Scala source to
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/classes...
[warn] warning: [options] bootstrap class path not set in conjunction with
-source 1.5
[warn] 1 warning
[info] Including: scala-compiler.jar
[info] Including: scala-compiler.jar
[info] Including: scala-library.jar
[info] Including: scala-library.jar
[info] Including: compress-lzf-0.8.4.jar
[info] Including: py4j-0.7.jar
[info] Including: compress-lzf-0.8.4.jar
[info] Including: config-0.3.1.jar
[info] Including: config-0.3.1.jar
[info] Including: guava-14.0.1.jar
[info] Including: guava-14.0.1.jar
[info] Including: kryo-2.21.jar
[info] Including: kryo-2.21.jar
[info] Including: log4j-1.2.17.jar
[info] Including: log4j-1.2.17.jar
[info] Including: metrics-core-3.0.0.jar
[info] Including: metrics-core-3.0.0.jar
[info] Including: metrics-ganglia-3.0.0.jar
[info] Including: metrics-ganglia-3.0.0.jar
[info] Including: metrics-json-3.0.0.jar
[info] Including: metrics-json-3.0.0.jar
[info] Including: metrics-jvm-3.0.0.jar
[info] Including: metrics-jvm-3.0.0.jar
[info] Including: netty-3.5.4.Final.jar
[info] Including: netty-3.5.4.Final.jar
[info] Including: snappy-java-1.0.5.jar
[info] Including: snappy-java-1.0.5.jar
[info] Including: akka-actor-2.0.5.jar
[info] Including: akka-actor-2.0.5.jar
[info] Including: akka-remote-2.0.5.jar
[info] Including: akka-remote-2.0.5.jar
[info] Including: akka-slf4j-2.0.5.jar
[info] Including: akka-slf4j-2.0.5.jar
[info] Including: akka-zeromq-2.0.5.jar
[info] Including: akka-zeromq-2.0.5.jar
[info] Including: asm-4.0.jar
[info] Including: asm-4.0.jar
[info] Including: asm-commons-4.0.jar
[info] Including: asm-commons-4.0.jar
[info] Including: asm-tree-4.0.jar
[info] Including: asm-tree-4.0.jar
[info] Including: avro-1.7.4.jar
[info] Including: avro-1.7.4.jar
[info] Including: avro-ipc-1.7.4.jar
[info] Including: avro-ipc-1.7.4.jar
[info] Including: chill-java-0.3.1.jar
[info] Including: chill-java-0.3.1.jar
[info] Including: chill_2.9.3-0.3.1.jar
[info] Including: chill_2.9.3-0.3.1.jar
[info] Including: colt-1.2.0.jar
[info] Including: colt-1.2.0.jar
[info] Including: commons-beanutils-1.7.0.jar
[info] Including: commons-beanutils-1.7.0.jar
[info] Including: commons-beanutils-core-1.8.0.jar
[info] Including: commons-beanutils-core-1.8.0.jar
[info] Including: commons-codec-1.4.jar
[info] Including: commons-codec-1.4.jar
[info] Including: commons-collections-3.2.1.jar
[info] Including: commons-collections-3.2.1.jar
[info] Including: commons-compress-1.4.1.jar
[info] Including: commons-compress-1.4.1.jar
[info] Including: commons-configuration-1.6.jar
[info] Including: commons-configuration-1.6.jar
[info] Including: commons-daemon-1.0.10.jar
[info] Including: commons-daemon-1.0.10.jar
[info] Including: commons-digester-1.8.jar
[info] Including: commons-digester-1.8.jar
[info] Including: commons-el-1.0.jar
[info] Including: commons-el-1.0.jar
[info] Including: commons-httpclient-3.1.jar
[info] Including: commons-httpclient-3.1.jar
[info] Including: commons-io-2.1.jar
[info] Including: commons-io-2.1.jar
[info] Including: commons-lang-2.4.jar
[info] Including: commons-lang-2.4.jar
[info] Including: commons-logging-1.1.1.jar
[info] Including: commons-logging-1.1.1.jar
[info] Including: commons-math-2.1.jar
[info] Including: commons-math-2.1.jar
[info] Including: commons-net-1.4.1.jar
[info] Including: commons-net-1.4.1.jar
[info] Including: concurrent-1.3.4.jar
[info] Including: concurrent-1.3.4.jar
[info] Including: dispatch-json_2.9.1-0.8.5.jar
[info] Including: dispatch-json_2.9.1-0.8.5.jar
[info] Including: fastutil-6.4.4.jar
[info] Including: fastutil-6.4.4.jar
[info] Including: flume-ng-sdk-1.2.0.jar
[info] Including: flume-ng-sdk-1.2.0.jar
[info] Including: gmetric4j-1.0.3.jar
[info] Including: gmetric4j-1.0.3.jar
[info] Including: h2-lzf-1.0.jar
[info] Including: h2-lzf-1.0.jar
[info] Including: hadoop-client-1.0.4.jar
[info] Including: hadoop-client-1.0.4.jar
[info] Including: hadoop-core-1.0.4.jar
[info] Including: hadoop-core-1.0.4.jar
[info] Including: hsqldb-1.8.0.10.jar
[info] Including: hsqldb-1.8.0.10.jar
[info] Including: httpclient-4.1.jar
[info] Including: httpclient-4.1.jar
[info] Including: httpcore-4.1.jar
[info] Including: httpcore-4.1.jar
[info] Including: jackson-annotations-2.2.2.jar
[info] Including: jackson-annotations-2.2.2.jar
[info] Including: jackson-core-2.2.2.jar
[info] Including: jackson-core-2.2.2.jar
[info] Including: jackson-core-asl-1.8.8.jar
[info] Including: jackson-core-asl-1.8.8.jar
[info] Including: jackson-databind-2.2.2.jar
[info] Including: jackson-databind-2.2.2.jar
[info] Including: jackson-mapper-asl-1.8.8.jar
[info] Including: jackson-mapper-asl-1.8.8.jar
[info] Including: jets3t-0.7.1.jar
[info] Including: jetty-6.1.26.jar
[info] Including: jblas-1.2.3.jar
[info] Including: jetty-continuation-7.6.8.v20121106.jar
[info] Including: jets3t-0.7.1.jar
[info] Including: jetty-http-7.6.8.v20121106.jar
[info] Including: jetty-io-7.6.8.v20121106.jar
[info] Including: jetty-6.1.26.jar
[info] Including: jetty-server-7.6.8.v20121106.jar
[info] Including: jetty-util-6.1.26.jar
[info] Including: jetty-continuation-7.6.8.v20121106.jar
[info] Including: jetty-http-7.6.8.v20121106.jar
[info] Including: jetty-util-7.6.8.v20121106.jar
[info] Including: jetty-io-7.6.8.v20121106.jar
[info] Including: jetty-server-7.6.8.v20121106.jar
[info] Including: jline-0.9.94.jar
[info] Including: jetty-util-6.1.26.jar
[info] Including: jetty-util-7.6.8.v20121106.jar
[info] Including: jna-3.0.9.jar
[info] Including: jline-0.9.94.jar
[info] Including: jna-3.0.9.jar
[info] Including: jnr-constants-0.8.2.jar
[info] Including: jnr-constants-0.8.2.jar
[info] Including: jsr305-1.3.9.jar
[info] Including: junit-3.8.1.jar
[info] Including: jsr305-1.3.9.jar
[info] Including: junit-3.8.1.jar
[info] Including: lift-json_2.9.2-2.5.jar
[info] Including: lift-json_2.9.2-2.5.jar
[info] Including: mesos-0.13.0.jar
[info] Including: mesos-0.13.0.jar
[info] Including: minlog-1.2.jar
[info] Including: minlog-1.2.jar
[info] Including: netty-all-4.0.0.Beta2.jar
[info] Including: netty-all-4.0.0.Beta2.jar
[info] Including: objenesis-1.2.jar
[info] Including: objenesis-1.2.jar
[info] Including: oncrpc-1.0.7.jar
[info] Including: oncrpc-1.0.7.jar
[info] Including: oro-2.0.8.jar
[info] Including: oro-2.0.8.jar
[info] Including: paranamer-2.4.1.jar
[info] Including: paranamer-2.4.1.jar
[info] Including: protobuf-java-2.4.1.jar
[info] Including: protobuf-java-2.4.1.jar
[info] Including: reflectasm-1.07-shaded.jar
[info] Including: reflectasm-1.07-shaded.jar
[info] Including: scalap-2.9.2.jar
[info] Including: scalap-2.9.2.jar
[info] Including: servlet-api-2.5-20110124.jar
[info] Including: servlet-api-2.5-20110124.jar
[info] Including: sjson_2.9.1-0.15.jar
[info] Including: sjson_2.9.1-0.15.jar
[info] Including: slf4j-api-1.7.5.jar
[info] Including: slf4j-api-1.7.5.jar
[info] Including: slf4j-log4j12-1.7.2.jar
[info] Including: slf4j-log4j12-1.7.2.jar
[info] Including: twitter4j-core-3.0.3.jar
[info] Including: twitter4j-core-3.0.3.jar
[info] Including: twitter4j-stream-3.0.3.jar
[info] Including: twitter4j-stream-3.0.3.jar
[info] Including: velocity-1.7.jar
[info] Including: velocity-1.7.jar
[info] Including: xmlenc-0.52.jar
[info] Including: xmlenc-0.52.jar
[info] Including: xz-1.0.jar
[info] Including: xz-1.0.jar
[info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
[info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
[info] Including: zkclient-0.1.jar
[info] Including: zkclient-0.1.jar
[info] Including: zookeeper-3.4.5.jar
[info] Including: zookeeper-3.4.5.jar
[info] Including: javax.servlet-2.5.0.v201103041518.jar
[info] Including: javax.servlet-2.5.0.v201103041518.jar
[info] Including: scala-jline.jar
[info] Including: kafka-0.7.2-spark.jar
[info] Including: kafka-0.7.2-spark.jar
[warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy 'first'
[warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
with strategy 'first'
[warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
with strategy 'first'
[warn] Merging 'META-INF/ASL2.0' with strategy 'first'
[warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
 [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FloatConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
strategy 'first'
 [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/IntegerConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
'first'
[warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
strategy 'first'
[warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
'first'
[warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
[warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ShortConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
with strategy 'first'
[warn] Merging
'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
'first'
[warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ClassConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
'first'
[warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
'first'
[warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
'first'
[warn] Merging 'javax/servlet/UnavailableException.class' with strategy
'first'
[warn] Merging 'META-INF/NOTICE' with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
'first'
[warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
[warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
'first'
[warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/StringConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
with strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
'first'
[warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
with strategy 'first'
[warn] Merging 'javax/servlet/LocalStrings.properties' with strategy 'first'
[warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
'first'
[warn] Merging
'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
strategy 'first'
[warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/DoubleConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BooleanConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
with strategy 'first'
[warn] Merging 'log4j.properties' with strategy 'discard'
[warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
[warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/CharacterConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
with strategy 'first'
[warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
strategy 'first'
[warn] Merging 'reference.conf' with strategy 'concat'
[warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
strategy 'first'
[warn] Merging 'about.html' with strategy 'first'
[warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
[warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
'first'
[warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/collections/FastHashMap$CollectionView.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
with strategy 'first'
[warn] Merging 'META-INF/LICENSE' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/collections/BufferUnderflowException.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
'first'
[warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
strategy 'first'
[warn] Strategy 'concat' was applied to a file
[warn] Strategy 'discard' was applied to 3 files
[warn] Strategy 'first' was applied to 212 files
[info] Checking every *.class/*.jar file's SHA-1.
[warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy 'first'
[warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
with strategy 'first'
[warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
with strategy 'first'
[warn] Merging 'META-INF/ASL2.0' with strategy 'first'
[warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
 [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FloatConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
strategy 'first'
 [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/IntegerConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
'first'
[warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
strategy 'first'
[warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
'first'
[warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
[warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ShortConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
with strategy 'first'
[warn] Merging
'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
'first'
[warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ClassConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
'first'
[warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
'first'
[warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
'first'
[warn] Merging 'javax/servlet/UnavailableException.class' with strategy
'first'
[warn] Merging 'META-INF/NOTICE' with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
'first'
[warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
[warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
'first'
[warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/StringConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
with strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
with strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
with strategy 'first'
[warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
'first'
[warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
with strategy 'first'
[warn] Merging 'javax/servlet/LocalStrings.properties' with strategy 'first'
[warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
'first'
[warn] Merging
'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
strategy 'first'
[warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/DoubleConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BooleanConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
with strategy 'first'
[warn] Merging 'log4j.properties' with strategy 'discard'
[warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
[warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
'first'
[warn] Merging
'org/apache/commons/beanutils/converters/CharacterConverter.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
with strategy 'first'
[warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
[warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
strategy 'first'
[warn] Merging 'reference.conf' with strategy 'concat'
[warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
strategy 'first'
[warn] Merging 'about.html' with strategy 'first'
[warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
[warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
'first'
[warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
strategy 'first'
[warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
with strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
strategy 'first'
[warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
with strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/collections/FastHashMap$CollectionView.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
'first'
[warn] Merging
'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
[warn] Merging
'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
strategy 'first'
[warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
with strategy 'first'
[warn] Merging 'META-INF/LICENSE' with strategy 'first'
[warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
strategy 'first'
[warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
strategy 'first'
[warn] Merging
'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
with strategy 'first'
[warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
strategy 'first'
[warn] Merging
'org/apache/commons/collections/BufferUnderflowException.class' with
strategy 'first'
[warn] Merging
'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
strategy 'first'
[warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
'first'
[warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
[warn] Merging
'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
strategy 'first'
[warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
strategy 'first'
[warn] Strategy 'concat' was applied to a file
[warn] Strategy 'discard' was applied to 3 files
[warn] Strategy 'first' was applied to 212 files
[info] Checking every *.class/*.jar file's SHA-1.
[info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
[info] Packaging
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
...
[info] SHA-1: 0657a347240266230247693f265a5797d40c326a
[info] Packaging
/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
...

--14dae9399ab92b520904ed0f54c5--

From dev-return-841-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:53:20 2013
Return-Path: <dev-return-841-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A7B910845
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:53:20 +0000 (UTC)
Received: (qmail 58892 invoked by uid 500); 9 Dec 2013 00:53:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58858 invoked by uid 500); 9 Dec 2013 00:53:19 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 58850 invoked by uid 99); 9 Dec 2013 00:53:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:53:19 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.160.52 as permitted sender)
Received: from [209.85.160.52] (HELO mail-pb0-f52.google.com) (209.85.160.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:53:13 +0000
Received: by mail-pb0-f52.google.com with SMTP id uo5so4336374pbc.39
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:52:52 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=N9hfHHYF9U+OBidM+8LHLn2pWR/L5OzN1RHT4rUUd7M=;
        b=vJZCt4hr7ZIH2RhZ0knKewNu7qQAwyQbA5QBZZ4mcd4Ip0chrOMFRwLFJfD/Bhh3/h
         2E16lKa2+smFvsrqLNQAJapVpuI69lhnjOH4UcyrxqxjiHFJnT7nPfxTjaPkAdZ9fD+g
         MtrP3kbs+O85SMb63RXvxHUqHmitrcHWtoQiF3t/1/9EA08JOemfjdJh2ZDRyGu9TcLD
         nFpT/qDxPvu+UtSWvbt/+g+xVgaAcJO2pYs1fvVXj3K+HVk0Joe8qk4scM4RbWFYZrii
         MHf8XUlZSrARg3UR9bgkDU3l0X7stJ0ylRSg5FAhBtik0Gk3K31N7Pdh37fdV/vrtYGc
         d2Rw==
X-Received: by 10.66.163.164 with SMTP id yj4mr17612958pab.91.1386550372334;
        Sun, 08 Dec 2013 16:52:52 -0800 (PST)
Received: from [192.168.1.106] (c-24-7-114-112.hsd1.ca.comcast.net. [24.7.114.112])
        by mx.google.com with ESMTPSA id hu10sm13674830pbc.11.2013.12.08.16.52.50
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 08 Dec 2013 16:52:51 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAAsvFPk-3x4kaXEq8Q6+rbnW2V119dUwWwZOErwbZDgQanHQqQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 16:52:49 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <626EB528-9B42-4828-B2AB-69242EBA99D6@gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com> <CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com> <CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com> <CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com> <CABPQxstAuGjE_=gHf5=iUDBtYzDDKEw_=dKoiGHHc5tf8+UyKQ@mail.gmail.com> <CAAsvFPk-3x4kaXEq8Q6+rbnW2V119dUwWwZOErwbZDgQanHQqQ@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

I agree that minor releases should be binary-compatible for all public =
APIs, and I think that=92s a good goal for future ones. In fact our =
releases have always provided full compatibility for =93external=94 =
APIs, just not for internal ones that you might use for defining a new =
RDD, new transformations, etc. However, it seems that more people want =
those directly, so that=92s a good goal to aim for.

In this case we pushed in more features than usual because this was the =
last branch on Scala 2.9, and there were some pretty key features (YARN =
2.2 compatibility, standalone mode HA) that we thought 2.9 users would =
want.

Something else we=92ll probably do is mark more =93internal=94, yet =
useful-to-extend, APIs through an annotation. I=92m talking about things =
like writing a custom RDD or SparkListener. These may change in major =
versions, but at least you=92ll be able to expect that maintenance =
releases in the original branch don=92t break them.

Matei

On Dec 8, 2013, at 2:45 PM, Mark Hamstra <mark@clearstorydata.com> =
wrote:

> Yup, I'm already started on that process.
>=20
> And it's not that I disagree with any particular change that was =
merged per
> se -- I haven't seen anything merged that most users won't want.  It's =
more
> that I object to the burden that our current =
development/versioning/release
> process puts on Spark users responsible for production code.  For =
them,
> adopting a new patch-level release should be a decision requiring =
almost no
> thinking since the new release should be essentially just bug-fixes =
that
> maintain full binary compatibility.  With our current process, those =
users
> have to suck in a bunch of new, less-tested, less-mature code that may
> comprise new features or functionality that the user doesn't want (at =
least
> not right away in production), but that they can't cleanly separate =
from
> the bug-fixes that they do want.  Our process simply has to change if =
we
> place users' desires ahead of Spark developers' desires.
>=20
>=20
> On Sun, Dec 8, 2013 at 2:12 PM, Patrick Wendell <pwendell@gmail.com> =
wrote:
>=20
>> Hey Mark,
>>=20
>> One constructive action you and other people can take to help us
>> assess the quality and completeness of this release is to download =
the
>> release, run the tests, run the release in your dev environment, read
>> through the documentation, etc. This is one of the main points of
>> releasing an RC to the community... even if you disagree with some
>> patches that were merged in, this is still a way you can help =
validate
>> the release.
>>=20
>> - Patrick
>>=20
>> On Sun, Dec 8, 2013 at 1:30 PM, Mark Hamstra =
<mark@clearstorydata.com>
>> wrote:
>>> I'm aware of the changes file, but it really doesn't address the =
issue
>> that
>>> I am raising.  The changes file just tells me what has gone into the
>>> release candidate.  In general, it doesn't tell me why those changes =
went
>>> in or provide any rationale by which to judge whether that is the
>> complete
>>> set of changes that should go in.
>>>=20
>>> I talked some with Matei about related versioning and release issues =
last
>>> week, and I've raised them in other contexts previously, but I'm =
taking
>> the
>>> liberty to annoy people again because I really am not happy with our
>>> current versioning and release process, and I really am of the =
opinion
>> that
>>> we've got to start doing much better before I can vote in favor of a =
1.0
>>> release.  I fully realize that this is not a 1.0 release, and that
>> because
>>> we are pre-1.0 we still have a lot of flexibility with releases that
>> break
>>> backward or forward compatibility and with version numbers that have
>>> nothing like the semantic meaning that they will eventually need to =
have;
>>> but it is not going to be easy to change our process and culture so =
that
>> we
>>> produce the kind of stability and reliability that Spark users need =
to be
>>> able to depend upon and version numbers that clearly communicate =
what
>> those
>>> users expect them to mean.  I think that we should start making =
those
>>> changes now.  Just because we have flexibility pre-1.0, that doesn't =
mean
>>> that we shouldn't start training ourselves now to work within the
>>> constraints of post-1.0 Spark.  If I'm to be happy voting for an =
eventual
>>> 1.0 release candidate, I'll need to have seen at least one full
>> development
>>> cycle that already adheres to the post-1.0 constraints, =
demonstrating the
>>> maturity of our development process.
>>>=20
>>> That demonstration cycle is clearly not this one -- and I understand =
that
>>> there were some compelling reasons (particularly with regard too =
getting
>> a
>>> "full" release of Spark based on Scala 2.9.3 before we make the jump =
to
>>> 2.10.  This "patch-level" release breaks binary compatibility and
>> contains
>>> a lot of code that isn't anywhere close to meeting the criterion for
>>> inclusion in a real, post-1.0 patch-level release: essentially =
"changes
>>> that every, or nearly every, existing Spark user needs (not just =
wants),
>>> and that work with all existing and future binaries built with the =
prior
>>> patch-level version of Spark as a dependency."  Like I said, we are
>> clearly
>>> nowhere close to that with the move from 0.8.0 to 0.8.1; but I also
>> haven't
>>> been able to recognize any alternative criterion by which to judge =
the
>>> quality and completeness of this release candidate.
>>>=20
>>> Maybe there just isn't one, and I'm just going to have to swallow my
>>> concerns while watching 0.8.1 go out the door; but if we don't start
>> doing
>>> better on this kind of thing in the future, you are going to start
>> hearing
>>> more complaining from me. I just hope that it doesn't get to the =
point
>>> where I feel compelled to actively oppose an eventual 1.0 release
>>> candidate.
>>>=20
>>>=20
>>> On Sun, Dec 8, 2013 at 12:37 PM, Henry Saputra =
<henry.saputra@gmail.com
>>> wrote:
>>>=20
>>>> Ah, sorry for the confusion Patrick, like you said I was just =
trying to
>> let
>>>> people aware about this file and the purpose of it.
>>>>=20
>>>> On Sunday, December 8, 2013, Patrick Wendell wrote:
>>>>=20
>>>>> Hey Henry,
>>>>>=20
>>>>> Are you suggesting we need to change something about or changes =
file?
>>>>> Or are you just pointing people to the file?
>>>>>=20
>>>>> - Patrick
>>>>>=20
>>>>> On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <
>> henry.saputra@gmail.com>
>>>>> wrote:
>>>>>> HI Spark devs,
>>>>>>=20
>>>>>> I have modified the Subject to avoid polluting the VOTE thread =
since
>>>>>> it related to more info how and which commits merge back to 0.8.*
>>>>>> branch.
>>>>>> Please respond to the previous question to this thread.
>>>>>>=20
>>>>>> Technically the CHANGES.txt [1] file should describe the changes =
in
>> a
>>>>>> particular release and it is the main requirement needed to cut =
an
>> ASF
>>>>>> release.
>>>>>>=20
>>>>>>=20
>>>>>> - Henry
>>>>>>=20
>>>>>> [1]
>>>>> =
https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>>>>>>=20
>>>>>> On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen =
<rosenville@gmail.com>
>>>>> wrote:
>>>>>>> We can use git log to figure out which changes haven't made it =
into
>>>>>>> branch-0.8.  Here's a quick attempt, which only lists pull =
requests
>>>> that
>>>>>>> were only merged into one of the branches.  For completeness, =
this
>>>>> could be
>>>>>>> extended to find commits that weren't part of a merge and are =
only
>>>>> present
>>>>>>> in one branch.
>>>>>>>=20
>>>>>>> *Script:*
>>>>>>>=20
>>>>>>> MASTER_BRANCH=3Dorigin/master
>>>>>>> RELEASE_BRANCH=3Dorigin/branch-0.8
>>>>>>>=20
>>>>>>> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  |
>> cut -f
>>>>> 2-
>>>>>>> -d ' ' | sort > master-prs
>>>>>>> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH |
>> cut -f
>>>>> 2-
>>>>>>> -d ' ' | sort > release-prs
>>>>>>>=20
>>>>>>> comm -23 master-prs release-prs > master-only
>>>>>>> comm -23 release-prs master-prs > release-only
>>>>>>>=20
>>>>>>>=20
>>>>>>> *Master Branch Only:*
>>>>>>> Merge pull request #1 from colorant/yarn-client-2.2
>>>>>>> Merge pull request #105 from pwendell/doc-fix
>>>>>>> Merge pull request #110 from pwendell/master
>>>>>>> Merge pull request #146 from =
JoshRosen/pyspark-custom-serializers
>>>>>>> Merge pull request #151 from russellcardullo/add-graphite-sink
>>>>>>> Merge pull request #154 from soulmachine/ClusterScheduler
>>>>>>> Merge pull request #156 from haoyuan/master
>>>>>>> Merge pull request #159 from liancheng/dagscheduler-actor-refine
>>>>>>> Merge pull request #16 from pwendell/master
>>>>>>> Merge pull request #185 from mkolod/random-number-generator
>>>>>>> Merge pull request #187 from aarondav/example-bcast-test
>>>>>>> Merge pull request #190 from markhamstra/Stages4Jobs
>>>>>>> Merge pull request #198 from
>>>>> ankurdave/zipPartitions-preservesPartitioning
>>>>>>> Merge pull request #2 from colorant/yarn-client-2.2
>>>>>>> Merge pull request #203 from witgo/master
>>>>>>> Merge pull request #204 from rxin/hash
>>>>>>> Merge pull request #205 from kayousterhout/logging
>>>>>>> Merge pull request #206 from ash211/patch-2
>>>>>>> Merge pull request #207 from henrydavidge/master
>>>>>>> Merge pull request #209 from pwendell/better-docs
>>>>>>> Merge pull request #210 from haitaoyao/http-timeout
>>>>>>> Merge pull request #212 from markhamstra/SPARK-963
>>>>>>> Merge pull request #216 from liancheng/fix-spark-966
>>>>>>> Merge pull request #217 from aarondav/mesos-urls
>>>>>>> Merge pull request #22 from GraceH/metrics-naming
>>>>>>> Merge pull request #220 from rxin/zippart
>>>>>>> Merge pull request #225 from ash211/patch-3
>>>>>>> Merge pull request #226 from ash211/patch-4
>>>>>>> Merge pull request #233 from hsaputra/changecontexttobackend
>>>>>>> Merge pull request #239 from aarondav/nit
>>>>>>> Merge pull request #242 from pwendell/master
>>>>>>> Merge pull request #3 from aarondav/pv-test
>>>>>>> Merge pull request #36 from pwendell/versions
>>>>>>> Merge pull request #37 from pwendell/merge-0.8
>>>>>>> Merge pull request #39 from pwendell/master
>>>>>>> Merge pull request #45 from pwendell/metrics_units
>>>>>>> Merge pull request #56 from jerryshao/kafka-0.8-dev
>>>>>>> Merge pull request #64 from prabeesh/master
>>>>>>> Merge pull request #66 from shivaram/sbt-assembly-deps
>>>>>>> Merge pull request #670 from jey/ec2-ssh-improvements
>>>>>>> Merge pull request #71 from aarondav/scdefaults
>>>>>>> Merge pull request #78 from mosharaf/master
>>>>>>> Merge pull request #8 from vchekan/checkpoint-ttl-restore
>>>>>>> Merge pull request #80 from rxin/build
>>>>>>> Merge pull request #82 from JoshRosen/map-output-t
>>>>=20
>>=20


From dev-return-842-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 00:59:18 2013
Return-Path: <dev-return-842-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9BF271085C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 00:59:18 +0000 (UTC)
Received: (qmail 61267 invoked by uid 500); 9 Dec 2013 00:59:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61232 invoked by uid 500); 9 Dec 2013 00:59:18 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 61224 invoked by uid 99); 9 Dec 2013 00:59:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:59:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.53] (HELO mail-bk0-f53.google.com) (209.85.214.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 00:59:12 +0000
Received: by mail-bk0-f53.google.com with SMTP id na10so1111904bkb.26
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 16:58:51 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=LSrism1Pv5RPYapfjdikPPduaiCcxz9LYb9RBpWh4Mo=;
        b=Nj62ZR5vp+rV/kbzzJ56cCZOc3jJB/Khil+4r2oWWP1IWOmGzHcTgRXFb308OTl4Wp
         UWwyOasA4pYH24bMICDup9CIkGtzMHlqoHr2R+FoUnHUHRXBls27ZVN3AleFWy0vNMLB
         ddl6plYrsGUCS8cS4hi6UXSJs8vEsR7GC4NVooYFwMxV3sbJBO2BFjz+fTyiEE1VtA1F
         jySkxDq24owfdm7W4i9VqwEy0seMRDSDpoUHDc+fMssPvVHomSb2QxpkeOyADOoiVqes
         q6ClM0JqiPBgRfARmx5yeQ1G7dAKhKswtE4PWM211XbH9oLxGy30CLSmAuHNGXHsbsIA
         Pkdw==
X-Gm-Message-State: ALoCoQnACTPP6y9gqQUeDe7/dfoniv66KIYflzI+KpkKUO3IMuJVj4VcfXONlEoIwgfbgwlEh5TA
MIME-Version: 1.0
X-Received: by 10.204.173.197 with SMTP id q5mr1338629bkz.96.1386550731345;
 Sun, 08 Dec 2013 16:58:51 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 16:58:51 -0800 (PST)
In-Reply-To: <626EB528-9B42-4828-B2AB-69242EBA99D6@gmail.com>
References: <CALuGr6YrdDCiE0n1W7Vo6Stq4zgNH1fwbLYGg8AucvQ4Dv+a3A@mail.gmail.com>
	<CABPQxsv+BQS=f_giKWHjWoEKj_eZ3qSxkNxy+XrjA5=Z2TJ6oQ@mail.gmail.com>
	<CALuGr6ZUaRJ6x--8cHYhuQNcj2S0SDQnBe7yp4YvNxGiQwYQkA@mail.gmail.com>
	<CAAsvFPk4AT78s544LNChu593AiDouTd2By+VN+KMgZLUpJR5JQ@mail.gmail.com>
	<CABPQxstAuGjE_=gHf5=iUDBtYzDDKEw_=dKoiGHHc5tf8+UyKQ@mail.gmail.com>
	<CAAsvFPk-3x4kaXEq8Q6+rbnW2V119dUwWwZOErwbZDgQanHQqQ@mail.gmail.com>
	<626EB528-9B42-4828-B2AB-69242EBA99D6@gmail.com>
Date: Sun, 8 Dec 2013 16:58:51 -0800
Message-ID: <CAAsvFP=taERK-FjFXSQ-M6sQmRYi+ADZRU2=ikUyMRa+yoj+Rw@mail.gmail.com>
Subject: Re: [DISCUSS] About the [VOTE] Release Apache Spark 0.8.1-incubating (rc1)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec52d523bce6f6904ed0f7fe5
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec52d523bce6f6904ed0f7fe5
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Now that I can immediately give a +1.


On Sun, Dec 8, 2013 at 4:52 PM, Matei Zaharia <matei.zaharia@gmail.com>wrot=
e:

> I agree that minor releases should be binary-compatible for all public
> APIs, and I think that=92s a good goal for future ones. In fact our relea=
ses
> have always provided full compatibility for =93external=94 APIs, just not=
 for
> internal ones that you might use for defining a new RDD, new
> transformations, etc. However, it seems that more people want those
> directly, so that=92s a good goal to aim for.
>
> In this case we pushed in more features than usual because this was the
> last branch on Scala 2.9, and there were some pretty key features (YARN 2=
.2
> compatibility, standalone mode HA) that we thought 2.9 users would want.
>
> Something else we=92ll probably do is mark more =93internal=94, yet
> useful-to-extend, APIs through an annotation. I=92m talking about things =
like
> writing a custom RDD or SparkListener. These may change in major versions=
,
> but at least you=92ll be able to expect that maintenance releases in the
> original branch don=92t break them.
>
> Matei
>
> On Dec 8, 2013, at 2:45 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
>
> > Yup, I'm already started on that process.
> >
> > And it's not that I disagree with any particular change that was merged
> per
> > se -- I haven't seen anything merged that most users won't want.  It's
> more
> > that I object to the burden that our current
> development/versioning/release
> > process puts on Spark users responsible for production code.  For them,
> > adopting a new patch-level release should be a decision requiring almos=
t
> no
> > thinking since the new release should be essentially just bug-fixes tha=
t
> > maintain full binary compatibility.  With our current process, those
> users
> > have to suck in a bunch of new, less-tested, less-mature code that may
> > comprise new features or functionality that the user doesn't want (at
> least
> > not right away in production), but that they can't cleanly separate fro=
m
> > the bug-fixes that they do want.  Our process simply has to change if w=
e
> > place users' desires ahead of Spark developers' desires.
> >
> >
> > On Sun, Dec 8, 2013 at 2:12 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >
> >> Hey Mark,
> >>
> >> One constructive action you and other people can take to help us
> >> assess the quality and completeness of this release is to download the
> >> release, run the tests, run the release in your dev environment, read
> >> through the documentation, etc. This is one of the main points of
> >> releasing an RC to the community... even if you disagree with some
> >> patches that were merged in, this is still a way you can help validate
> >> the release.
> >>
> >> - Patrick
> >>
> >> On Sun, Dec 8, 2013 at 1:30 PM, Mark Hamstra <mark@clearstorydata.com>
> >> wrote:
> >>> I'm aware of the changes file, but it really doesn't address the issu=
e
> >> that
> >>> I am raising.  The changes file just tells me what has gone into the
> >>> release candidate.  In general, it doesn't tell me why those changes
> went
> >>> in or provide any rationale by which to judge whether that is the
> >> complete
> >>> set of changes that should go in.
> >>>
> >>> I talked some with Matei about related versioning and release issues
> last
> >>> week, and I've raised them in other contexts previously, but I'm taki=
ng
> >> the
> >>> liberty to annoy people again because I really am not happy with our
> >>> current versioning and release process, and I really am of the opinio=
n
> >> that
> >>> we've got to start doing much better before I can vote in favor of a
> 1.0
> >>> release.  I fully realize that this is not a 1.0 release, and that
> >> because
> >>> we are pre-1.0 we still have a lot of flexibility with releases that
> >> break
> >>> backward or forward compatibility and with version numbers that have
> >>> nothing like the semantic meaning that they will eventually need to
> have;
> >>> but it is not going to be easy to change our process and culture so
> that
> >> we
> >>> produce the kind of stability and reliability that Spark users need t=
o
> be
> >>> able to depend upon and version numbers that clearly communicate what
> >> those
> >>> users expect them to mean.  I think that we should start making those
> >>> changes now.  Just because we have flexibility pre-1.0, that doesn't
> mean
> >>> that we shouldn't start training ourselves now to work within the
> >>> constraints of post-1.0 Spark.  If I'm to be happy voting for an
> eventual
> >>> 1.0 release candidate, I'll need to have seen at least one full
> >> development
> >>> cycle that already adheres to the post-1.0 constraints, demonstrating
> the
> >>> maturity of our development process.
> >>>
> >>> That demonstration cycle is clearly not this one -- and I understand
> that
> >>> there were some compelling reasons (particularly with regard too
> getting
> >> a
> >>> "full" release of Spark based on Scala 2.9.3 before we make the jump =
to
> >>> 2.10.  This "patch-level" release breaks binary compatibility and
> >> contains
> >>> a lot of code that isn't anywhere close to meeting the criterion for
> >>> inclusion in a real, post-1.0 patch-level release: essentially "chang=
es
> >>> that every, or nearly every, existing Spark user needs (not just
> wants),
> >>> and that work with all existing and future binaries built with the
> prior
> >>> patch-level version of Spark as a dependency."  Like I said, we are
> >> clearly
> >>> nowhere close to that with the move from 0.8.0 to 0.8.1; but I also
> >> haven't
> >>> been able to recognize any alternative criterion by which to judge th=
e
> >>> quality and completeness of this release candidate.
> >>>
> >>> Maybe there just isn't one, and I'm just going to have to swallow my
> >>> concerns while watching 0.8.1 go out the door; but if we don't start
> >> doing
> >>> better on this kind of thing in the future, you are going to start
> >> hearing
> >>> more complaining from me. I just hope that it doesn't get to the poin=
t
> >>> where I feel compelled to actively oppose an eventual 1.0 release
> >>> candidate.
> >>>
> >>>
> >>> On Sun, Dec 8, 2013 at 12:37 PM, Henry Saputra <
> henry.saputra@gmail.com
> >>> wrote:
> >>>
> >>>> Ah, sorry for the confusion Patrick, like you said I was just trying
> to
> >> let
> >>>> people aware about this file and the purpose of it.
> >>>>
> >>>> On Sunday, December 8, 2013, Patrick Wendell wrote:
> >>>>
> >>>>> Hey Henry,
> >>>>>
> >>>>> Are you suggesting we need to change something about or changes fil=
e?
> >>>>> Or are you just pointing people to the file?
> >>>>>
> >>>>> - Patrick
> >>>>>
> >>>>> On Sun, Dec 8, 2013 at 11:37 AM, Henry Saputra <
> >> henry.saputra@gmail.com>
> >>>>> wrote:
> >>>>>> HI Spark devs,
> >>>>>>
> >>>>>> I have modified the Subject to avoid polluting the VOTE thread sin=
ce
> >>>>>> it related to more info how and which commits merge back to 0.8.*
> >>>>>> branch.
> >>>>>> Please respond to the previous question to this thread.
> >>>>>>
> >>>>>> Technically the CHANGES.txt [1] file should describe the changes i=
n
> >> a
> >>>>>> particular release and it is the main requirement needed to cut an
> >> ASF
> >>>>>> release.
> >>>>>>
> >>>>>>
> >>>>>> - Henry
> >>>>>>
> >>>>>> [1]
> >>>>>
> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >>>>>>
> >>>>>> On Sun, Dec 8, 2013 at 12:03 AM, Josh Rosen <rosenville@gmail.com>
> >>>>> wrote:
> >>>>>>> We can use git log to figure out which changes haven't made it in=
to
> >>>>>>> branch-0.8.  Here's a quick attempt, which only lists pull reques=
ts
> >>>> that
> >>>>>>> were only merged into one of the branches.  For completeness, thi=
s
> >>>>> could be
> >>>>>>> extended to find commits that weren't part of a merge and are onl=
y
> >>>>> present
> >>>>>>> in one branch.
> >>>>>>>
> >>>>>>> *Script:*
> >>>>>>>
> >>>>>>> MASTER_BRANCH=3Dorigin/master
> >>>>>>> RELEASE_BRANCH=3Dorigin/branch-0.8
> >>>>>>>
> >>>>>>> git log --oneline --grep "Merge pull request" $MASTER_BRANCH  |
> >> cut -f
> >>>>> 2-
> >>>>>>> -d ' ' | sort > master-prs
> >>>>>>> git log --oneline --grep "Merge pull request" $RELEASE_BRANCH |
> >> cut -f
> >>>>> 2-
> >>>>>>> -d ' ' | sort > release-prs
> >>>>>>>
> >>>>>>> comm -23 master-prs release-prs > master-only
> >>>>>>> comm -23 release-prs master-prs > release-only
> >>>>>>>
> >>>>>>>
> >>>>>>> *Master Branch Only:*
> >>>>>>> Merge pull request #1 from colorant/yarn-client-2.2
> >>>>>>> Merge pull request #105 from pwendell/doc-fix
> >>>>>>> Merge pull request #110 from pwendell/master
> >>>>>>> Merge pull request #146 from JoshRosen/pyspark-custom-serializers
> >>>>>>> Merge pull request #151 from russellcardullo/add-graphite-sink
> >>>>>>> Merge pull request #154 from soulmachine/ClusterScheduler
> >>>>>>> Merge pull request #156 from haoyuan/master
> >>>>>>> Merge pull request #159 from liancheng/dagscheduler-actor-refine
> >>>>>>> Merge pull request #16 from pwendell/master
> >>>>>>> Merge pull request #185 from mkolod/random-number-generator
> >>>>>>> Merge pull request #187 from aarondav/example-bcast-test
> >>>>>>> Merge pull request #190 from markhamstra/Stages4Jobs
> >>>>>>> Merge pull request #198 from
> >>>>> ankurdave/zipPartitions-preservesPartitioning
> >>>>>>> Merge pull request #2 from colorant/yarn-client-2.2
> >>>>>>> Merge pull request #203 from witgo/master
> >>>>>>> Merge pull request #204 from rxin/hash
> >>>>>>> Merge pull request #205 from kayousterhout/logging
> >>>>>>> Merge pull request #206 from ash211/patch-2
> >>>>>>> Merge pull request #207 from henrydavidge/master
> >>>>>>> Merge pull request #209 from pwendell/better-docs
> >>>>>>> Merge pull request #210 from haitaoyao/http-timeout
> >>>>>>> Merge pull request #212 from markhamstra/SPARK-963
> >>>>>>> Merge pull request #216 from liancheng/fix-spark-966
> >>>>>>> Merge pull request #217 from aarondav/mesos-urls
> >>>>>>> Merge pull request #22 from GraceH/metrics-naming
> >>>>>>> Merge pull request #220 from rxin/zippart
> >>>>>>> Merge pull request #225 from ash211/patch-3
> >>>>>>> Merge pull request #226 from ash211/patch-4
> >>>>>>> Merge pull request #233 from hsaputra/changecontexttobackend
> >>>>>>> Merge pull request #239 from aarondav/nit
> >>>>>>> Merge pull request #242 from pwendell/master
> >>>>>>> Merge pull request #3 from aarondav/pv-test
> >>>>>>> Merge pull request #36 from pwendell/versions
> >>>>>>> Merge pull request #37 from pwendell/merge-0.8
> >>>>>>> Merge pull request #39 from pwendell/master
> >>>>>>> Merge pull request #45 from pwendell/metrics_units
> >>>>>>> Merge pull request #56 from jerryshao/kafka-0.8-dev
> >>>>>>> Merge pull request #64 from prabeesh/master
> >>>>>>> Merge pull request #66 from shivaram/sbt-assembly-deps
> >>>>>>> Merge pull request #670 from jey/ec2-ssh-improvements
> >>>>>>> Merge pull request #71 from aarondav/scdefaults
> >>>>>>> Merge pull request #78 from mosharaf/master
> >>>>>>> Merge pull request #8 from vchekan/checkpoint-ttl-restore
> >>>>>>> Merge pull request #80 from rxin/build
> >>>>>>> Merge pull request #82 from JoshRosen/map-output-t
> >>>>
> >>
>
>

--bcaec52d523bce6f6904ed0f7fe5--

From dev-return-843-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 01:06:36 2013
Return-Path: <dev-return-843-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6CD5310887
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 01:06:36 +0000 (UTC)
Received: (qmail 64495 invoked by uid 500); 9 Dec 2013 01:06:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64455 invoked by uid 500); 9 Dec 2013 01:06:35 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 64447 invoked by uid 99); 9 Dec 2013 01:06:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:06:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.42] (HELO mail-bk0-f42.google.com) (209.85.214.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:06:29 +0000
Received: by mail-bk0-f42.google.com with SMTP id w11so1133030bkz.1
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 17:06:07 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=MwIVAFwtaA8c+g76NfYVQme3V7TrSWavbXI2QYkOHkI=;
        b=UWoMV6DL2CK2wImW9zjwIr9UsFOOm0S0liCWuEujZ+oY5RBGI6teDMauqdzIy7PncF
         qTuIjcolDYAwPgZdtLUoDimbzV4E7vC3ZczUlEhCL84h3uw/cs2xDyptMc1CZh35MJjn
         5nGpS+8HYbjeDvcbUu7ko6kx25UdfWcpBF0MuYD3snGBdAQQRVd/OsY6ck+a71TlaGEY
         tRWowBDwARbA0TnHGIo2NsWM++Hba/arLK75o4mcQxf2mFJkSyn6Fq4AUiK2IjkTWLZQ
         MNrfcORKFvDlXACdFF6xczT+Cm+Uk24hVHg4b7TLz/bD+9827K2dji6EqK4fRZnKqe48
         CUZw==
X-Gm-Message-State: ALoCoQloE/YTl/JYgl278nUtr1vZ7BuWl0ZxVA84jaGI3CF5mFaQpj3kWcTamfxQYhZoWusJ6TaM
MIME-Version: 1.0
X-Received: by 10.205.65.81 with SMTP id xl17mr1342232bkb.66.1386551167219;
 Sun, 08 Dec 2013 17:06:07 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 17:06:07 -0800 (PST)
In-Reply-To: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
References: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
Date: Sun, 8 Dec 2013 17:06:07 -0800
Message-ID: <CAAsvFPmkfWkXW=OAVLqNfyU2QB7mv_jMhuXkrzaCRBF9b05eYg@mail.gmail.com>
Subject: Re: Spark Build Issue ('sbt/sbt assembly' hangs)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec53f2bbdc950d104ed0f9944
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f2bbdc950d104ed0f9944
Content-Type: text/plain; charset=ISO-8859-1

The assembly "hang" is something that I've also noticed over at least the
past few weeks.  If you are seeing what I am seeing, then the build is not
actually hung, but the building of assemblies takes a long time, a very
long time, a very very long time on Macs.  It's just the build of
assemblies via sbt on OSX that does this -- maven builds on Mac or any kind
of build on Linux go much faster.  On a Mac that also has other things to
do, I've seen the sbt assembly packaging take upwards of an hour.  Not good.


On Sun, Dec 8, 2013 at 4:46 PM, Taka Shinagawa <taka.epsilon@gmail.com>wrote:

> As I reported in the Spark 0.8-1 RC2 thread, the 'sbt/sbt assembly' hangs
> at the last step. It happens on a Macbook with Hadoop 2.2.0 (& Java
> 1.7.0_45) installed. The build was successful on another system with Hadoop
> 1.1.1 installed.
>
> Here's the build command and the entire log. Thanks for the help.
>
> ---------------------------------------------------------------
> $ sbt/sbt assembly
> [info] Loading project definition from
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/}default-c4ca6d...
> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> [info] Done updating.
> [info] Compiling 1 Scala source to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/target/scala-2.9.2/sbt-0.12/classes...
> [info] Loading project definition from
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/}plugins...
> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> [info] Done updating.
> [info] Compiling 1 Scala source to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/target/scala-2.9.2/sbt-0.12/classes...
> [info] Set current project to root (in build
> file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/)
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}core...
> [info] Resolving org.apache.derby#derby;10.4.2.0 ...
> [info] Done updating.
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}streaming...
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}bagel...
> [info] Resolving org.scala-lang#scala-library;2.9.3 ...
> [info] Done updating.
> [info] Resolving org.eclipse.jetty#jetty-util;7.6.8.v20121106 ...
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}mllib...
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}tools...
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}examples...
> [info] Resolving org.slf4j#slf4j-api;1.7.2 ...
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}repl...
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [info] Resolving org.apache.httpcomponents#httpcore;4.1 ...
> [info] Compiling 285 Scala sources and 18 Java sources to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/target/scala-2.9.3/classes...
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [info] Updating
>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}assembly...
> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> [info] Done updating.
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:131:
> method cleanupJob in class OutputCommitter is deprecated: see corresponding
> Javadoc for more information.
> [warn]     getOutputCommitter().cleanupJob(getJobContext())
> [warn]                          ^
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1059:
> class BitTorrentBroadcast in package broadcast is deprecated: Use
> TorrentBroadcast
> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> [warn]       ^
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1060:
> class BitTorrentBroadcast in package broadcast is deprecated: Use
> TorrentBroadcast
> [warn]     new BitTorrentBroadcast[T](value_, isLocal, id)
> [warn]         ^
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:600:
> class TreeBroadcast in package broadcast is deprecated: Use
> TorrentBroadcast
> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> [warn]       ^
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:601:
> class TreeBroadcast in package broadcast is deprecated: Use
> TorrentBroadcast
> [warn]     new TreeBroadcast[T](value_, isLocal, id)
> [warn]         ^
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:598:
> method cleanupJob in class OutputCommitter is deprecated: see corresponding
> Javadoc for more information.
> [warn]     jobCommitter.cleanupJob(jobTaskContext)
> [warn]                  ^
> [warn] 6 warnings found
> [warn] warning: [options] bootstrap class path not set in conjunction with
> -source 1.5
> [warn] Note: Some input files use unchecked or unsafe operations.
> [warn] Note: Recompile with -Xlint:unchecked for details.
> [warn] 1 warning
> [info] Compiling 1 Scala source to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/bagel/target/scala-2.9.3/classes...
> [info] Compiling 49 Scala sources to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/streaming/target/scala-2.9.3/classes...
> [info] Compiling 25 Scala sources to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/mllib/target/scala-2.9.3/classes...
> [info] Compiling 10 Scala sources to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/target/scala-2.9.3/classes...
> [warn]
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala:141:
> method stop in class Thread is deprecated: see corresponding Javadoc for
> more information.
> [warn]         line.thread.stop()
> [warn]                     ^
> [warn] one warning found
> [info] Compiling 39 Scala sources and 13 Java sources to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/examples/target/scala-2.9.3/classes...
> [info] Compiling 1 Scala source to
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/classes...
> [warn] warning: [options] bootstrap class path not set in conjunction with
> -source 1.5
> [warn] 1 warning
> [info] Including: scala-compiler.jar
> [info] Including: scala-compiler.jar
> [info] Including: scala-library.jar
> [info] Including: scala-library.jar
> [info] Including: compress-lzf-0.8.4.jar
> [info] Including: py4j-0.7.jar
> [info] Including: compress-lzf-0.8.4.jar
> [info] Including: config-0.3.1.jar
> [info] Including: config-0.3.1.jar
> [info] Including: guava-14.0.1.jar
> [info] Including: guava-14.0.1.jar
> [info] Including: kryo-2.21.jar
> [info] Including: kryo-2.21.jar
> [info] Including: log4j-1.2.17.jar
> [info] Including: log4j-1.2.17.jar
> [info] Including: metrics-core-3.0.0.jar
> [info] Including: metrics-core-3.0.0.jar
> [info] Including: metrics-ganglia-3.0.0.jar
> [info] Including: metrics-ganglia-3.0.0.jar
> [info] Including: metrics-json-3.0.0.jar
> [info] Including: metrics-json-3.0.0.jar
> [info] Including: metrics-jvm-3.0.0.jar
> [info] Including: metrics-jvm-3.0.0.jar
> [info] Including: netty-3.5.4.Final.jar
> [info] Including: netty-3.5.4.Final.jar
> [info] Including: snappy-java-1.0.5.jar
> [info] Including: snappy-java-1.0.5.jar
> [info] Including: akka-actor-2.0.5.jar
> [info] Including: akka-actor-2.0.5.jar
> [info] Including: akka-remote-2.0.5.jar
> [info] Including: akka-remote-2.0.5.jar
> [info] Including: akka-slf4j-2.0.5.jar
> [info] Including: akka-slf4j-2.0.5.jar
> [info] Including: akka-zeromq-2.0.5.jar
> [info] Including: akka-zeromq-2.0.5.jar
> [info] Including: asm-4.0.jar
> [info] Including: asm-4.0.jar
> [info] Including: asm-commons-4.0.jar
> [info] Including: asm-commons-4.0.jar
> [info] Including: asm-tree-4.0.jar
> [info] Including: asm-tree-4.0.jar
> [info] Including: avro-1.7.4.jar
> [info] Including: avro-1.7.4.jar
> [info] Including: avro-ipc-1.7.4.jar
> [info] Including: avro-ipc-1.7.4.jar
> [info] Including: chill-java-0.3.1.jar
> [info] Including: chill-java-0.3.1.jar
> [info] Including: chill_2.9.3-0.3.1.jar
> [info] Including: chill_2.9.3-0.3.1.jar
> [info] Including: colt-1.2.0.jar
> [info] Including: colt-1.2.0.jar
> [info] Including: commons-beanutils-1.7.0.jar
> [info] Including: commons-beanutils-1.7.0.jar
> [info] Including: commons-beanutils-core-1.8.0.jar
> [info] Including: commons-beanutils-core-1.8.0.jar
> [info] Including: commons-codec-1.4.jar
> [info] Including: commons-codec-1.4.jar
> [info] Including: commons-collections-3.2.1.jar
> [info] Including: commons-collections-3.2.1.jar
> [info] Including: commons-compress-1.4.1.jar
> [info] Including: commons-compress-1.4.1.jar
> [info] Including: commons-configuration-1.6.jar
> [info] Including: commons-configuration-1.6.jar
> [info] Including: commons-daemon-1.0.10.jar
> [info] Including: commons-daemon-1.0.10.jar
> [info] Including: commons-digester-1.8.jar
> [info] Including: commons-digester-1.8.jar
> [info] Including: commons-el-1.0.jar
> [info] Including: commons-el-1.0.jar
> [info] Including: commons-httpclient-3.1.jar
> [info] Including: commons-httpclient-3.1.jar
> [info] Including: commons-io-2.1.jar
> [info] Including: commons-io-2.1.jar
> [info] Including: commons-lang-2.4.jar
> [info] Including: commons-lang-2.4.jar
> [info] Including: commons-logging-1.1.1.jar
> [info] Including: commons-logging-1.1.1.jar
> [info] Including: commons-math-2.1.jar
> [info] Including: commons-math-2.1.jar
> [info] Including: commons-net-1.4.1.jar
> [info] Including: commons-net-1.4.1.jar
> [info] Including: concurrent-1.3.4.jar
> [info] Including: concurrent-1.3.4.jar
> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> [info] Including: fastutil-6.4.4.jar
> [info] Including: fastutil-6.4.4.jar
> [info] Including: flume-ng-sdk-1.2.0.jar
> [info] Including: flume-ng-sdk-1.2.0.jar
> [info] Including: gmetric4j-1.0.3.jar
> [info] Including: gmetric4j-1.0.3.jar
> [info] Including: h2-lzf-1.0.jar
> [info] Including: h2-lzf-1.0.jar
> [info] Including: hadoop-client-1.0.4.jar
> [info] Including: hadoop-client-1.0.4.jar
> [info] Including: hadoop-core-1.0.4.jar
> [info] Including: hadoop-core-1.0.4.jar
> [info] Including: hsqldb-1.8.0.10.jar
> [info] Including: hsqldb-1.8.0.10.jar
> [info] Including: httpclient-4.1.jar
> [info] Including: httpclient-4.1.jar
> [info] Including: httpcore-4.1.jar
> [info] Including: httpcore-4.1.jar
> [info] Including: jackson-annotations-2.2.2.jar
> [info] Including: jackson-annotations-2.2.2.jar
> [info] Including: jackson-core-2.2.2.jar
> [info] Including: jackson-core-2.2.2.jar
> [info] Including: jackson-core-asl-1.8.8.jar
> [info] Including: jackson-core-asl-1.8.8.jar
> [info] Including: jackson-databind-2.2.2.jar
> [info] Including: jackson-databind-2.2.2.jar
> [info] Including: jackson-mapper-asl-1.8.8.jar
> [info] Including: jackson-mapper-asl-1.8.8.jar
> [info] Including: jets3t-0.7.1.jar
> [info] Including: jetty-6.1.26.jar
> [info] Including: jblas-1.2.3.jar
> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> [info] Including: jets3t-0.7.1.jar
> [info] Including: jetty-http-7.6.8.v20121106.jar
> [info] Including: jetty-io-7.6.8.v20121106.jar
> [info] Including: jetty-6.1.26.jar
> [info] Including: jetty-server-7.6.8.v20121106.jar
> [info] Including: jetty-util-6.1.26.jar
> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> [info] Including: jetty-http-7.6.8.v20121106.jar
> [info] Including: jetty-util-7.6.8.v20121106.jar
> [info] Including: jetty-io-7.6.8.v20121106.jar
> [info] Including: jetty-server-7.6.8.v20121106.jar
> [info] Including: jline-0.9.94.jar
> [info] Including: jetty-util-6.1.26.jar
> [info] Including: jetty-util-7.6.8.v20121106.jar
> [info] Including: jna-3.0.9.jar
> [info] Including: jline-0.9.94.jar
> [info] Including: jna-3.0.9.jar
> [info] Including: jnr-constants-0.8.2.jar
> [info] Including: jnr-constants-0.8.2.jar
> [info] Including: jsr305-1.3.9.jar
> [info] Including: junit-3.8.1.jar
> [info] Including: jsr305-1.3.9.jar
> [info] Including: junit-3.8.1.jar
> [info] Including: lift-json_2.9.2-2.5.jar
> [info] Including: lift-json_2.9.2-2.5.jar
> [info] Including: mesos-0.13.0.jar
> [info] Including: mesos-0.13.0.jar
> [info] Including: minlog-1.2.jar
> [info] Including: minlog-1.2.jar
> [info] Including: netty-all-4.0.0.Beta2.jar
> [info] Including: netty-all-4.0.0.Beta2.jar
> [info] Including: objenesis-1.2.jar
> [info] Including: objenesis-1.2.jar
> [info] Including: oncrpc-1.0.7.jar
> [info] Including: oncrpc-1.0.7.jar
> [info] Including: oro-2.0.8.jar
> [info] Including: oro-2.0.8.jar
> [info] Including: paranamer-2.4.1.jar
> [info] Including: paranamer-2.4.1.jar
> [info] Including: protobuf-java-2.4.1.jar
> [info] Including: protobuf-java-2.4.1.jar
> [info] Including: reflectasm-1.07-shaded.jar
> [info] Including: reflectasm-1.07-shaded.jar
> [info] Including: scalap-2.9.2.jar
> [info] Including: scalap-2.9.2.jar
> [info] Including: servlet-api-2.5-20110124.jar
> [info] Including: servlet-api-2.5-20110124.jar
> [info] Including: sjson_2.9.1-0.15.jar
> [info] Including: sjson_2.9.1-0.15.jar
> [info] Including: slf4j-api-1.7.5.jar
> [info] Including: slf4j-api-1.7.5.jar
> [info] Including: slf4j-log4j12-1.7.2.jar
> [info] Including: slf4j-log4j12-1.7.2.jar
> [info] Including: twitter4j-core-3.0.3.jar
> [info] Including: twitter4j-core-3.0.3.jar
> [info] Including: twitter4j-stream-3.0.3.jar
> [info] Including: twitter4j-stream-3.0.3.jar
> [info] Including: velocity-1.7.jar
> [info] Including: velocity-1.7.jar
> [info] Including: xmlenc-0.52.jar
> [info] Including: xmlenc-0.52.jar
> [info] Including: xz-1.0.jar
> [info] Including: xz-1.0.jar
> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> [info] Including: zkclient-0.1.jar
> [info] Including: zkclient-0.1.jar
> [info] Including: zookeeper-3.4.5.jar
> [info] Including: zookeeper-3.4.5.jar
> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> [info] Including: scala-jline.jar
> [info] Including: kafka-0.7.2-spark.jar
> [info] Including: kafka-0.7.2-spark.jar
> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> with strategy 'first'
> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> with strategy 'first'
> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> 'first'
> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
> strategy 'first'
>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
> 'first'
> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
> 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
> 'first'
> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
> 'first'
> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> with strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> 'first'
> [warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> 'first'
> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
> strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
> strategy 'first'
> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> with strategy 'first'
> [warn] Merging 'log4j.properties' with strategy 'discard'
> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
> strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
> strategy 'first'
> [warn] Merging 'reference.conf' with strategy 'concat'
> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
> strategy 'first'
> [warn] Merging 'about.html' with strategy 'first'
> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
> 'first'
> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/collections/BufferUnderflowException.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
> strategy 'first'
> [warn] Strategy 'concat' was applied to a file
> [warn] Strategy 'discard' was applied to 3 files
> [warn] Strategy 'first' was applied to 212 files
> [info] Checking every *.class/*.jar file's SHA-1.
> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> with strategy 'first'
> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> with strategy 'first'
> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> 'first'
> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
> strategy 'first'
>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
> 'first'
> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
> 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
> 'first'
> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
> 'first'
> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> with strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> with strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> 'first'
> [warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> 'first'
> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
> 'first'
> [warn] Merging
>
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
> strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
> strategy 'first'
> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> with strategy 'first'
> [warn] Merging 'log4j.properties' with strategy 'discard'
> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
> 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
> strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> with strategy 'first'
> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
> strategy 'first'
> [warn] Merging 'reference.conf' with strategy 'concat'
> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
> strategy 'first'
> [warn] Merging 'about.html' with strategy 'first'
> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
> 'first'
> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> with strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> 'first'
> [warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> strategy 'first'
> [warn] Merging
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
> 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
> strategy 'first'
> [warn] Merging
>
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> with strategy 'first'
> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> strategy 'first'
> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> strategy 'first'
> [warn] Merging
>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> with strategy 'first'
> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
> strategy 'first'
> [warn] Merging
> 'org/apache/commons/collections/BufferUnderflowException.class' with
> strategy 'first'
> [warn] Merging
> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> strategy 'first'
> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> 'first'
> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> [warn] Merging
> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> strategy 'first'
> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
> strategy 'first'
> [warn] Strategy 'concat' was applied to a file
> [warn] Strategy 'discard' was applied to 3 files
> [warn] Strategy 'first' was applied to 212 files
> [info] Checking every *.class/*.jar file's SHA-1.
> [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> [info] Packaging
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> ...
> [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> [info] Packaging
>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> ...
>

--bcaec53f2bbdc950d104ed0f9944--

From dev-return-844-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 01:29:03 2013
Return-Path: <dev-return-844-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 28C77108E9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 01:29:03 +0000 (UTC)
Received: (qmail 82188 invoked by uid 500); 9 Dec 2013 01:29:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82152 invoked by uid 500); 9 Dec 2013 01:29:02 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 82144 invoked by uid 99); 9 Dec 2013 01:29:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:29:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.42 as permitted sender)
Received: from [209.85.219.42] (HELO mail-oa0-f42.google.com) (209.85.219.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:28:58 +0000
Received: by mail-oa0-f42.google.com with SMTP id i4so3169677oah.15
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 17:28:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=jQR/i08V/ahStkaPH81tx4+GhyjbrXCozk+fgejQUV8=;
        b=b3hpJCznNe9KmHxKAiwasIegIKdfRZL/N/hCgZkHbRmGmpQ1lFA/GbZ3ZcrRhy2Cbo
         ONpBVS2I50smfTMvBFmsjIdMzCHI08jaAwl5N6cYDKxZczmLJgJSdcrpb4ZK1ysEXxLf
         C2VganznG90/L67oIO1Vns+uBpOsypap8+tnLw7RZG9bkoBeyBkMFaojRtb7xlJij80c
         lcvvxkSbY7lykomODotrru/PNmWsbSfcPrFb7xctB/DuoLk6UYmU4nwj2zXD/ZFNlyGY
         SB0IwXeCt1exb99E6VPNs0CkbMR9co7fUGcIQFLnEOEVf8T0w0zDTw7jyom4G/2reAoe
         7l/Q==
MIME-Version: 1.0
X-Received: by 10.182.92.231 with SMTP id cp7mr133931obb.82.1386552518035;
 Sun, 08 Dec 2013 17:28:38 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 17:28:37 -0800 (PST)
In-Reply-To: <CAAsvFPmkfWkXW=OAVLqNfyU2QB7mv_jMhuXkrzaCRBF9b05eYg@mail.gmail.com>
References: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
	<CAAsvFPmkfWkXW=OAVLqNfyU2QB7mv_jMhuXkrzaCRBF9b05eYg@mail.gmail.com>
Date: Sun, 8 Dec 2013 17:28:37 -0800
Message-ID: <CABPQxsuYoRVbvJ1k96uNwcpwvSN97wn4qZGEP_GL_S-Osb1cOw@mail.gmail.com>
Subject: Re: Spark Build Issue ('sbt/sbt assembly' hangs)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Taka,

Most likely this is just the assembly task taking a long time as mark
said. What happens if you run 'package' or 'compile'? It could be that
on Mac's there is something where this is slow... I'm not sure.

Also, unless you specify the hadoop version in the build it will build
Hadoop 1.0.4. You keep mentioning Hadoop 2.2.0, but you didn't specify
that when you built so Spark has no way of knowing what you want.

Checkout the README for documentation on how to do that.

Also - does this all work well in the 0.8.0 release? If this is not
something specific to the 0.8.1 release than it would be good to know.

- Patrick

On Sun, Dec 8, 2013 at 5:06 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> The assembly "hang" is something that I've also noticed over at least the
> past few weeks.  If you are seeing what I am seeing, then the build is not
> actually hung, but the building of assemblies takes a long time, a very
> long time, a very very long time on Macs.  It's just the build of
> assemblies via sbt on OSX that does this -- maven builds on Mac or any kind
> of build on Linux go much faster.  On a Mac that also has other things to
> do, I've seen the sbt assembly packaging take upwards of an hour.  Not good.
>
>
> On Sun, Dec 8, 2013 at 4:46 PM, Taka Shinagawa <taka.epsilon@gmail.com>wrote:
>
>> As I reported in the Spark 0.8-1 RC2 thread, the 'sbt/sbt assembly' hangs
>> at the last step. It happens on a Macbook with Hadoop 2.2.0 (& Java
>> 1.7.0_45) installed. The build was successful on another system with Hadoop
>> 1.1.1 installed.
>>
>> Here's the build command and the entire log. Thanks for the help.
>>
>> ---------------------------------------------------------------
>> $ sbt/sbt assembly
>> [info] Loading project definition from
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/}default-c4ca6d...
>> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
>> [info] Done updating.
>> [info] Compiling 1 Scala source to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/target/scala-2.9.2/sbt-0.12/classes...
>> [info] Loading project definition from
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/}plugins...
>> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
>> [info] Done updating.
>> [info] Compiling 1 Scala source to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/target/scala-2.9.2/sbt-0.12/classes...
>> [info] Set current project to root (in build
>> file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/)
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}core...
>> [info] Resolving org.apache.derby#derby;10.4.2.0 ...
>> [info] Done updating.
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}streaming...
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}bagel...
>> [info] Resolving org.scala-lang#scala-library;2.9.3 ...
>> [info] Done updating.
>> [info] Resolving org.eclipse.jetty#jetty-util;7.6.8.v20121106 ...
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}mllib...
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}tools...
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}examples...
>> [info] Resolving org.slf4j#slf4j-api;1.7.2 ...
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}repl...
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [info] Resolving org.apache.httpcomponents#httpcore;4.1 ...
>> [info] Compiling 285 Scala sources and 18 Java sources to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/target/scala-2.9.3/classes...
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [info] Updating
>>
>> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}assembly...
>> [info] Resolving org.mockito#mockito-all;1.8.5 ...
>> [info] Done updating.
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:131:
>> method cleanupJob in class OutputCommitter is deprecated: see corresponding
>> Javadoc for more information.
>> [warn]     getOutputCommitter().cleanupJob(getJobContext())
>> [warn]                          ^
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1059:
>> class BitTorrentBroadcast in package broadcast is deprecated: Use
>> TorrentBroadcast
>> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
>> [warn]       ^
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1060:
>> class BitTorrentBroadcast in package broadcast is deprecated: Use
>> TorrentBroadcast
>> [warn]     new BitTorrentBroadcast[T](value_, isLocal, id)
>> [warn]         ^
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:600:
>> class TreeBroadcast in package broadcast is deprecated: Use
>> TorrentBroadcast
>> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
>> [warn]       ^
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:601:
>> class TreeBroadcast in package broadcast is deprecated: Use
>> TorrentBroadcast
>> [warn]     new TreeBroadcast[T](value_, isLocal, id)
>> [warn]         ^
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:598:
>> method cleanupJob in class OutputCommitter is deprecated: see corresponding
>> Javadoc for more information.
>> [warn]     jobCommitter.cleanupJob(jobTaskContext)
>> [warn]                  ^
>> [warn] 6 warnings found
>> [warn] warning: [options] bootstrap class path not set in conjunction with
>> -source 1.5
>> [warn] Note: Some input files use unchecked or unsafe operations.
>> [warn] Note: Recompile with -Xlint:unchecked for details.
>> [warn] 1 warning
>> [info] Compiling 1 Scala source to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/bagel/target/scala-2.9.3/classes...
>> [info] Compiling 49 Scala sources to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/streaming/target/scala-2.9.3/classes...
>> [info] Compiling 25 Scala sources to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/mllib/target/scala-2.9.3/classes...
>> [info] Compiling 10 Scala sources to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/target/scala-2.9.3/classes...
>> [warn]
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala:141:
>> method stop in class Thread is deprecated: see corresponding Javadoc for
>> more information.
>> [warn]         line.thread.stop()
>> [warn]                     ^
>> [warn] one warning found
>> [info] Compiling 39 Scala sources and 13 Java sources to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/examples/target/scala-2.9.3/classes...
>> [info] Compiling 1 Scala source to
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/classes...
>> [warn] warning: [options] bootstrap class path not set in conjunction with
>> -source 1.5
>> [warn] 1 warning
>> [info] Including: scala-compiler.jar
>> [info] Including: scala-compiler.jar
>> [info] Including: scala-library.jar
>> [info] Including: scala-library.jar
>> [info] Including: compress-lzf-0.8.4.jar
>> [info] Including: py4j-0.7.jar
>> [info] Including: compress-lzf-0.8.4.jar
>> [info] Including: config-0.3.1.jar
>> [info] Including: config-0.3.1.jar
>> [info] Including: guava-14.0.1.jar
>> [info] Including: guava-14.0.1.jar
>> [info] Including: kryo-2.21.jar
>> [info] Including: kryo-2.21.jar
>> [info] Including: log4j-1.2.17.jar
>> [info] Including: log4j-1.2.17.jar
>> [info] Including: metrics-core-3.0.0.jar
>> [info] Including: metrics-core-3.0.0.jar
>> [info] Including: metrics-ganglia-3.0.0.jar
>> [info] Including: metrics-ganglia-3.0.0.jar
>> [info] Including: metrics-json-3.0.0.jar
>> [info] Including: metrics-json-3.0.0.jar
>> [info] Including: metrics-jvm-3.0.0.jar
>> [info] Including: metrics-jvm-3.0.0.jar
>> [info] Including: netty-3.5.4.Final.jar
>> [info] Including: netty-3.5.4.Final.jar
>> [info] Including: snappy-java-1.0.5.jar
>> [info] Including: snappy-java-1.0.5.jar
>> [info] Including: akka-actor-2.0.5.jar
>> [info] Including: akka-actor-2.0.5.jar
>> [info] Including: akka-remote-2.0.5.jar
>> [info] Including: akka-remote-2.0.5.jar
>> [info] Including: akka-slf4j-2.0.5.jar
>> [info] Including: akka-slf4j-2.0.5.jar
>> [info] Including: akka-zeromq-2.0.5.jar
>> [info] Including: akka-zeromq-2.0.5.jar
>> [info] Including: asm-4.0.jar
>> [info] Including: asm-4.0.jar
>> [info] Including: asm-commons-4.0.jar
>> [info] Including: asm-commons-4.0.jar
>> [info] Including: asm-tree-4.0.jar
>> [info] Including: asm-tree-4.0.jar
>> [info] Including: avro-1.7.4.jar
>> [info] Including: avro-1.7.4.jar
>> [info] Including: avro-ipc-1.7.4.jar
>> [info] Including: avro-ipc-1.7.4.jar
>> [info] Including: chill-java-0.3.1.jar
>> [info] Including: chill-java-0.3.1.jar
>> [info] Including: chill_2.9.3-0.3.1.jar
>> [info] Including: chill_2.9.3-0.3.1.jar
>> [info] Including: colt-1.2.0.jar
>> [info] Including: colt-1.2.0.jar
>> [info] Including: commons-beanutils-1.7.0.jar
>> [info] Including: commons-beanutils-1.7.0.jar
>> [info] Including: commons-beanutils-core-1.8.0.jar
>> [info] Including: commons-beanutils-core-1.8.0.jar
>> [info] Including: commons-codec-1.4.jar
>> [info] Including: commons-codec-1.4.jar
>> [info] Including: commons-collections-3.2.1.jar
>> [info] Including: commons-collections-3.2.1.jar
>> [info] Including: commons-compress-1.4.1.jar
>> [info] Including: commons-compress-1.4.1.jar
>> [info] Including: commons-configuration-1.6.jar
>> [info] Including: commons-configuration-1.6.jar
>> [info] Including: commons-daemon-1.0.10.jar
>> [info] Including: commons-daemon-1.0.10.jar
>> [info] Including: commons-digester-1.8.jar
>> [info] Including: commons-digester-1.8.jar
>> [info] Including: commons-el-1.0.jar
>> [info] Including: commons-el-1.0.jar
>> [info] Including: commons-httpclient-3.1.jar
>> [info] Including: commons-httpclient-3.1.jar
>> [info] Including: commons-io-2.1.jar
>> [info] Including: commons-io-2.1.jar
>> [info] Including: commons-lang-2.4.jar
>> [info] Including: commons-lang-2.4.jar
>> [info] Including: commons-logging-1.1.1.jar
>> [info] Including: commons-logging-1.1.1.jar
>> [info] Including: commons-math-2.1.jar
>> [info] Including: commons-math-2.1.jar
>> [info] Including: commons-net-1.4.1.jar
>> [info] Including: commons-net-1.4.1.jar
>> [info] Including: concurrent-1.3.4.jar
>> [info] Including: concurrent-1.3.4.jar
>> [info] Including: dispatch-json_2.9.1-0.8.5.jar
>> [info] Including: dispatch-json_2.9.1-0.8.5.jar
>> [info] Including: fastutil-6.4.4.jar
>> [info] Including: fastutil-6.4.4.jar
>> [info] Including: flume-ng-sdk-1.2.0.jar
>> [info] Including: flume-ng-sdk-1.2.0.jar
>> [info] Including: gmetric4j-1.0.3.jar
>> [info] Including: gmetric4j-1.0.3.jar
>> [info] Including: h2-lzf-1.0.jar
>> [info] Including: h2-lzf-1.0.jar
>> [info] Including: hadoop-client-1.0.4.jar
>> [info] Including: hadoop-client-1.0.4.jar
>> [info] Including: hadoop-core-1.0.4.jar
>> [info] Including: hadoop-core-1.0.4.jar
>> [info] Including: hsqldb-1.8.0.10.jar
>> [info] Including: hsqldb-1.8.0.10.jar
>> [info] Including: httpclient-4.1.jar
>> [info] Including: httpclient-4.1.jar
>> [info] Including: httpcore-4.1.jar
>> [info] Including: httpcore-4.1.jar
>> [info] Including: jackson-annotations-2.2.2.jar
>> [info] Including: jackson-annotations-2.2.2.jar
>> [info] Including: jackson-core-2.2.2.jar
>> [info] Including: jackson-core-2.2.2.jar
>> [info] Including: jackson-core-asl-1.8.8.jar
>> [info] Including: jackson-core-asl-1.8.8.jar
>> [info] Including: jackson-databind-2.2.2.jar
>> [info] Including: jackson-databind-2.2.2.jar
>> [info] Including: jackson-mapper-asl-1.8.8.jar
>> [info] Including: jackson-mapper-asl-1.8.8.jar
>> [info] Including: jets3t-0.7.1.jar
>> [info] Including: jetty-6.1.26.jar
>> [info] Including: jblas-1.2.3.jar
>> [info] Including: jetty-continuation-7.6.8.v20121106.jar
>> [info] Including: jets3t-0.7.1.jar
>> [info] Including: jetty-http-7.6.8.v20121106.jar
>> [info] Including: jetty-io-7.6.8.v20121106.jar
>> [info] Including: jetty-6.1.26.jar
>> [info] Including: jetty-server-7.6.8.v20121106.jar
>> [info] Including: jetty-util-6.1.26.jar
>> [info] Including: jetty-continuation-7.6.8.v20121106.jar
>> [info] Including: jetty-http-7.6.8.v20121106.jar
>> [info] Including: jetty-util-7.6.8.v20121106.jar
>> [info] Including: jetty-io-7.6.8.v20121106.jar
>> [info] Including: jetty-server-7.6.8.v20121106.jar
>> [info] Including: jline-0.9.94.jar
>> [info] Including: jetty-util-6.1.26.jar
>> [info] Including: jetty-util-7.6.8.v20121106.jar
>> [info] Including: jna-3.0.9.jar
>> [info] Including: jline-0.9.94.jar
>> [info] Including: jna-3.0.9.jar
>> [info] Including: jnr-constants-0.8.2.jar
>> [info] Including: jnr-constants-0.8.2.jar
>> [info] Including: jsr305-1.3.9.jar
>> [info] Including: junit-3.8.1.jar
>> [info] Including: jsr305-1.3.9.jar
>> [info] Including: junit-3.8.1.jar
>> [info] Including: lift-json_2.9.2-2.5.jar
>> [info] Including: lift-json_2.9.2-2.5.jar
>> [info] Including: mesos-0.13.0.jar
>> [info] Including: mesos-0.13.0.jar
>> [info] Including: minlog-1.2.jar
>> [info] Including: minlog-1.2.jar
>> [info] Including: netty-all-4.0.0.Beta2.jar
>> [info] Including: netty-all-4.0.0.Beta2.jar
>> [info] Including: objenesis-1.2.jar
>> [info] Including: objenesis-1.2.jar
>> [info] Including: oncrpc-1.0.7.jar
>> [info] Including: oncrpc-1.0.7.jar
>> [info] Including: oro-2.0.8.jar
>> [info] Including: oro-2.0.8.jar
>> [info] Including: paranamer-2.4.1.jar
>> [info] Including: paranamer-2.4.1.jar
>> [info] Including: protobuf-java-2.4.1.jar
>> [info] Including: protobuf-java-2.4.1.jar
>> [info] Including: reflectasm-1.07-shaded.jar
>> [info] Including: reflectasm-1.07-shaded.jar
>> [info] Including: scalap-2.9.2.jar
>> [info] Including: scalap-2.9.2.jar
>> [info] Including: servlet-api-2.5-20110124.jar
>> [info] Including: servlet-api-2.5-20110124.jar
>> [info] Including: sjson_2.9.1-0.15.jar
>> [info] Including: sjson_2.9.1-0.15.jar
>> [info] Including: slf4j-api-1.7.5.jar
>> [info] Including: slf4j-api-1.7.5.jar
>> [info] Including: slf4j-log4j12-1.7.2.jar
>> [info] Including: slf4j-log4j12-1.7.2.jar
>> [info] Including: twitter4j-core-3.0.3.jar
>> [info] Including: twitter4j-core-3.0.3.jar
>> [info] Including: twitter4j-stream-3.0.3.jar
>> [info] Including: twitter4j-stream-3.0.3.jar
>> [info] Including: velocity-1.7.jar
>> [info] Including: velocity-1.7.jar
>> [info] Including: xmlenc-0.52.jar
>> [info] Including: xmlenc-0.52.jar
>> [info] Including: xz-1.0.jar
>> [info] Including: xz-1.0.jar
>> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
>> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
>> [info] Including: zkclient-0.1.jar
>> [info] Including: zkclient-0.1.jar
>> [info] Including: zookeeper-3.4.5.jar
>> [info] Including: zookeeper-3.4.5.jar
>> [info] Including: javax.servlet-2.5.0.v201103041518.jar
>> [info] Including: javax.servlet-2.5.0.v201103041518.jar
>> [info] Including: scala-jline.jar
>> [info] Including: kafka-0.7.2-spark.jar
>> [info] Including: kafka-0.7.2-spark.jar
>> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
>> with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
>> with strategy 'first'
>> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
>> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
>>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
>> strategy 'first'
>>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
>> 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
>> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/StringConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
>> 'first'
>> [warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
>> strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
>> strategy 'first'
>> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
>> with strategy 'first'
>> [warn] Merging 'log4j.properties' with strategy 'discard'
>> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
>> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
>> strategy 'first'
>> [warn] Merging 'reference.conf' with strategy 'concat'
>> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
>> strategy 'first'
>> [warn] Merging 'about.html' with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/collections/BufferUnderflowException.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
>> strategy 'first'
>> [warn] Strategy 'concat' was applied to a file
>> [warn] Strategy 'discard' was applied to 3 files
>> [warn] Strategy 'first' was applied to 212 files
>> [info] Checking every *.class/*.jar file's SHA-1.
>> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$EntrySet.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
>> with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
>> with strategy 'first'
>> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
>> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/locale/LocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
>>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class' with
>> strategy 'first'
>>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestListener.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContext.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with strategy
>> 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextListener.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/FileConverter.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
>> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
>> with strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
>> 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/StringConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
>> with strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
>> 'first'
>> [warn] Merging 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with strategy
>> 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class' with
>> strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
>> strategy 'first'
>> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/StringArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
>> with strategy 'first'
>> [warn] Merging 'log4j.properties' with strategy 'discard'
>> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
>> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/LongConverter.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
>> with strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
>> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
>> strategy 'first'
>> [warn] Merging 'reference.conf' with strategy 'concat'
>> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
>> strategy 'first'
>> [warn] Merging 'about.html' with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
>> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletException.class' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with strategy
>> 'first'
>> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
>> with strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
>> 'first'
>> [warn] Merging 'org/apache/commons/beanutils/converters/URLConverter.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
>> strategy 'first'
>> [warn] Merging
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/converters/ByteConverter.class' with strategy
>> 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
>> with strategy 'first'
>> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
>> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
>> strategy 'first'
>> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
>> strategy 'first'
>> [warn] Merging
>>
>> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
>> with strategy 'first'
>> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/collections/BufferUnderflowException.class' with
>> strategy 'first'
>> [warn] Merging
>> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
>> strategy 'first'
>> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
>> 'first'
>> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
>> [warn] Merging
>> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
>> strategy 'first'
>> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
>> strategy 'first'
>> [warn] Strategy 'concat' was applied to a file
>> [warn] Strategy 'discard' was applied to 3 files
>> [warn] Strategy 'first' was applied to 212 files
>> [info] Checking every *.class/*.jar file's SHA-1.
>> [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> [info] Packaging
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> ...
>> [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> [info] Packaging
>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> ...
>>

From dev-return-845-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 01:29:26 2013
Return-Path: <dev-return-845-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8F044108F7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 01:29:26 +0000 (UTC)
Received: (qmail 84205 invoked by uid 500); 9 Dec 2013 01:29:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84172 invoked by uid 500); 9 Dec 2013 01:29:26 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 84163 invoked by uid 99); 9 Dec 2013 01:29:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:29:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 01:29:22 +0000
Received: by mail-ob0-f177.google.com with SMTP id va2so3018057obc.8
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 17:29:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=iM0iEjxdaKGz/lUeL5wODvBzjJ9YWUzZkfQvGI6geJA=;
        b=fROGfpxgyckFA+ZV47O0ut15pLzBWRKaOkYzF/XPUgsDM6yuyifsTdmaLTgKQl3hFT
         mYwDFBoPEoracx2Ej0EqOH7CzC6o1SCPucXLlAetDCuKItYB2LI9vQnAvIu3QnuSC0eL
         DYkVk7oW0fKxBAw5i9IrP77HNu60E8JDOxzWb5pa9/uhjRw82US3DeNj5hdK3FvDv519
         4pjH1xAiNrpDRCmTbIcLD2ZpLBIlPiwDndJtKx/RjBmitjV4hBSosouqeRgi8U+CNztX
         KHnWDN1YZFDWMCpEg4tG7OWKhyQCl7RMrBhDcS9AxuEv/23MFUtG94WwbHa9lBNPr/B6
         PwAg==
MIME-Version: 1.0
X-Received: by 10.60.135.130 with SMTP id ps2mr914711oeb.46.1386552541438;
 Sun, 08 Dec 2013 17:29:01 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 17:29:01 -0800 (PST)
In-Reply-To: <CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
Date: Sun, 8 Dec 2013 17:29:01 -0800
Message-ID: <CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

For my own part I'll give a +1 to this RC.

On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com> wrote:
> OK. I will post the entire output via separate email. I just upgraded
> Hadoop to 2.2.0 recently. So there might be something I need to
> remove/clean up.
>
>
> On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> Hey Take,
>>
>> Could you start a separate thread to debug your build issue? In that
>> thread, could you paste the exact build command and entire output? The log
>> you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
>> based on the assembly file name it is logging.
>>
>> ---
>> sent from my phone
>> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com> wrote:
>>
>> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
>> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
>> command
>> > hangs at the last step.
>> >
>> > ...
>> > ...
>> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> > [info] Packaging
>> >
>> >
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> > ...
>> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> > [info] Packaging
>> >
>> >
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> > ...
>> > (hangs here)
>> > --------------------------
>> >
>> >
>> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I was
>> > able to build it successfully.
>> > ..
>> > ..
>> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> > [info] Packaging
>> >
>> >
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> > ...
>> > [info] Done packaging.
>> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>> > --------------------------
>> >
>> >
>> >
>> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
>> > wrote:
>> >
>> > > Please vote on releasing the following candidate as Apache Spark
>> > > (incubating) version 0.8.1.
>> > >
>> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>> > >
>> > >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> > >
>> > > The release files, including signatures, digests, etc can be found at:
>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> > >
>> > > Release artifacts are signed with the following key:
>> > > https://people.apache.org/keys/committer/pwendell.asc
>> > >
>> > > The staging repository for this release can be found at:
>> > > https://repository.apache.org/content/repositories/orgapachespark-024/
>> > >
>> > > The documentation corresponding to this release can be found at:
>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> > >
>> > > For information about the contents of this release see:
>> > > <attached> draft of release notes
>> > > <attached> draft of release credits
>> > > https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> > >
>> > > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>> > >
>> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
>> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>> > >
>> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> > > [ ] -1 Do not release this package because ...
>> > >
>> > > To learn more about Apache Spark, please see
>> > > http://spark.incubator.apache.org/
>> > >
>> >
>>

From dev-return-846-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 02:05:39 2013
Return-Path: <dev-return-846-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A3497109D4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 02:05:39 +0000 (UTC)
Received: (qmail 30840 invoked by uid 500); 9 Dec 2013 02:05:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30726 invoked by uid 500); 9 Dec 2013 02:05:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 30713 invoked by uid 99); 9 Dec 2013 02:05:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 02:05:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.52] (HELO mail-bk0-f52.google.com) (209.85.214.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 02:05:33 +0000
Received: by mail-bk0-f52.google.com with SMTP id u14so1127845bkz.39
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 18:05:10 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=nX8pzVIPSRXuVhnn0VaHthUM4nX2lRGiwqiCjeFKM9c=;
        b=B8QDnoCfoMN5YR0Of0lo3oslxbC6XaRQJ9Gm3ZKBXTk6RSPQYGtEacD+KCQBtQbvtX
         k3CiO2hIdkdwWlK0WKzNnjPeq2UkRZi3ufeEgfQ3RuhDEkZWNAmodVQIOkwa996RGyG2
         qW8vlMNnv4uexh329RHaXF0izFYCIIqBdZtlQ5oc0U9QgHf0SgjAeDllFKKU/KvyD4bD
         EAH2hUZF82TO7ibgMrLO0g3JUQGwDIQhi8sHgqgpfJDqsKHEvXPShk7dijlIZ3P/zghK
         16GWgIMh830vcY62RYGLWwN2qpdz6HikrlneNEHFbiWX/OI8cDBpchwvjJQpqGA/uN6A
         KzmA==
X-Gm-Message-State: ALoCoQnaUiNmtcSNph6sGmZYy1w4hwxH5LD1mN2SObFMnzLSecqj3706YQqhjtLoA74AAusp24Nj
MIME-Version: 1.0
X-Received: by 10.205.43.73 with SMTP id ub9mr1429701bkb.91.1386554710004;
 Sun, 08 Dec 2013 18:05:10 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 18:05:09 -0800 (PST)
In-Reply-To: <CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
Date: Sun, 8 Dec 2013 18:05:09 -0800
Message-ID: <CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec529960df3cac904ed106cef
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec529960df3cac904ed106cef
Content-Type: text/plain; charset=ISO-8859-1

SPARK-962 should be resolved before release.  See also:
https://github.com/apache/incubator-spark/pull/195

With the references to the way I changed Debian packaging for ClearStory,
we should be at least 90% of the way toward doing it right for Apache.


On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> For my own part I'll give a +1 to this RC.
>
> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com>
> wrote:
> > OK. I will post the entire output via separate email. I just upgraded
> > Hadoop to 2.2.0 recently. So there might be something I need to
> > remove/clean up.
> >
> >
> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >
> >> Hey Take,
> >>
> >> Could you start a separate thread to debug your build issue? In that
> >> thread, could you paste the exact build command and entire output? The
> log
> >> you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
> >> based on the assembly file name it is logging.
> >>
> >> ---
> >> sent from my phone
> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
> wrote:
> >>
> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
> >> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
> >> command
> >> > hangs at the last step.
> >> >
> >> > ...
> >> > ...
> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> >> > [info] Packaging
> >> >
> >> >
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> >> > ...
> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> >> > [info] Packaging
> >> >
> >> >
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> >> > ...
> >> > (hangs here)
> >> > --------------------------
> >> >
> >> >
> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I
> was
> >> > able to build it successfully.
> >> > ..
> >> > ..
> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> >> > [info] Packaging
> >> >
> >> >
> >>
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> >> > ...
> >> > [info] Done packaging.
> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
> >> > --------------------------
> >> >
> >> >
> >> >
> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
> >> > wrote:
> >> >
> >> > > Please vote on releasing the following candidate as Apache Spark
> >> > > (incubating) version 0.8.1.
> >> > >
> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
> >> > >
> >> > >
> >> >
> >>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> >> > >
> >> > > The release files, including signatures, digests, etc can be found
> at:
> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> >> > >
> >> > > Release artifacts are signed with the following key:
> >> > > https://people.apache.org/keys/committer/pwendell.asc
> >> > >
> >> > > The staging repository for this release can be found at:
> >> > >
> https://repository.apache.org/content/repositories/orgapachespark-024/
> >> > >
> >> > > The documentation corresponding to this release can be found at:
> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> >> > >
> >> > > For information about the contents of this release see:
> >> > > <attached> draft of release notes
> >> > > <attached> draft of release credits
> >> > >
> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >> > >
> >> > > Please vote on releasing this package as Apache Spark
> 0.8.1-incubating!
> >> > >
> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> >> > >
> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >> > > [ ] -1 Do not release this package because ...
> >> > >
> >> > > To learn more about Apache Spark, please see
> >> > > http://spark.incubator.apache.org/
> >> > >
> >> >
> >>
>

--bcaec529960df3cac904ed106cef--

From dev-return-847-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 02:07:47 2013
Return-Path: <dev-return-847-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31B8D109DA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 02:07:47 +0000 (UTC)
Received: (qmail 33928 invoked by uid 500); 9 Dec 2013 02:07:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33893 invoked by uid 500); 9 Dec 2013 02:07:46 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 33885 invoked by uid 99); 9 Dec 2013 02:07:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 02:07:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.43] (HELO mail-bk0-f43.google.com) (209.85.214.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 02:07:41 +0000
Received: by mail-bk0-f43.google.com with SMTP id mz12so1119597bkb.2
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 18:07:20 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=BIhE1i23Qrjd9uOuz4XVS/VwDG0ybl5Rh09GNYz+QwM=;
        b=EWjRa1KufE3nWz4C9uXi+qMYcOMuIAGW1Dp1HevSMATINi+JcicF79FllOBKVLHpQl
         hZeU9QcoD6xmr1EFalp0fOHVegC4d0FJPfDzp5AyUNYJZmc+jLJZQ8qXOv1nQtWGFdYA
         gjCnbfzl3n/3L3lPbmip8JhG5tTRQlnbBv0G0uCs0jJu0ZCbnCG7YgUpFCZOmIHTb1Xc
         e0JgVrzm4eZIMXTwMpaUco/6oQHaE2POPTA3e9nqpUyM7Cy8+Kc16jQXNpZwFhuAK39B
         0iYlzzOza8BQjFxvGViHzsqvaea91LbO6GyPyWWPFnMY+fucRKPl1UgmCN2Th5NLnOZd
         I4cw==
X-Gm-Message-State: ALoCoQnyPj6XYgUTWchK/LeAauNd4P5clk9BamIaryNZzza1aYD2CKG2SQPTMsKXtIMRUzkPD6AK
MIME-Version: 1.0
X-Received: by 10.205.14.197 with SMTP id pr5mr5109699bkb.33.1386554840656;
 Sun, 08 Dec 2013 18:07:20 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 18:07:20 -0800 (PST)
In-Reply-To: <CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
Date: Sun, 8 Dec 2013 18:07:20 -0800
Message-ID: <CAAsvFP=PBVByS2jE+-Ti4hzum7ucH9Xi5f+VTn9SLKzPOftcTQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=20cf301cc42cbd93fb04ed1074ac
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf301cc42cbd93fb04ed1074ac
Content-Type: text/plain; charset=ISO-8859-1

Probably not blockers, but there are still some non-deterministic test
failures -- e.g. streaming CheckpointSuite.


On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> SPARK-962 should be resolved before release.  See also:
> https://github.com/apache/incubator-spark/pull/195
>
> With the references to the way I changed Debian packaging for ClearStory,
> we should be at least 90% of the way toward doing it right for Apache.
>
>
> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com>wrote:
>
>> For my own part I'll give a +1 to this RC.
>>
>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com>
>> wrote:
>> > OK. I will post the entire output via separate email. I just upgraded
>> > Hadoop to 2.2.0 recently. So there might be something I need to
>> > remove/clean up.
>> >
>> >
>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >
>> >> Hey Take,
>> >>
>> >> Could you start a separate thread to debug your build issue? In that
>> >> thread, could you paste the exact build command and entire output? The
>> log
>> >> you posted here suggests the first build detected hadoop 1.0.4 not
>> 2.2.0
>> >> based on the assembly file name it is logging.
>> >>
>> >> ---
>> >> sent from my phone
>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
>> wrote:
>> >>
>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
>> >> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
>> >> command
>> >> > hangs at the last step.
>> >> >
>> >> > ...
>> >> > ...
>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> >> > ...
>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> >> > ...
>> >> > (hangs here)
>> >> > --------------------------
>> >> >
>> >> >
>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I
>> was
>> >> > able to build it successfully.
>> >> > ..
>> >> > ..
>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> >> > ...
>> >> > [info] Done packaging.
>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>> >> > --------------------------
>> >> >
>> >> >
>> >> >
>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com
>> >
>> >> > wrote:
>> >> >
>> >> > > Please vote on releasing the following candidate as Apache Spark
>> >> > > (incubating) version 0.8.1.
>> >> > >
>> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>> >> > >
>> >> > >
>> >> >
>> >>
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> >> > >
>> >> > > The release files, including signatures, digests, etc can be found
>> at:
>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> >> > >
>> >> > > Release artifacts are signed with the following key:
>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>> >> > >
>> >> > > The staging repository for this release can be found at:
>> >> > >
>> https://repository.apache.org/content/repositories/orgapachespark-024/
>> >> > >
>> >> > > The documentation corresponding to this release can be found at:
>> >> > >
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> >> > >
>> >> > > For information about the contents of this release see:
>> >> > > <attached> draft of release notes
>> >> > > <attached> draft of release credits
>> >> > >
>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> >> > >
>> >> > > Please vote on releasing this package as Apache Spark
>> 0.8.1-incubating!
>> >> > >
>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>> >> > >
>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> >> > > [ ] -1 Do not release this package because ...
>> >> > >
>> >> > > To learn more about Apache Spark, please see
>> >> > > http://spark.incubator.apache.org/
>> >> > >
>> >> >
>> >>
>>
>
>

--20cf301cc42cbd93fb04ed1074ac--

From dev-return-848-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 03:30:55 2013
Return-Path: <dev-return-848-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2D03C10B92
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 03:30:55 +0000 (UTC)
Received: (qmail 18194 invoked by uid 500); 9 Dec 2013 03:30:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18006 invoked by uid 500); 9 Dec 2013 03:30:44 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 17998 invoked by uid 99); 9 Dec 2013 03:30:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:30:43 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.53 as permitted sender)
Received: from [209.85.219.53] (HELO mail-oa0-f53.google.com) (209.85.219.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:30:39 +0000
Received: by mail-oa0-f53.google.com with SMTP id m1so3264015oag.40
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 19:30:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=J8eD2wKbXaNOiKdr1/usWeYBjq5e4eefxoX9yfJUK60=;
        b=YY4JRjw0DVuCWGxd3FhSPEtsijqT6R5xujeJBgb7GzultizlENXn7Pgo5Hc4Wxe1Dh
         eP7kynTgE6xqwTO6tovsL9JoPmQVZltHtMxw0W3Pms660KZxNjsUpS0q2JIQ0N+Qy9eG
         c+BnuotsP4n+1nvKUkk7NfngPpKLrK6b/SUHNm4ndMmxtyOSFpaUi3wV1P6sR68AaquU
         wWaaGCBUnLriZKbr/Sc/jIZpPceGz+CcUIV7HrZCt0Ac41CqUQCY1sEPUo3vhkoGL1s0
         br85RIjkt1oaZNRbofwGac9ITnNmNsNWzMEQqlON1rZVBXVGRd2An3NIzQ4cU3Sd1fKr
         W6Iw==
MIME-Version: 1.0
X-Received: by 10.182.153.196 with SMTP id vi4mr848531obb.75.1386559819101;
 Sun, 08 Dec 2013 19:30:19 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 19:30:19 -0800 (PST)
In-Reply-To: <CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
Date: Sun, 8 Dec 2013 19:30:19 -0800
Message-ID: <CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mark - ya this would be good to get in.

Does merging that particular PR put this in sufficient shape for the
0.8.1 release or are there other open patches we need to look at?

- Patrick

On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> SPARK-962 should be resolved before release.  See also:
> https://github.com/apache/incubator-spark/pull/195
>
> With the references to the way I changed Debian packaging for ClearStory,
> we should be at least 90% of the way toward doing it right for Apache.
>
>
> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> For my own part I'll give a +1 to this RC.
>>
>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com>
>> wrote:
>> > OK. I will post the entire output via separate email. I just upgraded
>> > Hadoop to 2.2.0 recently. So there might be something I need to
>> > remove/clean up.
>> >
>> >
>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >
>> >> Hey Take,
>> >>
>> >> Could you start a separate thread to debug your build issue? In that
>> >> thread, could you paste the exact build command and entire output? The
>> log
>> >> you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
>> >> based on the assembly file name it is logging.
>> >>
>> >> ---
>> >> sent from my phone
>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
>> wrote:
>> >>
>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
>> >> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
>> >> command
>> >> > hangs at the last step.
>> >> >
>> >> > ...
>> >> > ...
>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> >> > ...
>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> >> > ...
>> >> > (hangs here)
>> >> > --------------------------
>> >> >
>> >> >
>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I
>> was
>> >> > able to build it successfully.
>> >> > ..
>> >> > ..
>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> >> > [info] Packaging
>> >> >
>> >> >
>> >>
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> >> > ...
>> >> > [info] Done packaging.
>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>> >> > --------------------------
>> >> >
>> >> >
>> >> >
>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
>> >> > wrote:
>> >> >
>> >> > > Please vote on releasing the following candidate as Apache Spark
>> >> > > (incubating) version 0.8.1.
>> >> > >
>> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>> >> > >
>> >> > >
>> >> >
>> >>
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> >> > >
>> >> > > The release files, including signatures, digests, etc can be found
>> at:
>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> >> > >
>> >> > > Release artifacts are signed with the following key:
>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>> >> > >
>> >> > > The staging repository for this release can be found at:
>> >> > >
>> https://repository.apache.org/content/repositories/orgapachespark-024/
>> >> > >
>> >> > > The documentation corresponding to this release can be found at:
>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> >> > >
>> >> > > For information about the contents of this release see:
>> >> > > <attached> draft of release notes
>> >> > > <attached> draft of release credits
>> >> > >
>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> >> > >
>> >> > > Please vote on releasing this package as Apache Spark
>> 0.8.1-incubating!
>> >> > >
>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>> >> > >
>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> >> > > [ ] -1 Do not release this package because ...
>> >> > >
>> >> > > To learn more about Apache Spark, please see
>> >> > > http://spark.incubator.apache.org/
>> >> > >
>> >> >
>> >>
>>

From dev-return-849-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 03:47:09 2013
Return-Path: <dev-return-849-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 93FF210BC3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 03:47:09 +0000 (UTC)
Received: (qmail 26645 invoked by uid 500); 9 Dec 2013 03:47:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26605 invoked by uid 500); 9 Dec 2013 03:47:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 26597 invoked by uid 99); 9 Dec 2013 03:47:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:47:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:46:57 +0000
Received: by mail-oa0-f47.google.com with SMTP id k1so3253759oag.6
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 19:46:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=m/azC3M4EFg/U3T5hgfKg6HWLRDUOjVNCDxk2Phw3G8=;
        b=aMubcuqxovsvNuoINjSDAu7c4uH7mx0x9kQpSb4rn8LxQyhX7lffNUCwJtfRNzyGDP
         +no2FYW4p8WvKYise1L+uJaLD26D18RETsHl4wg5p3UckPbO2EUIZgDsu9A4/PbmhTkE
         S5BZS3FuJw35dbxr7IkqAICSapRVf6PejskpOuv2miBsUYmkhhMNU+OlHpT39XpLN9c2
         /a42/36aJW7oVHbRr3+cs2iJXWCxc+g/7mf5yG0SadNidlMQqdZ0xcEx/SEU6HFO3qAn
         wz+Ng0ASpcQYmNL6S1CbULON12XpM96tNHGEK35Ge/ocTCuWN2s3GNaC5lAcI+46xV5J
         y3gQ==
MIME-Version: 1.0
X-Received: by 10.60.115.164 with SMTP id jp4mr11263196oeb.19.1386560797144;
 Sun, 08 Dec 2013 19:46:37 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 19:46:37 -0800 (PST)
In-Reply-To: <CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
Date: Sun, 8 Dec 2013 19:46:37 -0800
Message-ID: <CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Looked into this a bit more - I think removing repl-bin is something
we should wait until 0.9 to do, because we've published it to maven in
0.8.0 and people might expect it to be there in 0.8.1.

Merging the directly referenced pull request (195) seems like a good
idea though since it fixes a bug in the script.

Is that what you are suggesting?

- Patrick

On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hey Mark - ya this would be good to get in.
>
> Does merging that particular PR put this in sufficient shape for the
> 0.8.1 release or are there other open patches we need to look at?
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
>> SPARK-962 should be resolved before release.  See also:
>> https://github.com/apache/incubator-spark/pull/195
>>
>> With the references to the way I changed Debian packaging for ClearStory,
>> we should be at least 90% of the way toward doing it right for Apache.
>>
>>
>> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>>> For my own part I'll give a +1 to this RC.
>>>
>>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com>
>>> wrote:
>>> > OK. I will post the entire output via separate email. I just upgraded
>>> > Hadoop to 2.2.0 recently. So there might be something I need to
>>> > remove/clean up.
>>> >
>>> >
>>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>> >
>>> >> Hey Take,
>>> >>
>>> >> Could you start a separate thread to debug your build issue? In that
>>> >> thread, could you paste the exact build command and entire output? The
>>> log
>>> >> you posted here suggests the first build detected hadoop 1.0.4 not 2.2.0
>>> >> based on the assembly file name it is logging.
>>> >>
>>> >> ---
>>> >> sent from my phone
>>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
>>> wrote:
>>> >>
>>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
>>> >> > completing the build process (sbt/sbt assembly) on Macbook. The sbt
>>> >> command
>>> >> > hangs at the last step.
>>> >> >
>>> >> > ...
>>> >> > ...
>>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>>> >> > [info] Packaging
>>> >> >
>>> >> >
>>> >>
>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>>> >> > ...
>>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>>> >> > [info] Packaging
>>> >> >
>>> >> >
>>> >>
>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>>> >> > ...
>>> >> > (hangs here)
>>> >> > --------------------------
>>> >> >
>>> >> >
>>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed, I
>>> was
>>> >> > able to build it successfully.
>>> >> > ..
>>> >> > ..
>>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>>> >> > [info] Packaging
>>> >> >
>>> >> >
>>> >>
>>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>>> >> > ...
>>> >> > [info] Done packaging.
>>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>>> >> > --------------------------
>>> >> >
>>> >> >
>>> >> >
>>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <pwendell@gmail.com>
>>> >> > wrote:
>>> >> >
>>> >> > > Please vote on releasing the following candidate as Apache Spark
>>> >> > > (incubating) version 0.8.1.
>>> >> > >
>>> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>>> >> > >
>>> >> > >
>>> >> >
>>> >>
>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>>> >> > >
>>> >> > > The release files, including signatures, digests, etc can be found
>>> at:
>>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>>> >> > >
>>> >> > > Release artifacts are signed with the following key:
>>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>>> >> > >
>>> >> > > The staging repository for this release can be found at:
>>> >> > >
>>> https://repository.apache.org/content/repositories/orgapachespark-024/
>>> >> > >
>>> >> > > The documentation corresponding to this release can be found at:
>>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>>> >> > >
>>> >> > > For information about the contents of this release see:
>>> >> > > <attached> draft of release notes
>>> >> > > <attached> draft of release credits
>>> >> > >
>>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>>> >> > >
>>> >> > > Please vote on releasing this package as Apache Spark
>>> 0.8.1-incubating!
>>> >> > >
>>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
>>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>>> >> > >
>>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>> >> > > [ ] -1 Do not release this package because ...
>>> >> > >
>>> >> > > To learn more about Apache Spark, please see
>>> >> > > http://spark.incubator.apache.org/
>>> >> > >
>>> >> >
>>> >>
>>>

From dev-return-850-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 03:55:07 2013
Return-Path: <dev-return-850-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B207210BDA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 03:55:07 +0000 (UTC)
Received: (qmail 30387 invoked by uid 500); 9 Dec 2013 03:54:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30342 invoked by uid 500); 9 Dec 2013 03:54:36 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 30334 invoked by uid 99); 9 Dec 2013 03:54:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:54:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.45] (HELO mail-bk0-f45.google.com) (209.85.214.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 03:54:29 +0000
Received: by mail-bk0-f45.google.com with SMTP id mx13so1152095bkb.32
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 19:54:06 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=CVmXC6lLKRaQUBZHUp2NN6VsOiQQpY0YTGcM6MCamKw=;
        b=mZ3zdAhjTt0BqtBe4zmRVCZrIjDSd5a5tDP0qhuLcWHpTDBn85E4t+Tk2AKUIZ60Ri
         LDVHgf5oOP/KjXAvBur85e0J64qEjLM5Xb+N9MkW3io5YlJFDVQdRLoDZbo3qLy50TXO
         e10f9fkqXOlIt+BEPRil2JNvlbFGOZ+jFFStC77uoj9QbHe8TI6tfzATosIzJGnnPYtx
         9Uh03vXaLnk2NFzx0B3B+JMceDd5mXf493YmtT+/gbTqVaO27Keoq6IcZBT3gIYvwdbn
         2CBvRVenq7U42Elyn8QpylbjnPHXuWm2GRTpacCFiWHwalnfC+rude5LGHV4lv5vzeBW
         Cn/A==
X-Gm-Message-State: ALoCoQlh8wRL9fqQVPEwtYs+CcOqXKKntb0Je+oZ44qrbQgnEYECdHWZ+0jU1p+xHGtDitmw88eK
MIME-Version: 1.0
X-Received: by 10.204.170.204 with SMTP id e12mr1453871bkz.81.1386561246459;
 Sun, 08 Dec 2013 19:54:06 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 19:54:06 -0800 (PST)
In-Reply-To: <CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 19:54:06 -0800
Message-ID: <CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec52c5e718e62b304ed11f2ff
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec52c5e718e62b304ed11f2ff
Content-Type: text/plain; charset=ISO-8859-1

Whatever Debian package gets built has to work, so that's the first
requirement.  I don't know how to decide whether a change is acceptable in
0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
leverage the assembly sub-project, making repl-bin unnecessary.


On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Looked into this a bit more - I think removing repl-bin is something
> we should wait until 0.9 to do, because we've published it to maven in
> 0.8.0 and people might expect it to be there in 0.8.1.
>
> Merging the directly referenced pull request (195) seems like a good
> idea though since it fixes a bug in the script.
>
> Is that what you are suggesting?
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hey Mark - ya this would be good to get in.
> >
> > Does merging that particular PR put this in sufficient shape for the
> > 0.8.1 release or are there other open patches we need to look at?
> >
> > - Patrick
> >
> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> >> SPARK-962 should be resolved before release.  See also:
> >> https://github.com/apache/incubator-spark/pull/195
> >>
> >> With the references to the way I changed Debian packaging for
> ClearStory,
> >> we should be at least 90% of the way toward doing it right for Apache.
> >>
> >>
> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >>
> >>> For my own part I'll give a +1 to this RC.
> >>>
> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com
> >
> >>> wrote:
> >>> > OK. I will post the entire output via separate email. I just upgraded
> >>> > Hadoop to 2.2.0 recently. So there might be something I need to
> >>> > remove/clean up.
> >>> >
> >>> >
> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
> >>> wrote:
> >>> >
> >>> >> Hey Take,
> >>> >>
> >>> >> Could you start a separate thread to debug your build issue? In that
> >>> >> thread, could you paste the exact build command and entire output?
> The
> >>> log
> >>> >> you posted here suggests the first build detected hadoop 1.0.4 not
> 2.2.0
> >>> >> based on the assembly file name it is logging.
> >>> >>
> >>> >> ---
> >>> >> sent from my phone
> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
> >>> wrote:
> >>> >>
> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
> >>> >> > completing the build process (sbt/sbt assembly) on Macbook. The
> sbt
> >>> >> command
> >>> >> > hangs at the last step.
> >>> >> >
> >>> >> > ...
> >>> >> > ...
> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> >>> >> > [info] Packaging
> >>> >> >
> >>> >> >
> >>> >>
> >>>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> >>> >> > ...
> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> >>> >> > [info] Packaging
> >>> >> >
> >>> >> >
> >>> >>
> >>>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> >>> >> > ...
> >>> >> > (hangs here)
> >>> >> > --------------------------
> >>> >> >
> >>> >> >
> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed,
> I
> >>> was
> >>> >> > able to build it successfully.
> >>> >> > ..
> >>> >> > ..
> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> >>> >> > [info] Packaging
> >>> >> >
> >>> >> >
> >>> >>
> >>>
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> >>> >> > ...
> >>> >> > [info] Done packaging.
> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
> >>> >> > --------------------------
> >>> >> >
> >>> >> >
> >>> >> >
> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
> pwendell@gmail.com>
> >>> >> > wrote:
> >>> >> >
> >>> >> > > Please vote on releasing the following candidate as Apache Spark
> >>> >> > > (incubating) version 0.8.1.
> >>> >> > >
> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
> >>> >> > >
> >>> >> > >
> >>> >> >
> >>> >>
> >>>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> >>> >> > >
> >>> >> > > The release files, including signatures, digests, etc can be
> found
> >>> at:
> >>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> >>> >> > >
> >>> >> > > Release artifacts are signed with the following key:
> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
> >>> >> > >
> >>> >> > > The staging repository for this release can be found at:
> >>> >> > >
> >>> https://repository.apache.org/content/repositories/orgapachespark-024/
> >>> >> > >
> >>> >> > > The documentation corresponding to this release can be found at:
> >>> >> > >
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> >>> >> > >
> >>> >> > > For information about the contents of this release see:
> >>> >> > > <attached> draft of release notes
> >>> >> > > <attached> draft of release credits
> >>> >> > >
> >>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >>> >> > >
> >>> >> > > Please vote on releasing this package as Apache Spark
> >>> 0.8.1-incubating!
> >>> >> > >
> >>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> >>> >> > >
> >>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >>> >> > > [ ] -1 Do not release this package because ...
> >>> >> > >
> >>> >> > > To learn more about Apache Spark, please see
> >>> >> > > http://spark.incubator.apache.org/
> >>> >> > >
> >>> >> >
> >>> >>
> >>>
>

--bcaec52c5e718e62b304ed11f2ff--

From dev-return-851-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 04:03:24 2013
Return-Path: <dev-return-851-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D763810BFB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 04:03:24 +0000 (UTC)
Received: (qmail 39772 invoked by uid 500); 9 Dec 2013 04:03:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39740 invoked by uid 500); 9 Dec 2013 04:03:11 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 39726 invoked by uid 99); 9 Dec 2013 04:03:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:03:08 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:03:02 +0000
Received: by mail-ob0-f181.google.com with SMTP id uy5so3100035obc.26
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 20:02:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=4OK2sjRPtAgqY6jgHfcW0AqCfPgVADzPna+HdVlQmZ0=;
        b=kJHbc3yzbo/gQC0nMDduv0tIyrZjxUqCmQWmxlUhpeUl4ag8Ya575lbWpzO+qIf9Bj
         76cGDBfoJh0lfIEAUIER0jXdvwA8ncK7hbgMipk4HcfxSu0z6kh+HivKVLhW294erIBu
         vHVBEyZ+a9nZ/otpdOVgssibTrGr0kCo1v6jF0wdc8bMQrZh8tuqubVk0LOyf8VeDxeo
         ucDhBdv9WOpt/L0eU27xNQ3E9h6WcvoWjlPEazP6cmJDpbFe5+6FZ0bfkwAhsPG2hyG3
         +Ac/IRs9BtBy32+34g8rGiCVkkdldhoOAbqo1TfrMDuCSZ6gLqw6qTFPnD/MnE3hdyRX
         2E7Q==
MIME-Version: 1.0
X-Received: by 10.60.65.227 with SMTP id a3mr11233204oet.13.1386561761492;
 Sun, 08 Dec 2013 20:02:41 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 20:02:41 -0800 (PST)
In-Reply-To: <CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
Date: Sun, 8 Dec 2013 20:02:41 -0800
Message-ID: <CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mark,

What I'm asking is whether this patch is sufficient to have a working
debian build in 0.8.1, or are there other outstanding issues to make
it work? By working I mean, within the initial design that was
contributed (with repl-bin) it works according to that approach.

We can redesign this packaging in 0.9. That will require having a PR
against Apache Spark, discussing, etc. But it doesn't need to be on
the critical path for this release.

- Patrick

On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> Whatever Debian package gets built has to work, so that's the first
> requirement.  I don't know how to decide whether a change is acceptable in
> 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
> leverage the assembly sub-project, making repl-bin unnecessary.
>
>
> On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> Looked into this a bit more - I think removing repl-bin is something
>> we should wait until 0.9 to do, because we've published it to maven in
>> 0.8.0 and people might expect it to be there in 0.8.1.
>>
>> Merging the directly referenced pull request (195) seems like a good
>> idea though since it fixes a bug in the script.
>>
>> Is that what you are suggesting?
>>
>> - Patrick
>>
>> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> > Hey Mark - ya this would be good to get in.
>> >
>> > Does merging that particular PR put this in sufficient shape for the
>> > 0.8.1 release or are there other open patches we need to look at?
>> >
>> > - Patrick
>> >
>> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com>
>> wrote:
>> >> SPARK-962 should be resolved before release.  See also:
>> >> https://github.com/apache/incubator-spark/pull/195
>> >>
>> >> With the references to the way I changed Debian packaging for
>> ClearStory,
>> >> we should be at least 90% of the way toward doing it right for Apache.
>> >>
>> >>
>> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >>
>> >>> For my own part I'll give a +1 to this RC.
>> >>>
>> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <taka.epsilon@gmail.com
>> >
>> >>> wrote:
>> >>> > OK. I will post the entire output via separate email. I just upgraded
>> >>> > Hadoop to 2.2.0 recently. So there might be something I need to
>> >>> > remove/clean up.
>> >>> >
>> >>> >
>> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <pwendell@gmail.com>
>> >>> wrote:
>> >>> >
>> >>> >> Hey Take,
>> >>> >>
>> >>> >> Could you start a separate thread to debug your build issue? In that
>> >>> >> thread, could you paste the exact build command and entire output?
>> The
>> >>> log
>> >>> >> you posted here suggests the first build detected hadoop 1.0.4 not
>> 2.2.0
>> >>> >> based on the assembly file name it is logging.
>> >>> >>
>> >>> >> ---
>> >>> >> sent from my phone
>> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com>
>> >>> wrote:
>> >>> >>
>> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having trouble
>> >>> >> > completing the build process (sbt/sbt assembly) on Macbook. The
>> sbt
>> >>> >> command
>> >>> >> > hangs at the last step.
>> >>> >> >
>> >>> >> > ...
>> >>> >> > ...
>> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> >>> >> > [info] Packaging
>> >>> >> >
>> >>> >> >
>> >>> >>
>> >>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> >>> >> > ...
>> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> >>> >> > [info] Packaging
>> >>> >> >
>> >>> >> >
>> >>> >>
>> >>>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> >>> >> > ...
>> >>> >> > (hangs here)
>> >>> >> > --------------------------
>> >>> >> >
>> >>> >> >
>> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45) installed,
>> I
>> >>> was
>> >>> >> > able to build it successfully.
>> >>> >> > ..
>> >>> >> > ..
>> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> >>> >> > [info] Packaging
>> >>> >> >
>> >>> >> >
>> >>> >>
>> >>>
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> >>> >> > ...
>> >>> >> > [info] Done packaging.
>> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>> >>> >> > --------------------------
>> >>> >> >
>> >>> >> >
>> >>> >> >
>> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
>> pwendell@gmail.com>
>> >>> >> > wrote:
>> >>> >> >
>> >>> >> > > Please vote on releasing the following candidate as Apache Spark
>> >>> >> > > (incubating) version 0.8.1.
>> >>> >> > >
>> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit bf23794a):
>> >>> >> > >
>> >>> >> > >
>> >>> >> >
>> >>> >>
>> >>>
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> >>> >> > >
>> >>> >> > > The release files, including signatures, digests, etc can be
>> found
>> >>> at:
>> >>> >> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> >>> >> > >
>> >>> >> > > Release artifacts are signed with the following key:
>> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>> >>> >> > >
>> >>> >> > > The staging repository for this release can be found at:
>> >>> >> > >
>> >>> https://repository.apache.org/content/repositories/orgapachespark-024/
>> >>> >> > >
>> >>> >> > > The documentation corresponding to this release can be found at:
>> >>> >> > >
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> >>> >> > >
>> >>> >> > > For information about the contents of this release see:
>> >>> >> > > <attached> draft of release notes
>> >>> >> > > <attached> draft of release credits
>> >>> >> > >
>> >>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> >>> >> > >
>> >>> >> > > Please vote on releasing this package as Apache Spark
>> >>> 0.8.1-incubating!
>> >>> >> > >
>> >>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC and
>> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>> >>> >> > >
>> >>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> >>> >> > > [ ] -1 Do not release this package because ...
>> >>> >> > >
>> >>> >> > > To learn more about Apache Spark, please see
>> >>> >> > > http://spark.incubator.apache.org/
>> >>> >> > >
>> >>> >> >
>> >>> >>
>> >>>
>>

From dev-return-852-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 04:08:23 2013
Return-Path: <dev-return-852-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 78EE710C19
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 04:08:23 +0000 (UTC)
Received: (qmail 41433 invoked by uid 500); 9 Dec 2013 04:07:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41407 invoked by uid 500); 9 Dec 2013 04:07:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 41397 invoked by uid 99); 9 Dec 2013 04:07:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:07:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.43] (HELO mail-bk0-f43.google.com) (209.85.214.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:07:38 +0000
Received: by mail-bk0-f43.google.com with SMTP id mz12so1145296bkb.2
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 20:07:17 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=5Zp6NgxGI9paTNTxrzWobo9UnN8gWgxMjUwEwbS6mzs=;
        b=iRWKT/coNJQRaYB83m2Weew8De4IbCUsTbFGPl3oL9BC4CwlZ75F2/9EaTl4XWuVnA
         XiJdbqvpxA/9/c8KG7DqFUVpxkzUtWOHKQnXZ24h9L2DvpedsSlEMAWSbvfGqo+myJld
         zBGV3jLjCOXBQya6QvzgpHNPMkBc29Z2EH4GA4yJZ+fcm2CAL2EeRxGi0qlaDJC0nwtw
         FdHPBWwx/yjbwRKS3a2LOTs1qYH+YaB5sL7zjnC9f2xqtNy25EElmlcC8n227Wd5UTmo
         WrE2leGbbPy+OFpsi4m5VC5G3IzbiiZ0fb7IrkOg8SEgkPMB6QZTfvbIUDpoxlN4B0dp
         lCdg==
X-Gm-Message-State: ALoCoQneWlrFKf7yDD4NV54reVTNwU9dv+ldtBNUHJKwpD68B4a1MbKRNg6WbfXQCjAn9l3NPEB1
MIME-Version: 1.0
X-Received: by 10.205.65.81 with SMTP id xl17mr1464350bkb.66.1386562037246;
 Sun, 08 Dec 2013 20:07:17 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 20:07:17 -0800 (PST)
In-Reply-To: <CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
Date: Sun, 8 Dec 2013 20:07:17 -0800
Message-ID: <CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec53f2bbdb0d78604ed122173
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f2bbdb0d78604ed122173
Content-Type: text/plain; charset=ISO-8859-1

Well, 195 is sufficient to give you something that runs, but it doesn't run
the same way as Spark built/distributed by other means -- e.g., after 195
the package still uses something equivalent to the old `run` script instead
of the current `spark-class` way.


On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Mark,
>
> What I'm asking is whether this patch is sufficient to have a working
> debian build in 0.8.1, or are there other outstanding issues to make
> it work? By working I mean, within the initial design that was
> contributed (with repl-bin) it works according to that approach.
>
> We can redesign this packaging in 0.9. That will require having a PR
> against Apache Spark, discussing, etc. But it doesn't need to be on
> the critical path for this release.
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> > Whatever Debian package gets built has to work, so that's the first
> > requirement.  I don't know how to decide whether a change is acceptable
> in
> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
> > leverage the assembly sub-project, making repl-bin unnecessary.
> >
> >
> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >
> >> Looked into this a bit more - I think removing repl-bin is something
> >> we should wait until 0.9 to do, because we've published it to maven in
> >> 0.8.0 and people might expect it to be there in 0.8.1.
> >>
> >> Merging the directly referenced pull request (195) seems like a good
> >> idea though since it fixes a bug in the script.
> >>
> >> Is that what you are suggesting?
> >>
> >> - Patrick
> >>
> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >> > Hey Mark - ya this would be good to get in.
> >> >
> >> > Does merging that particular PR put this in sufficient shape for the
> >> > 0.8.1 release or are there other open patches we need to look at?
> >> >
> >> > - Patrick
> >> >
> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com
> >
> >> wrote:
> >> >> SPARK-962 should be resolved before release.  See also:
> >> >> https://github.com/apache/incubator-spark/pull/195
> >> >>
> >> >> With the references to the way I changed Debian packaging for
> >> ClearStory,
> >> >> we should be at least 90% of the way toward doing it right for
> Apache.
> >> >>
> >> >>
> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >> >>
> >> >>> For my own part I'll give a +1 to this RC.
> >> >>>
> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
> taka.epsilon@gmail.com
> >> >
> >> >>> wrote:
> >> >>> > OK. I will post the entire output via separate email. I just
> upgraded
> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need to
> >> >>> > remove/clean up.
> >> >>> >
> >> >>> >
> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
> pwendell@gmail.com>
> >> >>> wrote:
> >> >>> >
> >> >>> >> Hey Take,
> >> >>> >>
> >> >>> >> Could you start a separate thread to debug your build issue? In
> that
> >> >>> >> thread, could you paste the exact build command and entire
> output?
> >> The
> >> >>> log
> >> >>> >> you posted here suggests the first build detected hadoop 1.0.4
> not
> >> 2.2.0
> >> >>> >> based on the assembly file name it is logging.
> >> >>> >>
> >> >>> >> ---
> >> >>> >> sent from my phone
> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com
> >
> >> >>> wrote:
> >> >>> >>
> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
> trouble
> >> >>> >> > completing the build process (sbt/sbt assembly) on Macbook. The
> >> sbt
> >> >>> >> command
> >> >>> >> > hangs at the last step.
> >> >>> >> >
> >> >>> >> > ...
> >> >>> >> > ...
> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> >> >>> >> > [info] Packaging
> >> >>> >> >
> >> >>> >> >
> >> >>> >>
> >> >>>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> >> >>> >> > ...
> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> >> >>> >> > [info] Packaging
> >> >>> >> >
> >> >>> >> >
> >> >>> >>
> >> >>>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> >> >>> >> > ...
> >> >>> >> > (hangs here)
> >> >>> >> > --------------------------
> >> >>> >> >
> >> >>> >> >
> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
> installed,
> >> I
> >> >>> was
> >> >>> >> > able to build it successfully.
> >> >>> >> > ..
> >> >>> >> > ..
> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> >> >>> >> > [info] Packaging
> >> >>> >> >
> >> >>> >> >
> >> >>> >>
> >> >>>
> >>
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> >> >>> >> > ...
> >> >>> >> > [info] Done packaging.
> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
> >> >>> >> > --------------------------
> >> >>> >> >
> >> >>> >> >
> >> >>> >> >
> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
> >> pwendell@gmail.com>
> >> >>> >> > wrote:
> >> >>> >> >
> >> >>> >> > > Please vote on releasing the following candidate as Apache
> Spark
> >> >>> >> > > (incubating) version 0.8.1.
> >> >>> >> > >
> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
> bf23794a):
> >> >>> >> > >
> >> >>> >> > >
> >> >>> >> >
> >> >>> >>
> >> >>>
> >>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> >> >>> >> > >
> >> >>> >> > > The release files, including signatures, digests, etc can be
> >> found
> >> >>> at:
> >> >>> >> > >
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> >> >>> >> > >
> >> >>> >> > > Release artifacts are signed with the following key:
> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
> >> >>> >> > >
> >> >>> >> > > The staging repository for this release can be found at:
> >> >>> >> > >
> >> >>>
> https://repository.apache.org/content/repositories/orgapachespark-024/
> >> >>> >> > >
> >> >>> >> > > The documentation corresponding to this release can be found
> at:
> >> >>> >> > >
> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> >> >>> >> > >
> >> >>> >> > > For information about the contents of this release see:
> >> >>> >> > > <attached> draft of release notes
> >> >>> >> > > <attached> draft of release credits
> >> >>> >> > >
> >> >>>
> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >> >>> >> > >
> >> >>> >> > > Please vote on releasing this package as Apache Spark
> >> >>> 0.8.1-incubating!
> >> >>> >> > >
> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC
> and
> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> >> >>> >> > >
> >> >>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >> >>> >> > > [ ] -1 Do not release this package because ...
> >> >>> >> > >
> >> >>> >> > > To learn more about Apache Spark, please see
> >> >>> >> > > http://spark.incubator.apache.org/
> >> >>> >> > >
> >> >>> >> >
> >> >>> >>
> >> >>>
> >>
>

--bcaec53f2bbdb0d78604ed122173--

From dev-return-853-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 04:26:28 2013
Return-Path: <dev-return-853-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25C0D10C80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 04:26:28 +0000 (UTC)
Received: (qmail 61358 invoked by uid 500); 9 Dec 2013 04:25:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61249 invoked by uid 500); 9 Dec 2013 04:25:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 61207 invoked by uid 99); 9 Dec 2013 04:25:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:25:45 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:25:39 +0000
Received: by mail-ob0-f181.google.com with SMTP id uy5so3195864obc.40
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 20:25:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=OXZl4F873reDwJxZNHZPfcWD5FbnIJES25rgJ5/9bEU=;
        b=0FfNMOHLhMdxnXAWtuBQTBR8XhQCwKU3iJxyJGnUEe5uyb2ImrpLRuo8EzE4REsnST
         Ngu58gca8mppsOW8R+WXv83eytTnlYZLJDh3PQl06orPEVfdnyzwhrGvTAVRg8gFBbng
         s3mlPcK38iFABakPbgrin3P6eLCmDqnoHhtBayLXkixzAYen1Yt+NhttX4yGdCZJwN8B
         Gg9SFkyM+pn0AsNdn7xTjEriNLOnqaAyDVINSPEi8QLMiCEj1hfbg3ghxHLedpQwjMFp
         d2nqB6Jh8ovzgpJy281W4DUGR7zaUaDCLXqGxZXrEKGp5YFhhwXQ/pnxo/yx8HoyNoEe
         jE1w==
MIME-Version: 1.0
X-Received: by 10.60.135.130 with SMTP id ps2mr1231434oeb.46.1386563118124;
 Sun, 08 Dec 2013 20:25:18 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 20:25:18 -0800 (PST)
In-Reply-To: <CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
	<CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
Date: Sun, 8 Dec 2013 20:25:18 -0800
Message-ID: <CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Mark,

Okay if 195 gets this in working order in the branch 0.8 let's just
merge that to keep it consistent with our docs and the way this is
done in 0.8.0

We can do a broader refactoring in 0.9. Would be great if you could
kick off a JIRA discussion or submit a PR relating to that.

- Patrick

On Sun, Dec 8, 2013 at 8:07 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> Well, 195 is sufficient to give you something that runs, but it doesn't run
> the same way as Spark built/distributed by other means -- e.g., after 195
> the package still uses something equivalent to the old `run` script instead
> of the current `spark-class` way.
>
>
> On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> Hey Mark,
>>
>> What I'm asking is whether this patch is sufficient to have a working
>> debian build in 0.8.1, or are there other outstanding issues to make
>> it work? By working I mean, within the initial design that was
>> contributed (with repl-bin) it works according to that approach.
>>
>> We can redesign this packaging in 0.9. That will require having a PR
>> against Apache Spark, discussing, etc. But it doesn't need to be on
>> the critical path for this release.
>>
>> - Patrick
>>
>> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
>> wrote:
>> > Whatever Debian package gets built has to work, so that's the first
>> > requirement.  I don't know how to decide whether a change is acceptable
>> in
>> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
>> > leverage the assembly sub-project, making repl-bin unnecessary.
>> >
>> >
>> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >
>> >> Looked into this a bit more - I think removing repl-bin is something
>> >> we should wait until 0.9 to do, because we've published it to maven in
>> >> 0.8.0 and people might expect it to be there in 0.8.1.
>> >>
>> >> Merging the directly referenced pull request (195) seems like a good
>> >> idea though since it fixes a bug in the script.
>> >>
>> >> Is that what you are suggesting?
>> >>
>> >> - Patrick
>> >>
>> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com>
>> >> wrote:
>> >> > Hey Mark - ya this would be good to get in.
>> >> >
>> >> > Does merging that particular PR put this in sufficient shape for the
>> >> > 0.8.1 release or are there other open patches we need to look at?
>> >> >
>> >> > - Patrick
>> >> >
>> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <mark@clearstorydata.com
>> >
>> >> wrote:
>> >> >> SPARK-962 should be resolved before release.  See also:
>> >> >> https://github.com/apache/incubator-spark/pull/195
>> >> >>
>> >> >> With the references to the way I changed Debian packaging for
>> >> ClearStory,
>> >> >> we should be at least 90% of the way toward doing it right for
>> Apache.
>> >> >>
>> >> >>
>> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <pwendell@gmail.com>
>> >> wrote:
>> >> >>
>> >> >>> For my own part I'll give a +1 to this RC.
>> >> >>>
>> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
>> taka.epsilon@gmail.com
>> >> >
>> >> >>> wrote:
>> >> >>> > OK. I will post the entire output via separate email. I just
>> upgraded
>> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need to
>> >> >>> > remove/clean up.
>> >> >>> >
>> >> >>> >
>> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
>> pwendell@gmail.com>
>> >> >>> wrote:
>> >> >>> >
>> >> >>> >> Hey Take,
>> >> >>> >>
>> >> >>> >> Could you start a separate thread to debug your build issue? In
>> that
>> >> >>> >> thread, could you paste the exact build command and entire
>> output?
>> >> The
>> >> >>> log
>> >> >>> >> you posted here suggests the first build detected hadoop 1.0.4
>> not
>> >> 2.2.0
>> >> >>> >> based on the assembly file name it is logging.
>> >> >>> >>
>> >> >>> >> ---
>> >> >>> >> sent from my phone
>> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <taka.epsilon@gmail.com
>> >
>> >> >>> wrote:
>> >> >>> >>
>> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
>> trouble
>> >> >>> >> > completing the build process (sbt/sbt assembly) on Macbook. The
>> >> sbt
>> >> >>> >> command
>> >> >>> >> > hangs at the last step.
>> >> >>> >> >
>> >> >>> >> > ...
>> >> >>> >> > ...
>> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> >> >>> >> > [info] Packaging
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >>
>> >> >>>
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> >> >>> >> > ...
>> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> >> >>> >> > [info] Packaging
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >>
>> >> >>>
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> >> >>> >> > ...
>> >> >>> >> > (hangs here)
>> >> >>> >> > --------------------------
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
>> installed,
>> >> I
>> >> >>> was
>> >> >>> >> > able to build it successfully.
>> >> >>> >> > ..
>> >> >>> >> > ..
>> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> >> >>> >> > [info] Packaging
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >>
>> >> >>>
>> >>
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> >> >>> >> > ...
>> >> >>> >> > [info] Done packaging.
>> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10 PM
>> >> >>> >> > --------------------------
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >> >
>> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
>> >> pwendell@gmail.com>
>> >> >>> >> > wrote:
>> >> >>> >> >
>> >> >>> >> > > Please vote on releasing the following candidate as Apache
>> Spark
>> >> >>> >> > > (incubating) version 0.8.1.
>> >> >>> >> > >
>> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
>> bf23794a):
>> >> >>> >> > >
>> >> >>> >> > >
>> >> >>> >> >
>> >> >>> >>
>> >> >>>
>> >>
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> >> >>> >> > >
>> >> >>> >> > > The release files, including signatures, digests, etc can be
>> >> found
>> >> >>> at:
>> >> >>> >> > >
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> >> >>> >> > >
>> >> >>> >> > > Release artifacts are signed with the following key:
>> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>> >> >>> >> > >
>> >> >>> >> > > The staging repository for this release can be found at:
>> >> >>> >> > >
>> >> >>>
>> https://repository.apache.org/content/repositories/orgapachespark-024/
>> >> >>> >> > >
>> >> >>> >> > > The documentation corresponding to this release can be found
>> at:
>> >> >>> >> > >
>> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> >> >>> >> > >
>> >> >>> >> > > For information about the contents of this release see:
>> >> >>> >> > > <attached> draft of release notes
>> >> >>> >> > > <attached> draft of release credits
>> >> >>> >> > >
>> >> >>>
>> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> >> >>> >> > >
>> >> >>> >> > > Please vote on releasing this package as Apache Spark
>> >> >>> 0.8.1-incubating!
>> >> >>> >> > >
>> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00 UTC
>> and
>> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
>> >> >>> >> > >
>> >> >>> >> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> >> >>> >> > > [ ] -1 Do not release this package because ...
>> >> >>> >> > >
>> >> >>> >> > > To learn more about Apache Spark, please see
>> >> >>> >> > > http://spark.incubator.apache.org/
>> >> >>> >> > >
>> >> >>> >> >
>> >> >>> >>
>> >> >>>
>> >>
>>

From dev-return-854-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 04:42:02 2013
Return-Path: <dev-return-854-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 901EE10CB5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 04:42:02 +0000 (UTC)
Received: (qmail 66845 invoked by uid 500); 9 Dec 2013 04:42:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66756 invoked by uid 500); 9 Dec 2013 04:41:53 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 66743 invoked by uid 99); 9 Dec 2013 04:41:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:41:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.42] (HELO mail-bk0-f42.google.com) (209.85.214.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:41:44 +0000
Received: by mail-bk0-f42.google.com with SMTP id w11so1179757bkz.1
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 20:41:23 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=4mgu0BeLB6O2KelOvY5cy+xpJtKt9NZH0zeqUHuKIgs=;
        b=eEGH4Pp/cqNkQZnOSqPp50wJM1JZ2mTEaDspliRowUoyDK0dHvl8WWH8SiLfVXgU9u
         RomjfVlmCXD1qxJr7gVrxgzKvEXEzbgBMfjSpBYgrWvuHBTe3NxF1PXlzXITykQruhmW
         IWZ5v9PtEE0ShjFt4pWEsJRHnjRLMwIvy+QRz9To7N1sJid3mPL2PE0N5Z70cjr668BH
         3eOMyD45imp1s+E07VtwYRRuf7Z9nidvNNuuyrdZI6UuZaG7X7uiy33Lwxy6uV2/tBks
         lpbmrpKRxYrITQR8LhMDtx3B9PQpcyE4u3ZW0hNUEQKDPZvyXKY/xvkTHOpjV3yrhzBU
         W3PA==
X-Gm-Message-State: ALoCoQmWBBNZYgcFWw4NMR6iBE2Dcavto3EyS5N70wewEB4+JlN0gUZkIMfRgDI+4Sr63x/2LYx3
MIME-Version: 1.0
X-Received: by 10.205.20.132 with SMTP id qo4mr1503058bkb.110.1386564083316;
 Sun, 08 Dec 2013 20:41:23 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 20:41:23 -0800 (PST)
In-Reply-To: <CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
	<CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
	<CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
Date: Sun, 8 Dec 2013 20:41:23 -0800
Message-ID: <CAAsvFPmx4mEnB03d5S6Nbky39BnWeg1YrPk5Mk6+hKkuVV0HjQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=20cf30223a9ba5614f04ed129be9
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf30223a9ba5614f04ed129be9
Content-Type: text/plain; charset=ISO-8859-1

Well, what I've already done for ClearStory is very close to how Debian
packaging should be done for Apache Spark.  That much can be put into a
pull request quickly.  The only real issues are exactly how the packages
should be named, checking that the metadata of the packages are exactly
correct for an Apache release, and deciding whether we should be producing
a spark-examples package, spark-tools package, separate the Java and Python
APIs into their own packages, create a source package, etc.  What we've
been doing up to now is essentially just the minimal packaging of a fat jar
that can be deployed by Chef or something similar.  It's never really been
put together in a way appropriate to go into a Debian or Ubuntu
distribution, for instance.


On Sun, Dec 8, 2013 at 8:25 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Mark,
>
> Okay if 195 gets this in working order in the branch 0.8 let's just
> merge that to keep it consistent with our docs and the way this is
> done in 0.8.0
>
> We can do a broader refactoring in 0.9. Would be great if you could
> kick off a JIRA discussion or submit a PR relating to that.
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 8:07 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> > Well, 195 is sufficient to give you something that runs, but it doesn't
> run
> > the same way as Spark built/distributed by other means -- e.g., after 195
> > the package still uses something equivalent to the old `run` script
> instead
> > of the current `spark-class` way.
> >
> >
> > On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >
> >> Hey Mark,
> >>
> >> What I'm asking is whether this patch is sufficient to have a working
> >> debian build in 0.8.1, or are there other outstanding issues to make
> >> it work? By working I mean, within the initial design that was
> >> contributed (with repl-bin) it works according to that approach.
> >>
> >> We can redesign this packaging in 0.9. That will require having a PR
> >> against Apache Spark, discussing, etc. But it doesn't need to be on
> >> the critical path for this release.
> >>
> >> - Patrick
> >>
> >> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
> >> wrote:
> >> > Whatever Debian package gets built has to work, so that's the first
> >> > requirement.  I don't know how to decide whether a change is
> acceptable
> >> in
> >> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
> >> > leverage the assembly sub-project, making repl-bin unnecessary.
> >> >
> >> >
> >> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >> >
> >> >> Looked into this a bit more - I think removing repl-bin is something
> >> >> we should wait until 0.9 to do, because we've published it to maven
> in
> >> >> 0.8.0 and people might expect it to be there in 0.8.1.
> >> >>
> >> >> Merging the directly referenced pull request (195) seems like a good
> >> >> idea though since it fixes a bug in the script.
> >> >>
> >> >> Is that what you are suggesting?
> >> >>
> >> >> - Patrick
> >> >>
> >> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com>
> >> >> wrote:
> >> >> > Hey Mark - ya this would be good to get in.
> >> >> >
> >> >> > Does merging that particular PR put this in sufficient shape for
> the
> >> >> > 0.8.1 release or are there other open patches we need to look at?
> >> >> >
> >> >> > - Patrick
> >> >> >
> >> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <
> mark@clearstorydata.com
> >> >
> >> >> wrote:
> >> >> >> SPARK-962 should be resolved before release.  See also:
> >> >> >> https://github.com/apache/incubator-spark/pull/195
> >> >> >>
> >> >> >> With the references to the way I changed Debian packaging for
> >> >> ClearStory,
> >> >> >> we should be at least 90% of the way toward doing it right for
> >> Apache.
> >> >> >>
> >> >> >>
> >> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <
> pwendell@gmail.com>
> >> >> wrote:
> >> >> >>
> >> >> >>> For my own part I'll give a +1 to this RC.
> >> >> >>>
> >> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
> >> taka.epsilon@gmail.com
> >> >> >
> >> >> >>> wrote:
> >> >> >>> > OK. I will post the entire output via separate email. I just
> >> upgraded
> >> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need to
> >> >> >>> > remove/clean up.
> >> >> >>> >
> >> >> >>> >
> >> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
> >> pwendell@gmail.com>
> >> >> >>> wrote:
> >> >> >>> >
> >> >> >>> >> Hey Take,
> >> >> >>> >>
> >> >> >>> >> Could you start a separate thread to debug your build issue?
> In
> >> that
> >> >> >>> >> thread, could you paste the exact build command and entire
> >> output?
> >> >> The
> >> >> >>> log
> >> >> >>> >> you posted here suggests the first build detected hadoop 1.0.4
> >> not
> >> >> 2.2.0
> >> >> >>> >> based on the assembly file name it is logging.
> >> >> >>> >>
> >> >> >>> >> ---
> >> >> >>> >> sent from my phone
> >> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <
> taka.epsilon@gmail.com
> >> >
> >> >> >>> wrote:
> >> >> >>> >>
> >> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
> >> trouble
> >> >> >>> >> > completing the build process (sbt/sbt assembly) on Macbook.
> The
> >> >> sbt
> >> >> >>> >> command
> >> >> >>> >> > hangs at the last step.
> >> >> >>> >> >
> >> >> >>> >> > ...
> >> >> >>> >> > ...
> >> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> >> >> >>> >> > [info] Packaging
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >>
> >> >> >>>
> >> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> >> >> >>> >> > ...
> >> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> >> >> >>> >> > [info] Packaging
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >>
> >> >> >>>
> >> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> >> >> >>> >> > ...
> >> >> >>> >> > (hangs here)
> >> >> >>> >> > --------------------------
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
> >> installed,
> >> >> I
> >> >> >>> was
> >> >> >>> >> > able to build it successfully.
> >> >> >>> >> > ..
> >> >> >>> >> > ..
> >> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
> >> >> >>> >> > [info] Packaging
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >>
> >> >> >>>
> >> >>
> >>
> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
> >> >> >>> >> > ...
> >> >> >>> >> > [info] Done packaging.
> >> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10
> PM
> >> >> >>> >> > --------------------------
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >> >
> >> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
> >> >> pwendell@gmail.com>
> >> >> >>> >> > wrote:
> >> >> >>> >> >
> >> >> >>> >> > > Please vote on releasing the following candidate as Apache
> >> Spark
> >> >> >>> >> > > (incubating) version 0.8.1.
> >> >> >>> >> > >
> >> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
> >> bf23794a):
> >> >> >>> >> > >
> >> >> >>> >> > >
> >> >> >>> >> >
> >> >> >>> >>
> >> >> >>>
> >> >>
> >>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
> >> >> >>> >> > >
> >> >> >>> >> > > The release files, including signatures, digests, etc can
> be
> >> >> found
> >> >> >>> at:
> >> >> >>> >> > >
> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
> >> >> >>> >> > >
> >> >> >>> >> > > Release artifacts are signed with the following key:
> >> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
> >> >> >>> >> > >
> >> >> >>> >> > > The staging repository for this release can be found at:
> >> >> >>> >> > >
> >> >> >>>
> >> https://repository.apache.org/content/repositories/orgapachespark-024/
> >> >> >>> >> > >
> >> >> >>> >> > > The documentation corresponding to this release can be
> found
> >> at:
> >> >> >>> >> > >
> >> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
> >> >> >>> >> > >
> >> >> >>> >> > > For information about the contents of this release see:
> >> >> >>> >> > > <attached> draft of release notes
> >> >> >>> >> > > <attached> draft of release credits
> >> >> >>> >> > >
> >> >> >>>
> >> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
> >> >> >>> >> > >
> >> >> >>> >> > > Please vote on releasing this package as Apache Spark
> >> >> >>> 0.8.1-incubating!
> >> >> >>> >> > >
> >> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00
> UTC
> >> and
> >> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> >> >> >>> >> > >
> >> >> >>> >> > > [ ] +1 Release this package as Apache Spark
> 0.8.1-incubating
> >> >> >>> >> > > [ ] -1 Do not release this package because ...
> >> >> >>> >> > >
> >> >> >>> >> > > To learn more about Apache Spark, please see
> >> >> >>> >> > > http://spark.incubator.apache.org/
> >> >> >>> >> > >
> >> >> >>> >> >
> >> >> >>> >>
> >> >> >>>
> >> >>
> >>
>

--20cf30223a9ba5614f04ed129be9--

From dev-return-855-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 04:42:53 2013
Return-Path: <dev-return-855-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7921F10CBA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 04:42:53 +0000 (UTC)
Received: (qmail 67514 invoked by uid 500); 9 Dec 2013 04:42:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67262 invoked by uid 500); 9 Dec 2013 04:42:47 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 67221 invoked by uid 99); 9 Dec 2013 04:42:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:42:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.53] (HELO mail-bk0-f53.google.com) (209.85.214.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 04:42:38 +0000
Received: by mail-bk0-f53.google.com with SMTP id na10so1168510bkb.12
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 20:42:18 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=w+/EwN7O/9YL5WGtXtww/vp991BTScmudRGlDutG6yU=;
        b=RkQVvEUe4/M7rJIJJ6rxbnn3/FQUnTWA7c3nDkvFbV85gJa9tj4T/XpfeuztFATBJE
         BUoFozXnIozq+ffWQSvYkJEBw/k3XMkm1Gn31nLw3a0AoeQvrftmTrAndgFE80iR1U73
         +F5CTxHDl1mF1iXs/Tt6gmByWa5NMyck7pEOwKU42oq2fN2nKcwbpS5yCaVkeEXtA4tR
         8X6bLd67LpG6/nZLU9C90y29MIuVZr7WSlLv4IEFxR3V2BT4iCBr55nbAwmTQ5juPvnq
         JnQyRaDqqcojP3jbcYO9Xp1oiYCxHKtsPPm1fSAY1PvKX4dtFZcgEWg5fS7irGRfj7MZ
         HJmw==
X-Gm-Message-State: ALoCoQkvOePa5yKR5H3aE1OyI+wPfEhCZemdvI1TMerNy0m3Xp4Aj+xKXmbuVPzd0mPz8uf2JysK
MIME-Version: 1.0
X-Received: by 10.204.118.67 with SMTP id u3mr5364535bkq.41.1386564138572;
 Sun, 08 Dec 2013 20:42:18 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Sun, 8 Dec 2013 20:42:18 -0800 (PST)
In-Reply-To: <CAAsvFPmx4mEnB03d5S6Nbky39BnWeg1YrPk5Mk6+hKkuVV0HjQ@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
	<CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
	<CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
	<CAAsvFPmx4mEnB03d5S6Nbky39BnWeg1YrPk5Mk6+hKkuVV0HjQ@mail.gmail.com>
Date: Sun, 8 Dec 2013 20:42:18 -0800
Message-ID: <CAAsvFP=UmVekB5DfuwfOHSbY=dCqKSZEDK4ZpGWZWnMg97BiFg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bea4532f085c304ed129e72
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea4532f085c304ed129e72
Content-Type: text/plain; charset=ISO-8859-1

And I think 195 is sufficient to build something that works; but I haven't
personally tested it.


On Sun, Dec 8, 2013 at 8:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> Well, what I've already done for ClearStory is very close to how Debian
> packaging should be done for Apache Spark.  That much can be put into a
> pull request quickly.  The only real issues are exactly how the packages
> should be named, checking that the metadata of the packages are exactly
> correct for an Apache release, and deciding whether we should be producing
> a spark-examples package, spark-tools package, separate the Java and Python
> APIs into their own packages, create a source package, etc.  What we've
> been doing up to now is essentially just the minimal packaging of a fat jar
> that can be deployed by Chef or something similar.  It's never really been
> put together in a way appropriate to go into a Debian or Ubuntu
> distribution, for instance.
>
>
> On Sun, Dec 8, 2013 at 8:25 PM, Patrick Wendell <pwendell@gmail.com>wrote:
>
>> Hey Mark,
>>
>> Okay if 195 gets this in working order in the branch 0.8 let's just
>> merge that to keep it consistent with our docs and the way this is
>> done in 0.8.0
>>
>> We can do a broader refactoring in 0.9. Would be great if you could
>> kick off a JIRA discussion or submit a PR relating to that.
>>
>> - Patrick
>>
>> On Sun, Dec 8, 2013 at 8:07 PM, Mark Hamstra <mark@clearstorydata.com>
>> wrote:
>> > Well, 195 is sufficient to give you something that runs, but it doesn't
>> run
>> > the same way as Spark built/distributed by other means -- e.g., after
>> 195
>> > the package still uses something equivalent to the old `run` script
>> instead
>> > of the current `spark-class` way.
>> >
>> >
>> > On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >
>> >> Hey Mark,
>> >>
>> >> What I'm asking is whether this patch is sufficient to have a working
>> >> debian build in 0.8.1, or are there other outstanding issues to make
>> >> it work? By working I mean, within the initial design that was
>> >> contributed (with repl-bin) it works according to that approach.
>> >>
>> >> We can redesign this packaging in 0.9. That will require having a PR
>> >> against Apache Spark, discussing, etc. But it doesn't need to be on
>> >> the critical path for this release.
>> >>
>> >> - Patrick
>> >>
>> >> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
>> >> wrote:
>> >> > Whatever Debian package gets built has to work, so that's the first
>> >> > requirement.  I don't know how to decide whether a change is
>> acceptable
>> >> in
>> >> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
>> >> > leverage the assembly sub-project, making repl-bin unnecessary.
>> >> >
>> >> >
>> >> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
>> >> wrote:
>> >> >
>> >> >> Looked into this a bit more - I think removing repl-bin is something
>> >> >> we should wait until 0.9 to do, because we've published it to maven
>> in
>> >> >> 0.8.0 and people might expect it to be there in 0.8.1.
>> >> >>
>> >> >> Merging the directly referenced pull request (195) seems like a good
>> >> >> idea though since it fixes a bug in the script.
>> >> >>
>> >> >> Is that what you are suggesting?
>> >> >>
>> >> >> - Patrick
>> >> >>
>> >> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com
>> >
>> >> >> wrote:
>> >> >> > Hey Mark - ya this would be good to get in.
>> >> >> >
>> >> >> > Does merging that particular PR put this in sufficient shape for
>> the
>> >> >> > 0.8.1 release or are there other open patches we need to look at?
>> >> >> >
>> >> >> > - Patrick
>> >> >> >
>> >> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <
>> mark@clearstorydata.com
>> >> >
>> >> >> wrote:
>> >> >> >> SPARK-962 should be resolved before release.  See also:
>> >> >> >> https://github.com/apache/incubator-spark/pull/195
>> >> >> >>
>> >> >> >> With the references to the way I changed Debian packaging for
>> >> >> ClearStory,
>> >> >> >> we should be at least 90% of the way toward doing it right for
>> >> Apache.
>> >> >> >>
>> >> >> >>
>> >> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <
>> pwendell@gmail.com>
>> >> >> wrote:
>> >> >> >>
>> >> >> >>> For my own part I'll give a +1 to this RC.
>> >> >> >>>
>> >> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
>> >> taka.epsilon@gmail.com
>> >> >> >
>> >> >> >>> wrote:
>> >> >> >>> > OK. I will post the entire output via separate email. I just
>> >> upgraded
>> >> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need
>> to
>> >> >> >>> > remove/clean up.
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
>> >> pwendell@gmail.com>
>> >> >> >>> wrote:
>> >> >> >>> >
>> >> >> >>> >> Hey Take,
>> >> >> >>> >>
>> >> >> >>> >> Could you start a separate thread to debug your build issue?
>> In
>> >> that
>> >> >> >>> >> thread, could you paste the exact build command and entire
>> >> output?
>> >> >> The
>> >> >> >>> log
>> >> >> >>> >> you posted here suggests the first build detected hadoop
>> 1.0.4
>> >> not
>> >> >> 2.2.0
>> >> >> >>> >> based on the assembly file name it is logging.
>> >> >> >>> >>
>> >> >> >>> >> ---
>> >> >> >>> >> sent from my phone
>> >> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <
>> taka.epsilon@gmail.com
>> >> >
>> >> >> >>> wrote:
>> >> >> >>> >>
>> >> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
>> >> trouble
>> >> >> >>> >> > completing the build process (sbt/sbt assembly) on
>> Macbook. The
>> >> >> sbt
>> >> >> >>> >> command
>> >> >> >>> >> > hangs at the last step.
>> >> >> >>> >> >
>> >> >> >>> >> > ...
>> >> >> >>> >> > ...
>> >> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>> >> >> >>> >> > [info] Packaging
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >>
>> >> >> >>>
>> >> >>
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>> >> >> >>> >> > ...
>> >> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>> >> >> >>> >> > [info] Packaging
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >>
>> >> >> >>>
>> >> >>
>> >>
>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>> >> >> >>> >> > ...
>> >> >> >>> >> > (hangs here)
>> >> >> >>> >> > --------------------------
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
>> >> installed,
>> >> >> I
>> >> >> >>> was
>> >> >> >>> >> > able to build it successfully.
>> >> >> >>> >> > ..
>> >> >> >>> >> > ..
>> >> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>> >> >> >>> >> > [info] Packaging
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >>
>> >> >> >>>
>> >> >>
>> >>
>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>> >> >> >>> >> > ...
>> >> >> >>> >> > [info] Done packaging.
>> >> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10
>> PM
>> >> >> >>> >> > --------------------------
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >> >
>> >> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
>> >> >> pwendell@gmail.com>
>> >> >> >>> >> > wrote:
>> >> >> >>> >> >
>> >> >> >>> >> > > Please vote on releasing the following candidate as
>> Apache
>> >> Spark
>> >> >> >>> >> > > (incubating) version 0.8.1.
>> >> >> >>> >> > >
>> >> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
>> >> bf23794a):
>> >> >> >>> >> > >
>> >> >> >>> >> > >
>> >> >> >>> >> >
>> >> >> >>> >>
>> >> >> >>>
>> >> >>
>> >>
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>> >> >> >>> >> > >
>> >> >> >>> >> > > The release files, including signatures, digests, etc
>> can be
>> >> >> found
>> >> >> >>> at:
>> >> >> >>> >> > >
>> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>> >> >> >>> >> > >
>> >> >> >>> >> > > Release artifacts are signed with the following key:
>> >> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>> >> >> >>> >> > >
>> >> >> >>> >> > > The staging repository for this release can be found at:
>> >> >> >>> >> > >
>> >> >> >>>
>> >> https://repository.apache.org/content/repositories/orgapachespark-024/
>> >> >> >>> >> > >
>> >> >> >>> >> > > The documentation corresponding to this release can be
>> found
>> >> at:
>> >> >> >>> >> > >
>> >> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>> >> >> >>> >> > >
>> >> >> >>> >> > > For information about the contents of this release see:
>> >> >> >>> >> > > <attached> draft of release notes
>> >> >> >>> >> > > <attached> draft of release credits
>> >> >> >>> >> > >
>> >> >> >>>
>> >> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>> >> >> >>> >> > >
>> >> >> >>> >> > > Please vote on releasing this package as Apache Spark
>> >> >> >>> 0.8.1-incubating!
>> >> >> >>> >> > >
>> >> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00
>> UTC
>> >> and
>> >> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are
>> cast.
>> >> >> >>> >> > >
>> >> >> >>> >> > > [ ] +1 Release this package as Apache Spark
>> 0.8.1-incubating
>> >> >> >>> >> > > [ ] -1 Do not release this package because ...
>> >> >> >>> >> > >
>> >> >> >>> >> > > To learn more about Apache Spark, please see
>> >> >> >>> >> > > http://spark.incubator.apache.org/
>> >> >> >>> >> > >
>> >> >> >>> >> >
>> >> >> >>> >>
>> >> >> >>>
>> >> >>
>> >>
>>
>
>

--047d7bea4532f085c304ed129e72--

From dev-return-856-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 05:13:44 2013
Return-Path: <dev-return-856-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BFE6C10D80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 05:13:44 +0000 (UTC)
Received: (qmail 89993 invoked by uid 500); 9 Dec 2013 05:13:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89940 invoked by uid 500); 9 Dec 2013 05:13:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 89931 invoked by uid 99); 9 Dec 2013 05:13:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 05:13:39 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.54 as permitted sender)
Received: from [209.85.219.54] (HELO mail-oa0-f54.google.com) (209.85.219.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 05:13:33 +0000
Received: by mail-oa0-f54.google.com with SMTP id h16so3322677oag.41
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 21:13:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=BcdSP443/Q3AFQVCIiZBvarGa7cBO59fSw/c4nn+cRE=;
        b=WH0rtyLZqCHGTJum0qdrvBKJI+6m2UREvdLzlBL7TJBHYTLnavmRJtI1r7pGXqkm9I
         hSixKFtfqkvoQlqW/FvZmWG5vd1Yg5ISrjoV+pHMd2ndXF92QjazI3+Nno0epXy9RwXj
         1CF1xGQ34B6LkrckTu/IcLtBY+mBofWzEE3ZJotnQKV6x7jKghi1QgW5Wjpkd+vX/wJi
         v/FppqMHJX7vvBa7v+hGM/psm12JlskT2ATHHD1LxOhmGCGQwdxBfFJ+Ji/57lSWy62+
         O2jeKvDsRajwsMAUjHcC4yVeGLjYMSWndKPdANPTjwcYcK6FU/BbAH8RqzAVaC6SRrAj
         M7LA==
MIME-Version: 1.0
X-Received: by 10.60.103.106 with SMTP id fv10mr2024749oeb.44.1386565992746;
 Sun, 08 Dec 2013 21:13:12 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 21:13:12 -0800 (PST)
In-Reply-To: <CAAsvFP=UmVekB5DfuwfOHSbY=dCqKSZEDK4ZpGWZWnMg97BiFg@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
	<CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
	<CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
	<CAAsvFPmx4mEnB03d5S6Nbky39BnWeg1YrPk5Mk6+hKkuVV0HjQ@mail.gmail.com>
	<CAAsvFP=UmVekB5DfuwfOHSbY=dCqKSZEDK4ZpGWZWnMg97BiFg@mail.gmail.com>
Date: Sun, 8 Dec 2013 21:13:12 -0800
Message-ID: <CABPQxsteVNJxazrj9tDLxzRz3BV-ASCuB4wK=JCv7SFxbNEA=A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Okay Mark thanks for bringing this up, I'm going to cut a new RC with this fix.

On Sun, Dec 8, 2013 at 8:42 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
> And I think 195 is sufficient to build something that works; but I haven't
> personally tested it.
>
>
> On Sun, Dec 8, 2013 at 8:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:
>
>> Well, what I've already done for ClearStory is very close to how Debian
>> packaging should be done for Apache Spark.  That much can be put into a
>> pull request quickly.  The only real issues are exactly how the packages
>> should be named, checking that the metadata of the packages are exactly
>> correct for an Apache release, and deciding whether we should be producing
>> a spark-examples package, spark-tools package, separate the Java and Python
>> APIs into their own packages, create a source package, etc.  What we've
>> been doing up to now is essentially just the minimal packaging of a fat jar
>> that can be deployed by Chef or something similar.  It's never really been
>> put together in a way appropriate to go into a Debian or Ubuntu
>> distribution, for instance.
>>
>>
>> On Sun, Dec 8, 2013 at 8:25 PM, Patrick Wendell <pwendell@gmail.com>wrote:
>>
>>> Hey Mark,
>>>
>>> Okay if 195 gets this in working order in the branch 0.8 let's just
>>> merge that to keep it consistent with our docs and the way this is
>>> done in 0.8.0
>>>
>>> We can do a broader refactoring in 0.9. Would be great if you could
>>> kick off a JIRA discussion or submit a PR relating to that.
>>>
>>> - Patrick
>>>
>>> On Sun, Dec 8, 2013 at 8:07 PM, Mark Hamstra <mark@clearstorydata.com>
>>> wrote:
>>> > Well, 195 is sufficient to give you something that runs, but it doesn't
>>> run
>>> > the same way as Spark built/distributed by other means -- e.g., after
>>> 195
>>> > the package still uses something equivalent to the old `run` script
>>> instead
>>> > of the current `spark-class` way.
>>> >
>>> >
>>> > On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>> >
>>> >> Hey Mark,
>>> >>
>>> >> What I'm asking is whether this patch is sufficient to have a working
>>> >> debian build in 0.8.1, or are there other outstanding issues to make
>>> >> it work? By working I mean, within the initial design that was
>>> >> contributed (with repl-bin) it works according to that approach.
>>> >>
>>> >> We can redesign this packaging in 0.9. That will require having a PR
>>> >> against Apache Spark, discussing, etc. But it doesn't need to be on
>>> >> the critical path for this release.
>>> >>
>>> >> - Patrick
>>> >>
>>> >> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
>>> >> wrote:
>>> >> > Whatever Debian package gets built has to work, so that's the first
>>> >> > requirement.  I don't know how to decide whether a change is
>>> acceptable
>>> >> in
>>> >> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
>>> >> > leverage the assembly sub-project, making repl-bin unnecessary.
>>> >> >
>>> >> >
>>> >> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
>>> >> wrote:
>>> >> >
>>> >> >> Looked into this a bit more - I think removing repl-bin is something
>>> >> >> we should wait until 0.9 to do, because we've published it to maven
>>> in
>>> >> >> 0.8.0 and people might expect it to be there in 0.8.1.
>>> >> >>
>>> >> >> Merging the directly referenced pull request (195) seems like a good
>>> >> >> idea though since it fixes a bug in the script.
>>> >> >>
>>> >> >> Is that what you are suggesting?
>>> >> >>
>>> >> >> - Patrick
>>> >> >>
>>> >> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com
>>> >
>>> >> >> wrote:
>>> >> >> > Hey Mark - ya this would be good to get in.
>>> >> >> >
>>> >> >> > Does merging that particular PR put this in sufficient shape for
>>> the
>>> >> >> > 0.8.1 release or are there other open patches we need to look at?
>>> >> >> >
>>> >> >> > - Patrick
>>> >> >> >
>>> >> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <
>>> mark@clearstorydata.com
>>> >> >
>>> >> >> wrote:
>>> >> >> >> SPARK-962 should be resolved before release.  See also:
>>> >> >> >> https://github.com/apache/incubator-spark/pull/195
>>> >> >> >>
>>> >> >> >> With the references to the way I changed Debian packaging for
>>> >> >> ClearStory,
>>> >> >> >> we should be at least 90% of the way toward doing it right for
>>> >> Apache.
>>> >> >> >>
>>> >> >> >>
>>> >> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <
>>> pwendell@gmail.com>
>>> >> >> wrote:
>>> >> >> >>
>>> >> >> >>> For my own part I'll give a +1 to this RC.
>>> >> >> >>>
>>> >> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
>>> >> taka.epsilon@gmail.com
>>> >> >> >
>>> >> >> >>> wrote:
>>> >> >> >>> > OK. I will post the entire output via separate email. I just
>>> >> upgraded
>>> >> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need
>>> to
>>> >> >> >>> > remove/clean up.
>>> >> >> >>> >
>>> >> >> >>> >
>>> >> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
>>> >> pwendell@gmail.com>
>>> >> >> >>> wrote:
>>> >> >> >>> >
>>> >> >> >>> >> Hey Take,
>>> >> >> >>> >>
>>> >> >> >>> >> Could you start a separate thread to debug your build issue?
>>> In
>>> >> that
>>> >> >> >>> >> thread, could you paste the exact build command and entire
>>> >> output?
>>> >> >> The
>>> >> >> >>> log
>>> >> >> >>> >> you posted here suggests the first build detected hadoop
>>> 1.0.4
>>> >> not
>>> >> >> 2.2.0
>>> >> >> >>> >> based on the assembly file name it is logging.
>>> >> >> >>> >>
>>> >> >> >>> >> ---
>>> >> >> >>> >> sent from my phone
>>> >> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <
>>> taka.epsilon@gmail.com
>>> >> >
>>> >> >> >>> wrote:
>>> >> >> >>> >>
>>> >> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
>>> >> trouble
>>> >> >> >>> >> > completing the build process (sbt/sbt assembly) on
>>> Macbook. The
>>> >> >> sbt
>>> >> >> >>> >> command
>>> >> >> >>> >> > hangs at the last step.
>>> >> >> >>> >> >
>>> >> >> >>> >> > ...
>>> >> >> >>> >> > ...
>>> >> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>>> >> >> >>> >> > [info] Packaging
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >>
>>> >> >> >>>
>>> >> >>
>>> >>
>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>>> >> >> >>> >> > ...
>>> >> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>>> >> >> >>> >> > [info] Packaging
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >>
>>> >> >> >>>
>>> >> >>
>>> >>
>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>>> >> >> >>> >> > ...
>>> >> >> >>> >> > (hangs here)
>>> >> >> >>> >> > --------------------------
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
>>> >> installed,
>>> >> >> I
>>> >> >> >>> was
>>> >> >> >>> >> > able to build it successfully.
>>> >> >> >>> >> > ..
>>> >> >> >>> >> > ..
>>> >> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>>> >> >> >>> >> > [info] Packaging
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >>
>>> >> >> >>>
>>> >> >>
>>> >>
>>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>>> >> >> >>> >> > ...
>>> >> >> >>> >> > [info] Done packaging.
>>> >> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10
>>> PM
>>> >> >> >>> >> > --------------------------
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >> >
>>> >> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
>>> >> >> pwendell@gmail.com>
>>> >> >> >>> >> > wrote:
>>> >> >> >>> >> >
>>> >> >> >>> >> > > Please vote on releasing the following candidate as
>>> Apache
>>> >> Spark
>>> >> >> >>> >> > > (incubating) version 0.8.1.
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
>>> >> bf23794a):
>>> >> >> >>> >> > >
>>> >> >> >>> >> > >
>>> >> >> >>> >> >
>>> >> >> >>> >>
>>> >> >> >>>
>>> >> >>
>>> >>
>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > The release files, including signatures, digests, etc
>>> can be
>>> >> >> found
>>> >> >> >>> at:
>>> >> >> >>> >> > >
>>> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > Release artifacts are signed with the following key:
>>> >> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > The staging repository for this release can be found at:
>>> >> >> >>> >> > >
>>> >> >> >>>
>>> >> https://repository.apache.org/content/repositories/orgapachespark-024/
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > The documentation corresponding to this release can be
>>> found
>>> >> at:
>>> >> >> >>> >> > >
>>> >> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > For information about the contents of this release see:
>>> >> >> >>> >> > > <attached> draft of release notes
>>> >> >> >>> >> > > <attached> draft of release credits
>>> >> >> >>> >> > >
>>> >> >> >>>
>>> >> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > Please vote on releasing this package as Apache Spark
>>> >> >> >>> 0.8.1-incubating!
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00
>>> UTC
>>> >> and
>>> >> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are
>>> cast.
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > [ ] +1 Release this package as Apache Spark
>>> 0.8.1-incubating
>>> >> >> >>> >> > > [ ] -1 Do not release this package because ...
>>> >> >> >>> >> > >
>>> >> >> >>> >> > > To learn more about Apache Spark, please see
>>> >> >> >>> >> > > http://spark.incubator.apache.org/
>>> >> >> >>> >> > >
>>> >> >> >>> >> >
>>> >> >> >>> >>
>>> >> >> >>>
>>> >> >>
>>> >>
>>>
>>
>>

From dev-return-857-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 06:30:56 2013
Return-Path: <dev-return-857-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CB7F810F3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 06:30:56 +0000 (UTC)
Received: (qmail 76926 invoked by uid 500); 9 Dec 2013 06:30:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76195 invoked by uid 500); 9 Dec 2013 06:30:53 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 76146 invoked by uid 99); 9 Dec 2013 06:30:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 06:30:49 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.46 as permitted sender)
Received: from [209.85.219.46] (HELO mail-oa0-f46.google.com) (209.85.219.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 06:30:44 +0000
Received: by mail-oa0-f46.google.com with SMTP id o6so3397158oag.33
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 22:30:23 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=jii5eN1gqMeL2ghXly2Wv9szBf2pNeCdNYmXmRgqNJk=;
        b=P9hlSWqzN18tdMZVXwGx6bW5Gv0Q9sAVJCBucKVyR9feN55AMFi7sapD/sA7sQZfw5
         ufRDE6KV1lozMp4Vgg4e+EpYjb79NYy17/gn6Ngd0hdK18uJptqHlizeXTdNz/4qA3w8
         PLVSocN0xQKElBIu0G3LT+BFR3dI1kz5z5/9pC8tabMQ4f5hILer1jvctMC7GABvnZ65
         GwxbpyeHUQmvhlqq23vF/klRjjQpu4xAHBrzeLAUpA51+u/rR2NMTa0TqzQz+SsNXj5x
         B3t3iB2NoSTrDSUJwALnnRQsuKlzqAyDuynu6TZahwqy4PCx4OhJut5L/Cgb4T1X/SKQ
         ZAkw==
MIME-Version: 1.0
X-Received: by 10.60.63.102 with SMTP id f6mr130586oes.76.1386570623652; Sun,
 08 Dec 2013 22:30:23 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 22:30:23 -0800 (PST)
Date: Sun, 8 Dec 2013 22:30:23 -0800
Message-ID: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/mixed; boundary=001a11c255327b4e5104ed142118
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c255327b4e5104ed142118
Content-Type: text/plain; charset=ISO-8859-1

Please vote on releasing the following candidate as Apache Spark
(incubating) version 0.8.1.

The tag to be voted on is v0.8.1-incubating (commit c88a9916):
https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=ba05afd29c81e152a84461f95b0e61a783897d7a

The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-025/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/

For information about the contents of this release see:
<attached> draft of release notes
<attached> draft of release credits
https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8

Please vote on releasing this package as Apache Spark 0.8.1-incubating!

The vote is open until Thursday, December 12th at 06:30 UTC and
passes if a majority of at least 3 +1 PPMC votes are cast.

[ ] +1 Release this package as Apache Spark 0.8.1-incubating
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.incubator.apache.org/

--001a11c255327b4e5104ed142118
Content-Type: text/plain; charset=UTF-8; name="0.8.1-credits.txt"
Content-Disposition: attachment; filename="0.8.1-credits.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hozc5noe0
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--001a11c255327b4e5104ed142118
Content-Type: text/plain; charset=UTF-8; name="0.8.1-notes.txt"
Content-Disposition: attachment; filename="0.8.1-notes.txt"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hozc5npq1
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--001a11c255327b4e5104ed142118--

From dev-return-858-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 06:31:25 2013
Return-Path: <dev-return-858-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 568A310F43
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 06:31:25 +0000 (UTC)
Received: (qmail 77581 invoked by uid 500); 9 Dec 2013 06:31:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77485 invoked by uid 500); 9 Dec 2013 06:31:17 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 77407 invoked by uid 99); 9 Dec 2013 06:31:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 06:31:14 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 06:31:10 +0000
Received: by mail-ob0-f176.google.com with SMTP id va2so3274457obc.35
        for <dev@spark.incubator.apache.org>; Sun, 08 Dec 2013 22:30:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=ZZJo1iHMmGnpdO7w7dEp9cRqGf/D8NgyDw6rfOQsM+8=;
        b=eOoqHUaAj/lY7qn4xaGRph+PnnBFPsUFj7Y+wSt0s1AkyMgx2OejbipyT9r/eVxZYY
         E/MycbeVASiun4aN+xua7fGuDIIFMKZHNM5xVRxN4dt0hH2gerhauWO4tpSCAx1vtqFe
         4Qv0JN4upHFRwIP21/6NG/6ll29pRVtUQxup5RO7ahqR0ALU5iXeVrXMewDR+mLsUGrq
         Uci6r1bdK21JTZgnJjLvrmbAB+GG0dM2989bfrtv3dfw4ooGG+2gnNH3+JIRIC48HIj8
         KQu7m4kFzObKi8IkCmMvL1Fj81atjC4pnmyoRFF06Tt3XZYoKIv4+l5umwSJYcEOifa3
         FxMw==
MIME-Version: 1.0
X-Received: by 10.60.17.70 with SMTP id m6mr4892oed.59.1386570650314; Sun, 08
 Dec 2013 22:30:50 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 8 Dec 2013 22:30:50 -0800 (PST)
In-Reply-To: <CABPQxsteVNJxazrj9tDLxzRz3BV-ASCuB4wK=JCv7SFxbNEA=A@mail.gmail.com>
References: <CABPQxstGVkW+zef6p3rc4_nN5PJ8WXh3xcidrRcDGB0eaZ5Fcw@mail.gmail.com>
	<CALkvKbkfgRiT1TE7DnYKxvKJnhD0O5yTSHNZ=SAE3SoaNPVX6w@mail.gmail.com>
	<CABPQxssUZd3E1fj-02274TYxR=kNXxjy+EESb+yqV+4YhaQ_dQ@mail.gmail.com>
	<CALkvKbk9DRazMbuB_QSnpjFrwoh2UuHTLZ_3hAWn+QrDDF+_ug@mail.gmail.com>
	<CABPQxsvLg_SksM6ZoyMMZtfzOq-RpDg8o9W_G26OoK2fr_Qr7A@mail.gmail.com>
	<CAAsvFPmJmv+5G0neJmHTG8MdZauWET-Sq9NkNU0byugd2Cs-0A@mail.gmail.com>
	<CABPQxstnbcA+58H2bAegi7Ly2Cxn32TfheRnisS-Pw6KPWkr_g@mail.gmail.com>
	<CABPQxstsXxm=-nnr7XmvzEg8NRzx6F-F_5wuYiAZ3pPm8BfpuQ@mail.gmail.com>
	<CAAsvFP=dzj5_iwk2Wyww20sGL5EfLot5N1JMVdYJS9704_hDvw@mail.gmail.com>
	<CABPQxsu8pA9W8Sq4wmeLmWRAy4V78sFSHJyF7VgDSn-W0gpY3Q@mail.gmail.com>
	<CAAsvFPmsHU2WP=A7MtUaB=kt0r-Nu58Q5NtACbK6bh37kYjsUw@mail.gmail.com>
	<CABPQxstbF8-in=5r_yhG-RwKae1vQoBgHbwL-e8_Gt8v=mNJ2g@mail.gmail.com>
	<CAAsvFPmx4mEnB03d5S6Nbky39BnWeg1YrPk5Mk6+hKkuVV0HjQ@mail.gmail.com>
	<CAAsvFP=UmVekB5DfuwfOHSbY=dCqKSZEDK4ZpGWZWnMg97BiFg@mail.gmail.com>
	<CABPQxsteVNJxazrj9tDLxzRz3BV-ASCuB4wK=JCv7SFxbNEA=A@mail.gmail.com>
Date: Sun, 8 Dec 2013 22:30:50 -0800
Message-ID: <CABPQxsscmsaM5S5Ag+Ke=L6cs-te3PpsTHutvh87eXToSw3Hcg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'm cancelling this vote in favor of RC3.

On Sun, Dec 8, 2013 at 9:13 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Okay Mark thanks for bringing this up, I'm going to cut a new RC with this fix.
>
> On Sun, Dec 8, 2013 at 8:42 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
>> And I think 195 is sufficient to build something that works; but I haven't
>> personally tested it.
>>
>>
>> On Sun, Dec 8, 2013 at 8:41 PM, Mark Hamstra <mark@clearstorydata.com>wrote:
>>
>>> Well, what I've already done for ClearStory is very close to how Debian
>>> packaging should be done for Apache Spark.  That much can be put into a
>>> pull request quickly.  The only real issues are exactly how the packages
>>> should be named, checking that the metadata of the packages are exactly
>>> correct for an Apache release, and deciding whether we should be producing
>>> a spark-examples package, spark-tools package, separate the Java and Python
>>> APIs into their own packages, create a source package, etc.  What we've
>>> been doing up to now is essentially just the minimal packaging of a fat jar
>>> that can be deployed by Chef or something similar.  It's never really been
>>> put together in a way appropriate to go into a Debian or Ubuntu
>>> distribution, for instance.
>>>
>>>
>>> On Sun, Dec 8, 2013 at 8:25 PM, Patrick Wendell <pwendell@gmail.com>wrote:
>>>
>>>> Hey Mark,
>>>>
>>>> Okay if 195 gets this in working order in the branch 0.8 let's just
>>>> merge that to keep it consistent with our docs and the way this is
>>>> done in 0.8.0
>>>>
>>>> We can do a broader refactoring in 0.9. Would be great if you could
>>>> kick off a JIRA discussion or submit a PR relating to that.
>>>>
>>>> - Patrick
>>>>
>>>> On Sun, Dec 8, 2013 at 8:07 PM, Mark Hamstra <mark@clearstorydata.com>
>>>> wrote:
>>>> > Well, 195 is sufficient to give you something that runs, but it doesn't
>>>> run
>>>> > the same way as Spark built/distributed by other means -- e.g., after
>>>> 195
>>>> > the package still uses something equivalent to the old `run` script
>>>> instead
>>>> > of the current `spark-class` way.
>>>> >
>>>> >
>>>> > On Sun, Dec 8, 2013 at 8:02 PM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>> >
>>>> >> Hey Mark,
>>>> >>
>>>> >> What I'm asking is whether this patch is sufficient to have a working
>>>> >> debian build in 0.8.1, or are there other outstanding issues to make
>>>> >> it work? By working I mean, within the initial design that was
>>>> >> contributed (with repl-bin) it works according to that approach.
>>>> >>
>>>> >> We can redesign this packaging in 0.9. That will require having a PR
>>>> >> against Apache Spark, discussing, etc. But it doesn't need to be on
>>>> >> the critical path for this release.
>>>> >>
>>>> >> - Patrick
>>>> >>
>>>> >> On Sun, Dec 8, 2013 at 7:54 PM, Mark Hamstra <mark@clearstorydata.com>
>>>> >> wrote:
>>>> >> > Whatever Debian package gets built has to work, so that's the first
>>>> >> > requirement.  I don't know how to decide whether a change is
>>>> acceptable
>>>> >> in
>>>> >> > 0.8 or has to wait until 0.9, but the 0.9 packaging should definitely
>>>> >> > leverage the assembly sub-project, making repl-bin unnecessary.
>>>> >> >
>>>> >> >
>>>> >> > On Sun, Dec 8, 2013 at 7:46 PM, Patrick Wendell <pwendell@gmail.com>
>>>> >> wrote:
>>>> >> >
>>>> >> >> Looked into this a bit more - I think removing repl-bin is something
>>>> >> >> we should wait until 0.9 to do, because we've published it to maven
>>>> in
>>>> >> >> 0.8.0 and people might expect it to be there in 0.8.1.
>>>> >> >>
>>>> >> >> Merging the directly referenced pull request (195) seems like a good
>>>> >> >> idea though since it fixes a bug in the script.
>>>> >> >>
>>>> >> >> Is that what you are suggesting?
>>>> >> >>
>>>> >> >> - Patrick
>>>> >> >>
>>>> >> >> On Sun, Dec 8, 2013 at 7:30 PM, Patrick Wendell <pwendell@gmail.com
>>>> >
>>>> >> >> wrote:
>>>> >> >> > Hey Mark - ya this would be good to get in.
>>>> >> >> >
>>>> >> >> > Does merging that particular PR put this in sufficient shape for
>>>> the
>>>> >> >> > 0.8.1 release or are there other open patches we need to look at?
>>>> >> >> >
>>>> >> >> > - Patrick
>>>> >> >> >
>>>> >> >> > On Sun, Dec 8, 2013 at 6:05 PM, Mark Hamstra <
>>>> mark@clearstorydata.com
>>>> >> >
>>>> >> >> wrote:
>>>> >> >> >> SPARK-962 should be resolved before release.  See also:
>>>> >> >> >> https://github.com/apache/incubator-spark/pull/195
>>>> >> >> >>
>>>> >> >> >> With the references to the way I changed Debian packaging for
>>>> >> >> ClearStory,
>>>> >> >> >> we should be at least 90% of the way toward doing it right for
>>>> >> Apache.
>>>> >> >> >>
>>>> >> >> >>
>>>> >> >> >> On Sun, Dec 8, 2013 at 5:29 PM, Patrick Wendell <
>>>> pwendell@gmail.com>
>>>> >> >> wrote:
>>>> >> >> >>
>>>> >> >> >>> For my own part I'll give a +1 to this RC.
>>>> >> >> >>>
>>>> >> >> >>> On Sun, Dec 8, 2013 at 4:30 PM, Taka Shinagawa <
>>>> >> taka.epsilon@gmail.com
>>>> >> >> >
>>>> >> >> >>> wrote:
>>>> >> >> >>> > OK. I will post the entire output via separate email. I just
>>>> >> upgraded
>>>> >> >> >>> > Hadoop to 2.2.0 recently. So there might be something I need
>>>> to
>>>> >> >> >>> > remove/clean up.
>>>> >> >> >>> >
>>>> >> >> >>> >
>>>> >> >> >>> > On Sun, Dec 8, 2013 at 4:24 PM, Patrick Wendell <
>>>> >> pwendell@gmail.com>
>>>> >> >> >>> wrote:
>>>> >> >> >>> >
>>>> >> >> >>> >> Hey Take,
>>>> >> >> >>> >>
>>>> >> >> >>> >> Could you start a separate thread to debug your build issue?
>>>> In
>>>> >> that
>>>> >> >> >>> >> thread, could you paste the exact build command and entire
>>>> >> output?
>>>> >> >> The
>>>> >> >> >>> log
>>>> >> >> >>> >> you posted here suggests the first build detected hadoop
>>>> 1.0.4
>>>> >> not
>>>> >> >> 2.2.0
>>>> >> >> >>> >> based on the assembly file name it is logging.
>>>> >> >> >>> >>
>>>> >> >> >>> >> ---
>>>> >> >> >>> >> sent from my phone
>>>> >> >> >>> >> On Dec 8, 2013 4:13 PM, "Taka Shinagawa" <
>>>> taka.epsilon@gmail.com
>>>> >> >
>>>> >> >> >>> wrote:
>>>> >> >> >>> >>
>>>> >> >> >>> >> > With Hadoop 2.2.0 (& Java 1.7.0_45) installed, I'm having
>>>> >> trouble
>>>> >> >> >>> >> > completing the build process (sbt/sbt assembly) on
>>>> Macbook. The
>>>> >> >> sbt
>>>> >> >> >>> >> command
>>>> >> >> >>> >> > hangs at the last step.
>>>> >> >> >>> >> >
>>>> >> >> >>> >> > ...
>>>> >> >> >>> >> > ...
>>>> >> >> >>> >> > [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
>>>> >> >> >>> >> > [info] Packaging
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >>
>>>> >> >> >>>
>>>> >> >>
>>>> >>
>>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
>>>> >> >> >>> >> > ...
>>>> >> >> >>> >> > [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
>>>> >> >> >>> >> > [info] Packaging
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >>
>>>> >> >> >>>
>>>> >> >>
>>>> >>
>>>> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
>>>> >> >> >>> >> > ...
>>>> >> >> >>> >> > (hangs here)
>>>> >> >> >>> >> > --------------------------
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >> > On another Macbook with Hadoop 1.1.1 (& Java 1.7.0_45)
>>>> >> installed,
>>>> >> >> I
>>>> >> >> >>> was
>>>> >> >> >>> >> > able to build it successfully.
>>>> >> >> >>> >> > ..
>>>> >> >> >>> >> > ..
>>>> >> >> >>> >> > [info] SHA-1: 77109cd085bd4f0d2b601b3451b35b961d357534
>>>> >> >> >>> >> > [info] Packaging
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >>
>>>> >> >> >>>
>>>> >> >>
>>>> >>
>>>> /Users/tshinagawa/Documents/Spark/RCs/spark-0.8.1-incubating/examples/target/scala-2.9.3/spark-examples-assembly-0.8.1-incubating.jar
>>>> >> >> >>> >> > ...
>>>> >> >> >>> >> > [info] Done packaging.
>>>> >> >> >>> >> > [success] Total time: 266 s, completed Dec 8, 2013 3:03:10
>>>> PM
>>>> >> >> >>> >> > --------------------------
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >> >
>>>> >> >> >>> >> > On Sun, Dec 8, 2013 at 12:41 PM, Patrick Wendell <
>>>> >> >> pwendell@gmail.com>
>>>> >> >> >>> >> > wrote:
>>>> >> >> >>> >> >
>>>> >> >> >>> >> > > Please vote on releasing the following candidate as
>>>> Apache
>>>> >> Spark
>>>> >> >> >>> >> > > (incubating) version 0.8.1.
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > The tag to be voted on is v0.8.1-incubating (commit
>>>> >> bf23794a):
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> >
>>>> >> >> >>> >>
>>>> >> >> >>>
>>>> >> >>
>>>> >>
>>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=e6ba91b5a7527316202797fc3dce469ff86cf203
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > The release files, including signatures, digests, etc
>>>> can be
>>>> >> >> found
>>>> >> >> >>> at:
>>>> >> >> >>> >> > >
>>>> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2/
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > Release artifacts are signed with the following key:
>>>> >> >> >>> >> > > https://people.apache.org/keys/committer/pwendell.asc
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > The staging repository for this release can be found at:
>>>> >> >> >>> >> > >
>>>> >> >> >>>
>>>> >> https://repository.apache.org/content/repositories/orgapachespark-024/
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > The documentation corresponding to this release can be
>>>> found
>>>> >> at:
>>>> >> >> >>> >> > >
>>>> >> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc2-docs/
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > For information about the contents of this release see:
>>>> >> >> >>> >> > > <attached> draft of release notes
>>>> >> >> >>> >> > > <attached> draft of release credits
>>>> >> >> >>> >> > >
>>>> >> >> >>>
>>>> >> https://github.com/apache/incubator-spark/blob/branch-0.8/CHANGES.txt
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > Please vote on releasing this package as Apache Spark
>>>> >> >> >>> 0.8.1-incubating!
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > The vote is open until Wednesday, December 11th at 21:00
>>>> UTC
>>>> >> and
>>>> >> >> >>> >> > > passes if a majority of at least 3 +1 PPMC votes are
>>>> cast.
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > [ ] +1 Release this package as Apache Spark
>>>> 0.8.1-incubating
>>>> >> >> >>> >> > > [ ] -1 Do not release this package because ...
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> > > To learn more about Apache Spark, please see
>>>> >> >> >>> >> > > http://spark.incubator.apache.org/
>>>> >> >> >>> >> > >
>>>> >> >> >>> >> >
>>>> >> >> >>> >>
>>>> >> >> >>>
>>>> >> >>
>>>> >>
>>>>
>>>
>>>

From dev-return-859-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 08:06:21 2013
Return-Path: <dev-return-859-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 57C2110102
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 08:06:21 +0000 (UTC)
Received: (qmail 89462 invoked by uid 500); 9 Dec 2013 08:06:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89431 invoked by uid 500); 9 Dec 2013 08:06:14 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 89410 invoked by uid 99); 9 Dec 2013 08:06:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 08:06:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.160.43 as permitted sender)
Received: from [209.85.160.43] (HELO mail-pb0-f43.google.com) (209.85.160.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 08:06:04 +0000
Received: by mail-pb0-f43.google.com with SMTP id rq2so4945084pbb.2
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 00:05:43 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=GwpoCqVtGEEloaJTbFDQHf1M4OCJI9FqIeZGyX708mc=;
        b=kYIk0VWSnofDxK1mIFsF459Jds0EDHuKi8MHQHlHIswZ93XoLOLx/duh3mjhF2+jlf
         j5EErcNwoOA2p1WueCvKhmE3jTX7ecWrNLUfDJglm9JvQNagcjciSmzxuoU2ggDIm8mO
         esUhzPnlstI6DR5Tk0uGLf4Iip61PZzB1B5hA72zENL+1GKt6MccQmzoYIKVmuxHdUUI
         m0U7yYfCzLn/GtDki5VhqQ3yZSdc7WorzF55Sl9HrQquAng3Gu9CC4rFegQFQ2OJciBl
         0RoLoS84TwHbgVfPM8Qbt18z82AVXXhhFeE6ubpQ3g3AR2N1zu5hLhcnzy7rQngbcZAs
         5i9w==
X-Gm-Message-State: ALoCoQmjHcjUF/ewLlRvWGJkskXiEXKeFX4dIYC5u+1vWXA8otZD8o3K4MFNMg6zxWnrbS12nY6b
MIME-Version: 1.0
X-Received: by 10.68.235.72 with SMTP id uk8mr19404659pbc.93.1386576343148;
 Mon, 09 Dec 2013 00:05:43 -0800 (PST)
Received: by 10.70.52.2 with HTTP; Mon, 9 Dec 2013 00:05:43 -0800 (PST)
In-Reply-To: <F5B17C19-2CB1-4692-BC10-8CDE9F7F8966@gmail.com>
References: <CACBYxK+U=jZf_rxkHiYN1z=cbiST619CYeD3rgRLNExu5pvwEQ@mail.gmail.com>
	<CADp44=eWL6q7058LFwmqY7QVOMo8+Z=FPZd9jzW5SXoExOKnhA@mail.gmail.com>
	<F5B17C19-2CB1-4692-BC10-8CDE9F7F8966@gmail.com>
Date: Mon, 9 Dec 2013 00:05:43 -0800
Message-ID: <CACBYxKLaHs6GpmpMzYqBZPni9uBbMZ8grTsa1UasTHYBo32wnQ@mail.gmail.com>
Subject: Re: Spark streaming quantile?
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b33914f6344ec04ed1576bd
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b33914f6344ec04ed1576bd
Content-Type: text/plain; charset=ISO-8859-1

Thanks all for the suggestions.  Exactly what I was looking for.

-Sandy


On Thu, Dec 5, 2013 at 5:00 AM, Sam Bessalah <samkiller@gmail.com> wrote:

> Just as stated before Algebird has many data structure to compute those
> like QTree, or Ted's tvdigest . Or you can look at stream-lib q digest
> https://github.com/addthis/stream-lib/blob/master/src/main/java/com/clearspring/analytics/stream/quantile/QDigest.java
> Or another one Frugal Streaming well described and with an implementation
> on the AK blog
>
> http://blog.aggregateknowledge.com/2013/09/16/sketch-of-the-day-frugal-streaming/
> There are some example in the Spark streaming sample on how to integrate
> algebird .
> Sam Bessalah
>
> > On Dec 5, 2013, at 5:41 AM, Ryan Weald <ryan@weald.com> wrote:
> >
> > Hi Sandy,
> > You could take a look at using the Q-Tree data structure that is provided
> > by Twitter's Algebird<
> https://github.com/twitter/algebird/blob/develop/algebird-core/src/main/scala/com/twitter/algebird/QTree.scala
> >.
> > Due to the associative properties of Algebird's SemiGroup it is ideally
> > suited for streaming computations.
> >
> > -Ryan
> >
> >
> >> On Wed, Dec 4, 2013 at 8:32 PM, Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
> >>
> >> Hi All,
> >>
> >> We're working on a Spark application that could make use of a computing
> >> quantiles in a streaming fashion.  Something in the vein of what DataFu
> has
> >> for Pig
> >>
> >>
> http://linkedin.github.io/datafu/docs/current/datafu/pig/stats/StreamingQuantile.html
> >> .
> >>
> >> Does anything like this exist in the Spark ecosystem?  If not, would
> there
> >> be a good place to contribute this if we write it?
> >>
> >> thanks,
> >> Sandy
> >>
>

--047d7b33914f6344ec04ed1576bd--

From dev-return-860-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 09:12:38 2013
Return-Path: <dev-return-860-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D83AA102D0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 09:12:38 +0000 (UTC)
Received: (qmail 12013 invoked by uid 500); 9 Dec 2013 09:12:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11967 invoked by uid 500); 9 Dec 2013 09:12:32 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 11959 invoked by uid 99); 9 Dec 2013 09:12:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:12:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taka.epsilon@gmail.com designates 209.85.219.53 as permitted sender)
Received: from [209.85.219.53] (HELO mail-oa0-f53.google.com) (209.85.219.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:12:24 +0000
Received: by mail-oa0-f53.google.com with SMTP id m1so3446145oag.26
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 01:12:04 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=iLmfuINxSu8LrUUrHowGKfZDwMgnPJ3rb3ewQaVNbEU=;
        b=hUztFJVJxcuuiNXRtA3V/Z4JkY9cYgzg5Eek6npop52WOiNBuoxKKbCRXdVoF7TiMf
         ss3ykx6kYmTpVI5sqvBHjmP6IUXO//sw4o4HG1HRAUJizO3IL51nrmivgfUKASGnEXKi
         FSoXFM8eiUYb4D2fSiRa/R+TPnpTdEDm5TtSXu0eFN9RNnFw8XLmO7hbRnUBgfWdywcB
         nbwZlnlm2yRiyOjPijmXw8t649OX2KEkXPT7bJQVk6joZgOiX7I4dR40gxoAr6GOyqmN
         blcBVYge/VLqUS2rE8KBUNFPKXtYFXX93kIQds5OwL/YMHjOOQFZbq72O9H0CSLWRJWQ
         0FSA==
MIME-Version: 1.0
X-Received: by 10.182.213.97 with SMTP id nr1mr1771793obc.48.1386580323887;
 Mon, 09 Dec 2013 01:12:03 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Mon, 9 Dec 2013 01:12:03 -0800 (PST)
In-Reply-To: <CABPQxsuYoRVbvJ1k96uNwcpwvSN97wn4qZGEP_GL_S-Osb1cOw@mail.gmail.com>
References: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
	<CAAsvFPmkfWkXW=OAVLqNfyU2QB7mv_jMhuXkrzaCRBF9b05eYg@mail.gmail.com>
	<CABPQxsuYoRVbvJ1k96uNwcpwvSN97wn4qZGEP_GL_S-Osb1cOw@mail.gmail.com>
Date: Mon, 9 Dec 2013 01:12:03 -0800
Message-ID: <CALkvKb=ftPiOZj8mnqJdRwW0+Nc=Z_1pjRnCEeE4605t3ukJuA@mail.gmail.com>
Subject: Re: Spark Build Issue ('sbt/sbt assembly' hangs)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c20afca86f9004ed16638c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c20afca86f9004ed16638c
Content-Type: text/plain; charset=ISO-8859-1

Seems like I'm having the same issue as Mark. It's not about Hadoop
versions-- sorry about the confusion. It turns out that the build process
is not hanging, although CPU usage goes below 1%.

After waiting for more than 2 hours, the sbt assembly command finished
successfully on the Macbook Pro (with 2.4GHz Intel Core 2 Duo & 8GB RAM).
On my regular Macbook (with 2.3GHz Intel Core i7 & 16GB RAM), the build
with sbt always completes in about 4 minutes. So I never expected the sbt
assembly takes this much longer on the other Macbook. I also ran the same
sbt command on Ubuntu 12.04 LTS on VirtualBox, it took more than one hour
and a half. I'm seeing this problem on both Mac and Linux as well as with
0.8.0 release.

The solution seems to upgrade sbt-assembly to version 0.10.1 (and sbt to
0.13.0). But sbt 0.13 requires sbt-dependency-graph 0.7.4 (from 0.7.3),
which depends on Scala 2.10. So I've learned that we can't upgrade them for
this release.

Thanks for the help!






On Sun, Dec 8, 2013 at 5:28 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Taka,
>
> Most likely this is just the assembly task taking a long time as mark
> said. What happens if you run 'package' or 'compile'? It could be that
> on Mac's there is something where this is slow... I'm not sure.
>
> Also, unless you specify the hadoop version in the build it will build
> Hadoop 1.0.4. You keep mentioning Hadoop 2.2.0, but you didn't specify
> that when you built so Spark has no way of knowing what you want.
>
> Checkout the README for documentation on how to do that.
>
> Also - does this all work well in the 0.8.0 release? If this is not
> something specific to the 0.8.1 release than it would be good to know.
>
> - Patrick
>
> On Sun, Dec 8, 2013 at 5:06 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> > The assembly "hang" is something that I've also noticed over at least the
> > past few weeks.  If you are seeing what I am seeing, then the build is
> not
> > actually hung, but the building of assemblies takes a long time, a very
> > long time, a very very long time on Macs.  It's just the build of
> > assemblies via sbt on OSX that does this -- maven builds on Mac or any
> kind
> > of build on Linux go much faster.  On a Mac that also has other things to
> > do, I've seen the sbt assembly packaging take upwards of an hour.  Not
> good.
> >
> >
> > On Sun, Dec 8, 2013 at 4:46 PM, Taka Shinagawa <taka.epsilon@gmail.com
> >wrote:
> >
> >> As I reported in the Spark 0.8-1 RC2 thread, the 'sbt/sbt assembly'
> hangs
> >> at the last step. It happens on a Macbook with Hadoop 2.2.0 (& Java
> >> 1.7.0_45) installed. The build was successful on another system with
> Hadoop
> >> 1.1.1 installed.
> >>
> >> Here's the build command and the entire log. Thanks for the help.
> >>
> >> ---------------------------------------------------------------
> >> $ sbt/sbt assembly
> >> [info] Loading project definition from
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/}default-c4ca6d...
> >> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> >> [info] Done updating.
> >> [info] Compiling 1 Scala source to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/target/scala-2.9.2/sbt-0.12/classes...
> >> [info] Loading project definition from
> >> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/}plugins...
> >> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> >> [info] Done updating.
> >> [info] Compiling 1 Scala source to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/target/scala-2.9.2/sbt-0.12/classes...
> >> [info] Set current project to root (in build
> >> file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/)
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}core...
> >> [info] Resolving org.apache.derby#derby;10.4.2.0 ...
> >> [info] Done updating.
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}streaming...
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}bagel...
> >> [info] Resolving org.scala-lang#scala-library;2.9.3 ...
> >> [info] Done updating.
> >> [info] Resolving org.eclipse.jetty#jetty-util;7.6.8.v20121106 ...
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}mllib...
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}tools...
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}examples...
> >> [info] Resolving org.slf4j#slf4j-api;1.7.2 ...
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}repl...
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [info] Resolving org.apache.httpcomponents#httpcore;4.1 ...
> >> [info] Compiling 285 Scala sources and 18 Java sources to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/target/scala-2.9.3/classes...
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [info] Updating
> >>
> >>
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}assembly...
> >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> >> [info] Done updating.
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:131:
> >> method cleanupJob in class OutputCommitter is deprecated: see
> corresponding
> >> Javadoc for more information.
> >> [warn]     getOutputCommitter().cleanupJob(getJobContext())
> >> [warn]                          ^
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1059:
> >> class BitTorrentBroadcast in package broadcast is deprecated: Use
> >> TorrentBroadcast
> >> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> >> [warn]       ^
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1060:
> >> class BitTorrentBroadcast in package broadcast is deprecated: Use
> >> TorrentBroadcast
> >> [warn]     new BitTorrentBroadcast[T](value_, isLocal, id)
> >> [warn]         ^
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:600:
> >> class TreeBroadcast in package broadcast is deprecated: Use
> >> TorrentBroadcast
> >> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> >> [warn]       ^
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:601:
> >> class TreeBroadcast in package broadcast is deprecated: Use
> >> TorrentBroadcast
> >> [warn]     new TreeBroadcast[T](value_, isLocal, id)
> >> [warn]         ^
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:598:
> >> method cleanupJob in class OutputCommitter is deprecated: see
> corresponding
> >> Javadoc for more information.
> >> [warn]     jobCommitter.cleanupJob(jobTaskContext)
> >> [warn]                  ^
> >> [warn] 6 warnings found
> >> [warn] warning: [options] bootstrap class path not set in conjunction
> with
> >> -source 1.5
> >> [warn] Note: Some input files use unchecked or unsafe operations.
> >> [warn] Note: Recompile with -Xlint:unchecked for details.
> >> [warn] 1 warning
> >> [info] Compiling 1 Scala source to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/bagel/target/scala-2.9.3/classes...
> >> [info] Compiling 49 Scala sources to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/streaming/target/scala-2.9.3/classes...
> >> [info] Compiling 25 Scala sources to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/mllib/target/scala-2.9.3/classes...
> >> [info] Compiling 10 Scala sources to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/target/scala-2.9.3/classes...
> >> [warn]
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala:141:
> >> method stop in class Thread is deprecated: see corresponding Javadoc for
> >> more information.
> >> [warn]         line.thread.stop()
> >> [warn]                     ^
> >> [warn] one warning found
> >> [info] Compiling 39 Scala sources and 13 Java sources to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/examples/target/scala-2.9.3/classes...
> >> [info] Compiling 1 Scala source to
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/classes...
> >> [warn] warning: [options] bootstrap class path not set in conjunction
> with
> >> -source 1.5
> >> [warn] 1 warning
> >> [info] Including: scala-compiler.jar
> >> [info] Including: scala-compiler.jar
> >> [info] Including: scala-library.jar
> >> [info] Including: scala-library.jar
> >> [info] Including: compress-lzf-0.8.4.jar
> >> [info] Including: py4j-0.7.jar
> >> [info] Including: compress-lzf-0.8.4.jar
> >> [info] Including: config-0.3.1.jar
> >> [info] Including: config-0.3.1.jar
> >> [info] Including: guava-14.0.1.jar
> >> [info] Including: guava-14.0.1.jar
> >> [info] Including: kryo-2.21.jar
> >> [info] Including: kryo-2.21.jar
> >> [info] Including: log4j-1.2.17.jar
> >> [info] Including: log4j-1.2.17.jar
> >> [info] Including: metrics-core-3.0.0.jar
> >> [info] Including: metrics-core-3.0.0.jar
> >> [info] Including: metrics-ganglia-3.0.0.jar
> >> [info] Including: metrics-ganglia-3.0.0.jar
> >> [info] Including: metrics-json-3.0.0.jar
> >> [info] Including: metrics-json-3.0.0.jar
> >> [info] Including: metrics-jvm-3.0.0.jar
> >> [info] Including: metrics-jvm-3.0.0.jar
> >> [info] Including: netty-3.5.4.Final.jar
> >> [info] Including: netty-3.5.4.Final.jar
> >> [info] Including: snappy-java-1.0.5.jar
> >> [info] Including: snappy-java-1.0.5.jar
> >> [info] Including: akka-actor-2.0.5.jar
> >> [info] Including: akka-actor-2.0.5.jar
> >> [info] Including: akka-remote-2.0.5.jar
> >> [info] Including: akka-remote-2.0.5.jar
> >> [info] Including: akka-slf4j-2.0.5.jar
> >> [info] Including: akka-slf4j-2.0.5.jar
> >> [info] Including: akka-zeromq-2.0.5.jar
> >> [info] Including: akka-zeromq-2.0.5.jar
> >> [info] Including: asm-4.0.jar
> >> [info] Including: asm-4.0.jar
> >> [info] Including: asm-commons-4.0.jar
> >> [info] Including: asm-commons-4.0.jar
> >> [info] Including: asm-tree-4.0.jar
> >> [info] Including: asm-tree-4.0.jar
> >> [info] Including: avro-1.7.4.jar
> >> [info] Including: avro-1.7.4.jar
> >> [info] Including: avro-ipc-1.7.4.jar
> >> [info] Including: avro-ipc-1.7.4.jar
> >> [info] Including: chill-java-0.3.1.jar
> >> [info] Including: chill-java-0.3.1.jar
> >> [info] Including: chill_2.9.3-0.3.1.jar
> >> [info] Including: chill_2.9.3-0.3.1.jar
> >> [info] Including: colt-1.2.0.jar
> >> [info] Including: colt-1.2.0.jar
> >> [info] Including: commons-beanutils-1.7.0.jar
> >> [info] Including: commons-beanutils-1.7.0.jar
> >> [info] Including: commons-beanutils-core-1.8.0.jar
> >> [info] Including: commons-beanutils-core-1.8.0.jar
> >> [info] Including: commons-codec-1.4.jar
> >> [info] Including: commons-codec-1.4.jar
> >> [info] Including: commons-collections-3.2.1.jar
> >> [info] Including: commons-collections-3.2.1.jar
> >> [info] Including: commons-compress-1.4.1.jar
> >> [info] Including: commons-compress-1.4.1.jar
> >> [info] Including: commons-configuration-1.6.jar
> >> [info] Including: commons-configuration-1.6.jar
> >> [info] Including: commons-daemon-1.0.10.jar
> >> [info] Including: commons-daemon-1.0.10.jar
> >> [info] Including: commons-digester-1.8.jar
> >> [info] Including: commons-digester-1.8.jar
> >> [info] Including: commons-el-1.0.jar
> >> [info] Including: commons-el-1.0.jar
> >> [info] Including: commons-httpclient-3.1.jar
> >> [info] Including: commons-httpclient-3.1.jar
> >> [info] Including: commons-io-2.1.jar
> >> [info] Including: commons-io-2.1.jar
> >> [info] Including: commons-lang-2.4.jar
> >> [info] Including: commons-lang-2.4.jar
> >> [info] Including: commons-logging-1.1.1.jar
> >> [info] Including: commons-logging-1.1.1.jar
> >> [info] Including: commons-math-2.1.jar
> >> [info] Including: commons-math-2.1.jar
> >> [info] Including: commons-net-1.4.1.jar
> >> [info] Including: commons-net-1.4.1.jar
> >> [info] Including: concurrent-1.3.4.jar
> >> [info] Including: concurrent-1.3.4.jar
> >> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> >> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> >> [info] Including: fastutil-6.4.4.jar
> >> [info] Including: fastutil-6.4.4.jar
> >> [info] Including: flume-ng-sdk-1.2.0.jar
> >> [info] Including: flume-ng-sdk-1.2.0.jar
> >> [info] Including: gmetric4j-1.0.3.jar
> >> [info] Including: gmetric4j-1.0.3.jar
> >> [info] Including: h2-lzf-1.0.jar
> >> [info] Including: h2-lzf-1.0.jar
> >> [info] Including: hadoop-client-1.0.4.jar
> >> [info] Including: hadoop-client-1.0.4.jar
> >> [info] Including: hadoop-core-1.0.4.jar
> >> [info] Including: hadoop-core-1.0.4.jar
> >> [info] Including: hsqldb-1.8.0.10.jar
> >> [info] Including: hsqldb-1.8.0.10.jar
> >> [info] Including: httpclient-4.1.jar
> >> [info] Including: httpclient-4.1.jar
> >> [info] Including: httpcore-4.1.jar
> >> [info] Including: httpcore-4.1.jar
> >> [info] Including: jackson-annotations-2.2.2.jar
> >> [info] Including: jackson-annotations-2.2.2.jar
> >> [info] Including: jackson-core-2.2.2.jar
> >> [info] Including: jackson-core-2.2.2.jar
> >> [info] Including: jackson-core-asl-1.8.8.jar
> >> [info] Including: jackson-core-asl-1.8.8.jar
> >> [info] Including: jackson-databind-2.2.2.jar
> >> [info] Including: jackson-databind-2.2.2.jar
> >> [info] Including: jackson-mapper-asl-1.8.8.jar
> >> [info] Including: jackson-mapper-asl-1.8.8.jar
> >> [info] Including: jets3t-0.7.1.jar
> >> [info] Including: jetty-6.1.26.jar
> >> [info] Including: jblas-1.2.3.jar
> >> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> >> [info] Including: jets3t-0.7.1.jar
> >> [info] Including: jetty-http-7.6.8.v20121106.jar
> >> [info] Including: jetty-io-7.6.8.v20121106.jar
> >> [info] Including: jetty-6.1.26.jar
> >> [info] Including: jetty-server-7.6.8.v20121106.jar
> >> [info] Including: jetty-util-6.1.26.jar
> >> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> >> [info] Including: jetty-http-7.6.8.v20121106.jar
> >> [info] Including: jetty-util-7.6.8.v20121106.jar
> >> [info] Including: jetty-io-7.6.8.v20121106.jar
> >> [info] Including: jetty-server-7.6.8.v20121106.jar
> >> [info] Including: jline-0.9.94.jar
> >> [info] Including: jetty-util-6.1.26.jar
> >> [info] Including: jetty-util-7.6.8.v20121106.jar
> >> [info] Including: jna-3.0.9.jar
> >> [info] Including: jline-0.9.94.jar
> >> [info] Including: jna-3.0.9.jar
> >> [info] Including: jnr-constants-0.8.2.jar
> >> [info] Including: jnr-constants-0.8.2.jar
> >> [info] Including: jsr305-1.3.9.jar
> >> [info] Including: junit-3.8.1.jar
> >> [info] Including: jsr305-1.3.9.jar
> >> [info] Including: junit-3.8.1.jar
> >> [info] Including: lift-json_2.9.2-2.5.jar
> >> [info] Including: lift-json_2.9.2-2.5.jar
> >> [info] Including: mesos-0.13.0.jar
> >> [info] Including: mesos-0.13.0.jar
> >> [info] Including: minlog-1.2.jar
> >> [info] Including: minlog-1.2.jar
> >> [info] Including: netty-all-4.0.0.Beta2.jar
> >> [info] Including: netty-all-4.0.0.Beta2.jar
> >> [info] Including: objenesis-1.2.jar
> >> [info] Including: objenesis-1.2.jar
> >> [info] Including: oncrpc-1.0.7.jar
> >> [info] Including: oncrpc-1.0.7.jar
> >> [info] Including: oro-2.0.8.jar
> >> [info] Including: oro-2.0.8.jar
> >> [info] Including: paranamer-2.4.1.jar
> >> [info] Including: paranamer-2.4.1.jar
> >> [info] Including: protobuf-java-2.4.1.jar
> >> [info] Including: protobuf-java-2.4.1.jar
> >> [info] Including: reflectasm-1.07-shaded.jar
> >> [info] Including: reflectasm-1.07-shaded.jar
> >> [info] Including: scalap-2.9.2.jar
> >> [info] Including: scalap-2.9.2.jar
> >> [info] Including: servlet-api-2.5-20110124.jar
> >> [info] Including: servlet-api-2.5-20110124.jar
> >> [info] Including: sjson_2.9.1-0.15.jar
> >> [info] Including: sjson_2.9.1-0.15.jar
> >> [info] Including: slf4j-api-1.7.5.jar
> >> [info] Including: slf4j-api-1.7.5.jar
> >> [info] Including: slf4j-log4j12-1.7.2.jar
> >> [info] Including: slf4j-log4j12-1.7.2.jar
> >> [info] Including: twitter4j-core-3.0.3.jar
> >> [info] Including: twitter4j-core-3.0.3.jar
> >> [info] Including: twitter4j-stream-3.0.3.jar
> >> [info] Including: twitter4j-stream-3.0.3.jar
> >> [info] Including: velocity-1.7.jar
> >> [info] Including: velocity-1.7.jar
> >> [info] Including: xmlenc-0.52.jar
> >> [info] Including: xmlenc-0.52.jar
> >> [info] Including: xz-1.0.jar
> >> [info] Including: xz-1.0.jar
> >> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> >> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> >> [info] Including: zkclient-0.1.jar
> >> [info] Including: zkclient-0.1.jar
> >> [info] Including: zookeeper-3.4.5.jar
> >> [info] Including: zookeeper-3.4.5.jar
> >> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> >> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> >> [info] Including: scala-jline.jar
> >> [info] Including: kafka-0.7.2-spark.jar
> >> [info] Including: kafka-0.7.2-spark.jar
> >> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> >> with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> >> with strategy 'first'
> >> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
> >>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> >> 'first'
> >> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class'
> with
> >> strategy 'first'
> >>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContext.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FileConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
> >> 'first'
> >> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> >> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy
> 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy
> 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with
> strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
> >> strategy 'first'
> >> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/StringArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> >> with strategy 'first'
> >> [warn] Merging 'log4j.properties' with strategy 'discard'
> >> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> >> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/LongConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
> >> strategy 'first'
> >> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
> >> strategy 'first'
> >> [warn] Merging 'reference.conf' with strategy 'concat'
> >> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
> >> strategy 'first'
> >> [warn] Merging 'about.html' with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletException.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/converters/URLConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ByteConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/collections/BufferUnderflowException.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
> >> strategy 'first'
> >> [warn] Strategy 'concat' was applied to a file
> >> [warn] Strategy 'discard' was applied to 3 files
> >> [warn] Strategy 'first' was applied to 212 files
> >> [info] Checking every *.class/*.jar file's SHA-1.
> >> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> >> with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> >> with strategy 'first'
> >> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
> >>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> >> 'first'
> >> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class'
> with
> >> strategy 'first'
> >>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContext.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextListener.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionActivationListener.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/FileConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/UnavailableException.class' with strategy
> >> 'first'
> >> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> >> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy
> 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy
> 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$KeySet.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/instantiator/perc/PercInstantiator.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/NestedNullException.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with
> strategy
> >> 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class' with
> >> strategy 'first'
> >> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/StringArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> >> strategy 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConversionException.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> >> with strategy 'first'
> >> [warn] Merging 'log4j.properties' with strategy 'discard'
> >> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> >> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/LongConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/CharacterConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> >> with strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class' with
> >> strategy 'first'
> >> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> >> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> >> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class' with
> >> strategy 'first'
> >> [warn] Merging 'reference.conf' with strategy 'concat'
> >> [warn] Merging 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class' with
> >> strategy 'first'
> >> [warn] Merging 'about.html' with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy 'first'
> >> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletException.class' with strategy
> 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with
> strategy
> >> 'first'
> >> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> >> with strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$Values.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> >> 'first'
> >> [warn] Merging
> 'org/apache/commons/beanutils/converters/URLConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/LongArrayConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/converters/ByteConverter.class' with
> strategy
> >> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy
> 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> >> with strategy 'first'
> >> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> >> strategy 'first'
> >> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> >> strategy 'first'
> >> [warn] Merging
> >>
> >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> >> with strategy 'first'
> >> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class'
> with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/collections/BufferUnderflowException.class' with
> >> strategy 'first'
> >> [warn] Merging
> >> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> >> 'first'
> >> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> >> [warn] Merging
> >> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> >> strategy 'first'
> >> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class' with
> >> strategy 'first'
> >> [warn] Strategy 'concat' was applied to a file
> >> [warn] Strategy 'discard' was applied to 3 files
> >> [warn] Strategy 'first' was applied to 212 files
> >> [info] Checking every *.class/*.jar file's SHA-1.
> >> [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> >> [info] Packaging
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> >> ...
> >> [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> >> [info] Packaging
> >>
> >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> >> ...
> >>
>

--001a11c20afca86f9004ed16638c--

From dev-return-861-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 09:44:42 2013
Return-Path: <dev-return-861-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 63B371038C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 09:44:42 +0000 (UTC)
Received: (qmail 69659 invoked by uid 500); 9 Dec 2013 09:44:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69295 invoked by uid 500); 9 Dec 2013 09:44:35 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 69284 invoked by uid 99); 9 Dec 2013 09:44:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:44:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:44:29 +0000
Received: by mail-ie0-f182.google.com with SMTP id as1so5686879iec.13
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 01:44:07 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=bODrqlob2ToNooEO/KAiO1z0X4UtyNSdHGZ/7Jd8HS8=;
        b=AW2xYJCVd9qaB20wN4PF6BQHr60xsKmN7h6ipvDjDV0oYKhuuiuEuojOGsBXlWJWjF
         BLCRNJCqneCQNzsPvBmjpZzhEutbXqupFvnaOHyJvzDbU7zH3Ej3/dsllTPyEjS8IHWU
         h3sFpWr0CrUXnnNgUPvtBHIzR7mT+q4iXFfi3CQQrJO2zvisKrzpJ0V2o3pz+rxiJdSo
         6T0avb9sSOb4x+5tK5ygh8hUYfRDZjCTnWxw7jpdLb94Fa03pOc3GfibxjmEDl55MOb0
         iYk5Iti5PzfQrfHnqSVrFbwCZTENBIB3b2a2w63A++blOFLKHLob3RSgi5hIWhQ3d41f
         NfQw==
X-Gm-Message-State: ALoCoQmLZe+pN2Al3trggmi7DaSDvYiN4Oqd2eRW/kWruXE81UzIFHuEY+QQUX7FMqzc73o0Ckn0
X-Received: by 10.42.82.196 with SMTP id e4mr523603icl.58.1386582246892; Mon,
 09 Dec 2013 01:44:06 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.224.161 with HTTP; Mon, 9 Dec 2013 01:43:46 -0800 (PST)
In-Reply-To: <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
 <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
From: =?UTF-8?Q?Grega_Ke=C5=A1pret?= <grega@celtra.com>
Date: Mon, 9 Dec 2013 10:43:46 +0100
Message-ID: <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com>
Subject: Re: spark.task.maxFailures
To: dev@spark.incubator.apache.org
Content-Type: multipart/related; boundary=20cf30363fa148742304ed16d61b
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf30363fa148742304ed16d61b
Content-Type: multipart/alternative; boundary=20cf30363fa148742104ed16d61a

--20cf30363fa148742104ed16d61a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Reynold,

I submitted a pull request here -
https://github.com/apache/incubator-spark/pull/245
Do I need to do anything else (perhaps add a ticket in JIRA)?

Best,
Grega
--
[image: Inline image 1]
*Grega Ke=C5=A1pret*
Analytics engineer

Celtra =E2=80=94 Rich Media Mobile Advertising
celtra.com <http://www.celtra.com/> |
@celtramobile<http://www.twitter.com/celtramobile>


On Fri, Nov 29, 2013 at 6:24 PM, Reynold Xin <rxin@apache.org> wrote:

> Looks like a bug to me. Can you submit a pull request?
>
>
>
> On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret <grega@celtra.com> wr=
ote:
>
> > Looking at
> > http://spark.incubator.apache.org/docs/latest/configuration.html
> > docs says:
> > Number of individual task failures before giving up on the job. Should =
be
> > greater than or equal to 1. Number of allowed retries =3D this value - =
1.
> >
> > However, looking at the code
> >
> >
> https://github.com/apache/incubator-spark/blob/master/core/src/main/scala=
/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.scala#L532
> >
> > if I set spark.task.maxFailures to 1, this means that job will fail aft=
er
> > task fails for the second time. Shouldn't this line be corrected to if =
(
> > numFailures(index) >=3D MAX_TASK_FAILURES) {
> > ?
> >
> > I can open a pull request if this is the case.
> >
> > Thanks,
> > Grega
> > --
> > [image: Inline image 1]
> > *Grega Ke=C5=A1pret*
> > Analytics engineer
> >
> > Celtra =E2=80=94 Rich Media Mobile Advertising
> > celtra.com <http://www.celtra.com/> | @celtramobile<
> http://www.twitter.com/celtramobile>
> >
>

--20cf30363fa148742104ed16d61a
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Reynold,<div><br></div><div>I submitted a pull request =
here -=C2=A0<a href=3D"https://github.com/apache/incubator-spark/pull/245">=
https://github.com/apache/incubator-spark/pull/245</a></div><div>Do I need =
to do anything else (perhaps add a ticket in JIRA)?</div>

<div class=3D"gmail_extra"><br></div><div class=3D"gmail_extra">Best,<br cl=
ear=3D"all"><div><div dir=3D"ltr"><div>Grega</div>--<br><table style=3D"lin=
e-height:12px;color:rgb(119,121,133);font-size:11px;font-family:Helvetica,A=
rial,sans-serif;margin:6px 0px;padding:0px">

<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><br>Analytics engineer<br><b=
r><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobile=
 Advertising</span><br>

</div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helvetica,Ari=
al,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><span s=
tyle=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif">=C2=
=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=3D"f=
ont-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blan=
k">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>

</span></td></tr></tbody></table></div></div>
<br><br><div class=3D"gmail_quote">On Fri, Nov 29, 2013 at 6:24 PM, Reynold=
 Xin <span dir=3D"ltr">&lt;<a href=3D"mailto:rxin@apache.org" target=3D"_bl=
ank">rxin@apache.org</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
">

Looks like a bug to me. Can you submit a pull request?<br>
<div class=3D"im"><br>
<br>
<br>
On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret &lt;<a href=3D"mailto:g=
rega@celtra.com">grega@celtra.com</a>&gt; wrote:<br>
<br>
&gt; Looking at<br>
&gt; <a href=3D"http://spark.incubator.apache.org/docs/latest/configuration=
.html" target=3D"_blank">http://spark.incubator.apache.org/docs/latest/conf=
iguration.html</a><br>
&gt; docs says:<br>
&gt; Number of individual task failures before giving up on the job. Should=
 be<br>
&gt; greater than or equal to 1. Number of allowed retries =3D this value -=
 1.<br>
&gt;<br>
&gt; However, looking at the code<br>
&gt;<br>
&gt; <a href=3D"https://github.com/apache/incubator-spark/blob/master/core/=
src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.sca=
la#L532" target=3D"_blank">https://github.com/apache/incubator-spark/blob/m=
aster/core/src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSet=
Manager.scala#L532</a><br>


&gt;<br>
&gt; if I set spark.task.maxFailures to 1, this means that job will fail af=
ter<br>
&gt; task fails for the second time. Shouldn&#39;t this line be corrected t=
o if (<br>
&gt; numFailures(index) &gt;=3D MAX_TASK_FAILURES) {<br>
&gt; ?<br>
&gt;<br>
&gt; I can open a pull request if this is the case.<br>
&gt;<br>
&gt; Thanks,<br>
&gt; Grega<br>
&gt; --<br>
&gt; [image: Inline image 1]<br>
</div>&gt; *Grega Ke=C5=A1pret*<br>
<div class=3D"im">&gt; Analytics engineer<br>
&gt;<br>
&gt; Celtra =E2=80=94 Rich Media Mobile Advertising<br>
</div>&gt; <a href=3D"http://celtra.com" target=3D"_blank">celtra.com</a> &=
lt;<a href=3D"http://www.celtra.com/" target=3D"_blank">http://www.celtra.c=
om/</a>&gt; | @celtramobile&lt;<a href=3D"http://www.twitter.com/celtramobi=
le" target=3D"_blank">http://www.twitter.com/celtramobile</a>&gt;<br>


&gt;<br>
</blockquote></div><br></div></div>

--20cf30363fa148742104ed16d61a--
--20cf30363fa148742304ed16d61b--

From dev-return-862-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 09:45:54 2013
Return-Path: <dev-return-862-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 524611038E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 09:45:54 +0000 (UTC)
Received: (qmail 69938 invoked by uid 500); 9 Dec 2013 09:45:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69880 invoked by uid 500); 9 Dec 2013 09:45:49 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 69862 invoked by uid 99); 9 Dec 2013 09:45:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:45:47 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 209.85.212.175 as permitted sender)
Received: from [209.85.212.175] (HELO mail-wi0-f175.google.com) (209.85.212.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 09:44:58 +0000
Received: by mail-wi0-f175.google.com with SMTP id hi5so3466213wib.8
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 01:44:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=HJni6xBn1bEQr/8gAV9p28FRndJhF1aj2Rk4XR+hkl0=;
        b=D0i37YHNdNhvOJEgn6GSfZwwnvBzXT12g5zsrwlhFFjhFScWSwLCWOH69tOKKz6gvX
         992k6o8+UC0YFENYRFt/cdIa1IfX18A41VcC/771RUmVPhNu/G7GgeqrmIPEmHMiQz6G
         iBmVzDGPVsH3gZeEv/+4UQiuTUNHvtokLU3wGXrrDeprwRbJGDSgtP8NMqOQBl2GA45q
         z7YtJMOjahyD0u/0FGesJrDfsexz0kyGNT4b7lzoeGw+vxU/VVgJsYEqOnw6Pixy5RyN
         ITTMsAHYr3LtQGBJEiTdPgwf6bK61B3ekzw31KAmBYH73/tvZ+3pnVNRAF7wYc8iubFr
         tuNw==
X-Received: by 10.180.75.115 with SMTP id b19mr13219343wiw.19.1386582277586;
 Mon, 09 Dec 2013 01:44:37 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.64.132 with HTTP; Mon, 9 Dec 2013 01:44:17 -0800 (PST)
In-Reply-To: <CALkvKb=ftPiOZj8mnqJdRwW0+Nc=Z_1pjRnCEeE4605t3ukJuA@mail.gmail.com>
References: <CALkvKbneenFGtNEwt+7Z6DaSPy_UjmiMM1ZFnNb3t3RGH1-p-A@mail.gmail.com>
 <CAAsvFPmkfWkXW=OAVLqNfyU2QB7mv_jMhuXkrzaCRBF9b05eYg@mail.gmail.com>
 <CABPQxsuYoRVbvJ1k96uNwcpwvSN97wn4qZGEP_GL_S-Osb1cOw@mail.gmail.com> <CALkvKb=ftPiOZj8mnqJdRwW0+Nc=Z_1pjRnCEeE4605t3ukJuA@mail.gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Mon, 9 Dec 2013 15:14:17 +0530
Message-ID: <CAOYDGoDfkctjksqEhLhSCwj-p_yRvK3k+UEDC8PCCK2DuOKiGw@mail.gmail.com>
Subject: Re: Spark Build Issue ('sbt/sbt assembly' hangs)
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d043be23c1b870904ed16d83f
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043be23c1b870904ed16d83f
Content-Type: text/plain; charset=ISO-8859-1

I have generally observed if I clean assembly before building it, it works
fine and also building assembly/assembly and example/assembly separately
helps.

sbt/sbt
> project assembly
> clean
> project root
> assembly/assembly

or
shorter version
$ rm -r assembly/target
$ sbt/sbt assembly/assembly

and then if you want you can build example assembly separately with sbt/sbt
example/assembly .

HTH


On Mon, Dec 9, 2013 at 2:42 PM, Taka Shinagawa <taka.epsilon@gmail.com>wrote:

> Seems like I'm having the same issue as Mark. It's not about Hadoop
> versions-- sorry about the confusion. It turns out that the build process
> is not hanging, although CPU usage goes below 1%.
>
> After waiting for more than 2 hours, the sbt assembly command finished
> successfully on the Macbook Pro (with 2.4GHz Intel Core 2 Duo & 8GB RAM).
> On my regular Macbook (with 2.3GHz Intel Core i7 & 16GB RAM), the build
> with sbt always completes in about 4 minutes. So I never expected the sbt
> assembly takes this much longer on the other Macbook. I also ran the same
> sbt command on Ubuntu 12.04 LTS on VirtualBox, it took more than one hour
> and a half. I'm seeing this problem on both Mac and Linux as well as with
> 0.8.0 release.
>
> The solution seems to upgrade sbt-assembly to version 0.10.1 (and sbt to
> 0.13.0). But sbt 0.13 requires sbt-dependency-graph 0.7.4 (from 0.7.3),
> which depends on Scala 2.10. So I've learned that we can't upgrade them for
> this release.
>
> Thanks for the help!
>
>
>
>
>
>
> On Sun, Dec 8, 2013 at 5:28 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Hey Taka,
> >
> > Most likely this is just the assembly task taking a long time as mark
> > said. What happens if you run 'package' or 'compile'? It could be that
> > on Mac's there is something where this is slow... I'm not sure.
> >
> > Also, unless you specify the hadoop version in the build it will build
> > Hadoop 1.0.4. You keep mentioning Hadoop 2.2.0, but you didn't specify
> > that when you built so Spark has no way of knowing what you want.
> >
> > Checkout the README for documentation on how to do that.
> >
> > Also - does this all work well in the 0.8.0 release? If this is not
> > something specific to the 0.8.1 release than it would be good to know.
> >
> > - Patrick
> >
> > On Sun, Dec 8, 2013 at 5:06 PM, Mark Hamstra <mark@clearstorydata.com>
> > wrote:
> > > The assembly "hang" is something that I've also noticed over at least
> the
> > > past few weeks.  If you are seeing what I am seeing, then the build is
> > not
> > > actually hung, but the building of assemblies takes a long time, a very
> > > long time, a very very long time on Macs.  It's just the build of
> > > assemblies via sbt on OSX that does this -- maven builds on Mac or any
> > kind
> > > of build on Linux go much faster.  On a Mac that also has other things
> to
> > > do, I've seen the sbt assembly packaging take upwards of an hour.  Not
> > good.
> > >
> > >
> > > On Sun, Dec 8, 2013 at 4:46 PM, Taka Shinagawa <taka.epsilon@gmail.com
> > >wrote:
> > >
> > >> As I reported in the Spark 0.8-1 RC2 thread, the 'sbt/sbt assembly'
> > hangs
> > >> at the last step. It happens on a Macbook with Hadoop 2.2.0 (& Java
> > >> 1.7.0_45) installed. The build was successful on another system with
> > Hadoop
> > >> 1.1.1 installed.
> > >>
> > >> Here's the build command and the entire log. Thanks for the help.
> > >>
> > >> ---------------------------------------------------------------
> > >> $ sbt/sbt assembly
> > >> [info] Loading project definition from
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/}default-c4ca6d...
> > >> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> > >> [info] Done updating.
> > >> [info] Compiling 1 Scala source to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/project/target/scala-2.9.2/sbt-0.12/classes...
> > >> [info] Loading project definition from
> > >>
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/}plugins...
> > >> [info] Resolving org.scala-sbt#precompiled-2_10_1;0.12.4 ...
> > >> [info] Done updating.
> > >> [info] Compiling 1 Scala source to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/project/target/scala-2.9.2/sbt-0.12/classes...
> > >> [info] Set current project to root (in build
> > >> file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/)
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}core...
> > >> [info] Resolving org.apache.derby#derby;10.4.2.0 ...
> > >> [info] Done updating.
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}streaming...
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}bagel...
> > >> [info] Resolving org.scala-lang#scala-library;2.9.3 ...
> > >> [info] Done updating.
> > >> [info] Resolving org.eclipse.jetty#jetty-util;7.6.8.v20121106 ...
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}mllib...
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}tools...
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}examples...
> > >> [info] Resolving org.slf4j#slf4j-api;1.7.2 ...
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}repl...
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [info] Resolving org.apache.httpcomponents#httpcore;4.1 ...
> > >> [info] Compiling 285 Scala sources and 18 Java sources to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/target/scala-2.9.3/classes...
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [info] Updating
> > >>
> > >>
> >
> {file:/Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/}assembly...
> > >> [info] Resolving org.mockito#mockito-all;1.8.5 ...
> > >> [info] Done updating.
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:131:
> > >> method cleanupJob in class OutputCommitter is deprecated: see
> > corresponding
> > >> Javadoc for more information.
> > >> [warn]     getOutputCommitter().cleanupJob(getJobContext())
> > >> [warn]                          ^
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1059:
> > >> class BitTorrentBroadcast in package broadcast is deprecated: Use
> > >> TorrentBroadcast
> > >> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> > >> [warn]       ^
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/BitTorrentBroadcast.scala:1060:
> > >> class BitTorrentBroadcast in package broadcast is deprecated: Use
> > >> TorrentBroadcast
> > >> [warn]     new BitTorrentBroadcast[T](value_, isLocal, id)
> > >> [warn]         ^
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:600:
> > >> class TreeBroadcast in package broadcast is deprecated: Use
> > >> TorrentBroadcast
> > >> [warn]   def newBroadcast[T](value_ : T, isLocal: Boolean, id: Long) =
> > >> [warn]       ^
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/broadcast/TreeBroadcast.scala:601:
> > >> class TreeBroadcast in package broadcast is deprecated: Use
> > >> TorrentBroadcast
> > >> [warn]     new TreeBroadcast[T](value_, isLocal, id)
> > >> [warn]         ^
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:598:
> > >> method cleanupJob in class OutputCommitter is deprecated: see
> > corresponding
> > >> Javadoc for more information.
> > >> [warn]     jobCommitter.cleanupJob(jobTaskContext)
> > >> [warn]                  ^
> > >> [warn] 6 warnings found
> > >> [warn] warning: [options] bootstrap class path not set in conjunction
> > with
> > >> -source 1.5
> > >> [warn] Note: Some input files use unchecked or unsafe operations.
> > >> [warn] Note: Recompile with -Xlint:unchecked for details.
> > >> [warn] 1 warning
> > >> [info] Compiling 1 Scala source to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/bagel/target/scala-2.9.3/classes...
> > >> [info] Compiling 49 Scala sources to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/streaming/target/scala-2.9.3/classes...
> > >> [info] Compiling 25 Scala sources to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/mllib/target/scala-2.9.3/classes...
> > >> [info] Compiling 10 Scala sources to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/target/scala-2.9.3/classes...
> > >> [warn]
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala:141:
> > >> method stop in class Thread is deprecated: see corresponding Javadoc
> for
> > >> more information.
> > >> [warn]         line.thread.stop()
> > >> [warn]                     ^
> > >> [warn] one warning found
> > >> [info] Compiling 39 Scala sources and 13 Java sources to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/examples/target/scala-2.9.3/classes...
> > >> [info] Compiling 1 Scala source to
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/classes...
> > >> [warn] warning: [options] bootstrap class path not set in conjunction
> > with
> > >> -source 1.5
> > >> [warn] 1 warning
> > >> [info] Including: scala-compiler.jar
> > >> [info] Including: scala-compiler.jar
> > >> [info] Including: scala-library.jar
> > >> [info] Including: scala-library.jar
> > >> [info] Including: compress-lzf-0.8.4.jar
> > >> [info] Including: py4j-0.7.jar
> > >> [info] Including: compress-lzf-0.8.4.jar
> > >> [info] Including: config-0.3.1.jar
> > >> [info] Including: config-0.3.1.jar
> > >> [info] Including: guava-14.0.1.jar
> > >> [info] Including: guava-14.0.1.jar
> > >> [info] Including: kryo-2.21.jar
> > >> [info] Including: kryo-2.21.jar
> > >> [info] Including: log4j-1.2.17.jar
> > >> [info] Including: log4j-1.2.17.jar
> > >> [info] Including: metrics-core-3.0.0.jar
> > >> [info] Including: metrics-core-3.0.0.jar
> > >> [info] Including: metrics-ganglia-3.0.0.jar
> > >> [info] Including: metrics-ganglia-3.0.0.jar
> > >> [info] Including: metrics-json-3.0.0.jar
> > >> [info] Including: metrics-json-3.0.0.jar
> > >> [info] Including: metrics-jvm-3.0.0.jar
> > >> [info] Including: metrics-jvm-3.0.0.jar
> > >> [info] Including: netty-3.5.4.Final.jar
> > >> [info] Including: netty-3.5.4.Final.jar
> > >> [info] Including: snappy-java-1.0.5.jar
> > >> [info] Including: snappy-java-1.0.5.jar
> > >> [info] Including: akka-actor-2.0.5.jar
> > >> [info] Including: akka-actor-2.0.5.jar
> > >> [info] Including: akka-remote-2.0.5.jar
> > >> [info] Including: akka-remote-2.0.5.jar
> > >> [info] Including: akka-slf4j-2.0.5.jar
> > >> [info] Including: akka-slf4j-2.0.5.jar
> > >> [info] Including: akka-zeromq-2.0.5.jar
> > >> [info] Including: akka-zeromq-2.0.5.jar
> > >> [info] Including: asm-4.0.jar
> > >> [info] Including: asm-4.0.jar
> > >> [info] Including: asm-commons-4.0.jar
> > >> [info] Including: asm-commons-4.0.jar
> > >> [info] Including: asm-tree-4.0.jar
> > >> [info] Including: asm-tree-4.0.jar
> > >> [info] Including: avro-1.7.4.jar
> > >> [info] Including: avro-1.7.4.jar
> > >> [info] Including: avro-ipc-1.7.4.jar
> > >> [info] Including: avro-ipc-1.7.4.jar
> > >> [info] Including: chill-java-0.3.1.jar
> > >> [info] Including: chill-java-0.3.1.jar
> > >> [info] Including: chill_2.9.3-0.3.1.jar
> > >> [info] Including: chill_2.9.3-0.3.1.jar
> > >> [info] Including: colt-1.2.0.jar
> > >> [info] Including: colt-1.2.0.jar
> > >> [info] Including: commons-beanutils-1.7.0.jar
> > >> [info] Including: commons-beanutils-1.7.0.jar
> > >> [info] Including: commons-beanutils-core-1.8.0.jar
> > >> [info] Including: commons-beanutils-core-1.8.0.jar
> > >> [info] Including: commons-codec-1.4.jar
> > >> [info] Including: commons-codec-1.4.jar
> > >> [info] Including: commons-collections-3.2.1.jar
> > >> [info] Including: commons-collections-3.2.1.jar
> > >> [info] Including: commons-compress-1.4.1.jar
> > >> [info] Including: commons-compress-1.4.1.jar
> > >> [info] Including: commons-configuration-1.6.jar
> > >> [info] Including: commons-configuration-1.6.jar
> > >> [info] Including: commons-daemon-1.0.10.jar
> > >> [info] Including: commons-daemon-1.0.10.jar
> > >> [info] Including: commons-digester-1.8.jar
> > >> [info] Including: commons-digester-1.8.jar
> > >> [info] Including: commons-el-1.0.jar
> > >> [info] Including: commons-el-1.0.jar
> > >> [info] Including: commons-httpclient-3.1.jar
> > >> [info] Including: commons-httpclient-3.1.jar
> > >> [info] Including: commons-io-2.1.jar
> > >> [info] Including: commons-io-2.1.jar
> > >> [info] Including: commons-lang-2.4.jar
> > >> [info] Including: commons-lang-2.4.jar
> > >> [info] Including: commons-logging-1.1.1.jar
> > >> [info] Including: commons-logging-1.1.1.jar
> > >> [info] Including: commons-math-2.1.jar
> > >> [info] Including: commons-math-2.1.jar
> > >> [info] Including: commons-net-1.4.1.jar
> > >> [info] Including: commons-net-1.4.1.jar
> > >> [info] Including: concurrent-1.3.4.jar
> > >> [info] Including: concurrent-1.3.4.jar
> > >> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> > >> [info] Including: dispatch-json_2.9.1-0.8.5.jar
> > >> [info] Including: fastutil-6.4.4.jar
> > >> [info] Including: fastutil-6.4.4.jar
> > >> [info] Including: flume-ng-sdk-1.2.0.jar
> > >> [info] Including: flume-ng-sdk-1.2.0.jar
> > >> [info] Including: gmetric4j-1.0.3.jar
> > >> [info] Including: gmetric4j-1.0.3.jar
> > >> [info] Including: h2-lzf-1.0.jar
> > >> [info] Including: h2-lzf-1.0.jar
> > >> [info] Including: hadoop-client-1.0.4.jar
> > >> [info] Including: hadoop-client-1.0.4.jar
> > >> [info] Including: hadoop-core-1.0.4.jar
> > >> [info] Including: hadoop-core-1.0.4.jar
> > >> [info] Including: hsqldb-1.8.0.10.jar
> > >> [info] Including: hsqldb-1.8.0.10.jar
> > >> [info] Including: httpclient-4.1.jar
> > >> [info] Including: httpclient-4.1.jar
> > >> [info] Including: httpcore-4.1.jar
> > >> [info] Including: httpcore-4.1.jar
> > >> [info] Including: jackson-annotations-2.2.2.jar
> > >> [info] Including: jackson-annotations-2.2.2.jar
> > >> [info] Including: jackson-core-2.2.2.jar
> > >> [info] Including: jackson-core-2.2.2.jar
> > >> [info] Including: jackson-core-asl-1.8.8.jar
> > >> [info] Including: jackson-core-asl-1.8.8.jar
> > >> [info] Including: jackson-databind-2.2.2.jar
> > >> [info] Including: jackson-databind-2.2.2.jar
> > >> [info] Including: jackson-mapper-asl-1.8.8.jar
> > >> [info] Including: jackson-mapper-asl-1.8.8.jar
> > >> [info] Including: jets3t-0.7.1.jar
> > >> [info] Including: jetty-6.1.26.jar
> > >> [info] Including: jblas-1.2.3.jar
> > >> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> > >> [info] Including: jets3t-0.7.1.jar
> > >> [info] Including: jetty-http-7.6.8.v20121106.jar
> > >> [info] Including: jetty-io-7.6.8.v20121106.jar
> > >> [info] Including: jetty-6.1.26.jar
> > >> [info] Including: jetty-server-7.6.8.v20121106.jar
> > >> [info] Including: jetty-util-6.1.26.jar
> > >> [info] Including: jetty-continuation-7.6.8.v20121106.jar
> > >> [info] Including: jetty-http-7.6.8.v20121106.jar
> > >> [info] Including: jetty-util-7.6.8.v20121106.jar
> > >> [info] Including: jetty-io-7.6.8.v20121106.jar
> > >> [info] Including: jetty-server-7.6.8.v20121106.jar
> > >> [info] Including: jline-0.9.94.jar
> > >> [info] Including: jetty-util-6.1.26.jar
> > >> [info] Including: jetty-util-7.6.8.v20121106.jar
> > >> [info] Including: jna-3.0.9.jar
> > >> [info] Including: jline-0.9.94.jar
> > >> [info] Including: jna-3.0.9.jar
> > >> [info] Including: jnr-constants-0.8.2.jar
> > >> [info] Including: jnr-constants-0.8.2.jar
> > >> [info] Including: jsr305-1.3.9.jar
> > >> [info] Including: junit-3.8.1.jar
> > >> [info] Including: jsr305-1.3.9.jar
> > >> [info] Including: junit-3.8.1.jar
> > >> [info] Including: lift-json_2.9.2-2.5.jar
> > >> [info] Including: lift-json_2.9.2-2.5.jar
> > >> [info] Including: mesos-0.13.0.jar
> > >> [info] Including: mesos-0.13.0.jar
> > >> [info] Including: minlog-1.2.jar
> > >> [info] Including: minlog-1.2.jar
> > >> [info] Including: netty-all-4.0.0.Beta2.jar
> > >> [info] Including: netty-all-4.0.0.Beta2.jar
> > >> [info] Including: objenesis-1.2.jar
> > >> [info] Including: objenesis-1.2.jar
> > >> [info] Including: oncrpc-1.0.7.jar
> > >> [info] Including: oncrpc-1.0.7.jar
> > >> [info] Including: oro-2.0.8.jar
> > >> [info] Including: oro-2.0.8.jar
> > >> [info] Including: paranamer-2.4.1.jar
> > >> [info] Including: paranamer-2.4.1.jar
> > >> [info] Including: protobuf-java-2.4.1.jar
> > >> [info] Including: protobuf-java-2.4.1.jar
> > >> [info] Including: reflectasm-1.07-shaded.jar
> > >> [info] Including: reflectasm-1.07-shaded.jar
> > >> [info] Including: scalap-2.9.2.jar
> > >> [info] Including: scalap-2.9.2.jar
> > >> [info] Including: servlet-api-2.5-20110124.jar
> > >> [info] Including: servlet-api-2.5-20110124.jar
> > >> [info] Including: sjson_2.9.1-0.15.jar
> > >> [info] Including: sjson_2.9.1-0.15.jar
> > >> [info] Including: slf4j-api-1.7.5.jar
> > >> [info] Including: slf4j-api-1.7.5.jar
> > >> [info] Including: slf4j-log4j12-1.7.2.jar
> > >> [info] Including: slf4j-log4j12-1.7.2.jar
> > >> [info] Including: twitter4j-core-3.0.3.jar
> > >> [info] Including: twitter4j-core-3.0.3.jar
> > >> [info] Including: twitter4j-stream-3.0.3.jar
> > >> [info] Including: twitter4j-stream-3.0.3.jar
> > >> [info] Including: velocity-1.7.jar
> > >> [info] Including: velocity-1.7.jar
> > >> [info] Including: xmlenc-0.52.jar
> > >> [info] Including: xmlenc-0.52.jar
> > >> [info] Including: xz-1.0.jar
> > >> [info] Including: xz-1.0.jar
> > >> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> > >> [info] Including: zeromq-scala-binding_2.9.1-0.0.6.jar
> > >> [info] Including: zkclient-0.1.jar
> > >> [info] Including: zkclient-0.1.jar
> > >> [info] Including: zookeeper-3.4.5.jar
> > >> [info] Including: zookeeper-3.4.5.jar
> > >> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> > >> [info] Including: javax.servlet-2.5.0.v201103041518.jar
> > >> [info] Including: scala-jline.jar
> > >> [info] Including: kafka-0.7.2-spark.jar
> > >> [info] Including: kafka-0.7.2-spark.jar
> > >> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
> > >>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class'
> > with
> > >> strategy 'first'
> > >>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with
> strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContext.class' with strategy
> > 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy
> 'first'
> > >> [warn] Merging
> 'javax/servlet/http/HttpSessionActivationListener.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FileConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/UnavailableException.class' with
> strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> > >> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy
> > 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$KeySet.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/objenesis/instantiator/perc/PercInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/beanutils/NestedNullException.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/StringArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy
> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy
> > 'first'
> > >> [warn] Merging
> 'org/apache/commons/beanutils/ConversionException.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'log4j.properties' with strategy 'discard'
> > >> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> > >> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/LongConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/CharacterConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy
> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'reference.conf' with strategy 'concat'
> > >> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'about.html' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy
> 'first'
> > >> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletException.class' with strategy
> > 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$Values.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/converters/URLConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/LongArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ByteConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/collections/BufferUnderflowException.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class'
> with
> > >> strategy 'first'
> > >> [warn] Strategy 'concat' was applied to a file
> > >> [warn] Strategy 'discard' was applied to 3 files
> > >> [warn] Strategy 'first' was applied to 212 files
> > >> [info] Checking every *.class/*.jar file's SHA-1.
> > >> [warn] Merging 'org/objenesis/instantiator/gcj/GCJInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/SingleThreadModel.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/RequestDispatcher.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FloatArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ResultSetIterator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/objenesis/instantiator/sun/SunReflectionFactorySerializationInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/locale/LocaleBeanUtils.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Label.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisSerializer.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/collections/FastHashMap$EntrySet.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtilsBean.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextAttributeEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/minlog/Log$Logger.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/ConvertingWrapDynaBean.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'META-INF/ASL2.0' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/NoBodyResponse.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/BigIntegerLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/AccessibleInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_2.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/locale/LocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/xml.xsd' with strategy 'first'
> > >>  [warn] Merging 'org/apache/commons/collections/Buffer.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FloatConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DoubleLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ObjectStreamClassInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/XMLSchema.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/objenesis/instantiator/ObjectInstantiator.class'
> > with
> > >> strategy 'first'
> > >>  [warn] Merging 'javax/servlet/ServletRequestWrapper.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/IntegerConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/Objenesis.class' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionEvent.class' with
> strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> 'org/objenesis/instantiator/sun/SunReflectionFactoryInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletResponse.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/IntegerArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlDateLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionBindingListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/instantiator/NullInstantiator.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaClass.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/NOTICE.txt' with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/minlog/Log.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/MethodUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/IntegerLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlTimeLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > 'org/objenesis/instantiator/gcj/GCJInstantiatorBase.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ShortConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$Descriptor.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/strategy/SerializingInstantiatorStrategy.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/strategy/StdInstantiatorStrategy.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContext.class' with strategy
> > 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/Converter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaProperty.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/sun/Sun13SerializationInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator$MockStream.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConstructorUtils.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletRequest.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> 'com/esotericsoftware/reflectasm/AccessClassLoader.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ClassConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextListener.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Opcodes.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/BeanAccessLanguageException.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/gcj/GCJInstantiatorBase$DummyStream.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> 'org/apache/commons/beanutils/converters/CharacterArrayConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/jrockit/JRockitLegacyInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleConvertUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/MappedPropertyDescriptor.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/ServletResponseWrapper.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/gcj/GCJSerializationInstantiator.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/NoBodyOutputStream.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/FilterConfig.class' with strategy
> 'first'
> > >> [warn] Merging
> 'javax/servlet/http/HttpSessionActivationListener.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/perc/PercSerializationInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtils.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Frame.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/JDBCDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/FileConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/UnavailableException.class' with
> strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/NOTICE' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ObjectInputStreamInstantiator.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/DynaBean.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
> > >> [warn] Merging 'javax/servlet/resources/j2ee_1_4.xsd' with strategy
> > 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_3.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaMap.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSession.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/FieldWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/BigDecimalLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Type.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextEvent.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/StringLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletInputStream.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Item.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DateLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletResponse.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestEvent.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/MutableDynaClass.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Edge.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BigDecimalConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/StringConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/ByteLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/Cookie.class' with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/RowSetDynaClass.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/SqlTimestampLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BigIntegerConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/Servlet.class' with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$KeySet.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean$1.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisHelper.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handler.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >>
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Handle.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/objenesis/instantiator/perc/PercInstantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_5.xsd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/objenesis/instantiator/sun/Sun13InstantiatorBase.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/beanutils/NestedNullException.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/LocalStrings.properties' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/http/LocalStrings.properties' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/collections/FastHashMap$CollectionView$CollectionViewIterator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlTimestampConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/reflectasm/FieldAccess.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'META-INF/DEPENDENCIES' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ByteArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/StringArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/DoubleConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletResponseWrapper.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/MethodUtils$MethodDescriptor.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/FastHashMap.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletOutputStream.class' with strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/AbstractArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/WrapDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/DoubleArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/ShortLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/jsp_2_0.xsd' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ShortArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisBase.class' with strategy
> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BooleanConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/ContextClassLoaderLocal.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequest.class' with strategy
> > 'first'
> > >> [warn] Merging
> 'org/apache/commons/beanutils/ConversionException.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/j2ee_web_services_1_1.xsd'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/Attribute.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'log4j.properties' with strategy 'discard'
> > >> [warn] Merging 'META-INF/ECLIPSEF.SF' with strategy 'discard'
> > >> [warn] Merging 'javax/servlet/Filter.class' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/LongConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/CharacterConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisStd.class' with strategy
> 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlDateConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaClass.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestAttributeEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpUtils.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtilsBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ResultSetDynaClass.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> 'com/esotericsoftware/reflectasm/ConstructorAccess.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'org/objenesis/strategy/InstantiatorStrategy.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'META-INF/INDEX.LIST' with strategy 'first'
> > >> [warn] Merging 'com/esotericsoftware/reflectasm/MethodAccess.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/web-app_2_4.xsd' with strategy
> > >> 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean$1.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'reference.conf' with strategy 'concat'
> > >> [warn] Merging
> 'org/objenesis/instantiator/sun/Sun13Instantiator.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/SerializationInstantiatorHelper.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'about.html' with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletConfig.class' with strategy
> 'first'
> > >> [warn] Merging 'org/objenesis/strategy/BaseInstantiatorStrategy.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletException.class' with strategy
> > 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/PropertyUtils.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionContext.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging 'META-INF/LICENSE.txt' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/BooleanArrayConverter.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BeanUtilsBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > 'javax/servlet/resources/j2ee_web_services_client_1_1.xsd'
> > >> with strategy 'first'
> > >> [warn] Merging
> 'org/apache/commons/collections/FastHashMap$Values.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/SqlTimeConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/GenericServlet.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleBeanUtils$Descriptor.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/ConvertUtilsBean.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassWriter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/resources/datatypes.dtd' with strategy
> > >> 'first'
> > >> [warn] Merging
> > 'org/apache/commons/beanutils/converters/URLConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServletRequestWrapper.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/FloatLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/LongArrayConverter.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/ArrayStack.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ByteVector.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/BasicDynaBean.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/collections/FastHashMap$CollectionView.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/LocaleConvertUtilsBean.class'
> with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/LongLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/converters/ByteConverter.class' with
> > strategy
> > >> 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/ConstructorInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpServlet.class' with strategy
> > 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/jrockit/JRockit131Instantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletRequestAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'org/apache/commons/beanutils/locale/converters/DecimalLocaleConverter.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'META-INF/LICENSE' with strategy 'first'
> > >> [warn] Merging 'org/apache/commons/beanutils/LazyDynaClass.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'javax/servlet/http/HttpSessionBindingEvent.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >>
> > >>
> >
> 'com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/AnnotationVisitor.class'
> > >> with strategy 'first'
> > >> [warn] Merging 'javax/servlet/ServletContextAttributeListener.class'
> > with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/collections/BufferUnderflowException.class' with
> > >> strategy 'first'
> > >> [warn] Merging
> > >> 'org/objenesis/instantiator/basic/NewInstanceInstantiator.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/objenesis/ObjenesisException.class' with strategy
> > >> 'first'
> > >> [warn] Merging 'javax/servlet/FilterChain.class' with strategy 'first'
> > >> [warn] Merging
> > >> 'org/apache/commons/beanutils/locale/BaseLocaleConverter.class' with
> > >> strategy 'first'
> > >> [warn] Merging 'org/apache/commons/collections/FastHashMap$1.class'
> with
> > >> strategy 'first'
> > >> [warn] Strategy 'concat' was applied to a file
> > >> [warn] Strategy 'discard' was applied to 3 files
> > >> [warn] Strategy 'first' was applied to 212 files
> > >> [info] Checking every *.class/*.jar file's SHA-1.
> > >> [info] SHA-1: ce8275f5841002164c4305c912a2892ec7c1d395
> > >> [info] Packaging
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/tools/target/scala-2.9.3/spark-tools-assembly-0.8.1-incubating.jar
> > >> ...
> > >> [info] SHA-1: 0657a347240266230247693f265a5797d40c326a
> > >> [info] Packaging
> > >>
> > >>
> >
> /Users/taka/Documents/Spark/Releases/spark-0.8.1-incubating-rc2/assembly/target/scala-2.9.3/spark-assembly-0.8.1-incubating-hadoop1.0.4.jar
> > >> ...
> > >>
> >
>



-- 
s

--f46d043be23c1b870904ed16d83f--

From dev-return-863-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 15:35:54 2013
Return-Path: <dev-return-863-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6875210E2B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 15:35:54 +0000 (UTC)
Received: (qmail 66112 invoked by uid 500); 9 Dec 2013 15:35:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65742 invoked by uid 500); 9 Dec 2013 15:35:48 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 65732 invoked by uid 99); 9 Dec 2013 15:35:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 15:35:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 15:35:42 +0000
Received: by mail-ie0-f178.google.com with SMTP id lx4so6416334iec.9
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 07:35:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=ESdWot7UtSRVVcFfkm8BRHJaGF4mo6ruPvR8cKErAfA=;
        b=RFBGkrG/IcfywAPxD+n2aNUQZLs/dtpwpv/rXmfqgPqQVX3RSxOfq1Z+SaBW+V3q57
         u8GQYhLkKRf7Gb/0OKc/YhSL1Jul852zECrVSuy8C5QCKrORUj6cFWq6ILjz8zmupv3f
         IWAyctED0zZ3TqTXKBLUoUVrxV1JpDXIkeeqo4RFmT5MEao9ITFNWdsa6jX7wJ+SbmQv
         bYOHAHWrv7wuFZ212q113UNBnuz8N5m0ot+F6F5CxcbkeYtVIxpfRdCCGiVu3mzWP+Jy
         Lc6ugN1B6QRh/U47IGPlVA1HXujEqqd8yAangEjS6R/u+M+pjcSpKJybOI/xXOD9ImIt
         6XqA==
X-Gm-Message-State: ALoCoQneESlGnIxSfoVJ327Z9nZeZ+tfz04JZL7VZwGJun25738rhqu+skFJlYYyFIdTfthBBBUq
X-Received: by 10.42.61.147 with SMTP id u19mr13867548ich.36.1386603321495;
 Mon, 09 Dec 2013 07:35:21 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.224.161 with HTTP; Mon, 9 Dec 2013 07:35:01 -0800 (PST)
In-Reply-To: <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
 <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com> <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com>
From: =?UTF-8?Q?Grega_Ke=C5=A1pret?= <grega@celtra.com>
Date: Mon, 9 Dec 2013 16:35:01 +0100
Message-ID: <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
Subject: Re: spark.task.maxFailures
To: dev@spark.incubator.apache.org
Content-Type: multipart/related; boundary=20cf302234d56c406d04ed1bbe49
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf302234d56c406d04ed1bbe49
Content-Type: multipart/alternative; boundary=20cf302234d56c406b04ed1bbe48

--20cf302234d56c406b04ed1bbe48
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi!

I tried this (by setting spark.task.maxFailures to 1) and it still does not
fail-fast. I started a job and after some time, I killed all JVMs running
on one of the two workers. I was expecting Spark job to fail, however it
re-fetched tasks to one of the two workers that was still alive and the job
succeeded.

Grega
--
[image: Inline image 1]
*Grega Ke=C5=A1pret*
Analytics engineer

Celtra =E2=80=94 Rich Media Mobile Advertising
celtra.com <http://www.celtra.com/> |
@celtramobile<http://www.twitter.com/celtramobile>


On Mon, Dec 9, 2013 at 10:43 AM, Grega Ke=C5=A1pret <grega@celtra.com> wrot=
e:

> Hi Reynold,
>
> I submitted a pull request here -
> https://github.com/apache/incubator-spark/pull/245
> Do I need to do anything else (perhaps add a ticket in JIRA)?
>
> Best,
> Grega
> --
> [image: Inline image 1]
> *Grega Ke=C5=A1pret*
>
> Analytics engineer
>
> Celtra =E2=80=94 Rich Media Mobile Advertising
> celtra.com <http://www.celtra.com/> | @celtramobile<http://www.twitter.co=
m/celtramobile>
>
>
> On Fri, Nov 29, 2013 at 6:24 PM, Reynold Xin <rxin@apache.org> wrote:
>
>> Looks like a bug to me. Can you submit a pull request?
>>
>>
>>
>> On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret <grega@celtra.com> w=
rote:
>>
>> > Looking at
>> > http://spark.incubator.apache.org/docs/latest/configuration.html
>> > docs says:
>> > Number of individual task failures before giving up on the job. Should
>> be
>> > greater than or equal to 1. Number of allowed retries =3D this value -=
 1.
>> >
>> > However, looking at the code
>> >
>> >
>> https://github.com/apache/incubator-spark/blob/master/core/src/main/scal=
a/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.scala#L532
>> >
>> > if I set spark.task.maxFailures to 1, this means that job will fail
>> after
>> > task fails for the second time. Shouldn't this line be corrected to if=
 (
>> > numFailures(index) >=3D MAX_TASK_FAILURES) {
>> > ?
>> >
>> > I can open a pull request if this is the case.
>> >
>> > Thanks,
>> > Grega
>> > --
>> > [image: Inline image 1]
>> > *Grega Ke=C5=A1pret*
>> > Analytics engineer
>> >
>> > Celtra =E2=80=94 Rich Media Mobile Advertising
>> > celtra.com <http://www.celtra.com/> | @celtramobile<
>> http://www.twitter.com/celtramobile>
>> >
>>
>
>

--20cf302234d56c406b04ed1bbe48
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><span style=3D"font-family:arial,sans-serif;font-size:12.8=
00000190734863px">Hi!</span><div style=3D"font-family:arial,sans-serif;font=
-size:12.800000190734863px"><br></div><div style=3D"font-family:arial,sans-=
serif;font-size:12.800000190734863px">

I tried this (by setting spark.task.maxFailures to 1) and it still does not=
 fail-fast. I started a job and after some time, I killed all JVMs running =
on one of the two workers. I was expecting Spark job to fail, however it re=
-fetched tasks to one of the two workers that was still alive and the job s=
ucceeded.=C2=A0</div>

</div><div class=3D"gmail_extra"><br clear=3D"all"><div><div dir=3D"ltr"><d=
iv>Grega</div>--<br><table style=3D"line-height:12px;color:rgb(119,121,133)=
;font-size:11px;font-family:Helvetica,Arial,sans-serif;margin:6px 0px;paddi=
ng:0px">

<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><br>Analytics engineer<br><b=
r><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobile=
 Advertising</span><br>

</div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helvetica,Ari=
al,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><span s=
tyle=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif">=C2=
=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=3D"f=
ont-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blan=
k">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>

</span></td></tr></tbody></table></div></div>
<br><br><div class=3D"gmail_quote">On Mon, Dec 9, 2013 at 10:43 AM, Grega K=
e=C5=A1pret <span dir=3D"ltr">&lt;<a href=3D"mailto:grega@celtra.com" targe=
t=3D"_blank">grega@celtra.com</a>&gt;</span> wrote:<br><blockquote class=3D=
"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding=
-left:1ex">

<div dir=3D"ltr">Hi Reynold,<div><br></div><div>I submitted a pull request =
here -=C2=A0<a href=3D"https://github.com/apache/incubator-spark/pull/245" =
target=3D"_blank">https://github.com/apache/incubator-spark/pull/245</a></d=
iv><div>

Do I need to do anything else (perhaps add a ticket in JIRA)?</div>
<div class=3D"gmail_extra"><br></div><div class=3D"gmail_extra">Best,<br cl=
ear=3D"all"><div><div dir=3D"ltr"><div>Grega</div>--<br><table style=3D"lin=
e-height:12px;color:rgb(119,121,133);font-size:11px;font-family:Helvetica,A=
rial,sans-serif;margin:6px 0px;padding:0px">


<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><div class=3D"im"><br>Analyt=
ics engineer<br>

<br><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobi=
le Advertising</span><br>
</div></div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helveti=
ca,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><=
span style=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif=
">=C2=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=
=3D"font-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"=
_blank">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>


</span></td></tr></tbody></table></div></div><div><div class=3D"h5">
<br><br><div class=3D"gmail_quote">On Fri, Nov 29, 2013 at 6:24 PM, Reynold=
 Xin <span dir=3D"ltr">&lt;<a href=3D"mailto:rxin@apache.org" target=3D"_bl=
ank">rxin@apache.org</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
">


Looks like a bug to me. Can you submit a pull request?<br>
<div><br>
<br>
<br>
On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret &lt;<a href=3D"mailto:g=
rega@celtra.com" target=3D"_blank">grega@celtra.com</a>&gt; wrote:<br>
<br>
&gt; Looking at<br>
&gt; <a href=3D"http://spark.incubator.apache.org/docs/latest/configuration=
.html" target=3D"_blank">http://spark.incubator.apache.org/docs/latest/conf=
iguration.html</a><br>
&gt; docs says:<br>
&gt; Number of individual task failures before giving up on the job. Should=
 be<br>
&gt; greater than or equal to 1. Number of allowed retries =3D this value -=
 1.<br>
&gt;<br>
&gt; However, looking at the code<br>
&gt;<br>
&gt; <a href=3D"https://github.com/apache/incubator-spark/blob/master/core/=
src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.sca=
la#L532" target=3D"_blank">https://github.com/apache/incubator-spark/blob/m=
aster/core/src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSet=
Manager.scala#L532</a><br>



&gt;<br>
&gt; if I set spark.task.maxFailures to 1, this means that job will fail af=
ter<br>
&gt; task fails for the second time. Shouldn&#39;t this line be corrected t=
o if (<br>
&gt; numFailures(index) &gt;=3D MAX_TASK_FAILURES) {<br>
&gt; ?<br>
&gt;<br>
&gt; I can open a pull request if this is the case.<br>
&gt;<br>
&gt; Thanks,<br>
&gt; Grega<br>
&gt; --<br>
&gt; [image: Inline image 1]<br>
</div>&gt; *Grega Ke=C5=A1pret*<br>
<div>&gt; Analytics engineer<br>
&gt;<br>
&gt; Celtra =E2=80=94 Rich Media Mobile Advertising<br>
</div>&gt; <a href=3D"http://celtra.com" target=3D"_blank">celtra.com</a> &=
lt;<a href=3D"http://www.celtra.com/" target=3D"_blank">http://www.celtra.c=
om/</a>&gt; | @celtramobile&lt;<a href=3D"http://www.twitter.com/celtramobi=
le" target=3D"_blank">http://www.twitter.com/celtramobile</a>&gt;<br>



&gt;<br>
</blockquote></div><br></div></div></div></div>
</blockquote></div><br></div>

--20cf302234d56c406b04ed1bbe48--
--20cf302234d56c406d04ed1bbe49--

From dev-return-864-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 16:19:23 2013
Return-Path: <dev-return-864-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 439C110FD2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 16:19:23 +0000 (UTC)
Received: (qmail 53292 invoked by uid 500); 9 Dec 2013 16:19:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52948 invoked by uid 500); 9 Dec 2013 16:19:20 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 52879 invoked by uid 99); 9 Dec 2013 16:19:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 16:19:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.213.176] (HELO mail-ig0-f176.google.com) (209.85.213.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 16:19:09 +0000
Received: by mail-ig0-f176.google.com with SMTP id k19so1417323igc.3
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 08:18:47 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=4RcWL/f+m5HH7/Up7nQPkOCLU+O97rffmlrRozP6lD0=;
        b=caKZdiUx1zSz74dpYMk6oEu3cIhvSQ4vqooN45OtZvkW7PMy7zaHHmi7eS4zIo0Y0Z
         yN3UJ7rRo3Bnmp1BnzFhmn6ds2EpEs76WRxJVrnfcSNEFB8R28j8kI/fJWi5Ys0vuJGO
         Y1y0m2cTlzjOTfCU7UVb28ebASTapmHcokUIbObnIJDCv/FPjM4D2cN7XsM52uzdVVCD
         4P30mHue4uxUxaBMJxl7gGnf4I+Tecf2cuSV7yfxcoxcjysSNJkZG8Jh95zBdNg9PB3Z
         PD06/eNrodRAHKBtmezCp5rbfseXibbhfWzFIQYly6tbgreRRNrQZh7ZVCtU6Nq6YKBk
         RBAA==
X-Gm-Message-State: ALoCoQkfCD6GCt+HXenuIhgVqMZUT2TsEM68tIj45QZX54qy8QK0b2LGoi5+mYL8YEHixDQ0sJog
X-Received: by 10.43.129.70 with SMTP id hh6mr1212673icc.68.1386605927712;
 Mon, 09 Dec 2013 08:18:47 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.224.161 with HTTP; Mon, 9 Dec 2013 08:18:27 -0800 (PST)
In-Reply-To: <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
 <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
 <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com> <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
From: =?UTF-8?Q?Grega_Ke=C5=A1pret?= <grega@celtra.com>
Date: Mon, 9 Dec 2013 17:18:27 +0100
Message-ID: <CAMihvYbZ6Up2-d9gXfWmsXYXwD0TTjx+RTskQVAuawVN41HUuA@mail.gmail.com>
Subject: Re: spark.task.maxFailures
To: dev@spark.incubator.apache.org
Content-Type: multipart/related; boundary=001a11c2ab14c44a2f04ed1c5931
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2ab14c44a2f04ed1c5931
Content-Type: multipart/alternative; boundary=001a11c2ab14c44a2c04ed1c5930

--001a11c2ab14c44a2c04ed1c5930
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I see that it is the DAGScheduler that orchestrates task resubmission. This
code<https://github.com/apache/incubator-spark/blob/master/core/src/main/sc=
ala/org/apache/spark/scheduler/DAGScheduler.scala#L625-L633>
is
responsible for calling submitStage for any failed stages. How does
spark.task.maxFailures affect this (if at all) ?

Log on driver:
https://gist.github.com/gregakespret/7874908#file-gistfile1-txt-L1045-L1062=
(lines
where I killed JVM worker are selected)


Grega
--
[image: Inline image 1]
*Grega Ke=C5=A1pret*
Analytics engineer

Celtra =E2=80=94 Rich Media Mobile Advertising
celtra.com <http://www.celtra.com/> |
@celtramobile<http://www.twitter.com/celtramobile>


On Mon, Dec 9, 2013 at 4:35 PM, Grega Ke=C5=A1pret <grega@celtra.com> wrote=
:

> Hi!
>
> I tried this (by setting spark.task.maxFailures to 1) and it still does
> not fail-fast. I started a job and after some time, I killed all JVMs
> running on one of the two workers. I was expecting Spark job to fail,
> however it re-fetched tasks to one of the two workers that was still aliv=
e
> and the job succeeded.
>
> Grega
> --
> [image: Inline image 1]
> *Grega Ke=C5=A1pret*
> Analytics engineer
>
> Celtra =E2=80=94 Rich Media Mobile Advertising
> celtra.com <http://www.celtra.com/> | @celtramobile<http://www.twitter.co=
m/celtramobile>
>
>
> On Mon, Dec 9, 2013 at 10:43 AM, Grega Ke=C5=A1pret <grega@celtra.com> wr=
ote:
>
>> Hi Reynold,
>>
>> I submitted a pull request here -
>> https://github.com/apache/incubator-spark/pull/245
>> Do I need to do anything else (perhaps add a ticket in JIRA)?
>>
>> Best,
>> Grega
>> --
>> [image: Inline image 1]
>> *Grega Ke=C5=A1pret*
>>
>> Analytics engineer
>>
>> Celtra =E2=80=94 Rich Media Mobile Advertising
>> celtra.com <http://www.celtra.com/> | @celtramobile<http://www.twitter.c=
om/celtramobile>
>>
>>
>> On Fri, Nov 29, 2013 at 6:24 PM, Reynold Xin <rxin@apache.org> wrote:
>>
>>> Looks like a bug to me. Can you submit a pull request?
>>>
>>>
>>>
>>> On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret <grega@celtra.com> =
wrote:
>>>
>>> > Looking at
>>> > http://spark.incubator.apache.org/docs/latest/configuration.html
>>> > docs says:
>>> > Number of individual task failures before giving up on the job. Shoul=
d
>>> be
>>> > greater than or equal to 1. Number of allowed retries =3D this value =
- 1.
>>> >
>>> > However, looking at the code
>>> >
>>> >
>>> https://github.com/apache/incubator-spark/blob/master/core/src/main/sca=
la/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.scala#L532
>>> >
>>> > if I set spark.task.maxFailures to 1, this means that job will fail
>>> after
>>> > task fails for the second time. Shouldn't this line be corrected to i=
f
>>> (
>>> > numFailures(index) >=3D MAX_TASK_FAILURES) {
>>> > ?
>>> >
>>> > I can open a pull request if this is the case.
>>> >
>>> > Thanks,
>>> > Grega
>>> > --
>>> > [image: Inline image 1]
>>> > *Grega Ke=C5=A1pret*
>>> > Analytics engineer
>>> >
>>> > Celtra =E2=80=94 Rich Media Mobile Advertising
>>> > celtra.com <http://www.celtra.com/> | @celtramobile<
>>> http://www.twitter.com/celtramobile>
>>> >
>>>
>>
>>
>

--001a11c2ab14c44a2c04ed1c5930
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">I see that it is the DAGScheduler that orchestrates task r=
esubmission. <a href=3D"https://github.com/apache/incubator-spark/blob/mast=
er/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L625-L=
633">This code</a>=C2=A0is responsible for calling submitStage for any fail=
ed stages. How does spark.task.maxFailures affect this (if at all) ?<div>

<br></div><div>Log on driver:=C2=A0<a href=3D"https://gist.github.com/grega=
kespret/7874908#file-gistfile1-txt-L1045-L1062">https://gist.github.com/gre=
gakespret/7874908#file-gistfile1-txt-L1045-L1062</a> (lines where I killed =
JVM worker are selected)</div>

<div><br></div></div><div class=3D"gmail_extra"><br clear=3D"all"><div><div=
 dir=3D"ltr"><div>Grega</div>--<br><table style=3D"line-height:12px;color:r=
gb(119,121,133);font-size:11px;font-family:Helvetica,Arial,sans-serif;margi=
n:6px 0px;padding:0px">

<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><br>Analytics engineer<br><b=
r><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobile=
 Advertising</span><br>

</div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helvetica,Ari=
al,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><span s=
tyle=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif">=C2=
=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=3D"f=
ont-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blan=
k">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>

</span></td></tr></tbody></table></div></div>
<br><br><div class=3D"gmail_quote">On Mon, Dec 9, 2013 at 4:35 PM, Grega Ke=
=C5=A1pret <span dir=3D"ltr">&lt;<a href=3D"mailto:grega@celtra.com" target=
=3D"_blank">grega@celtra.com</a>&gt;</span> wrote:<br><blockquote class=3D"=
gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-=
left:1ex">

<div dir=3D"ltr"><span style=3D"font-family:arial,sans-serif;font-size:12.8=
00000190734863px">Hi!</span><div style=3D"font-family:arial,sans-serif;font=
-size:12.800000190734863px"><br></div><div style=3D"font-family:arial,sans-=
serif;font-size:12.800000190734863px">


I tried this (by setting spark.task.maxFailures to 1) and it still does not=
 fail-fast. I started a job and after some time, I killed all JVMs running =
on one of the two workers. I was expecting Spark job to fail, however it re=
-fetched tasks to one of the two workers that was still alive and the job s=
ucceeded.=C2=A0</div>


</div><div class=3D"gmail_extra"><div class=3D"im"><br clear=3D"all"><div><=
div dir=3D"ltr"><div>Grega</div>--<br><table style=3D"line-height:12px;colo=
r:rgb(119,121,133);font-size:11px;font-family:Helvetica,Arial,sans-serif;ma=
rgin:6px 0px;padding:0px">


<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><br>Analytics engineer<br><b=
r><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobile=
 Advertising</span><br>


</div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helvetica,Ari=
al,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><span s=
tyle=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif">=C2=
=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=3D"f=
ont-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blan=
k">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>


</span></td></tr></tbody></table></div></div>
<br><br></div><div><div class=3D"h5"><div class=3D"gmail_quote">On Mon, Dec=
 9, 2013 at 10:43 AM, Grega Ke=C5=A1pret <span dir=3D"ltr">&lt;<a href=3D"m=
ailto:grega@celtra.com" target=3D"_blank">grega@celtra.com</a>&gt;</span> w=
rote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;borde=
r-left:1px #ccc solid;padding-left:1ex">


<div dir=3D"ltr">Hi Reynold,<div><br></div><div>I submitted a pull request =
here -=C2=A0<a href=3D"https://github.com/apache/incubator-spark/pull/245" =
target=3D"_blank">https://github.com/apache/incubator-spark/pull/245</a></d=
iv><div>


Do I need to do anything else (perhaps add a ticket in JIRA)?</div>
<div class=3D"gmail_extra"><br></div><div class=3D"gmail_extra">Best,<br cl=
ear=3D"all"><div><div dir=3D"ltr"><div>Grega</div>--<br><table style=3D"lin=
e-height:12px;color:rgb(119,121,133);font-size:11px;font-family:Helvetica,A=
rial,sans-serif;margin:6px 0px;padding:0px">



<tbody><tr><td valign=3D"top"><img src=3D"cid:ii_13b04c50817df16a" alt=3D"I=
nline image 1"></td><td style=3D"line-height:13px"><div><strong style=3D"co=
lor:rgb(34,37,103)">Grega Ke=C5=A1pret</strong><div><br>Analytics engineer<=
br>
<br><span style=3D"color:rgb(159,159,171)">Celtra =E2=80=94 Rich Media Mobi=
le Advertising</span><br>
</div></div><a href=3D"http://www.celtra.com/" style=3D"font-family:Helveti=
ca,Arial,sans-serif;color:rgb(17,85,204)" target=3D"_blank">celtra.com</a><=
span style=3D"color:rgb(159,159,171);font-family:Helvetica,Arial,sans-serif=
">=C2=A0|=C2=A0</span><a href=3D"http://www.twitter.com/celtramobile" style=
=3D"font-family:Helvetica,Arial,sans-serif;color:rgb(17,85,204)" target=3D"=
_blank">@celtramobile</a><span style=3D"color:rgb(159,159,171)"><br>



</span></td></tr></tbody></table></div></div><div><div>
<br><br><div class=3D"gmail_quote">On Fri, Nov 29, 2013 at 6:24 PM, Reynold=
 Xin <span dir=3D"ltr">&lt;<a href=3D"mailto:rxin@apache.org" target=3D"_bl=
ank">rxin@apache.org</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
">



Looks like a bug to me. Can you submit a pull request?<br>
<div><br>
<br>
<br>
On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret &lt;<a href=3D"mailto:g=
rega@celtra.com" target=3D"_blank">grega@celtra.com</a>&gt; wrote:<br>
<br>
&gt; Looking at<br>
&gt; <a href=3D"http://spark.incubator.apache.org/docs/latest/configuration=
.html" target=3D"_blank">http://spark.incubator.apache.org/docs/latest/conf=
iguration.html</a><br>
&gt; docs says:<br>
&gt; Number of individual task failures before giving up on the job. Should=
 be<br>
&gt; greater than or equal to 1. Number of allowed retries =3D this value -=
 1.<br>
&gt;<br>
&gt; However, looking at the code<br>
&gt;<br>
&gt; <a href=3D"https://github.com/apache/incubator-spark/blob/master/core/=
src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.sca=
la#L532" target=3D"_blank">https://github.com/apache/incubator-spark/blob/m=
aster/core/src/main/scala/org/apache/spark/scheduler/cluster/ClusterTaskSet=
Manager.scala#L532</a><br>




&gt;<br>
&gt; if I set spark.task.maxFailures to 1, this means that job will fail af=
ter<br>
&gt; task fails for the second time. Shouldn&#39;t this line be corrected t=
o if (<br>
&gt; numFailures(index) &gt;=3D MAX_TASK_FAILURES) {<br>
&gt; ?<br>
&gt;<br>
&gt; I can open a pull request if this is the case.<br>
&gt;<br>
&gt; Thanks,<br>
&gt; Grega<br>
&gt; --<br>
&gt; [image: Inline image 1]<br>
</div>&gt; *Grega Ke=C5=A1pret*<br>
<div>&gt; Analytics engineer<br>
&gt;<br>
&gt; Celtra =E2=80=94 Rich Media Mobile Advertising<br>
</div>&gt; <a href=3D"http://celtra.com" target=3D"_blank">celtra.com</a> &=
lt;<a href=3D"http://www.celtra.com/" target=3D"_blank">http://www.celtra.c=
om/</a>&gt; | @celtramobile&lt;<a href=3D"http://www.twitter.com/celtramobi=
le" target=3D"_blank">http://www.twitter.com/celtramobile</a>&gt;<br>




&gt;<br>
</blockquote></div><br></div></div></div></div>
</blockquote></div><br></div></div></div>
</blockquote></div><br></div>

--001a11c2ab14c44a2c04ed1c5930--
--001a11c2ab14c44a2f04ed1c5931--

From dev-return-865-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 17:22:39 2013
Return-Path: <dev-return-865-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 319CF10228
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 17:22:39 +0000 (UTC)
Received: (qmail 79192 invoked by uid 500); 9 Dec 2013 17:22:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78958 invoked by uid 500); 9 Dec 2013 17:22:29 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 47374 invoked by uid 99); 9 Dec 2013 13:46:51 -0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
From: Deenar Toraskar <deenar.toraskar@db.com>
To: "'dev@spark.incubator.apache.org'" <dev@spark.incubator.apache.org>
Date: Mon, 9 Dec 2013 14:46:13 +0100
Subject: Spark API - support for asynchronous calls - Reactive style [I]
Thread-Topic: Spark API - support for asynchronous calls - Reactive style [I]
Thread-Index: Ac705QHrqQm1iKBjShK74tr+E2zzYQ==
Message-ID: <0A72D5474816A044BF164916E111EDA401395A55E10C@DEFRCDBG003.de.db.com>
Accept-Language: en-US, de-DE
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-tituslabs-classifications-30: TLPropertyRoot=db.com;Classification=For
 internal use only;
x-titus-version: 3.5.10.6
x-tituslabs-classificationhash-30: 2PrCjJ7f5poVv9TjWbkmkmhhFvA3h7YAevodhdZi6VLZr8JD94xLer25ol58Eik+ARMrOrXYp0CMKLCWSyj5On0o1T0geEePBFCkJnLPT1wnCBPj15i1CyA0rKwcWp/Ifrp5dQjP1/gIBfKhKK+O+ovMvyL1FGlq080GI/QaTB0PLx62ruY5xICotsCyM38mczOdhnn594PO0p7pmDxDJfM/dOQuq1WHl3u4EvfSJWQqOnCWxS31vnMPoMTXgH1YfkQ8BV12WijaXBpUvrhOgA==
x-tituslabs-subjectpostlabel: [I]
acceptlanguage: en-US, de-DE
x-trailer: Yes
Content-Type: multipart/alternative;
	boundary="_000_0A72D5474816A044BF164916E111EDA401395A55E10CDEFRCDBG003_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_0A72D5474816A044BF164916E111EDA401395A55E10CDEFRCDBG003_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Classification: For internal use only
Hi developers

Are there any plans to have Spark (and Shark) APIs that are asynchronous an=
d non blocking? APIs that return Futures and Iteratee/Enumerators would be =
very useful to users building scalable apps using Spark, specially when com=
bined with a fully asynchronous/non-blocking framework like Play!.

Something along the lines of ReactiveMongo
http://stephane.godbillon.com/2012/08/30/reactivemongo-for-scala-unleashing=
-mongodb-streaming-capabilities-for-realtime-web


Deenar

---
This e-mail may contain confidential and/or privileged information. If you =
are not the intended recipient (or have received this e-mail in error) plea=
se notify the sender immediately and delete this e-mail. Any unauthorized c=
opying, disclosure or distribution of the material in this e-mail is strict=
ly forbidden.

Please refer to http://www.db.com/en/content/eu_disclosures.htm for additio=
nal EU corporate and regulatory disclosures.

--_000_0A72D5474816A044BF164916E111EDA401395A55E10CDEFRCDBG003_--

From dev-return-866-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 17:32:00 2013
Return-Path: <dev-return-866-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D83BE1026F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 17:32:00 +0000 (UTC)
Received: (qmail 95872 invoked by uid 500); 9 Dec 2013 17:32:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95812 invoked by uid 500); 9 Dec 2013 17:32:00 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 95804 invoked by uid 99); 9 Dec 2013 17:31:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 17:31:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.49] (HELO mail-bk0-f49.google.com) (209.85.214.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 17:31:55 +0000
Received: by mail-bk0-f49.google.com with SMTP id my13so1490450bkb.36
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 09:31:34 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=rNY/G7IefGgLvdqdyESdbOp6aOYlC3QJYNdSyojIWKE=;
        b=AYHmCVwKhfhXxvFG4Plarj2aWDCpDZLLYhDP2J1c4mrhqUtJWb1hB3vg2nj/UxPJ+y
         9qmzwE37Wqs4SE/vXBFuLhHKUu1z5o1wb7QwnKU8pKNOnpDb6tCs54ss3q6OCKrhjdxb
         nXSSNEA3RzYVlmhpVM7AS+Mg0r/cwHp8sm2SNIrE0A1B1zYj28U6IDKxFGqmztTV0a64
         zPd+cuiMZJWXYmo9YzSsOd6naRFMznCLMBYSlZCSeYL7YGuuxqPrHpTWJLg7JblbauW3
         03UTWMLf++rX/HF6Fl42e+K9mrVhC8ujEdW5wc4a+Uib/vnPHmqocSOoQDbyBc4T7iK9
         kmBQ==
X-Gm-Message-State: ALoCoQkd6OPWQF/Lynojku0BexyBulMU79ng5/q1bLLwtJpfFQDdmpFQiXRdh4U7g15gC2kw4YtX
MIME-Version: 1.0
X-Received: by 10.205.35.204 with SMTP id sx12mr2646599bkb.49.1386610293624;
 Mon, 09 Dec 2013 09:31:33 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Mon, 9 Dec 2013 09:31:33 -0800 (PST)
In-Reply-To: <0A72D5474816A044BF164916E111EDA401395A55E10C@DEFRCDBG003.de.db.com>
References: <0A72D5474816A044BF164916E111EDA401395A55E10C@DEFRCDBG003.de.db.com>
Date: Mon, 9 Dec 2013 09:31:33 -0800
Message-ID: <CAAsvFP=_OeSqCz6JAddbs5+kMu630yLuqeh8V2kFkjacdQLPHg@mail.gmail.com>
Subject: Re: Spark API - support for asynchronous calls - Reactive style [I]
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec52c61ddfeb1ec04ed1d5d54
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec52c61ddfeb1ec04ed1d5d54
Content-Type: text/plain; charset=ISO-8859-1

Spark has already supported async jobs for awhile now --
https://github.com/apache/incubator-spark/pull/29, and they even work
correctly after https://github.com/apache/incubator-spark/pull/232

There are now implicit conversions from RDD to
AsyncRDDActions<https://github.com/apache/incubator-spark/blob/master/core/src/main/scala/org/apache/spark/rdd/AsyncRDDActions.scala>,
where async actions like countAsync are defined.


On Mon, Dec 9, 2013 at 5:46 AM, Deenar Toraskar <deenar.toraskar@db.com>wrote:

> Classification: For internal use only
> Hi developers
>
> Are there any plans to have Spark (and Shark) APIs that are asynchronous
> and non blocking? APIs that return Futures and Iteratee/Enumerators would
> be very useful to users building scalable apps using Spark, specially when
> combined with a fully asynchronous/non-blocking framework like Play!.
>
> Something along the lines of ReactiveMongo
>
> http://stephane.godbillon.com/2012/08/30/reactivemongo-for-scala-unleashing-mongodb-streaming-capabilities-for-realtime-web
>
>
> Deenar
>
> ---
> This e-mail may contain confidential and/or privileged information. If you
> are not the intended recipient (or have received this e-mail in error)
> please notify the sender immediately and delete this e-mail. Any
> unauthorized copying, disclosure or distribution of the material in this
> e-mail is strictly forbidden.
>
> Please refer to http://www.db.com/en/content/eu_disclosures.htm for
> additional EU corporate and regulatory disclosures.
>

--bcaec52c61ddfeb1ec04ed1d5d54--

From dev-return-867-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 17:38:03 2013
Return-Path: <dev-return-867-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 57CFB10289
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 17:38:03 +0000 (UTC)
Received: (qmail 4834 invoked by uid 500); 9 Dec 2013 17:38:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4802 invoked by uid 500); 9 Dec 2013 17:38:02 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 4794 invoked by uid 99); 9 Dec 2013 17:38:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 17:38:02 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [98.139.212.154] (HELO nm3-vm0.bullet.mail.bf1.yahoo.com) (98.139.212.154)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 09 Dec 2013 17:37:54 +0000
Received: from [66.196.81.170] by nm3.bullet.mail.bf1.yahoo.com with NNFMP; 09 Dec 2013 17:37:32 -0000
Received: from [98.139.212.223] by tm16.bullet.mail.bf1.yahoo.com with NNFMP; 09 Dec 2013 17:37:31 -0000
Received: from [127.0.0.1] by omp1032.mail.bf1.yahoo.com with NNFMP; 09 Dec 2013 17:37:31 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 717305.7497.bm@omp1032.mail.bf1.yahoo.com
Received: (qmail 38469 invoked by uid 60001); 9 Dec 2013 17:37:31 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1386610651; bh=aeutmcufFYrrKRMhP7xB4FNZN1iKJDkAndp0VHr6sfU=; h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=VenS/SflB48Qymew+gGeK06ERHmudM48mh8k8hXR2it+quG9CbhpkpWBgRoDYYR2NWVEf4Hjp3vIgMrRIkdM/nTEaVwPTUeYAU4u++Hn7mabi2G7GK1+Ma4zgcfOlbt2QoiwkWgRzTvQJNAliLz5NhnCt/vE0Xc2yB0FP2vTXP0=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=j6vcFv3dnvRtfzqDyQbrXbgvcYd55AREHCwuwjuFsYgfJkwkWsP4wCxqPeUmCfQ+Mzt9NCMj3syoJKA9+CaCX/I84Nf9sb3IQ6wVOi2pikHTLaeapNk8YbVWDe+Gb7dyY2IxYtqOXfUFoKNc4Rw+Qkk2hHsyyOYGxWT4jmP7Ink=;
X-YMail-OSG: SLvxQMEVM1nSV3MuHEeucd60MvReayvWDXY3vwhfcf4oFSe
 D7l.zPNPhNI52Hq6HzSOUOO30lTz0Cwh7HujUuDYj2aP9JqEmBc7aHIc5ymc
 Gl0CzWS2_ykSFJrMQUysF.vSe0Osme3PbOL1LLRzb0k4l22SrCrQ8qe3eMx6
 9OcfPBzu.Lb19pCtZxlVJ5NqMYFqxis_gylvdnT7K1DtRnJhYQaAP6kIr5D3
 ARcjvmhORJbbOuDkd1glVrUyQ7utmffhMv3N18Ay4frqM379v1SE1TwJuAFP
 EGnCDX1odIpHjdgb2Yfysdxr5jUMQnDVdlEBEqe3rJtiCDANhR9sg30QVAj9
 r948kLy12tu4xuwRJyaPMQZVmtyQJGTukfrUa.U2nzq3kdYF_Mowvv4QnHWS
 xV9Cwdn.kIK4u1KLAmI_K8Jj9.WqgQZuLFjxmexA2_StqAwgB9DpFtp9gVXD
 _c1Qoy0IdQ_xC619JZNsRXhNfQHpxiMTseAi.aXvuaDWeL76WN3a9sf.Z27s
 Wx_fTQs2vqojilXUcH1wDEa67a5IUGRKIxIyXHmoHCYTxmuN3Vf7Gsz9JzB7
 KNTRt1Gm1TB_LhMyzutFdZZGfT08PtnXjekt2rA1FsTj4edY2BAcq9_heEBb
 K5kfiwGtBp9m517k73UkT577luVHz8dz5RgUCm50P.8yA7K2HbmhK_Xk6YcW
 XQ9q0MqwBkLSSjORW9TqcbpvZhpCKx71xnDeKV4j6TSaFzG0VhilDSJr_rW_
 UXKb962hzw9oviOpNlYo4oVgMQS5N4B3BTA--
Received: from [207.93.212.51] by web160802.mail.bf1.yahoo.com via HTTP; Mon, 09 Dec 2013 09:37:31 PST
X-Rocket-MIMEInfo: 002.001,SSBoYXZlbid0IHNlZW4gYSByZXNwb25zZSB0byBteSBTZXB0ZW1iZXIgcXVlc3Rpb24gYW5kIHdhcyB3b25kZXJpbmcgaWYgYW55b25lIGhhZCBhbnkgaW5zaWdodHMgaW50byB0aGUgcHJvYmxlbSBJIHdhcyBoYXZpbmcgY2xlYW5seSBzaHV0dGluZyBkb3duIEthZmthLgoKTm90ZTogRm9yIHRoZSBwdXJwb3NlcyBvZiB0aGUgQXBhY2hlIDIuMCBsaWNlbnNlLCByZWdhcmRpbmcgdGhlIGNvbnRlbnRzIG9mIHRoaXMgYW5kIG15IGVhcmxpZXIgbWVzc2FnZTogVEhJUyBJUyBOT1QgQSBDT05UUklCVVRJT04uCgoBMAEBAQE-
X-Mailer: YahooMailWebService/0.8.169.609
References: <1380220041.2428.YahooMailNeo@web160804.mail.bf1.yahoo.com>
Message-ID: <1386610651.36144.YahooMailNeo@web160802.mail.bf1.yahoo.com>
Date: Mon, 9 Dec 2013 09:37:31 -0800 (PST)
From: Michael Malak <michaelmalak@yahoo.com>
Reply-To: Michael Malak <michaelmalak@yahoo.com>
Subject: Re: Kafka not shutting down cleanly; Actor serializtion?
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
In-Reply-To: <1380220041.2428.YahooMailNeo@web160804.mail.bf1.yahoo.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="485266291-1612830810-1386610651=:36144"
X-Virus-Checked: Checked by ClamAV on apache.org

--485266291-1612830810-1386610651=:36144
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

I haven't seen a response to my September question and was wondering if any=
one had any insights into the problem I was having cleanly shutting down Ka=
fka.=0A=0ANote: For the purposes of the Apache 2.0 license, regarding the c=
ontents of this and my earlier message: THIS IS NOT A CONTRIBUTION.=0A=0A=
=0A________________________________=0A From: Michael Malak <michaelmalak@ya=
hoo.com>=0ATo: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache=
.org> =0ASent: Thursday, September 26, 2013 12:27 PM=0ASubject: Kafka not s=
hutting down cleanly; Actor serializtion?=0A =0A=0A=0ATathagata:=0A=0A=0AI =
don't believe Kafka streams are being shut down cleanly, which implies that=
 the most recent Kafka offsets are not being committed back to Zookeeper, w=
hich implies starting/restarting a Spark Streaming process would result in =
duplicate events.=0A=0AThe simple Spark Streaming code (running in local mo=
de) pasted below at the end of this e-mail, which uses a hard-coded queueSt=
ream as its only input stream, exits cleanly when the presence of the senti=
nel file is detected. However, if the queueStream is replaced with a kafkaS=
tream, the process never exits (unless I put a System.exit() as the very la=
st line -- to forcibly kill all threads).=0A=0AIn attempting to understand =
the Kafka shutdown process, I traced through the Spark Streaming codebase w=
ith println()s. I noticed the following:=0A=0A1. Although KafkaInputDStream=
.scala initializes the class member variable=A0consumerConnector in onStart=
(), I don't see a corresponding consumerConnector.shutdown() anywhere such =
as in the onStop(). It is my understanding that it is the consumer shutdown=
() that commits the offsets back to Zookeeper. See the Kafka example at=A0h=
ttps://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example#Con=
sumerGroupExample-FullSourceCode=0A=0A2. There is a similar apparent asymme=
try with executorPool, where it is not released in the onStop(). (A further=
 minor encumbrance is that it is a variable local to onStart() rather than =
being a class member variable)=0A=0A3. Through my println() tracing and Akk=
a debug-level logging, I'm not seeing NetworkReceiverActor ever receiving a=
 StopReceiver message from ReceiverExecutor. From some poking around and te=
sting, it seems possible to successfully send any type of message to Networ=
kReceiverActor only prior to that NetowrkReceiverActor being serialized int=
o an RDD on line 146 of NetworkInputTracker.scala=0Ahttps://github.com/meso=
s/spark/blob/branch-0.8/streaming/src/main/scala/org/apache/spark/streaming=
/NetworkInputTracker.scala#L146=0A=0APrior to the actor being put into the =
RDD, messages can be sent to the actor, but not after the actor is put into=
 the RDD. Is it possible that Akka actors are intolerant of being serialize=
d?=0A=0A4. I noticed a lot of "TODO" comments sprinkled throughout the code=
 relating to shutdown/termination/cleanup.=0A=0AMy biggest concern is #3 ab=
ove, because if my suppositions are correct, then there might be some major=
 re-architecting involved. The other issues I could probably fix on my own =
and commit back.=0A=0A=0Aimport spark.streaming._=0A=0Aobject SimpleSparkSt=
reaming {=0A=A0 @volatile var receivedStop =3D false=0A=A0 val sentinelFile=
 =3D new java.io.File("/home/mmalak/stop")=0A=0A=A0 def main(args: Array[St=
ring]) {=0A=A0 =A0 val Array(master, zkQuorum, broker, group, topics, numTh=
reads) =3D args=0A=0A=A0 =A0 sentinelFile.delete=0A=0A=A0 =A0 val ssc =3D =
=A0new StreamingContext(master, "SimpleBeta", Seconds(1), System.getenv("SP=
ARK_HOME"), Seq("./target/scala-2.9.2/my.jar"))=0A=A0 =A0 ssc.checkpoint("/=
home/mmalak/checkpointing")=0A=0A=A0 =A0 ssc.queueStream(new scala.collecti=
on.mutable.Queue[spark.RDD[Int]] +=3D ssc.sparkContext.makeRDD(List(1))).fo=
reach(rdd =3D>=0A=A0 =A0 =A0 println("receivedStop[" + receivedStop + "]"))=
=0A=A0 =A0 ssc.start()=0A=0A=A0 =A0 while (!sentinelFile.exists) {Thread.sl=
eep(1000)}=0A=A0 =A0 println("Stop detected")=0A=A0 =A0 receivedStop =3D tr=
ue=0A=A0 =A0 ssc.stop()=0A=A0 =A0 println("Exiting main")=0A=A0 }=0A}
--485266291-1612830810-1386610651=:36144--

From dev-return-868-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec  9 19:22:33 2013
Return-Path: <dev-return-868-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3170F10690
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Dec 2013 19:22:33 +0000 (UTC)
Received: (qmail 39100 invoked by uid 500); 9 Dec 2013 19:22:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39063 invoked by uid 500); 9 Dec 2013 19:22:32 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 39055 invoked by uid 99); 9 Dec 2013 19:22:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 19:22:32 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.43 as permitted sender)
Received: from [209.85.219.43] (HELO mail-oa0-f43.google.com) (209.85.219.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Dec 2013 19:22:26 +0000
Received: by mail-oa0-f43.google.com with SMTP id i7so4408712oag.16
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 11:22:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=pxLxMlb7NeZROFRMGyspF+MjLYWUUqzLarjuaDv/2YY=;
        b=CRCwS+YvWNX8jr0+QBvuP9v5E+q7KglmULp6rIWsfQRRzGLl31rm4bY3SWtVtgKROt
         ckiBUWxJm8lq/yg8F/SMLs6W7/yDgCchQV9TfxIX/bprgU6lCXzIuX94/SobNFYdpmz+
         xx5UAU33nvDUiPeIKzayOuwnGL77DNFgywLUHFas+VclyGKD0FEG1v9TvUm9j5ZEctvP
         P9CuZR/xAPYvJFzSpSoD9ciZduYK0NlfWmH8/NBUCzzgFgT/vuwT84DT/4ODPpMGog+z
         j0PZXO3uSt5Qdj1nDiHCNYoS4amL1kXk0GYFNqf6J2xfemy0/b8Vy9mvoY0NM+FO7c9i
         L3LQ==
MIME-Version: 1.0
X-Received: by 10.182.92.231 with SMTP id cp7mr26617obb.82.1386616925321; Mon,
 09 Dec 2013 11:22:05 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Mon, 9 Dec 2013 11:22:05 -0800 (PST)
In-Reply-To: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
Date: Mon, 9 Dec 2013 11:22:05 -0800
Message-ID: <CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'll go ahead and kick this off with a +1.

On Sun, Dec 8, 2013 at 10:30 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark
> (incubating) version 0.8.1.
>
> The tag to be voted on is v0.8.1-incubating (commit c88a9916):
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=ba05afd29c81e152a84461f95b0e61a783897d7a
>
> The release files, including signatures, digests, etc can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-025/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/
>
> For information about the contents of this release see:
> <attached> draft of release notes
> <attached> draft of release credits
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>
> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>
> The vote is open until Thursday, December 12th at 06:30 UTC and
> passes if a majority of at least 3 +1 PPMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.incubator.apache.org/

From dev-return-869-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 10 06:42:04 2013
Return-Path: <dev-return-869-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2D13010C87
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Dec 2013 06:42:04 +0000 (UTC)
Received: (qmail 35335 invoked by uid 500); 10 Dec 2013 06:41:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35080 invoked by uid 500); 10 Dec 2013 06:41:26 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 34889 invoked by uid 99); 10 Dec 2013 06:41:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Dec 2013 06:41:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Dec 2013 06:41:15 +0000
Received: by mail-ob0-f180.google.com with SMTP id wo20so4803980obc.25
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 22:40:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=u7065C+VUTvzVAlwYTTtVSNsDPij4SDYrt00unpz52E=;
        b=d8xhk5s5joLXXHPTeWQMNKBo4rCtGdz96J1Wa0sTBQaQshUmbTtzjiWGZoaPrGH2rn
         VioXo2CIoFNKme0os+4/RmAMM6aptChtiK62f2BYpKugK8cWubVic75JTQYzd6kfjVUA
         Z6jKGG3WaDgveD77nE6DucBw+IK8s8NmIW7xutZqTbabqhM9LpJhuefvoP28URBF4gke
         wPXFEWKU7Rh4DUMxtkXNmqzDcxdLsmtnjDjFd4PVnJrw6CfGVc++GNBvjGRdyocUv/zn
         puBgljaJx+PyrdBQaV9FhkpqAYeu+MiSApXTtFMMZREjnV1AO+/W610T1i8vRk58kT6Q
         GOMw==
MIME-Version: 1.0
X-Received: by 10.182.153.196 with SMTP id vi4mr208210obb.75.1386657655204;
 Mon, 09 Dec 2013 22:40:55 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Mon, 9 Dec 2013 22:40:55 -0800 (PST)
In-Reply-To: <CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
	<CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
Date: Mon, 9 Dec 2013 22:40:55 -0800
Message-ID: <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'm going to -1 this now because we had two issues reported today.
They were reported off the list so I'm summarizing here:

(1) Raymond Liu found an issue with the Maven build for YARN 2.2+.
Previously we had only tested the sbt build since this is what we
refer to in the docs, but we'd like to support this for Maven as well.

(2) I noticed we were missing some header files from recent patches.
This will result in a -1 downstream during an IPMC release, so we
should fix it.

- Patrick

On Mon, Dec 9, 2013 at 11:22 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> I'll go ahead and kick this off with a +1.
>
> On Sun, Dec 8, 2013 at 10:30 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>> Please vote on releasing the following candidate as Apache Spark
>> (incubating) version 0.8.1.
>>
>> The tag to be voted on is v0.8.1-incubating (commit c88a9916):
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=ba05afd29c81e152a84461f95b0e61a783897d7a
>>
>> The release files, including signatures, digests, etc can be found at:
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/
>>
>> Release artifacts are signed with the following key:
>> https://people.apache.org/keys/committer/pwendell.asc
>>
>> The staging repository for this release can be found at:
>> https://repository.apache.org/content/repositories/orgapachespark-025/
>>
>> The documentation corresponding to this release can be found at:
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/
>>
>> For information about the contents of this release see:
>> <attached> draft of release notes
>> <attached> draft of release credits
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>>
>> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>>
>> The vote is open until Thursday, December 12th at 06:30 UTC and
>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>
>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> [ ] -1 Do not release this package because ...
>>
>> To learn more about Apache Spark, please see
>> http://spark.incubator.apache.org/

From dev-return-870-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 10 06:44:56 2013
Return-Path: <dev-return-870-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7166A10CA3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Dec 2013 06:44:56 +0000 (UTC)
Received: (qmail 42078 invoked by uid 500); 10 Dec 2013 06:44:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42034 invoked by uid 500); 10 Dec 2013 06:44:53 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 42026 invoked by uid 99); 10 Dec 2013 06:44:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Dec 2013 06:44:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.53 as permitted sender)
Received: from [74.125.82.53] (HELO mail-wg0-f53.google.com) (74.125.82.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Dec 2013 06:44:45 +0000
Received: by mail-wg0-f53.google.com with SMTP id k14so4494083wgh.20
        for <dev@spark.incubator.apache.org>; Mon, 09 Dec 2013 22:44:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=QWShwQSxVblbq74yfZwAvsLdd8VR2k3SD0IVkmW0Rdk=;
        b=YKY+RmYOEc/66T2rxqAVsEmJbhH3fNS3Dyc2BIS7W5uZUaXAssGX+JJluQwJTeM43p
         RbIAU/69oY1MGxb2yeW2Udb4k6PtvcIp5bXLwr7/Al66QyIomclkA5JtRERURMiTozmh
         3xZMYD+2DEDflvlLAYYq1XwQUqC+KmRXqide9X/4YnU6H4uFyUs1isL7gqAbKOxvjBSs
         NkRPEmX6L/MH7dsHeRTdzfiPpF00EaBnCoh48NfbbhNOjbrJsMCOhvoRPykVor+Vorum
         AnOR7x0DEE7dZ1rwm7qahJHxMVmBo3uUg5DJmQmk8BKMIGAqqcFH4pElrU+2ZJ5XLVvQ
         Gfrg==
MIME-Version: 1.0
X-Received: by 10.180.99.42 with SMTP id en10mr11785226wib.36.1386657865092;
 Mon, 09 Dec 2013 22:44:25 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Mon, 9 Dec 2013 22:44:25 -0800 (PST)
In-Reply-To: <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
	<CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
	<CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
Date: Mon, 9 Dec 2013 22:44:25 -0800
Message-ID: <CALuGr6bzGNBoRR8zUmeNwcw2Nibtefz0c5xo=YbvOeG+5ERk_g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for catching the problems, Patrick and Raymond.

- Henry

On Mon, Dec 9, 2013 at 10:40 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> I'm going to -1 this now because we had two issues reported today.
> They were reported off the list so I'm summarizing here:
>
> (1) Raymond Liu found an issue with the Maven build for YARN 2.2+.
> Previously we had only tested the sbt build since this is what we
> refer to in the docs, but we'd like to support this for Maven as well.
>
> (2) I noticed we were missing some header files from recent patches.
> This will result in a -1 downstream during an IPMC release, so we
> should fix it.
>
> - Patrick
>
> On Mon, Dec 9, 2013 at 11:22 AM, Patrick Wendell <pwendell@gmail.com> wrote:
>> I'll go ahead and kick this off with a +1.
>>
>> On Sun, Dec 8, 2013 at 10:30 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>> Please vote on releasing the following candidate as Apache Spark
>>> (incubating) version 0.8.1.
>>>
>>> The tag to be voted on is v0.8.1-incubating (commit c88a9916):
>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=tag;h=ba05afd29c81e152a84461f95b0e61a783897d7a
>>>
>>> The release files, including signatures, digests, etc can be found at:
>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/
>>>
>>> Release artifacts are signed with the following key:
>>> https://people.apache.org/keys/committer/pwendell.asc
>>>
>>> The staging repository for this release can be found at:
>>> https://repository.apache.org/content/repositories/orgapachespark-025/
>>>
>>> The documentation corresponding to this release can be found at:
>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/
>>>
>>> For information about the contents of this release see:
>>> <attached> draft of release notes
>>> <attached> draft of release credits
>>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>>>
>>> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>>>
>>> The vote is open until Thursday, December 12th at 06:30 UTC and
>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>>
>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>> [ ] -1 Do not release this package because ...
>>>
>>> To learn more about Apache Spark, please see
>>> http://spark.incubator.apache.org/

From dev-return-871-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 10 22:28:40 2013
Return-Path: <dev-return-871-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0B7D810DB3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Dec 2013 22:28:40 +0000 (UTC)
Received: (qmail 7662 invoked by uid 500); 10 Dec 2013 22:28:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7536 invoked by uid 500); 10 Dec 2013 22:28:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 56480 invoked by uid 99); 10 Dec 2013 21:15:17 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jkestelyn@cloudera.com designates 209.85.214.176 as permitted sender)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=euaDEH34DFcNI5uLZY47CwDYkImbMzFZV3w1EToy9DM=;
        b=DngZioxyonLQQeMihzwNIsxNaa+Pw/tlpYOjYay6bUEi0OzgXZz2zULls1CGd848+Z
         rfYkkw7ZJgq1BzxIM9WxMDd8wI/CY7/M5eI2iSGGGrKVBZaJcHW+aSkze8GkIslKA2B/
         ZdR3qd1u3PIY4SJ5voDdi20Zu7Bcps8G9Z6xqbhVJDfZ48/UpeALFWTmL1ukSDufUA+H
         3dqsJk2AWfYdOTJyQc5vbo7UiOzRBZJA+QQJtV3acKVjhO2HpNrj7mGUK6iJ74EoWP6K
         A0kySrErK9tdCswb5rUHoRMAObH32Go8GKXkmwqi2lNv5Il9YCUtSIUUKeOBqnQNMu0x
         nDoQ==
X-Gm-Message-State: ALoCoQnCtGk8W7mgvSDCyvtwqWzp/OebK2dpgfw5p1D3HyL/HSDzNQdKEaS8DK6pe0DiUKkeQ8ML
X-Received: by 10.60.78.227 with SMTP id e3mr18532990oex.5.1386710093522; Tue,
 10 Dec 2013 13:14:53 -0800 (PST)
MIME-Version: 1.0
In-Reply-To: <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com> <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
From: Justin Kestelyn <jkestelyn@cloudera.com>
Date: Tue, 10 Dec 2013 13:14:32 -0800
Message-ID: <CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: horia@alum.berkeley.edu
Cc: dev@spark.incubator.apache.org, Olivier Grisel <olivier.grisel@ensta.org>, 
	Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>
Content-Type: multipart/alternative; boundary=089e0111bca48804a204ed349ab3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0111bca48804a204ed349ab3
Content-Type: text/plain; charset=ISO-8859-1

Location:

Cloudera
433 California Street
San Francisco, CA


On Tue, Dec 3, 2013 at 9:30 AM, Horia <horia@alum.berkeley.edu> wrote:

> I am very interested in this and will most definitely participate!
>
> Please share the event sign-up list and location details when all the
> organizational hurdles have been resolved :-)
>
>
>
> On Mon, Dec 2, 2013 at 1:45 PM, Reynold Xin <rxin@apache.org> wrote:
>
>> Definitely some people will get confused. It's up to you. If we post it,
>> we
>> can mark it in the title that this is a hackathon.
>>
>>
>> On Mon, Dec 2, 2013 at 1:43 PM, Olivier Grisel <olivier.grisel@ensta.org
>> >wrote:
>>
>> > 2013/12/2 Reynold Xin <rxin@apache.org>:
>> > > Including the link to the meetup group:
>> > http://www.meetup.com/spark-users/
>> >
>> > I am not opposed to it but I am wondering if people will not confuse
>> > it with a traditional meetup if we do so.
>> >
>> > --
>> > Olivier
>> >
>>
>
>


-- 

*Justin Kestelyn*
Developer Outreach
Cloudera | www.cloudera.com

Tel: 650.683.4688
Email: jkestelyn@cloudera.com
Twitter: @kestelyn, @ClouderaEng

--089e0111bca48804a204ed349ab3--

From dev-return-872-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 00:49:36 2013
Return-Path: <dev-return-872-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1FFD0101FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 00:49:36 +0000 (UTC)
Received: (qmail 76742 invoked by uid 500); 11 Dec 2013 00:49:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76677 invoked by uid 500); 11 Dec 2013 00:49:35 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 76669 invoked by uid 99); 11 Dec 2013 00:49:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 00:49:35 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 00:49:30 +0000
Received: by mail-oa0-f47.google.com with SMTP id k1so6468307oag.6
        for <dev@spark.incubator.apache.org>; Tue, 10 Dec 2013 16:49:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=hj930UdYafoQoGv0zHO0ia5toP9tsurB/vGpUpdeSEk=;
        b=Atg6dE9zcs1v6F4kShH99JeGtRgA/IMyGWhCOXS3+7qrvcDR6koK96h7CWXqPiGRDN
         Cwdg2KVbRPN2nHBD/5vem2bE718bzmKefVrinvjJoVsWADpPLvUgQfOvKOllKrl6V8xH
         moPUYpPZeQTzK1W8/oVxFOC2IJ7eDjvuU52jTcLVRptqiyLRKf1KbWI+rYJOcQf8MlMQ
         3elDPgtBTRqOt2BYcnTEwnh+2MVyE0lY0dWIoM7AtNClJCP6BxuonAk1eecnD2Zl5Cwf
         ybdke0O2qx4K1jDUpFq9e10OC3OOzXPu0UCl7Cb7CxkYXOpg/L7tmSxKpOAvHOfikYSW
         gjBQ==
MIME-Version: 1.0
X-Received: by 10.60.92.137 with SMTP id cm9mr18561872oeb.38.1386722949427;
 Tue, 10 Dec 2013 16:49:09 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Tue, 10 Dec 2013 16:49:09 -0800 (PST)
Date: Tue, 10 Dec 2013 16:49:09 -0800
Message-ID: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Please vote on releasing the following candidate as Apache Spark
(incubating) version 0.8.1.

The tag to be voted on is v0.8.1-incubating (commit b87d31d):
https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e

The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-040/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/

For information about the contents of this release see:
https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8

Please vote on releasing this package as Apache Spark 0.8.1-incubating!

The vote is open until Saturday, December 14th at 01:00 UTC and
passes if a majority of at least 3 +1 PPMC votes are cast.

[ ] +1 Release this package as Apache Spark 0.8.1-incubating
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.incubator.apache.org/

From dev-return-873-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 03:49:59 2013
Return-Path: <dev-return-873-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2D27F10743
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 03:49:59 +0000 (UTC)
Received: (qmail 30057 invoked by uid 500); 11 Dec 2013 03:49:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29703 invoked by uid 500); 11 Dec 2013 03:49:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29695 invoked by uid 99); 11 Dec 2013 03:49:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 03:49:49 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [76.96.30.16] (HELO qmta01.emeryville.ca.mail.comcast.net) (76.96.30.16)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 03:49:41 +0000
Received: from omta15.emeryville.ca.mail.comcast.net ([76.96.30.71])
	by qmta01.emeryville.ca.mail.comcast.net with comcast
	id 03gR1n0031Y3wxoA13pKjw; Wed, 11 Dec 2013 03:49:19 +0000
Received: from boudnik.org ([24.4.185.157])
	by omta15.emeryville.ca.mail.comcast.net with comcast
	id 03pJ1n00G3QAh8g8b3pJeZ; Wed, 11 Dec 2013 03:49:19 +0000
Received: from localhost (tpx.boudnik.org [192.168.102.148])
	by boudnik.org (8.14.3/8.14.3/Debian-5+lenny1) with ESMTP id rBB3nIho006781
	for <dev@spark.incubator.apache.org>; Tue, 10 Dec 2013 19:49:18 -0800
Date: Tue, 10 Dec 2013 19:49:17 -0800
From: Konstantin Boudnik <cos@apache.org>
To: dev@spark.incubator.apache.org
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
Message-ID: <20131211034917.GB8865@tpx>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
 <CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
 <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/signed; micalg=pgp-sha256;
	protocol="application/pgp-signature"; boundary="qcHopEYAB45HaUaB"
Content-Disposition: inline
In-Reply-To: <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
X-Organization: It's something of 'Cos
X-PGP-Key: http://www.boudnik.org/~cos/pubkey.asc
User-Agent: Mutt/1.5.21 (2010-09-15)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=comcast.net;
	s=q20121106; t=1386733759;
	bh=U0oMKkbfhnRdM1jO9jjOWTECwMpmh738LVLSvDBgT84=;
	h=Received:Received:Received:Date:From:To:Subject:Message-ID:
	 MIME-Version:Content-Type;
	b=IQkIITbFfqjrEzuMDImIRh8oGgpCU9kiY7sYbFfb445nzbFh0Wz3tR56Kp1yIuMKW
	 Axgm20opqZwNQH1OUD3n/Je8DL0BomxtIRltGTRffLQslONtFu67oA3vaxIhEhFe8c
	 FGIdxAUrb5cNaiPuXMzEsArdB2RGVUljJYfIFOTKymhtmaA83kTDiLFcsfhFD6fyoS
	 77GSDdVOJJ7Yi8bQ+AuSQdrmmlbV2bAUaB8sdvSMctCVkH0sL2WYGgxeRj/T3MItR+
	 eSiQMskoTIgxeT3UjPjBR8tox3KabHXqZAJshhoQqXoYo4EHVHf7RUZMca9gLQQiDh
	 jd23unpkRP0zQ==
X-Virus-Checked: Checked by ClamAV on apache.org

--qcHopEYAB45HaUaB
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
Content-Transfer-Encoding: quoted-printable

On Mon, Dec 09, 2013 at 10:40PM, Patrick Wendell wrote:
> I'm going to -1 this now because we had two issues reported today.
> They were reported off the list so I'm summarizing here:
>=20
> (1) Raymond Liu found an issue with the Maven build for YARN 2.2+.
> Previously we had only tested the sbt build since this is what we
> refer to in the docs, but we'd like to support this for Maven as well.

Is there a ticket on the Maven issue? As I was the one who put it in place I
suppose it would be easier for me to fix it quickky.

Cos

> (2) I noticed we were missing some header files from recent patches.
> This will result in a -1 downstream during an IPMC release, so we
> should fix it.
>=20
> - Patrick
>=20
> On Mon, Dec 9, 2013 at 11:22 AM, Patrick Wendell <pwendell@gmail.com> wro=
te:
> > I'll go ahead and kick this off with a +1.
> >
> > On Sun, Dec 8, 2013 at 10:30 PM, Patrick Wendell <pwendell@gmail.com> w=
rote:
> >> Please vote on releasing the following candidate as Apache Spark
> >> (incubating) version 0.8.1.
> >>
> >> The tag to be voted on is v0.8.1-incubating (commit c88a9916):
> >> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dta=
g;h=3Dba05afd29c81e152a84461f95b0e61a783897d7a
> >>
> >> The release files, including signatures, digests, etc can be found at:
> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/
> >>
> >> Release artifacts are signed with the following key:
> >> https://people.apache.org/keys/committer/pwendell.asc
> >>
> >> The staging repository for this release can be found at:
> >> https://repository.apache.org/content/repositories/orgapachespark-025/
> >>
> >> The documentation corresponding to this release can be found at:
> >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/
> >>
> >> For information about the contents of this release see:
> >> <attached> draft of release notes
> >> <attached> draft of release credits
> >> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dbl=
ob;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch=
-0.8
> >>
> >> Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> >>
> >> The vote is open until Thursday, December 12th at 06:30 UTC and
> >> passes if a majority of at least 3 +1 PPMC votes are cast.
> >>
> >> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >> [ ] -1 Do not release this package because ...
> >>
> >> To learn more about Apache Spark, please see
> >> http://spark.incubator.apache.org/

--qcHopEYAB45HaUaB
Content-Type: application/pgp-signature; name="signature.asc"
Content-Description: Digital signature

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iF4EAREIAAYFAlKn4L0ACgkQenyFlstYjhLAEgD+OcKRczo3kXx2UCC1bB1NYUSO
7SDA72T4OApObmjYe1gA/RkDfUbMWZpH9xpnslQ7oxnVIfoeqJ5tj750svbTcRsX
=40VZ
-----END PGP SIGNATURE-----

--qcHopEYAB45HaUaB--

From dev-return-874-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 03:55:36 2013
Return-Path: <dev-return-874-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F311E1074E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 03:55:35 +0000 (UTC)
Received: (qmail 33735 invoked by uid 500); 11 Dec 2013 03:55:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33671 invoked by uid 500); 11 Dec 2013 03:55:23 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 33663 invoked by uid 99); 11 Dec 2013 03:55:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 03:55:21 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of raymond.liu@intel.com designates 192.55.52.93 as permitted sender)
Received: from [192.55.52.93] (HELO mga11.intel.com) (192.55.52.93)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 03:55:17 +0000
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
  by fmsmga102.fm.intel.com with ESMTP; 10 Dec 2013 19:54:56 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.93,869,1378882800"; 
   d="scan'208";a="448068237"
Received: from fmsmsx107.amr.corp.intel.com ([10.19.9.54])
  by fmsmga002.fm.intel.com with ESMTP; 10 Dec 2013 19:54:56 -0800
Received: from shsmsx152.ccr.corp.intel.com (10.239.6.52) by
 FMSMSX107.amr.corp.intel.com (10.19.9.54) with Microsoft SMTP Server (TLS) id
 14.3.123.3; Tue, 10 Dec 2013 19:54:55 -0800
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.57]) by
 SHSMSX152.ccr.corp.intel.com ([10.239.6.52]) with mapi id 14.03.0123.003;
 Wed, 11 Dec 2013 11:54:54 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
Thread-Topic: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
Thread-Index: AQHO9iQkjpNlpH8WJE2/4wPpMHCIcJpOXMSQ
Date: Wed, 11 Dec 2013 03:54:53 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A010F1ABD@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
 <CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
 <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
 <20131211034917.GB8865@tpx>
In-Reply-To: <20131211034917.GB8865@tpx>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

SGkgS29uc3RhbnRpbg0KDQogVGhpcyBvbmUgaGF2ZSBiZWVuIGZpeGVkLiBodHRwczovL2dpdGh1
Yi5jb20vYXBhY2hlL2luY3ViYXRvci1zcGFyay9wdWxsLzI0OA0KIFRob3VnaCBJIGFtIG5vdCBz
dXJlIHdoZXRoZXIgdGhlcmUgYXJlIGJldHRlciBzb2x1dGlvbi4NCg0KQmVzdCBSZWdhcmRzLA0K
UmF5bW9uZCBMaXUNCg0KDQotLS0tLU9yaWdpbmFsIE1lc3NhZ2UtLS0tLQ0KRnJvbTogS29uc3Rh
bnRpbiBCb3VkbmlrIFttYWlsdG86Y29zQGFwYWNoZS5vcmddIA0KU2VudDogV2VkbmVzZGF5LCBE
ZWNlbWJlciAxMSwgMjAxMyAxMTo0OSBBTQ0KVG86IGRldkBzcGFyay5pbmN1YmF0b3IuYXBhY2hl
Lm9yZw0KU3ViamVjdDogUmU6IFtWT1RFXSBSZWxlYXNlIEFwYWNoZSBTcGFyayAwLjguMS1pbmN1
YmF0aW5nIChyYzMpDQoNCk9uIE1vbiwgRGVjIDA5LCAyMDEzIGF0IDEwOjQwUE0sIFBhdHJpY2sg
V2VuZGVsbCB3cm90ZToNCj4gSSdtIGdvaW5nIHRvIC0xIHRoaXMgbm93IGJlY2F1c2Ugd2UgaGFk
IHR3byBpc3N1ZXMgcmVwb3J0ZWQgdG9kYXkuDQo+IFRoZXkgd2VyZSByZXBvcnRlZCBvZmYgdGhl
IGxpc3Qgc28gSSdtIHN1bW1hcml6aW5nIGhlcmU6DQo+IA0KPiAoMSkgUmF5bW9uZCBMaXUgZm91
bmQgYW4gaXNzdWUgd2l0aCB0aGUgTWF2ZW4gYnVpbGQgZm9yIFlBUk4gMi4yKy4NCj4gUHJldmlv
dXNseSB3ZSBoYWQgb25seSB0ZXN0ZWQgdGhlIHNidCBidWlsZCBzaW5jZSB0aGlzIGlzIHdoYXQg
d2UgDQo+IHJlZmVyIHRvIGluIHRoZSBkb2NzLCBidXQgd2UnZCBsaWtlIHRvIHN1cHBvcnQgdGhp
cyBmb3IgTWF2ZW4gYXMgd2VsbC4NCg0KSXMgdGhlcmUgYSB0aWNrZXQgb24gdGhlIE1hdmVuIGlz
c3VlPyBBcyBJIHdhcyB0aGUgb25lIHdobyBwdXQgaXQgaW4gcGxhY2UgSSBzdXBwb3NlIGl0IHdv
dWxkIGJlIGVhc2llciBmb3IgbWUgdG8gZml4IGl0IHF1aWNra3kuDQoNCkNvcw0KDQo+ICgyKSBJ
IG5vdGljZWQgd2Ugd2VyZSBtaXNzaW5nIHNvbWUgaGVhZGVyIGZpbGVzIGZyb20gcmVjZW50IHBh
dGNoZXMuDQo+IFRoaXMgd2lsbCByZXN1bHQgaW4gYSAtMSBkb3duc3RyZWFtIGR1cmluZyBhbiBJ
UE1DIHJlbGVhc2UsIHNvIHdlIA0KPiBzaG91bGQgZml4IGl0Lg0KPiANCj4gLSBQYXRyaWNrDQo+
IA0KPiBPbiBNb24sIERlYyA5LCAyMDEzIGF0IDExOjIyIEFNLCBQYXRyaWNrIFdlbmRlbGwgPHB3
ZW5kZWxsQGdtYWlsLmNvbT4gd3JvdGU6DQo+ID4gSSdsbCBnbyBhaGVhZCBhbmQga2ljayB0aGlz
IG9mZiB3aXRoIGEgKzEuDQo+ID4NCj4gPiBPbiBTdW4sIERlYyA4LCAyMDEzIGF0IDEwOjMwIFBN
LCBQYXRyaWNrIFdlbmRlbGwgPHB3ZW5kZWxsQGdtYWlsLmNvbT4gd3JvdGU6DQo+ID4+IFBsZWFz
ZSB2b3RlIG9uIHJlbGVhc2luZyB0aGUgZm9sbG93aW5nIGNhbmRpZGF0ZSBhcyBBcGFjaGUgU3Bh
cmsNCj4gPj4gKGluY3ViYXRpbmcpIHZlcnNpb24gMC44LjEuDQo+ID4+DQo+ID4+IFRoZSB0YWcg
dG8gYmUgdm90ZWQgb24gaXMgdjAuOC4xLWluY3ViYXRpbmcgKGNvbW1pdCBjODhhOTkxNik6DQo+
ID4+IGh0dHBzOi8vZ2l0LXdpcC11cy5hcGFjaGUub3JnL3JlcG9zL2FzZj9wPWluY3ViYXRvci1z
cGFyay5naXQ7YT10YWcNCj4gPj4gO2g9YmEwNWFmZDI5YzgxZTE1MmE4NDQ2MWY5NWIwZTYxYTc4
Mzg5N2Q3YQ0KPiA+Pg0KPiA+PiBUaGUgcmVsZWFzZSBmaWxlcywgaW5jbHVkaW5nIHNpZ25hdHVy
ZXMsIGRpZ2VzdHMsIGV0YyBjYW4gYmUgZm91bmQgYXQ6DQo+ID4+IGh0dHA6Ly9wZW9wbGUuYXBh
Y2hlLm9yZy9+cHdlbmRlbGwvc3BhcmstMC44LjEtaW5jdWJhdGluZy1yYzMvDQo+ID4+DQo+ID4+
IFJlbGVhc2UgYXJ0aWZhY3RzIGFyZSBzaWduZWQgd2l0aCB0aGUgZm9sbG93aW5nIGtleToNCj4g
Pj4gaHR0cHM6Ly9wZW9wbGUuYXBhY2hlLm9yZy9rZXlzL2NvbW1pdHRlci9wd2VuZGVsbC5hc2MN
Cj4gPj4NCj4gPj4gVGhlIHN0YWdpbmcgcmVwb3NpdG9yeSBmb3IgdGhpcyByZWxlYXNlIGNhbiBi
ZSBmb3VuZCBhdDoNCj4gPj4gaHR0cHM6Ly9yZXBvc2l0b3J5LmFwYWNoZS5vcmcvY29udGVudC9y
ZXBvc2l0b3JpZXMvb3JnYXBhY2hlc3BhcmstMA0KPiA+PiAyNS8NCj4gPj4NCj4gPj4gVGhlIGRv
Y3VtZW50YXRpb24gY29ycmVzcG9uZGluZyB0byB0aGlzIHJlbGVhc2UgY2FuIGJlIGZvdW5kIGF0
Og0KPiA+PiBodHRwOi8vcGVvcGxlLmFwYWNoZS5vcmcvfnB3ZW5kZWxsL3NwYXJrLTAuOC4xLWlu
Y3ViYXRpbmctcmMzLWRvY3MvDQo+ID4+DQo+ID4+IEZvciBpbmZvcm1hdGlvbiBhYm91dCB0aGUg
Y29udGVudHMgb2YgdGhpcyByZWxlYXNlIHNlZToNCj4gPj4gPGF0dGFjaGVkPiBkcmFmdCBvZiBy
ZWxlYXNlIG5vdGVzDQo+ID4+IDxhdHRhY2hlZD4gZHJhZnQgb2YgcmVsZWFzZSBjcmVkaXRzDQo+
ID4+IGh0dHBzOi8vZ2l0LXdpcC11cy5hcGFjaGUub3JnL3JlcG9zL2FzZj9wPWluY3ViYXRvci1z
cGFyay5naXQ7YT1ibG8NCj4gPj4gYjtmPUNIQU5HRVMudHh0O2g9Y2UwYWVhYjUyNDUwNWI2M2M3
OTk5ZTAzNzExNTdhYzJkZWY2ZmUxYztoYj1icmFuYw0KPiA+PiBoLTAuOA0KPiA+Pg0KPiA+PiBQ
bGVhc2Ugdm90ZSBvbiByZWxlYXNpbmcgdGhpcyBwYWNrYWdlIGFzIEFwYWNoZSBTcGFyayAwLjgu
MS1pbmN1YmF0aW5nIQ0KPiA+Pg0KPiA+PiBUaGUgdm90ZSBpcyBvcGVuIHVudGlsIFRodXJzZGF5
LCBEZWNlbWJlciAxMnRoIGF0IDA2OjMwIFVUQyBhbmQgDQo+ID4+IHBhc3NlcyBpZiBhIG1ham9y
aXR5IG9mIGF0IGxlYXN0IDMgKzEgUFBNQyB2b3RlcyBhcmUgY2FzdC4NCj4gPj4NCj4gPj4gWyBd
ICsxIFJlbGVhc2UgdGhpcyBwYWNrYWdlIGFzIEFwYWNoZSBTcGFyayAwLjguMS1pbmN1YmF0aW5n
IFsgXSAtMSANCj4gPj4gRG8gbm90IHJlbGVhc2UgdGhpcyBwYWNrYWdlIGJlY2F1c2UgLi4uDQo+
ID4+DQo+ID4+IFRvIGxlYXJuIG1vcmUgYWJvdXQgQXBhY2hlIFNwYXJrLCBwbGVhc2Ugc2VlIA0K
PiA+PiBodHRwOi8vc3BhcmsuaW5jdWJhdG9yLmFwYWNoZS5vcmcvDQo=

From dev-return-875-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 04:18:49 2013
Return-Path: <dev-return-875-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D20FE107C8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 04:18:49 +0000 (UTC)
Received: (qmail 57714 invoked by uid 500); 11 Dec 2013 04:18:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57676 invoked by uid 500); 11 Dec 2013 04:18:43 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 57664 invoked by uid 99); 11 Dec 2013 04:18:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 04:18:42 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [76.96.30.56] (HELO qmta06.emeryville.ca.mail.comcast.net) (76.96.30.56)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 04:18:34 +0000
Received: from omta21.emeryville.ca.mail.comcast.net ([76.96.30.88])
	by qmta06.emeryville.ca.mail.comcast.net with comcast
	id 036q1n0051u4NiLA64JCb9; Wed, 11 Dec 2013 04:18:12 +0000
Received: from boudnik.org ([24.4.185.157])
	by omta21.emeryville.ca.mail.comcast.net with comcast
	id 04JB1n00N3QAh8g8h4JCtE; Wed, 11 Dec 2013 04:18:12 +0000
Received: from localhost (tpx.boudnik.org [192.168.102.148])
	by boudnik.org (8.14.3/8.14.3/Debian-5+lenny1) with ESMTP id rBB4IBAw006905
	for <dev@spark.incubator.apache.org>; Tue, 10 Dec 2013 20:18:11 -0800
Date: Tue, 10 Dec 2013 20:18:10 -0800
From: Konstantin Boudnik <cos@apache.org>
To: dev@spark.incubator.apache.org
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
Message-ID: <20131211041810.GE8865@tpx>
References: <CABPQxsskqHbU4_zxoCvXJ34Rtmh2Zw9Z0U-MCh56vo6oM6MLPg@mail.gmail.com>
 <CABPQxss=wp9ref2oOQ6PfSqGVLiN_ZNYQJ5wWr=DvetqF02FbQ@mail.gmail.com>
 <CABPQxsuXrUyF0nkDAc0_MYtv59qNA-4tDGAGmjYfqFTpTMdEfQ@mail.gmail.com>
 <20131211034917.GB8865@tpx>
 <391D65D0EBFC9B4B95E117F72A360F1A010F1ABD@SHSMSX101.ccr.corp.intel.com>
MIME-Version: 1.0
Content-Type: multipart/signed; micalg=pgp-sha256;
	protocol="application/pgp-signature"; boundary="xJK8B5Wah2CMJs8h"
Content-Disposition: inline
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F1ABD@SHSMSX101.ccr.corp.intel.com>
X-Organization: It's something of 'Cos
X-PGP-Key: http://www.boudnik.org/~cos/pubkey.asc
User-Agent: Mutt/1.5.21 (2010-09-15)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=comcast.net;
	s=q20121106; t=1386735492;
	bh=tqxI+SAdxSYDD0G2X8GNzpjB3HVUwIeWNzd3P7xsGcg=;
	h=Received:Received:Received:Date:From:To:Subject:Message-ID:
	 MIME-Version:Content-Type;
	b=K258dvxKov+IEojZcw3ZJqnR8S4bbqqpaoIK7aY9QOm5yAyuclhrWSZVJKSNCiUl+
	 URZfjt0jKoizzrt1tTq+uWDUyIzr7ieQ0IDdM7403mJubp7Q7SUaN+1KcwirdMaSWX
	 WXrsCONSum1NSxcLKJ5QfIob2YrYf+4Fq7aFKoUkAnvWPxr542xZS5POGfjGlW+H9S
	 21RkSA0cUUxR5XkV8lr//5hBRD1enjAGPC8MnjMME3tJjnBt4N5Vs8lTkpoEtbe6W+
	 88WIynFbLfEAwQHr64K3Mx9yxAxNZhYNdz8barq6c/9uyUQp0sC1uX+xR+cFJLN/EZ
	 7fxnobika75Lg==
X-Virus-Checked: Checked by ClamAV on apache.org

--xJK8B5Wah2CMJs8h
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
Content-Transfer-Encoding: quoted-printable

I think it's all good - thanks! Sorry for being later to the party.

Cos

On Wed, Dec 11, 2013 at 03:54AM, Liu, Raymond wrote:
> Hi Konstantin
>=20
>  This one have been fixed. https://github.com/apache/incubator-spark/pull=
/248
>  Though I am not sure whether there are better solution.
>=20
> Best Regards,
> Raymond Liu
>=20
>=20
> -----Original Message-----
> From: Konstantin Boudnik [mailto:cos@apache.org]=20
> Sent: Wednesday, December 11, 2013 11:49 AM
> To: dev@spark.incubator.apache.org
> Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc3)
>=20
> On Mon, Dec 09, 2013 at 10:40PM, Patrick Wendell wrote:
> > I'm going to -1 this now because we had two issues reported today.
> > They were reported off the list so I'm summarizing here:
> >=20
> > (1) Raymond Liu found an issue with the Maven build for YARN 2.2+.
> > Previously we had only tested the sbt build since this is what we=20
> > refer to in the docs, but we'd like to support this for Maven as well.
>=20
> Is there a ticket on the Maven issue? As I was the one who put it in plac=
e I suppose it would be easier for me to fix it quickky.
>=20
> Cos
>=20
> > (2) I noticed we were missing some header files from recent patches.
> > This will result in a -1 downstream during an IPMC release, so we=20
> > should fix it.
> >=20
> > - Patrick
> >=20
> > On Mon, Dec 9, 2013 at 11:22 AM, Patrick Wendell <pwendell@gmail.com> w=
rote:
> > > I'll go ahead and kick this off with a +1.
> > >
> > > On Sun, Dec 8, 2013 at 10:30 PM, Patrick Wendell <pwendell@gmail.com>=
 wrote:
> > >> Please vote on releasing the following candidate as Apache Spark
> > >> (incubating) version 0.8.1.
> > >>
> > >> The tag to be voted on is v0.8.1-incubating (commit c88a9916):
> > >> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3D=
tag
> > >> ;h=3Dba05afd29c81e152a84461f95b0e61a783897d7a
> > >>
> > >> The release files, including signatures, digests, etc can be found a=
t:
> > >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3/
> > >>
> > >> Release artifacts are signed with the following key:
> > >> https://people.apache.org/keys/committer/pwendell.asc
> > >>
> > >> The staging repository for this release can be found at:
> > >> https://repository.apache.org/content/repositories/orgapachespark-0
> > >> 25/
> > >>
> > >> The documentation corresponding to this release can be found at:
> > >> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc3-docs/
> > >>
> > >> For information about the contents of this release see:
> > >> <attached> draft of release notes
> > >> <attached> draft of release credits
> > >> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3D=
blo
> > >> b;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3D=
branc
> > >> h-0.8
> > >>
> > >> Please vote on releasing this package as Apache Spark 0.8.1-incubati=
ng!
> > >>
> > >> The vote is open until Thursday, December 12th at 06:30 UTC and=20
> > >> passes if a majority of at least 3 +1 PPMC votes are cast.
> > >>
> > >> [ ] +1 Release this package as Apache Spark 0.8.1-incubating [ ] -1=
=20
> > >> Do not release this package because ...
> > >>
> > >> To learn more about Apache Spark, please see=20
> > >> http://spark.incubator.apache.org/

--xJK8B5Wah2CMJs8h
Content-Type: application/pgp-signature; name="signature.asc"
Content-Description: Digital signature

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iF4EAREIAAYFAlKn54IACgkQenyFlstYjhIsvgEAh6WO5norOXOCR/dwKsYZlXqB
MMsc8HIK5s7y8w+ZGEoA/Aq1iwlzLGG94XyW19KuY8lIZGdCSSDVOhfmD2PKrp5q
=4CrE
-----END PGP SIGNATURE-----

--xJK8B5Wah2CMJs8h--

From dev-return-876-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 04:24:47 2013
Return-Path: <dev-return-876-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE0AB107EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 04:24:47 +0000 (UTC)
Received: (qmail 63761 invoked by uid 500); 11 Dec 2013 04:24:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63668 invoked by uid 500); 11 Dec 2013 04:24:46 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 63660 invoked by uid 99); 11 Dec 2013 04:24:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 04:24:44 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 04:24:37 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so8696621pdj.17
        for <dev@spark.incubator.apache.org>; Tue, 10 Dec 2013 20:24:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=MC+nwaH8QrFG6G6EDdk4IumYXrv6LPKzAb39Se4Pb8A=;
        b=ftlYUntSqIfJ0QIs5b/BhDsjqWQYYDGgfgB0BkNhrN2M/Xyzc0SWlspE96Pze9e+j0
         8LUShNouaM3v6J7COaJ5shxN5Ce35iR7VZFr5DZsdIpqH9FuCEeNFPhBYderBJy7TX1X
         14yOtIemtfEW5smRwuK/NsmH6ZpZwqko106lu/P0HzOxgc/XWJH9NX9iJJUEzXt0wjuZ
         d2jCeQMrAYHNZV0q82uZDuTW0xFMDbMrCNy/iSzgFtNY7LcBEg8jqE6gtF12MhAjEun5
         ZYqXwF+PrRSM2/QFlCN58ZMJh0RBDyT3ee+EG+R12OJLh/Bc2ic+Jh/pSVEl1TDR6ZZe
         kiHA==
X-Received: by 10.66.156.106 with SMTP id wd10mr31985964pab.125.1386735856084;
        Tue, 10 Dec 2013 20:24:16 -0800 (PST)
Received: from [192.168.1.105] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id jk16sm29332193pbb.34.2013.12.10.20.24.13
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 10 Dec 2013 20:24:14 -0800 (PST)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
Date: Tue, 10 Dec 2013 20:24:12 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

+1

Built and tested it on Mac OS X.

Matei


On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Please vote on releasing the following candidate as Apache Spark
> (incubating) version 0.8.1.
>=20
> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> =
https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubator=
-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>=20
> The release files, including signatures, digests, etc can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>=20
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>=20
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-040/
>=20
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>=20
> For information about the contents of this release see:
> =
https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;f=
=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
>=20
> Please vote on releasing this package as Apache Spark =
0.8.1-incubating!
>=20
> The vote is open until Saturday, December 14th at 01:00 UTC and
> passes if a majority of at least 3 +1 PPMC votes are cast.
>=20
> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> [ ] -1 Do not release this package because ...
>=20
> To learn more about Apache Spark, please see
> http://spark.incubator.apache.org/


From dev-return-877-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 07:59:28 2013
Return-Path: <dev-return-877-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A1D110D3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 07:59:28 +0000 (UTC)
Received: (qmail 26770 invoked by uid 500); 11 Dec 2013 07:59:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26684 invoked by uid 500); 11 Dec 2013 07:59:22 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 26676 invoked by uid 99); 11 Dec 2013 07:59:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 07:59:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of scrapcodes@gmail.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 07:59:16 +0000
Received: by mail-wi0-f179.google.com with SMTP id z2so444967wiv.6
        for <dev@spark.incubator.apache.org>; Tue, 10 Dec 2013 23:58:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=+WBoWfO0r+56K2x4AdKyYef+BTlfgrHE9oPZIIHPto8=;
        b=xQTazJVvWDtdEEIxJaz21Mn5YHC3SKAH6dRTCMf3gR3tTRNhJ6Fcu4xbqMw7iP+RvK
         EjaaZOPelSzNsgg2TIsfK9WTGaW6H7gvhTmdiahq418bbnd7qIkXLz/EUARGFf7ATv02
         sGxtQ75DbVNYw9nhyIcfSkuAigHThnk9nhdWsOE8c0sG2k1uzzjxpJkBguUDLAhPln2o
         l8O9Z3XCJ82hJGYPzLw8AwK3xY6Orr2bhwkR60z4b1nRVxpZ8DnUM1EEChiSZIP8gJYT
         u98PvzzgWLP8NLvQpX/mQ1cF0OhqtqaegcAmyK+UHWK9axoGPn94lHKIq8IujwkoOlM8
         f6sA==
X-Received: by 10.180.10.74 with SMTP id g10mr1577732wib.11.1386748735239;
 Tue, 10 Dec 2013 23:58:55 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.64.132 with HTTP; Tue, 10 Dec 2013 23:58:35 -0800 (PST)
In-Reply-To: <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
 <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Wed, 11 Dec 2013 13:28:35 +0530
Message-ID: <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c25a92c1becd04ed3d995b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25a92c1becd04ed3d995b
Content-Type: text/plain; charset=ISO-8859-1

Hi Patrick and Matei,

Was trying out this and followed the quick start guide which says do
sbt/sbt assembly, like few others I was also stuck for few minutes on
linux. On the other hand if I use sbt/sbt assembly/assembly it is much
faster.

Should we change the documentation to reflect this. It will not be great
for first time users to get stuck there.


On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <matei.zaharia@gmail.com>wrote:

> +1
>
> Built and tested it on Mac OS X.
>
> Matei
>
>
> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
> > Please vote on releasing the following candidate as Apache Spark
> > (incubating) version 0.8.1.
> >
> > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> >
> > The release files, including signatures, digests, etc can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-040/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> >
> > For information about the contents of this release see:
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
> >
> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> >
> > The vote is open until Saturday, December 14th at 01:00 UTC and
> > passes if a majority of at least 3 +1 PPMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.incubator.apache.org/
>
>


-- 
s

--001a11c25a92c1becd04ed3d995b--

From dev-return-878-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 08:02:55 2013
Return-Path: <dev-return-878-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1312710D5D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 08:02:55 +0000 (UTC)
Received: (qmail 33942 invoked by uid 500); 11 Dec 2013 08:02:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33791 invoked by uid 500); 11 Dec 2013 08:02:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 33779 invoked by uid 99); 11 Dec 2013 08:02:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:02:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of scrapcodes@gmail.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:02:46 +0000
Received: by mail-wg0-f52.google.com with SMTP id x13so6094429wgg.7
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 00:02:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=+YstOxcPRvPWWlhlL4pqmlU1CVNSlUJZJ+wAMEtE6M4=;
        b=xbzbaOnSt9ZDmaOt5RvtI5CbcAlyyMASePBB7K/qptNRNgEqPcLxdUz3Ogf/lduppC
         wMppHUVOVl8K92KS/rn1MBCRC7tneJ0L8Igxzaqh/ctdwdaiCC0l//0/mimW6tXM/Sb+
         DangcC7G5gOOPNlVJ6yDQzoRx+1qWHy95tecy48uaZri1gH3YWIbEaOEEFdQGi68wG2E
         bK9VbbqMdIu3gu/RsVMRrb2Xn908QUwtGTVG43pRIijhmOHEYNi0XNzkq8f8slVSRY4h
         8szp2xJ3Az6mY/+975JOggJyQQZk7+uUGc5Y2Bsz+/KKsTBQvxHXhVzOJlOdzjr1Hq0n
         OgBg==
X-Received: by 10.180.10.74 with SMTP id g10mr1590485wib.11.1386748945188;
 Wed, 11 Dec 2013 00:02:25 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.64.132 with HTTP; Wed, 11 Dec 2013 00:02:05 -0800 (PST)
In-Reply-To: <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
 <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Wed, 11 Dec 2013 13:32:05 +0530
Message-ID: <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c25a924550c504ed3da68e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25a924550c504ed3da68e
Content-Type: text/plain; charset=ISO-8859-1

forgot to mention, after running sbt/sbt assembly/assembly running sbt/sbt
examples/assembly takes just 37s. Not to mention my hardware is not really
great.


On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <scrapcodes@gmail.com>wrote:

> Hi Patrick and Matei,
>
> Was trying out this and followed the quick start guide which says do
> sbt/sbt assembly, like few others I was also stuck for few minutes on
> linux. On the other hand if I use sbt/sbt assembly/assembly it is much
> faster.
>
> Should we change the documentation to reflect this. It will not be great
> for first time users to get stuck there.
>
>
> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <matei.zaharia@gmail.com>wrote:
>
>> +1
>>
>> Built and tested it on Mac OS X.
>>
>> Matei
>>
>>
>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> > Please vote on releasing the following candidate as Apache Spark
>> > (incubating) version 0.8.1.
>> >
>> > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>> >
>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>> >
>> > The release files, including signatures, digests, etc can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>> >
>> > Release artifacts are signed with the following key:
>> > https://people.apache.org/keys/committer/pwendell.asc
>> >
>> > The staging repository for this release can be found at:
>> > https://repository.apache.org/content/repositories/orgapachespark-040/
>> >
>> > The documentation corresponding to this release can be found at:
>> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>> >
>> > For information about the contents of this release see:
>> >
>> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>> >
>> > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>> >
>> > The vote is open until Saturday, December 14th at 01:00 UTC and
>> > passes if a majority of at least 3 +1 PPMC votes are cast.
>> >
>> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> > [ ] -1 Do not release this package because ...
>> >
>> > To learn more about Apache Spark, please see
>> > http://spark.incubator.apache.org/
>>
>>
>
>
> --
> s
>



-- 
s

--001a11c25a924550c504ed3da68e--

From dev-return-879-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 08:41:36 2013
Return-Path: <dev-return-879-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8931F10E79
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 08:41:36 +0000 (UTC)
Received: (qmail 98349 invoked by uid 500); 11 Dec 2013 08:41:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98278 invoked by uid 500); 11 Dec 2013 08:41:30 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 98264 invoked by uid 99); 11 Dec 2013 08:41:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:41:27 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taka.epsilon@gmail.com designates 209.85.219.51 as permitted sender)
Received: from [209.85.219.51] (HELO mail-oa0-f51.google.com) (209.85.219.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:41:22 +0000
Received: by mail-oa0-f51.google.com with SMTP id i7so6896609oag.24
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 00:41:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=dYk1Wnm+pKe9jF2plea81sQCccJNrbJlDOQKIxTrzm4=;
        b=Ae6JfC7p5NGLdDsQTHxFBwUgkvj3qRjhfqB5YnTMquh00Hygh5/DQX05Xjt4XeGp8j
         cdkBtXe6fnPMlux2Ygeum73nUeawD+Zqm4M1I1oQpIaCslRpP74vsFewpvr7993khuqt
         /m6CbEtGAczaN4ahDxoxy4AQgTfZmxPK3AUVZb766/5MncXUR7xBpIpNT834fO6NVAAZ
         qVwmR2NZky3WGHHkE8AmxKfoGPoRW3+ufrETjKSJNI5xa3O81ewfJUVuIS7RC/4V1elO
         pLmNcsku86l8oeFJWTAQv4iWA7QjAqB/oXk+W5muLEHGfZvotR5LwNMND5egW26OTe4G
         eI/g==
MIME-Version: 1.0
X-Received: by 10.182.146.104 with SMTP id tb8mr195301obb.54.1386751261270;
 Wed, 11 Dec 2013 00:41:01 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Wed, 11 Dec 2013 00:41:01 -0800 (PST)
In-Reply-To: <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
Date: Wed, 11 Dec 2013 00:41:01 -0800
Message-ID: <CALkvKbmen-OGGi13_CnzczXK-3W7n3Rv+ExziFtu2TLP_zsRRg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d04451a3951e8f104ed3e30df
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04451a3951e8f104ed3e30df
Content-Type: text/plain; charset=ISO-8859-1

That's a good point. Although it's definitely not a blocker for this
release, it would be more user friendly to mention sbt/sbt
assembly/assembly as well as Maven build instructions in the README and
quick-start files (at least until the time-consuming sbt assembly process
on a regular hardware gets resolved).

I've been able to build RC4 (against Hadoop 2.2.0) with Maven on my slower
Mac and Ubuntu 12.0.4 LTS successfully. On my faster Mac, sbt/sbt assembly
has completed in 4min.

Thanks for fixing the Maven build for Hadoop 2.2.0!


On Tue, Dec 10, 2013 at 11:58 PM, Prashant Sharma <scrapcodes@gmail.com>wrote:

> Hi Patrick and Matei,
>
> Was trying out this and followed the quick start guide which says do
> sbt/sbt assembly, like few others I was also stuck for few minutes on
> linux. On the other hand if I use sbt/sbt assembly/assembly it is much
> faster.
>
> Should we change the documentation to reflect this. It will not be great
> for first time users to get stuck there.
>
>
> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <matei.zaharia@gmail.com
> >wrote:
>
> > +1
> >
> > Built and tested it on Mac OS X.
> >
> > Matei
> >
> >
> > On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> >
> > > Please vote on releasing the following candidate as Apache Spark
> > > (incubating) version 0.8.1.
> > >
> > > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> > >
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> > >
> > > The release files, including signatures, digests, etc can be found at:
> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > > https://repository.apache.org/content/repositories/orgapachespark-040/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> > >
> > > For information about the contents of this release see:
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
> > >
> > > Please vote on releasing this package as Apache Spark 0.8.1-incubating!
> > >
> > > The vote is open until Saturday, December 14th at 01:00 UTC and
> > > passes if a majority of at least 3 +1 PPMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.incubator.apache.org/
> >
> >
>
>
> --
> s
>

--f46d04451a3951e8f104ed3e30df--

From dev-return-880-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 08:45:03 2013
Return-Path: <dev-return-880-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6522F10E80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 08:45:03 +0000 (UTC)
Received: (qmail 1243 invoked by uid 500); 11 Dec 2013 08:45:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1193 invoked by uid 500); 11 Dec 2013 08:45:02 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 1179 invoked by uid 99); 11 Dec 2013 08:45:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:45:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.51] (HELO mail-bk0-f51.google.com) (209.85.214.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 08:44:54 +0000
Received: by mail-bk0-f51.google.com with SMTP id 6so179491bkj.24
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 00:44:33 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=O8nT/hLhz5RN9O7pw5WHx/YPKL5hRwD+nCWaCGLsCsY=;
        b=iu1/AZX9ISbdLPBKXMxH2pzjeMiPTmgcexbIIRG0+u3SUkSKndxSV9WxqjVtCy7RPs
         uZvTnz+XOMSUr1Uqid2tigoLIsuiTxAFCwOM3QDwzWNt9J9+Tfgmf4SX0CJEpKFI58OW
         D4c5+PfgXomzqtKkLXIbUN5HdJ2r+1kJW6tydbDhEQqYkg6o+aejmF3S6zcmlcb+PKg7
         kXGxTciuCVLqBmxSiXNEkr6u0Dg8fuIKgFYB1yumCMN4wOXfrbuqcOO+X6xLO9mvi77S
         OAmb42L3g07cqwxzVHgqgTFwi133TjmmqWD+G8NswfPvwIESyYjTYA3pGbozTNKWYvAP
         YLkQ==
X-Gm-Message-State: ALoCoQki94qIBTn59oRWdlRIWyAYuC8kkGiVs/dSFqtvYW3uM6gfe8QpRJ7GgzxebgYsFc+0UhLd
MIME-Version: 1.0
X-Received: by 10.204.248.72 with SMTP id mf8mr291638bkb.56.1386751472988;
 Wed, 11 Dec 2013 00:44:32 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Wed, 11 Dec 2013 00:44:32 -0800 (PST)
In-Reply-To: <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
Date: Wed, 11 Dec 2013 00:44:32 -0800
Message-ID: <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11335590f0d24f04ed3e3c1d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11335590f0d24f04ed3e3c1d
Content-Type: text/plain; charset=ISO-8859-1

Interesting, and confirmed: On my machine where `./sbt/sbt assembly` takes
a long, long, looooong time to complete (a MBP, in my case), building three
separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less time.



On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <scrapcodes@gmail.com>wrote:

> forgot to mention, after running sbt/sbt assembly/assembly running sbt/sbt
> examples/assembly takes just 37s. Not to mention my hardware is not really
> great.
>
>
> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <scrapcodes@gmail.com
> >wrote:
>
> > Hi Patrick and Matei,
> >
> > Was trying out this and followed the quick start guide which says do
> > sbt/sbt assembly, like few others I was also stuck for few minutes on
> > linux. On the other hand if I use sbt/sbt assembly/assembly it is much
> > faster.
> >
> > Should we change the documentation to reflect this. It will not be great
> > for first time users to get stuck there.
> >
> >
> > On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <matei.zaharia@gmail.com
> >wrote:
> >
> >> +1
> >>
> >> Built and tested it on Mac OS X.
> >>
> >> Matei
> >>
> >>
> >> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >>
> >> > Please vote on releasing the following candidate as Apache Spark
> >> > (incubating) version 0.8.1.
> >> >
> >> > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> >> >
> >>
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> >> >
> >> > The release files, including signatures, digests, etc can be found at:
> >> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> >> >
> >> > Release artifacts are signed with the following key:
> >> > https://people.apache.org/keys/committer/pwendell.asc
> >> >
> >> > The staging repository for this release can be found at:
> >> >
> https://repository.apache.org/content/repositories/orgapachespark-040/
> >> >
> >> > The documentation corresponding to this release can be found at:
> >> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> >> >
> >> > For information about the contents of this release see:
> >> >
> >>
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
> >> >
> >> > Please vote on releasing this package as Apache Spark
> 0.8.1-incubating!
> >> >
> >> > The vote is open until Saturday, December 14th at 01:00 UTC and
> >> > passes if a majority of at least 3 +1 PPMC votes are cast.
> >> >
> >> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >> > [ ] -1 Do not release this package because ...
> >> >
> >> > To learn more about Apache Spark, please see
> >> > http://spark.incubator.apache.org/
> >>
> >>
> >
> >
> > --
> > s
> >
>
>
>
> --
> s
>

--001a11335590f0d24f04ed3e3c1d--

From dev-return-881-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 09:04:58 2013
Return-Path: <dev-return-881-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8142D10F1B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 09:04:58 +0000 (UTC)
Received: (qmail 45044 invoked by uid 500); 11 Dec 2013 09:04:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44693 invoked by uid 500); 11 Dec 2013 09:04:56 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 44678 invoked by uid 99); 11 Dec 2013 09:04:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 09:04:56 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 09:04:50 +0000
Received: by mail-wi0-f182.google.com with SMTP id en1so512247wid.15
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 01:04:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=OtcnHMV9Z18C0kWmE3CkuRU2mtBiireBAz7JcyEV75I=;
        b=MHNnYYwuUI1viUyXxLgmd9Ns6Xe8t1neCNolwsnYaNscedQnf+PaLrfNnbRtlSubco
         L4Csg/tfULaetA2+Q1AvVOyUtzTY7h2YqttFOAYypb3FkWkD2/uGmzoLW4N3QA0nnTtI
         usobnuhi12+nH1CEOXQBLOIV4OLO62tDXVXGaYmp0ShSn2xeC5vxltxk2sqBoENXkQit
         J0TwL0wvhdWlQ9eY6l+hWOeMF5LjBJUUhPm7Ih/ZDFgyXWVdd0qZOn0LrZ3RL6eG+0sP
         Rad47ULh57EM2PijPhqUWFnouBT/7MijbdcsAACf+7/8S058kGq/ASP/JRUfIUQ4DhQB
         jBNg==
X-Received: by 10.180.75.115 with SMTP id b19mr23395863wiw.19.1386752669906;
 Wed, 11 Dec 2013 01:04:29 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.64.132 with HTTP; Wed, 11 Dec 2013 01:04:09 -0800 (PST)
In-Reply-To: <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
 <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
 <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com> <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Wed, 11 Dec 2013 14:34:09 +0530
Message-ID: <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d043be23c47fa0504ed3e8448
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043be23c47fa0504ed3e8448
Content-Type: text/plain; charset=ISO-8859-1

I hope this PR https://github.com/apache/incubator-spark/pull/252 can help.
Again this is not a blocker for the release from my side either.


On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> Interesting, and confirmed: On my machine where `./sbt/sbt assembly` takes
> a long, long, looooong time to complete (a MBP, in my case), building three
> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less time.
>
>
>
> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <scrapcodes@gmail.com
> >wrote:
>
> > forgot to mention, after running sbt/sbt assembly/assembly running
> sbt/sbt
> > examples/assembly takes just 37s. Not to mention my hardware is not
> really
> > great.
> >
> >
> > On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <scrapcodes@gmail.com
> > >wrote:
> >
> > > Hi Patrick and Matei,
> > >
> > > Was trying out this and followed the quick start guide which says do
> > > sbt/sbt assembly, like few others I was also stuck for few minutes on
> > > linux. On the other hand if I use sbt/sbt assembly/assembly it is much
> > > faster.
> > >
> > > Should we change the documentation to reflect this. It will not be
> great
> > > for first time users to get stuck there.
> > >
> > >
> > > On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> matei.zaharia@gmail.com
> > >wrote:
> > >
> > >> +1
> > >>
> > >> Built and tested it on Mac OS X.
> > >>
> > >> Matei
> > >>
> > >>
> > >> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > >>
> > >> > Please vote on releasing the following candidate as Apache Spark
> > >> > (incubating) version 0.8.1.
> > >> >
> > >> > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> > >> >
> > >>
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> > >> >
> > >> > The release files, including signatures, digests, etc can be found
> at:
> > >> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> > >> >
> > >> > Release artifacts are signed with the following key:
> > >> > https://people.apache.org/keys/committer/pwendell.asc
> > >> >
> > >> > The staging repository for this release can be found at:
> > >> >
> > https://repository.apache.org/content/repositories/orgapachespark-040/
> > >> >
> > >> > The documentation corresponding to this release can be found at:
> > >> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> > >> >
> > >> > For information about the contents of this release see:
> > >> >
> > >>
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
> > >> >
> > >> > Please vote on releasing this package as Apache Spark
> > 0.8.1-incubating!
> > >> >
> > >> > The vote is open until Saturday, December 14th at 01:00 UTC and
> > >> > passes if a majority of at least 3 +1 PPMC votes are cast.
> > >> >
> > >> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > >> > [ ] -1 Do not release this package because ...
> > >> >
> > >> > To learn more about Apache Spark, please see
> > >> > http://spark.incubator.apache.org/
> > >>
> > >>
> > >
> > >
> > > --
> > > s
> > >
> >
> >
> >
> > --
> > s
> >
>



-- 
s

--f46d043be23c47fa0504ed3e8448--

From dev-return-882-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 09:57:34 2013
Return-Path: <dev-return-882-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 20E7F10165
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 09:57:34 +0000 (UTC)
Received: (qmail 61153 invoked by uid 500); 11 Dec 2013 09:57:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60782 invoked by uid 500); 11 Dec 2013 09:57:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 59851 invoked by uid 99); 11 Dec 2013 09:57:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 09:57:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of olivier.grisel@gmail.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 09:57:21 +0000
Received: by mail-we0-f172.google.com with SMTP id w62so6276277wes.3
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 01:57:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=P5PfS3DSaef19SYXeYg7xpAgoXXj58RaqGI7J5JwY7s=;
        b=Z49TLmTKuFsgyvQaZi6jaYnhAo6HBBN+wUGg6GTlNDBT4mAr1H+kfiU+RJbj/oKr5d
         bkILgPllr/5doLzYbzYkKgKn12H040lCqtnCAky19vnFJjeqSkklTWBiUGLEPC7JM/R5
         KuttgGj7VisESzgPGfxbYmUEJ+PF+1DJjtO3uB4d8C5kuzjMhPwWAhzXkIlz5pe9SqQT
         jXTxdb8N/h8RyalCWTUHbQNC8xYHvL8Cr1hJ9csX+DKAAzeu1IKS7P9zm/9o0O5a8oWM
         s0DD8NvR2qqfDFV/S0KN0B3wRVLT0LgBloaIhV1lGYpFQMlHLwUg5ptEYeFDepiFic87
         /E6A==
X-Received: by 10.180.39.177 with SMTP id q17mr23643965wik.16.1386755820993;
 Wed, 11 Dec 2013 01:57:00 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Wed, 11 Dec 2013 01:56:40 -0800 (PST)
In-Reply-To: <CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com> <CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Wed, 11 Dec 2013 10:56:40 +0100
X-Google-Sender-Auth: KsNTPUFrddiDfMye_m0vkd7Mok4
Message-ID: <CAFvE7K7dw8vhYoedczk42-JDFuxM0BQvuokorbQOcW8M881Q3g@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Justin Kestelyn <jkestelyn@cloudera.com>
Cc: Horia Airoh <horia@alum.berkeley.edu>, dev <dev@spark.incubator.apache.org>, 
	Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

2013/12/10 Justin Kestelyn <jkestelyn@cloudera.com>:
> Location:
>
> Cloudera
> 433 California Street
> San Francisco, CA

Thanks I will add that on the wiki, shall we start at 9am? 9.30am?

-- 
Olivier

From dev-return-883-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 16:14:36 2013
Return-Path: <dev-return-883-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F363A10DEE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 16:14:35 +0000 (UTC)
Received: (qmail 50189 invoked by uid 500); 11 Dec 2013 16:14:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50141 invoked by uid 500); 11 Dec 2013 16:14:29 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50130 invoked by uid 99); 11 Dec 2013 16:14:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 16:14:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of horia.fsf@gmail.com designates 209.85.160.48 as permitted sender)
Received: from [209.85.160.48] (HELO mail-pb0-f48.google.com) (209.85.160.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 16:14:22 +0000
Received: by mail-pb0-f48.google.com with SMTP id md12so10257653pbc.35
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 08:14:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:reply-to:sender:in-reply-to:references:date:message-id
         :subject:from:to:cc:content-type;
        bh=BbaRW7FENqs4LQKObt4t3iOjEu/PIpY54OvyGx+k1zk=;
        b=oCLcQzEnAH7KJQuUkvhz8TD9Vz20Xs48+TCRqPdJC7AFD1n+JMrDvqtBJXUQO0Cypc
         G6vQQqBxtQW47uFu0JXz2hNqHLox2l32VfPFWuYdqeJjD0y80UkRl13JhnutpxcD/004
         HAVv+bZ6hLG8EYrBdVj9CQnOerBFB/D57gdfZSS//zE/MO1/Y51N0hA2dBZKB9AZCdXT
         GZllSXc46j8q5cj/h/asW9MgYrx74IP2kc2Vtomd0s7pTh+ara8OI2Lls0GaeeS0uNXi
         Y5iSfAXDu3NGag4DnvoPdzcVL1Dz5HocsNLZ5/H994XlP1Jg6SLubqz9o5iIXYwq+mph
         Wflw==
MIME-Version: 1.0
X-Received: by 10.68.217.194 with SMTP id pa2mr2634316pbc.1.1386778440963;
 Wed, 11 Dec 2013 08:14:00 -0800 (PST)
Reply-To: horia@alum.berkeley.edu
Sender: horia.fsf@gmail.com
Received: by 10.70.54.226 with HTTP; Wed, 11 Dec 2013 08:14:00 -0800 (PST)
In-Reply-To: <CAFvE7K7dw8vhYoedczk42-JDFuxM0BQvuokorbQOcW8M881Q3g@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
	<CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
	<CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
	<CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
	<CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
	<CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
	<CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
	<CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
	<CAFvE7K7dw8vhYoedczk42-JDFuxM0BQvuokorbQOcW8M881Q3g@mail.gmail.com>
Date: Wed, 11 Dec 2013 08:14:00 -0800
X-Google-Sender-Auth: e1WJ4MQSic7ovHPNU0YAgrSbLXU
Message-ID: <CAPfXE6NEqM8wURwO8N2b3-vBqAYj2uLhr9ZOv760iz4TRbYQTA@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
From: Horia <horia@alum.berkeley.edu>
To: Olivier Grisel <olivier.grisel@ensta.org>
Cc: Justin Kestelyn <jkestelyn@cloudera.com>, dev <dev@spark.incubator.apache.org>, 
	Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>
Content-Type: multipart/alternative; boundary=047d7b2edf335b1c7704ed44843f
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b2edf335b1c7704ed44843f
Content-Type: text/plain; charset=ISO-8859-1

If it's up for a vote, I'd say we start at 9:30 :)



On Wed, Dec 11, 2013 at 1:56 AM, Olivier Grisel <olivier.grisel@ensta.org>wrote:

> 2013/12/10 Justin Kestelyn <jkestelyn@cloudera.com>:
> > Location:
> >
> > Cloudera
> > 433 California Street
> > San Francisco, CA
>
> Thanks I will add that on the wiki, shall we start at 9am? 9.30am?
>
> --
> Olivier
>

--047d7b2edf335b1c7704ed44843f--

From dev-return-884-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 16:56:46 2013
Return-Path: <dev-return-884-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A06710F0E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 16:56:46 +0000 (UTC)
Received: (qmail 30131 invoked by uid 500); 11 Dec 2013 16:56:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29338 invoked by uid 500); 11 Dec 2013 16:56:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29326 invoked by uid 99); 11 Dec 2013 16:56:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 16:56:38 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.219.51 as permitted sender)
Received: from [209.85.219.51] (HELO mail-oa0-f51.google.com) (209.85.219.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 16:56:32 +0000
Received: by mail-oa0-f51.google.com with SMTP id i7so7550986oag.24
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 08:56:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=+w+Phxiez+HO/1onyMIRGoEIflj8Zt83RmCKFcxDn+U=;
        b=zvYbWvco6Z2uGF8aFZg8El8+mm1UrQKXSF/nedUJrXo381O/R8U6bLxdpqjrQ7iUTf
         3MVR9nS+PwU0VuvQrFAatvVU4Kh/iOPJA2GRMxPXWJ6oFVH36BZkIUa37CLxfEXyC0qH
         5htBYTNSWQR+lTwyE19+ZeArXcPFL2Ni/cpLXCJFQ+mi/KkjYKJL1gdQ9ldwI2UZlz8D
         MRIdyOGCTi5zyOmlRo73hEW3iXhr1WnxVKQY7X5nqE51wHpihJkeAWjJZS+cUL1Wp0Ol
         uvMWa3+RX/36OCF5XpcN4KAdQ9x3pP51wE/8i+j9lWl8Os+OFUQ+kAxEuTyWFWPB4SXJ
         v3cg==
MIME-Version: 1.0
X-Received: by 10.60.40.5 with SMTP id t5mr1895897oek.26.1386780971785; Wed,
 11 Dec 2013 08:56:11 -0800 (PST)
Received: by 10.182.95.103 with HTTP; Wed, 11 Dec 2013 08:56:11 -0800 (PST)
In-Reply-To: <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
Date: Wed, 11 Dec 2013 18:56:11 +0200
Message-ID: <CALD+6GO_MTQ0vCgyPA_k3fYb2a4TapUoO9sXYHO=40YWm-Kg6g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013cc2b234667804ed451bcf
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013cc2b234667804ed451bcf
Content-Type: text/plain; charset=ISO-8859-1

   - Successfully built via sbt/sbt assembly/assembly on Mac OS X, as well
   as on a dev Ubuntu EC2 box
   - Successfully tested via sbt/sbt test locally
   - Successfully built and tested using mvn package locally
   - I've tested my own Spark jobs (built against 0.8.0-incubating) on this
   RC and all works fine, as well as tested with my job server (also built
   against 0.8.0-incubating)
   - Ran a few spark examples and the shell and PySpark shell
   - For my part, tested the MLlib implicit code I added, and checked docs


I'm +1


On Wed, Dec 11, 2013 at 11:04 AM, Prashant Sharma <scrapcodes@gmail.com>wrote:

> I hope this PR https://github.com/apache/incubator-spark/pull/252 can
> help.
> Again this is not a blocker for the release from my side either.
>
>
> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
>
> > Interesting, and confirmed: On my machine where `./sbt/sbt assembly`
> takes
> > a long, long, looooong time to complete (a MBP, in my case), building
> three
> > separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> > examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less
> time.
> >
> >
> >
> > On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <scrapcodes@gmail.com
> > >wrote:
> >
> > > forgot to mention, after running sbt/sbt assembly/assembly running
> > sbt/sbt
> > > examples/assembly takes just 37s. Not to mention my hardware is not
> > really
> > > great.
> > >
> > >
> > > On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <scrapcodes@gmail.com
> > > >wrote:
> > >
> > > > Hi Patrick and Matei,
> > > >
> > > > Was trying out this and followed the quick start guide which says do
> > > > sbt/sbt assembly, like few others I was also stuck for few minutes on
> > > > linux. On the other hand if I use sbt/sbt assembly/assembly it is
> much
> > > > faster.
> > > >
> > > > Should we change the documentation to reflect this. It will not be
> > great
> > > > for first time users to get stuck there.
> > > >
> > > >
> > > > On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> > matei.zaharia@gmail.com
> > > >wrote:
> > > >
> > > >> +1
> > > >>
> > > >> Built and tested it on Mac OS X.
> > > >>
> > > >> Matei
> > > >>
> > > >>
> > > >> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
> > > wrote:
> > > >>
> > > >> > Please vote on releasing the following candidate as Apache Spark
> > > >> > (incubating) version 0.8.1.
> > > >> >
> > > >> > The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> > > >> >
> > > >>
> > >
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> > > >> >
> > > >> > The release files, including signatures, digests, etc can be found
> > at:
> > > >> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> > > >> >
> > > >> > Release artifacts are signed with the following key:
> > > >> > https://people.apache.org/keys/committer/pwendell.asc
> > > >> >
> > > >> > The staging repository for this release can be found at:
> > > >> >
> > > https://repository.apache.org/content/repositories/orgapachespark-040/
> > > >> >
> > > >> > The documentation corresponding to this release can be found at:
> > > >> >
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> > > >> >
> > > >> > For information about the contents of this release see:
> > > >> >
> > > >>
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHANGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
> > > >> >
> > > >> > Please vote on releasing this package as Apache Spark
> > > 0.8.1-incubating!
> > > >> >
> > > >> > The vote is open until Saturday, December 14th at 01:00 UTC and
> > > >> > passes if a majority of at least 3 +1 PPMC votes are cast.
> > > >> >
> > > >> > [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > > >> > [ ] -1 Do not release this package because ...
> > > >> >
> > > >> > To learn more about Apache Spark, please see
> > > >> > http://spark.incubator.apache.org/
> > > >>
> > > >>
> > > >
> > > >
> > > > --
> > > > s
> > > >
> > >
> > >
> > >
> > > --
> > > s
> > >
> >
>
>
>
> --
> s
>

--089e013cc2b234667804ed451bcf--

From dev-return-885-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 18:39:34 2013
Return-Path: <dev-return-885-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5320910306
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 18:39:34 +0000 (UTC)
Received: (qmail 38697 invoked by uid 500); 11 Dec 2013 18:39:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38641 invoked by uid 500); 11 Dec 2013 18:39:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 38633 invoked by uid 99); 11 Dec 2013 18:39:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 18:39:33 +0000
X-ASF-Spam-Status: No, hits=1.0 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 18:39:29 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so9981174pdj.17
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 10:39:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=7PCV9kYw3zvAcNFGbx5h6i4omVmBK+hJu39mOg1AlUA=;
        b=xEZqfqfgC7FfDA7boiRuHiViUYCEn0DKKtTpXXfVNqsZwjxfKHNp3KYeZPbpGiDBmp
         gTWKwBt8tu9eHpAa+ZgozXfJaYsO238JXtQxdm9GtKwMieo81En8Cb5elCRoZ2p9sPOH
         65aERrXmcvO9Gj2KhC/gaqdwI7ZyqgpJwpthbu+kdopJsMbMuFAwdqPQi8F/+oP66Vuj
         T7UW8GINC6VHFcx6y2VTw0SHirjUrJLl8xYRkubB0WS1jwGCx6NtciTFYJMUKPJweuVd
         u5iGQjx4i//ObLvLWfvJPD2G6HN1zxkHRennCgtXQRcEpk6MJhgPXfAmN40XkQMGWlsm
         IpBg==
X-Received: by 10.68.172.196 with SMTP id be4mr3855407pbc.12.1386787148674;
        Wed, 11 Dec 2013 10:39:08 -0800 (PST)
Received: from [192.168.1.105] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id hw10sm34353173pbc.24.2013.12.11.10.39.06
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 11 Dec 2013 10:39:07 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
Date: Wed, 11 Dec 2013 10:39:04 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com> <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com> <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com> <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com> <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Woah, weird, but definitely good to know.

If you=92re doing Spark development, there=92s also a more convenient =
option added by Shivaram in the master branch. You can do sbt =
assemble-deps to package *just* the dependencies of each project in a =
special assembly JAR, and then use sbt compile to update the code. This =
will use the classes directly out of the target/scala-2.9.3/classes =
directories. You have to redo assemble-deps only if your external =
dependencies change.

Matei

On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com> =
wrote:

> I hope this PR https://github.com/apache/incubator-spark/pull/252 can =
help.
> Again this is not a blocker for the release from my side either.
>=20
>=20
> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra =
<mark@clearstorydata.com>wrote:
>=20
>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly` =
takes
>> a long, long, looooong time to complete (a MBP, in my case), building =
three
>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less =
time.
>>=20
>>=20
>>=20
>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma =
<scrapcodes@gmail.com
>>> wrote:
>>=20
>>> forgot to mention, after running sbt/sbt assembly/assembly running
>> sbt/sbt
>>> examples/assembly takes just 37s. Not to mention my hardware is not
>> really
>>> great.
>>>=20
>>>=20
>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma =
<scrapcodes@gmail.com
>>>> wrote:
>>>=20
>>>> Hi Patrick and Matei,
>>>>=20
>>>> Was trying out this and followed the quick start guide which says =
do
>>>> sbt/sbt assembly, like few others I was also stuck for few minutes =
on
>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is =
much
>>>> faster.
>>>>=20
>>>> Should we change the documentation to reflect this. It will not be
>> great
>>>> for first time users to get stuck there.
>>>>=20
>>>>=20
>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>> matei.zaharia@gmail.com
>>>> wrote:
>>>>=20
>>>>> +1
>>>>>=20
>>>>> Built and tested it on Mac OS X.
>>>>>=20
>>>>> Matei
>>>>>=20
>>>>>=20
>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>>>=20
>>>>>> Please vote on releasing the following candidate as Apache Spark
>>>>>> (incubating) version 0.8.1.
>>>>>>=20
>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>>>>>>=20
>>>>>=20
>>>=20
>> =
https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubator=
-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>>>>>=20
>>>>>> The release files, including signatures, digests, etc can be =
found
>> at:
>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>>>>>>=20
>>>>>> Release artifacts are signed with the following key:
>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>>>>=20
>>>>>> The staging repository for this release can be found at:
>>>>>>=20
>>> =
https://repository.apache.org/content/repositories/orgapachespark-040/
>>>>>>=20
>>>>>> The documentation corresponding to this release can be found at:
>>>>>> =
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>>>>>>=20
>>>>>> For information about the contents of this release see:
>>>>>>=20
>>>>>=20
>>>=20
>> =
https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;f=
=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
>>>>>>=20
>>>>>> Please vote on releasing this package as Apache Spark
>>> 0.8.1-incubating!
>>>>>>=20
>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>>>>>=20
>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>>>>> [ ] -1 Do not release this package because ...
>>>>>>=20
>>>>>> To learn more about Apache Spark, please see
>>>>>> http://spark.incubator.apache.org/
>>>>>=20
>>>>>=20
>>>>=20
>>>>=20
>>>> --
>>>> s
>>>>=20
>>>=20
>>>=20
>>>=20
>>> --
>>> s
>>>=20
>>=20
>=20
>=20
>=20
> --=20
> s


From dev-return-886-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 19:49:58 2013
Return-Path: <dev-return-886-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D7930105BC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 19:49:58 +0000 (UTC)
Received: (qmail 40438 invoked by uid 500); 11 Dec 2013 19:49:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40402 invoked by uid 500); 11 Dec 2013 19:49:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 40394 invoked by uid 99); 11 Dec 2013 19:49:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 19:49:58 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.49 as permitted sender)
Received: from [209.85.219.49] (HELO mail-oa0-f49.google.com) (209.85.219.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 19:49:54 +0000
Received: by mail-oa0-f49.google.com with SMTP id i4so7794275oah.22
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 11:49:34 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=2H4YcCjtEo2AeNZU0gtWeID517iJ9rMy40+7pMXLBHM=;
        b=qzDDN+2MjxA/V882nucci4ArZgfiMHpohPR0ahd8XAmmUR81EHP/09bUnfg6Vq7nas
         gQM25GwKjuHGPTX/XIr7JI7HYs/bk7wTE/nfrpEkLmejn3vLeHiZmcXZH+0RLBPDbebN
         I9/N1Km988yrnNdt4GnldAH0dgyI7EuBfS3eMMjyTKKM3cHbyPzMN97w+Zrv2omxEg6u
         VGvS+r4JfsNcTAoY/A4STV+gBnsdaruDcJBvbR+JrLjPmSfMYuhW5WPU/hxhILNFcT4b
         yhb1uGLituB9JXMc3v7xOK0iUMNyFlJtJ+NETd3+KsKdpsTOtCgQm0s+UH0/GVoD7cF7
         Ymng==
MIME-Version: 1.0
X-Received: by 10.60.59.5 with SMTP id v5mr2620641oeq.30.1386791374187; Wed,
 11 Dec 2013 11:49:34 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Wed, 11 Dec 2013 11:49:34 -0800 (PST)
In-Reply-To: <1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
Date: Wed, 11 Dec 2013 11:49:34 -0800
Message-ID: <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I'll +1 myself also.

For anyone who has the slow build problem: does this issue happen when
building v0.8.0-incubating also? Trying to figure out whether it's
related to something we added in 0.8.1 or if it's a long standing
issue.

- Patrick

On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.com> w=
rote:
> Woah, weird, but definitely good to know.
>
> If you=92re doing Spark development, there=92s also a more convenient opt=
ion added by Shivaram in the master branch. You can do sbt assemble-deps to=
 package *just* the dependencies of each project in a special assembly JAR,=
 and then use sbt compile to update the code. This will use the classes dir=
ectly out of the target/scala-2.9.3/classes directories. You have to redo a=
ssemble-deps only if your external dependencies change.
>
> Matei
>
> On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com> wrote=
:
>
>> I hope this PR https://github.com/apache/incubator-spark/pull/252 can he=
lp.
>> Again this is not a blocker for the release from my side either.
>>
>>
>> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com>w=
rote:
>>
>>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly` ta=
kes
>>> a long, long, looooong time to complete (a MBP, in my case), building t=
hree
>>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less t=
ime.
>>>
>>>
>>>
>>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <scrapcodes@gmail.com
>>>> wrote:
>>>
>>>> forgot to mention, after running sbt/sbt assembly/assembly running
>>> sbt/sbt
>>>> examples/assembly takes just 37s. Not to mention my hardware is not
>>> really
>>>> great.
>>>>
>>>>
>>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <scrapcodes@gmail.com
>>>>> wrote:
>>>>
>>>>> Hi Patrick and Matei,
>>>>>
>>>>> Was trying out this and followed the quick start guide which says do
>>>>> sbt/sbt assembly, like few others I was also stuck for few minutes on
>>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is muc=
h
>>>>> faster.
>>>>>
>>>>> Should we change the documentation to reflect this. It will not be
>>> great
>>>>> for first time users to get stuck there.
>>>>>
>>>>>
>>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>> matei.zaharia@gmail.com
>>>>> wrote:
>>>>>
>>>>>> +1
>>>>>>
>>>>>> Built and tested it on Mac OS X.
>>>>>>
>>>>>> Matei
>>>>>>
>>>>>>
>>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>>>>
>>>>>>> Please vote on releasing the following candidate as Apache Spark
>>>>>>> (incubating) version 0.8.1.
>>>>>>>
>>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>>>>>>>
>>>>>>
>>>>
>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincuba=
tor-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>>>>>>
>>>>>>> The release files, including signatures, digests, etc can be found
>>> at:
>>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>>>>>>>
>>>>>>> Release artifacts are signed with the following key:
>>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>>>>>
>>>>>>> The staging repository for this release can be found at:
>>>>>>>
>>>> https://repository.apache.org/content/repositories/orgapachespark-040/
>>>>>>>
>>>>>>> The documentation corresponding to this release can be found at:
>>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>>>>>>>
>>>>>>> For information about the contents of this release see:
>>>>>>>
>>>>>>
>>>>
>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblo=
b;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-=
0.8
>>>>>>>
>>>>>>> Please vote on releasing this package as Apache Spark
>>>> 0.8.1-incubating!
>>>>>>>
>>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
>>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>>>>>>
>>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>>>>>> [ ] -1 Do not release this package because ...
>>>>>>>
>>>>>>> To learn more about Apache Spark, please see
>>>>>>> http://spark.incubator.apache.org/
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> s
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> s
>>>>
>>>
>>
>>
>>
>> --
>> s
>

From dev-return-887-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 20:24:00 2013
Return-Path: <dev-return-887-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BE1EF106C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 20:24:00 +0000 (UTC)
Received: (qmail 14865 invoked by uid 500); 11 Dec 2013 20:24:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14768 invoked by uid 500); 11 Dec 2013 20:24:00 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 14760 invoked by uid 99); 11 Dec 2013 20:24:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 20:24:00 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of taka.epsilon@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 20:23:56 +0000
Received: by mail-ob0-f177.google.com with SMTP id vb8so2017744obc.22
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 12:23:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=qCtHzeG5UFq6RlLNvpZW69hzY/JsP4pL230n56A5/dk=;
        b=n25LrCzOexY3R6e5xu3ecSk+9ACf6WkgPMtX3vGIme5g7Jedki927vWDLFson3vN88
         D7xZa1zQ+7ThUcPRXTHAjZ0ohBvl0DkOD534iTF6bRGRj5Awl3w4ZaITRHQBWn2nPapF
         omH5wVd+RWb9ofBgKlfFNeQzXfb2+VHebp3fQF8Z7v8UPu4Ob66xiiSSgPAW2GSZ6Jjs
         3IgYyaulU+65BSu9a3iseNmuUVYVF3dkOLh0iEVFcKGNG1iPbK6H92fdZtAMq3dsWsyq
         sEaupGCOr43oCM6VDwGl8p0677sV8wArhfunCU1bBmZvqiWLOZNfPTkAUtozpWXLJIl4
         SeKQ==
MIME-Version: 1.0
X-Received: by 10.182.19.132 with SMTP id f4mr2709851obe.14.1386793415834;
 Wed, 11 Dec 2013 12:23:35 -0800 (PST)
Received: by 10.182.126.228 with HTTP; Wed, 11 Dec 2013 12:23:35 -0800 (PST)
In-Reply-To: <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
Date: Wed, 11 Dec 2013 12:23:35 -0800
Message-ID: <CALkvKbnC+7=wZTEZM-pvmK4N+qi_=i=WsQz21_uULk5cZqhwSA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Taka Shinagawa <taka.epsilon@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c2aa6aed825804ed48009e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2aa6aed825804ed48009e
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

On my Core 2 Duo (slower) Mac, I'm having the same problem with building
v0.8.0-incubating as well.

I'm suspecting the slow build problem is caused by sbt-assembly as reported
here.
https://github.com/sbt/sbt-assembly/issues/68

I tried to upgrade sbt-assembly to version 0.10.1 (and sbt to 0.13.0). But
because of the "sbt-assembly 0.10.1 =3D=3D> sbt 0.13 =3D=3D> sbt-dependency=
-graph
0.7.4 =3D=3D> Scala 2.10" dependency, I wasn't able to use sbt-assembly 0.1=
0.1
for this release.

According to this thread ( https://github.com/sbt/sbt-assembly/issues/96 ),
with sbt-assembly 0.9.2, setting "assemblyCacheOutput in assembly :=3D
false" might
fix. I haven't verified, though.



On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com>wrote=
:

> I'll +1 myself also.
>
> For anyone who has the slow build problem: does this issue happen when
> building v0.8.0-incubating also? Trying to figure out whether it's
> related to something we added in 0.8.1 or if it's a long standing
> issue.
>
> - Patrick
>
> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Woah, weird, but definitely good to know.
> >
> > If you=92re doing Spark development, there=92s also a more convenient o=
ption
> added by Shivaram in the master branch. You can do sbt assemble-deps to
> package *just* the dependencies of each project in a special assembly JAR=
,
> and then use sbt compile to update the code. This will use the classes
> directly out of the target/scala-2.9.3/classes directories. You have to
> redo assemble-deps only if your external dependencies change.
> >
> > Matei
> >
> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
> wrote:
> >
> >> I hope this PR https://github.com/apache/incubator-spark/pull/252 can
> help.
> >> Again this is not a blocker for the release from my side either.
> >>
> >>
> >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
> >>
> >>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly`
> takes
> >>> a long, long, looooong time to complete (a MBP, in my case), building
> three
> >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less
> time.
> >>>
> >>>
> >>>
> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
> scrapcodes@gmail.com
> >>>> wrote:
> >>>
> >>>> forgot to mention, after running sbt/sbt assembly/assembly running
> >>> sbt/sbt
> >>>> examples/assembly takes just 37s. Not to mention my hardware is not
> >>> really
> >>>> great.
> >>>>
> >>>>
> >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
> scrapcodes@gmail.com
> >>>>> wrote:
> >>>>
> >>>>> Hi Patrick and Matei,
> >>>>>
> >>>>> Was trying out this and followed the quick start guide which says d=
o
> >>>>> sbt/sbt assembly, like few others I was also stuck for few minutes =
on
> >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is
> much
> >>>>> faster.
> >>>>>
> >>>>> Should we change the documentation to reflect this. It will not be
> >>> great
> >>>>> for first time users to get stuck there.
> >>>>>
> >>>>>
> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> >>> matei.zaharia@gmail.com
> >>>>> wrote:
> >>>>>
> >>>>>> +1
> >>>>>>
> >>>>>> Built and tested it on Mac OS X.
> >>>>>>
> >>>>>> Matei
> >>>>>>
> >>>>>>
> >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>> Please vote on releasing the following candidate as Apache Spark
> >>>>>>> (incubating) version 0.8.1.
> >>>>>>>
> >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> >>>>>>>
> >>>>>>
> >>>>
> >>>
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> >>>>>>>
> >>>>>>> The release files, including signatures, digests, etc can be foun=
d
> >>> at:
> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> >>>>>>>
> >>>>>>> Release artifacts are signed with the following key:
> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
> >>>>>>>
> >>>>>>> The staging repository for this release can be found at:
> >>>>>>>
> >>>>
> https://repository.apache.org/content/repositories/orgapachespark-040/
> >>>>>>>
> >>>>>>> The documentation corresponding to this release can be found at:
> >>>>>>>
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> >>>>>>>
> >>>>>>> For information about the contents of this release see:
> >>>>>>>
> >>>>>>
> >>>>
> >>>
> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;=
f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
> >>>>>>>
> >>>>>>> Please vote on releasing this package as Apache Spark
> >>>> 0.8.1-incubating!
> >>>>>>>
> >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
> >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
> >>>>>>>
> >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >>>>>>> [ ] -1 Do not release this package because ...
> >>>>>>>
> >>>>>>> To learn more about Apache Spark, please see
> >>>>>>> http://spark.incubator.apache.org/
> >>>>>>
> >>>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> s
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> s
> >>>>
> >>>
> >>
> >>
> >>
> >> --
> >> s
> >
>

--001a11c2aa6aed825804ed48009e--

From dev-return-888-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 20:49:35 2013
Return-Path: <dev-return-888-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EBF91077A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 20:49:35 +0000 (UTC)
Received: (qmail 66484 invoked by uid 500); 11 Dec 2013 20:49:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66453 invoked by uid 500); 11 Dec 2013 20:49:35 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 66445 invoked by uid 99); 11 Dec 2013 20:49:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 20:49:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.139.212.127] (HELO nm22-vm1.bullet.mail.bf1.yahoo.com) (98.139.212.127)
    by apache.org (qpsmtpd/0.29) with SMTP; Wed, 11 Dec 2013 20:49:30 +0000
Received: from [66.196.81.171] by nm22.bullet.mail.bf1.yahoo.com with NNFMP; 11 Dec 2013 20:49:09 -0000
Received: from [98.139.212.228] by tm17.bullet.mail.bf1.yahoo.com with NNFMP; 11 Dec 2013 20:49:09 -0000
Received: from [127.0.0.1] by omp1037.mail.bf1.yahoo.com with NNFMP; 11 Dec 2013 20:49:09 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 71406.92733.bm@omp1037.mail.bf1.yahoo.com
Received: (qmail 75771 invoked by uid 60001); 11 Dec 2013 20:49:09 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1386794948; bh=sH2S4UeFeaomUcnAIAwArDHHMJQPi8BRAZ2zID4/MVQ=; h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=6cEDBr6RFW4EHZqCB9gOFSQC3l4Hrz8SiDUKtLeu80AWXfSVJaA0CWS/2GbDihQlM8JpX+7zQjJ6SbmM7y6Tp0AgqraWiBJ4W2rtONcdYyx7Bu3EjiG4U8/Dt5iI7/LJmZJDMtqo36hM24K0wBGT2rcTN1EFlavoghOXJ8op9mU=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=MwKG7QDTmINHY9OiZEx0y9lm7XpA71i1VLlEp6WHO0SEgJGxu+zRjUUvnGOEblYrAhQ4aOdjhVZWu+w7TqicDTZU7jYFGtMrKK/o9UQ/4ftNvt+OA5ytz9uq9vVWFNZi8/7+2pI9N1YEu6EbXpuyAolSoNCwCb3XdPLs0O5BhTo=;
X-YMail-OSG: s72PQ84VM1nAXiyfWSUCwqJ7ff8UGTHJPSKzuYHAArmDrYS
 IJgJSswcsE9aDZxvznLl.See2p2NFUgWNW_Ebrs48DwxiloeisFfeeSMTUQp
 IhSRpsjK48M4XHpp5ZOdaStiwIeri_ZGRRfPYH9WHWBgk9f5qC.iH3ob7qMM
 ZDbhemUHFKZj9zk02PpfbF2Ie6dCSERBIFXwsFpL7WRGAMGbQUm.fRPU3VCI
 _tLfFllUxTmuDajbTTtXAVZZ6xqzL1SC0PF_DhXKOAgWbJckL74ux2FsCGBv
 0lrPRDwjRk076S8Ig3p7ewnvFmkLdNu0SWbVI8ckZu7UTr7ERP0FEoJCgrdV
 OgH7YUnme48D0AGIWV3qYGJnA1GFQuhJm5z7EhzTn2B75NHSYQKbTYVKmYxN
 z6wPHHsqJ2nFv8qKIMeGHGNHB3TcCZFfpZNJkVy4RKJKlfOr3D9s3d7a884i
 xcLh.T3y2ZdMJozMNutOZTMPcySEbzBfB4E5WX3L9k304yh6XZ1P7uQbYeS.
 rsd7I_vc7GsFmz5_bzEPkZIJLUZ5gDO_CVC8MLxMWEuz5O4r_pfSflpJx8iY
 Bzvbh1wrkMq.elxSyVTHEjscHzlWt0COjpbq7RFyo3mfXoH4KmZXvnYfXXmB
 yRlmct9xDRV3iL1nM8qFwqa.cMl8XgZ8iZzLicgUS6u1WJPVhnp4hW5Wrh6z
 ay0i.m3skY0Cxg0ui6cbXX37QktFs2bpeEXI0Nq4_j6oDWE3nj6sLt7pcHxk
 -
Received: from [204.11.79.50] by web140103.mail.bf1.yahoo.com via HTTP; Wed, 11 Dec 2013 12:49:08 PST
X-Rocket-MIMEInfo: 002.001,SGV5IGZvbGtzLAoKSSdtIHRyeWluZyB0byB2ZXJpZnkgdGhlIHNpZ25hdHVyZSBvbiB0aGUgcmM0IGJ1dCBhbSBnZXR0aW5nIGEgQkFEIHNpZ25hdHVyZSwgaXMgaXQgd29ya2luZyBmb3Igb3RoZXJzPyDCoFBlcmhhcHMgSSBtZXNzZWQgdXAgdGhlIGltcG9ydCBvZiB0aGUgYXNjIGZpbGUuCgokIGdwZyAtLXZlcmlmeSBzcGFyay0wLjguMS1pbmN1YmF0aW5nLnRnei5hc2Mgc3BhcmstMC44LjEtaW5jdWJhdGluZy50Z3oKZ3BnOiBTaWduYXR1cmUgbWFkZSBUdWUgMTAgRGVjIDIwMTMgMTA6NTM6MTUgUE0gVVQBMAEBAQE-
X-Mailer: YahooMailWebService/0.8.169.609
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com> <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com> 
Message-ID: <1386794948.64899.YahooMailNeo@web140103.mail.bf1.yahoo.com>
Date: Wed, 11 Dec 2013 12:49:08 -0800 (PST)
From: Tom Graves <tgraves_cs@yahoo.com>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
In-Reply-To: <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="-916770207-221633980-1386794948=:64899"
X-Virus-Checked: Checked by ClamAV on apache.org

---916770207-221633980-1386794948=:64899
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hey folks,=0A=0AI'm trying to verify the signature on the rc4 but am gettin=
g a BAD signature, is it working for others? =C2=A0Perhaps I messed up the =
import of the asc file.=0A=0A$ gpg --verify spark-0.8.1-incubating.tgz.asc =
spark-0.8.1-incubating.tgz=0Agpg: Signature made Tue 10 Dec 2013 10:53:15 P=
M UTC using RSA key ID 9E4FE3AF=0Agpg: BAD signature from "Patrick Wendell =
<pwendell@gmail.com>"=0A=0ATom=0A=0A=0A=0AOn Wednesday, December 11, 2013 1=
:50 PM, Patrick Wendell <pwendell@gmail.com> wrote:=0A =0AI'll +1 myself al=
so.=0A=0AFor anyone who has the slow build problem: does this issue happen =
when=0Abuilding v0.8.0-incubating also? Trying to figure out whether it's=
=0Arelated to something we added in 0.8.1=0A or if it's a long standing=0Ai=
ssue.=0A=0A- Patrick=0A=0A=0AOn Wed, Dec 11, 2013 at 10:39 AM, Matei Zahari=
a <matei.zaharia@gmail.com> wrote:=0A> Woah, weird, but definitely good to =
know.=0A>=0A> If you=E2=80=99re doing Spark development, there=E2=80=99s al=
so a more convenient option added by Shivaram in the master branch. You can=
 do sbt assemble-deps to package *just* the dependencies of each project in=
 a special assembly JAR, and then use sbt compile to update the code. This =
will use the classes directly out of the target/scala-2.9.3/classes directo=
ries. You have to redo assemble-deps only if your external dependencies cha=
nge.=0A>=0A> Matei=0A>=0A> On Dec 11, 2013, at 1:04 AM, Prashant Sharma <sc=
rapcodes@gmail.com> wrote:=0A>=0A>> I hope this PR https://github.com/apach=
e/incubator-spark/pull/252 can help.=0A>> Again this is not a blocker for t=
he release from my side either.=0A>>=0A>>=0A>> On Wed, Dec 11, 2013 at 2:14=
 PM, Mark Hamstra <mark@clearstorydata.com>wrote:=0A>>=0A>>> Interesting, a=
nd confirmed: On my machine where `./sbt/sbt assembly` takes=0A>>> a long, =
long, looooong time to complete (a MBP, in=0A my case), building three=0A>>=
> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt=0A>>> exam=
ples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less time.=0A>=
>>=0A>>>=0A>>>=0A>>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <scr=
apcodes@gmail.com=0A>>>> wrote:=0A>>>=0A>>>> forgot to mention, after runni=
ng sbt/sbt assembly/assembly running=0A>>> sbt/sbt=0A>>>> examples/assembly=
 takes just 37s. Not to mention my hardware is not=0A>>> really=0A>>>> grea=
t.=0A>>>>=0A>>>>=0A>>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <s=
crapcodes@gmail.com=0A>>>>> wrote:=0A>>>>=0A>>>>> Hi Patrick and Matei,=0A>=
>>>>=0A>>>>> Was trying out this and followed the quick start guide which s=
ays do=0A>>>>> sbt/sbt assembly, like few others I was also stuck for few m=
inutes on=0A>>>>> linux. On the other hand if I use sbt/sbt assembly/assemb=
ly it is much=0A>>>>> faster.=0A>>>>>=0A>>>>> Should we change the document=
ation to reflect this. It will not be=0A>>> great=0A>>>>> for first time=0A=
 users to get stuck there.=0A>>>>>=0A>>>>>=0A>>>>> On Wed, Dec 11, 2013 at =
9:54 AM, Matei Zaharia <=0A>>> matei.zaharia@gmail.com=0A>>>>> wrote:=0A>>>=
>>=0A>>>>>> +1=0A>>>>>>=0A>>>>>> Built and tested it on Mac OS X.=0A>>>>>>=
=0A>>>>>> Matei=0A>>>>>>=0A>>>>>>=0A>>>>>> On Dec 10, 2013, at 4:49 PM, Pat=
rick Wendell <pwendell@gmail.com>=0A>>>> wrote:=0A>>>>>>=0A>>>>>>> Please v=
ote on releasing the following candidate as Apache Spark=0A>>>>>>> (incubat=
ing) version 0.8.1.=0A>>>>>>>=0A>>>>>>> The tag to be voted on is v0.8.1-in=
cubating (commit b87d31d):=0A>>>>>>>=0A>>>>>>=0A>>>>=0A>>> https://git-wip-=
us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubator-spark.git;a=3Dco=
mmit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e=0A>>>>>>>=0A>>>>>>> The=
=0A release files, including signatures, digests, etc can be found=0A>>> at=
:=0A>>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/=
=0A>>>>>>>=0A>>>>>>> Release artifacts are signed with the following key:=
=0A>>>>>>> https://people.apache.org/keys/committer/pwendell.asc=0A>>>>>>>=
=0A>>>>>>> The staging repository for this release can be found at:=0A>>>>>=
>>=0A>>>> https://repository.apache.org/content/repositories/orgapachespark=
-040/=0A>>>>>>>=0A>>>>>>> The documentation corresponding to this release c=
an be found at:=0A>>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-in=
cubating-rc4-docs/=0A>>>>>>>=0A>>>>>>> For information about the contents o=
f this release see:=0A>>>>>>>=0A>>>>>>=0A>>>>=0A>>> https://git-wip-us.apac=
he.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;f=3DCHANGES.txt;h=3Dce0ae=
ab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.8=0A>>>>>>>=0A>>>>>>> Ple=
ase vote on releasing this package as Apache Spark=0A>>>> 0.8.1-incubating!=
=0A>>>>>>>=0A>>>>>>> The vote is open until Saturday, December 14th at 01:0=
0 UTC and=0A>>>>>>> passes if a majority of at least 3 +1 PPMC votes are ca=
st.=0A>>>>>>>=0A>>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-i=
ncubating=0A>>>>>>> [ ] -1 Do not release this package because ...=0A>>>>>>=
>=0A>>>>>>> To learn more about=0A Apache Spark, please see=0A>>>>>>> http:=
//spark.incubator.apache.org/=0A>>>>>>=0A>>>>>>=0A>>>>>=0A>>>>>=0A>>>>> --=
=0A>>>>> s=0A>>>>>=0A>>>>=0A>>>>=0A>>>>=0A>>>> --=0A>>>> s=0A>>>>=0A>>>=0A>=
>=0A>>=0A>>=0A>> --=0A>> s=0A>
---916770207-221633980-1386794948=:64899--

From dev-return-889-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 21:11:04 2013
Return-Path: <dev-return-889-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 08441107FC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 21:11:04 +0000 (UTC)
Received: (qmail 6268 invoked by uid 500); 11 Dec 2013 21:11:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6140 invoked by uid 500); 11 Dec 2013 21:11:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 6132 invoked by uid 99); 11 Dec 2013 21:11:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 21:11:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.52] (HELO mail-bk0-f52.google.com) (209.85.214.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 21:10:57 +0000
Received: by mail-bk0-f52.google.com with SMTP id u14so538670bkz.25
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 13:10:34 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=LKzZwNx1Wkvdixz9FiKBGd5X3bOgwKMGI8jaNybWuuw=;
        b=NEGzD/mVdytmOxE3S/8TDyIKUd+nYuZTW9KtotFIJjTMCRAD1oySzHoWPWAGs9NuwL
         Fh6y66+Xnbtis1hysizvb0ay8hn2wo/Alz/a1ccqb6ob083BQxVd33z46Lx4h6keNE4D
         K8pa8Kkstn7ZokT8Bq0AUc/zHa0/OOZ6ssjbMP9fjhz4Ls+7aMPwXQRUZPZCMTtMaGMa
         Pf6J21ytT88Bww5eE4GgrZkEuWsNYX3Hbb0YPtpRRlXsFOZKV4Y+YOdwYi0WXEE4oLIj
         y5Z3x4vBe7rOVEysl7t25UI3AOP8nT01Jnf+PWb7QNVOqYU700Q5NweErabEvYtRqZyu
         2vrw==
X-Gm-Message-State: ALoCoQnDZu2EilWW7jy9/4/Kh8963fPsznIt6EBoswwKOeIn0ZkYro56rNfRZMRykwhOdP70Ct5O
MIME-Version: 1.0
X-Received: by 10.204.66.194 with SMTP id o2mr620916bki.98.1386796234389; Wed,
 11 Dec 2013 13:10:34 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Wed, 11 Dec 2013 13:10:34 -0800 (PST)
In-Reply-To: <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
Date: Wed, 11 Dec 2013 13:10:34 -0800
Message-ID: <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1132eda2ed9daf04ed48a8c5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1132eda2ed9daf04ed48a8c5
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

I don't know how to make sense of the numbers, but here's what I've got
from a very small sample size.

For both v0.8.0-incubating and v0.8.1-incubating, building separate
assemblies is faster than `./sbt/sbt assembly` and the times for building
separate assemblies for 0.8.0 and 0.8.1 are about the same.

For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long as the
sum of the separate assemblies.
For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as the
sum of the separate assemblies.

Weird.


On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com>wrote=
:

> I'll +1 myself also.
>
> For anyone who has the slow build problem: does this issue happen when
> building v0.8.0-incubating also? Trying to figure out whether it's
> related to something we added in 0.8.1 or if it's a long standing
> issue.
>
> - Patrick
>
> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Woah, weird, but definitely good to know.
> >
> > If you=92re doing Spark development, there=92s also a more convenient o=
ption
> added by Shivaram in the master branch. You can do sbt assemble-deps to
> package *just* the dependencies of each project in a special assembly JAR=
,
> and then use sbt compile to update the code. This will use the classes
> directly out of the target/scala-2.9.3/classes directories. You have to
> redo assemble-deps only if your external dependencies change.
> >
> > Matei
> >
> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
> wrote:
> >
> >> I hope this PR https://github.com/apache/incubator-spark/pull/252 can
> help.
> >> Again this is not a blocker for the release from my side either.
> >>
> >>
> >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
> >>
> >>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly`
> takes
> >>> a long, long, looooong time to complete (a MBP, in my case), building
> three
> >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much less
> time.
> >>>
> >>>
> >>>
> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
> scrapcodes@gmail.com
> >>>> wrote:
> >>>
> >>>> forgot to mention, after running sbt/sbt assembly/assembly running
> >>> sbt/sbt
> >>>> examples/assembly takes just 37s. Not to mention my hardware is not
> >>> really
> >>>> great.
> >>>>
> >>>>
> >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
> scrapcodes@gmail.com
> >>>>> wrote:
> >>>>
> >>>>> Hi Patrick and Matei,
> >>>>>
> >>>>> Was trying out this and followed the quick start guide which says d=
o
> >>>>> sbt/sbt assembly, like few others I was also stuck for few minutes =
on
> >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is
> much
> >>>>> faster.
> >>>>>
> >>>>> Should we change the documentation to reflect this. It will not be
> >>> great
> >>>>> for first time users to get stuck there.
> >>>>>
> >>>>>
> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> >>> matei.zaharia@gmail.com
> >>>>> wrote:
> >>>>>
> >>>>>> +1
> >>>>>>
> >>>>>> Built and tested it on Mac OS X.
> >>>>>>
> >>>>>> Matei
> >>>>>>
> >>>>>>
> >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>> Please vote on releasing the following candidate as Apache Spark
> >>>>>>> (incubating) version 0.8.1.
> >>>>>>>
> >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> >>>>>>>
> >>>>>>
> >>>>
> >>>
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> >>>>>>>
> >>>>>>> The release files, including signatures, digests, etc can be foun=
d
> >>> at:
> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> >>>>>>>
> >>>>>>> Release artifacts are signed with the following key:
> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
> >>>>>>>
> >>>>>>> The staging repository for this release can be found at:
> >>>>>>>
> >>>>
> https://repository.apache.org/content/repositories/orgapachespark-040/
> >>>>>>>
> >>>>>>> The documentation corresponding to this release can be found at:
> >>>>>>>
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> >>>>>>>
> >>>>>>> For information about the contents of this release see:
> >>>>>>>
> >>>>>>
> >>>>
> >>>
> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;=
f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
> >>>>>>>
> >>>>>>> Please vote on releasing this package as Apache Spark
> >>>> 0.8.1-incubating!
> >>>>>>>
> >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
> >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
> >>>>>>>
> >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >>>>>>> [ ] -1 Do not release this package because ...
> >>>>>>>
> >>>>>>> To learn more about Apache Spark, please see
> >>>>>>> http://spark.incubator.apache.org/
> >>>>>>
> >>>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> s
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> s
> >>>>
> >>>
> >>
> >>
> >>
> >> --
> >> s
> >
>

--001a1132eda2ed9daf04ed48a8c5--

From dev-return-890-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 21:52:53 2013
Return-Path: <dev-return-890-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D83A610992
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 21:52:53 +0000 (UTC)
Received: (qmail 93267 invoked by uid 500); 11 Dec 2013 21:52:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93206 invoked by uid 500); 11 Dec 2013 21:52:53 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 93198 invoked by uid 99); 11 Dec 2013 21:52:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 21:52:53 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jkestelyn@cloudera.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 21:52:49 +0000
Received: by mail-ob0-f179.google.com with SMTP id wm4so7662921obc.24
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 13:52:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=mO/6b7RyAtpS/vb6sLiwaRF8tVCW18TcWwYOWrdtKi4=;
        b=Isl7sHtxNDgyNB2F34SyznapD5JMISeGBOh02CEV93qXRpiFIyCKwMNVKsQ/3Y7uPH
         1opvjkSf7sI4FnL+drPrrm13Y22d6rFK361BvLgfSUn89DJaZpjwEUAD0b3aUW04hABH
         UPftwGYkjYlxKBlg5wKN1yn6bx2CHrpn+VDACRZmXAkURPF1iN6/v7ac+VBPjE2hmE9X
         +0NJzp6xtBSqyt+n8Jnd1jEDd75uEzNQFnLRtvw5oRprSbyRlORVqNDp/Q93RGWEzv+E
         W8nAiBQ2Kka2qfmLqtmqyqYwuvgMR5ehgLJuBO0vcLbckpoeDJdvnLeeIpN6M2pVYVkm
         KIWg==
X-Gm-Message-State: ALoCoQk+XvpAJR6KfyJjs6oqq7BCjG7SGoQR+5uMuriTCt273Cz8LTKG0cswfFGfVwWranz8y+ZL
X-Received: by 10.60.143.98 with SMTP id sd2mr2901867oeb.63.1386798749006;
 Wed, 11 Dec 2013 13:52:29 -0800 (PST)
MIME-Version: 1.0
Received: by 10.60.135.227 with HTTP; Wed, 11 Dec 2013 13:52:08 -0800 (PST)
In-Reply-To: <CAPfXE6NEqM8wURwO8N2b3-vBqAYj2uLhr9ZOv760iz4TRbYQTA@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
 <CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
 <CAFvE7K7dw8vhYoedczk42-JDFuxM0BQvuokorbQOcW8M881Q3g@mail.gmail.com> <CAPfXE6NEqM8wURwO8N2b3-vBqAYj2uLhr9ZOv760iz4TRbYQTA@mail.gmail.com>
From: Justin Kestelyn <jkestelyn@cloudera.com>
Date: Wed, 11 Dec 2013 13:52:08 -0800
Message-ID: <CAC-fmwzyAC2jKHGh8m5RGvcsx3=ze-WXE+Y_7=_kEnZVa=kTag@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Horia Airoh <horia@alum.berkeley.edu>
Cc: Olivier Grisel <olivier.grisel@ensta.org>, dev <dev@spark.incubator.apache.org>, 
	Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>
Content-Type: multipart/alternative; boundary=047d7b4725a8cf50ea04ed493e20
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b4725a8cf50ea04ed493e20
Content-Type: text/plain; charset=ISO-8859-1

Please also add to the venue info: The group will be on the 6th floor.


On Wed, Dec 11, 2013 at 8:14 AM, Horia <horia@alum.berkeley.edu> wrote:

> If it's up for a vote, I'd say we start at 9:30 :)
>
>
>
> On Wed, Dec 11, 2013 at 1:56 AM, Olivier Grisel <olivier.grisel@ensta.org>wrote:
>
>> 2013/12/10 Justin Kestelyn <jkestelyn@cloudera.com>:
>> > Location:
>> >
>> > Cloudera
>> > 433 California Street
>> > San Francisco, CA
>>
>> Thanks I will add that on the wiki, shall we start at 9am? 9.30am?
>>
>> --
>> Olivier
>>
>
>


-- 

*Justin Kestelyn*
Developer Outreach & Relations
Cloudera | www.cloudera.com

Tel: 650.683.4688
Email: jkestelyn@cloudera.com
Twitter: @kestelyn, @ClouderaEng

--047d7b4725a8cf50ea04ed493e20--

From dev-return-891-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 11 23:15:42 2013
Return-Path: <dev-return-891-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3A52810C01
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Dec 2013 23:15:42 +0000 (UTC)
Received: (qmail 56200 invoked by uid 500); 11 Dec 2013 23:15:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56161 invoked by uid 500); 11 Dec 2013 23:15:42 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 56153 invoked by uid 99); 11 Dec 2013 23:15:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 23:15:41 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Dec 2013 23:15:38 +0000
Received: by mail-ob0-f180.google.com with SMTP id wo20so7629403obc.25
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 15:15:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=xNZtITRDcRIWvyGxcds8qLACQw7GNIyE6StQpSfxaMY=;
        b=wzeTfFlivprq61YsIR+1fe+2Fxl1x3tji3rmfON9dGwt2Tyuo0yYR1RkoRS5AkYwhF
         vDayJuTMkOOWZ/Z7vYlFcwwSV17RqJ0c1nAIxOCwK8OCUFpEpkNIgin1r15bKyVDnJUs
         PnfZDbVPlDkMojwPtP7Vq2mKHDH9nGz2H7Mymb6ER2s9Cd2dslvnrDq3UeEv/CbaRiXL
         zNERlJF/upvUBgYHH3E4HCfVFlSAGU9qS9Er/+lLCxg1kehUG8tBjRnA3QX5fK5AGPaA
         iTaWKDYS5NxL7g+If3/oPj3IlQpEmzNr3LpLv1fcdDQ4z9HE3SQlkrpMFPD39wAwTPS8
         nhGA==
MIME-Version: 1.0
X-Received: by 10.182.233.228 with SMTP id tz4mr3198184obc.56.1386803717225;
 Wed, 11 Dec 2013 15:15:17 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Wed, 11 Dec 2013 15:15:17 -0800 (PST)
In-Reply-To: <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
Date: Wed, 11 Dec 2013 15:15:17 -0800
Message-ID: <CABPQxsu1nYNtFew8FaMcW4z0rJmkOi6g+e5wqk+Duq6yKPYfhQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Tom,

I re-verified the signatures and got someone else to do it. It seemed
fine. Here is what I did.

gpg --recv-key 9E4FE3AF
wget http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-0.=
8.1-incubating.tgz.asc
wget http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-0.=
8.1-incubating.tgz
gpg --verify spark-0.8.1-incubating.tgz.asc spark-0.8.1-incubating.tgz
gpg: Signature made Tue 10 Dec 2013 02:53:15 PM PST using RSA key ID 9E4FE3=
AF
gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"

On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com> wro=
te:
> I don't know how to make sense of the numbers, but here's what I've got
> from a very small sample size.
>
> For both v0.8.0-incubating and v0.8.1-incubating, building separate
> assemblies is faster than `./sbt/sbt assembly` and the times for building
> separate assemblies for 0.8.0 and 0.8.1 are about the same.
>
> For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long as t=
he
> sum of the separate assemblies.
> For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as th=
e
> sum of the separate assemblies.
>
> Weird.
>
>
> On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com>wro=
te:
>
>> I'll +1 myself also.
>>
>> For anyone who has the slow build problem: does this issue happen when
>> building v0.8.0-incubating also? Trying to figure out whether it's
>> related to something we added in 0.8.1 or if it's a long standing
>> issue.
>>
>> - Patrick
>>
>> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.com=
>
>> wrote:
>> > Woah, weird, but definitely good to know.
>> >
>> > If you=92re doing Spark development, there=92s also a more convenient =
option
>> added by Shivaram in the master branch. You can do sbt assemble-deps to
>> package *just* the dependencies of each project in a special assembly JA=
R,
>> and then use sbt compile to update the code. This will use the classes
>> directly out of the target/scala-2.9.3/classes directories. You have to
>> redo assemble-deps only if your external dependencies change.
>> >
>> > Matei
>> >
>> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
>> wrote:
>> >
>> >> I hope this PR https://github.com/apache/incubator-spark/pull/252 can
>> help.
>> >> Again this is not a blocker for the release from my side either.
>> >>
>> >>
>> >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.co=
m
>> >wrote:
>> >>
>> >>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly`
>> takes
>> >>> a long, long, looooong time to complete (a MBP, in my case), buildin=
g
>> three
>> >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>> >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much les=
s
>> time.
>> >>>
>> >>>
>> >>>
>> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>> scrapcodes@gmail.com
>> >>>> wrote:
>> >>>
>> >>>> forgot to mention, after running sbt/sbt assembly/assembly running
>> >>> sbt/sbt
>> >>>> examples/assembly takes just 37s. Not to mention my hardware is not
>> >>> really
>> >>>> great.
>> >>>>
>> >>>>
>> >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>> scrapcodes@gmail.com
>> >>>>> wrote:
>> >>>>
>> >>>>> Hi Patrick and Matei,
>> >>>>>
>> >>>>> Was trying out this and followed the quick start guide which says =
do
>> >>>>> sbt/sbt assembly, like few others I was also stuck for few minutes=
 on
>> >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is
>> much
>> >>>>> faster.
>> >>>>>
>> >>>>> Should we change the documentation to reflect this. It will not be
>> >>> great
>> >>>>> for first time users to get stuck there.
>> >>>>>
>> >>>>>
>> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>> >>> matei.zaharia@gmail.com
>> >>>>> wrote:
>> >>>>>
>> >>>>>> +1
>> >>>>>>
>> >>>>>> Built and tested it on Mac OS X.
>> >>>>>>
>> >>>>>> Matei
>> >>>>>>
>> >>>>>>
>> >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com>
>> >>>> wrote:
>> >>>>>>
>> >>>>>>> Please vote on releasing the following candidate as Apache Spark
>> >>>>>>> (incubating) version 0.8.1.
>> >>>>>>>
>> >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>> >>>>>>>
>> >>>>>>
>> >>>>
>> >>>
>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubat=
or-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>> >>>>>>>
>> >>>>>>> The release files, including signatures, digests, etc can be fou=
nd
>> >>> at:
>> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>> >>>>>>>
>> >>>>>>> Release artifacts are signed with the following key:
>> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>> >>>>>>>
>> >>>>>>> The staging repository for this release can be found at:
>> >>>>>>>
>> >>>>
>> https://repository.apache.org/content/repositories/orgapachespark-040/
>> >>>>>>>
>> >>>>>>> The documentation corresponding to this release can be found at:
>> >>>>>>>
>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>> >>>>>>>
>> >>>>>>> For information about the contents of this release see:
>> >>>>>>>
>> >>>>>>
>> >>>>
>> >>>
>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob=
;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0=
.8
>> >>>>>>>
>> >>>>>>> Please vote on releasing this package as Apache Spark
>> >>>> 0.8.1-incubating!
>> >>>>>>>
>> >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
>> >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>> >>>>>>>
>> >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> >>>>>>> [ ] -1 Do not release this package because ...
>> >>>>>>>
>> >>>>>>> To learn more about Apache Spark, please see
>> >>>>>>> http://spark.incubator.apache.org/
>> >>>>>>
>> >>>>>>
>> >>>>>
>> >>>>>
>> >>>>> --
>> >>>>> s
>> >>>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>> --
>> >>>> s
>> >>>>
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >> s
>> >
>>

From dev-return-892-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 00:27:43 2013
Return-Path: <dev-return-892-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9D65E10E9E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 00:27:43 +0000 (UTC)
Received: (qmail 85905 invoked by uid 500); 12 Dec 2013 00:27:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85869 invoked by uid 500); 12 Dec 2013 00:27:43 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 85861 invoked by uid 99); 12 Dec 2013 00:27:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 00:27:43 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.42 as permitted sender)
Received: from [209.85.219.42] (HELO mail-oa0-f42.google.com) (209.85.219.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 00:27:37 +0000
Received: by mail-oa0-f42.google.com with SMTP id i4so8271160oah.29
        for <dev@spark.incubator.apache.org>; Wed, 11 Dec 2013 16:27:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=vn1KFASqZnfmyqkqqscJbj2UetGXt30AH2dueStBYig=;
        b=y0hmrmL9vbiyA2FXP5UoE5BwqS+fYavZiJuT2OyBXtfMhyrT18tcFswgTBKFGmdOm0
         SiPhNXTpLx1yK98w922RE/abSu3Ut7KTsgJ6jUWU3gsqD+P2zCMrIl4WhdQ5kl37AiQN
         fzm3ok+mZZpzFP9kIrFICaCV9CxwFlLolfAEtXplpjhqk7gEIrWqtZEJd3O4GTgdB0oI
         f8XREbGBGLQauqt17fxcVSYeAfj+qyFo54Cf3mkyAGPW4MRLzuvy39snEHTwyzfTbHdb
         qeFoiaw2IdqWZLhNfKhWWrmSAJHK7RinFIxR2xS5Ng2dBlTnvxqqvqmdogqzQ11go9yD
         cjRg==
MIME-Version: 1.0
X-Received: by 10.60.63.102 with SMTP id f6mr19609oes.76.1386808036509; Wed,
 11 Dec 2013 16:27:16 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Wed, 11 Dec 2013 16:27:16 -0800 (PST)
In-Reply-To: <CABPQxsu1nYNtFew8FaMcW4z0rJmkOi6g+e5wqk+Duq6yKPYfhQ@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CABPQxsu1nYNtFew8FaMcW4z0rJmkOi6g+e5wqk+Duq6yKPYfhQ@mail.gmail.com>
Date: Wed, 11 Dec 2013 16:27:16 -0800
Message-ID: <CABPQxstPD-n+aZph7jpWgkgQbuvpCKmPQW2ieOj9VVSSykmzuA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

I also talked to a few people who got corrupted binaries when
downloading from the people.apache HTTP. In that case the checksum
failed but if they re-downloaded it worked. So maybe just re-download
and try again?

On Wed, Dec 11, 2013 at 3:15 PM, Patrick Wendell <pwendell@gmail.com> wrote=
:
> Hey Tom,
>
> I re-verified the signatures and got someone else to do it. It seemed
> fine. Here is what I did.
>
> gpg --recv-key 9E4FE3AF
> wget http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-=
0.8.1-incubating.tgz.asc
> wget http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-=
0.8.1-incubating.tgz
> gpg --verify spark-0.8.1-incubating.tgz.asc spark-0.8.1-incubating.tgz
> gpg: Signature made Tue 10 Dec 2013 02:53:15 PM PST using RSA key ID 9E4F=
E3AF
> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
>
> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com> w=
rote:
>> I don't know how to make sense of the numbers, but here's what I've got
>> from a very small sample size.
>>
>> For both v0.8.0-incubating and v0.8.1-incubating, building separate
>> assemblies is faster than `./sbt/sbt assembly` and the times for buildin=
g
>> separate assemblies for 0.8.0 and 0.8.1 are about the same.
>>
>> For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long as =
the
>> sum of the separate assemblies.
>> For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as t=
he
>> sum of the separate assemblies.
>>
>> Weird.
>>
>>
>> On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com>wr=
ote:
>>
>>> I'll +1 myself also.
>>>
>>> For anyone who has the slow build problem: does this issue happen when
>>> building v0.8.0-incubating also? Trying to figure out whether it's
>>> related to something we added in 0.8.1 or if it's a long standing
>>> issue.
>>>
>>> - Patrick
>>>
>>> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.co=
m>
>>> wrote:
>>> > Woah, weird, but definitely good to know.
>>> >
>>> > If you=92re doing Spark development, there=92s also a more convenient=
 option
>>> added by Shivaram in the master branch. You can do sbt assemble-deps to
>>> package *just* the dependencies of each project in a special assembly J=
AR,
>>> and then use sbt compile to update the code. This will use the classes
>>> directly out of the target/scala-2.9.3/classes directories. You have to
>>> redo assemble-deps only if your external dependencies change.
>>> >
>>> > Matei
>>> >
>>> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
>>> wrote:
>>> >
>>> >> I hope this PR https://github.com/apache/incubator-spark/pull/252 ca=
n
>>> help.
>>> >> Again this is not a blocker for the release from my side either.
>>> >>
>>> >>
>>> >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.c=
om
>>> >wrote:
>>> >>
>>> >>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly=
`
>>> takes
>>> >>> a long, long, looooong time to complete (a MBP, in my case), buildi=
ng
>>> three
>>> >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>>> >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much le=
ss
>>> time.
>>> >>>
>>> >>>
>>> >>>
>>> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>>> scrapcodes@gmail.com
>>> >>>> wrote:
>>> >>>
>>> >>>> forgot to mention, after running sbt/sbt assembly/assembly running
>>> >>> sbt/sbt
>>> >>>> examples/assembly takes just 37s. Not to mention my hardware is no=
t
>>> >>> really
>>> >>>> great.
>>> >>>>
>>> >>>>
>>> >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>>> scrapcodes@gmail.com
>>> >>>>> wrote:
>>> >>>>
>>> >>>>> Hi Patrick and Matei,
>>> >>>>>
>>> >>>>> Was trying out this and followed the quick start guide which says=
 do
>>> >>>>> sbt/sbt assembly, like few others I was also stuck for few minute=
s on
>>> >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is
>>> much
>>> >>>>> faster.
>>> >>>>>
>>> >>>>> Should we change the documentation to reflect this. It will not b=
e
>>> >>> great
>>> >>>>> for first time users to get stuck there.
>>> >>>>>
>>> >>>>>
>>> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>> >>> matei.zaharia@gmail.com
>>> >>>>> wrote:
>>> >>>>>
>>> >>>>>> +1
>>> >>>>>>
>>> >>>>>> Built and tested it on Mac OS X.
>>> >>>>>>
>>> >>>>>> Matei
>>> >>>>>>
>>> >>>>>>
>>> >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com=
>
>>> >>>> wrote:
>>> >>>>>>
>>> >>>>>>> Please vote on releasing the following candidate as Apache Spar=
k
>>> >>>>>>> (incubating) version 0.8.1.
>>> >>>>>>>
>>> >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>>> >>>>>>>
>>> >>>>>>
>>> >>>>
>>> >>>
>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincuba=
tor-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>> >>>>>>>
>>> >>>>>>> The release files, including signatures, digests, etc can be fo=
und
>>> >>> at:
>>> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>>> >>>>>>>
>>> >>>>>>> Release artifacts are signed with the following key:
>>> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>> >>>>>>>
>>> >>>>>>> The staging repository for this release can be found at:
>>> >>>>>>>
>>> >>>>
>>> https://repository.apache.org/content/repositories/orgapachespark-040/
>>> >>>>>>>
>>> >>>>>>> The documentation corresponding to this release can be found at=
:
>>> >>>>>>>
>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>>> >>>>>>>
>>> >>>>>>> For information about the contents of this release see:
>>> >>>>>>>
>>> >>>>>>
>>> >>>>
>>> >>>
>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblo=
b;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-=
0.8
>>> >>>>>>>
>>> >>>>>>> Please vote on releasing this package as Apache Spark
>>> >>>> 0.8.1-incubating!
>>> >>>>>>>
>>> >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
>>> >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>> >>>>>>>
>>> >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>> >>>>>>> [ ] -1 Do not release this package because ...
>>> >>>>>>>
>>> >>>>>>> To learn more about Apache Spark, please see
>>> >>>>>>> http://spark.incubator.apache.org/
>>> >>>>>>
>>> >>>>>>
>>> >>>>>
>>> >>>>>
>>> >>>>> --
>>> >>>>> s
>>> >>>>>
>>> >>>>
>>> >>>>
>>> >>>>
>>> >>>> --
>>> >>>> s
>>> >>>>
>>> >>>
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> s
>>> >
>>>

From dev-return-893-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 08:21:33 2013
Return-Path: <dev-return-893-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8AEC610A62
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 08:21:33 +0000 (UTC)
Received: (qmail 44954 invoked by uid 500); 12 Dec 2013 08:21:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44638 invoked by uid 500); 12 Dec 2013 08:21:27 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 44601 invoked by uid 99); 12 Dec 2013 08:21:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:21:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.54 as permitted sender)
Received: from [209.85.219.54] (HELO mail-oa0-f54.google.com) (209.85.219.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:21:21 +0000
Received: by mail-oa0-f54.google.com with SMTP id h16so67331oag.27
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 00:21:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=l//jonlZY+Hk2Hxluo6J/mcnUPy1lffMECM94JknyHA=;
        b=0zhqTmD0XeOd6iSgScgovszUnE1iug6IHShKPLMOqkCrDbW8JC2oRd9t7psvUxQbqv
         WHLCzbEX/pEFjQ5zBuKpR8Fb9V+SwKVj6Xb0f1YxbHVrpTjRIbnT0zR3sAWBZ9syLe6w
         coDRPkzLFRYFhYCPfLaGNQBbY7iSFdysNknjeDYC//g4fuFHfrXHBY8mEAGBCwsW/RmO
         zRAIrJkrPCmGmfqxFAU06zA4H6e3wPvxe2dEujrwuH8fIfG0T2Oq8z/3lJdkSRiKNS5U
         sT1Xf7h25XOEXmUqyrPZCRunlAp2LGicbeU2nfJhIgxUfeVhoLsu5hpHmeHUFRvxkpWP
         JfeQ==
MIME-Version: 1.0
X-Received: by 10.60.51.102 with SMTP id j6mr4548391oeo.6.1386836460986; Thu,
 12 Dec 2013 00:21:00 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Thu, 12 Dec 2013 00:21:00 -0800 (PST)
Date: Thu, 12 Dec 2013 00:21:00 -0800
Message-ID: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
Subject: Scala 2.10 Merge
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c30a689e813b04ed52062b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c30a689e813b04ed52062b
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Hi Developers,

In the next few days we are planning to merge Scala 2.10 support into
Spark. For those that haven't been following this, Prashant Sharma has been
maintaining the scala-2.10 branch of Spark for several months. This branch
is current with master and has been reviewed for merging:

https://github.com/apache/incubator-spark/tree/scala-2.10

Scala 2.10 support is one of the most requested features for Spark - it
will be great to get this into Spark 0.9! Please note that *Scala 2.10 is
not binary compatible with Scala 2.9*. With that in mind, I wanted to give
a few heads-up/requests to developers:

If you are developing applications on top of Spark=92s master branch, those
will need to migrate to Scala 2.10. You may want to download and test the
current scala-2.10 branch in order to make sure you will be okay as Spark
developments move forward. Of course, you can always stick with the current
master commit and be fine (I=92ll cut a tag when we do the merge in order t=
o
delineate where the version changes). Please open new threads on the dev
list to report and discuss any issues.

This merge will temporarily drop support for YARN 2.2 on the master branch.
This is because the workaround we used was only compiled for Scala 2.9. We
are going to come up with a more robust solution to YARN 2.2 support before
releasing 0.9.

Going forward, we will continue to make maintenance releases on branch-0.8
which will remain compatible with Scala 2.9.

For those interested, the primary code changes in this merge are upgrading
the akka version, changing the use of Scala 2.9=92s ClassManifest construct
to Scala 2.10=92s ClassTag, and updating the spark shell to work with Scala
2.10's repl.

- Patrick

--001a11c30a689e813b04ed52062b--

From dev-return-894-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 08:27:15 2013
Return-Path: <dev-return-894-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 774B610A70
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 08:27:15 +0000 (UTC)
Received: (qmail 46769 invoked by uid 500); 12 Dec 2013 08:27:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46733 invoked by uid 500); 12 Dec 2013 08:27:10 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 46723 invoked by uid 99); 12 Dec 2013 08:27:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:27:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 74.125.82.49 as permitted sender)
Received: from [74.125.82.49] (HELO mail-wg0-f49.google.com) (74.125.82.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:27:03 +0000
Received: by mail-wg0-f49.google.com with SMTP id x12so73440wgg.16
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 00:26:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=Bx5QJasjdZ59AL1+goCal23Kun/ApEMf31qftVmHqSc=;
        b=gC3v9ZAjzUlCOWwlIpHFZwL/pTJhv8XDcrwtEhuhB4sWvSr4UKA/S8YNoNfzsE73Ih
         QbgZ2GPOBV61iTCso+20VU1D6QA6OrVdzxvs5bQiKRrZ1yovMrfxSQFFPJ8CXStZKXdM
         X9ytougRMBnpC0hdfuzM5QnKrM0PKd6eqxz0CS6QXUsFhRaKdOXJwtBqIu+psQ6VzgPm
         Mqj2wmd18T/CjwZUJ5ZRnYMVbWKZegdnLH0YUfSMs4JVa6aKHMkL8od+IZ1I3EKzbh9o
         WbxNjrKj5LWDswHd+22B3KUOoBQZ7y9pTtFlHic7cbwnyh3Dm9tuE7vB33T2gRuA44fF
         Oq7Q==
X-Received: by 10.194.80.137 with SMTP id r9mr472443wjx.88.1386836803064; Thu,
 12 Dec 2013 00:26:43 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.39.194 with HTTP; Thu, 12 Dec 2013 00:26:23 -0800 (PST)
In-Reply-To: <CABPQxstPD-n+aZph7jpWgkgQbuvpCKmPQW2ieOj9VVSSykmzuA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
 <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
 <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
 <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
 <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
 <1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com> <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
 <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
 <CABPQxsu1nYNtFew8FaMcW4z0rJmkOi6g+e5wqk+Duq6yKPYfhQ@mail.gmail.com> <CABPQxstPD-n+aZph7jpWgkgQbuvpCKmPQW2ieOj9VVSSykmzuA@mail.gmail.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Thu, 12 Dec 2013 13:56:23 +0530
Message-ID: <CAOYDGoDrZfub0mfjjs-NnHbds+iBbYDasGf4axkqGMM0G6_caA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bdc8e86021aea04ed521bcd
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc8e86021aea04ed521bcd
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

+1, built and tested on linux.


On Thu, Dec 12, 2013 at 5:57 AM, Patrick Wendell <pwendell@gmail.com> wrote=
:

> I also talked to a few people who got corrupted binaries when
> downloading from the people.apache HTTP. In that case the checksum
> failed but if they re-downloaded it worked. So maybe just re-download
> and try again?
>
> On Wed, Dec 11, 2013 at 3:15 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hey Tom,
> >
> > I re-verified the signatures and got someone else to do it. It seemed
> > fine. Here is what I did.
> >
> > gpg --recv-key 9E4FE3AF
> > wget
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-0.8.1=
-incubating.tgz.asc
> > wget
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/spark-0.8.1=
-incubating.tgz
> > gpg --verify spark-0.8.1-incubating.tgz.asc spark-0.8.1-incubating.tgz
> > gpg: Signature made Tue 10 Dec 2013 02:53:15 PM PST using RSA key ID
> 9E4FE3AF
> > gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
> >
> > On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> >> I don't know how to make sense of the numbers, but here's what I've go=
t
> >> from a very small sample size.
> >>
> >> For both v0.8.0-incubating and v0.8.1-incubating, building separate
> >> assemblies is faster than `./sbt/sbt assembly` and the times for
> building
> >> separate assemblies for 0.8.0 and 0.8.1 are about the same.
> >>
> >> For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long a=
s
> the
> >> sum of the separate assemblies.
> >> For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as
> the
> >> sum of the separate assemblies.
> >>
> >> Weird.
> >>
> >>
> >> On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com
> >wrote:
> >>
> >>> I'll +1 myself also.
> >>>
> >>> For anyone who has the slow build problem: does this issue happen whe=
n
> >>> building v0.8.0-incubating also? Trying to figure out whether it's
> >>> related to something we added in 0.8.1 or if it's a long standing
> >>> issue.
> >>>
> >>> - Patrick
> >>>
> >>> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
> matei.zaharia@gmail.com>
> >>> wrote:
> >>> > Woah, weird, but definitely good to know.
> >>> >
> >>> > If you=92re doing Spark development, there=92s also a more convenie=
nt
> option
> >>> added by Shivaram in the master branch. You can do sbt assemble-deps =
to
> >>> package *just* the dependencies of each project in a special assembly
> JAR,
> >>> and then use sbt compile to update the code. This will use the classe=
s
> >>> directly out of the target/scala-2.9.3/classes directories. You have =
to
> >>> redo assemble-deps only if your external dependencies change.
> >>> >
> >>> > Matei
> >>> >
> >>> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
> >>> wrote:
> >>> >
> >>> >> I hope this PR https://github.com/apache/incubator-spark/pull/252c=
an
> >>> help.
> >>> >> Again this is not a blocker for the release from my side either.
> >>> >>
> >>> >>
> >>> >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
> mark@clearstorydata.com
> >>> >wrote:
> >>> >>
> >>> >>> Interesting, and confirmed: On my machine where `./sbt/sbt
> assembly`
> >>> takes
> >>> >>> a long, long, looooong time to complete (a MBP, in my case),
> building
> >>> three
> >>> >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> >>> >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much
> less
> >>> time.
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
> >>> scrapcodes@gmail.com
> >>> >>>> wrote:
> >>> >>>
> >>> >>>> forgot to mention, after running sbt/sbt assembly/assembly runni=
ng
> >>> >>> sbt/sbt
> >>> >>>> examples/assembly takes just 37s. Not to mention my hardware is
> not
> >>> >>> really
> >>> >>>> great.
> >>> >>>>
> >>> >>>>
> >>> >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
> >>> scrapcodes@gmail.com
> >>> >>>>> wrote:
> >>> >>>>
> >>> >>>>> Hi Patrick and Matei,
> >>> >>>>>
> >>> >>>>> Was trying out this and followed the quick start guide which
> says do
> >>> >>>>> sbt/sbt assembly, like few others I was also stuck for few
> minutes on
> >>> >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it =
is
> >>> much
> >>> >>>>> faster.
> >>> >>>>>
> >>> >>>>> Should we change the documentation to reflect this. It will not
> be
> >>> >>> great
> >>> >>>>> for first time users to get stuck there.
> >>> >>>>>
> >>> >>>>>
> >>> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> >>> >>> matei.zaharia@gmail.com
> >>> >>>>> wrote:
> >>> >>>>>
> >>> >>>>>> +1
> >>> >>>>>>
> >>> >>>>>> Built and tested it on Mac OS X.
> >>> >>>>>>
> >>> >>>>>> Matei
> >>> >>>>>>
> >>> >>>>>>
> >>> >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
> pwendell@gmail.com>
> >>> >>>> wrote:
> >>> >>>>>>
> >>> >>>>>>> Please vote on releasing the following candidate as Apache
> Spark
> >>> >>>>>>> (incubating) version 0.8.1.
> >>> >>>>>>>
> >>> >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> >>> >>>>>>>
> >>> >>>>>>
> >>> >>>>
> >>> >>>
> >>>
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> >>> >>>>>>>
> >>> >>>>>>> The release files, including signatures, digests, etc can be
> found
> >>> >>> at:
> >>> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4=
/
> >>> >>>>>>>
> >>> >>>>>>> Release artifacts are signed with the following key:
> >>> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
> >>> >>>>>>>
> >>> >>>>>>> The staging repository for this release can be found at:
> >>> >>>>>>>
> >>> >>>>
> >>> https://repository.apache.org/content/repositories/orgapachespark-040=
/
> >>> >>>>>>>
> >>> >>>>>>> The documentation corresponding to this release can be found
> at:
> >>> >>>>>>>
> >>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> >>> >>>>>>>
> >>> >>>>>>> For information about the contents of this release see:
> >>> >>>>>>>
> >>> >>>>>>
> >>> >>>>
> >>> >>>
> >>>
> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;=
f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
> >>> >>>>>>>
> >>> >>>>>>> Please vote on releasing this package as Apache Spark
> >>> >>>> 0.8.1-incubating!
> >>> >>>>>>>
> >>> >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC a=
nd
> >>> >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
> >>> >>>>>>>
> >>> >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> >>> >>>>>>> [ ] -1 Do not release this package because ...
> >>> >>>>>>>
> >>> >>>>>>> To learn more about Apache Spark, please see
> >>> >>>>>>> http://spark.incubator.apache.org/
> >>> >>>>>>
> >>> >>>>>>
> >>> >>>>>
> >>> >>>>>
> >>> >>>>> --
> >>> >>>>> s
> >>> >>>>>
> >>> >>>>
> >>> >>>>
> >>> >>>>
> >>> >>>> --
> >>> >>>> s
> >>> >>>>
> >>> >>>
> >>> >>
> >>> >>
> >>> >>
> >>> >> --
> >>> >> s
> >>> >
> >>>
>



--=20
s

--047d7bdc8e86021aea04ed521bcd--

From dev-return-895-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 08:39:28 2013
Return-Path: <dev-return-895-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B111E10ADD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 08:39:28 +0000 (UTC)
Received: (qmail 74597 invoked by uid 500); 12 Dec 2013 08:39:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74546 invoked by uid 500); 12 Dec 2013 08:39:27 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 74533 invoked by uid 99); 12 Dec 2013 08:39:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:39:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of olivier.grisel@gmail.com designates 209.85.212.170 as permitted sender)
Received: from [209.85.212.170] (HELO mail-wi0-f170.google.com) (209.85.212.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:39:21 +0000
Received: by mail-wi0-f170.google.com with SMTP id hq4so394964wib.3
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 00:39:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=rDrt0+eKYti/tvfTb8L+9HmWEs1idShBDSGML2F8+iI=;
        b=tjck7eud5E/q9HYBC2bzoRPCgJJHGPAFJIddVd+Tnb6mow0OR0WPmCWi0XNFfof0c9
         QHYJzFn7TQPD50A+N4bbqL78Pg3RsS7zDceSbvmIxFVSCyLGOVfq4Z6JOwE9tFXRzQPd
         lchXTQWyLjeNEKRU41sJ+VzHFrYd7Bu+Mel4YtWkggSyU90FjSyfYEU1caRvBQqGzwMl
         xtIhX0PPb0XlOB9yd7nkJU72qJ0C53WbnSsmMNIX7m82uUnq4ZIQkc/jDywFfInZGu2C
         ob0AFic+pj07TQviZyGiwCwXhZ6oqbnOYAO+qi8HCYsV8+FxCV+kiDmGMU5tqZgX8mFG
         7SFg==
X-Received: by 10.180.189.49 with SMTP id gf17mr28007312wic.23.1386837540258;
 Thu, 12 Dec 2013 00:39:00 -0800 (PST)
MIME-Version: 1.0
Sender: olivier.grisel@gmail.com
Received: by 10.194.19.70 with HTTP; Thu, 12 Dec 2013 00:38:39 -0800 (PST)
In-Reply-To: <CAC-fmwzyAC2jKHGh8m5RGvcsx3=ze-WXE+Y_7=_kEnZVa=kTag@mail.gmail.com>
References: <CALD+6GN1BS8wmOJ18NznimkL7uhGTsO2jk-f+=vcEMW2hB6DPQ@mail.gmail.com>
 <CAFvE7K4y3PyAPpvMLgjgp_otprijoskXyX2y+mzMtciFYvfw0g@mail.gmail.com>
 <CAC1ssC47gCjOZuPy1LMKMaY1oJS9YPAFHqcWKaFZ+H1V8FHJNA@mail.gmail.com>
 <CAC1ssC72acFTfsuM01r1bj-717yWG6WGr0rQwvsMcbixMWp9jw@mail.gmail.com>
 <CAFvE7K4Ye0S88wPw06-EEWZ_LF6mg91a0hqsO-=+-nxgt9cBfA@mail.gmail.com>
 <CAC1ssC7TVX5xNU_kWXn4HzNXGMpdV_Lfcs=g+bC3=C__xCMiSg@mail.gmail.com>
 <CAPfXE6NN3bUJjpcQUu3KJ1R2PR-KmEnm9humvQ_fyxrWP86YOA@mail.gmail.com>
 <CAC-fmwy9bE7jDrHV1+ndj+WCw+b1JacCJM-sgQjrQoUed2D-iA@mail.gmail.com>
 <CAFvE7K7dw8vhYoedczk42-JDFuxM0BQvuokorbQOcW8M881Q3g@mail.gmail.com>
 <CAPfXE6NEqM8wURwO8N2b3-vBqAYj2uLhr9ZOv760iz4TRbYQTA@mail.gmail.com> <CAC-fmwzyAC2jKHGh8m5RGvcsx3=ze-WXE+Y_7=_kEnZVa=kTag@mail.gmail.com>
From: Olivier Grisel <olivier.grisel@ensta.org>
Date: Thu, 12 Dec 2013 09:38:39 +0100
X-Google-Sender-Auth: uX598A20_93uiLAl3N7CKkz2MOI
Message-ID: <CAFvE7K6hF7V=EbNo3-LkBg-MbstgcxN3TY=6Kdx6F999PQj72Q@mail.gmail.com>
Subject: Re: PySpark / scikit-learn integration sprint at Cloudera - Strata
 Conference Friday 14th Feb 2014
To: Justin Kestelyn <jkestelyn@cloudera.com>
Cc: Horia Airoh <horia@alum.berkeley.edu>, dev <dev@spark.incubator.apache.org>, 
	Reynold Xin <rxin@apache.org>, Nick Pentreath <nick.pentreath@gmail.com>, 
	Uri Laserson <Uri.Laserson@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Done.

-- 
Olivier

From dev-return-896-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 08:42:53 2013
Return-Path: <dev-return-896-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4246210AE5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 08:42:53 +0000 (UTC)
Received: (qmail 79170 invoked by uid 500); 12 Dec 2013 08:42:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79029 invoked by uid 500); 12 Dec 2013 08:42:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 79019 invoked by uid 99); 12 Dec 2013 08:42:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:42:52 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of raymond.liu@intel.com designates 192.55.52.88 as permitted sender)
Received: from [192.55.52.88] (HELO mga01.intel.com) (192.55.52.88)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 08:42:47 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by fmsmga101.fm.intel.com with ESMTP; 12 Dec 2013 00:42:27 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.93,877,1378882800"; 
   d="scan'208";a="442948578"
Received: from fmsmsx108.amr.corp.intel.com ([10.19.9.228])
  by fmsmga001.fm.intel.com with ESMTP; 12 Dec 2013 00:42:27 -0800
Received: from shsmsx103.ccr.corp.intel.com (10.239.4.69) by
 FMSMSX108.amr.corp.intel.com (10.19.9.228) with Microsoft SMTP Server (TLS)
 id 14.3.123.3; Thu, 12 Dec 2013 00:42:26 -0800
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.57]) by
 SHSMSX103.ccr.corp.intel.com ([169.254.4.86]) with mapi id 14.03.0123.003;
 Thu, 12 Dec 2013 16:42:25 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: RE: Scala 2.10 Merge
Thread-Topic: Scala 2.10 Merge
Thread-Index: AQHO9xMxz1T1mh145E+Xto/3UYWafppQOzyA
Date: Thu, 12 Dec 2013 08:42:24 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
In-Reply-To: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Patrick

	What does that means for drop YARN 2.2? seems codes are still there. You m=
ean if build upon 2.2 it will break, and won't and work right? Since the ho=
me made akka build on scala 2.10 are not there. While, if for this case, ca=
n we just use akka 2.3-M1 which run on protobuf 2.5 for replacement?

Best Regards,
Raymond Liu


-----Original Message-----
From: Patrick Wendell [mailto:pwendell@gmail.com]=20
Sent: Thursday, December 12, 2013 4:21 PM
To: dev@spark.incubator.apache.org
Subject: Scala 2.10 Merge

Hi Developers,

In the next few days we are planning to merge Scala 2.10 support into Spark=
. For those that haven't been following this, Prashant Sharma has been main=
taining the scala-2.10 branch of Spark for several months. This branch is c=
urrent with master and has been reviewed for merging:

https://github.com/apache/incubator-spark/tree/scala-2.10

Scala 2.10 support is one of the most requested features for Spark - it wil=
l be great to get this into Spark 0.9! Please note that *Scala 2.10 is not =
binary compatible with Scala 2.9*. With that in mind, I wanted to give a fe=
w heads-up/requests to developers:

If you are developing applications on top of Spark's master branch, those w=
ill need to migrate to Scala 2.10. You may want to download and test the cu=
rrent scala-2.10 branch in order to make sure you will be okay as Spark dev=
elopments move forward. Of course, you can always stick with the current ma=
ster commit and be fine (I'll cut a tag when we do the merge in order to de=
lineate where the version changes). Please open new threads on the dev list=
 to report and discuss any issues.

This merge will temporarily drop support for YARN 2.2 on the master branch.
This is because the workaround we used was only compiled for Scala 2.9. We =
are going to come up with a more robust solution to YARN 2.2 support before=
 releasing 0.9.

Going forward, we will continue to make maintenance releases on branch-0.8 =
which will remain compatible with Scala 2.9.

For those interested, the primary code changes in this merge are upgrading =
the akka version, changing the use of Scala 2.9's ClassManifest construct t=
o Scala 2.10's ClassTag, and updating the spark shell to work with Scala 2.=
10's repl.

- Patrick

From dev-return-897-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 09:12:48 2013
Return-Path: <dev-return-897-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A3CDA10BA5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 09:12:48 +0000 (UTC)
Received: (qmail 32417 invoked by uid 500); 12 Dec 2013 09:12:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32386 invoked by uid 500); 12 Dec 2013 09:12:46 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 32376 invoked by uid 99); 12 Dec 2013 09:12:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 09:12:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.54 as permitted sender)
Received: from [209.85.219.54] (HELO mail-oa0-f54.google.com) (209.85.219.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 09:12:42 +0000
Received: by mail-oa0-f54.google.com with SMTP id h16so118998oag.13
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 01:12:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=bwsAOzt3sHYI71dZuH818ecwKI5ZkuwQhjo80iL++N8=;
        b=dibt9SaHwBMdJglXZtzKYA8sUNHw8RuIe3z9aZFg2HaGiRICHxlZzpWlmb+WGW5m9n
         YuYW3TDr3G6c/uwUm6bsLzdhRt4eYtn3j3sIah4oGCh2dZIqpHnC/L6cVBx/PJr0i6LZ
         J3XAN7AJe+qe8Ii8AVI60fTbBKEXAuh/wCaJL8LKcNN78QY4yFmzHEC309SvwVgH6uIX
         mkzr0+gpKZiALwOo61F5Nte0eXWDLLgkvlsf33z/xJDG1vxPBRkx/jWzRIkYXFHcAEFg
         H8FWTQFc9mscoLgD/7HulFoyuiskmH2vhjFJGpJMK1Wu8xT51fKXQJ5tqAyEHhpX/Xum
         MxOA==
MIME-Version: 1.0
X-Received: by 10.182.112.130 with SMTP id iq2mr4535974obb.57.1386839541271;
 Thu, 12 Dec 2013 01:12:21 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Thu, 12 Dec 2013 01:12:21 -0800 (PST)
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
Date: Thu, 12 Dec 2013 01:12:21 -0800
Message-ID: <CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e01229a0637d26a04ed52bee3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01229a0637d26a04ed52bee3
Content-Type: text/plain; charset=ISO-8859-1

Hey Raymond,

This won't work because AFAIK akka 2.3-M1 is not binary compatible with
akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need to still
use the older protobuf library, so we'd need to support both.

I'd also be concerned about having a reference to a non-released version of
akka. Akka is the source of our hardest-to-find bugs and simultaneously
trying to support 2.2.3 and 2.3-M1 is a bit daunting. Of course, if you are
building off of master you can maintain a fork that uses this.

- Patrick


On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond <raymond.liu@intel.com>wrote:

> Hi Patrick
>
>         What does that means for drop YARN 2.2? seems codes are still
> there. You mean if build upon 2.2 it will break, and won't and work right?
> Since the home made akka build on scala 2.10 are not there. While, if for
> this case, can we just use akka 2.3-M1 which run on protobuf 2.5 for
> replacement?
>
> Best Regards,
> Raymond Liu
>
>
> -----Original Message-----
> From: Patrick Wendell [mailto:pwendell@gmail.com]
> Sent: Thursday, December 12, 2013 4:21 PM
> To: dev@spark.incubator.apache.org
> Subject: Scala 2.10 Merge
>
> Hi Developers,
>
> In the next few days we are planning to merge Scala 2.10 support into
> Spark. For those that haven't been following this, Prashant Sharma has been
> maintaining the scala-2.10 branch of Spark for several months. This branch
> is current with master and has been reviewed for merging:
>
> https://github.com/apache/incubator-spark/tree/scala-2.10
>
> Scala 2.10 support is one of the most requested features for Spark - it
> will be great to get this into Spark 0.9! Please note that *Scala 2.10 is
> not binary compatible with Scala 2.9*. With that in mind, I wanted to give
> a few heads-up/requests to developers:
>
> If you are developing applications on top of Spark's master branch, those
> will need to migrate to Scala 2.10. You may want to download and test the
> current scala-2.10 branch in order to make sure you will be okay as Spark
> developments move forward. Of course, you can always stick with the current
> master commit and be fine (I'll cut a tag when we do the merge in order to
> delineate where the version changes). Please open new threads on the dev
> list to report and discuss any issues.
>
> This merge will temporarily drop support for YARN 2.2 on the master branch.
> This is because the workaround we used was only compiled for Scala 2.9. We
> are going to come up with a more robust solution to YARN 2.2 support before
> releasing 0.9.
>
> Going forward, we will continue to make maintenance releases on branch-0.8
> which will remain compatible with Scala 2.9.
>
> For those interested, the primary code changes in this merge are upgrading
> the akka version, changing the use of Scala 2.9's ClassManifest construct
> to Scala 2.10's ClassTag, and updating the spark shell to work with Scala
> 2.10's repl.
>
> - Patrick
>

--089e01229a0637d26a04ed52bee3--

From dev-return-898-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 09:13:44 2013
Return-Path: <dev-return-898-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7DEEE10BAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 09:13:44 +0000 (UTC)
Received: (qmail 33679 invoked by uid 500); 12 Dec 2013 09:13:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33594 invoked by uid 500); 12 Dec 2013 09:13:44 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 33586 invoked by uid 99); 12 Dec 2013 09:13:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 09:13:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 09:13:37 +0000
Received: by mail-ob0-f171.google.com with SMTP id wp18so116656obc.16
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 01:13:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=cuw5VxqL/QNKRJONXdEvXNfcJgTGGrLMZL0YKtJLdrs=;
        b=l8DMz38N/6YlqxVsTTiumlCUQgzS+5x12dykekn3x03yb3z7Y+IbfxR2AHZXs7dZV/
         x+NuE1tndzj6gxTCAm5ZDIEtQzqed+8kw78QErrh3cVch3O86Ph7jlz4FtAGVnNkCUQO
         uixeZfvwMbmjboRoUTr6/wTSszVz8rYhlXIricC12zW9QJMcoa9blatCKZth55Kx89C7
         4rTwrZJTPmMSy4DL++zV2iwExemFF4RlN4QmySJZnanqLACzHUQjdEE02dogszF+jUA6
         hLvCMaBWCQ44Qg7nJ/Gmi5mGBNySDJ8X9EQmDx7NC1zMFVGmgPNnJSTBqzmfgWR1Oofv
         IjjA==
MIME-Version: 1.0
X-Received: by 10.182.158.71 with SMTP id ws7mr4766925obb.6.1386839596921;
 Thu, 12 Dec 2013 01:13:16 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Thu, 12 Dec 2013 01:13:16 -0800 (PST)
In-Reply-To: <CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
	<CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
Date: Thu, 12 Dec 2013 01:13:16 -0800
Message-ID: <CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e01494a1688fb5804ed52c129
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01494a1688fb5804ed52c129
Content-Type: text/plain; charset=ISO-8859-1

Also - the code is still there because of a recent merge that took in some
newer changes... we'll be removing it for the final merge.


On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Raymond,
>
> This won't work because AFAIK akka 2.3-M1 is not binary compatible with
> akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need to still
> use the older protobuf library, so we'd need to support both.
>
> I'd also be concerned about having a reference to a non-released version
> of akka. Akka is the source of our hardest-to-find bugs and simultaneously
> trying to support 2.2.3 and 2.3-M1 is a bit daunting. Of course, if you are
> building off of master you can maintain a fork that uses this.
>
> - Patrick
>
>
> On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond <raymond.liu@intel.com>wrote:
>
>> Hi Patrick
>>
>>         What does that means for drop YARN 2.2? seems codes are still
>> there. You mean if build upon 2.2 it will break, and won't and work right?
>> Since the home made akka build on scala 2.10 are not there. While, if for
>> this case, can we just use akka 2.3-M1 which run on protobuf 2.5 for
>> replacement?
>>
>> Best Regards,
>> Raymond Liu
>>
>>
>> -----Original Message-----
>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>> Sent: Thursday, December 12, 2013 4:21 PM
>> To: dev@spark.incubator.apache.org
>> Subject: Scala 2.10 Merge
>>
>> Hi Developers,
>>
>> In the next few days we are planning to merge Scala 2.10 support into
>> Spark. For those that haven't been following this, Prashant Sharma has been
>> maintaining the scala-2.10 branch of Spark for several months. This branch
>> is current with master and has been reviewed for merging:
>>
>> https://github.com/apache/incubator-spark/tree/scala-2.10
>>
>> Scala 2.10 support is one of the most requested features for Spark - it
>> will be great to get this into Spark 0.9! Please note that *Scala 2.10 is
>> not binary compatible with Scala 2.9*. With that in mind, I wanted to give
>> a few heads-up/requests to developers:
>>
>> If you are developing applications on top of Spark's master branch, those
>> will need to migrate to Scala 2.10. You may want to download and test the
>> current scala-2.10 branch in order to make sure you will be okay as Spark
>> developments move forward. Of course, you can always stick with the current
>> master commit and be fine (I'll cut a tag when we do the merge in order to
>> delineate where the version changes). Please open new threads on the dev
>> list to report and discuss any issues.
>>
>> This merge will temporarily drop support for YARN 2.2 on the master
>> branch.
>> This is because the workaround we used was only compiled for Scala 2.9.
>> We are going to come up with a more robust solution to YARN 2.2 support
>> before releasing 0.9.
>>
>> Going forward, we will continue to make maintenance releases on
>> branch-0.8 which will remain compatible with Scala 2.9.
>>
>> For those interested, the primary code changes in this merge are
>> upgrading the akka version, changing the use of Scala 2.9's ClassManifest
>> construct to Scala 2.10's ClassTag, and updating the spark shell to work
>> with Scala 2.10's repl.
>>
>> - Patrick
>>
>
>

--089e01494a1688fb5804ed52c129--

From dev-return-899-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 11:06:56 2013
Return-Path: <dev-return-899-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A0EDA10E3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 11:06:56 +0000 (UTC)
Received: (qmail 50539 invoked by uid 500); 12 Dec 2013 11:06:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50357 invoked by uid 500); 12 Dec 2013 11:06:49 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50349 invoked by uid 99); 12 Dec 2013 11:06:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 11:06:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scrapcodes@gmail.com designates 74.125.82.42 as permitted sender)
Received: from [74.125.82.42] (HELO mail-wg0-f42.google.com) (74.125.82.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 11:06:42 +0000
Received: by mail-wg0-f42.google.com with SMTP id a1so507859wgh.5
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 03:06:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=DjNcd4kv5ZwKYKoMBKZlVwhC+jDofeQMqn845k4ZJEM=;
        b=qQKQhuR9JKA7U3xGoJfirYlIJVqi0vQ2LLg2bYtGnuVV9yHdlb1m6NhcMyAJn5IoEE
         DVh/zUAvgSbN6jHcyW0xrQEZgBMJlDE6OYe1yuTk3Ea31ou60Xd90knzTAlk3WmZ0WOK
         rcfn+4Fch7R6DqTzuD+bWjAB8KxXGH/JpSSQu8BehFyMrmo3CtwDBGOEsGqrLewERhMz
         AWkKv/ebNdcwARxWUcqFrQFbzhpXyNcLGMLvw0iquXV3sRDYTJ6AXIAj41QmceOTSh+F
         JNR4JzmWiHMoeQqu0f9lNVqYI3sOGjiaFRKN1YixfqItf90qtKBeYUrfU7Srl6QRq1VR
         B3VA==
X-Received: by 10.194.48.7 with SMTP id h7mr39135wjn.92.1386846382696; Thu, 12
 Dec 2013 03:06:22 -0800 (PST)
MIME-Version: 1.0
Received: by 10.216.39.194 with HTTP; Thu, 12 Dec 2013 03:06:02 -0800 (PST)
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
 <391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
From: Prashant Sharma <scrapcodes@gmail.com>
Date: Thu, 12 Dec 2013 16:36:02 +0530
Message-ID: <CAOYDGoC9gUkPt5iOM6Ry0ejz++mKx7EhfvxT-n0Rya_iNtq40Q@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7ba975e4ffb0a404ed545543
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7ba975e4ffb0a404ed545543
Content-Type: text/plain; charset=ISO-8859-1

Hey Raymond,

I just gave what you said a try but have no intentions of maintaining it.
You might want it helpful
https://github.com/ScrapCodes/incubator-spark/tree/yarn-2.2 incase you are
willing to maintain it.

For the record, above branch is updated to master with scala 2.10 and uses
akka 2.3-M1 if one uses new-yarn and uses akka 2.2.3 otherwise.



On Thu, Dec 12, 2013 at 2:12 PM, Liu, Raymond <raymond.liu@intel.com> wrote:

> Hi Patrick
>
>         What does that means for drop YARN 2.2? seems codes are still
> there. You mean if build upon 2.2 it will break, and won't and work right?
> Since the home made akka build on scala 2.10 are not there. While, if for
> this case, can we just use akka 2.3-M1 which run on protobuf 2.5 for
> replacement?
>
> Best Regards,
> Raymond Liu
>
>
> -----Original Message-----
> From: Patrick Wendell [mailto:pwendell@gmail.com]
> Sent: Thursday, December 12, 2013 4:21 PM
> To: dev@spark.incubator.apache.org
> Subject: Scala 2.10 Merge
>
> Hi Developers,
>
> In the next few days we are planning to merge Scala 2.10 support into
> Spark. For those that haven't been following this, Prashant Sharma has been
> maintaining the scala-2.10 branch of Spark for several months. This branch
> is current with master and has been reviewed for merging:
>
> https://github.com/apache/incubator-spark/tree/scala-2.10
>
> Scala 2.10 support is one of the most requested features for Spark - it
> will be great to get this into Spark 0.9! Please note that *Scala 2.10 is
> not binary compatible with Scala 2.9*. With that in mind, I wanted to give
> a few heads-up/requests to developers:
>
> If you are developing applications on top of Spark's master branch, those
> will need to migrate to Scala 2.10. You may want to download and test the
> current scala-2.10 branch in order to make sure you will be okay as Spark
> developments move forward. Of course, you can always stick with the current
> master commit and be fine (I'll cut a tag when we do the merge in order to
> delineate where the version changes). Please open new threads on the dev
> list to report and discuss any issues.
>
> This merge will temporarily drop support for YARN 2.2 on the master branch.
> This is because the workaround we used was only compiled for Scala 2.9. We
> are going to come up with a more robust solution to YARN 2.2 support before
> releasing 0.9.
>
> Going forward, we will continue to make maintenance releases on branch-0.8
> which will remain compatible with Scala 2.9.
>
> For those interested, the primary code changes in this merge are upgrading
> the akka version, changing the use of Scala 2.9's ClassManifest construct
> to Scala 2.10's ClassTag, and updating the spark shell to work with Scala
> 2.10's repl.
>
> - Patrick
>



-- 
s

--047d7ba975e4ffb0a404ed545543--

From dev-return-900-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 13:30:07 2013
Return-Path: <dev-return-900-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3872410425
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 13:30:07 +0000 (UTC)
Received: (qmail 52622 invoked by uid 500); 12 Dec 2013 13:30:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51933 invoked by uid 500); 12 Dec 2013 13:30:02 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 51907 invoked by uid 99); 12 Dec 2013 13:30:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 13:30:01 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [98.139.212.180] (HELO nm21.bullet.mail.bf1.yahoo.com) (98.139.212.180)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 12 Dec 2013 13:29:56 +0000
Received: from [66.196.81.172] by nm21.bullet.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 13:29:35 -0000
Received: from [98.139.212.239] by tm18.bullet.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 13:29:35 -0000
Received: from [127.0.0.1] by omp1048.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 13:29:35 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 502487.11848.bm@omp1048.mail.bf1.yahoo.com
Received: (qmail 89879 invoked by uid 60001); 12 Dec 2013 13:29:35 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1386854974; bh=TbLCawPsU+PwqHWeoPY1mvs0QAaFAEPzgRCq4Bl8ieY=; h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=r09cQg8GboQtcl4QN4uJvj8Q2qkehBsXDrQYhgdQyLzJ5CUtu1lW33d9JRkQlWSNIKNkyVIkPBT9Hn7Z90WJOsZBQuWvOQh/o9TPUNqezUuQD+ECK/jMQMO56Bbd2iB7Bz9loNIVlteOyG2NamI3IFS8AhMHvpUAVBYSWXoNzIs=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=b+iuh92vfz6Pp3CviRLRdZ8R07UYskMc+HW4inQ2Z3g8TPm31ugdA/pUxpeI81Mf0I71G6Ll0HaJzijZ6P9g/UDN3/zx0ieywV/ayFDzmz25eqKq0F+26u/ysSdF/qmWD4TofcUVKz8RGJPWTKvK9KzcAtNeoSNiuaEjM2BVmnw=;
X-YMail-OSG: auMWkR4VM1ksO0XYeJbv5AuDmDrYNLn5Bei7_eho56_XJob
 KRN9K4DXdQQQi6YfnFhQsKF2zvthlfhglWgi6RIRYgYEIa1WtXrmRrsSI5sG
 ITpeE2hmHFm_z.IenSNPjPouvTxXGei2wmek9sT3ODs5rf47mn97KJ_gkv36
 2vA7ewAeM1HKdP1O6VI2RYsGCoYHzv7L37uhmuM6XlPgAcCghIPvizGR_dBp
 jM2dUV2biCjdAifynnRhuhQIwHjtMWW8uWa7vb3KGHtNKV2h1K6lz9q6cagL
 p5qmbEF7uTpsp8WEwoD7ExFePCcE7ZPDuJeytc.RsPSiVH_e2zgc95gmpHue
 .d8Ssi271UkiLHDB1t1F2EN_hXi6x2wskcWkzPNLbPHep7Ym2bUDJwblrbrc
 iUF6k8ygl1Pd4YaXzY5LVs.J5.omIu5KccTlBNchFulaN9aBgO.yuLWaUVNk
 LJPDkvIJzK_v4izx0KsR9NadixLuNz2AnLRLsxf9.QRUKl7QG_Uspn1ymThZ
 OUd_Yo0dwcFRUK1GXHSeBAmUPW1RfO70_dgYoo7g6XKdCUfAPdwmx1atanp5
 O3ZglM.n58Ex8nDSshTYeS3.PEDz4.mRaMGRSrSZQ3PS_5Zy6Q5QzwOdKZvP
 AJAMvdv2WVePkubePhUvZ83XaEnDJumGhup.DoJVCi6akDSygYPEAZhvXjNz
 2PWXpyPL7y.1pFYAeLBWLlgCy9X_eAicEAwL07XpjZ4baqPqlkgxoQjCs4ue
 X1FCARv9kgPj4RQ--
Received: from [209.131.62.115] by web140106.mail.bf1.yahoo.com via HTTP; Thu, 12 Dec 2013 05:29:34 PST
X-Rocket-MIMEInfo: 002.001,SSByZS1kb3dubG9hZGVkIHRoZSBzb3VyY2UgdGFyYmFsbCBhbmQgaXQgd29ya3Mgbm93LgoKVG9tCgoKCk9uIFdlZG5lc2RheSwgRGVjZW1iZXIgMTEsIDIwMTMgNjoyNyBQTSwgUGF0cmljayBXZW5kZWxsIDxwd2VuZGVsbEBnbWFpbC5jb20.IHdyb3RlOgogCkkgYWxzbyB0YWxrZWQgdG8gYSBmZXcgcGVvcGxlIHdobyBnb3QgY29ycnVwdGVkIGJpbmFyaWVzIHdoZW4KZG93bmxvYWRpbmcgZnJvbSB0aGUgcGVvcGxlLmFwYWNoZSBIVFRQLiBJbiB0aGF0IGNhc2UgdGhlIGNoZWNrc3VtCmZhaWxlZCBidXQgaWYBMAEBAQE-
X-Mailer: YahooMailWebService/0.8.169.609
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>	<CABPQxsu1nYNtFew8FaMcW4z0rJmkOi6g+e5wqk+Duq6yKPYfhQ@mail.gmail.com> <CABPQxstPD-n+aZph7jpWgkgQbuvpCKmPQW2ieOj9VVSSykmzuA@mail.gmail.com>
Message-ID: <1386854974.58230.YahooMailNeo@web140106.mail.bf1.yahoo.com>
Date: Thu, 12 Dec 2013 05:29:34 -0800 (PST)
From: Tom Graves <tgraves_cs@yahoo.com>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
In-Reply-To: <CABPQxstPD-n+aZph7jpWgkgQbuvpCKmPQW2ieOj9VVSSykmzuA@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="-156808750-1371428903-1386854974=:58230"
X-Virus-Checked: Checked by ClamAV on apache.org

---156808750-1371428903-1386854974=:58230
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

I re-downloaded the source tarball and it works now.=0A=0ATom=0A=0A=0A=0AOn=
 Wednesday, December 11, 2013 6:27 PM, Patrick Wendell <pwendell@gmail.com>=
 wrote:=0A =0AI also talked to a few people who got corrupted binaries when=
=0Adownloading from the people.apache HTTP. In that case the checksum=0Afai=
led but if they re-downloaded it worked. So maybe just re-download=0Aand tr=
y again?=0A=0A=0AOn Wed, Dec 11, 2013 at 3:15 PM, Patrick Wendell <pwendell=
@gmail.com> wrote:=0A> Hey Tom,=0A>=0A> I re-verified the signatures and go=
t someone else to do it. It seemed=0A> fine. Here is what I did.=0A>=0A> gp=
g --recv-key 9E4FE3AF=0A> wget http://people.apache.org/~pwendell/spark-0.8=
.1-incubating-rc4/spark-0.8.1-incubating.tgz.asc=0A> wget http://people.apa=
che.org/~pwendell/spark-0.8.1-incubating-rc4/spark-0.8.1-incubating.tgz=0A>=
 gpg --verify spark-0.8.1-incubating.tgz.asc spark-0.8.1-incubating.tgz=0A>=
 gpg: Signature made Tue 10 Dec 2013 02:53:15 PM PST using RSA key ID 9E4FE=
3AF=0A> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"=0A>=
=0A> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com=
> wrote:=0A>> I don't know how to make sense of the numbers, but here's wha=
t I've got=0A>> from a very small sample size.=0A>>=0A>> For both v0.8.0-in=
cubating and v0.8.1-incubating, building separate=0A>> assemblies is faster=
 than `./sbt/sbt assembly` and the times for building=0A>> separate assembl=
ies for 0.8.0 and 0.8.1 are about the same.=0A>>=0A>> For v0.8.0-incubating=
, `./sbt/sbt assembly` takes about 2.5x as long as the=0A>> sum of the sepa=
rate assemblies.=0A>> For v0.8.1-incubating, `./sbt/sbt assembly` takes alm=
ost 8x as long as the=0A>> sum of the separate assemblies.=0A>>=0A>> Weird.=
=0A>>=0A>>=0A>> On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell=
@gmail.com>wrote:=0A>>=0A>>> I'll +1 myself also.=0A>>>=0A>>> For anyone wh=
o has the slow build problem: does this issue happen when=0A>>> building v0=
.8.0-incubating also? Trying to figure out whether it's=0A>>> related to so=
mething we added in 0.8.1 or if it's a long standing=0A>>> issue.=0A>>>=0A>=
>> - Patrick=0A>>>=0A>>> On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <m=
atei.zaharia@gmail.com>=0A>>> wrote:=0A>>> > Woah, weird, but definitely go=
od to know.=0A>>> >=0A>>> > If you=E2=80=99re doing Spark development, ther=
e=E2=80=99s also a more convenient option=0A>>> added by Shivaram in the ma=
ster branch. You can do sbt assemble-deps to=0A>>> package *just* the depen=
dencies of each project in a special assembly JAR,=0A>>> and then use sbt c=
ompile to update the code. This will use the classes=0A>>> directly out of =
the target/scala-2.9.3/classes directories. You have to=0A>>> redo assemble=
-deps only if your external dependencies change.=0A>>> >=0A>>> > Matei=0A>>=
> >=0A>>> > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.=
com>=0A>>> wrote:=0A>>> >=0A>>> >> I hope this PR https://github.com/apache=
/incubator-spark/pull/252 can=0A>>> help.=0A>>> >> Again this is not a bloc=
ker for the release from my side either.=0A>>> >>=0A>>> >>=0A>>> >> On Wed,=
 Dec 11, 2013 at 2:14 PM, Mark Hamstra <mark@clearstorydata.com=0A>>> >wrot=
e:=0A>>> >>=0A>>> >>> Interesting, and confirmed: On my machine where `./sb=
t/sbt assembly`=0A>>> takes=0A>>> >>> a long, long, looooong time to comple=
te (a MBP, in my case), building=0A>>> three=0A>>> >>> separate assemblies =
(`./sbt/sbt assembly/assembly`, `./sbt/sbt=0A>>> >>> examples/assembly`, `.=
/sbt/sbt tools/assembly`) takes much, much less=0A>>> time.=0A>>> >>>=0A>>>=
 >>>=0A>>> >>>=0A>>> >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma =
<=0A>>> scrapcodes@gmail.com=0A>>> >>>> wrote:=0A>>> >>>=0A>>> >>>> forgot =
to mention, after running sbt/sbt assembly/assembly running=0A>>> >>> sbt/s=
bt=0A>>> >>>> examples/assembly takes just 37s. Not to mention my hardware =
is not=0A>>> >>> really=0A>>> >>>> great.=0A>>> >>>>=0A>>> >>>>=0A>>> >>>> =
On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <=0A>>> scrapcodes@gmail.c=
om=0A>>> >>>>> wrote:=0A>>> >>>>=0A>>> >>>>> Hi Patrick and Matei,=0A>>> >>=
>>>=0A>>> >>>>> Was trying out this and followed the quick start guide whic=
h says do=0A>>> >>>>> sbt/sbt assembly, like few others I was also stuck fo=
r few minutes on=0A>>> >>>>> linux. On the other hand if I use sbt/sbt asse=
mbly/assembly it is=0A>>> much=0A>>> >>>>> faster.=0A>>> >>>>>=0A>>> >>>>> =
Should we change the documentation to reflect this. It will not be=0A>>> >>=
> great=0A>>> >>>>> for first time users to get stuck there.=0A>>> >>>>>=0A=
>>> >>>>>=0A>>> >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <=0A>>=
> >>> matei.zaharia@gmail.com=0A>>> >>>>> wrote:=0A>>> >>>>>=0A>>> >>>>>> +=
1=0A>>> >>>>>>=0A>>> >>>>>> Built and tested it on Mac OS X.=0A>>> >>>>>>=
=0A>>> >>>>>> Matei=0A>>> >>>>>>=0A>>> >>>>>>=0A>>> >>>>>> On Dec 10, 2013,=
 at 4:49 PM, Patrick Wendell <pwendell@gmail.com>=0A>>> >>>> wrote:=0A>>> >=
>>>>>=0A>>> >>>>>>> Please vote on releasing the following candidate as Apa=
che Spark=0A>>> >>>>>>> (incubating) version 0.8.1.=0A>>> >>>>>>>=0A>>> >>>=
>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):=0A>>> >>=
>>>>>=0A>>> >>>>>>=0A>>> >>>>=0A>>> >>>=0A>>> https://git-wip-us.apache.org=
/repos/asf/incubator-spark/repo?p=3Dincubator-spark.git;a=3Dcommit;h=3Db87d=
31dd8eb4b4e47c0138e9242d0dd6922c8c4e=0A>>> >>>>>>>=0A>>> >>>>>>> The releas=
e files, including signatures, digests, etc can be found=0A>>> >>> at:=0A>>=
> >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/=0A=
>>> >>>>>>>=0A>>> >>>>>>> Release artifacts are signed with the following k=
ey:=0A>>> >>>>>>> https://people.apache.org/keys/committer/pwendell.asc=0A>=
>> >>>>>>>=0A>>> >>>>>>> The staging repository for this release can be fou=
nd at:=0A>>> >>>>>>>=0A>>> >>>>=0A>>> https://repository.apache.org/content=
/repositories/orgapachespark-040/=0A>>> >>>>>>>=0A>>> >>>>>>> The documenta=
tion corresponding to this release can be found at:=0A>>> >>>>>>>=0A>>> htt=
p://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/=0A>>> >>>>=
>>>=0A>>> >>>>>>> For information about the contents of this release see:=
=0A>>> >>>>>>>=0A>>> >>>>>>=0A>>> >>>>=0A>>> >>>=0A>>> https://git-wip-us.a=
pache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;f=3DCHANGES.txt;h=3Dce=
0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.8=0A>>> >>>>>>>=0A>>> =
>>>>>>> Please vote on releasing this package as Apache Spark=0A>>> >>>> 0.=
8.1-incubating!=0A>>> >>>>>>>=0A>>> >>>>>>> The vote is open until Saturday=
, December 14th at 01:00 UTC and=0A>>> >>>>>>> passes if a majority of at l=
east 3 +1 PPMC votes are cast.=0A>>> >>>>>>>=0A>>> >>>>>>> [ ] +1 Release t=
his package as Apache Spark 0.8.1-incubating=0A>>> >>>>>>> [ ] -1 Do not re=
lease this package because ...=0A>>> >>>>>>>=0A>>> >>>>>>> To learn more ab=
out Apache Spark, please see=0A>>> >>>>>>> http://spark.incubator.apache.or=
g/=0A>>> >>>>>>=0A>>> >>>>>>=0A>>> >>>>>=0A>>> >>>>>=0A>>> >>>>> --=0A>>> >=
>>>> s=0A>>> >>>>>=0A>>> >>>>=0A>>> >>>>=0A>>> >>>>=0A>>> >>>> --=0A>>> >>>=
> s=0A>>> >>>>=0A>>> >>>=0A>>> >>=0A>>> >>=0A>>> >>=0A>>> >> --=0A>>> >> s=
=0A>>> >=0A>>>
---156808750-1371428903-1386854974=:58230--

From dev-return-901-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 15:02:35 2013
Return-Path: <dev-return-901-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AC37E106F2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 15:02:35 +0000 (UTC)
Received: (qmail 29223 invoked by uid 500); 12 Dec 2013 15:02:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29170 invoked by uid 500); 12 Dec 2013 15:02:34 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29158 invoked by uid 99); 12 Dec 2013 15:02:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 15:02:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [216.109.115.223] (HELO nm50-vm4.bullet.mail.bf1.yahoo.com) (216.109.115.223)
    by apache.org (qpsmtpd/0.29) with SMTP; Thu, 12 Dec 2013 15:02:25 +0000
Received: from [66.196.81.174] by nm50.bullet.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 15:02:04 -0000
Received: from [98.139.212.226] by tm20.bullet.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 15:02:04 -0000
Received: from [127.0.0.1] by omp1035.mail.bf1.yahoo.com with NNFMP; 12 Dec 2013 15:02:04 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 424686.3648.bm@omp1035.mail.bf1.yahoo.com
Received: (qmail 72099 invoked by uid 60001); 12 Dec 2013 15:02:04 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1386860524; bh=jG1G8xNNCz0GLC+fzS8lr+rtdnT5rlwUNCOL+eSPO6w=; h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type; b=wqoXvkF6mKlmGTgvW1Xa8QT+TaO+ttdvF4JVBVrXjIcHoWxChZ/XIJvkIUGwSI7Hu+x+HJHnI1i6IKlvclpXSy49X7+gTsgAMA2AJNs2Q0BKUyX7ylVbcno7SiPqyGOC47/03gNOqI7eEIZ6YwYlUujXvRfbNEt6Kq73d+gmdqw=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=X-YMail-OSG:Received:X-Rocket-MIMEInfo:X-Mailer:References:Message-ID:Date:From:Reply-To:Subject:To:In-Reply-To:MIME-Version:Content-Type;
  b=pIqZqxeQU7RAz+a4O0Yrsq6T2tKpD0j09m39EA0AnQRhEFcw3GV2MzAqG5Dbo8pG/8s2masO3U/t+nPN/KCbOaC23dI57o7OW8Rk99tn0eLGMfjcIVqrSBwj37toN+ABJqq6EhwT/ZjdlTmMdwPJSD6IM388AwVIgY+TLSwWUlc=;
X-YMail-OSG: SbM3.NoVM1l710X_t8XWJl81DZqyVc.Q9Z9btSdzU1fHhqI
 NP207vOTF1I3QvQXeM20m1uHA8j68QJjaetIX_oPmF7B5kNEMwz2CoSaKvo9
 6fuQKkk_MVklWJbD_bmVgLftb_bhAv7iLTup78.0q9KeFQjhY1hiE599wWBI
 Dti.T92Tyx9SQReRdj2mx1Wf2TQ8V0uvL42kMCvKBWEq9.2QEd3yhS6rbJe2
 Y.Ux2uAyWC3W8V11LG6Y70JOXp4u6.MIZ4P5ZZ4_HxxGuiW_kQDTx6b_wK2f
 76AI23kJemFYCifjqBbnGIokq2iPwh5bbDBgsYOM5ElM3xPqD0WzjxDhEgBI
 OTcXQoPC7Qhkr4IIrv7gZS5ctOSYKSLW7__ykE0mTWodH68f6UvwbzSCxHaW
 Vjr4vQrKeixdm6D0lHc3z9d76nImiaqszOEEyTd7iLpLzphdK_bCVducUE51
 P0iqpLNFgAcbt0YY6axzLM6oRNQlxEVNWLCeblfBGzLmYHJnPRtu7HDCpEVZ
 _D11RluFBT.RBTETT1XqoKX5j73V9HFLgo8tHwHjB2xi4k_.FAaNfeutObQ1
 AveYaeSN_FdDJgTgNZFX.v7VtIeqD6FDLYffoL8u0KKzJdeifNxWgU5bMh_8
 VLOnzPf54L03fKd7ZxX.oWkSPhCIBKcNdYI46uRdd6aa4bI.N5g--
Received: from [209.131.62.115] by web140106.mail.bf1.yahoo.com via HTTP; Thu, 12 Dec 2013 07:02:03 PST
X-Rocket-MIMEInfo: 002.001,KzEuwqAKCkJ1aWx0IHNwYXJrIG9uIHlhcm4gZm9yIGJvdGggaGFkb29wIDAuMjMgYW5kIGhhZG9vcCAyLjIuMCBvbiByZWRoYXQgbGludXggdXNpbmcgbWF2ZW4uIMKgUmFuIHNvbWUgdGVzdHMgb24gYm90aCBhIHNlY3VyZSBIYWRvb3AgMC4yMyBjbHVzdGVyIGFuZCBhIHNlY3VyZSBIYWRvb3AgMi4yLjAgY2x1c3Rlci4gwqBWZXJpZmllZCBzaWduYXR1cmVzIGFuZCBtZDUuCgpUb20KCgoKT24gVHVlc2RheSwgRGVjZW1iZXIgMTAsIDIwMTMgNjo0OSBQTSwgUGF0cmljayBXZW5kZWxsIDxwd2VuZGVsbEBnbWEBMAEBAQE-
X-Mailer: YahooMailWebService/0.8.169.609
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com> 
Message-ID: <1386860523.14012.YahooMailNeo@web140106.mail.bf1.yahoo.com>
Date: Thu, 12 Dec 2013 07:02:03 -0800 (PST)
From: Tom Graves <tgraves_cs@yahoo.com>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
In-Reply-To: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="-156808750-1711602087-1386860523=:14012"
X-Virus-Checked: Checked by ClamAV on apache.org

---156808750-1711602087-1386860523=:14012
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

+1.=A0=0A=0ABuilt spark on yarn for both hadoop 0.23 and hadoop 2.2.0 on re=
dhat linux using maven. =A0Ran some tests on both a secure Hadoop 0.23 clus=
ter and a secure Hadoop 2.2.0 cluster. =A0Verified signatures and md5.=0A=
=0ATom=0A=0A=0A=0AOn Tuesday, December 10, 2013 6:49 PM, Patrick Wendell <p=
wendell@gmail.com> wrote:=0A =0APlease vote on releasing the following cand=
idate as Apache Spark=0A(incubating) version 0.8.1.=0A=0AThe tag to be vote=
d on is v0.8.1-incubating (commit b87d31d):=0Ahttps://git-wip-us.apache.org=
/repos/asf/incubator-spark/repo?p=3Dincubator-spark.git;a=3Dcommit;h=3Db87d=
31dd8eb4b4e47c0138e9242d0dd6922c8c4e=0A=0AThe release files, including sign=
atures, digests, etc can be found=0A at:=0Ahttp://people.apache.org/~pwende=
ll/spark-0.8.1-incubating-rc4/=0A=0ARelease artifacts are signed with the f=
ollowing key:=0Ahttps://people.apache.org/keys/committer/pwendell.asc=0A=0A=
The staging repository for this release can be found at:=0Ahttps://reposito=
ry.apache.org/content/repositories/orgapachespark-040/=0A=0AThe documentati=
on corresponding to this release can be found at:=0Ahttp://people.apache.or=
g/~pwendell/spark-0.8.1-incubating-rc4-docs/=0A=0AFor information about the=
 contents of this release see:=0Ahttps://git-wip-us.apache.org/repos/asf?p=
=3Dincubator-spark.git;a=3Dblob;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0=
371157ac2def6fe1c;hb=3Dbranch-0.8=0A=0APlease vote on releasing this packag=
e as Apache Spark 0.8.1-incubating!=0A=0AThe vote is open until Saturday, D=
ecember 14th at 01:00 UTC and=0Apasses if a majority of at least 3 +1 PPMC =
votes are cast.=0A=0A[ ] +1 Release this package as Apache Spark 0.8.1-incu=
bating=0A[ ] -1 Do not release this package because ...=0A=0ATo learn more =
about Apache Spark, please see=0Ahttp://spark.incubator.apache.org/
---156808750-1711602087-1386860523=:14012--

From dev-return-902-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 16:56:34 2013
Return-Path: <dev-return-902-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7FCC010A3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 16:56:34 +0000 (UTC)
Received: (qmail 77024 invoked by uid 500); 12 Dec 2013 16:56:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76774 invoked by uid 500); 12 Dec 2013 16:56:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 76766 invoked by uid 99); 12 Dec 2013 16:56:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 16:56:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.212.44 as permitted sender)
Received: from [209.85.212.44] (HELO mail-vb0-f44.google.com) (209.85.212.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 16:56:27 +0000
Received: by mail-vb0-f44.google.com with SMTP id x8so477944vbf.31
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 08:56:06 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=B1Z4nS+KkLrLRWBIQ+GiGuLWublsnuXlZYjlbn4W3yE=;
        b=YyzMQ914Nq5nUyVzRjfxgiQ8SKvNZcLMjj30h2JlMROTfg+HkPquk/XZEb94S19BWP
         iyj75XWpK3U0KVC1oSMVPdE5UGTpLPIg3x0eKoug4Zi5EFQ59/bVu+EnZfGIoGIo1YWg
         Fhxh7+tDzHaTC5o+YTgtsh0QyXITmbozTi+Rc=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=B1Z4nS+KkLrLRWBIQ+GiGuLWublsnuXlZYjlbn4W3yE=;
        b=lWHVM4ZVbZLQ19o2qbCZSTMtRE6ffSy8b5CpXEqDFTK8GEDg/PcgSu8RR2veh0J8dN
         5aXQ5CYRS2RhFtlOklOEW2oSmdRXARya2i1IhOFxosmnYB9iNszHytFKze3lWSoP5uR4
         4wCWt42hOS6uL072VGIb7tIOIb9yFlvritwYMBNrKPwgm7oXcAvzUbW9e/+W7A1ToKp8
         HpinfS81bZzyJmTNtSrY48UAjLXfGw/gumpjHCetDfi/0ZSUnyBC3Z47Q+5AAgRD2uZa
         cqt79PpO0q/WACFL5fsplfT2LL48svKnDNgYFgdYbQt/S0TDsJYenDxfZcqc678VbuCX
         Zn/A==
X-Gm-Message-State: ALoCoQl7IcxAhGUeKOjp6gIa9W1zim++70ryYsd/8yCQrz9w8/ZpXeEB8TrGHXufrreIL7JbIzaS
MIME-Version: 1.0
X-Received: by 10.58.233.2 with SMTP id ts2mr29635vec.78.1386867365919; Thu,
 12 Dec 2013 08:56:05 -0800 (PST)
Received: by 10.220.17.193 with HTTP; Thu, 12 Dec 2013 08:56:05 -0800 (PST)
In-Reply-To: <CAAsvFP=_OeSqCz6JAddbs5+kMu630yLuqeh8V2kFkjacdQLPHg@mail.gmail.com>
References: <0A72D5474816A044BF164916E111EDA401395A55E10C@DEFRCDBG003.de.db.com>
	<CAAsvFP=_OeSqCz6JAddbs5+kMu630yLuqeh8V2kFkjacdQLPHg@mail.gmail.com>
Date: Thu, 12 Dec 2013 08:56:05 -0800
Message-ID: <CADWPM3i=O3L7sSXc4AYpZ_LF1L-vL6+UGgjm1m87gtphAoqwAw@mail.gmail.com>
Subject: Re: Spark API - support for asynchronous calls - Reactive style [I]
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e0115f066b2545304ed5938c7
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0115f066b2545304ed5938c7
Content-Type: text/plain; charset=ISO-8859-1

Mark,

Thanks.  The FutureAction API looks awesome.


On Mon, Dec 9, 2013 at 9:31 AM, Mark Hamstra <mark@clearstorydata.com>wrote:

> Spark has already supported async jobs for awhile now --
> https://github.com/apache/incubator-spark/pull/29, and they even work
> correctly after https://github.com/apache/incubator-spark/pull/232
>
> There are now implicit conversions from RDD to
> AsyncRDDActions<
> https://github.com/apache/incubator-spark/blob/master/core/src/main/scala/org/apache/spark/rdd/AsyncRDDActions.scala
> >,
> where async actions like countAsync are defined.
>
>
> On Mon, Dec 9, 2013 at 5:46 AM, Deenar Toraskar <deenar.toraskar@db.com
> >wrote:
>
> > Classification: For internal use only
> > Hi developers
> >
> > Are there any plans to have Spark (and Shark) APIs that are asynchronous
> > and non blocking? APIs that return Futures and Iteratee/Enumerators would
> > be very useful to users building scalable apps using Spark, specially
> when
> > combined with a fully asynchronous/non-blocking framework like Play!.
> >
> > Something along the lines of ReactiveMongo
> >
> >
> http://stephane.godbillon.com/2012/08/30/reactivemongo-for-scala-unleashing-mongodb-streaming-capabilities-for-realtime-web
> >
> >
> > Deenar
> >
> > ---
> > This e-mail may contain confidential and/or privileged information. If
> you
> > are not the intended recipient (or have received this e-mail in error)
> > please notify the sender immediately and delete this e-mail. Any
> > unauthorized copying, disclosure or distribution of the material in this
> > e-mail is strictly forbidden.
> >
> > Please refer to http://www.db.com/en/content/eu_disclosures.htm for
> > additional EU corporate and regulatory disclosures.
> >
>



-- 
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><http://www.twitter.com/ooyala>

--089e0115f066b2545304ed5938c7--

From dev-return-903-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 16:59:30 2013
Return-Path: <dev-return-903-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3451C10A4F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 16:59:30 +0000 (UTC)
Received: (qmail 80683 invoked by uid 500); 12 Dec 2013 16:59:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80457 invoked by uid 500); 12 Dec 2013 16:59:29 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 80432 invoked by uid 99); 12 Dec 2013 16:59:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 16:59:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ev@ooyala.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 16:59:21 +0000
Received: by mail-vc0-f181.google.com with SMTP id ks9so472895vcb.26
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 08:59:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=xyrBE2jR9dmXR2x45dNXz1VPTqNWU33Z4mIsOBvtd8A=;
        b=IRwZRXGOio/21tZUrVfrnmUeZQkctdPbuuTtGwfatimAxMQbnuJum8hAeYzhdSzIOc
         YPRsiJSWUAIvO6g79G8u4nHrt4JpvuyKRPPnVn15Vd1+ePU+X2LdiPoIE7NUtNzgsLjt
         ERgMh0fklaQ9y8SBu4RDRBSNIPWSlfAw+k/+o=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=xyrBE2jR9dmXR2x45dNXz1VPTqNWU33Z4mIsOBvtd8A=;
        b=ev2ydqz4oz4Ywt6fiOTym270VkQ8MhX/86PdU3UVoKg50t/Sc2Z6j0Gszp/ksa1Z+H
         VvP+KCb7rwmaa4az5ngx4UiGY+v6LbgAoq3Ykd1+Ae2qiBDkrarGLZuLg/H8fHMd+NsQ
         IVTQHFczWwJEUwZtoJqO+yV1f5BG9rD5283QIv41jlZI59fgyeLnkuKI+SYjRyfWeP9s
         V3tKnGZnVvDJvJznKb7bWHTq+y6vFox0hiB7X+ny+lx2qXDcRjS+WQpPVKhKlFA8blYA
         BV7ArMhygAcd29qs/Q2BIpS/L1m6nGA4tvQnGLpLrSb6c5szqsy0WurX9weInOUtKHln
         j1Sg==
X-Gm-Message-State: ALoCoQlFu26fcb8gMXAxCN5eyCV9/J9Qi0Ew4NyehftBRd7NfFeqVGz4tH2QT5RqXnITp69pT0dI
MIME-Version: 1.0
X-Received: by 10.220.69.20 with SMTP id x20mr32585vci.69.1386867540134; Thu,
 12 Dec 2013 08:59:00 -0800 (PST)
Received: by 10.220.17.193 with HTTP; Thu, 12 Dec 2013 08:59:00 -0800 (PST)
In-Reply-To: <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
Date: Thu, 12 Dec 2013 08:59:00 -0800
Message-ID: <CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a8ed01491da04ed594316
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a8ed01491da04ed594316
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

I'd be personally fine with a standard workflow of assemble-deps +
packaging just the Spark files as separate packages, if it speeds up
everyone's development time.


On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com>wrot=
e:

> I don't know how to make sense of the numbers, but here's what I've got
> from a very small sample size.
>
> For both v0.8.0-incubating and v0.8.1-incubating, building separate
> assemblies is faster than `./sbt/sbt assembly` and the times for building
> separate assemblies for 0.8.0 and 0.8.1 are about the same.
>
> For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long as t=
he
> sum of the separate assemblies.
> For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as th=
e
> sum of the separate assemblies.
>
> Weird.
>
>
> On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com
> >wrote:
>
> > I'll +1 myself also.
> >
> > For anyone who has the slow build problem: does this issue happen when
> > building v0.8.0-incubating also? Trying to figure out whether it's
> > related to something we added in 0.8.1 or if it's a long standing
> > issue.
> >
> > - Patrick
> >
> > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <matei.zaharia@gmail.co=
m
> >
> > wrote:
> > > Woah, weird, but definitely good to know.
> > >
> > > If you=92re doing Spark development, there=92s also a more convenient
> option
> > added by Shivaram in the master branch. You can do sbt assemble-deps to
> > package *just* the dependencies of each project in a special assembly
> JAR,
> > and then use sbt compile to update the code. This will use the classes
> > directly out of the target/scala-2.9.3/classes directories. You have to
> > redo assemble-deps only if your external dependencies change.
> > >
> > > Matei
> > >
> > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
> > wrote:
> > >
> > >> I hope this PR https://github.com/apache/incubator-spark/pull/252 ca=
n
> > help.
> > >> Again this is not a blocker for the release from my side either.
> > >>
> > >>
> > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
> mark@clearstorydata.com
> > >wrote:
> > >>
> > >>> Interesting, and confirmed: On my machine where `./sbt/sbt assembly=
`
> > takes
> > >>> a long, long, looooong time to complete (a MBP, in my case), buildi=
ng
> > three
> > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much le=
ss
> > time.
> > >>>
> > >>>
> > >>>
> > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
> > scrapcodes@gmail.com
> > >>>> wrote:
> > >>>
> > >>>> forgot to mention, after running sbt/sbt assembly/assembly running
> > >>> sbt/sbt
> > >>>> examples/assembly takes just 37s. Not to mention my hardware is no=
t
> > >>> really
> > >>>> great.
> > >>>>
> > >>>>
> > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
> > scrapcodes@gmail.com
> > >>>>> wrote:
> > >>>>
> > >>>>> Hi Patrick and Matei,
> > >>>>>
> > >>>>> Was trying out this and followed the quick start guide which says
> do
> > >>>>> sbt/sbt assembly, like few others I was also stuck for few minute=
s
> on
> > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it is
> > much
> > >>>>> faster.
> > >>>>>
> > >>>>> Should we change the documentation to reflect this. It will not b=
e
> > >>> great
> > >>>>> for first time users to get stuck there.
> > >>>>>
> > >>>>>
> > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> > >>> matei.zaharia@gmail.com
> > >>>>> wrote:
> > >>>>>
> > >>>>>> +1
> > >>>>>>
> > >>>>>> Built and tested it on Mac OS X.
> > >>>>>>
> > >>>>>> Matei
> > >>>>>>
> > >>>>>>
> > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <pwendell@gmail.com=
>
> > >>>> wrote:
> > >>>>>>
> > >>>>>>> Please vote on releasing the following candidate as Apache Spar=
k
> > >>>>>>> (incubating) version 0.8.1.
> > >>>>>>>
> > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> > >>>>>>>
> > >>>>>>
> > >>>>
> > >>>
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> > >>>>>>>
> > >>>>>>> The release files, including signatures, digests, etc can be
> found
> > >>> at:
> > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> > >>>>>>>
> > >>>>>>> Release artifacts are signed with the following key:
> > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
> > >>>>>>>
> > >>>>>>> The staging repository for this release can be found at:
> > >>>>>>>
> > >>>>
> > https://repository.apache.org/content/repositories/orgapachespark-040/
> > >>>>>>>
> > >>>>>>> The documentation corresponding to this release can be found at=
:
> > >>>>>>>
> > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> > >>>>>>>
> > >>>>>>> For information about the contents of this release see:
> > >>>>>>>
> > >>>>>>
> > >>>>
> > >>>
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;=
f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
> > >>>>>>>
> > >>>>>>> Please vote on releasing this package as Apache Spark
> > >>>> 0.8.1-incubating!
> > >>>>>>>
> > >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC and
> > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
> > >>>>>>>
> > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > >>>>>>> [ ] -1 Do not release this package because ...
> > >>>>>>>
> > >>>>>>> To learn more about Apache Spark, please see
> > >>>>>>> http://spark.incubator.apache.org/
> > >>>>>>
> > >>>>>>
> > >>>>>
> > >>>>>
> > >>>>> --
> > >>>>> s
> > >>>>>
> > >>>>
> > >>>>
> > >>>>
> > >>>> --
> > >>>> s
> > >>>>
> > >>>
> > >>
> > >>
> > >>
> > >> --
> > >> s
> > >
> >
>



--=20
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><ht=
tp://www.twitter.com/ooyala>

--047d7b3a8ed01491da04ed594316--

From dev-return-904-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 17:04:19 2013
Return-Path: <dev-return-904-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D2C810A89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 17:04:19 +0000 (UTC)
Received: (qmail 89061 invoked by uid 500); 12 Dec 2013 17:04:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88849 invoked by uid 500); 12 Dec 2013 17:04:18 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 88841 invoked by uid 99); 12 Dec 2013 17:04:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 17:04:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.128.177 as permitted sender)
Received: from [209.85.128.177] (HELO mail-ve0-f177.google.com) (209.85.128.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 17:04:11 +0000
Received: by mail-ve0-f177.google.com with SMTP id db12so509054veb.8
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 09:03:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=+/j6aJfDjOWSdMxw2OmTtB6rTW9ZGXK+qi7G620bGFY=;
        b=LYxIlCdH4VIF/WHLz06stWvGpn60/NC7iXipYxgUijH2X0TcaHU765mKMHo6g7a2Gp
         dyNlfoWHUo+btocV4pkfsZ0CiiZuxOBVf3c65SZY51OQYNVz6Fr++sQcNGxMuuZ7T/pc
         Il5tHgULv8xddGhseVDVh0apjsj4GiTAJlFCc=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=+/j6aJfDjOWSdMxw2OmTtB6rTW9ZGXK+qi7G620bGFY=;
        b=WwCFy5S4djOfCLKJMCLy/XlW9S0yO0lf9wttWcDX8UV3xIHp6+zghStS3fVasK8mNK
         t3itCWUrvH3NO+pOvHeDRaGEZ+0gxx3EaSqtXH6Q9GB0bbFkivjzi7bnP9aW6K/8csgo
         mbbF/M7B5ATUqrjcMBQODNIkI1wOWOVkkHyXPQBqzI20zz4X4cAP04LLDYk6aIL1mZhZ
         UpnbV6jIBic6gKedu2zMrcQrPA8PkOXUt/fLQuLhAvm45q0zGqy8e6gCviRBR2a7gNjV
         F1JEu3z/Q2vZMvJBV1yhOUxYbNvIQfABGW5Aw1DNTwUcinjGjb03/p7aLzjNg4l3zsj5
         SVhw==
X-Gm-Message-State: ALoCoQkRRZcK5p0iCDIII35aTvRmWwq/dTN2TJjFQi2cpwguJ3iJj/mKo//KO2eBuGbz87lTU4b1
MIME-Version: 1.0
X-Received: by 10.52.181.4 with SMTP id ds4mr244108vdc.51.1386867831004; Thu,
 12 Dec 2013 09:03:51 -0800 (PST)
Received: by 10.220.17.193 with HTTP; Thu, 12 Dec 2013 09:03:50 -0800 (PST)
In-Reply-To: <CALD+6GPiLTukP3F5JB+t+-80Y4fFpHHCy+CqwdV49+zwp_-xgg@mail.gmail.com>
References: <CALD+6GPiLTukP3F5JB+t+-80Y4fFpHHCy+CqwdV49+zwp_-xgg@mail.gmail.com>
Date: Thu, 12 Dec 2013 09:03:50 -0800
Message-ID: <CADWPM3jLMq4PaorZ9A93ng5W4uFX2YJfi+Q1vFKJb_zydz10vw@mail.gmail.com>
Subject: Re: Intellij IDEA build issues
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=bcaec548aa376af5f804ed595474
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec548aa376af5f804ed595474
Content-Type: text/plain; charset=ISO-8859-1

Nick, have you tried using the latest Scala plug-in, which features native
SBT project imports?   ie you no longer need to run gen-idea.


On Sat, Dec 7, 2013 at 4:15 AM, Nick Pentreath <nick.pentreath@gmail.com>wrote:

> Hi Spark Devs,
>
> Hoping someone cane help me out. No matter what I do, I cannot get Intellij
> to build Spark from source. I am using IDEA 13. I run sbt gen-idea and
> everything seems to work fine.
>
> When I try to build using IDEA, everything compiles but I get the error
> below.
>
> Have any of you come across the same?
>
> ======
>
> Internal error: (java.lang.AssertionError)
> java/nio/channels/FileChannel$MapMode already declared as
> ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
> java.lang.AssertionError: java/nio/channels/FileChannel$MapMode already
> declared as ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
> at
>
> ch.epfl.lamp.fjbg.JInnerClassesAttribute.addEntry(JInnerClassesAttribute.java:74)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:738)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:733)
> at
>
> scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59)
> at scala.collection.immutable.List.foreach(List.scala:76)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.addInnerClasses(GenJVM.scala:733)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.emitClass(GenJVM.scala:200)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.genClass(GenJVM.scala:355)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
> at
>
> scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
> at
>
> scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
> at
>
> scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
> at scala.collection.Iterator$class.foreach(Iterator.scala:772)
> at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
> at
> scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
> at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
> at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:104)
> at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.scala:86)
> at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
> at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
> at xsbt.CachedCompiler0.run(CompilerInterface.scala:123)
> at xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:99)
> at xsbt.CachedCompiler0.run(CompilerInterface.scala:99)
> at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> at
>
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
> at
>
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
> at java.lang.reflect.Method.invoke(Method.java:601)
> at sbt.compiler.AnalyzingCompiler.call(AnalyzingCompiler.scala:102)
> at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:48)
> at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:41)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply$mcV$sp(AggressiveCompile.scala:106)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
> at
>
> sbt.compiler.AggressiveCompile.sbt$compiler$AggressiveCompile$$timed(AggressiveCompile.scala:173)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:105)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:102)
> at scala.Option.foreach(Option.scala:236)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
> at scala.Option.foreach(Option.scala:236)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6.compileScala$1(AggressiveCompile.scala:102)
> at
>
> sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:151)
> at
> sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:89)
> at sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:39)
> at sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:37)
> at sbt.inc.Incremental$.cycle(Incremental.scala:75)
> at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:34)
> at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:33)
> at sbt.inc.Incremental$.manageClassfiles(Incremental.scala:42)
> at sbt.inc.Incremental$.compile(Incremental.scala:33)
> at sbt.inc.IncrementalCompile$.apply(Compile.scala:27)
> at sbt.compiler.AggressiveCompile.compile2(AggressiveCompile.scala:164)
> at sbt.compiler.AggressiveCompile.compile1(AggressiveCompile.scala:73)
> at
>
> org.jetbrains.jps.incremental.scala.local.CompilerImpl.compile(CompilerImpl.scala:61)
> at
>
> org.jetbrains.jps.incremental.scala.local.LocalServer.compile(LocalServer.scala:26)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:118)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:100)
> at scala.util.Either$RightProjection.map(Either.scala:536)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:100)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:99)
> at scala.util.Either$RightProjection.flatMap(Either.scala:523)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:99)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:98)
> at scala.util.Either$RightProjection.flatMap(Either.scala:523)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder.doBuild(ScalaBuilder.scala:98)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilder.build(ScalaBuilder.scala:68)
> at
>
> org.jetbrains.jps.incremental.scala.ScalaBuilderService$ScalaBuilderDecorator.build(ScalaBuilderService.java:42)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.runModuleLevelBuilders(IncProjectBuilder.java:1086)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.runBuildersForChunk(IncProjectBuilder.java:797)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.buildTargetsChunk(IncProjectBuilder.java:845)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.buildChunkIfAffected(IncProjectBuilder.java:760)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.buildChunks(IncProjectBuilder.java:583)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.runBuild(IncProjectBuilder.java:344)
> at
>
> org.jetbrains.jps.incremental.IncProjectBuilder.build(IncProjectBuilder.java:184)
> at org.jetbrains.jps.cmdline.BuildRunner.runBuild(BuildRunner.java:129)
> at org.jetbrains.jps.cmdline.BuildSession.runBuild(BuildSession.java:224)
> at org.jetbrains.jps.cmdline.BuildSession.run(BuildSession.java:113)
> at
>
> org.jetbrains.jps.cmdline.BuildMain$MyMessageHandler$1.run(BuildMain.java:133)
> at
>
> org.jetbrains.jps.service.impl.SharedThreadPoolImpl$1.run(SharedThreadPoolImpl.java:41)
> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
> at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
> at java.util.concurrent.FutureTask.run(FutureTask.java:166)
> at
>
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> at
>
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> at java.lang.Thread.run(Thread.java:722)
>



-- 
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><http://www.twitter.com/ooyala>

--bcaec548aa376af5f804ed595474--

From dev-return-905-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 12 19:52:28 2013
Return-Path: <dev-return-905-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5D79B100D6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Dec 2013 19:52:28 +0000 (UTC)
Received: (qmail 6047 invoked by uid 500); 12 Dec 2013 19:52:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6007 invoked by uid 500); 12 Dec 2013 19:52:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 5997 invoked by uid 99); 12 Dec 2013 19:52:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 19:52:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.214.52] (HELO mail-bk0-f52.google.com) (209.85.214.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Dec 2013 19:52:22 +0000
Received: by mail-bk0-f52.google.com with SMTP id u14so1044854bkz.25
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 11:52:02 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=rZcs9RqHeD+nrc4iSrsWFdCG5MVvBjeTMJZ4N6lsLoE=;
        b=CkO00UZxlnpDq9QmkvMhiIEOqTayRPnP8zys0wFkwSu24pDdbmMc/1zGGuia15tNt+
         Amop0FsYTg0xx06I1u/UD1Vdl650pH1yqLsvPHRiKNAEyXVv3Dlb/+oc+t+KV0EqkP/A
         UE9fz+8mzyALbtE/PG8qdI+3XhM2QgXX4GjePnDfh92xvycteGceJspVIlyEWSj0pJQI
         rVawAXCfMKTLr2y2LDNnqTCRxIJT3f6BYJryVK0XL00bMfAPL0pUIyxn8bCRf/iDH+HI
         5hxnm9Ohd2vVc7Hx5PV3kUNkeHgPVTX+FJ+d78vdcs4Jingt4kD3SpMlux9ZHq+zvkCZ
         0YQw==
X-Gm-Message-State: ALoCoQkfll5BLpBQX3sN5jv36NL9MMTPTMfET3hU9uIe6XTNs9XPDrdT1rPFl+EfKFNMc+h8bYQ3
MIME-Version: 1.0
X-Received: by 10.204.53.75 with SMTP id l11mr3064353bkg.35.1386877921877;
 Thu, 12 Dec 2013 11:52:01 -0800 (PST)
Received: by 10.204.101.201 with HTTP; Thu, 12 Dec 2013 11:52:01 -0800 (PST)
In-Reply-To: <CADWPM3i=O3L7sSXc4AYpZ_LF1L-vL6+UGgjm1m87gtphAoqwAw@mail.gmail.com>
References: <0A72D5474816A044BF164916E111EDA401395A55E10C@DEFRCDBG003.de.db.com>
	<CAAsvFP=_OeSqCz6JAddbs5+kMu630yLuqeh8V2kFkjacdQLPHg@mail.gmail.com>
	<CADWPM3i=O3L7sSXc4AYpZ_LF1L-vL6+UGgjm1m87gtphAoqwAw@mail.gmail.com>
Date: Thu, 12 Dec 2013 11:52:01 -0800
Message-ID: <CAAsvFPnGVHYCDuUw+f0d+1-EC_fvuRHm+TO_-LH76hs0jVNAoQ@mail.gmail.com>
Subject: Re: Spark API - support for asynchronous calls - Reactive style [I]
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c3692ae1c50004ed5bada1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3692ae1c50004ed5bada1
Content-Type: text/plain; charset=ISO-8859-1

I'm having fun with it.  And it's almost all Reynold's work, so I can't
take credit for it.


On Thu, Dec 12, 2013 at 8:56 AM, Evan Chan <ev@ooyala.com> wrote:

> Mark,
>
> Thanks.  The FutureAction API looks awesome.
>
>
> On Mon, Dec 9, 2013 at 9:31 AM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
>
> > Spark has already supported async jobs for awhile now --
> > https://github.com/apache/incubator-spark/pull/29, and they even work
> > correctly after https://github.com/apache/incubator-spark/pull/232
> >
> > There are now implicit conversions from RDD to
> > AsyncRDDActions<
> >
> https://github.com/apache/incubator-spark/blob/master/core/src/main/scala/org/apache/spark/rdd/AsyncRDDActions.scala
> > >,
> > where async actions like countAsync are defined.
> >
> >
> > On Mon, Dec 9, 2013 at 5:46 AM, Deenar Toraskar <deenar.toraskar@db.com
> > >wrote:
> >
> > > Classification: For internal use only
> > > Hi developers
> > >
> > > Are there any plans to have Spark (and Shark) APIs that are
> asynchronous
> > > and non blocking? APIs that return Futures and Iteratee/Enumerators
> would
> > > be very useful to users building scalable apps using Spark, specially
> > when
> > > combined with a fully asynchronous/non-blocking framework like Play!.
> > >
> > > Something along the lines of ReactiveMongo
> > >
> > >
> >
> http://stephane.godbillon.com/2012/08/30/reactivemongo-for-scala-unleashing-mongodb-streaming-capabilities-for-realtime-web
> > >
> > >
> > > Deenar
> > >
> > > ---
> > > This e-mail may contain confidential and/or privileged information. If
> > you
> > > are not the intended recipient (or have received this e-mail in error)
> > > please notify the sender immediately and delete this e-mail. Any
> > > unauthorized copying, disclosure or distribution of the material in
> this
> > > e-mail is strictly forbidden.
> > >
> > > Please refer to http://www.db.com/en/content/eu_disclosures.htm for
> > > additional EU corporate and regulatory disclosures.
> > >
> >
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/>
> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><
> http://www.twitter.com/ooyala>
>

--001a11c3692ae1c50004ed5bada1--

From dev-return-906-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 13 01:57:36 2013
Return-Path: <dev-return-906-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ECE9210073
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Dec 2013 01:57:36 +0000 (UTC)
Received: (qmail 93251 invoked by uid 500); 13 Dec 2013 01:57:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93209 invoked by uid 500); 13 Dec 2013 01:57:36 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 93201 invoked by uid 99); 13 Dec 2013 01:57:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 01:57:36 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of raymond.liu@intel.com designates 134.134.136.24 as permitted sender)
Received: from [134.134.136.24] (HELO mga09.intel.com) (134.134.136.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 01:57:30 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by orsmga102.jf.intel.com with ESMTP; 12 Dec 2013 17:53:23 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.95,476,1384329600"; 
   d="scan'208";a="443459481"
Received: from fmsmsx103.amr.corp.intel.com ([10.19.9.34])
  by fmsmga001.fm.intel.com with ESMTP; 12 Dec 2013 17:57:08 -0800
Received: from fmsmsx153.amr.corp.intel.com (10.19.17.7) by
 FMSMSX103.amr.corp.intel.com (10.19.9.34) with Microsoft SMTP Server (TLS) id
 14.3.123.3; Thu, 12 Dec 2013 17:57:08 -0800
Received: from shsmsx104.ccr.corp.intel.com (10.239.4.70) by
 FMSMSX153.amr.corp.intel.com (10.19.17.7) with Microsoft SMTP Server (TLS) id
 14.3.123.3; Thu, 12 Dec 2013 17:57:08 -0800
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.57]) by
 SHSMSX104.ccr.corp.intel.com ([169.254.5.186]) with mapi id 14.03.0123.003;
 Fri, 13 Dec 2013 09:57:00 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: RE: Scala 2.10 Merge
Thread-Topic: Scala 2.10 Merge
Thread-Index: AQHO9xMxz1T1mh145E+Xto/3UYWafppQOzyA//+FB4CAAABCAIABmqGg
Date: Fri, 13 Dec 2013 01:56:59 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A010F3BBD@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
	<CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
 <CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com>
In-Reply-To: <CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Patrick

	So what's the plan for support Yarn 2.2 in 0.9? As far as I can see, if yo=
u want to support both 2.2 and 2.0 , due to protobuf version incompatible i=
ssue. You need two version of akka anyway.

	Akka 2.3-M1 looks like have a little bit change in API, we probably could =
isolate the code like what we did on yarn part API. I remember that it is m=
entioned that to use reflection for different API is preferred. So the purp=
ose to use reflection is to use one release bin jar to support both version=
 of Hadoop/Yarn on runtime, instead of build different bin jar on compile t=
ime?

	 Then all code related to hadoop will also be built in separate modules fo=
r loading on demand? This sounds to me involve a lot of works. And you stil=
l need to have shim layer and separate code for different version API and d=
epends on different version Akka etc. Sounds like and even strict demands v=
ersus our current approaching on master, and with dynamic class loader in a=
ddition, And the problem we are facing now are still there?

Best Regards,
Raymond Liu

-----Original Message-----
From: Patrick Wendell [mailto:pwendell@gmail.com]=20
Sent: Thursday, December 12, 2013 5:13 PM
To: dev@spark.incubator.apache.org
Subject: Re: Scala 2.10 Merge

Also - the code is still there because of a recent merge that took in some =
newer changes... we'll be removing it for the final merge.


On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com> wrote=
:

> Hey Raymond,
>
> This won't work because AFAIK akka 2.3-M1 is not binary compatible=20
> with akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need=20
> to still use the older protobuf library, so we'd need to support both.
>
> I'd also be concerned about having a reference to a non-released=20
> version of akka. Akka is the source of our hardest-to-find bugs and=20
> simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.=20
> Of course, if you are building off of master you can maintain a fork that=
 uses this.
>
> - Patrick
>
>
> On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond <raymond.liu@intel.com>wro=
te:
>
>> Hi Patrick
>>
>>         What does that means for drop YARN 2.2? seems codes are still=20
>> there. You mean if build upon 2.2 it will break, and won't and work righ=
t?
>> Since the home made akka build on scala 2.10 are not there. While, if=20
>> for this case, can we just use akka 2.3-M1 which run on protobuf 2.5=20
>> for replacement?
>>
>> Best Regards,
>> Raymond Liu
>>
>>
>> -----Original Message-----
>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>> Sent: Thursday, December 12, 2013 4:21 PM
>> To: dev@spark.incubator.apache.org
>> Subject: Scala 2.10 Merge
>>
>> Hi Developers,
>>
>> In the next few days we are planning to merge Scala 2.10 support into=20
>> Spark. For those that haven't been following this, Prashant Sharma=20
>> has been maintaining the scala-2.10 branch of Spark for several=20
>> months. This branch is current with master and has been reviewed for mer=
ging:
>>
>> https://github.com/apache/incubator-spark/tree/scala-2.10
>>
>> Scala 2.10 support is one of the most requested features for Spark -=20
>> it will be great to get this into Spark 0.9! Please note that *Scala=20
>> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I=20
>> wanted to give a few heads-up/requests to developers:
>>
>> If you are developing applications on top of Spark's master branch,=20
>> those will need to migrate to Scala 2.10. You may want to download=20
>> and test the current scala-2.10 branch in order to make sure you will=20
>> be okay as Spark developments move forward. Of course, you can always=20
>> stick with the current master commit and be fine (I'll cut a tag when=20
>> we do the merge in order to delineate where the version changes).=20
>> Please open new threads on the dev list to report and discuss any issues=
.
>>
>> This merge will temporarily drop support for YARN 2.2 on the master=20
>> branch.
>> This is because the workaround we used was only compiled for Scala 2.9.
>> We are going to come up with a more robust solution to YARN 2.2=20
>> support before releasing 0.9.
>>
>> Going forward, we will continue to make maintenance releases on
>> branch-0.8 which will remain compatible with Scala 2.9.
>>
>> For those interested, the primary code changes in this merge are=20
>> upgrading the akka version, changing the use of Scala 2.9's=20
>> ClassManifest construct to Scala 2.10's ClassTag, and updating the=20
>> spark shell to work with Scala 2.10's repl.
>>
>> - Patrick
>>
>
>

From dev-return-907-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 13 04:30:25 2013
Return-Path: <dev-return-907-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A6AE310515
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Dec 2013 04:30:25 +0000 (UTC)
Received: (qmail 55085 invoked by uid 500); 13 Dec 2013 04:28:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55017 invoked by uid 500); 13 Dec 2013 04:27:48 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 54772 invoked by uid 99); 13 Dec 2013 04:27:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 04:27:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.50 as permitted sender)
Received: from [209.85.219.50] (HELO mail-oa0-f50.google.com) (209.85.219.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 04:26:56 +0000
Received: by mail-oa0-f50.google.com with SMTP id n16so1551395oag.9
        for <dev@spark.incubator.apache.org>; Thu, 12 Dec 2013 20:26:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=qBHMj4pB3usKeae/Y95R37wNzxrtazn23Qz10jgyBZY=;
        b=PkB/vLfxvaZZzjsz0AuJG71z4xPqo3ZtuU+DthRL4qmSv03nwcNGRFGN3XRFjkqNbk
         xSyUrFGU8Jlo3An59MzUKOMFn4bOi26t2EEXnunhmKhDFW8WC4HbDYgAigUPpgkNxVDl
         9NmAq0u1YyyBB/hi4UMDAyFO9rfIq3YXkRS2+xSBW2HBgXSxhlwcHVtNprmlT2mh0p1Q
         jCNo5iQvSwhKLC+sqPpmxp4LNlLqMFGOmDgx53dDrdvFoh3MM5L3xMZ2rXsdWE2SEYia
         CUzexVj8fWDyzKAeU0AwSZl4PlPPHa0bS55dOMHyF5OY5uHVohHEqhMHSEOpMJMvMGOK
         qUwg==
MIME-Version: 1.0
X-Received: by 10.182.42.105 with SMTP id n9mr263426obl.33.1386908795433; Thu,
 12 Dec 2013 20:26:35 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Thu, 12 Dec 2013 20:26:35 -0800 (PST)
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F3BBD@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
	<CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
	<CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F3BBD@SHSMSX101.ccr.corp.intel.com>
Date: Thu, 12 Dec 2013 20:26:35 -0800
Message-ID: <CABPQxstm23ZGvZJKWqVaJqfDGjZQ9=BuRzU=Q0X_hhcX7LHDkA@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=14dae939981f1678b804ed62de02
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae939981f1678b804ed62de02
Content-Type: text/plain; charset=ISO-8859-1

Hey Reymond,

Let's move this discussion out of this thread and into the associated JIRA.
I'll write up our current approach over there.

https://spark-project.atlassian.net/browse/SPARK-995

- Patrick


On Thu, Dec 12, 2013 at 5:56 PM, Liu, Raymond <raymond.liu@intel.com> wrote:

> Hi Patrick
>
>         So what's the plan for support Yarn 2.2 in 0.9? As far as I can
> see, if you want to support both 2.2 and 2.0 , due to protobuf version
> incompatible issue. You need two version of akka anyway.
>
>         Akka 2.3-M1 looks like have a little bit change in API, we
> probably could isolate the code like what we did on yarn part API. I
> remember that it is mentioned that to use reflection for different API is
> preferred. So the purpose to use reflection is to use one release bin jar
> to support both version of Hadoop/Yarn on runtime, instead of build
> different bin jar on compile time?
>
>          Then all code related to hadoop will also be built in separate
> modules for loading on demand? This sounds to me involve a lot of works.
> And you still need to have shim layer and separate code for different
> version API and depends on different version Akka etc. Sounds like and even
> strict demands versus our current approaching on master, and with dynamic
> class loader in addition, And the problem we are facing now are still there?
>
> Best Regards,
> Raymond Liu
>
> -----Original Message-----
> From: Patrick Wendell [mailto:pwendell@gmail.com]
> Sent: Thursday, December 12, 2013 5:13 PM
> To: dev@spark.incubator.apache.org
> Subject: Re: Scala 2.10 Merge
>
> Also - the code is still there because of a recent merge that took in some
> newer changes... we'll be removing it for the final merge.
>
>
> On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Hey Raymond,
> >
> > This won't work because AFAIK akka 2.3-M1 is not binary compatible
> > with akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need
> > to still use the older protobuf library, so we'd need to support both.
> >
> > I'd also be concerned about having a reference to a non-released
> > version of akka. Akka is the source of our hardest-to-find bugs and
> > simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.
> > Of course, if you are building off of master you can maintain a fork
> that uses this.
> >
> > - Patrick
> >
> >
> > On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond <raymond.liu@intel.com
> >wrote:
> >
> >> Hi Patrick
> >>
> >>         What does that means for drop YARN 2.2? seems codes are still
> >> there. You mean if build upon 2.2 it will break, and won't and work
> right?
> >> Since the home made akka build on scala 2.10 are not there. While, if
> >> for this case, can we just use akka 2.3-M1 which run on protobuf 2.5
> >> for replacement?
> >>
> >> Best Regards,
> >> Raymond Liu
> >>
> >>
> >> -----Original Message-----
> >> From: Patrick Wendell [mailto:pwendell@gmail.com]
> >> Sent: Thursday, December 12, 2013 4:21 PM
> >> To: dev@spark.incubator.apache.org
> >> Subject: Scala 2.10 Merge
> >>
> >> Hi Developers,
> >>
> >> In the next few days we are planning to merge Scala 2.10 support into
> >> Spark. For those that haven't been following this, Prashant Sharma
> >> has been maintaining the scala-2.10 branch of Spark for several
> >> months. This branch is current with master and has been reviewed for
> merging:
> >>
> >> https://github.com/apache/incubator-spark/tree/scala-2.10
> >>
> >> Scala 2.10 support is one of the most requested features for Spark -
> >> it will be great to get this into Spark 0.9! Please note that *Scala
> >> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I
> >> wanted to give a few heads-up/requests to developers:
> >>
> >> If you are developing applications on top of Spark's master branch,
> >> those will need to migrate to Scala 2.10. You may want to download
> >> and test the current scala-2.10 branch in order to make sure you will
> >> be okay as Spark developments move forward. Of course, you can always
> >> stick with the current master commit and be fine (I'll cut a tag when
> >> we do the merge in order to delineate where the version changes).
> >> Please open new threads on the dev list to report and discuss any
> issues.
> >>
> >> This merge will temporarily drop support for YARN 2.2 on the master
> >> branch.
> >> This is because the workaround we used was only compiled for Scala 2.9.
> >> We are going to come up with a more robust solution to YARN 2.2
> >> support before releasing 0.9.
> >>
> >> Going forward, we will continue to make maintenance releases on
> >> branch-0.8 which will remain compatible with Scala 2.9.
> >>
> >> For those interested, the primary code changes in this merge are
> >> upgrading the akka version, changing the use of Scala 2.9's
> >> ClassManifest construct to Scala 2.10's ClassTag, and updating the
> >> spark shell to work with Scala 2.10's repl.
> >>
> >> - Patrick
> >>
> >
> >
>

--14dae939981f1678b804ed62de02--

From dev-return-908-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 13 19:26:54 2013
Return-Path: <dev-return-908-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2601710141
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Dec 2013 19:26:54 +0000 (UTC)
Received: (qmail 99183 invoked by uid 500); 13 Dec 2013 19:26:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99068 invoked by uid 500); 13 Dec 2013 19:26:53 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 98575 invoked by uid 99); 13 Dec 2013 19:26:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 19:26:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andykonwinski@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Dec 2013 19:26:47 +0000
Received: by mail-wg0-f51.google.com with SMTP id b13so2267870wgh.18
        for <multiple recipients>; Fri, 13 Dec 2013 11:26:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=uZDnxpsw9Y+Guo34QE0vIQXT+HxKObfQERkbtIJilBc=;
        b=OTGBwZRO4yxKOd8CxyPq3hdYQoof6LcakWHkJgWVrCeKUME8aFAodyVVv+3Kq0Yfc9
         sRpNM7/h+h3y31fiQ7Ldhc4rYF/Yz29qRybHnOw/rOuV11qlEZ87TH5le2jefHaI/ppr
         eW8x/GNK1IJWsTZ6qJaX60cT5HTuXir+X48PHuU9SKgdL3uLIysAUqkhw+kl3UWZ06ue
         ispGN8wAxr2/AZIgl+noMmQPDhZHYLYyJvjwO/rSjHwxOrJE5xkv61iaHrMEI9RejT+Q
         VPxtSs/TvXyiJeGAWjNWIj7LMuaGcu0nKpl9NZ1DKakLLxnhgyrXwekV5ZJwsOMZDw3A
         UpuQ==
MIME-Version: 1.0
X-Received: by 10.194.189.70 with SMTP id gg6mr961135wjc.91.1386962786547;
 Fri, 13 Dec 2013 11:26:26 -0800 (PST)
Received: by 10.216.26.1 with HTTP; Fri, 13 Dec 2013 11:26:26 -0800 (PST)
Date: Fri, 13 Dec 2013 11:26:26 -0800
Message-ID: <CALEZFQwSZvqEPKwXN5dKw36EwtHJeAEGWEWbitXBY+rWep+u4A@mail.gmail.com>
Subject: Spark Summit 2013 videos available now
From: Andy Konwinski <andykonwinski@gmail.com>
To: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7bd6bac835808e04ed6f705d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd6bac835808e04ed6f705d
Content-Type: text/plain; charset=ISO-8859-1

Hi Spark user@ and dev@ list members,

We are happy to announce that videos and slides of all talks from the first
Spark Summit last week, Dec 2-3 in Downtown SF, are now available on the
Spark Summit 2013 webpage at http://spark-summit.org/summit-2013. There is
a link for each talk's slides and video next to the talk's title in the
summit agenda. There are also links to the YouTube playlists for each
Summit session (Keynotes<http://www.youtube.com/playlist?list=PL-x35fyliRwjXj33QvAXN0Vlx0gc6u0je>,
Track A<http://www.youtube.com/playlist?list=PL-x35fyliRwiNcKwIkDEQZBejiqxEJ79U>,
Track B<http://www.youtube.com/playlist?list=PL-x35fyliRwh6YpI80pu2t0JDVHXOtU7y>,
and Training Day<http://www.youtube.com/playlist?list=PL-x35fyliRwjR1Umntxz52zv3EcKpbzCp>
).

You can also now pre-register for Summit
2014<http://spark-summit.org/2014/pre-register>to get notified when
tickets go on sale. Finally please let us know if you
have feedback from the Summit.

Enjoy the videos!

Andy

--047d7bd6bac835808e04ed6f705d--

From dev-return-909-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 02:38:08 2013
Return-Path: <dev-return-909-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4D9C610CC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 02:38:08 +0000 (UTC)
Received: (qmail 60906 invoked by uid 500); 14 Dec 2013 02:38:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60879 invoked by uid 500); 14 Dec 2013 02:38:08 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 60871 invoked by uid 99); 14 Dec 2013 02:38:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 02:38:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 02:38:04 +0000
Received: by mail-ob0-f172.google.com with SMTP id gq1so2804456obb.3
        for <dev@spark.incubator.apache.org>; Fri, 13 Dec 2013 18:37:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=1nrJUao38x4IOz4w4Mh5uoTnokbceUYmd3J781+Huuw=;
        b=BAQraZQHMGFeq8R8/8t0jpY2rKvYmHso0q4hGjlfYVFMvG7FpZEpUqBcHc9GGKubqH
         vcxmToOQ8CbAgOs+1V0RqVR+CyYUW3W5QryRiwxSthb1GHdFYGABHqimE2pYgpojMDPe
         NR2L7FOm8uRqj3Zh5ZMRPhoq4Yfp8gzPg1xt7TZ3auLeSe8udPBCiQSaP9L5CpNxgJkX
         F4Ks2wBt6fisSW4AUsfTYsv0Sw5Idmajm42drmj5oMwRfmph/copXR5VxOyrE1ftfwKH
         gEychjbamIdhU05TxUkpOymp2XnYzYYUFK25rl7zky+rYBWBWJd2ZVlJxanj2pmD+Mpa
         U+aA==
MIME-Version: 1.0
X-Received: by 10.182.148.106 with SMTP id tr10mr3880320obb.65.1386988663518;
 Fri, 13 Dec 2013 18:37:43 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Fri, 13 Dec 2013 18:37:43 -0800 (PST)
In-Reply-To: <CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
Date: Fri, 13 Dec 2013 18:37:43 -0800
Message-ID: <CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e012940d898bb5704ed757682
X-Virus-Checked: Checked by ClamAV on apache.org

--089e012940d898bb5704ed757682
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or -1
votes.

+1 (5 Total)
Matei Zaharia*
Nick Pentreath*
Patrick Wendell*
Prashant Sharma*
Tom Graves*

0 (0 Total)

-1 (0 Total)

* =3D Binding Vote

As per the incubator release guide [1] I'll be sending this to the
general incubator list for a final vote from IPMC members.

[1]
http://incubator.apache.org/guides/releasemanagement.html#best-practice-inc=
ubator-release-
vote


On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:

> I'd be personally fine with a standard workflow of assemble-deps +
> packaging just the Spark files as separate packages, if it speeds up
> everyone's development time.
>
>
> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
>
> > I don't know how to make sense of the numbers, but here's what I've got
> > from a very small sample size.
> >
> > For both v0.8.0-incubating and v0.8.1-incubating, building separate
> > assemblies is faster than `./sbt/sbt assembly` and the times for buildi=
ng
> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
> >
> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long as
> the
> > sum of the separate assemblies.
> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as
> the
> > sum of the separate assemblies.
> >
> > Weird.
> >
> >
> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com
> > >wrote:
> >
> > > I'll +1 myself also.
> > >
> > > For anyone who has the slow build problem: does this issue happen whe=
n
> > > building v0.8.0-incubating also? Trying to figure out whether it's
> > > related to something we added in 0.8.1 or if it's a long standing
> > > issue.
> > >
> > > - Patrick
> > >
> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
> matei.zaharia@gmail.com
> > >
> > > wrote:
> > > > Woah, weird, but definitely good to know.
> > > >
> > > > If you=92re doing Spark development, there=92s also a more convenie=
nt
> > option
> > > added by Shivaram in the master branch. You can do sbt assemble-deps =
to
> > > package *just* the dependencies of each project in a special assembly
> > JAR,
> > > and then use sbt compile to update the code. This will use the classe=
s
> > > directly out of the target/scala-2.9.3/classes directories. You have =
to
> > > redo assemble-deps only if your external dependencies change.
> > > >
> > > > Matei
> > > >
> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com>
> > > wrote:
> > > >
> > > >> I hope this PR https://github.com/apache/incubator-spark/pull/252c=
an
> > > help.
> > > >> Again this is not a blocker for the release from my side either.
> > > >>
> > > >>
> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
> > mark@clearstorydata.com
> > > >wrote:
> > > >>
> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
> assembly`
> > > takes
> > > >>> a long, long, looooong time to complete (a MBP, in my case),
> building
> > > three
> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much
> less
> > > time.
> > > >>>
> > > >>>
> > > >>>
> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
> > > scrapcodes@gmail.com
> > > >>>> wrote:
> > > >>>
> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly runni=
ng
> > > >>> sbt/sbt
> > > >>>> examples/assembly takes just 37s. Not to mention my hardware is
> not
> > > >>> really
> > > >>>> great.
> > > >>>>
> > > >>>>
> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
> > > scrapcodes@gmail.com
> > > >>>>> wrote:
> > > >>>>
> > > >>>>> Hi Patrick and Matei,
> > > >>>>>
> > > >>>>> Was trying out this and followed the quick start guide which sa=
ys
> > do
> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
> minutes
> > on
> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it =
is
> > > much
> > > >>>>> faster.
> > > >>>>>
> > > >>>>> Should we change the documentation to reflect this. It will not
> be
> > > >>> great
> > > >>>>> for first time users to get stuck there.
> > > >>>>>
> > > >>>>>
> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
> > > >>> matei.zaharia@gmail.com
> > > >>>>> wrote:
> > > >>>>>
> > > >>>>>> +1
> > > >>>>>>
> > > >>>>>> Built and tested it on Mac OS X.
> > > >>>>>>
> > > >>>>>> Matei
> > > >>>>>>
> > > >>>>>>
> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
> pwendell@gmail.com>
> > > >>>> wrote:
> > > >>>>>>
> > > >>>>>>> Please vote on releasing the following candidate as Apache
> Spark
> > > >>>>>>> (incubating) version 0.8.1.
> > > >>>>>>>
> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d):
> > > >>>>>>>
> > > >>>>>>
> > > >>>>
> > > >>>
> > >
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
> > > >>>>>>>
> > > >>>>>>> The release files, including signatures, digests, etc can be
> > found
> > > >>> at:
> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4=
/
> > > >>>>>>>
> > > >>>>>>> Release artifacts are signed with the following key:
> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
> > > >>>>>>>
> > > >>>>>>> The staging repository for this release can be found at:
> > > >>>>>>>
> > > >>>>
> > > https://repository.apache.org/content/repositories/orgapachespark-040=
/
> > > >>>>>>>
> > > >>>>>>> The documentation corresponding to this release can be found
> at:
> > > >>>>>>>
> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
> > > >>>>>>>
> > > >>>>>>> For information about the contents of this release see:
> > > >>>>>>>
> > > >>>>>>
> > > >>>>
> > > >>>
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob;=
f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0.=
8
> > > >>>>>>>
> > > >>>>>>> Please vote on releasing this package as Apache Spark
> > > >>>> 0.8.1-incubating!
> > > >>>>>>>
> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC a=
nd
> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
> > > >>>>>>>
> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
> > > >>>>>>> [ ] -1 Do not release this package because ...
> > > >>>>>>>
> > > >>>>>>> To learn more about Apache Spark, please see
> > > >>>>>>> http://spark.incubator.apache.org/
> > > >>>>>>
> > > >>>>>>
> > > >>>>>
> > > >>>>>
> > > >>>>> --
> > > >>>>> s
> > > >>>>>
> > > >>>>
> > > >>>>
> > > >>>>
> > > >>>> --
> > > >>>> s
> > > >>>>
> > > >>>
> > > >>
> > > >>
> > > >>
> > > >> --
> > > >> s
> > > >
> > >
> >
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/>
> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><
> http://www.twitter.com/ooyala>
>

--089e012940d898bb5704ed757682--

From dev-return-910-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 08:59:54 2013
Return-Path: <dev-return-910-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B72EA10317
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 08:59:54 +0000 (UTC)
Received: (qmail 57774 invoked by uid 500); 14 Dec 2013 08:59:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57669 invoked by uid 500); 14 Dec 2013 08:59:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 57647 invoked by uid 99); 14 Dec 2013 08:59:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 08:59:51 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.182 as permitted sender)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 08:59:47 +0000
Received: by mail-ob0-f182.google.com with SMTP id wp4so2968383obc.13
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 00:59:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=GJqwHosy++olQhqKALPwrJro3QKxG3+BHPbASo9qerg=;
        b=CJm4LvVZS15dDsJfSCvF8Z6dRaTSYqwP8OrPzHvF3utihK1l4Ik6N8QotFe0LLbVpc
         b5Y6LSYKfqFKvXW2IlZkGSqlJMuwNbUALbcbR3Ij84Eqfu1kW52ViQTcRigHyUTkiKIv
         oJ9IT8qjqYOwY2ow6Eyr+3ZhF3zxR5vItQaNQM2sCfBYoUfm2MH2ZEOKfMsJ9hQy6IcP
         6lFOOMa0AJolfeLRnBxsLpFjoSQvTPrNKmPVyrYTDIXCQMKk+GhSPJ3nR0Y0/Irr4ML2
         EdL2y1132ziRGBTmsq+lY5fLEbrAZoYwPjBMPGpSQPxzi957UYU4D0J6nM+Sp7701Sgk
         Eblw==
MIME-Version: 1.0
X-Received: by 10.60.68.135 with SMTP id w7mr4679527oet.37.1387011566525; Sat,
 14 Dec 2013 00:59:26 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sat, 14 Dec 2013 00:59:26 -0800 (PST)
In-Reply-To: <CABPQxstm23ZGvZJKWqVaJqfDGjZQ9=BuRzU=Q0X_hhcX7LHDkA@mail.gmail.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com>
	<CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com>
	<CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F3BBD@SHSMSX101.ccr.corp.intel.com>
	<CABPQxstm23ZGvZJKWqVaJqfDGjZQ9=BuRzU=Q0X_hhcX7LHDkA@mail.gmail.com>
Date: Sat, 14 Dec 2013 00:59:26 -0800
Message-ID: <CABPQxstv2XqzYKqEDaVEKU-qeP1E3ULxkCGNnAbD8-W6v3g1WQ@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Alright I just merged this in - so Spark is officially "Scala 2.10"
from here forward.

For reference I cut a new branch called scala-2.9 with the commit
immediately prior to the merge:
https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-spark.git;a=shortlog;h=refs/heads/scala-2.9

- Patrick

On Thu, Dec 12, 2013 at 8:26 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hey Reymond,
>
> Let's move this discussion out of this thread and into the associated JIRA.
> I'll write up our current approach over there.
>
> https://spark-project.atlassian.net/browse/SPARK-995
>
> - Patrick
>
>
> On Thu, Dec 12, 2013 at 5:56 PM, Liu, Raymond <raymond.liu@intel.com> wrote:
>>
>> Hi Patrick
>>
>>         So what's the plan for support Yarn 2.2 in 0.9? As far as I can
>> see, if you want to support both 2.2 and 2.0 , due to protobuf version
>> incompatible issue. You need two version of akka anyway.
>>
>>         Akka 2.3-M1 looks like have a little bit change in API, we
>> probably could isolate the code like what we did on yarn part API. I
>> remember that it is mentioned that to use reflection for different API is
>> preferred. So the purpose to use reflection is to use one release bin jar to
>> support both version of Hadoop/Yarn on runtime, instead of build different
>> bin jar on compile time?
>>
>>          Then all code related to hadoop will also be built in separate
>> modules for loading on demand? This sounds to me involve a lot of works. And
>> you still need to have shim layer and separate code for different version
>> API and depends on different version Akka etc. Sounds like and even strict
>> demands versus our current approaching on master, and with dynamic class
>> loader in addition, And the problem we are facing now are still there?
>>
>> Best Regards,
>> Raymond Liu
>>
>> -----Original Message-----
>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>> Sent: Thursday, December 12, 2013 5:13 PM
>> To: dev@spark.incubator.apache.org
>> Subject: Re: Scala 2.10 Merge
>>
>> Also - the code is still there because of a recent merge that took in some
>> newer changes... we'll be removing it for the final merge.
>>
>>
>> On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Hey Raymond,
>> >
>> > This won't work because AFAIK akka 2.3-M1 is not binary compatible
>> > with akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need
>> > to still use the older protobuf library, so we'd need to support both.
>> >
>> > I'd also be concerned about having a reference to a non-released
>> > version of akka. Akka is the source of our hardest-to-find bugs and
>> > simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.
>> > Of course, if you are building off of master you can maintain a fork
>> > that uses this.
>> >
>> > - Patrick
>> >
>> >
>> > On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond
>> > <raymond.liu@intel.com>wrote:
>> >
>> >> Hi Patrick
>> >>
>> >>         What does that means for drop YARN 2.2? seems codes are still
>> >> there. You mean if build upon 2.2 it will break, and won't and work
>> >> right?
>> >> Since the home made akka build on scala 2.10 are not there. While, if
>> >> for this case, can we just use akka 2.3-M1 which run on protobuf 2.5
>> >> for replacement?
>> >>
>> >> Best Regards,
>> >> Raymond Liu
>> >>
>> >>
>> >> -----Original Message-----
>> >> From: Patrick Wendell [mailto:pwendell@gmail.com]
>> >> Sent: Thursday, December 12, 2013 4:21 PM
>> >> To: dev@spark.incubator.apache.org
>> >> Subject: Scala 2.10 Merge
>> >>
>> >> Hi Developers,
>> >>
>> >> In the next few days we are planning to merge Scala 2.10 support into
>> >> Spark. For those that haven't been following this, Prashant Sharma
>> >> has been maintaining the scala-2.10 branch of Spark for several
>> >> months. This branch is current with master and has been reviewed for
>> >> merging:
>> >>
>> >> https://github.com/apache/incubator-spark/tree/scala-2.10
>> >>
>> >> Scala 2.10 support is one of the most requested features for Spark -
>> >> it will be great to get this into Spark 0.9! Please note that *Scala
>> >> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I
>> >> wanted to give a few heads-up/requests to developers:
>> >>
>> >> If you are developing applications on top of Spark's master branch,
>> >> those will need to migrate to Scala 2.10. You may want to download
>> >> and test the current scala-2.10 branch in order to make sure you will
>> >> be okay as Spark developments move forward. Of course, you can always
>> >> stick with the current master commit and be fine (I'll cut a tag when
>> >> we do the merge in order to delineate where the version changes).
>> >> Please open new threads on the dev list to report and discuss any
>> >> issues.
>> >>
>> >> This merge will temporarily drop support for YARN 2.2 on the master
>> >> branch.
>> >> This is because the workaround we used was only compiled for Scala 2.9.
>> >> We are going to come up with a more robust solution to YARN 2.2
>> >> support before releasing 0.9.
>> >>
>> >> Going forward, we will continue to make maintenance releases on
>> >> branch-0.8 which will remain compatible with Scala 2.9.
>> >>
>> >> For those interested, the primary code changes in this merge are
>> >> upgrading the akka version, changing the use of Scala 2.9's
>> >> ClassManifest construct to Scala 2.10's ClassTag, and updating the
>> >> spark shell to work with Scala 2.10's repl.
>> >>
>> >> - Patrick
>> >>
>> >
>> >
>
>

From dev-return-911-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 09:54:07 2013
Return-Path: <dev-return-911-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EC0C1040F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 09:54:07 +0000 (UTC)
Received: (qmail 6291 invoked by uid 500); 14 Dec 2013 09:54:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6091 invoked by uid 500); 14 Dec 2013 09:53:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 5946 invoked by uid 99); 14 Dec 2013 09:53:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 09:53:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.49 as permitted sender)
Received: from [209.85.216.49] (HELO mail-qa0-f49.google.com) (209.85.216.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 09:53:44 +0000
Received: by mail-qa0-f49.google.com with SMTP id ii20so217630qab.8
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 01:53:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:in-reply-to:references:from:to:subject
         :content-type;
        bh=kVHAfUD7okN95NOO/QW7zJc//buZNxaNcEgxQtjnYsg=;
        b=DcQWM4niF7mxl4JmlsvW9Q74UbSC5ihrjZ38rC6aSFSlJnwiLb66X8NEG36PTWLm07
         Cz5rI44iOoGwBaModJCldNkQhW2O4DpOtqlcMVU+FJS/Gkqz8s3tshDfnhDPvuHgR8Wx
         tM7yCx2jyDwe9+jvVW3mlb/2Jf1FS0ATtWwKS4w2aFbpG1NkQ5RvTonYFf0eoW4uYXEk
         qJ8915MhsENz+qhU/PMW28GwJLhcLdS8Wj7dWj3phX/i/haojZ71MO8b6hzgr4mtjSrU
         KfqeOmS+LXnlH7jjXP89sUbwGm+A4g7tDKb/9psidFSTRdClIdVPDPZ/iLYf9JkYIbPt
         sd9Q==
X-Received: by 10.224.168.13 with SMTP id s13mr12840174qay.18.1387014803875;
        Sat, 14 Dec 2013 01:53:23 -0800 (PST)
Received: from [127.0.0.1] (ec2-54-235-159-161.compute-1.amazonaws.com. [54.235.159.161])
        by mx.google.com with ESMTPSA id w5sm18061416qat.10.2013.12.14.01.53.23
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 14 Dec 2013 01:53:23 -0800 (PST)
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Date: Sat, 14 Dec 2013 01:53:23 -0800 (PST)
Message-Id: <1387014802830.183f5682@Nodemailer>
In-Reply-To: <CABPQxstv2XqzYKqEDaVEKU-qeP1E3ULxkCGNnAbD8-W6v3g1WQ@mail.gmail.com>
References: <CABPQxstv2XqzYKqEDaVEKU-qeP1E3ULxkCGNnAbD8-W6v3g1WQ@mail.gmail.com>
X-Orchestra-Oid: 29C06D16-7DAF-4BAA-A009-DA724B2826CD
X-Orchestra-Sig: 1a3ef1dd5e9cb3198c1909e13481db4b34e276fb
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1454203463662873092
X-Orchestra-Thrid-Sig: 8f04b740b7f33ea89d5ca7bd151f9a5fda3bc802
X-Orchestra-Account: 2b923ff26f72b6f81f81d7e9f4bec80199dbebc8
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Subject: Re: Scala 2.10 Merge
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1387014803171"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1387014803171
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Whoohoo!

Great job everyone especially Prashant!

=E2=80=94
Sent from Mailbox for iPhone

On Sat, Dec 14, 2013 at 10:59 AM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Alright I just merged this in - so Spark is officially =22Scala 2.10=22
> from here forward.
> For reference I cut a new branch called scala-2.9 with the commit
> immediately prior to the merge:
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo=3Fp=3Dincuba=
tor-spark.git;a=3Dshortlog;h=3Drefs/heads/scala-2.9
> - Patrick
> On Thu, Dec 12, 2013 at 8:26 PM, Patrick Wendell <pwendell@gmail.com> =
wrote:
>> Hey Reymond,
>>
>> Let's move this discussion out of this thread and into the associated =
JIRA.
>> I'll write up our current approach over there.
>>
>> https://spark-project.atlassian.net/browse/SPARK-995
>>
>> - Patrick
>>
>>
>> On Thu, Dec 12, 2013 at 5:56 PM, Liu, Raymond <raymond.liu@intel.com> =
wrote:
>>>
>>> Hi Patrick
>>>
>>>         So what's the plan for support Yarn 2.2 in 0.9=3F As far as I =
can
>>> see, if you want to support both 2.2 and 2.0 , due to protobuf version
>>> incompatible issue. You need two version of akka anyway.
>>>
>>>         Akka 2.3-M1 looks like have a little bit change in API, we
>>> probably could isolate the code like what we did on yarn part API. I
>>> remember that it is mentioned that to use reflection for different API =
is
>>> preferred. So the purpose to use reflection is to use one release bin =
jar to
>>> support both version of Hadoop/Yarn on runtime, instead of build =
different
>>> bin jar on compile time=3F
>>>
>>>          Then all code related to hadoop will also be built in =
separate
>>> modules for loading on demand=3F This sounds to me involve a lot of =
works. And
>>> you still need to have shim layer and separate code for different =
version
>>> API and depends on different version Akka etc. Sounds like and even =
strict
>>> demands versus our current approaching on master, and with dynamic =
class
>>> loader in addition, And the problem we are facing now are still =
there=3F
>>>
>>> Best Regards,
>>> Raymond Liu
>>>
>>> -----Original Message-----
>>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>>> Sent: Thursday, December 12, 2013 5:13 PM
>>> To: dev@spark.incubator.apache.org
>>> Subject: Re: Scala 2.10 Merge
>>>
>>> Also - the code is still there because of a recent merge that took in =
some
>>> newer changes... we'll be removing it for the final merge.
>>>
>>>
>>> On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>> > Hey Raymond,
>>> >
>>> > This won't work because AFAIK akka 2.3-M1 is not binary compatible
>>> > with akka 2.2.3 (right=3F). For all of the non-yarn 2.2 versions we =
need
>>> > to still use the older protobuf library, so we'd need to support both=
.
>>> >
>>> > I'd also be concerned about having a reference to a non-released
>>> > version of akka. Akka is the source of our hardest-to-find bugs and
>>> > simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.
>>> > Of course, if you are building off of master you can maintain a fork
>>> > that uses this.
>>> >
>>> > - Patrick
>>> >
>>> >
>>> > On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond
>>> > <raymond.liu@intel.com>wrote:
>>> >
>>> >> Hi Patrick
>>> >>
>>> >>         What does that means for drop YARN 2.2=3F seems codes are =
still
>>> >> there. You mean if build upon 2.2 it will break, and won't and work
>>> >> right=3F
>>> >> Since the home made akka build on scala 2.10 are not there. While, =
if
>>> >> for this case, can we just use akka 2.3-M1 which run on protobuf 2.=
5
>>> >> for replacement=3F
>>> >>
>>> >> Best Regards,
>>> >> Raymond Liu
>>> >>
>>> >>
>>> >> -----Original Message-----
>>> >> From: Patrick Wendell [mailto:pwendell@gmail.com]
>>> >> Sent: Thursday, December 12, 2013 4:21 PM
>>> >> To: dev@spark.incubator.apache.org
>>> >> Subject: Scala 2.10 Merge
>>> >>
>>> >> Hi Developers,
>>> >>
>>> >> In the next few days we are planning to merge Scala 2.10 support =
into
>>> >> Spark. For those that haven't been following this, Prashant Sharma
>>> >> has been maintaining the scala-2.10 branch of Spark for several
>>> >> months. This branch is current with master and has been reviewed =
for
>>> >> merging:
>>> >>
>>> >> https://github.com/apache/incubator-spark/tree/scala-2.10
>>> >>
>>> >> Scala 2.10 support is one of the most requested features for Spark =
-
>>> >> it will be great to get this into Spark 0.9! Please note that =
*Scala
>>> >> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I
>>> >> wanted to give a few heads-up/requests to developers:
>>> >>
>>> >> If you are developing applications on top of Spark's master branch,
>>> >> those will need to migrate to Scala 2.10. You may want to download
>>> >> and test the current scala-2.10 branch in order to make sure you =
will
>>> >> be okay as Spark developments move forward. Of course, you can =
always
>>> >> stick with the current master commit and be fine (I'll cut a tag =
when
>>> >> we do the merge in order to delineate where the version changes).
>>> >> Please open new threads on the dev list to report and discuss any
>>> >> issues.
>>> >>
>>> >> This merge will temporarily drop support for YARN 2.2 on the master
>>> >> branch.
>>> >> This is because the workaround we used was only compiled for Scala 2=
.9.
>>> >> We are going to come up with a more robust solution to YARN 2.2
>>> >> support before releasing 0.9.
>>> >>
>>> >> Going forward, we will continue to make maintenance releases on
>>> >> branch-0.8 which will remain compatible with Scala 2.9.
>>> >>
>>> >> For those interested, the primary code changes in this merge are
>>> >> upgrading the akka version, changing the use of Scala 2.9's
>>> >> ClassManifest construct to Scala 2.10's ClassTag, and updating the
>>> >> spark shell to work with Scala 2.10's repl.
>>> >>
>>> >> - Patrick
>>> >>
>>> >
>>> >
>>
>>
------Nodemailer-0.5.0-?=_1-1387014803171--

From dev-return-912-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 10:04:38 2013
Return-Path: <dev-return-912-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEAA910427
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 10:04:38 +0000 (UTC)
Received: (qmail 9861 invoked by uid 500); 14 Dec 2013 10:04:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9831 invoked by uid 500); 14 Dec 2013 10:04:35 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 9823 invoked by uid 99); 14 Dec 2013 10:04:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 10:04:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of samkiller@gmail.com designates 74.125.82.49 as permitted sender)
Received: from [74.125.82.49] (HELO mail-wg0-f49.google.com) (74.125.82.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 10:04:29 +0000
Received: by mail-wg0-f49.google.com with SMTP id x12so2874057wgg.16
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 02:04:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:references:from:content-type:in-reply-to:message-id:date:to
         :content-transfer-encoding:mime-version;
        bh=NP/OkygXsudtznAU42by5AJkGSYFsjyPpEPb5hIyV6o=;
        b=OTvt+G8aUSS/r7Bf89fbkdaXpzB54MW60Omj7cOJWg9Kt6cP3MOqfuvKP1wAlXND/0
         bXMCoP5nHkg+jyiQh4raNiHMtqjEbRBw9kpMGFrjBTVv6OMz1o3u04WCTxqRWHgdju1b
         Bgf5FSPGh5iph0u7fiTilLiXxmNAApJK4j1QDs+jejvdKgon7N5ASredI3yBVwoh/F4+
         6gHjM10TKdIQAp0qtYcmM6DWVOieEZOVjdGMWirgbVkJiS6/XcPfEt1XrOhaFdG7qV53
         0sBXq4AGuETN8Be0oMGdIf/JfW436jKnGkxiQ0RhklVWHiPINFiLRcsPGkqp6hbst+nR
         fg2Q==
X-Received: by 10.180.96.106 with SMTP id dr10mr5665524wib.27.1387015448364;
        Sat, 14 Dec 2013 02:04:08 -0800 (PST)
Received: from [134.157.251.250] ([134.157.251.250])
        by mx.google.com with ESMTPSA id fj8sm22680455wib.1.2013.12.14.02.04.05
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 14 Dec 2013 02:04:05 -0800 (PST)
Subject: Re: Scala 2.10 Merge
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A010F318F@SHSMSX101.ccr.corp.intel.com> <CABPQxsvYBer35Yk-R=-xpF3VvqJkAxY+ARv2Gv7Ko7hoTeo7_w@mail.gmail.com> <CABPQxsvFeOqP3ANzqjSqkVc47Vd12b8jwK6nGFs07PX+74pbtA@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A010F3BBD@SHSMSX101.ccr.corp.intel.com> <CABPQxstm23ZGvZJKWqVaJqfDGjZQ9=BuRzU=Q0X_hhcX7LHDkA@mail.gmail.com> <CABPQxstv2XqzYKqEDaVEKU-qeP1E3ULxkCGNnAbD8-W6v3g1WQ@mail.gmail.com>
From: Sam Bessalah <samkiller@gmail.com>
Content-Type: text/plain;
	charset=us-ascii
X-Mailer: iPad Mail (11B554a)
In-Reply-To: <CABPQxstv2XqzYKqEDaVEKU-qeP1E3ULxkCGNnAbD8-W6v3g1WQ@mail.gmail.com>
Message-Id: <526B51F9-7BF8-40F5-8955-787E7ABADE4D@gmail.com>
Date: Sat, 14 Dec 2013 11:03:58 +0100
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Transfer-Encoding: quoted-printable
Mime-Version: 1.0 (1.0)
X-Virus-Checked: Checked by ClamAV on apache.org

Yes. Awesome.
Great job guys.

Sam Bessalah

> On Dec 14, 2013, at 9:59 AM, Patrick Wendell <pwendell@gmail.com> wrote:
>=20
> Alright I just merged this in - so Spark is officially "Scala 2.10"
> from here forward.
>=20
> For reference I cut a new branch called scala-2.9 with the commit
> immediately prior to the merge:
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubator=
-spark.git;a=3Dshortlog;h=3Drefs/heads/scala-2.9
>=20
> - Patrick
>=20
>> On Thu, Dec 12, 2013 at 8:26 PM, Patrick Wendell <pwendell@gmail.com> wro=
te:
>> Hey Reymond,
>>=20
>> Let's move this discussion out of this thread and into the associated JIR=
A.
>> I'll write up our current approach over there.
>>=20
>> https://spark-project.atlassian.net/browse/SPARK-995
>>=20
>> - Patrick
>>=20
>>=20
>>> On Thu, Dec 12, 2013 at 5:56 PM, Liu, Raymond <raymond.liu@intel.com> wr=
ote:
>>>=20
>>> Hi Patrick
>>>=20
>>>        So what's the plan for support Yarn 2.2 in 0.9? As far as I can
>>> see, if you want to support both 2.2 and 2.0 , due to protobuf version
>>> incompatible issue. You need two version of akka anyway.
>>>=20
>>>        Akka 2.3-M1 looks like have a little bit change in API, we
>>> probably could isolate the code like what we did on yarn part API. I
>>> remember that it is mentioned that to use reflection for different API i=
s
>>> preferred. So the purpose to use reflection is to use one release bin ja=
r to
>>> support both version of Hadoop/Yarn on runtime, instead of build differe=
nt
>>> bin jar on compile time?
>>>=20
>>>         Then all code related to hadoop will also be built in separate
>>> modules for loading on demand? This sounds to me involve a lot of works.=
 And
>>> you still need to have shim layer and separate code for different versio=
n
>>> API and depends on different version Akka etc. Sounds like and even stri=
ct
>>> demands versus our current approaching on master, and with dynamic class=

>>> loader in addition, And the problem we are facing now are still there?
>>>=20
>>> Best Regards,
>>> Raymond Liu
>>>=20
>>> -----Original Message-----
>>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>>> Sent: Thursday, December 12, 2013 5:13 PM
>>> To: dev@spark.incubator.apache.org
>>> Subject: Re: Scala 2.10 Merge
>>>=20
>>> Also - the code is still there because of a recent merge that took in so=
me
>>> newer changes... we'll be removing it for the final merge.
>>>=20
>>>=20
>>> On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>=20
>>>> Hey Raymond,
>>>>=20
>>>> This won't work because AFAIK akka 2.3-M1 is not binary compatible
>>>> with akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we need
>>>> to still use the older protobuf library, so we'd need to support both.
>>>>=20
>>>> I'd also be concerned about having a reference to a non-released
>>>> version of akka. Akka is the source of our hardest-to-find bugs and
>>>> simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.
>>>> Of course, if you are building off of master you can maintain a fork
>>>> that uses this.
>>>>=20
>>>> - Patrick
>>>>=20
>>>>=20
>>>> On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond
>>>> <raymond.liu@intel.com>wrote:
>>>>=20
>>>>> Hi Patrick
>>>>>=20
>>>>>        What does that means for drop YARN 2.2? seems codes are still
>>>>> there. You mean if build upon 2.2 it will break, and won't and work
>>>>> right?
>>>>> Since the home made akka build on scala 2.10 are not there. While, if
>>>>> for this case, can we just use akka 2.3-M1 which run on protobuf 2.5
>>>>> for replacement?
>>>>>=20
>>>>> Best Regards,
>>>>> Raymond Liu
>>>>>=20
>>>>>=20
>>>>> -----Original Message-----
>>>>> From: Patrick Wendell [mailto:pwendell@gmail.com]
>>>>> Sent: Thursday, December 12, 2013 4:21 PM
>>>>> To: dev@spark.incubator.apache.org
>>>>> Subject: Scala 2.10 Merge
>>>>>=20
>>>>> Hi Developers,
>>>>>=20
>>>>> In the next few days we are planning to merge Scala 2.10 support into
>>>>> Spark. For those that haven't been following this, Prashant Sharma
>>>>> has been maintaining the scala-2.10 branch of Spark for several
>>>>> months. This branch is current with master and has been reviewed for
>>>>> merging:
>>>>>=20
>>>>> https://github.com/apache/incubator-spark/tree/scala-2.10
>>>>>=20
>>>>> Scala 2.10 support is one of the most requested features for Spark -
>>>>> it will be great to get this into Spark 0.9! Please note that *Scala
>>>>> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I
>>>>> wanted to give a few heads-up/requests to developers:
>>>>>=20
>>>>> If you are developing applications on top of Spark's master branch,
>>>>> those will need to migrate to Scala 2.10. You may want to download
>>>>> and test the current scala-2.10 branch in order to make sure you will
>>>>> be okay as Spark developments move forward. Of course, you can always
>>>>> stick with the current master commit and be fine (I'll cut a tag when
>>>>> we do the merge in order to delineate where the version changes).
>>>>> Please open new threads on the dev list to report and discuss any
>>>>> issues.
>>>>>=20
>>>>> This merge will temporarily drop support for YARN 2.2 on the master
>>>>> branch.
>>>>> This is because the workaround we used was only compiled for Scala 2.9=
.
>>>>> We are going to come up with a more robust solution to YARN 2.2
>>>>> support before releasing 0.9.
>>>>>=20
>>>>> Going forward, we will continue to make maintenance releases on
>>>>> branch-0.8 which will remain compatible with Scala 2.9.
>>>>>=20
>>>>> For those interested, the primary code changes in this merge are
>>>>> upgrading the akka version, changing the use of Scala 2.9's
>>>>> ClassManifest construct to Scala 2.10's ClassTag, and updating the
>>>>> spark shell to work with Scala 2.10's repl.
>>>>>=20
>>>>> - Patrick
>>=20
>>=20

From dev-return-913-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 10:38:41 2013
Return-Path: <dev-return-913-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7CC22104B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 10:38:41 +0000 (UTC)
Received: (qmail 40959 invoked by uid 500); 14 Dec 2013 10:38:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40870 invoked by uid 500); 14 Dec 2013 10:38:32 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 40850 invoked by uid 99); 14 Dec 2013 10:38:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 10:38:30 +0000
X-ASF-Spam-Status: No, hits=1.6 required=5.0
	tests=FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andy.petrella@gmail.com designates 74.125.83.46 as permitted sender)
Received: from [74.125.83.46] (HELO mail-ee0-f46.google.com) (74.125.83.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 10:38:25 +0000
Received: by mail-ee0-f46.google.com with SMTP id d49so1296130eek.19
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 02:38:04 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:to:from:subject:date:mime-version:content-type;
        bh=aInNeZZGiWYGWmNOhU6xyAy6m1m+dp0XzQVjkC0Dl2w=;
        b=gNJEfTnpOO4rYhmNZk6YbO86aYbB40/ERl940DkXSVPxVRxYcuGsLVF9WtkHBul8jZ
         PXSbXFSqMAYfWzTaHaPH3sOCCEYrp7oFazDnyUPK4uH0VYtFl43z4zVbQE/e47qmBK/c
         dxiLzcA8A0KqxBz7qO1iac4MWF/as4cXb9wyVdkWgF0MEnByTxylY+Ub7roNHbpOYF78
         l0Ytr8tN4MNUJMYbcszDkGD7qNtG0s0TKgwF040dlYITFLdigZxhib5a41bVKKxWmirE
         dNrO/zKpQOkhNIdWEwWiy8AMItUGROUtP3G+rHe1DOywWJ8r9Ih/VNyv7fcdnS6bXGK8
         +6QQ==
X-Received: by 10.14.9.68 with SMTP id 44mr7075307ees.105.1387017484481;
        Sat, 14 Dec 2013 02:38:04 -0800 (PST)
Received: from [46.178.119.157] ([46.178.119.157])
        by mx.google.com with ESMTPSA id l4sm17026576een.13.2013.12.14.02.37.52
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sat, 14 Dec 2013 02:38:03 -0800 (PST)
Message-ID: <52ac350b.04c20e0a.118a.fffff9d1@mx.google.com>
To: dev@spark.incubator.apache.org,dev@spark.incubator.apache.org
From: "=?utf-8?B?YW5keS5wZXRyZWxsYUBnbWFpbC5jb20=?=" <andy.petrella@gmail.com>
Subject: =?utf-8?B?UmUgOiBTY2FsYSAyLjEwIE1lcmdl?=
Date: Sat, 14 Dec 2013 11:37:53 +0100
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_Part_4_1387017473054"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_4_1387017473054
Content-Type: text/plain;
	charset=utf-8
Content-Transfer-Encoding: base64
Content-Disposition: inline
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------=_Part_4_1387017473054--


From dev-return-914-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 18:32:15 2013
Return-Path: <dev-return-914-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C23D810C30
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 18:32:15 +0000 (UTC)
Received: (qmail 61814 invoked by uid 500); 14 Dec 2013 18:32:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61769 invoked by uid 500); 14 Dec 2013 18:32:15 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 61761 invoked by uid 99); 14 Dec 2013 18:32:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:32:14 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:32:09 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so3139333wgh.29
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 10:31:49 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=dHjP5IkGf86tgpKPKYnI9Dcq85zY3+UHyD4sCgUqbFk=;
        b=B8+wibgAflla6+7vG4QJKal1YVJNvh5C8HBo71kPPNFOZXAhfALg5emS0wD2PkRpv7
         yNzkJ2Xz6yHRFyxyZ1TB1Q3Uqhqx04q69WA/uxFjMxwde7+AZyHsSEv0QH2qyRfVBh37
         f6AsdhqVMuew0w6xv484WLL0uSYNoWtnez+CMo1h+5nLBvtelngoE3p7Qg4Wvud/1duQ
         Vzg6WPmHypeIolKKK5nnoHiXmMw/SS/59UwzLkz9W8qjltDg9OvZGLT41bxkcRH3AS2m
         ErfgJqc/1jvDAJpe6x2BqFH+ueC+Xzxu6eTlj25tbSBFH/I0TMTn4BCh1YZEr7/So0Ag
         CGfQ==
MIME-Version: 1.0
X-Received: by 10.180.79.67 with SMTP id h3mr6953948wix.58.1387045909109; Sat,
 14 Dec 2013 10:31:49 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sat, 14 Dec 2013 10:31:48 -0800 (PST)
In-Reply-To: <CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
Date: Sat, 14 Dec 2013 10:31:48 -0800
Message-ID: <CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Patrick, as sebb has mentioned let's move the binaries from the
voting directory in your people.apache.org directory.
ASF release voting is for source code and not binaries, and
technically we provide binaries for convenience.

And add link to the KEYS location in the dist[1] to let verify signatures.

Sorry for the late response to the VOTE thread, guys.

- Henry

[1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS

On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> wrote=
:
> The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or -1
> votes.
>
> +1 (5 Total)
> Matei Zaharia*
> Nick Pentreath*
> Patrick Wendell*
> Prashant Sharma*
> Tom Graves*
>
> 0 (0 Total)
>
> -1 (0 Total)
>
> * =3D Binding Vote
>
> As per the incubator release guide [1] I'll be sending this to the
> general incubator list for a final vote from IPMC members.
>
> [1]
> http://incubator.apache.org/guides/releasemanagement.html#best-practice-i=
ncubator-release-
> vote
>
>
> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>
>> I'd be personally fine with a standard workflow of assemble-deps +
>> packaging just the Spark files as separate packages, if it speeds up
>> everyone's development time.
>>
>>
>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com
>> >wrote:
>>
>> > I don't know how to make sense of the numbers, but here's what I've go=
t
>> > from a very small sample size.
>> >
>> > For both v0.8.0-incubating and v0.8.1-incubating, building separate
>> > assemblies is faster than `./sbt/sbt assembly` and the times for build=
ing
>> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
>> >
>> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long a=
s
>> the
>> > sum of the separate assemblies.
>> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long as
>> the
>> > sum of the separate assemblies.
>> >
>> > Weird.
>> >
>> >
>> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com
>> > >wrote:
>> >
>> > > I'll +1 myself also.
>> > >
>> > > For anyone who has the slow build problem: does this issue happen wh=
en
>> > > building v0.8.0-incubating also? Trying to figure out whether it's
>> > > related to something we added in 0.8.1 or if it's a long standing
>> > > issue.
>> > >
>> > > - Patrick
>> > >
>> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
>> matei.zaharia@gmail.com
>> > >
>> > > wrote:
>> > > > Woah, weird, but definitely good to know.
>> > > >
>> > > > If you=E2=80=99re doing Spark development, there=E2=80=99s also a =
more convenient
>> > option
>> > > added by Shivaram in the master branch. You can do sbt assemble-deps=
 to
>> > > package *just* the dependencies of each project in a special assembl=
y
>> > JAR,
>> > > and then use sbt compile to update the code. This will use the class=
es
>> > > directly out of the target/scala-2.9.3/classes directories. You have=
 to
>> > > redo assemble-deps only if your external dependencies change.
>> > > >
>> > > > Matei
>> > > >
>> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.com=
>
>> > > wrote:
>> > > >
>> > > >> I hope this PR https://github.com/apache/incubator-spark/pull/252=
can
>> > > help.
>> > > >> Again this is not a blocker for the release from my side either.
>> > > >>
>> > > >>
>> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
>> > mark@clearstorydata.com
>> > > >wrote:
>> > > >>
>> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
>> assembly`
>> > > takes
>> > > >>> a long, long, looooong time to complete (a MBP, in my case),
>> building
>> > > three
>> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, much
>> less
>> > > time.
>> > > >>>
>> > > >>>
>> > > >>>
>> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>> > > scrapcodes@gmail.com
>> > > >>>> wrote:
>> > > >>>
>> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly runn=
ing
>> > > >>> sbt/sbt
>> > > >>>> examples/assembly takes just 37s. Not to mention my hardware is
>> not
>> > > >>> really
>> > > >>>> great.
>> > > >>>>
>> > > >>>>
>> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>> > > scrapcodes@gmail.com
>> > > >>>>> wrote:
>> > > >>>>
>> > > >>>>> Hi Patrick and Matei,
>> > > >>>>>
>> > > >>>>> Was trying out this and followed the quick start guide which s=
ays
>> > do
>> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
>> minutes
>> > on
>> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly it=
 is
>> > > much
>> > > >>>>> faster.
>> > > >>>>>
>> > > >>>>> Should we change the documentation to reflect this. It will no=
t
>> be
>> > > >>> great
>> > > >>>>> for first time users to get stuck there.
>> > > >>>>>
>> > > >>>>>
>> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>> > > >>> matei.zaharia@gmail.com
>> > > >>>>> wrote:
>> > > >>>>>
>> > > >>>>>> +1
>> > > >>>>>>
>> > > >>>>>> Built and tested it on Mac OS X.
>> > > >>>>>>
>> > > >>>>>> Matei
>> > > >>>>>>
>> > > >>>>>>
>> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
>> pwendell@gmail.com>
>> > > >>>> wrote:
>> > > >>>>>>
>> > > >>>>>>> Please vote on releasing the following candidate as Apache
>> Spark
>> > > >>>>>>> (incubating) version 0.8.1.
>> > > >>>>>>>
>> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d)=
:
>> > > >>>>>>>
>> > > >>>>>>
>> > > >>>>
>> > > >>>
>> > >
>> >
>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubat=
or-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>> > > >>>>>>>
>> > > >>>>>>> The release files, including signatures, digests, etc can be
>> > found
>> > > >>> at:
>> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc=
4/
>> > > >>>>>>>
>> > > >>>>>>> Release artifacts are signed with the following key:
>> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>> > > >>>>>>>
>> > > >>>>>>> The staging repository for this release can be found at:
>> > > >>>>>>>
>> > > >>>>
>> > > https://repository.apache.org/content/repositories/orgapachespark-04=
0/
>> > > >>>>>>>
>> > > >>>>>>> The documentation corresponding to this release can be found
>> at:
>> > > >>>>>>>
>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>> > > >>>>>>>
>> > > >>>>>>> For information about the contents of this release see:
>> > > >>>>>>>
>> > > >>>>>>
>> > > >>>>
>> > > >>>
>> > >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblob=
;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-0=
.8
>> > > >>>>>>>
>> > > >>>>>>> Please vote on releasing this package as Apache Spark
>> > > >>>> 0.8.1-incubating!
>> > > >>>>>>>
>> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC =
and
>> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>> > > >>>>>>>
>> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubating
>> > > >>>>>>> [ ] -1 Do not release this package because ...
>> > > >>>>>>>
>> > > >>>>>>> To learn more about Apache Spark, please see
>> > > >>>>>>> http://spark.incubator.apache.org/
>> > > >>>>>>
>> > > >>>>>>
>> > > >>>>>
>> > > >>>>>
>> > > >>>>> --
>> > > >>>>> s
>> > > >>>>>
>> > > >>>>
>> > > >>>>
>> > > >>>>
>> > > >>>> --
>> > > >>>> s
>> > > >>>>
>> > > >>>
>> > > >>
>> > > >>
>> > > >>
>> > > >> --
>> > > >> s
>> > > >
>> > >
>> >
>>
>>
>>
>> --
>> --
>> Evan Chan
>> Staff Engineer
>> ev@ooyala.com  |
>>
>> <http://www.ooyala.com/>
>> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala>=
<
>> http://www.twitter.com/ooyala>
>>

From dev-return-915-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 18:40:34 2013
Return-Path: <dev-return-915-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD25010C47
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 18:40:34 +0000 (UTC)
Received: (qmail 65590 invoked by uid 500); 14 Dec 2013 18:40:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65557 invoked by uid 500); 14 Dec 2013 18:40:34 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 65549 invoked by uid 99); 14 Dec 2013 18:40:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:40:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.182 as permitted sender)
Received: from [74.125.82.182] (HELO mail-we0-f182.google.com) (74.125.82.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:40:29 +0000
Received: by mail-we0-f182.google.com with SMTP id q59so3177172wes.27
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 10:40:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=8MNSOXFDttaKn0ArI0DQnhORP6fxjfMR1j8UV7h7od0=;
        b=PL9crufT8sK59bD5SWYgovUDaLmRU/xTIwLg14wipDX6HS4GI42kxVeP8RyVsk/m6d
         Hu6aKUu/W6H7BJPgxQhXZFROpFGWEhH6VZfhvgcsJO7WboTJcGVRpfyxmxUyclPucThT
         FrGrUVxiNeH53KZmIKrlc4FnhHm3YLc5lMGJ85fhrW0VeL0uboy15KJE+Y22RL/Q+QjM
         fLSeU/fVPqXWtD1eI4dk/dlRhZl2v/vyK1nsbtgpu4Mv7VlolxjZg2VVCtCFMqq9n3IE
         nLle3GlP/JKn9oB5xN4sjaTso2/7zn998W6I08Si6Qx80K2v62Yl9WsJX6DmxAQ38Ccf
         TioA==
MIME-Version: 1.0
X-Received: by 10.180.19.201 with SMTP id h9mr7310402wie.36.1387046407534;
 Sat, 14 Dec 2013 10:40:07 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sat, 14 Dec 2013 10:40:07 -0800 (PST)
In-Reply-To: <CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
Date: Sat, 14 Dec 2013 10:40:07 -0800
Message-ID: <CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Actually we should be fine putting the binaries there as long as the
VOTE is for the source.

Let's verify with sebb in the general@ list about his concern.

- Henry

On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <henry.saputra@gmail.com> w=
rote:
> Hi Patrick, as sebb has mentioned let's move the binaries from the
> voting directory in your people.apache.org directory.
> ASF release voting is for source code and not binaries, and
> technically we provide binaries for convenience.
>
> And add link to the KEYS location in the dist[1] to let verify signatures=
.
>
> Sorry for the late response to the VOTE thread, guys.
>
> - Henry
>
> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>
> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> wro=
te:
>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or -1
>> votes.
>>
>> +1 (5 Total)
>> Matei Zaharia*
>> Nick Pentreath*
>> Patrick Wendell*
>> Prashant Sharma*
>> Tom Graves*
>>
>> 0 (0 Total)
>>
>> -1 (0 Total)
>>
>> * =3D Binding Vote
>>
>> As per the incubator release guide [1] I'll be sending this to the
>> general incubator list for a final vote from IPMC members.
>>
>> [1]
>> http://incubator.apache.org/guides/releasemanagement.html#best-practice-=
incubator-release-
>> vote
>>
>>
>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>>
>>> I'd be personally fine with a standard workflow of assemble-deps +
>>> packaging just the Spark files as separate packages, if it speeds up
>>> everyone's development time.
>>>
>>>
>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com
>>> >wrote:
>>>
>>> > I don't know how to make sense of the numbers, but here's what I've g=
ot
>>> > from a very small sample size.
>>> >
>>> > For both v0.8.0-incubating and v0.8.1-incubating, building separate
>>> > assemblies is faster than `./sbt/sbt assembly` and the times for buil=
ding
>>> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
>>> >
>>> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long =
as
>>> the
>>> > sum of the separate assemblies.
>>> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long a=
s
>>> the
>>> > sum of the separate assemblies.
>>> >
>>> > Weird.
>>> >
>>> >
>>> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.com
>>> > >wrote:
>>> >
>>> > > I'll +1 myself also.
>>> > >
>>> > > For anyone who has the slow build problem: does this issue happen w=
hen
>>> > > building v0.8.0-incubating also? Trying to figure out whether it's
>>> > > related to something we added in 0.8.1 or if it's a long standing
>>> > > issue.
>>> > >
>>> > > - Patrick
>>> > >
>>> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
>>> matei.zaharia@gmail.com
>>> > >
>>> > > wrote:
>>> > > > Woah, weird, but definitely good to know.
>>> > > >
>>> > > > If you=E2=80=99re doing Spark development, there=E2=80=99s also a=
 more convenient
>>> > option
>>> > > added by Shivaram in the master branch. You can do sbt assemble-dep=
s to
>>> > > package *just* the dependencies of each project in a special assemb=
ly
>>> > JAR,
>>> > > and then use sbt compile to update the code. This will use the clas=
ses
>>> > > directly out of the target/scala-2.9.3/classes directories. You hav=
e to
>>> > > redo assemble-deps only if your external dependencies change.
>>> > > >
>>> > > > Matei
>>> > > >
>>> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.co=
m>
>>> > > wrote:
>>> > > >
>>> > > >> I hope this PR https://github.com/apache/incubator-spark/pull/25=
2can
>>> > > help.
>>> > > >> Again this is not a blocker for the release from my side either.
>>> > > >>
>>> > > >>
>>> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
>>> > mark@clearstorydata.com
>>> > > >wrote:
>>> > > >>
>>> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
>>> assembly`
>>> > > takes
>>> > > >>> a long, long, looooong time to complete (a MBP, in my case),
>>> building
>>> > > three
>>> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>>> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, muc=
h
>>> less
>>> > > time.
>>> > > >>>
>>> > > >>>
>>> > > >>>
>>> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>>> > > scrapcodes@gmail.com
>>> > > >>>> wrote:
>>> > > >>>
>>> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly run=
ning
>>> > > >>> sbt/sbt
>>> > > >>>> examples/assembly takes just 37s. Not to mention my hardware i=
s
>>> not
>>> > > >>> really
>>> > > >>>> great.
>>> > > >>>>
>>> > > >>>>
>>> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>>> > > scrapcodes@gmail.com
>>> > > >>>>> wrote:
>>> > > >>>>
>>> > > >>>>> Hi Patrick and Matei,
>>> > > >>>>>
>>> > > >>>>> Was trying out this and followed the quick start guide which =
says
>>> > do
>>> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
>>> minutes
>>> > on
>>> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly i=
t is
>>> > > much
>>> > > >>>>> faster.
>>> > > >>>>>
>>> > > >>>>> Should we change the documentation to reflect this. It will n=
ot
>>> be
>>> > > >>> great
>>> > > >>>>> for first time users to get stuck there.
>>> > > >>>>>
>>> > > >>>>>
>>> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>> > > >>> matei.zaharia@gmail.com
>>> > > >>>>> wrote:
>>> > > >>>>>
>>> > > >>>>>> +1
>>> > > >>>>>>
>>> > > >>>>>> Built and tested it on Mac OS X.
>>> > > >>>>>>
>>> > > >>>>>> Matei
>>> > > >>>>>>
>>> > > >>>>>>
>>> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
>>> pwendell@gmail.com>
>>> > > >>>> wrote:
>>> > > >>>>>>
>>> > > >>>>>>> Please vote on releasing the following candidate as Apache
>>> Spark
>>> > > >>>>>>> (incubating) version 0.8.1.
>>> > > >>>>>>>
>>> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31d=
):
>>> > > >>>>>>>
>>> > > >>>>>>
>>> > > >>>>
>>> > > >>>
>>> > >
>>> >
>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincuba=
tor-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>> > > >>>>>>>
>>> > > >>>>>>> The release files, including signatures, digests, etc can b=
e
>>> > found
>>> > > >>> at:
>>> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-r=
c4/
>>> > > >>>>>>>
>>> > > >>>>>>> Release artifacts are signed with the following key:
>>> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>> > > >>>>>>>
>>> > > >>>>>>> The staging repository for this release can be found at:
>>> > > >>>>>>>
>>> > > >>>>
>>> > > https://repository.apache.org/content/repositories/orgapachespark-0=
40/
>>> > > >>>>>>>
>>> > > >>>>>>> The documentation corresponding to this release can be foun=
d
>>> at:
>>> > > >>>>>>>
>>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>>> > > >>>>>>>
>>> > > >>>>>>> For information about the contents of this release see:
>>> > > >>>>>>>
>>> > > >>>>>>
>>> > > >>>>
>>> > > >>>
>>> > >
>>> >
>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dblo=
b;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch-=
0.8
>>> > > >>>>>>>
>>> > > >>>>>>> Please vote on releasing this package as Apache Spark
>>> > > >>>> 0.8.1-incubating!
>>> > > >>>>>>>
>>> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 UTC=
 and
>>> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>> > > >>>>>>>
>>> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubatin=
g
>>> > > >>>>>>> [ ] -1 Do not release this package because ...
>>> > > >>>>>>>
>>> > > >>>>>>> To learn more about Apache Spark, please see
>>> > > >>>>>>> http://spark.incubator.apache.org/
>>> > > >>>>>>
>>> > > >>>>>>
>>> > > >>>>>
>>> > > >>>>>
>>> > > >>>>> --
>>> > > >>>>> s
>>> > > >>>>>
>>> > > >>>>
>>> > > >>>>
>>> > > >>>>
>>> > > >>>> --
>>> > > >>>> s
>>> > > >>>>
>>> > > >>>
>>> > > >>
>>> > > >>
>>> > > >>
>>> > > >> --
>>> > > >> s
>>> > > >
>>> > >
>>> >
>>>
>>>
>>>
>>> --
>>> --
>>> Evan Chan
>>> Staff Engineer
>>> ev@ooyala.com  |
>>>
>>> <http://www.ooyala.com/>
>>> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala=
><
>>> http://www.twitter.com/ooyala>
>>>

From dev-return-916-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 18:56:26 2013
Return-Path: <dev-return-916-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 64E0510C65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 18:56:26 +0000 (UTC)
Received: (qmail 70795 invoked by uid 500); 14 Dec 2013 18:56:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70756 invoked by uid 500); 14 Dec 2013 18:56:26 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 70748 invoked by uid 99); 14 Dec 2013 18:56:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:56:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 18:56:22 +0000
Received: by mail-ob0-f176.google.com with SMTP id vb8so3287633obc.21
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 10:56:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=kET0peGyc+Gy8zCb8UpVW70alJ90JU0JjnWVGvNlk+0=;
        b=M7WbGGLJSYCHpdDTW8jT9jQAXFpGCDgAFSqDjwQqfYEjvCDKAHRdAoHCq/BkRunWka
         mWIQVtmk8zgdjWuyJRE2k8JXTTGhhgrFtKOXCP4dWdmDX7XRw/7PhuLPxhx7GRwyI9y0
         Ae4fdgDDfO6E25L58xh1l6AA9aJJbrKPmTwZ+urWMAhPrWt2JMk6mT0BAJAlf2jc3Wmw
         KKvqIRHt+Lst586NAcXxabIKRbEOCynJxcWN8HiLG2wtEWp2bIykzniw569GFri9EkfZ
         q3YeO5snknU9cOILg9Qad491qPXz7HMDrP+Ii7mASZwaGscjIaw9dR6dgJuoPd0VBHJd
         cdNQ==
MIME-Version: 1.0
X-Received: by 10.60.39.169 with SMTP id q9mr164440oek.79.1387047361843; Sat,
 14 Dec 2013 10:56:01 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sat, 14 Dec 2013 10:56:01 -0800 (PST)
In-Reply-To: <CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
Date: Sat, 14 Dec 2013 10:56:01 -0800
Message-ID: <CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Henry,

One thing a lot of people do during the vote is test the binaries and
make sure they work. This is really valuable. If you'd like I could
add a caveat to the vote thread explaining that we are only voting on
the source.

- Patrick

On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <henry.saputra@gmail.com> w=
rote:
> Actually we should be fine putting the binaries there as long as the
> VOTE is for the source.
>
> Let's verify with sebb in the general@ list about his concern.
>
> - Henry
>
> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <henry.saputra@gmail.com>=
 wrote:
>> Hi Patrick, as sebb has mentioned let's move the binaries from the
>> voting directory in your people.apache.org directory.
>> ASF release voting is for source code and not binaries, and
>> technically we provide binaries for convenience.
>>
>> And add link to the KEYS location in the dist[1] to let verify signature=
s.
>>
>> Sorry for the late response to the VOTE thread, guys.
>>
>> - Henry
>>
>> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>
>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> wr=
ote:
>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or -=
1
>>> votes.
>>>
>>> +1 (5 Total)
>>> Matei Zaharia*
>>> Nick Pentreath*
>>> Patrick Wendell*
>>> Prashant Sharma*
>>> Tom Graves*
>>>
>>> 0 (0 Total)
>>>
>>> -1 (0 Total)
>>>
>>> * =3D Binding Vote
>>>
>>> As per the incubator release guide [1] I'll be sending this to the
>>> general incubator list for a final vote from IPMC members.
>>>
>>> [1]
>>> http://incubator.apache.org/guides/releasemanagement.html#best-practice=
-incubator-release-
>>> vote
>>>
>>>
>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>>>
>>>> I'd be personally fine with a standard workflow of assemble-deps +
>>>> packaging just the Spark files as separate packages, if it speeds up
>>>> everyone's development time.
>>>>
>>>>
>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.com
>>>> >wrote:
>>>>
>>>> > I don't know how to make sense of the numbers, but here's what I've =
got
>>>> > from a very small sample size.
>>>> >
>>>> > For both v0.8.0-incubating and v0.8.1-incubating, building separate
>>>> > assemblies is faster than `./sbt/sbt assembly` and the times for bui=
lding
>>>> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
>>>> >
>>>> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as long=
 as
>>>> the
>>>> > sum of the separate assemblies.
>>>> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long =
as
>>>> the
>>>> > sum of the separate assemblies.
>>>> >
>>>> > Weird.
>>>> >
>>>> >
>>>> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.co=
m
>>>> > >wrote:
>>>> >
>>>> > > I'll +1 myself also.
>>>> > >
>>>> > > For anyone who has the slow build problem: does this issue happen =
when
>>>> > > building v0.8.0-incubating also? Trying to figure out whether it's
>>>> > > related to something we added in 0.8.1 or if it's a long standing
>>>> > > issue.
>>>> > >
>>>> > > - Patrick
>>>> > >
>>>> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
>>>> matei.zaharia@gmail.com
>>>> > >
>>>> > > wrote:
>>>> > > > Woah, weird, but definitely good to know.
>>>> > > >
>>>> > > > If you=92re doing Spark development, there=92s also a more conve=
nient
>>>> > option
>>>> > > added by Shivaram in the master branch. You can do sbt assemble-de=
ps to
>>>> > > package *just* the dependencies of each project in a special assem=
bly
>>>> > JAR,
>>>> > > and then use sbt compile to update the code. This will use the cla=
sses
>>>> > > directly out of the target/scala-2.9.3/classes directories. You ha=
ve to
>>>> > > redo assemble-deps only if your external dependencies change.
>>>> > > >
>>>> > > > Matei
>>>> > > >
>>>> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.c=
om>
>>>> > > wrote:
>>>> > > >
>>>> > > >> I hope this PR https://github.com/apache/incubator-spark/pull/2=
52can
>>>> > > help.
>>>> > > >> Again this is not a blocker for the release from my side either=
.
>>>> > > >>
>>>> > > >>
>>>> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
>>>> > mark@clearstorydata.com
>>>> > > >wrote:
>>>> > > >>
>>>> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
>>>> assembly`
>>>> > > takes
>>>> > > >>> a long, long, looooong time to complete (a MBP, in my case),
>>>> building
>>>> > > three
>>>> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sbt
>>>> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, mu=
ch
>>>> less
>>>> > > time.
>>>> > > >>>
>>>> > > >>>
>>>> > > >>>
>>>> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>>>> > > scrapcodes@gmail.com
>>>> > > >>>> wrote:
>>>> > > >>>
>>>> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly ru=
nning
>>>> > > >>> sbt/sbt
>>>> > > >>>> examples/assembly takes just 37s. Not to mention my hardware =
is
>>>> not
>>>> > > >>> really
>>>> > > >>>> great.
>>>> > > >>>>
>>>> > > >>>>
>>>> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>>>> > > scrapcodes@gmail.com
>>>> > > >>>>> wrote:
>>>> > > >>>>
>>>> > > >>>>> Hi Patrick and Matei,
>>>> > > >>>>>
>>>> > > >>>>> Was trying out this and followed the quick start guide which=
 says
>>>> > do
>>>> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
>>>> minutes
>>>> > on
>>>> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly =
it is
>>>> > > much
>>>> > > >>>>> faster.
>>>> > > >>>>>
>>>> > > >>>>> Should we change the documentation to reflect this. It will =
not
>>>> be
>>>> > > >>> great
>>>> > > >>>>> for first time users to get stuck there.
>>>> > > >>>>>
>>>> > > >>>>>
>>>> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>>> > > >>> matei.zaharia@gmail.com
>>>> > > >>>>> wrote:
>>>> > > >>>>>
>>>> > > >>>>>> +1
>>>> > > >>>>>>
>>>> > > >>>>>> Built and tested it on Mac OS X.
>>>> > > >>>>>>
>>>> > > >>>>>> Matei
>>>> > > >>>>>>
>>>> > > >>>>>>
>>>> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
>>>> pwendell@gmail.com>
>>>> > > >>>> wrote:
>>>> > > >>>>>>
>>>> > > >>>>>>> Please vote on releasing the following candidate as Apache
>>>> Spark
>>>> > > >>>>>>> (incubating) version 0.8.1.
>>>> > > >>>>>>>
>>>> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d31=
d):
>>>> > > >>>>>>>
>>>> > > >>>>>>
>>>> > > >>>>
>>>> > > >>>
>>>> > >
>>>> >
>>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincub=
ator-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>>> > > >>>>>>>
>>>> > > >>>>>>> The release files, including signatures, digests, etc can =
be
>>>> > found
>>>> > > >>> at:
>>>> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating-=
rc4/
>>>> > > >>>>>>>
>>>> > > >>>>>>> Release artifacts are signed with the following key:
>>>> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>> > > >>>>>>>
>>>> > > >>>>>>> The staging repository for this release can be found at:
>>>> > > >>>>>>>
>>>> > > >>>>
>>>> > > https://repository.apache.org/content/repositories/orgapachespark-=
040/
>>>> > > >>>>>>>
>>>> > > >>>>>>> The documentation corresponding to this release can be fou=
nd
>>>> at:
>>>> > > >>>>>>>
>>>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs=
/
>>>> > > >>>>>>>
>>>> > > >>>>>>> For information about the contents of this release see:
>>>> > > >>>>>>>
>>>> > > >>>>>>
>>>> > > >>>>
>>>> > > >>>
>>>> > >
>>>> >
>>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Dbl=
ob;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranch=
-0.8
>>>> > > >>>>>>>
>>>> > > >>>>>>> Please vote on releasing this package as Apache Spark
>>>> > > >>>> 0.8.1-incubating!
>>>> > > >>>>>>>
>>>> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 UT=
C and
>>>> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast.
>>>> > > >>>>>>>
>>>> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubati=
ng
>>>> > > >>>>>>> [ ] -1 Do not release this package because ...
>>>> > > >>>>>>>
>>>> > > >>>>>>> To learn more about Apache Spark, please see
>>>> > > >>>>>>> http://spark.incubator.apache.org/
>>>> > > >>>>>>
>>>> > > >>>>>>
>>>> > > >>>>>
>>>> > > >>>>>
>>>> > > >>>>> --
>>>> > > >>>>> s
>>>> > > >>>>>
>>>> > > >>>>
>>>> > > >>>>
>>>> > > >>>>
>>>> > > >>>> --
>>>> > > >>>> s
>>>> > > >>>>
>>>> > > >>>
>>>> > > >>
>>>> > > >>
>>>> > > >>
>>>> > > >> --
>>>> > > >> s
>>>> > > >
>>>> > >
>>>> >
>>>>
>>>>
>>>>
>>>> --
>>>> --
>>>> Evan Chan
>>>> Staff Engineer
>>>> ev@ooyala.com  |
>>>>
>>>> <http://www.ooyala.com/>
>>>> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyal=
a><
>>>> http://www.twitter.com/ooyala>
>>>>

From dev-return-917-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 19:08:40 2013
Return-Path: <dev-return-917-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4985810CA4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 19:08:40 +0000 (UTC)
Received: (qmail 74464 invoked by uid 500); 14 Dec 2013 19:08:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74426 invoked by uid 500); 14 Dec 2013 19:08:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 74418 invoked by uid 99); 14 Dec 2013 19:08:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:08:40 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.43 as permitted sender)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:08:36 +0000
Received: by mail-wg0-f43.google.com with SMTP id k14so3155421wgh.22
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 11:08:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=2zMW6tQDBuHKMIa3ZRezBQyh9rDHT2H4gJcDsAOUokA=;
        b=Nh+tL7MgEcOVBWRcS0S+VQdHIedD6RqGeOK/FnbS3DOwk+yQJ/BycpUn7R3sfMql+s
         uZo2W5koN+C1tTBIKogo8/zzz0t36lmWJxIqfh9TTS09zKd+0FycA2DgkkF/fHD/dOd7
         tcV23RJnMmRTzTj2pGy/5cA0MSW69hmUFiyT/rT3ruxcDXwdu7+JixtQr2/rDqMZFQke
         1eBL8dtfMsLtswrQO6MiYpxCBA71FPcKh1J+JOVTCcKiuWvZSaiZWQmJhhQbn1gd7Nb4
         KywCLEwEMNyHk+uc5xaPL42QtfPHeZWCytDvEZ6M0mqJ3VUml1DTyvuI6u6KFIyD1XUF
         gGNg==
MIME-Version: 1.0
X-Received: by 10.194.192.198 with SMTP id hi6mr239943wjc.92.1387048095252;
 Sat, 14 Dec 2013 11:08:15 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sat, 14 Dec 2013 11:08:15 -0800 (PST)
In-Reply-To: <CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
Date: Sat, 14 Dec 2013 11:08:15 -0800
Message-ID: <CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Patrick,

Yeap I agree, but technically ASF VOTE release on source only, there
even debate about it =3D), so putting it in the vote staging artifact
could confuse people because in our case we do package 3rd party
libraries in the binary jars.

I have sent email to sebb asking clarification about his concern in
general@ list.

- Henry

On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com> wrot=
e:
> Hey Henry,
>
> One thing a lot of people do during the vote is test the binaries and
> make sure they work. This is really valuable. If you'd like I could
> add a caveat to the vote thread explaining that we are only voting on
> the source.
>
> - Patrick
>
> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <henry.saputra@gmail.com>=
 wrote:
>> Actually we should be fine putting the binaries there as long as the
>> VOTE is for the source.
>>
>> Let's verify with sebb in the general@ list about his concern.
>>
>> - Henry
>>
>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <henry.saputra@gmail.com=
> wrote:
>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
>>> voting directory in your people.apache.org directory.
>>> ASF release voting is for source code and not binaries, and
>>> technically we provide binaries for convenience.
>>>
>>> And add link to the KEYS location in the dist[1] to let verify signatur=
es.
>>>
>>> Sorry for the late response to the VOTE thread, guys.
>>>
>>> - Henry
>>>
>>> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>>
>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> w=
rote:
>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or =
-1
>>>> votes.
>>>>
>>>> +1 (5 Total)
>>>> Matei Zaharia*
>>>> Nick Pentreath*
>>>> Patrick Wendell*
>>>> Prashant Sharma*
>>>> Tom Graves*
>>>>
>>>> 0 (0 Total)
>>>>
>>>> -1 (0 Total)
>>>>
>>>> * =3D Binding Vote
>>>>
>>>> As per the incubator release guide [1] I'll be sending this to the
>>>> general incubator list for a final vote from IPMC members.
>>>>
>>>> [1]
>>>> http://incubator.apache.org/guides/releasemanagement.html#best-practic=
e-incubator-release-
>>>> vote
>>>>
>>>>
>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>>>>
>>>>> I'd be personally fine with a standard workflow of assemble-deps +
>>>>> packaging just the Spark files as separate packages, if it speeds up
>>>>> everyone's development time.
>>>>>
>>>>>
>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.co=
m
>>>>> >wrote:
>>>>>
>>>>> > I don't know how to make sense of the numbers, but here's what I've=
 got
>>>>> > from a very small sample size.
>>>>> >
>>>>> > For both v0.8.0-incubating and v0.8.1-incubating, building separate
>>>>> > assemblies is faster than `./sbt/sbt assembly` and the times for bu=
ilding
>>>>> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
>>>>> >
>>>>> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as lon=
g as
>>>>> the
>>>>> > sum of the separate assemblies.
>>>>> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as long=
 as
>>>>> the
>>>>> > sum of the separate assemblies.
>>>>> >
>>>>> > Weird.
>>>>> >
>>>>> >
>>>>> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.c=
om
>>>>> > >wrote:
>>>>> >
>>>>> > > I'll +1 myself also.
>>>>> > >
>>>>> > > For anyone who has the slow build problem: does this issue happen=
 when
>>>>> > > building v0.8.0-incubating also? Trying to figure out whether it'=
s
>>>>> > > related to something we added in 0.8.1 or if it's a long standing
>>>>> > > issue.
>>>>> > >
>>>>> > > - Patrick
>>>>> > >
>>>>> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
>>>>> matei.zaharia@gmail.com
>>>>> > >
>>>>> > > wrote:
>>>>> > > > Woah, weird, but definitely good to know.
>>>>> > > >
>>>>> > > > If you=E2=80=99re doing Spark development, there=E2=80=99s also=
 a more convenient
>>>>> > option
>>>>> > > added by Shivaram in the master branch. You can do sbt assemble-d=
eps to
>>>>> > > package *just* the dependencies of each project in a special asse=
mbly
>>>>> > JAR,
>>>>> > > and then use sbt compile to update the code. This will use the cl=
asses
>>>>> > > directly out of the target/scala-2.9.3/classes directories. You h=
ave to
>>>>> > > redo assemble-deps only if your external dependencies change.
>>>>> > > >
>>>>> > > > Matei
>>>>> > > >
>>>>> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail.=
com>
>>>>> > > wrote:
>>>>> > > >
>>>>> > > >> I hope this PR https://github.com/apache/incubator-spark/pull/=
252can
>>>>> > > help.
>>>>> > > >> Again this is not a blocker for the release from my side eithe=
r.
>>>>> > > >>
>>>>> > > >>
>>>>> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
>>>>> > mark@clearstorydata.com
>>>>> > > >wrote:
>>>>> > > >>
>>>>> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
>>>>> assembly`
>>>>> > > takes
>>>>> > > >>> a long, long, looooong time to complete (a MBP, in my case),
>>>>> building
>>>>> > > three
>>>>> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/sb=
t
>>>>> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, m=
uch
>>>>> less
>>>>> > > time.
>>>>> > > >>>
>>>>> > > >>>
>>>>> > > >>>
>>>>> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>>>>> > > scrapcodes@gmail.com
>>>>> > > >>>> wrote:
>>>>> > > >>>
>>>>> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly r=
unning
>>>>> > > >>> sbt/sbt
>>>>> > > >>>> examples/assembly takes just 37s. Not to mention my hardware=
 is
>>>>> not
>>>>> > > >>> really
>>>>> > > >>>> great.
>>>>> > > >>>>
>>>>> > > >>>>
>>>>> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>>>>> > > scrapcodes@gmail.com
>>>>> > > >>>>> wrote:
>>>>> > > >>>>
>>>>> > > >>>>> Hi Patrick and Matei,
>>>>> > > >>>>>
>>>>> > > >>>>> Was trying out this and followed the quick start guide whic=
h says
>>>>> > do
>>>>> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
>>>>> minutes
>>>>> > on
>>>>> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembly=
 it is
>>>>> > > much
>>>>> > > >>>>> faster.
>>>>> > > >>>>>
>>>>> > > >>>>> Should we change the documentation to reflect this. It will=
 not
>>>>> be
>>>>> > > >>> great
>>>>> > > >>>>> for first time users to get stuck there.
>>>>> > > >>>>>
>>>>> > > >>>>>
>>>>> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>>>> > > >>> matei.zaharia@gmail.com
>>>>> > > >>>>> wrote:
>>>>> > > >>>>>
>>>>> > > >>>>>> +1
>>>>> > > >>>>>>
>>>>> > > >>>>>> Built and tested it on Mac OS X.
>>>>> > > >>>>>>
>>>>> > > >>>>>> Matei
>>>>> > > >>>>>>
>>>>> > > >>>>>>
>>>>> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
>>>>> pwendell@gmail.com>
>>>>> > > >>>> wrote:
>>>>> > > >>>>>>
>>>>> > > >>>>>>> Please vote on releasing the following candidate as Apach=
e
>>>>> Spark
>>>>> > > >>>>>>> (incubating) version 0.8.1.
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d3=
1d):
>>>>> > > >>>>>>>
>>>>> > > >>>>>>
>>>>> > > >>>>
>>>>> > > >>>
>>>>> > >
>>>>> >
>>>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincu=
bator-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> The release files, including signatures, digests, etc can=
 be
>>>>> > found
>>>>> > > >>> at:
>>>>> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubating=
-rc4/
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> Release artifacts are signed with the following key:
>>>>> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> The staging repository for this release can be found at:
>>>>> > > >>>>>>>
>>>>> > > >>>>
>>>>> > > https://repository.apache.org/content/repositories/orgapachespark=
-040/
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> The documentation corresponding to this release can be fo=
und
>>>>> at:
>>>>> > > >>>>>>>
>>>>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-doc=
s/
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> For information about the contents of this release see:
>>>>> > > >>>>>>>
>>>>> > > >>>>>>
>>>>> > > >>>>
>>>>> > > >>>
>>>>> > >
>>>>> >
>>>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3Db=
lob;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbranc=
h-0.8
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> Please vote on releasing this package as Apache Spark
>>>>> > > >>>> 0.8.1-incubating!
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 U=
TC and
>>>>> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cast=
.
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incubat=
ing
>>>>> > > >>>>>>> [ ] -1 Do not release this package because ...
>>>>> > > >>>>>>>
>>>>> > > >>>>>>> To learn more about Apache Spark, please see
>>>>> > > >>>>>>> http://spark.incubator.apache.org/
>>>>> > > >>>>>>
>>>>> > > >>>>>>
>>>>> > > >>>>>
>>>>> > > >>>>>
>>>>> > > >>>>> --
>>>>> > > >>>>> s
>>>>> > > >>>>>
>>>>> > > >>>>
>>>>> > > >>>>
>>>>> > > >>>>
>>>>> > > >>>> --
>>>>> > > >>>> s
>>>>> > > >>>>
>>>>> > > >>>
>>>>> > > >>
>>>>> > > >>
>>>>> > > >>
>>>>> > > >> --
>>>>> > > >> s
>>>>> > > >
>>>>> > >
>>>>> >
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> --
>>>>> Evan Chan
>>>>> Staff Engineer
>>>>> ev@ooyala.com  |
>>>>>
>>>>> <http://www.ooyala.com/>
>>>>> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooya=
la><
>>>>> http://www.twitter.com/ooyala>
>>>>>

From dev-return-918-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 19:12:52 2013
Return-Path: <dev-return-918-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B83CA10CCA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 19:12:52 +0000 (UTC)
Received: (qmail 80722 invoked by uid 500); 14 Dec 2013 19:12:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80687 invoked by uid 500); 14 Dec 2013 19:12:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 80679 invoked by uid 99); 14 Dec 2013 19:12:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:12:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.50 as permitted sender)
Received: from [209.85.219.50] (HELO mail-oa0-f50.google.com) (209.85.219.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:12:46 +0000
Received: by mail-oa0-f50.google.com with SMTP id n16so3453902oag.37
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 11:12:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=railLDgC78T0TvkGs5ADbsboAsHdmUInbZVUn5MaJBs=;
        b=MmNnvnD5tMP2/Vx7ETBbNnM17I+kfocBl+B+Ivs36l9iQ9xa5JlZDQ77y8I7o3v6xS
         XAON2HwWf/aAuBVn2EDqkB1AJkq1OsiP/uvt6IlJR9tpxb7yZpjqEApolgydM5YnAuPc
         WjlN9fhR36FsWRy8ornJLY0EKKidGYI9ILKNjhJtualicH1bLV2YWe8Z2OUqWaxBa/Al
         +tDDDBz3ru1w5hEds0vym3SrUe3y6bEHDrn4RAUvS9yw5/5NDQUY3OaFnuKNIqpOENkt
         z5mNfEXazA+eNchAb4hU2ncUMFPN+9EpVVIORQMcmWFItKTaed4bdcQRtHVWbVhuUR0P
         0LdQ==
MIME-Version: 1.0
X-Received: by 10.60.17.70 with SMTP id m6mr617282oed.59.1387048345845; Sat,
 14 Dec 2013 11:12:25 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sat, 14 Dec 2013 11:12:25 -0800 (PST)
In-Reply-To: <CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
Date: Sat, 14 Dec 2013 11:12:25 -0800
Message-ID: <CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Henry - from that thread it looks like sebb's concern was something
different than this.

On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <henry.saputra@gmail.com> w=
rote:
> Hi Patrick,
>
> Yeap I agree, but technically ASF VOTE release on source only, there
> even debate about it =3D), so putting it in the vote staging artifact
> could confuse people because in our case we do package 3rd party
> libraries in the binary jars.
>
> I have sent email to sebb asking clarification about his concern in
> general@ list.
>
> - Henry
>
> On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com> wr=
ote:
>> Hey Henry,
>>
>> One thing a lot of people do during the vote is test the binaries and
>> make sure they work. This is really valuable. If you'd like I could
>> add a caveat to the vote thread explaining that we are only voting on
>> the source.
>>
>> - Patrick
>>
>> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <henry.saputra@gmail.com=
> wrote:
>>> Actually we should be fine putting the binaries there as long as the
>>> VOTE is for the source.
>>>
>>> Let's verify with sebb in the general@ list about his concern.
>>>
>>> - Henry
>>>
>>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <henry.saputra@gmail.co=
m> wrote:
>>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
>>>> voting directory in your people.apache.org directory.
>>>> ASF release voting is for source code and not binaries, and
>>>> technically we provide binaries for convenience.
>>>>
>>>> And add link to the KEYS location in the dist[1] to let verify signatu=
res.
>>>>
>>>> Sorry for the late response to the VOTE thread, guys.
>>>>
>>>> - Henry
>>>>
>>>> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>>>
>>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> =
wrote:
>>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0 or=
 -1
>>>>> votes.
>>>>>
>>>>> +1 (5 Total)
>>>>> Matei Zaharia*
>>>>> Nick Pentreath*
>>>>> Patrick Wendell*
>>>>> Prashant Sharma*
>>>>> Tom Graves*
>>>>>
>>>>> 0 (0 Total)
>>>>>
>>>>> -1 (0 Total)
>>>>>
>>>>> * =3D Binding Vote
>>>>>
>>>>> As per the incubator release guide [1] I'll be sending this to the
>>>>> general incubator list for a final vote from IPMC members.
>>>>>
>>>>> [1]
>>>>> http://incubator.apache.org/guides/releasemanagement.html#best-practi=
ce-incubator-release-
>>>>> vote
>>>>>
>>>>>
>>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>>>>>
>>>>>> I'd be personally fine with a standard workflow of assemble-deps +
>>>>>> packaging just the Spark files as separate packages, if it speeds up
>>>>>> everyone's development time.
>>>>>>
>>>>>>
>>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <mark@clearstorydata.c=
om
>>>>>> >wrote:
>>>>>>
>>>>>> > I don't know how to make sense of the numbers, but here's what I'v=
e got
>>>>>> > from a very small sample size.
>>>>>> >
>>>>>> > For both v0.8.0-incubating and v0.8.1-incubating, building separat=
e
>>>>>> > assemblies is faster than `./sbt/sbt assembly` and the times for b=
uilding
>>>>>> > separate assemblies for 0.8.0 and 0.8.1 are about the same.
>>>>>> >
>>>>>> > For v0.8.0-incubating, `./sbt/sbt assembly` takes about 2.5x as lo=
ng as
>>>>>> the
>>>>>> > sum of the separate assemblies.
>>>>>> > For v0.8.1-incubating, `./sbt/sbt assembly` takes almost 8x as lon=
g as
>>>>>> the
>>>>>> > sum of the separate assemblies.
>>>>>> >
>>>>>> > Weird.
>>>>>> >
>>>>>> >
>>>>>> > On Wed, Dec 11, 2013 at 11:49 AM, Patrick Wendell <pwendell@gmail.=
com
>>>>>> > >wrote:
>>>>>> >
>>>>>> > > I'll +1 myself also.
>>>>>> > >
>>>>>> > > For anyone who has the slow build problem: does this issue happe=
n when
>>>>>> > > building v0.8.0-incubating also? Trying to figure out whether it=
's
>>>>>> > > related to something we added in 0.8.1 or if it's a long standin=
g
>>>>>> > > issue.
>>>>>> > >
>>>>>> > > - Patrick
>>>>>> > >
>>>>>> > > On Wed, Dec 11, 2013 at 10:39 AM, Matei Zaharia <
>>>>>> matei.zaharia@gmail.com
>>>>>> > >
>>>>>> > > wrote:
>>>>>> > > > Woah, weird, but definitely good to know.
>>>>>> > > >
>>>>>> > > > If you=92re doing Spark development, there=92s also a more con=
venient
>>>>>> > option
>>>>>> > > added by Shivaram in the master branch. You can do sbt assemble-=
deps to
>>>>>> > > package *just* the dependencies of each project in a special ass=
embly
>>>>>> > JAR,
>>>>>> > > and then use sbt compile to update the code. This will use the c=
lasses
>>>>>> > > directly out of the target/scala-2.9.3/classes directories. You =
have to
>>>>>> > > redo assemble-deps only if your external dependencies change.
>>>>>> > > >
>>>>>> > > > Matei
>>>>>> > > >
>>>>>> > > > On Dec 11, 2013, at 1:04 AM, Prashant Sharma <scrapcodes@gmail=
.com>
>>>>>> > > wrote:
>>>>>> > > >
>>>>>> > > >> I hope this PR https://github.com/apache/incubator-spark/pull=
/252can
>>>>>> > > help.
>>>>>> > > >> Again this is not a blocker for the release from my side eith=
er.
>>>>>> > > >>
>>>>>> > > >>
>>>>>> > > >> On Wed, Dec 11, 2013 at 2:14 PM, Mark Hamstra <
>>>>>> > mark@clearstorydata.com
>>>>>> > > >wrote:
>>>>>> > > >>
>>>>>> > > >>> Interesting, and confirmed: On my machine where `./sbt/sbt
>>>>>> assembly`
>>>>>> > > takes
>>>>>> > > >>> a long, long, looooong time to complete (a MBP, in my case),
>>>>>> building
>>>>>> > > three
>>>>>> > > >>> separate assemblies (`./sbt/sbt assembly/assembly`, `./sbt/s=
bt
>>>>>> > > >>> examples/assembly`, `./sbt/sbt tools/assembly`) takes much, =
much
>>>>>> less
>>>>>> > > time.
>>>>>> > > >>>
>>>>>> > > >>>
>>>>>> > > >>>
>>>>>> > > >>> On Wed, Dec 11, 2013 at 12:02 AM, Prashant Sharma <
>>>>>> > > scrapcodes@gmail.com
>>>>>> > > >>>> wrote:
>>>>>> > > >>>
>>>>>> > > >>>> forgot to mention, after running sbt/sbt assembly/assembly =
running
>>>>>> > > >>> sbt/sbt
>>>>>> > > >>>> examples/assembly takes just 37s. Not to mention my hardwar=
e is
>>>>>> not
>>>>>> > > >>> really
>>>>>> > > >>>> great.
>>>>>> > > >>>>
>>>>>> > > >>>>
>>>>>> > > >>>> On Wed, Dec 11, 2013 at 1:28 PM, Prashant Sharma <
>>>>>> > > scrapcodes@gmail.com
>>>>>> > > >>>>> wrote:
>>>>>> > > >>>>
>>>>>> > > >>>>> Hi Patrick and Matei,
>>>>>> > > >>>>>
>>>>>> > > >>>>> Was trying out this and followed the quick start guide whi=
ch says
>>>>>> > do
>>>>>> > > >>>>> sbt/sbt assembly, like few others I was also stuck for few
>>>>>> minutes
>>>>>> > on
>>>>>> > > >>>>> linux. On the other hand if I use sbt/sbt assembly/assembl=
y it is
>>>>>> > > much
>>>>>> > > >>>>> faster.
>>>>>> > > >>>>>
>>>>>> > > >>>>> Should we change the documentation to reflect this. It wil=
l not
>>>>>> be
>>>>>> > > >>> great
>>>>>> > > >>>>> for first time users to get stuck there.
>>>>>> > > >>>>>
>>>>>> > > >>>>>
>>>>>> > > >>>>> On Wed, Dec 11, 2013 at 9:54 AM, Matei Zaharia <
>>>>>> > > >>> matei.zaharia@gmail.com
>>>>>> > > >>>>> wrote:
>>>>>> > > >>>>>
>>>>>> > > >>>>>> +1
>>>>>> > > >>>>>>
>>>>>> > > >>>>>> Built and tested it on Mac OS X.
>>>>>> > > >>>>>>
>>>>>> > > >>>>>> Matei
>>>>>> > > >>>>>>
>>>>>> > > >>>>>>
>>>>>> > > >>>>>> On Dec 10, 2013, at 4:49 PM, Patrick Wendell <
>>>>>> pwendell@gmail.com>
>>>>>> > > >>>> wrote:
>>>>>> > > >>>>>>
>>>>>> > > >>>>>>> Please vote on releasing the following candidate as Apac=
he
>>>>>> Spark
>>>>>> > > >>>>>>> (incubating) version 0.8.1.
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> The tag to be voted on is v0.8.1-incubating (commit b87d=
31d):
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>
>>>>>> > > >>>>
>>>>>> > > >>>
>>>>>> > >
>>>>>> >
>>>>>> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dinc=
ubator-spark.git;a=3Dcommit;h=3Db87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> The release files, including signatures, digests, etc ca=
n be
>>>>>> > found
>>>>>> > > >>> at:
>>>>>> > > >>>>>>> http://people.apache.org/~pwendell/spark-0.8.1-incubatin=
g-rc4/
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> Release artifacts are signed with the following key:
>>>>>> > > >>>>>>> https://people.apache.org/keys/committer/pwendell.asc
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> The staging repository for this release can be found at:
>>>>>> > > >>>>>>>
>>>>>> > > >>>>
>>>>>> > > https://repository.apache.org/content/repositories/orgapachespar=
k-040/
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> The documentation corresponding to this release can be f=
ound
>>>>>> at:
>>>>>> > > >>>>>>>
>>>>>> > > http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-do=
cs/
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> For information about the contents of this release see:
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>
>>>>>> > > >>>>
>>>>>> > > >>>
>>>>>> > >
>>>>>> >
>>>>>> https://git-wip-us.apache.org/repos/asf?p=3Dincubator-spark.git;a=3D=
blob;f=3DCHANGES.txt;h=3Dce0aeab524505b63c7999e0371157ac2def6fe1c;hb=3Dbran=
ch-0.8
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> Please vote on releasing this package as Apache Spark
>>>>>> > > >>>> 0.8.1-incubating!
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> The vote is open until Saturday, December 14th at 01:00 =
UTC and
>>>>>> > > >>>>>>> passes if a majority of at least 3 +1 PPMC votes are cas=
t.
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> [ ] +1 Release this package as Apache Spark 0.8.1-incuba=
ting
>>>>>> > > >>>>>>> [ ] -1 Do not release this package because ...
>>>>>> > > >>>>>>>
>>>>>> > > >>>>>>> To learn more about Apache Spark, please see
>>>>>> > > >>>>>>> http://spark.incubator.apache.org/
>>>>>> > > >>>>>>
>>>>>> > > >>>>>>
>>>>>> > > >>>>>
>>>>>> > > >>>>>
>>>>>> > > >>>>> --
>>>>>> > > >>>>> s
>>>>>> > > >>>>>
>>>>>> > > >>>>
>>>>>> > > >>>>
>>>>>> > > >>>>
>>>>>> > > >>>> --
>>>>>> > > >>>> s
>>>>>> > > >>>>
>>>>>> > > >>>
>>>>>> > > >>
>>>>>> > > >>
>>>>>> > > >>
>>>>>> > > >> --
>>>>>> > > >> s
>>>>>> > > >
>>>>>> > >
>>>>>> >
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> --
>>>>>> Evan Chan
>>>>>> Staff Engineer
>>>>>> ev@ooyala.com  |
>>>>>>
>>>>>> <http://www.ooyala.com/>
>>>>>> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooy=
ala><
>>>>>> http://www.twitter.com/ooyala>
>>>>>>

From dev-return-919-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 14 19:21:15 2013
Return-Path: <dev-return-919-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B77910D00
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Dec 2013 19:21:15 +0000 (UTC)
Received: (qmail 94235 invoked by uid 500); 14 Dec 2013 19:21:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94199 invoked by uid 500); 14 Dec 2013 19:21:15 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 94191 invoked by uid 99); 14 Dec 2013 19:21:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:21:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Dec 2013 19:21:11 +0000
Received: by mail-we0-f169.google.com with SMTP id w61so3187111wes.0
        for <dev@spark.incubator.apache.org>; Sat, 14 Dec 2013 11:20:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=zvjIoBkbZEGYIaRvTeOkUJ//QSpmDSacLHQ5IWDomw8=;
        b=xFxEXnRsxw0v0QkosBWgnbZi0CpzC3cOPbqA/f2tBw+YOMCMYrlKgcQK+broYWahVB
         sqUFUf2UKMjf+LAbCrV90DyZE2EGokGiveGpGEy4R93f6QJoXCtVQG0eSYdzYSNqIpaP
         TAhiUZ5JCp+Uy2OJbI/hyIDnMwfS9o7lhOw1yhTna7oH5ordOaqpAXABUzT0pg1F0bFw
         r0Ni9kLYDsRE63tfJwQAFcZmI8TGSVyASSHyHtxJtrt/THeyhLtN3zx/1Z/TNh8acHHS
         jHPfUDKgVe5mTwf8dnrbDX9rd3/i1VFSPWgE4TqReRMtM6X/Q1QFqVJTKwWN7uR3Gu7k
         Fn2Q==
MIME-Version: 1.0
X-Received: by 10.194.237.226 with SMTP id vf2mr830756wjc.58.1387048850438;
 Sat, 14 Dec 2013 11:20:50 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Sat, 14 Dec 2013 11:20:50 -0800 (PST)
In-Reply-To: <CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
Date: Sat, 14 Dec 2013 11:20:50 -0800
Message-ID: <CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e01493d96043edb04ed837ae1
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493d96043edb04ed837ae1
Content-Type: text/plain; charset=UTF-8

Yeah seems like it. He was ok with our prev release.
Let's wait for his reply

On Saturday, December 14, 2013, Patrick Wendell wrote:

> Henry - from that thread it looks like sebb's concern was something
> different than this.
>
> On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <henry.saputra@gmail.com>
> wrote:
> > Hi Patrick,
> >
> > Yeap I agree, but technically ASF VOTE release on source only, there
> > even debate about it =), so putting it in the vote staging artifact
> > could confuse people because in our case we do package 3rd party
> > libraries in the binary jars.
> >
> > I have sent email to sebb asking clarification about his concern in
> > general@ list.
> >
> > - Henry
> >
> > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >> Hey Henry,
> >>
> >> One thing a lot of people do during the vote is test the binaries and
> >> make sure they work. This is really valuable. If you'd like I could
> >> add a caveat to the vote thread explaining that we are only voting on
> >> the source.
> >>
> >> - Patrick
> >>
> >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
> henry.saputra@gmail.com> wrote:
> >>> Actually we should be fine putting the binaries there as long as the
> >>> VOTE is for the source.
> >>>
> >>> Let's verify with sebb in the general@ list about his concern.
> >>>
> >>> - Henry
> >>>
> >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
> henry.saputra@gmail.com> wrote:
> >>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
> >>>> voting directory in your people.apache.org directory.
> >>>> ASF release voting is for source code and not binaries, and
> >>>> technically we provide binaries for convenience.
> >>>>
> >>>> And add link to the KEYS location in the dist[1] to let verify
> signatures.
> >>>>
> >>>> Sorry for the late response to the VOTE thread, guys.
> >>>>
> >>>> - Henry
> >>>>
> >>>> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
> >>>>
> >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0
> or -1
> >>>>> votes.
> >>>>>
> >>>>> +1 (5 Total)
> >>>>> Matei Zaharia*
> >>>>> Nick Pentreath*
> >>>>> Patrick Wendell*
> >>>>> Prashant Sharma*
> >>>>> Tom Graves*
> >>>>>
> >>>>> 0 (0 Total)
> >>>>>
> >>>>> -1 (0 Total)
> >>>>>
> >>>>> * = Binding Vote
> >>>>>
> >>>>> As per the incubator release guide [1] I'll be sending this to the
> >>>>> general incubator list for a final vote from IPMC members.
> >>>>>
> >>>>> [1]
> >>>>>
> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
> >>>>> vote
> >>>>>
> >>>>>
> >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
> >>>>>
> >>>>>> I'd be personally fine with a standard workflow of assemble-deps +
> >>>>>> packaging just the Spark files as separate packages, if it speeds up
> >>>>>> everyone's development time.
> >>>>>>
> >>>>>>
> >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
> mark@clearstorydata.com
> >>>>>> >wrote:
> >>>>>>
> >>>>>> > I don't know how to make sense of the numbers, but here's what
> I've got
> >>>>>> > from a very small sample size.

--089e01493d96043edb04ed837ae1--

From dev-return-920-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 15 12:31:37 2013
Return-Path: <dev-return-920-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CC0DE10B3E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Dec 2013 12:31:37 +0000 (UTC)
Received: (qmail 96010 invoked by uid 500); 15 Dec 2013 12:31:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95724 invoked by uid 500); 15 Dec 2013 12:31:29 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 95716 invoked by uid 99); 15 Dec 2013 12:31:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 12:31:26 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of azuryyyu@gmail.com designates 209.85.212.51 as permitted sender)
Received: from [209.85.212.51] (HELO mail-vb0-f51.google.com) (209.85.212.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 12:31:21 +0000
Received: by mail-vb0-f51.google.com with SMTP id 11so2487613vbe.10
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 04:31:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=IVae4NBIjMpXjULL0HSyGx5e/itLDIE6Mo+gqvdi1lA=;
        b=02IrKioJZPuUyWNT55NcLGSyM+anfcX/F0riMf495f+72kdjqMv1uCjpEZnAswSrmI
         ime+yeIGksyZV/Nc2Af44r7L8t7kDhfS5sAHpeWT97+7DnQwxeapJ8A+h1jOmiPeFivB
         M5yIUpSjOHQsjPovdLsWajjCzkHTrKWvKhfGGkDfQKiEitIBh//WXWc/80gkfzZzW6ZM
         IYATrwEmFClBPP48nqWFVjYcY82OmkJKI295fgZPpBx3s6dlwGN7tty8tnuTrDFylmtU
         bi8wLHHpB+yhErNalgCwCRApQZxuLtPNS3NOy9SvnH9BTobZGqr4KpcFAdJnbvnI8Hhr
         wNyg==
MIME-Version: 1.0
X-Received: by 10.58.210.66 with SMTP id ms2mr6296899vec.10.1387110660403;
 Sun, 15 Dec 2013 04:31:00 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 04:31:00 -0800 (PST)
In-Reply-To: <CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
Date: Sun, 15 Dec 2013 20:31:00 +0800
Message-ID: <CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bd6ae8c2d795204ed91dec6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd6ae8c2d795204ed91dec6
Content-Type: text/plain; charset=ISO-8859-1

Hi,
Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
Thanks.


On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <henry.saputra@gmail.com>wrote:

> Yeah seems like it. He was ok with our prev release.
> Let's wait for his reply
>
> On Saturday, December 14, 2013, Patrick Wendell wrote:
>
> > Henry - from that thread it looks like sebb's concern was something
> > different than this.
> >
> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <henry.saputra@gmail.com
> >
> > wrote:
> > > Hi Patrick,
> > >
> > > Yeap I agree, but technically ASF VOTE release on source only, there
> > > even debate about it =), so putting it in the vote staging artifact
> > > could confuse people because in our case we do package 3rd party
> > > libraries in the binary jars.
> > >
> > > I have sent email to sebb asking clarification about his concern in
> > > general@ list.
> > >
> > > - Henry
> > >
> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > >> Hey Henry,
> > >>
> > >> One thing a lot of people do during the vote is test the binaries and
> > >> make sure they work. This is really valuable. If you'd like I could
> > >> add a caveat to the vote thread explaining that we are only voting on
> > >> the source.
> > >>
> > >> - Patrick
> > >>
> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
> > henry.saputra@gmail.com> wrote:
> > >>> Actually we should be fine putting the binaries there as long as the
> > >>> VOTE is for the source.
> > >>>
> > >>> Let's verify with sebb in the general@ list about his concern.
> > >>>
> > >>> - Henry
> > >>>
> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
> > henry.saputra@gmail.com> wrote:
> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
> > >>>> voting directory in your people.apache.org directory.
> > >>>> ASF release voting is for source code and not binaries, and
> > >>>> technically we provide binaries for convenience.
> > >>>>
> > >>>> And add link to the KEYS location in the dist[1] to let verify
> > signatures.
> > >>>>
> > >>>> Sorry for the late response to the VOTE thread, guys.
> > >>>>
> > >>>> - Henry
> > >>>>
> > >>>> [1] https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
> > >>>>
> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
> pwendell@gmail.com>
> > wrote:
> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0
> > or -1
> > >>>>> votes.
> > >>>>>
> > >>>>> +1 (5 Total)
> > >>>>> Matei Zaharia*
> > >>>>> Nick Pentreath*
> > >>>>> Patrick Wendell*
> > >>>>> Prashant Sharma*
> > >>>>> Tom Graves*
> > >>>>>
> > >>>>> 0 (0 Total)
> > >>>>>
> > >>>>> -1 (0 Total)
> > >>>>>
> > >>>>> * = Binding Vote
> > >>>>>
> > >>>>> As per the incubator release guide [1] I'll be sending this to the
> > >>>>> general incubator list for a final vote from IPMC members.
> > >>>>>
> > >>>>> [1]
> > >>>>>
> >
> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
> > >>>>> vote
> > >>>>>
> > >>>>>
> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
> > >>>>>
> > >>>>>> I'd be personally fine with a standard workflow of assemble-deps +
> > >>>>>> packaging just the Spark files as separate packages, if it speeds
> up
> > >>>>>> everyone's development time.
> > >>>>>>
> > >>>>>>
> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
> > mark@clearstorydata.com
> > >>>>>> >wrote:
> > >>>>>>
> > >>>>>> > I don't know how to make sense of the numbers, but here's what
> > I've got
> > >>>>>> > from a very small sample size.
>

--047d7bd6ae8c2d795204ed91dec6--

From dev-return-921-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 15 12:31:54 2013
Return-Path: <dev-return-921-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7EF4B10B3F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Dec 2013 12:31:54 +0000 (UTC)
Received: (qmail 96195 invoked by uid 500); 15 Dec 2013 12:31:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96160 invoked by uid 500); 15 Dec 2013 12:31:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 96152 invoked by uid 99); 15 Dec 2013 12:31:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 12:31:51 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of azuryyyu@gmail.com designates 209.85.128.171 as permitted sender)
Received: from [209.85.128.171] (HELO mail-ve0-f171.google.com) (209.85.128.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 12:31:45 +0000
Received: by mail-ve0-f171.google.com with SMTP id pa12so2614796veb.30
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 04:31:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=9ZTineKd6BT5yQDf4/SCV6OQw5uTUQadrrTXjHIQ7z0=;
        b=b7dymFXMQfuqDThEAmcYm4i1Rq9/Bcr7haVFvH7ESHtviPlVizHXhXnuHH4FP4l2sC
         25Z5yECJOlinGwnKaZLH1mJh+RfdslsLys2FJlDvTQdOc45Qpi+g2a7FCxXQX4y/rbJn
         wrcGU9PfkAey/ykaF2DBAWMZARCpraQLXKqsidj95LDqHMNP2RXl90eqTquUbKhGMbqP
         D4RBOF5OT4l8JFR8kVB82vqqaRa/USju28RzOl6VJNk1mQkoShO69FntM4nWim4/vPBM
         SLhzTgbS/3UqxfhExWksgjUZ8EjCp/GwtidJ4tQYvYbGDm4r3r4Wr4V067Yu8iViw62S
         BhYg==
MIME-Version: 1.0
X-Received: by 10.52.163.165 with SMTP id yj5mr1442496vdb.42.1387110684848;
 Sun, 15 Dec 2013 04:31:24 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 04:31:24 -0800 (PST)
In-Reply-To: <CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
Date: Sun, 15 Dec 2013 20:31:24 +0800
Message-ID: <CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c25004a2774204ed91df9b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25004a2774204ed91df9b
Content-Type: text/plain; charset=ISO-8859-1

yarn 2.2, not yarn 0.22, I am so sorry.


On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:

> Hi,
> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
> Thanks.
>
>
> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <henry.saputra@gmail.com>wrote:
>
>> Yeah seems like it. He was ok with our prev release.
>> Let's wait for his reply
>>
>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>>
>> > Henry - from that thread it looks like sebb's concern was something
>> > different than this.
>> >
>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>> henry.saputra@gmail.com>
>> > wrote:
>> > > Hi Patrick,
>> > >
>> > > Yeap I agree, but technically ASF VOTE release on source only, there
>> > > even debate about it =), so putting it in the vote staging artifact
>> > > could confuse people because in our case we do package 3rd party
>> > > libraries in the binary jars.
>> > >
>> > > I have sent email to sebb asking clarification about his concern in
>> > > general@ list.
>> > >
>> > > - Henry
>> > >
>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com
>> >
>> > wrote:
>> > >> Hey Henry,
>> > >>
>> > >> One thing a lot of people do during the vote is test the binaries and
>> > >> make sure they work. This is really valuable. If you'd like I could
>> > >> add a caveat to the vote thread explaining that we are only voting on
>> > >> the source.
>> > >>
>> > >> - Patrick
>> > >>
>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>> > henry.saputra@gmail.com> wrote:
>> > >>> Actually we should be fine putting the binaries there as long as the
>> > >>> VOTE is for the source.
>> > >>>
>> > >>> Let's verify with sebb in the general@ list about his concern.
>> > >>>
>> > >>> - Henry
>> > >>>
>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>> > henry.saputra@gmail.com> wrote:
>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
>> > >>>> voting directory in your people.apache.org directory.
>> > >>>> ASF release voting is for source code and not binaries, and
>> > >>>> technically we provide binaries for convenience.
>> > >>>>
>> > >>>> And add link to the KEYS location in the dist[1] to let verify
>> > signatures.
>> > >>>>
>> > >>>> Sorry for the late response to the VOTE thread, guys.
>> > >>>>
>> > >>>> - Henry
>> > >>>>
>> > >>>> [1]
>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>> > >>>>
>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>> pwendell@gmail.com>
>> > wrote:
>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0
>> > or -1
>> > >>>>> votes.
>> > >>>>>
>> > >>>>> +1 (5 Total)
>> > >>>>> Matei Zaharia*
>> > >>>>> Nick Pentreath*
>> > >>>>> Patrick Wendell*
>> > >>>>> Prashant Sharma*
>> > >>>>> Tom Graves*
>> > >>>>>
>> > >>>>> 0 (0 Total)
>> > >>>>>
>> > >>>>> -1 (0 Total)
>> > >>>>>
>> > >>>>> * = Binding Vote
>> > >>>>>
>> > >>>>> As per the incubator release guide [1] I'll be sending this to the
>> > >>>>> general incubator list for a final vote from IPMC members.
>> > >>>>>
>> > >>>>> [1]
>> > >>>>>
>> >
>> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
>> > >>>>> vote
>> > >>>>>
>> > >>>>>
>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>> > >>>>>
>> > >>>>>> I'd be personally fine with a standard workflow of assemble-deps
>> +
>> > >>>>>> packaging just the Spark files as separate packages, if it
>> speeds up
>> > >>>>>> everyone's development time.
>> > >>>>>>
>> > >>>>>>
>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>> > mark@clearstorydata.com
>> > >>>>>> >wrote:
>> > >>>>>>
>> > >>>>>> > I don't know how to make sense of the numbers, but here's what
>> > I've got
>> > >>>>>> > from a very small sample size.
>>
>
>

--001a11c25004a2774204ed91df9b--

From dev-return-922-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 15 18:43:40 2013
Return-Path: <dev-return-922-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C564B100B5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Dec 2013 18:43:40 +0000 (UTC)
Received: (qmail 78045 invoked by uid 500); 15 Dec 2013 18:43:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78010 invoked by uid 500); 15 Dec 2013 18:43:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 78002 invoked by uid 99); 15 Dec 2013 18:43:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 18:43:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 18:43:33 +0000
Received: by mail-oa0-f47.google.com with SMTP id k1so4123423oag.34
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 10:43:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=nDCHQwRHpkUeAu0crysStMnnqqXMnykinqC0yiyaL0A=;
        b=hhB2NBYT2HaUKQvaePWj5ErXb5ueTB7T07fZbaJuvSHAzZ//Xw8gN1BeXaY7Ci3J92
         /X5ciyMjKsE0bSCrRCWfBgWh9mcWPTJvTH/H5ZdV9Sxe9vKQdgsaO0TDVz5+rknwM0dG
         xT+Q+lfd7/Us7ao0VkNMgGegq70Gwbt6GkxHWq10l4YZjL9bz5YJXFznUbljLEWEkrTg
         k5knAOYfuhcEIqms2rZVE+i88HW4Cu8eqZH4/CePati+gcjmjCyEkigrUrplNS52arPJ
         +DFT7kwGRy7CwKwu0+JaBswJV68wXpDiJ+UA5zbGxyJCyLCeHUT/T96/sL47SIgyeQio
         ilDQ==
MIME-Version: 1.0
X-Received: by 10.182.78.68 with SMTP id z4mr8964287obw.29.1387132992174; Sun,
 15 Dec 2013 10:43:12 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Sun, 15 Dec 2013 10:43:12 -0800 (PST)
In-Reply-To: <CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
Date: Sun, 15 Dec 2013 10:43:12 -0800
Message-ID: <CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

You can checkout the docs mentioned in the vote thread. There is also
a pre-build binary for hadoop2 that is compiled for YARN 2.2

- Patrick

On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
> yarn 2.2, not yarn 0.22, I am so sorry.
>
>
> On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>
>> Hi,
>> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
>> Thanks.
>>
>>
>> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <henry.saputra@gmail.com>wrote:
>>
>>> Yeah seems like it. He was ok with our prev release.
>>> Let's wait for his reply
>>>
>>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>>>
>>> > Henry - from that thread it looks like sebb's concern was something
>>> > different than this.
>>> >
>>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>>> henry.saputra@gmail.com>
>>> > wrote:
>>> > > Hi Patrick,
>>> > >
>>> > > Yeap I agree, but technically ASF VOTE release on source only, there
>>> > > even debate about it =), so putting it in the vote staging artifact
>>> > > could confuse people because in our case we do package 3rd party
>>> > > libraries in the binary jars.
>>> > >
>>> > > I have sent email to sebb asking clarification about his concern in
>>> > > general@ list.
>>> > >
>>> > > - Henry
>>> > >
>>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <pwendell@gmail.com
>>> >
>>> > wrote:
>>> > >> Hey Henry,
>>> > >>
>>> > >> One thing a lot of people do during the vote is test the binaries and
>>> > >> make sure they work. This is really valuable. If you'd like I could
>>> > >> add a caveat to the vote thread explaining that we are only voting on
>>> > >> the source.
>>> > >>
>>> > >> - Patrick
>>> > >>
>>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>>> > henry.saputra@gmail.com> wrote:
>>> > >>> Actually we should be fine putting the binaries there as long as the
>>> > >>> VOTE is for the source.
>>> > >>>
>>> > >>> Let's verify with sebb in the general@ list about his concern.
>>> > >>>
>>> > >>> - Henry
>>> > >>>
>>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>>> > henry.saputra@gmail.com> wrote:
>>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries from the
>>> > >>>> voting directory in your people.apache.org directory.
>>> > >>>> ASF release voting is for source code and not binaries, and
>>> > >>>> technically we provide binaries for convenience.
>>> > >>>>
>>> > >>>> And add link to the KEYS location in the dist[1] to let verify
>>> > signatures.
>>> > >>>>
>>> > >>>> Sorry for the late response to the VOTE thread, guys.
>>> > >>>>
>>> > >>>> - Henry
>>> > >>>>
>>> > >>>> [1]
>>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>> > >>>>
>>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>>> pwendell@gmail.com>
>>> > wrote:
>>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and no 0
>>> > or -1
>>> > >>>>> votes.
>>> > >>>>>
>>> > >>>>> +1 (5 Total)
>>> > >>>>> Matei Zaharia*
>>> > >>>>> Nick Pentreath*
>>> > >>>>> Patrick Wendell*
>>> > >>>>> Prashant Sharma*
>>> > >>>>> Tom Graves*
>>> > >>>>>
>>> > >>>>> 0 (0 Total)
>>> > >>>>>
>>> > >>>>> -1 (0 Total)
>>> > >>>>>
>>> > >>>>> * = Binding Vote
>>> > >>>>>
>>> > >>>>> As per the incubator release guide [1] I'll be sending this to the
>>> > >>>>> general incubator list for a final vote from IPMC members.
>>> > >>>>>
>>> > >>>>> [1]
>>> > >>>>>
>>> >
>>> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
>>> > >>>>> vote
>>> > >>>>>
>>> > >>>>>
>>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com> wrote:
>>> > >>>>>
>>> > >>>>>> I'd be personally fine with a standard workflow of assemble-deps
>>> +
>>> > >>>>>> packaging just the Spark files as separate packages, if it
>>> speeds up
>>> > >>>>>> everyone's development time.
>>> > >>>>>>
>>> > >>>>>>
>>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>>> > mark@clearstorydata.com
>>> > >>>>>> >wrote:
>>> > >>>>>>
>>> > >>>>>> > I don't know how to make sense of the numbers, but here's what
>>> > I've got
>>> > >>>>>> > from a very small sample size.
>>>
>>
>>

From dev-return-923-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 15 23:43:01 2013
Return-Path: <dev-return-923-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D0DF10598
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Dec 2013 23:43:01 +0000 (UTC)
Received: (qmail 99559 invoked by uid 500); 15 Dec 2013 23:43:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99522 invoked by uid 500); 15 Dec 2013 23:43:01 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 99514 invoked by uid 99); 15 Dec 2013 23:43:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 23:43:01 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of azuryyyu@gmail.com designates 209.85.212.41 as permitted sender)
Received: from [209.85.212.41] (HELO mail-vb0-f41.google.com) (209.85.212.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Dec 2013 23:42:57 +0000
Received: by mail-vb0-f41.google.com with SMTP id p14so1095648vbm.0
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 15:42:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=oAQWsLmFj0apenT4OWu/nvZQylnTxwCWvt5y7VJB+I0=;
        b=vUo2/lPOBd7vsuppTUDCKfjoNX0Z/uL0O5ahml2xR6UagvTfcHQtOXFQH8ZWN5NwcP
         eFwa3Wk/Sq2S3R1jHU3ZAob/YZrspfHm8NG5udtT6anmS1Exu4+ZS6shU2CULc2MsRZF
         qNk+s5CwuSCWWFVNZ784erBD/TX/OArXdIfN3Z9vzmguEqAU7Ts4D4qq+OkOpv6aTKCl
         353wp6whS9Q3BX2SNM8/+wtJTXv7kU+eeMvovd6yCK3VcfKLPGQiSKDrWb13NxLbPdPJ
         3geyesezKam4LRAuYP8rmIDs/E+HcUbHDl7YxzGSgZjEUFX8b14hjBYOcVyYRQtrqBVe
         KBjQ==
MIME-Version: 1.0
X-Received: by 10.52.171.79 with SMTP id as15mr5849886vdc.1.1387150956539;
 Sun, 15 Dec 2013 15:42:36 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 15:42:36 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 15:42:36 -0800 (PST)
In-Reply-To: <CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
Date: Mon, 16 Dec 2013 07:42:36 +0800
Message-ID: <CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b6d91d403e7fe04ed9b4066
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6d91d403e7fe04ed9b4066
Content-Type: text/plain; charset=ISO-8859-1

Thanks Patrick.
On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:

> You can checkout the docs mentioned in the vote thread. There is also
> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>
> - Patrick
>
> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
> > yarn 2.2, not yarn 0.22, I am so sorry.
> >
> >
> > On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
> >
> >> Hi,
> >> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
> >> Thanks.
> >>
> >>
> >> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <henry.saputra@gmail.com
> >wrote:
> >>
> >>> Yeah seems like it. He was ok with our prev release.
> >>> Let's wait for his reply
> >>>
> >>> On Saturday, December 14, 2013, Patrick Wendell wrote:
> >>>
> >>> > Henry - from that thread it looks like sebb's concern was something
> >>> > different than this.
> >>> >
> >>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
> >>> henry.saputra@gmail.com>
> >>> > wrote:
> >>> > > Hi Patrick,
> >>> > >
> >>> > > Yeap I agree, but technically ASF VOTE release on source only,
> there
> >>> > > even debate about it =), so putting it in the vote staging artifact
> >>> > > could confuse people because in our case we do package 3rd party
> >>> > > libraries in the binary jars.
> >>> > >
> >>> > > I have sent email to sebb asking clarification about his concern in
> >>> > > general@ list.
> >>> > >
> >>> > > - Henry
> >>> > >
> >>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
> pwendell@gmail.com
> >>> >
> >>> > wrote:
> >>> > >> Hey Henry,
> >>> > >>
> >>> > >> One thing a lot of people do during the vote is test the binaries
> and
> >>> > >> make sure they work. This is really valuable. If you'd like I
> could
> >>> > >> add a caveat to the vote thread explaining that we are only
> voting on
> >>> > >> the source.
> >>> > >>
> >>> > >> - Patrick
> >>> > >>
> >>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
> >>> > henry.saputra@gmail.com> wrote:
> >>> > >>> Actually we should be fine putting the binaries there as long as
> the
> >>> > >>> VOTE is for the source.
> >>> > >>>
> >>> > >>> Let's verify with sebb in the general@ list about his concern.
> >>> > >>>
> >>> > >>> - Henry
> >>> > >>>
> >>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
> >>> > henry.saputra@gmail.com> wrote:
> >>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries from
> the
> >>> > >>>> voting directory in your people.apache.org directory.
> >>> > >>>> ASF release voting is for source code and not binaries, and
> >>> > >>>> technically we provide binaries for convenience.
> >>> > >>>>
> >>> > >>>> And add link to the KEYS location in the dist[1] to let verify
> >>> > signatures.
> >>> > >>>>
> >>> > >>>> Sorry for the late response to the VOTE thread, guys.
> >>> > >>>>
> >>> > >>>> - Henry
> >>> > >>>>
> >>> > >>>> [1]
> >>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
> >>> > >>>>
> >>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
> >>> pwendell@gmail.com>
> >>> > wrote:
> >>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and
> no 0
> >>> > or -1
> >>> > >>>>> votes.
> >>> > >>>>>
> >>> > >>>>> +1 (5 Total)
> >>> > >>>>> Matei Zaharia*
> >>> > >>>>> Nick Pentreath*
> >>> > >>>>> Patrick Wendell*
> >>> > >>>>> Prashant Sharma*
> >>> > >>>>> Tom Graves*
> >>> > >>>>>
> >>> > >>>>> 0 (0 Total)
> >>> > >>>>>
> >>> > >>>>> -1 (0 Total)
> >>> > >>>>>
> >>> > >>>>> * = Binding Vote
> >>> > >>>>>
> >>> > >>>>> As per the incubator release guide [1] I'll be sending this to
> the
> >>> > >>>>> general incubator list for a final vote from IPMC members.
> >>> > >>>>>
> >>> > >>>>> [1]
> >>> > >>>>>
> >>> >
> >>>
> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
> >>> > >>>>> vote
> >>> > >>>>>
> >>> > >>>>>
> >>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com>
> wrote:
> >>> > >>>>>
> >>> > >>>>>> I'd be personally fine with a standard workflow of
> assemble-deps
> >>> +
> >>> > >>>>>> packaging just the Spark files as separate packages, if it
> >>> speeds up
> >>> > >>>>>> everyone's development time.
> >>> > >>>>>>
> >>> > >>>>>>
> >>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
> >>> > mark@clearstorydata.com
> >>> > >>>>>> >wrote:
> >>> > >>>>>>
> >>> > >>>>>> > I don't know how to make sense of the numbers, but here's
> what
> >>> > I've got
> >>> > >>>>>> > from a very small sample size.
> >>>
> >>
> >>
>

--047d7b6d91d403e7fe04ed9b4066--

From dev-return-924-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 02:30:30 2013
Return-Path: <dev-return-924-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E568810803
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 02:30:30 +0000 (UTC)
Received: (qmail 24577 invoked by uid 500); 16 Dec 2013 02:30:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24479 invoked by uid 500); 16 Dec 2013 02:30:30 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 24471 invoked by uid 99); 16 Dec 2013 02:30:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 02:30:30 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of azuryyyu@gmail.com designates 209.85.128.171 as permitted sender)
Received: from [209.85.128.171] (HELO mail-ve0-f171.google.com) (209.85.128.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 02:30:26 +0000
Received: by mail-ve0-f171.google.com with SMTP id pa12so2864357veb.2
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 18:30:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=R3vC2vxe9FFBP/JIhvqlI2hMMQqKldX/ySyd23yDFgo=;
        b=PZqfvPZ9X+P/nhT8Wxzmot/DdhsYGQeGxPTXOnPyNjusmKTAhae1vVXfBW6YgUZx83
         GVmMX+PEC3h4+jLU/WuPAgrS5aGGhuYtsolcMDwEIvOzzUk6ipAB52sVl1Sg7uX9UGIF
         MjjsAvPV5xed6sdYFIAX1nCY9JI4GavihRlVBWdFpQNOFPJE+tMRlJ+x1+RelF6gxrLm
         tJptTpGUzq3KxPSuUX/oYQK3ldB0W3OgTV9D4HsYV/GubZv+mZGujhIowahdYtg6+6TU
         JgVZ37ecpMwutP2kK7RP0UBsI46L6V9YowUvMcbPuFUy7nDD0yoU/VkGEDNBSgbRIxVn
         idMw==
MIME-Version: 1.0
X-Received: by 10.220.183.199 with SMTP id ch7mr2903801vcb.27.1387161005693;
 Sun, 15 Dec 2013 18:30:05 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 18:30:05 -0800 (PST)
In-Reply-To: <CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
	<CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
Date: Mon, 16 Dec 2013 10:30:05 +0800
Message-ID: <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c1bce0fdbd7704ed9d963a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1bce0fdbd7704ed9d963a
Content-Type: text/plain; charset=ISO-8859-1

Hi here,
Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some
uncompatable API between these two versions.
Hadoop-2.x using protobuf-2.5.0


but if some guys want to run Spark on mesos, then mesos using
protobuf-2.4.1 currently. so we may discuss here for a better solution.



On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:

> Thanks Patrick.
> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
>
>> You can checkout the docs mentioned in the vote thread. There is also
>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>>
>> - Patrick
>>
>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> > yarn 2.2, not yarn 0.22, I am so sorry.
>> >
>> >
>> > On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> >
>> >> Hi,
>> >> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
>> >> Thanks.
>> >>
>> >>
>> >> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
>> henry.saputra@gmail.com>wrote:
>> >>
>> >>> Yeah seems like it. He was ok with our prev release.
>> >>> Let's wait for his reply
>> >>>
>> >>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>> >>>
>> >>> > Henry - from that thread it looks like sebb's concern was something
>> >>> > different than this.
>> >>> >
>> >>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>> >>> henry.saputra@gmail.com>
>> >>> > wrote:
>> >>> > > Hi Patrick,
>> >>> > >
>> >>> > > Yeap I agree, but technically ASF VOTE release on source only,
>> there
>> >>> > > even debate about it =), so putting it in the vote staging
>> artifact
>> >>> > > could confuse people because in our case we do package 3rd party
>> >>> > > libraries in the binary jars.
>> >>> > >
>> >>> > > I have sent email to sebb asking clarification about his concern
>> in
>> >>> > > general@ list.
>> >>> > >
>> >>> > > - Henry
>> >>> > >
>> >>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
>> pwendell@gmail.com
>> >>> >
>> >>> > wrote:
>> >>> > >> Hey Henry,
>> >>> > >>
>> >>> > >> One thing a lot of people do during the vote is test the
>> binaries and
>> >>> > >> make sure they work. This is really valuable. If you'd like I
>> could
>> >>> > >> add a caveat to the vote thread explaining that we are only
>> voting on
>> >>> > >> the source.
>> >>> > >>
>> >>> > >> - Patrick
>> >>> > >>
>> >>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>> Actually we should be fine putting the binaries there as long
>> as the
>> >>> > >>> VOTE is for the source.
>> >>> > >>>
>> >>> > >>> Let's verify with sebb in the general@ list about his concern.
>> >>> > >>>
>> >>> > >>> - Henry
>> >>> > >>>
>> >>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries from
>> the
>> >>> > >>>> voting directory in your people.apache.org directory.
>> >>> > >>>> ASF release voting is for source code and not binaries, and
>> >>> > >>>> technically we provide binaries for convenience.
>> >>> > >>>>
>> >>> > >>>> And add link to the KEYS location in the dist[1] to let verify
>> >>> > signatures.
>> >>> > >>>>
>> >>> > >>>> Sorry for the late response to the VOTE thread, guys.
>> >>> > >>>>
>> >>> > >>>> - Henry
>> >>> > >>>>
>> >>> > >>>> [1]
>> >>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>> >>> > >>>>
>> >>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>> >>> pwendell@gmail.com>
>> >>> > wrote:
>> >>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's and
>> no 0
>> >>> > or -1
>> >>> > >>>>> votes.
>> >>> > >>>>>
>> >>> > >>>>> +1 (5 Total)
>> >>> > >>>>> Matei Zaharia*
>> >>> > >>>>> Nick Pentreath*
>> >>> > >>>>> Patrick Wendell*
>> >>> > >>>>> Prashant Sharma*
>> >>> > >>>>> Tom Graves*
>> >>> > >>>>>
>> >>> > >>>>> 0 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> -1 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> * = Binding Vote
>> >>> > >>>>>
>> >>> > >>>>> As per the incubator release guide [1] I'll be sending this
>> to the
>> >>> > >>>>> general incubator list for a final vote from IPMC members.
>> >>> > >>>>>
>> >>> > >>>>> [1]
>> >>> > >>>>>
>> >>> >
>> >>>
>> http://incubator.apache.org/guides/releasemanagement.html#best-practice-incubator-release-
>> >>> > >>>>> vote
>> >>> > >>>>>
>> >>> > >>>>>
>> >>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan <ev@ooyala.com>
>> wrote:
>> >>> > >>>>>
>> >>> > >>>>>> I'd be personally fine with a standard workflow of
>> assemble-deps
>> >>> +
>> >>> > >>>>>> packaging just the Spark files as separate packages, if it
>> >>> speeds up
>> >>> > >>>>>> everyone's development time.
>> >>> > >>>>>>
>> >>> > >>>>>>
>> >>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>> >>> > mark@clearstorydata.com
>> >>> > >>>>>> >wrote:
>> >>> > >>>>>>
>> >>> > >>>>>> > I don't know how to make sense of the numbers, but here's
>> what
>> >>> > I've got
>> >>> > >>>>>> > from a very small sample size.
>> >>>
>> >>
>> >>
>>
>

--001a11c1bce0fdbd7704ed9d963a--

From dev-return-925-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 02:48:40 2013
Return-Path: <dev-return-925-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 793DA10845
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 02:48:40 +0000 (UTC)
Received: (qmail 34652 invoked by uid 500); 16 Dec 2013 02:48:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34608 invoked by uid 500); 16 Dec 2013 02:48:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 34600 invoked by uid 99); 16 Dec 2013 02:48:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 02:48:40 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of raymond.liu@intel.com designates 134.134.136.24 as permitted sender)
Received: from [134.134.136.24] (HELO mga09.intel.com) (134.134.136.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 02:48:34 +0000
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by orsmga102.jf.intel.com with ESMTP; 15 Dec 2013 18:44:25 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.95,492,1384329600"; 
   d="scan'208";a="425141777"
Received: from fmsmsx104.amr.corp.intel.com ([10.19.9.35])
  by orsmga001.jf.intel.com with ESMTP; 15 Dec 2013 18:48:11 -0800
Received: from fmsmsx114.amr.corp.intel.com (10.18.116.8) by
 FMSMSX104.amr.corp.intel.com (10.19.9.35) with Microsoft SMTP Server (TLS) id
 14.3.123.3; Sun, 15 Dec 2013 18:48:11 -0800
Received: from shsmsx152.ccr.corp.intel.com (10.239.6.52) by
 FMSMSX114.amr.corp.intel.com (10.18.116.8) with Microsoft SMTP Server (TLS)
 id 14.3.123.3; Sun, 15 Dec 2013 18:48:10 -0800
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.57]) by
 SHSMSX152.ccr.corp.intel.com ([10.239.6.52]) with mapi id 14.03.0123.003;
 Mon, 16 Dec 2013 10:48:09 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
Thread-Topic: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
Thread-Index: AQHO+gbULNGznYS8EES8Jf+aoBFEi5pWHk5A
Date: Mon, 16 Dec 2013 02:48:08 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
	<CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
 <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
In-Reply-To: <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Azuryy

Please Check https://spark-project.atlassian.net/browse/SPARK-995 for this =
protobuf version issue

Best Regards,
Raymond Liu

-----Original Message-----
From: Azuryy Yu [mailto:azuryyyu@gmail.com]=20
Sent: Monday, December 16, 2013 10:30 AM
To: dev@spark.incubator.apache.org
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)

Hi here,
Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some uncomp=
atable API between these two versions.
Hadoop-2.x using protobuf-2.5.0


but if some guys want to run Spark on mesos, then mesos using
protobuf-2.4.1 currently. so we may discuss here for a better solution.



On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:

> Thanks Patrick.
> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
>
>> You can checkout the docs mentioned in the vote thread. There is also=20
>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>>
>> - Patrick
>>
>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> > yarn 2.2, not yarn 0.22, I am so sorry.
>> >
>> >
>> > On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> >
>> >> Hi,
>> >> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
>> >> Thanks.
>> >>
>> >>
>> >> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
>> henry.saputra@gmail.com>wrote:
>> >>
>> >>> Yeah seems like it. He was ok with our prev release.
>> >>> Let's wait for his reply
>> >>>
>> >>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>> >>>
>> >>> > Henry - from that thread it looks like sebb's concern was=20
>> >>> > something different than this.
>> >>> >
>> >>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>> >>> henry.saputra@gmail.com>
>> >>> > wrote:
>> >>> > > Hi Patrick,
>> >>> > >
>> >>> > > Yeap I agree, but technically ASF VOTE release on source=20
>> >>> > > only,
>> there
>> >>> > > even debate about it =3D), so putting it in the vote staging
>> artifact
>> >>> > > could confuse people because in our case we do package 3rd=20
>> >>> > > party libraries in the binary jars.
>> >>> > >
>> >>> > > I have sent email to sebb asking clarification about his=20
>> >>> > > concern
>> in
>> >>> > > general@ list.
>> >>> > >
>> >>> > > - Henry
>> >>> > >
>> >>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
>> pwendell@gmail.com
>> >>> >
>> >>> > wrote:
>> >>> > >> Hey Henry,
>> >>> > >>
>> >>> > >> One thing a lot of people do during the vote is test the
>> binaries and
>> >>> > >> make sure they work. This is really valuable. If you'd like=20
>> >>> > >> I
>> could
>> >>> > >> add a caveat to the vote thread explaining that we are only
>> voting on
>> >>> > >> the source.
>> >>> > >>
>> >>> > >> - Patrick
>> >>> > >>
>> >>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>> Actually we should be fine putting the binaries there as=20
>> >>> > >>> long
>> as the
>> >>> > >>> VOTE is for the source.
>> >>> > >>>
>> >>> > >>> Let's verify with sebb in the general@ list about his concern.
>> >>> > >>>
>> >>> > >>> - Henry
>> >>> > >>>
>> >>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries=20
>> >>> > >>>> from
>> the
>> >>> > >>>> voting directory in your people.apache.org directory.
>> >>> > >>>> ASF release voting is for source code and not binaries,=20
>> >>> > >>>> and technically we provide binaries for convenience.
>> >>> > >>>>
>> >>> > >>>> And add link to the KEYS location in the dist[1] to let=20
>> >>> > >>>> verify
>> >>> > signatures.
>> >>> > >>>>
>> >>> > >>>> Sorry for the late response to the VOTE thread, guys.
>> >>> > >>>>
>> >>> > >>>> - Henry
>> >>> > >>>>
>> >>> > >>>> [1]
>> >>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>> >>> > >>>>
>> >>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>> >>> pwendell@gmail.com>
>> >>> > wrote:
>> >>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's=20
>> >>> > >>>>> and
>> no 0
>> >>> > or -1
>> >>> > >>>>> votes.
>> >>> > >>>>>
>> >>> > >>>>> +1 (5 Total)
>> >>> > >>>>> Matei Zaharia*
>> >>> > >>>>> Nick Pentreath*
>> >>> > >>>>> Patrick Wendell*
>> >>> > >>>>> Prashant Sharma*
>> >>> > >>>>> Tom Graves*
>> >>> > >>>>>
>> >>> > >>>>> 0 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> -1 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> * =3D Binding Vote
>> >>> > >>>>>
>> >>> > >>>>> As per the incubator release guide [1] I'll be sending=20
>> >>> > >>>>> this
>> to the
>> >>> > >>>>> general incubator list for a final vote from IPMC members.
>> >>> > >>>>>
>> >>> > >>>>> [1]
>> >>> > >>>>>
>> >>> >
>> >>>
>> http://incubator.apache.org/guides/releasemanagement.html#best-practi
>> ce-incubator-release-
>> >>> > >>>>> vote
>> >>> > >>>>>
>> >>> > >>>>>
>> >>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan=20
>> >>> > >>>>> <ev@ooyala.com>
>> wrote:
>> >>> > >>>>>
>> >>> > >>>>>> I'd be personally fine with a standard workflow of
>> assemble-deps
>> >>> +
>> >>> > >>>>>> packaging just the Spark files as separate packages, if=20
>> >>> > >>>>>> it
>> >>> speeds up
>> >>> > >>>>>> everyone's development time.
>> >>> > >>>>>>
>> >>> > >>>>>>
>> >>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>> >>> > mark@clearstorydata.com
>> >>> > >>>>>> >wrote:
>> >>> > >>>>>>
>> >>> > >>>>>> > I don't know how to make sense of the numbers, but=20
>> >>> > >>>>>> > here's
>> what
>> >>> > I've got
>> >>> > >>>>>> > from a very small sample size.
>> >>>
>> >>
>> >>
>>
>

From dev-return-926-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 03:01:05 2013
Return-Path: <dev-return-926-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2424C1089D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 03:01:05 +0000 (UTC)
Received: (qmail 47233 invoked by uid 500); 16 Dec 2013 03:01:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47201 invoked by uid 500); 16 Dec 2013 03:01:04 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 47193 invoked by uid 99); 16 Dec 2013 03:01:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 03:01:04 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of raymond.liu@intel.com designates 134.134.136.20 as permitted sender)
Received: from [134.134.136.20] (HELO mga02.intel.com) (134.134.136.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 03:00:59 +0000
Received: from orsmga002.jf.intel.com ([10.7.209.21])
  by orsmga101.jf.intel.com with ESMTP; 15 Dec 2013 19:00:37 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="4.95,492,1384329600"; 
   d="scan'208";a="452757285"
Received: from fmsmsx108.amr.corp.intel.com ([10.19.9.228])
  by orsmga002.jf.intel.com with ESMTP; 15 Dec 2013 19:00:36 -0800
Received: from FMSMSX110.amr.corp.intel.com (10.18.116.10) by
 FMSMSX108.amr.corp.intel.com (10.19.9.228) with Microsoft SMTP Server (TLS)
 id 14.3.123.3; Sun, 15 Dec 2013 19:00:36 -0800
Received: from shsmsx104.ccr.corp.intel.com (10.239.4.70) by
 fmsmsx110.amr.corp.intel.com (10.18.116.10) with Microsoft SMTP Server (TLS)
 id 14.3.123.3; Sun, 15 Dec 2013 19:00:36 -0800
Received: from shsmsx101.ccr.corp.intel.com ([169.254.1.57]) by
 SHSMSX104.ccr.corp.intel.com ([169.254.5.186]) with mapi id 14.03.0123.003;
 Mon, 16 Dec 2013 11:00:34 +0800
From: "Liu, Raymond" <raymond.liu@intel.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
Thread-Topic: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
Thread-Index: AQHO+gbULNGznYS8EES8Jf+aoBFEi5pWHk5AgAAA53A=
Date: Mon, 16 Dec 2013 03:00:34 +0000
Message-ID: <391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
	<CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
 <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
 <391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com>
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com>
Accept-Language: zh-CN, en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

That issue is for 0.9's solution.

And if you mean for 0.8.1, when you build against hadoop 2.2 Yarn, protobuf=
 is already using 2.5.0 instead of 2.4.1. so it will works fine with hadoop=
 2.2
And regarding on 0.8.1 you build against hadoop 2.2 Yarn, while run upon me=
sos... strange combination, I am not sure, might have problem. If have prob=
lem, you might need to build mesos against 2.5.0, I don't test that, if you=
 got time, mind take a test?

Best Regards,
Raymond Liu


-----Original Message-----
From: Liu, Raymond [mailto:raymond.liu@intel.com]=20
Sent: Monday, December 16, 2013 10:48 AM
To: dev@spark.incubator.apache.org
Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)

Hi Azuryy

Please Check https://spark-project.atlassian.net/browse/SPARK-995 for this =
protobuf version issue

Best Regards,
Raymond Liu

-----Original Message-----
From: Azuryy Yu [mailto:azuryyyu@gmail.com]
Sent: Monday, December 16, 2013 10:30 AM
To: dev@spark.incubator.apache.org
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)

Hi here,
Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some uncomp=
atable API between these two versions.
Hadoop-2.x using protobuf-2.5.0


but if some guys want to run Spark on mesos, then mesos using
protobuf-2.4.1 currently. so we may discuss here for a better solution.



On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:

> Thanks Patrick.
> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
>
>> You can checkout the docs mentioned in the vote thread. There is also=20
>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>>
>> - Patrick
>>
>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> > yarn 2.2, not yarn 0.22, I am so sorry.
>> >
>> >
>> > On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>> >
>> >> Hi,
>> >> Spark-0.8.1 supports yarn 0.22 right? where to find the release note?
>> >> Thanks.
>> >>
>> >>
>> >> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
>> henry.saputra@gmail.com>wrote:
>> >>
>> >>> Yeah seems like it. He was ok with our prev release.
>> >>> Let's wait for his reply
>> >>>
>> >>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>> >>>
>> >>> > Henry - from that thread it looks like sebb's concern was=20
>> >>> > something different than this.
>> >>> >
>> >>> > On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>> >>> henry.saputra@gmail.com>
>> >>> > wrote:
>> >>> > > Hi Patrick,
>> >>> > >
>> >>> > > Yeap I agree, but technically ASF VOTE release on source=20
>> >>> > > only,
>> there
>> >>> > > even debate about it =3D), so putting it in the vote staging
>> artifact
>> >>> > > could confuse people because in our case we do package 3rd=20
>> >>> > > party libraries in the binary jars.
>> >>> > >
>> >>> > > I have sent email to sebb asking clarification about his=20
>> >>> > > concern
>> in
>> >>> > > general@ list.
>> >>> > >
>> >>> > > - Henry
>> >>> > >
>> >>> > > On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
>> pwendell@gmail.com
>> >>> >
>> >>> > wrote:
>> >>> > >> Hey Henry,
>> >>> > >>
>> >>> > >> One thing a lot of people do during the vote is test the
>> binaries and
>> >>> > >> make sure they work. This is really valuable. If you'd like=20
>> >>> > >> I
>> could
>> >>> > >> add a caveat to the vote thread explaining that we are only
>> voting on
>> >>> > >> the source.
>> >>> > >>
>> >>> > >> - Patrick
>> >>> > >>
>> >>> > >> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>> Actually we should be fine putting the binaries there as=20
>> >>> > >>> long
>> as the
>> >>> > >>> VOTE is for the source.
>> >>> > >>>
>> >>> > >>> Let's verify with sebb in the general@ list about his concern.
>> >>> > >>>
>> >>> > >>> - Henry
>> >>> > >>>
>> >>> > >>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>> >>> > henry.saputra@gmail.com> wrote:
>> >>> > >>>> Hi Patrick, as sebb has mentioned let's move the binaries=20
>> >>> > >>>> from
>> the
>> >>> > >>>> voting directory in your people.apache.org directory.
>> >>> > >>>> ASF release voting is for source code and not binaries,=20
>> >>> > >>>> and technically we provide binaries for convenience.
>> >>> > >>>>
>> >>> > >>>> And add link to the KEYS location in the dist[1] to let=20
>> >>> > >>>> verify
>> >>> > signatures.
>> >>> > >>>>
>> >>> > >>>> Sorry for the late response to the VOTE thread, guys.
>> >>> > >>>>
>> >>> > >>>> - Henry
>> >>> > >>>>
>> >>> > >>>> [1]
>> >>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>> >>> > >>>>
>> >>> > >>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>> >>> pwendell@gmail.com>
>> >>> > wrote:
>> >>> > >>>>> The vote is now closed. This vote passes with 5 PPMC +1's=20
>> >>> > >>>>> and
>> no 0
>> >>> > or -1
>> >>> > >>>>> votes.
>> >>> > >>>>>
>> >>> > >>>>> +1 (5 Total)
>> >>> > >>>>> Matei Zaharia*
>> >>> > >>>>> Nick Pentreath*
>> >>> > >>>>> Patrick Wendell*
>> >>> > >>>>> Prashant Sharma*
>> >>> > >>>>> Tom Graves*
>> >>> > >>>>>
>> >>> > >>>>> 0 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> -1 (0 Total)
>> >>> > >>>>>
>> >>> > >>>>> * =3D Binding Vote
>> >>> > >>>>>
>> >>> > >>>>> As per the incubator release guide [1] I'll be sending=20
>> >>> > >>>>> this
>> to the
>> >>> > >>>>> general incubator list for a final vote from IPMC members.
>> >>> > >>>>>
>> >>> > >>>>> [1]
>> >>> > >>>>>
>> >>> >
>> >>>
>> http://incubator.apache.org/guides/releasemanagement.html#best-practi
>> ce-incubator-release-
>> >>> > >>>>> vote
>> >>> > >>>>>
>> >>> > >>>>>
>> >>> > >>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan=20
>> >>> > >>>>> <ev@ooyala.com>
>> wrote:
>> >>> > >>>>>
>> >>> > >>>>>> I'd be personally fine with a standard workflow of
>> assemble-deps
>> >>> +
>> >>> > >>>>>> packaging just the Spark files as separate packages, if=20
>> >>> > >>>>>> it
>> >>> speeds up
>> >>> > >>>>>> everyone's development time.
>> >>> > >>>>>>
>> >>> > >>>>>>
>> >>> > >>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>> >>> > mark@clearstorydata.com
>> >>> > >>>>>> >wrote:
>> >>> > >>>>>>
>> >>> > >>>>>> > I don't know how to make sense of the numbers, but=20
>> >>> > >>>>>> > here's
>> what
>> >>> > I've got
>> >>> > >>>>>> > from a very small sample size.
>> >>>
>> >>
>> >>
>>
>

From dev-return-927-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 06:02:43 2013
Return-Path: <dev-return-927-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 721A410BC9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 06:02:43 +0000 (UTC)
Received: (qmail 97462 invoked by uid 500); 16 Dec 2013 06:02:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96993 invoked by uid 500); 16 Dec 2013 06:02:37 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 96977 invoked by uid 99); 16 Dec 2013 06:02:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 06:02:35 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.181 as permitted sender)
Received: from [209.85.192.181] (HELO mail-pd0-f181.google.com) (209.85.192.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 06:02:31 +0000
Received: by mail-pd0-f181.google.com with SMTP id p10so4883825pdj.40
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 22:02:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=Hr02xUBFKq+TI+cd7SxZ0i5QgPiLzDDzpGr1Rk4uOFA=;
        b=k01Bpr1IIDgqrAUGoDHvoqcCJpF8Kw8ws72YYvpA+9kBfsqb05AKthlVdsp6699Dxd
         oMVRSEx1W3lFFEU+UAGwyrH7HxVuABB/Y69bSq0qgMUEDZlPi6mQz+KkBdyZF5fAbATT
         QosaUM0DPgo8PZrRfNKTr14d3OhLJCdXSGPUvxI/vHNq28z73JbdeUzg80FTTMOV0fzo
         Ryt9K4TA+VS+wJTSSy/xiTpXdRWJvlro++SWb6B7jS68cvrcJ2e4oxGxkPWFbirCT4da
         UwkMvKTO7OPmysIr8y7XSUqUQBB/kkVacNdEwvGxDD19sgB1NL8YuRA3LvF/oCpzI4AI
         k4cw==
X-Received: by 10.68.139.228 with SMTP id rb4mr17900296pbb.15.1387173730814;
        Sun, 15 Dec 2013 22:02:10 -0800 (PST)
Received: from [192.168.1.106] (c-24-7-114-112.hsd1.ca.comcast.net. [24.7.114.112])
        by mx.google.com with ESMTPSA id jn12sm23372699pbd.37.2013.12.15.22.02.08
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 15 Dec 2013 22:02:09 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com>
Date: Sun, 15 Dec 2013 22:02:05 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <F024BED8-3851-4498-8228-0F0D8F2091EB@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com> <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com> <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com> <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com> <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com> <1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com> <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com> <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com> <CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com> <CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com> <CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com> <CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com> <CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com> <CALuGr6YhvtBm3VOa+tLD1ZVtCii_yW2HkZNF7jz7GU2i3Co9Nw@mail.gm
 ail.com> <CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com> <CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com> <CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com> <CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com> <CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com> <CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com> <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com> <391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Mesos will almost certainly compile fine with protobuf 2.5. The protobuf =
compiler and binary format is forward-compatible across releases, it=92s =
just the Java artifacts that aren=92t. You=92ll need to ask Mesos to =
provide a version with protobuf 2.5, and use that with these versions of =
Hadoop.

Matei

On Dec 15, 2013, at 7:00 PM, Liu, Raymond <raymond.liu@intel.com> wrote:

> That issue is for 0.9's solution.
>=20
> And if you mean for 0.8.1, when you build against hadoop 2.2 Yarn, =
protobuf is already using 2.5.0 instead of 2.4.1. so it will works fine =
with hadoop 2.2
> And regarding on 0.8.1 you build against hadoop 2.2 Yarn, while run =
upon mesos... strange combination, I am not sure, might have problem. If =
have problem, you might need to build mesos against 2.5.0, I don't test =
that, if you got time, mind take a test?
>=20
> Best Regards,
> Raymond Liu
>=20
>=20
> -----Original Message-----
> From: Liu, Raymond [mailto:raymond.liu@intel.com]=20
> Sent: Monday, December 16, 2013 10:48 AM
> To: dev@spark.incubator.apache.org
> Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
>=20
> Hi Azuryy
>=20
> Please Check https://spark-project.atlassian.net/browse/SPARK-995 for =
this protobuf version issue
>=20
> Best Regards,
> Raymond Liu
>=20
> -----Original Message-----
> From: Azuryy Yu [mailto:azuryyyu@gmail.com]
> Sent: Monday, December 16, 2013 10:30 AM
> To: dev@spark.incubator.apache.org
> Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
>=20
> Hi here,
> Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some =
uncompatable API between these two versions.
> Hadoop-2.x using protobuf-2.5.0
>=20
>=20
> but if some guys want to run Spark on mesos, then mesos using
> protobuf-2.4.1 currently. so we may discuss here for a better =
solution.
>=20
>=20
>=20
> On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>=20
>> Thanks Patrick.
>> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
>>=20
>>> You can checkout the docs mentioned in the vote thread. There is =
also=20
>>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>>>=20
>>> - Patrick
>>>=20
>>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> =
wrote:
>>>> yarn 2.2, not yarn 0.22, I am so sorry.
>>>>=20
>>>>=20
>>>> On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com> =
wrote:
>>>>=20
>>>>> Hi,
>>>>> Spark-0.8.1 supports yarn 0.22 right? where to find the release =
note?
>>>>> Thanks.
>>>>>=20
>>>>>=20
>>>>> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
>>> henry.saputra@gmail.com>wrote:
>>>>>=20
>>>>>> Yeah seems like it. He was ok with our prev release.
>>>>>> Let's wait for his reply
>>>>>>=20
>>>>>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>>>>>>=20
>>>>>>> Henry - from that thread it looks like sebb's concern was=20
>>>>>>> something different than this.
>>>>>>>=20
>>>>>>> On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>>>>>> henry.saputra@gmail.com>
>>>>>>> wrote:
>>>>>>>> Hi Patrick,
>>>>>>>>=20
>>>>>>>> Yeap I agree, but technically ASF VOTE release on source=20
>>>>>>>> only,
>>> there
>>>>>>>> even debate about it =3D), so putting it in the vote staging
>>> artifact
>>>>>>>> could confuse people because in our case we do package 3rd=20
>>>>>>>> party libraries in the binary jars.
>>>>>>>>=20
>>>>>>>> I have sent email to sebb asking clarification about his=20
>>>>>>>> concern
>>> in
>>>>>>>> general@ list.
>>>>>>>>=20
>>>>>>>> - Henry
>>>>>>>>=20
>>>>>>>> On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
>>> pwendell@gmail.com
>>>>>>>=20
>>>>>>> wrote:
>>>>>>>>> Hey Henry,
>>>>>>>>>=20
>>>>>>>>> One thing a lot of people do during the vote is test the
>>> binaries and
>>>>>>>>> make sure they work. This is really valuable. If you'd like=20
>>>>>>>>> I
>>> could
>>>>>>>>> add a caveat to the vote thread explaining that we are only
>>> voting on
>>>>>>>>> the source.
>>>>>>>>>=20
>>>>>>>>> - Patrick
>>>>>>>>>=20
>>>>>>>>> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>>>>>>> henry.saputra@gmail.com> wrote:
>>>>>>>>>> Actually we should be fine putting the binaries there as=20
>>>>>>>>>> long
>>> as the
>>>>>>>>>> VOTE is for the source.
>>>>>>>>>>=20
>>>>>>>>>> Let's verify with sebb in the general@ list about his =
concern.
>>>>>>>>>>=20
>>>>>>>>>> - Henry
>>>>>>>>>>=20
>>>>>>>>>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>>>>>>> henry.saputra@gmail.com> wrote:
>>>>>>>>>>> Hi Patrick, as sebb has mentioned let's move the binaries=20
>>>>>>>>>>> from
>>> the
>>>>>>>>>>> voting directory in your people.apache.org directory.
>>>>>>>>>>> ASF release voting is for source code and not binaries,=20
>>>>>>>>>>> and technically we provide binaries for convenience.
>>>>>>>>>>>=20
>>>>>>>>>>> And add link to the KEYS location in the dist[1] to let=20
>>>>>>>>>>> verify
>>>>>>> signatures.
>>>>>>>>>>>=20
>>>>>>>>>>> Sorry for the late response to the VOTE thread, guys.
>>>>>>>>>>>=20
>>>>>>>>>>> - Henry
>>>>>>>>>>>=20
>>>>>>>>>>> [1]
>>>>>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>>>>>>>>>>=20
>>>>>>>>>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>>>>>> pwendell@gmail.com>
>>>>>>> wrote:
>>>>>>>>>>>> The vote is now closed. This vote passes with 5 PPMC +1's=20=

>>>>>>>>>>>> and
>>> no 0
>>>>>>> or -1
>>>>>>>>>>>> votes.
>>>>>>>>>>>>=20
>>>>>>>>>>>> +1 (5 Total)
>>>>>>>>>>>> Matei Zaharia*
>>>>>>>>>>>> Nick Pentreath*
>>>>>>>>>>>> Patrick Wendell*
>>>>>>>>>>>> Prashant Sharma*
>>>>>>>>>>>> Tom Graves*
>>>>>>>>>>>>=20
>>>>>>>>>>>> 0 (0 Total)
>>>>>>>>>>>>=20
>>>>>>>>>>>> -1 (0 Total)
>>>>>>>>>>>>=20
>>>>>>>>>>>> * =3D Binding Vote
>>>>>>>>>>>>=20
>>>>>>>>>>>> As per the incubator release guide [1] I'll be sending=20
>>>>>>>>>>>> this
>>> to the
>>>>>>>>>>>> general incubator list for a final vote from IPMC members.
>>>>>>>>>>>>=20
>>>>>>>>>>>> [1]
>>>>>>>>>>>>=20
>>>>>>>=20
>>>>>>=20
>>> =
http://incubator.apache.org/guides/releasemanagement.html#best-practi
>>> ce-incubator-release-
>>>>>>>>>>>> vote
>>>>>>>>>>>>=20
>>>>>>>>>>>>=20
>>>>>>>>>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan=20
>>>>>>>>>>>> <ev@ooyala.com>
>>> wrote:
>>>>>>>>>>>>=20
>>>>>>>>>>>>> I'd be personally fine with a standard workflow of
>>> assemble-deps
>>>>>> +
>>>>>>>>>>>>> packaging just the Spark files as separate packages, if=20
>>>>>>>>>>>>> it
>>>>>> speeds up
>>>>>>>>>>>>> everyone's development time.
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>>>>>>> mark@clearstorydata.com
>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> I don't know how to make sense of the numbers, but=20
>>>>>>>>>>>>>> here's
>>> what
>>>>>>> I've got
>>>>>>>>>>>>>> from a very small sample size.
>>>>>>=20
>>>>>=20
>>>>>=20
>>>=20
>>=20


From dev-return-928-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 06:26:15 2013
Return-Path: <dev-return-928-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A0EAF10C25
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 06:26:15 +0000 (UTC)
Received: (qmail 12362 invoked by uid 500); 16 Dec 2013 06:26:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12040 invoked by uid 500); 16 Dec 2013 06:26:10 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 12032 invoked by uid 99); 16 Dec 2013 06:26:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 06:26:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of azuryyyu@gmail.com designates 209.85.220.169 as permitted sender)
Received: from [209.85.220.169] (HELO mail-vc0-f169.google.com) (209.85.220.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 06:26:05 +0000
Received: by mail-vc0-f169.google.com with SMTP id hu19so2947978vcb.28
        for <dev@spark.incubator.apache.org>; Sun, 15 Dec 2013 22:25:45 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=4fRux/HKO9WJVlHyIEOhB0pVZkCfY0SjUPk0LEY6zTc=;
        b=a95oJxbx0byY0H4VYWzox4bGu1rAyfaLUBNtY+cL79nbE4HwgMAiUowqz6fHpKfPaN
         U/VHjWz2EeqUpKwXokkO90Wpu+IaLzPVcB7EsqtyOZa4Fx9fnihn1JgGNtnnD+MA0U3M
         8mrTi/UcjidgNKigrQlkA+9XHXClYV7CRnjRYGuxMpe4rep3W8qqZd6yJuGmFHBRVrHY
         7kbRYVTSLe6Vnr25nrVQmRbIu9CiSDXIU880auPZHA5l4IixtOO8hhM8bqIYtLByR61G
         auL8D+rTPqRYU+jPCo6HZ/5ClRhHr5Q/3t6n10GUStNeW78UQp+Zj4+Z8ufC2c6AO6gg
         4hVw==
MIME-Version: 1.0
X-Received: by 10.220.244.132 with SMTP id lq4mr3217810vcb.31.1387175145089;
 Sun, 15 Dec 2013 22:25:45 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Sun, 15 Dec 2013 22:25:44 -0800 (PST)
In-Reply-To: <F024BED8-3851-4498-8228-0F0D8F2091EB@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
	<CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
	<CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com>
	<F024BED8-3851-4498-8228-0F0D8F2091EB@gmail.com>
Date: Mon, 16 Dec 2013 14:25:44 +0800
Message-ID: <CALr1C9qnOpn=aj=HaeraJZZpg5d=C-AoV=DC=U_o6jZfedj0dw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0115f682c3af9d04eda0e16f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0115f682c3af9d04eda0e16f
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Maybe I am not give a clear description. I am runing Spark on yarn. instead
of Mesos. I just want build Spark with protobuf2.5. I am not care about
Mesos.

I've changed Spark pom.xml to probobuf2.5 manually.




On Mon, Dec 16, 2013 at 2:02 PM, Matei Zaharia <matei.zaharia@gmail.com>wro=
te:

> Mesos will almost certainly compile fine with protobuf 2.5. The protobuf
> compiler and binary format is forward-compatible across releases, it=92s =
just
> the Java artifacts that aren=92t. You=92ll need to ask Mesos to provide a
> version with protobuf 2.5, and use that with these versions of Hadoop.
>
> Matei
>
> On Dec 15, 2013, at 7:00 PM, Liu, Raymond <raymond.liu@intel.com> wrote:
>
> > That issue is for 0.9's solution.
> >
> > And if you mean for 0.8.1, when you build against hadoop 2.2 Yarn,
> protobuf is already using 2.5.0 instead of 2.4.1. so it will works fine
> with hadoop 2.2
> > And regarding on 0.8.1 you build against hadoop 2.2 Yarn, while run upo=
n
> mesos... strange combination, I am not sure, might have problem. If have
> problem, you might need to build mesos against 2.5.0, I don't test that, =
if
> you got time, mind take a test?
> >
> > Best Regards,
> > Raymond Liu
> >
> >
> > -----Original Message-----
> > From: Liu, Raymond [mailto:raymond.liu@intel.com]
> > Sent: Monday, December 16, 2013 10:48 AM
> > To: dev@spark.incubator.apache.org
> > Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
> >
> > Hi Azuryy
> >
> > Please Check https://spark-project.atlassian.net/browse/SPARK-995 for
> this protobuf version issue
> >
> > Best Regards,
> > Raymond Liu
> >
> > -----Original Message-----
> > From: Azuryy Yu [mailto:azuryyyu@gmail.com]
> > Sent: Monday, December 16, 2013 10:30 AM
> > To: dev@spark.incubator.apache.org
> > Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
> >
> > Hi here,
> > Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some
> uncompatable API between these two versions.
> > Hadoop-2.x using protobuf-2.5.0
> >
> >
> > but if some guys want to run Spark on mesos, then mesos using
> > protobuf-2.4.1 currently. so we may discuss here for a better solution.
> >
> >
> >
> > On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote:
> >
> >> Thanks Patrick.
> >> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
> >>
> >>> You can checkout the docs mentioned in the vote thread. There is also
> >>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
> >>>
> >>> - Patrick
> >>>
> >>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> wrote=
:
> >>>> yarn 2.2, not yarn 0.22, I am so sorry.
> >>>>
> >>>>
> >>>> On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com>
> wrote:
> >>>>
> >>>>> Hi,
> >>>>> Spark-0.8.1 supports yarn 0.22 right? where to find the release not=
e?
> >>>>> Thanks.
> >>>>>
> >>>>>
> >>>>> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
> >>> henry.saputra@gmail.com>wrote:
> >>>>>
> >>>>>> Yeah seems like it. He was ok with our prev release.
> >>>>>> Let's wait for his reply
> >>>>>>
> >>>>>> On Saturday, December 14, 2013, Patrick Wendell wrote:
> >>>>>>
> >>>>>>> Henry - from that thread it looks like sebb's concern was
> >>>>>>> something different than this.
> >>>>>>>
> >>>>>>> On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
> >>>>>> henry.saputra@gmail.com>
> >>>>>>> wrote:
> >>>>>>>> Hi Patrick,
> >>>>>>>>
> >>>>>>>> Yeap I agree, but technically ASF VOTE release on source
> >>>>>>>> only,
> >>> there
> >>>>>>>> even debate about it =3D), so putting it in the vote staging
> >>> artifact
> >>>>>>>> could confuse people because in our case we do package 3rd
> >>>>>>>> party libraries in the binary jars.
> >>>>>>>>
> >>>>>>>> I have sent email to sebb asking clarification about his
> >>>>>>>> concern
> >>> in
> >>>>>>>> general@ list.
> >>>>>>>>
> >>>>>>>> - Henry
> >>>>>>>>
> >>>>>>>> On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
> >>> pwendell@gmail.com
> >>>>>>>
> >>>>>>> wrote:
> >>>>>>>>> Hey Henry,
> >>>>>>>>>
> >>>>>>>>> One thing a lot of people do during the vote is test the
> >>> binaries and
> >>>>>>>>> make sure they work. This is really valuable. If you'd like
> >>>>>>>>> I
> >>> could
> >>>>>>>>> add a caveat to the vote thread explaining that we are only
> >>> voting on
> >>>>>>>>> the source.
> >>>>>>>>>
> >>>>>>>>> - Patrick
> >>>>>>>>>
> >>>>>>>>> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
> >>>>>>> henry.saputra@gmail.com> wrote:
> >>>>>>>>>> Actually we should be fine putting the binaries there as
> >>>>>>>>>> long
> >>> as the
> >>>>>>>>>> VOTE is for the source.
> >>>>>>>>>>
> >>>>>>>>>> Let's verify with sebb in the general@ list about his concern.
> >>>>>>>>>>
> >>>>>>>>>> - Henry
> >>>>>>>>>>
> >>>>>>>>>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
> >>>>>>> henry.saputra@gmail.com> wrote:
> >>>>>>>>>>> Hi Patrick, as sebb has mentioned let's move the binaries
> >>>>>>>>>>> from
> >>> the
> >>>>>>>>>>> voting directory in your people.apache.org directory.
> >>>>>>>>>>> ASF release voting is for source code and not binaries,
> >>>>>>>>>>> and technically we provide binaries for convenience.
> >>>>>>>>>>>
> >>>>>>>>>>> And add link to the KEYS location in the dist[1] to let
> >>>>>>>>>>> verify
> >>>>>>> signatures.
> >>>>>>>>>>>
> >>>>>>>>>>> Sorry for the late response to the VOTE thread, guys.
> >>>>>>>>>>>
> >>>>>>>>>>> - Henry
> >>>>>>>>>>>
> >>>>>>>>>>> [1]
> >>>>>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
> >>>>>>>>>>>
> >>>>>>>>>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
> >>>>>> pwendell@gmail.com>
> >>>>>>> wrote:
> >>>>>>>>>>>> The vote is now closed. This vote passes with 5 PPMC +1's
> >>>>>>>>>>>> and
> >>> no 0
> >>>>>>> or -1
> >>>>>>>>>>>> votes.
> >>>>>>>>>>>>
> >>>>>>>>>>>> +1 (5 Total)
> >>>>>>>>>>>> Matei Zaharia*
> >>>>>>>>>>>> Nick Pentreath*
> >>>>>>>>>>>> Patrick Wendell*
> >>>>>>>>>>>> Prashant Sharma*
> >>>>>>>>>>>> Tom Graves*
> >>>>>>>>>>>>
> >>>>>>>>>>>> 0 (0 Total)
> >>>>>>>>>>>>
> >>>>>>>>>>>> -1 (0 Total)
> >>>>>>>>>>>>
> >>>>>>>>>>>> * =3D Binding Vote
> >>>>>>>>>>>>
> >>>>>>>>>>>> As per the incubator release guide [1] I'll be sending
> >>>>>>>>>>>> this
> >>> to the
> >>>>>>>>>>>> general incubator list for a final vote from IPMC members.
> >>>>>>>>>>>>
> >>>>>>>>>>>> [1]
> >>>>>>>>>>>>
> >>>>>>>
> >>>>>>
> >>> http://incubator.apache.org/guides/releasemanagement.html#best-practi
> >>> ce-incubator-release-
> >>>>>>>>>>>> vote
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan
> >>>>>>>>>>>> <ev@ooyala.com>
> >>> wrote:
> >>>>>>>>>>>>
> >>>>>>>>>>>>> I'd be personally fine with a standard workflow of
> >>> assemble-deps
> >>>>>> +
> >>>>>>>>>>>>> packaging just the Spark files as separate packages, if
> >>>>>>>>>>>>> it
> >>>>>> speeds up
> >>>>>>>>>>>>> everyone's development time.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
> >>>>>>> mark@clearstorydata.com
> >>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>> I don't know how to make sense of the numbers, but
> >>>>>>>>>>>>>> here's
> >>> what
> >>>>>>> I've got
> >>>>>>>>>>>>>> from a very small sample size.
> >>>>>>
> >>>>>
> >>>>>
> >>>
> >>
>
>

--089e0115f682c3af9d04eda0e16f--

From dev-return-929-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 08:23:11 2013
Return-Path: <dev-return-929-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E067910EC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 08:23:11 +0000 (UTC)
Received: (qmail 61253 invoked by uid 500); 16 Dec 2013 08:23:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61214 invoked by uid 500); 16 Dec 2013 08:23:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 61205 invoked by uid 99); 16 Dec 2013 08:23:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 08:23:00 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 08:22:56 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so5049111pdj.3
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 00:22:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=nCZqTRlITLLYUy1NsbJHM79tgkCv98Y3J/T1GZrX0qc=;
        b=VsHoHk3KkBAyj2VtpKEY4AoGy8ucoXuW9/ozw3feBclmDdRVXBp/hIGUCW2wQ2ZiCW
         aoqGNoSEP3Utj5mvFMSrGf1wKilvMTn6av693ONF2eW0HQfRcDU47Wr29R9nUjFBMg9Y
         K6nALPjkSsqNl5Govq0+75gE99sQM8PrRAR+dyuXzM9tW25gnVQmVU5YMN5RoH8TdwBQ
         Xgyy+P62xnLohTCeiaPqON5/2ApV35peAVLNDlkNo6g1b1Fc3vlJS4uyividSMYMRvF9
         aLsWczpcddG7O2mX+GF3uSqu+bEhFHpcypw3eaZ/IKlJQHoPJsOvx28gP/WeS0QLqKLp
         fmrA==
X-Received: by 10.66.66.42 with SMTP id c10mr18572450pat.98.1387182155958;
        Mon, 16 Dec 2013 00:22:35 -0800 (PST)
Received: from [192.168.1.106] (c-24-7-114-112.hsd1.ca.comcast.net. [24.7.114.112])
        by mx.google.com with ESMTPSA id ye1sm33429803pab.19.2013.12.16.00.22.33
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 16 Dec 2013 00:22:34 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CALr1C9qnOpn=aj=HaeraJZZpg5d=C-AoV=DC=U_o6jZfedj0dw@mail.gmail.com>
Date: Mon, 16 Dec 2013 00:22:28 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <67221AEB-9247-4623-AE54-DBA18588D399@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com> <8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com> <CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com> <CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com> <CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com> <CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com> <1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com> <CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com> <CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com> <CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com> <CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com> <CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com> <CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com> <CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com> <CABPQxsvpRXb61CsS8iwnWSBdtGCWeQo8c8=dvojTF+tHH7DY8g@mail.gm
 ail.com> <CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com> <CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com> <CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com> <CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com> <CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com> <CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com> <391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com> <391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com> <F024BED8-3851-4498-8228-0F0D8F2091EB@gmail.com> <CALr1C9qnOpn=aj=HaeraJZZpg5d=C-AoV=DC=U_o6jZfedj0dw@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Are you using 0.8.1? It will build with protobuf 2.5 instead of 2.4 as =
long as you make it depend on Hadoop 2.2. But make sure you build it =
with SPARK_HADOOP_VERSION=3D2.2.0 or whatever.

Spark 0.8.0 doesn=92t support Hadoop 2.2 due to this issue.

Matei

On Dec 15, 2013, at 10:25 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:

> Maybe I am not give a clear description. I am runing Spark on yarn. =
instead
> of Mesos. I just want build Spark with protobuf2.5. I am not care =
about
> Mesos.
>=20
> I've changed Spark pom.xml to probobuf2.5 manually.
>=20
>=20
>=20
>=20
> On Mon, Dec 16, 2013 at 2:02 PM, Matei Zaharia =
<matei.zaharia@gmail.com>wrote:
>=20
>> Mesos will almost certainly compile fine with protobuf 2.5. The =
protobuf
>> compiler and binary format is forward-compatible across releases, =
it=92s just
>> the Java artifacts that aren=92t. You=92ll need to ask Mesos to =
provide a
>> version with protobuf 2.5, and use that with these versions of =
Hadoop.
>>=20
>> Matei
>>=20
>> On Dec 15, 2013, at 7:00 PM, Liu, Raymond <raymond.liu@intel.com> =
wrote:
>>=20
>>> That issue is for 0.9's solution.
>>>=20
>>> And if you mean for 0.8.1, when you build against hadoop 2.2 Yarn,
>> protobuf is already using 2.5.0 instead of 2.4.1. so it will works =
fine
>> with hadoop 2.2
>>> And regarding on 0.8.1 you build against hadoop 2.2 Yarn, while run =
upon
>> mesos... strange combination, I am not sure, might have problem. If =
have
>> problem, you might need to build mesos against 2.5.0, I don't test =
that, if
>> you got time, mind take a test?
>>>=20
>>> Best Regards,
>>> Raymond Liu
>>>=20
>>>=20
>>> -----Original Message-----
>>> From: Liu, Raymond [mailto:raymond.liu@intel.com]
>>> Sent: Monday, December 16, 2013 10:48 AM
>>> To: dev@spark.incubator.apache.org
>>> Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
>>>=20
>>> Hi Azuryy
>>>=20
>>> Please Check https://spark-project.atlassian.net/browse/SPARK-995 =
for
>> this protobuf version issue
>>>=20
>>> Best Regards,
>>> Raymond Liu
>>>=20
>>> -----Original Message-----
>>> From: Azuryy Yu [mailto:azuryyyu@gmail.com]
>>> Sent: Monday, December 16, 2013 10:30 AM
>>> To: dev@spark.incubator.apache.org
>>> Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
>>>=20
>>> Hi here,
>>> Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some
>> uncompatable API between these two versions.
>>> Hadoop-2.x using protobuf-2.5.0
>>>=20
>>>=20
>>> but if some guys want to run Spark on mesos, then mesos using
>>> protobuf-2.4.1 currently. so we may discuss here for a better =
solution.
>>>=20
>>>=20
>>>=20
>>> On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> =
wrote:
>>>=20
>>>> Thanks Patrick.
>>>> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
>>>>=20
>>>>> You can checkout the docs mentioned in the vote thread. There is =
also
>>>>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
>>>>>=20
>>>>> - Patrick
>>>>>=20
>>>>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com> =
wrote:
>>>>>> yarn 2.2, not yarn 0.22, I am so sorry.
>>>>>>=20
>>>>>>=20
>>>>>> On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com>
>> wrote:
>>>>>>=20
>>>>>>> Hi,
>>>>>>> Spark-0.8.1 supports yarn 0.22 right? where to find the release =
note?
>>>>>>> Thanks.
>>>>>>>=20
>>>>>>>=20
>>>>>>> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
>>>>> henry.saputra@gmail.com>wrote:
>>>>>>>=20
>>>>>>>> Yeah seems like it. He was ok with our prev release.
>>>>>>>> Let's wait for his reply
>>>>>>>>=20
>>>>>>>> On Saturday, December 14, 2013, Patrick Wendell wrote:
>>>>>>>>=20
>>>>>>>>> Henry - from that thread it looks like sebb's concern was
>>>>>>>>> something different than this.
>>>>>>>>>=20
>>>>>>>>> On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
>>>>>>>> henry.saputra@gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>> Hi Patrick,
>>>>>>>>>>=20
>>>>>>>>>> Yeap I agree, but technically ASF VOTE release on source
>>>>>>>>>> only,
>>>>> there
>>>>>>>>>> even debate about it =3D), so putting it in the vote staging
>>>>> artifact
>>>>>>>>>> could confuse people because in our case we do package 3rd
>>>>>>>>>> party libraries in the binary jars.
>>>>>>>>>>=20
>>>>>>>>>> I have sent email to sebb asking clarification about his
>>>>>>>>>> concern
>>>>> in
>>>>>>>>>> general@ list.
>>>>>>>>>>=20
>>>>>>>>>> - Henry
>>>>>>>>>>=20
>>>>>>>>>> On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
>>>>> pwendell@gmail.com
>>>>>>>>>=20
>>>>>>>>> wrote:
>>>>>>>>>>> Hey Henry,
>>>>>>>>>>>=20
>>>>>>>>>>> One thing a lot of people do during the vote is test the
>>>>> binaries and
>>>>>>>>>>> make sure they work. This is really valuable. If you'd like
>>>>>>>>>>> I
>>>>> could
>>>>>>>>>>> add a caveat to the vote thread explaining that we are only
>>>>> voting on
>>>>>>>>>>> the source.
>>>>>>>>>>>=20
>>>>>>>>>>> - Patrick
>>>>>>>>>>>=20
>>>>>>>>>>> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
>>>>>>>>> henry.saputra@gmail.com> wrote:
>>>>>>>>>>>> Actually we should be fine putting the binaries there as
>>>>>>>>>>>> long
>>>>> as the
>>>>>>>>>>>> VOTE is for the source.
>>>>>>>>>>>>=20
>>>>>>>>>>>> Let's verify with sebb in the general@ list about his =
concern.
>>>>>>>>>>>>=20
>>>>>>>>>>>> - Henry
>>>>>>>>>>>>=20
>>>>>>>>>>>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
>>>>>>>>> henry.saputra@gmail.com> wrote:
>>>>>>>>>>>>> Hi Patrick, as sebb has mentioned let's move the binaries
>>>>>>>>>>>>> from
>>>>> the
>>>>>>>>>>>>> voting directory in your people.apache.org directory.
>>>>>>>>>>>>> ASF release voting is for source code and not binaries,
>>>>>>>>>>>>> and technically we provide binaries for convenience.
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> And add link to the KEYS location in the dist[1] to let
>>>>>>>>>>>>> verify
>>>>>>>>> signatures.
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> Sorry for the late response to the VOTE thread, guys.
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> - Henry
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> [1]
>>>>>>>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
>>>>>>>> pwendell@gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>>>>>> The vote is now closed. This vote passes with 5 PPMC +1's
>>>>>>>>>>>>>> and
>>>>> no 0
>>>>>>>>> or -1
>>>>>>>>>>>>>> votes.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> +1 (5 Total)
>>>>>>>>>>>>>> Matei Zaharia*
>>>>>>>>>>>>>> Nick Pentreath*
>>>>>>>>>>>>>> Patrick Wendell*
>>>>>>>>>>>>>> Prashant Sharma*
>>>>>>>>>>>>>> Tom Graves*
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> 0 (0 Total)
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> -1 (0 Total)
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> * =3D Binding Vote
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> As per the incubator release guide [1] I'll be sending
>>>>>>>>>>>>>> this
>>>>> to the
>>>>>>>>>>>>>> general incubator list for a final vote from IPMC =
members.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> [1]
>>>>>>>>>>>>>>=20
>>>>>>>>>=20
>>>>>>>>=20
>>>>> =
http://incubator.apache.org/guides/releasemanagement.html#best-practi
>>>>> ce-incubator-release-
>>>>>>>>>>>>>> vote
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan
>>>>>>>>>>>>>> <ev@ooyala.com>
>>>>> wrote:
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> I'd be personally fine with a standard workflow of
>>>>> assemble-deps
>>>>>>>> +
>>>>>>>>>>>>>>> packaging just the Spark files as separate packages, if
>>>>>>>>>>>>>>> it
>>>>>>>> speeds up
>>>>>>>>>>>>>>> everyone's development time.
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
>>>>>>>>> mark@clearstorydata.com
>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> I don't know how to make sense of the numbers, but
>>>>>>>>>>>>>>>> here's
>>>>> what
>>>>>>>>> I've got
>>>>>>>>>>>>>>>> from a very small sample size.
>>>>>>>>=20
>>>>>>>=20
>>>>>>>=20
>>>>>=20
>>>>=20
>>=20
>>=20


From dev-return-930-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 08:39:17 2013
Return-Path: <dev-return-930-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6B3AB10F42
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 08:39:17 +0000 (UTC)
Received: (qmail 85894 invoked by uid 500); 16 Dec 2013 08:39:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85661 invoked by uid 500); 16 Dec 2013 08:39:12 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 85653 invoked by uid 99); 16 Dec 2013 08:39:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 08:39:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of azuryyyu@gmail.com designates 209.85.128.174 as permitted sender)
Received: from [209.85.128.174] (HELO mail-ve0-f174.google.com) (209.85.128.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 08:39:06 +0000
Received: by mail-ve0-f174.google.com with SMTP id pa12so3034935veb.19
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 00:38:45 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=IsGpAVylca1Repdfd3k4gzFyGNktSATcyvwIxt2BP+4=;
        b=ZRBU7/3C8PmiTxyby0mS13lC0+CLa8DYLlGAkqFkoXkag/Rh7JxYy4DEGPEMRQ/DOp
         3HeB0LIiycRFlIu022k0Mv6ogBaOLNepM5dM4bsXLxGzKQQRjJ8hVoH+6SNLmukGCIf8
         0XcsfRYDL1vqIO9MjceSxH6gP0dWzOVwq77yOy+9nwQsZhcZWnd3fb0Lvsi1oCLlhmWZ
         FG5zGZlta5AqkWQfp9VZOT5GnO1vxxKCoa8Q5oVfaY9p2rYWQ7k3HWAplvjcLRBtHBQt
         z7NO1cC7Dy5fAoDkzvOJmhkG/oJw4wjGWgqLnGvLTE7g8A0GbysIHUDZx6Y2amoNVTXj
         xFGw==
MIME-Version: 1.0
X-Received: by 10.221.60.134 with SMTP id ws6mr1366965vcb.44.1387183124942;
 Mon, 16 Dec 2013 00:38:44 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Mon, 16 Dec 2013 00:38:44 -0800 (PST)
In-Reply-To: <67221AEB-9247-4623-AE54-DBA18588D399@gmail.com>
References: <CABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA@mail.gmail.com>
	<8AAB1384-AC7E-4276-9BEE-77B2F8466F86@gmail.com>
	<CAOYDGoD0BK_khHmTBLpEeaFh+ZOGGd+KMkMZYMb0NUOiXAA5mA@mail.gmail.com>
	<CAOYDGoD5++OiX6UpmQcE2N1RZqro7QfVs4iazAe28ks4BgSjXw@mail.gmail.com>
	<CAAsvFP=oMi4Y3+FW_jc8ypVyU6tArnpDFmm+09OvjNUnqZ-kBQ@mail.gmail.com>
	<CAOYDGoBoAG_Ld-ahgPGGbLVDq8FPUMwfBbg2u4h4A0mWczF2RA@mail.gmail.com>
	<1D6C09D2-6207-4729-8B06-CBDD4A25C42E@gmail.com>
	<CABPQxsshsWn=0qEevakv9u25v3zhWVw=RD1iVSQWvHO5kdEmoA@mail.gmail.com>
	<CAAsvFPmVFeRt5A_Ps0ARtoKK=2w8SQOC13RdOS8mFCcHqXJ7Rg@mail.gmail.com>
	<CADWPM3iSPjD9=f+phnT9LJDsWsf=xe4LJx6NOxJeV6XsAv+fmg@mail.gmail.com>
	<CABPQxstS2R44SG5_+8dBOO30-n=uQaDU_DEYZCT8xruwRAXcMQ@mail.gmail.com>
	<CALuGr6YFNj5L4e2HzpFCP3dv4tOBaZi2H58KOtun27nrXfQ8qA@mail.gmail.com>
	<CALuGr6ZA-B1FMWLa+M_w7Wn1wK2G3Gk=pdGSUL3iZ78uL3k4iA@mail.gmail.com>
	<CABPQxst3ZTTwj+_ww-Sm=j1ZE1qSDoqMzQ6-o4_M5hvkyJvs+Q@mail.gmail.com>
	<CALuGr6Z6uBuH=BPjx3D2=HjMnGKsrwZTbm3Q-_3WBptSwiy57w@mail.gmail.com>
	<CALr1C9rPgYV0Bk_RQ4dEJ=jPcgZszOcj9sVRHXtNHh=3sJZkFA@mail.gmail.com>
	<CALr1C9paoGj_N_WLq+TiWJyMQ9yiKky+Bxwqy55oNH+6xBQy+g@mail.gmail.com>
	<CABPQxsvzoUVrR7zxtf4mTMVWLke1OES-BLRwUc2p8ydF_qydag@mail.gmail.com>
	<CALr1C9odTEmzYMCYXsVQ15nzt+c8NXMawv0ZAwyyYKqqt27phw@mail.gmail.com>
	<CALr1C9qUCU+ZsSaN58H+9SVv_5Z=NHUfqfH2oHaGEWGg2jdcPw@mail.gmail.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F5677@SHSMSX101.ccr.corp.intel.com>
	<391D65D0EBFC9B4B95E117F72A360F1A010F56A4@SHSMSX101.ccr.corp.intel.com>
	<F024BED8-3851-4498-8228-0F0D8F2091EB@gmail.com>
	<CALr1C9qnOpn=aj=HaeraJZZpg5d=C-AoV=DC=U_o6jZfedj0dw@mail.gmail.com>
	<67221AEB-9247-4623-AE54-DBA18588D399@gmail.com>
Date: Mon, 16 Dec 2013 16:38:44 +0800
Message-ID: <CALr1C9pqRTp_E8PYehSmvHyB30Q2sOjcdzpgV=DMTQjW_0j6Vg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a113393a46695ea04eda2bd94
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113393a46695ea04eda2bd94
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Hi Matei,
Thanks for your response. I am using 0.8.1, and yes, It was using
protobuf-2.5. Sorry I made a mistake before this email.

I used -Phadoop2-yarn, so I don't find it using pb-2.5, actually, I should
use -Pnew-yarn.

Thank you Matei.




On Mon, Dec 16, 2013 at 4:22 PM, Matei Zaharia <matei.zaharia@gmail.com>wro=
te:

> Are you using 0.8.1? It will build with protobuf 2.5 instead of 2.4 as
> long as you make it depend on Hadoop 2.2. But make sure you build it with
> SPARK_HADOOP_VERSION=3D2.2.0 or whatever.
>
> Spark 0.8.0 doesn=92t support Hadoop 2.2 due to this issue.
>
> Matei
>
> On Dec 15, 2013, at 10:25 PM, Azuryy Yu <azuryyyu@gmail.com> wrote:
>
> > Maybe I am not give a clear description. I am runing Spark on yarn.
> instead
> > of Mesos. I just want build Spark with protobuf2.5. I am not care about
> > Mesos.
> >
> > I've changed Spark pom.xml to probobuf2.5 manually.
> >
> >
> >
> >
> > On Mon, Dec 16, 2013 at 2:02 PM, Matei Zaharia <matei.zaharia@gmail.com
> >wrote:
> >
> >> Mesos will almost certainly compile fine with protobuf 2.5. The protob=
uf
> >> compiler and binary format is forward-compatible across releases, it=
=92s
> just
> >> the Java artifacts that aren=92t. You=92ll need to ask Mesos to provid=
e a
> >> version with protobuf 2.5, and use that with these versions of Hadoop.
> >>
> >> Matei
> >>
> >> On Dec 15, 2013, at 7:00 PM, Liu, Raymond <raymond.liu@intel.com>
> wrote:
> >>
> >>> That issue is for 0.9's solution.
> >>>
> >>> And if you mean for 0.8.1, when you build against hadoop 2.2 Yarn,
> >> protobuf is already using 2.5.0 instead of 2.4.1. so it will works fin=
e
> >> with hadoop 2.2
> >>> And regarding on 0.8.1 you build against hadoop 2.2 Yarn, while run
> upon
> >> mesos... strange combination, I am not sure, might have problem. If ha=
ve
> >> problem, you might need to build mesos against 2.5.0, I don't test
> that, if
> >> you got time, mind take a test?
> >>>
> >>> Best Regards,
> >>> Raymond Liu
> >>>
> >>>
> >>> -----Original Message-----
> >>> From: Liu, Raymond [mailto:raymond.liu@intel.com]
> >>> Sent: Monday, December 16, 2013 10:48 AM
> >>> To: dev@spark.incubator.apache.org
> >>> Subject: RE: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
> >>>
> >>> Hi Azuryy
> >>>
> >>> Please Check https://spark-project.atlassian.net/browse/SPARK-995 for
> >> this protobuf version issue
> >>>
> >>> Best Regards,
> >>> Raymond Liu
> >>>
> >>> -----Original Message-----
> >>> From: Azuryy Yu [mailto:azuryyyu@gmail.com]
> >>> Sent: Monday, December 16, 2013 10:30 AM
> >>> To: dev@spark.incubator.apache.org
> >>> Subject: Re: [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
> >>>
> >>> Hi here,
> >>> Do we have plan to upgrade protobuf from 2.4.1 to 2.5.0? PB has some
> >> uncompatable API between these two versions.
> >>> Hadoop-2.x using protobuf-2.5.0
> >>>
> >>>
> >>> but if some guys want to run Spark on mesos, then mesos using
> >>> protobuf-2.4.1 currently. so we may discuss here for a better solutio=
n.
> >>>
> >>>
> >>>
> >>> On Mon, Dec 16, 2013 at 7:42 AM, Azuryy Yu <azuryyyu@gmail.com> wrote=
:
> >>>
> >>>> Thanks Patrick.
> >>>> On 16 Dec 2013 02:43, "Patrick Wendell" <pwendell@gmail.com> wrote:
> >>>>
> >>>>> You can checkout the docs mentioned in the vote thread. There is al=
so
> >>>>> a pre-build binary for hadoop2 that is compiled for YARN 2.2
> >>>>>
> >>>>> - Patrick
> >>>>>
> >>>>> On Sun, Dec 15, 2013 at 4:31 AM, Azuryy Yu <azuryyyu@gmail.com>
> wrote:
> >>>>>> yarn 2.2, not yarn 0.22, I am so sorry.
> >>>>>>
> >>>>>>
> >>>>>> On Sun, Dec 15, 2013 at 8:31 PM, Azuryy Yu <azuryyyu@gmail.com>
> >> wrote:
> >>>>>>
> >>>>>>> Hi,
> >>>>>>> Spark-0.8.1 supports yarn 0.22 right? where to find the release
> note?
> >>>>>>> Thanks.
> >>>>>>>
> >>>>>>>
> >>>>>>> On Sun, Dec 15, 2013 at 3:20 AM, Henry Saputra <
> >>>>> henry.saputra@gmail.com>wrote:
> >>>>>>>
> >>>>>>>> Yeah seems like it. He was ok with our prev release.
> >>>>>>>> Let's wait for his reply
> >>>>>>>>
> >>>>>>>> On Saturday, December 14, 2013, Patrick Wendell wrote:
> >>>>>>>>
> >>>>>>>>> Henry - from that thread it looks like sebb's concern was
> >>>>>>>>> something different than this.
> >>>>>>>>>
> >>>>>>>>> On Sat, Dec 14, 2013 at 11:08 AM, Henry Saputra <
> >>>>>>>> henry.saputra@gmail.com>
> >>>>>>>>> wrote:
> >>>>>>>>>> Hi Patrick,
> >>>>>>>>>>
> >>>>>>>>>> Yeap I agree, but technically ASF VOTE release on source
> >>>>>>>>>> only,
> >>>>> there
> >>>>>>>>>> even debate about it =3D), so putting it in the vote staging
> >>>>> artifact
> >>>>>>>>>> could confuse people because in our case we do package 3rd
> >>>>>>>>>> party libraries in the binary jars.
> >>>>>>>>>>
> >>>>>>>>>> I have sent email to sebb asking clarification about his
> >>>>>>>>>> concern
> >>>>> in
> >>>>>>>>>> general@ list.
> >>>>>>>>>>
> >>>>>>>>>> - Henry
> >>>>>>>>>>
> >>>>>>>>>> On Sat, Dec 14, 2013 at 10:56 AM, Patrick Wendell <
> >>>>> pwendell@gmail.com
> >>>>>>>>>
> >>>>>>>>> wrote:
> >>>>>>>>>>> Hey Henry,
> >>>>>>>>>>>
> >>>>>>>>>>> One thing a lot of people do during the vote is test the
> >>>>> binaries and
> >>>>>>>>>>> make sure they work. This is really valuable. If you'd like
> >>>>>>>>>>> I
> >>>>> could
> >>>>>>>>>>> add a caveat to the vote thread explaining that we are only
> >>>>> voting on
> >>>>>>>>>>> the source.
> >>>>>>>>>>>
> >>>>>>>>>>> - Patrick
> >>>>>>>>>>>
> >>>>>>>>>>> On Sat, Dec 14, 2013 at 10:40 AM, Henry Saputra <
> >>>>>>>>> henry.saputra@gmail.com> wrote:
> >>>>>>>>>>>> Actually we should be fine putting the binaries there as
> >>>>>>>>>>>> long
> >>>>> as the
> >>>>>>>>>>>> VOTE is for the source.
> >>>>>>>>>>>>
> >>>>>>>>>>>> Let's verify with sebb in the general@ list about his
> concern.
> >>>>>>>>>>>>
> >>>>>>>>>>>> - Henry
> >>>>>>>>>>>>
> >>>>>>>>>>>> On Sat, Dec 14, 2013 at 10:31 AM, Henry Saputra <
> >>>>>>>>> henry.saputra@gmail.com> wrote:
> >>>>>>>>>>>>> Hi Patrick, as sebb has mentioned let's move the binaries
> >>>>>>>>>>>>> from
> >>>>> the
> >>>>>>>>>>>>> voting directory in your people.apache.org directory.
> >>>>>>>>>>>>> ASF release voting is for source code and not binaries,
> >>>>>>>>>>>>> and technically we provide binaries for convenience.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> And add link to the KEYS location in the dist[1] to let
> >>>>>>>>>>>>> verify
> >>>>>>>>> signatures.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> Sorry for the late response to the VOTE thread, guys.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> - Henry
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> [1]
> >>>>>>>> https://dist.apache.org/repos/dist/release/incubator/spark/KEYS
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> On Fri, Dec 13, 2013 at 6:37 PM, Patrick Wendell <
> >>>>>>>> pwendell@gmail.com>
> >>>>>>>>> wrote:
> >>>>>>>>>>>>>> The vote is now closed. This vote passes with 5 PPMC +1's
> >>>>>>>>>>>>>> and
> >>>>> no 0
> >>>>>>>>> or -1
> >>>>>>>>>>>>>> votes.
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> +1 (5 Total)
> >>>>>>>>>>>>>> Matei Zaharia*
> >>>>>>>>>>>>>> Nick Pentreath*
> >>>>>>>>>>>>>> Patrick Wendell*
> >>>>>>>>>>>>>> Prashant Sharma*
> >>>>>>>>>>>>>> Tom Graves*
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> 0 (0 Total)
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> -1 (0 Total)
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> * =3D Binding Vote
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> As per the incubator release guide [1] I'll be sending
> >>>>>>>>>>>>>> this
> >>>>> to the
> >>>>>>>>>>>>>> general incubator list for a final vote from IPMC members.
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> [1]
> >>>>>>>>>>>>>>
> >>>>>>>>>
> >>>>>>>>
> >>>>>
> http://incubator.apache.org/guides/releasemanagement.html#best-practi
> >>>>> ce-incubator-release-
> >>>>>>>>>>>>>> vote
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> On Thu, Dec 12, 2013 at 8:59 AM, Evan Chan
> >>>>>>>>>>>>>> <ev@ooyala.com>
> >>>>> wrote:
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> I'd be personally fine with a standard workflow of
> >>>>> assemble-deps
> >>>>>>>> +
> >>>>>>>>>>>>>>> packaging just the Spark files as separate packages, if
> >>>>>>>>>>>>>>> it
> >>>>>>>> speeds up
> >>>>>>>>>>>>>>> everyone's development time.
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> On Wed, Dec 11, 2013 at 1:10 PM, Mark Hamstra <
> >>>>>>>>> mark@clearstorydata.com
> >>>>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> I don't know how to make sense of the numbers, but
> >>>>>>>>>>>>>>>> here's
> >>>>> what
> >>>>>>>>> I've got
> >>>>>>>>>>>>>>>> from a very small sample size.
> >>>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>
> >>>>
> >>
> >>
>
>

--001a113393a46695ea04eda2bd94--

From dev-return-931-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 09:37:36 2013
Return-Path: <dev-return-931-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1258810154
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 09:37:36 +0000 (UTC)
Received: (qmail 6788 invoked by uid 500); 16 Dec 2013 09:37:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6075 invoked by uid 500); 16 Dec 2013 09:37:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 6014 invoked by uid 99); 16 Dec 2013 09:37:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 09:37:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.219.41 as permitted sender)
Received: from [209.85.219.41] (HELO mail-oa0-f41.google.com) (209.85.219.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 09:37:16 +0000
Received: by mail-oa0-f41.google.com with SMTP id j17so4738183oag.28
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 01:36:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=IEe7a0t0U0rgHea76KpihdoFbsm8JePOqTeG7bqsSFA=;
        b=hU1EaQsN5yhIKyswnurUiSfQR8GZFo/bdfBNgFESNwGOvIQKMcC4nCyVhowVar/G2s
         SgdJYjlTxQ/GYR6+KaHx7koXbPO/1EbA5rBXriw/DYdBwaO0bvWVcfRVn92Sk0XJd5Xy
         KRwEMTWva4VYFdhfdu+5rpaD68r8QVdUJQ3XCvtb2oeO8MaGPoE1S/5xj23z7ieDIYOH
         +ookBFAsQWxLHZrL2asrqwL9C57xiavXSknRWQvHpPmiUvx9YQs6PhgPHV4DUowTnJmQ
         2AbPTlQ0ybriO88oyZfNWWmm0jxRP4b9o5iLmVvkIpieR521YNfP7nFLp55/+x1f6DqA
         wNVg==
MIME-Version: 1.0
X-Received: by 10.182.153.226 with SMTP id vj2mr10847188obb.26.1387186615605;
 Mon, 16 Dec 2013 01:36:55 -0800 (PST)
Received: by 10.182.95.103 with HTTP; Mon, 16 Dec 2013 01:36:55 -0800 (PST)
In-Reply-To: <CADWPM3jLMq4PaorZ9A93ng5W4uFX2YJfi+Q1vFKJb_zydz10vw@mail.gmail.com>
References: <CALD+6GPiLTukP3F5JB+t+-80Y4fFpHHCy+CqwdV49+zwp_-xgg@mail.gmail.com>
	<CADWPM3jLMq4PaorZ9A93ng5W4uFX2YJfi+Q1vFKJb_zydz10vw@mail.gmail.com>
Date: Mon, 16 Dec 2013 11:36:55 +0200
Message-ID: <CALD+6GOFx2ONedCLOGrAwFKJMntYSczrUOm9VKK9UKS5vZ6usQ@mail.gmail.com>
Subject: Re: Intellij IDEA build issues
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013d0dc075fc2904eda38dd2
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d0dc075fc2904eda38dd2
Content-Type: text/plain; charset=ISO-8859-1

Thanks Evan, I tried it and the new SBT direct import seems to work well,
though I did run into issues with some yarn imports on Spark.

n


On Thu, Dec 12, 2013 at 7:03 PM, Evan Chan <ev@ooyala.com> wrote:

> Nick, have you tried using the latest Scala plug-in, which features native
> SBT project imports?   ie you no longer need to run gen-idea.
>
>
> On Sat, Dec 7, 2013 at 4:15 AM, Nick Pentreath <nick.pentreath@gmail.com
> >wrote:
>
> > Hi Spark Devs,
> >
> > Hoping someone cane help me out. No matter what I do, I cannot get
> Intellij
> > to build Spark from source. I am using IDEA 13. I run sbt gen-idea and
> > everything seems to work fine.
> >
> > When I try to build using IDEA, everything compiles but I get the error
> > below.
> >
> > Have any of you come across the same?
> >
> > ======
> >
> > Internal error: (java.lang.AssertionError)
> > java/nio/channels/FileChannel$MapMode already declared as
> > ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
> > java.lang.AssertionError: java/nio/channels/FileChannel$MapMode already
> > declared as ch.epfl.lamp.fjbg.JInnerClassesAttribute$Entry@1b5b798b
> > at
> >
> >
> ch.epfl.lamp.fjbg.JInnerClassesAttribute.addEntry(JInnerClassesAttribute.java:74)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:738)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator$$anonfun$addInnerClasses$3.apply(GenJVM.scala:733)
> > at
> >
> >
> scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59)
> > at scala.collection.immutable.List.foreach(List.scala:76)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.addInnerClasses(GenJVM.scala:733)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.emitClass(GenJVM.scala:200)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$BytecodeGenerator.genClass(GenJVM.scala:355)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
> > at
> >
> >
> scala.tools.nsc.backend.jvm.GenJVM$JvmPhase$$anonfun$run$4.apply(GenJVM.scala:86)
> > at
> >
> >
> scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
> > at
> >
> >
> scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:104)
> > at scala.collection.Iterator$class.foreach(Iterator.scala:772)
> > at
> scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
> > at
> >
> scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
> > at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
> > at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:104)
> > at scala.tools.nsc.backend.jvm.GenJVM$JvmPhase.run(GenJVM.scala:86)
> > at scala.tools.nsc.Global$Run.compileSources(Global.scala:953)
> > at scala.tools.nsc.Global$Run.compile(Global.scala:1041)
> > at xsbt.CachedCompiler0.run(CompilerInterface.scala:123)
> > at xsbt.CachedCompiler0.liftedTree1$1(CompilerInterface.scala:99)
> > at xsbt.CachedCompiler0.run(CompilerInterface.scala:99)
> > at xsbt.CompilerInterface.run(CompilerInterface.scala:27)
> > at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> > at
> >
> >
> sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
> > at
> >
> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
> > at java.lang.reflect.Method.invoke(Method.java:601)
> > at sbt.compiler.AnalyzingCompiler.call(AnalyzingCompiler.scala:102)
> > at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:48)
> > at sbt.compiler.AnalyzingCompiler.compile(AnalyzingCompiler.scala:41)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply$mcV$sp(AggressiveCompile.scala:106)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3$$anonfun$apply$1.apply(AggressiveCompile.scala:106)
> > at
> >
> >
> sbt.compiler.AggressiveCompile.sbt$compiler$AggressiveCompile$$timed(AggressiveCompile.scala:173)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:105)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1$$anonfun$apply$3.apply(AggressiveCompile.scala:102)
> > at scala.Option.foreach(Option.scala:236)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6$$anonfun$compileScala$1$1.apply(AggressiveCompile.scala:102)
> > at scala.Option.foreach(Option.scala:236)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6.compileScala$1(AggressiveCompile.scala:102)
> > at
> >
> >
> sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:151)
> > at
> >
> sbt.compiler.AggressiveCompile$$anonfun$6.apply(AggressiveCompile.scala:89)
> > at
> sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:39)
> > at
> sbt.inc.IncrementalCompile$$anonfun$doCompile$1.apply(Compile.scala:37)
> > at sbt.inc.Incremental$.cycle(Incremental.scala:75)
> > at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:34)
> > at sbt.inc.Incremental$$anonfun$1.apply(Incremental.scala:33)
> > at sbt.inc.Incremental$.manageClassfiles(Incremental.scala:42)
> > at sbt.inc.Incremental$.compile(Incremental.scala:33)
> > at sbt.inc.IncrementalCompile$.apply(Compile.scala:27)
> > at sbt.compiler.AggressiveCompile.compile2(AggressiveCompile.scala:164)
> > at sbt.compiler.AggressiveCompile.compile1(AggressiveCompile.scala:73)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.local.CompilerImpl.compile(CompilerImpl.scala:61)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.local.LocalServer.compile(LocalServer.scala:26)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:118)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3$$anonfun$apply$4.apply(ScalaBuilder.scala:100)
> > at scala.util.Either$RightProjection.map(Either.scala:536)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:100)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5$$anonfun$apply$3.apply(ScalaBuilder.scala:99)
> > at scala.util.Either$RightProjection.flatMap(Either.scala:523)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:99)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$5.apply(ScalaBuilder.scala:98)
> > at scala.util.Either$RightProjection.flatMap(Either.scala:523)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder.doBuild(ScalaBuilder.scala:98)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilder.build(ScalaBuilder.scala:68)
> > at
> >
> >
> org.jetbrains.jps.incremental.scala.ScalaBuilderService$ScalaBuilderDecorator.build(ScalaBuilderService.java:42)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.runModuleLevelBuilders(IncProjectBuilder.java:1086)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.runBuildersForChunk(IncProjectBuilder.java:797)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.buildTargetsChunk(IncProjectBuilder.java:845)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.buildChunkIfAffected(IncProjectBuilder.java:760)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.buildChunks(IncProjectBuilder.java:583)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.runBuild(IncProjectBuilder.java:344)
> > at
> >
> >
> org.jetbrains.jps.incremental.IncProjectBuilder.build(IncProjectBuilder.java:184)
> > at org.jetbrains.jps.cmdline.BuildRunner.runBuild(BuildRunner.java:129)
> > at org.jetbrains.jps.cmdline.BuildSession.runBuild(BuildSession.java:224)
> > at org.jetbrains.jps.cmdline.BuildSession.run(BuildSession.java:113)
> > at
> >
> >
> org.jetbrains.jps.cmdline.BuildMain$MyMessageHandler$1.run(BuildMain.java:133)
> > at
> >
> >
> org.jetbrains.jps.service.impl.SharedThreadPoolImpl$1.run(SharedThreadPoolImpl.java:41)
> > at
> java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
> > at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
> > at java.util.concurrent.FutureTask.run(FutureTask.java:166)
> > at
> >
> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> > at
> >
> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> > at java.lang.Thread.run(Thread.java:722)
> >
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/>
> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><
> http://www.twitter.com/ooyala>
>

--089e013d0dc075fc2904eda38dd2--

From dev-return-932-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 17:59:18 2013
Return-Path: <dev-return-932-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 846C710283
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 17:59:18 +0000 (UTC)
Received: (qmail 71975 invoked by uid 500); 16 Dec 2013 17:59:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71940 invoked by uid 500); 16 Dec 2013 17:59:17 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 71932 invoked by uid 99); 16 Dec 2013 17:59:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 17:59:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.212.51 as permitted sender)
Received: from [209.85.212.51] (HELO mail-vb0-f51.google.com) (209.85.212.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 17:59:11 +0000
Received: by mail-vb0-f51.google.com with SMTP id 11so3375544vbe.38
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 09:58:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=dllWgRvtQfog7zaEVC2cKEh1vxre6UXd8ptbt98wUpU=;
        b=PpKj450iE1X8EC7H7jGdo9jKCMmfwJCJg49Sg9ez20O3QRi8N//jW83ndGPV/WilEv
         HLqF1BTw8LPeajvXuj7ovMU+ZUOoR7FO3ACG+1QxdFILeaVXoBZhIwO7VD6XfUWJwKCr
         d27IdpAhTQDjVBPgdzTSb3PZcuCbtVKczrJPE=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=dllWgRvtQfog7zaEVC2cKEh1vxre6UXd8ptbt98wUpU=;
        b=Y5eo9hMYndyD+AvmcJHjpY9Oon7siYCfYvDNVNBzyUEbbccw6uReyEQikLMnOOjt6T
         nx1BZN5V//pXc8HfOPtR5tRlGRlIwYrk4Bq3ozZIOxwTSle5Gt6JRHwr+E5C0cYX4gQE
         SwHMVar3hJ9hYoqz/wZY98ZFXwpXQWU1hGb9H9WQfogVA9J+rTqiv7Yzru5k8AT8rwaq
         r3EK6hktqyjQiE7KX3U9RsJ+kmqzlVORseMcyNCfs/x07v/9qNCna9Sbet/ojVXpMug2
         +/cYt02g8QcYdoXv7LnUkJegz2RfZM0NB4UYFpjQjPcLkWGqxgUrmneq6UR8ARPuQELM
         Hb5g==
X-Gm-Message-State: ALoCoQkVMlPDw+Xyw0ioKzy4CYXZvj79/dWuxUJak6WndQG2KUTTXy5moenkMks7T+0l5DsmL8y2
MIME-Version: 1.0
X-Received: by 10.220.200.65 with SMTP id ev1mr8918317vcb.13.1387216730208;
 Mon, 16 Dec 2013 09:58:50 -0800 (PST)
Received: by 10.220.17.193 with HTTP; Mon, 16 Dec 2013 09:58:50 -0800 (PST)
In-Reply-To: <52ac350b.04c20e0a.118a.fffff9d1@mx.google.com>
References: <52ac350b.04c20e0a.118a.fffff9d1@mx.google.com>
Date: Mon, 16 Dec 2013 09:58:50 -0800
Message-ID: <CADWPM3ikUvL2nohaBDN6ZJUWXLKwCuX357pzf-09Seh94=pfYQ@mail.gmail.com>
Subject: Re: Re : Scala 2.10 Merge
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e0122a45c6e516604edaa90be
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a45c6e516604edaa90be
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

Great job everyone!  A big step forward.


On Sat, Dec 14, 2013 at 2:37 AM, andy.petrella@gmail.com <
andy.petrella@gmail.com> wrote:

> That's a very good news!
> Congrats
>
> Envoy=E9 depuis mon HTC
>
> ----- Reply message -----
> De : "Sam Bessalah" <samkiller@gmail.com>
> Pour : "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
> Objet : Scala 2.10 Merge
> Date : sam., d=E9c. 14, 2013 11:03
>
>
> Yes. Awesome.
> Great job guys.
>
> Sam Bessalah
>
> > On Dec 14, 2013, at 9:59 AM, Patrick Wendell <pwendell@gmail.com> wrote=
:
> >
> > Alright I just merged this in - so Spark is officially "Scala 2.10"
> > from here forward.
> >
> > For reference I cut a new branch called scala-2.9 with the commit
> > immediately prior to the merge:
> >
> https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=3Dincubato=
r-spark.git;a=3Dshortlog;h=3Drefs/heads/scala-2.9
> >
> > - Patrick
> >
> >> On Thu, Dec 12, 2013 at 8:26 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >> Hey Reymond,
> >>
> >> Let's move this discussion out of this thread and into the associated
> JIRA.
> >> I'll write up our current approach over there.
> >>
> >> https://spark-project.atlassian.net/browse/SPARK-995
> >>
> >> - Patrick
> >>
> >>
> >>> On Thu, Dec 12, 2013 at 5:56 PM, Liu, Raymond <raymond.liu@intel.com>
> wrote:
> >>>
> >>> Hi Patrick
> >>>
> >>>        So what's the plan for support Yarn 2.2 in 0.9? As far as I ca=
n
> >>> see, if you want to support both 2.2 and 2.0 , due to protobuf versio=
n
> >>> incompatible issue. You need two version of akka anyway.
> >>>
> >>>        Akka 2.3-M1 looks like have a little bit change in API, we
> >>> probably could isolate the code like what we did on yarn part API. I
> >>> remember that it is mentioned that to use reflection for different AP=
I
> is
> >>> preferred. So the purpose to use reflection is to use one release bin
> jar to
> >>> support both version of Hadoop/Yarn on runtime, instead of build
> different
> >>> bin jar on compile time?
> >>>
> >>>         Then all code related to hadoop will also be built in separat=
e
> >>> modules for loading on demand? This sounds to me involve a lot of
> works. And
> >>> you still need to have shim layer and separate code for different
> version
> >>> API and depends on different version Akka etc. Sounds like and even
> strict
> >>> demands versus our current approaching on master, and with dynamic
> class
> >>> loader in addition, And the problem we are facing now are still there=
?
> >>>
> >>> Best Regards,
> >>> Raymond Liu
> >>>
> >>> -----Original Message-----
> >>> From: Patrick Wendell [mailto:pwendell@gmail.com]
> >>> Sent: Thursday, December 12, 2013 5:13 PM
> >>> To: dev@spark.incubator.apache.org
> >>> Subject: Re: Scala 2.10 Merge
> >>>
> >>> Also - the code is still there because of a recent merge that took in
> some
> >>> newer changes... we'll be removing it for the final merge.
> >>>
> >>>
> >>> On Thu, Dec 12, 2013 at 1:12 AM, Patrick Wendell <pwendell@gmail.com>
> >>> wrote:
> >>>
> >>>> Hey Raymond,
> >>>>
> >>>> This won't work because AFAIK akka 2.3-M1 is not binary compatible
> >>>> with akka 2.2.3 (right?). For all of the non-yarn 2.2 versions we ne=
ed
> >>>> to still use the older protobuf library, so we'd need to support bot=
h.
> >>>>
> >>>> I'd also be concerned about having a reference to a non-released
> >>>> version of akka. Akka is the source of our hardest-to-find bugs and
> >>>> simultaneously trying to support 2.2.3 and 2.3-M1 is a bit daunting.
> >>>> Of course, if you are building off of master you can maintain a fork
> >>>> that uses this.
> >>>>
> >>>> - Patrick
> >>>>
> >>>>
> >>>> On Thu, Dec 12, 2013 at 12:42 AM, Liu, Raymond
> >>>> <raymond.liu@intel.com>wrote:
> >>>>
> >>>>> Hi Patrick
> >>>>>
> >>>>>        What does that means for drop YARN 2.2? seems codes are stil=
l
> >>>>> there. You mean if build upon 2.2 it will break, and won't and work
> >>>>> right?
> >>>>> Since the home made akka build on scala 2.10 are not there. While, =
if
> >>>>> for this case, can we just use akka 2.3-M1 which run on protobuf 2.=
5
> >>>>> for replacement?
> >>>>>
> >>>>> Best Regards,
> >>>>> Raymond Liu
> >>>>>
> >>>>>
> >>>>> -----Original Message-----
> >>>>> From: Patrick Wendell [mailto:pwendell@gmail.com]
> >>>>> Sent: Thursday, December 12, 2013 4:21 PM
> >>>>> To: dev@spark.incubator.apache.org
> >>>>> Subject: Scala 2.10 Merge
> >>>>>
> >>>>> Hi Developers,
> >>>>>
> >>>>> In the next few days we are planning to merge Scala 2.10 support in=
to
> >>>>> Spark. For those that haven't been following this, Prashant Sharma
> >>>>> has been maintaining the scala-2.10 branch of Spark for several
> >>>>> months. This branch is current with master and has been reviewed fo=
r
> >>>>> merging:
> >>>>>
> >>>>> https://github.com/apache/incubator-spark/tree/scala-2.10
> >>>>>
> >>>>> Scala 2.10 support is one of the most requested features for Spark =
-
> >>>>> it will be great to get this into Spark 0.9! Please note that *Scal=
a
> >>>>> 2.10 is not binary compatible with Scala 2.9*. With that in mind, I
> >>>>> wanted to give a few heads-up/requests to developers:
> >>>>>
> >>>>> If you are developing applications on top of Spark's master branch,
> >>>>> those will need to migrate to Scala 2.10. You may want to download
> >>>>> and test the current scala-2.10 branch in order to make sure you wi=
ll
> >>>>> be okay as Spark developments move forward. Of course, you can alwa=
ys
> >>>>> stick with the current master commit and be fine (I'll cut a tag wh=
en
> >>>>> we do the merge in order to delineate where the version changes).
> >>>>> Please open new threads on the dev list to report and discuss any
> >>>>> issues.
> >>>>>
> >>>>> This merge will temporarily drop support for YARN 2.2 on the master
> >>>>> branch.
> >>>>> This is because the workaround we used was only compiled for Scala
> 2.9.
> >>>>> We are going to come up with a more robust solution to YARN 2.2
> >>>>> support before releasing 0.9.
> >>>>>
> >>>>> Going forward, we will continue to make maintenance releases on
> >>>>> branch-0.8 which will remain compatible with Scala 2.9.
> >>>>>
> >>>>> For those interested, the primary code changes in this merge are
> >>>>> upgrading the akka version, changing the use of Scala 2.9's
> >>>>> ClassManifest construct to Scala 2.10's ClassTag, and updating the
> >>>>> spark shell to work with Scala 2.10's repl.
> >>>>>
> >>>>> - Patrick
> >>
> >>
>



--=20
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><ht=
tp://www.twitter.com/ooyala>

--089e0122a45c6e516604edaa90be--

From dev-return-933-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 22:13:25 2013
Return-Path: <dev-return-933-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 953B610F3F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 22:13:25 +0000 (UTC)
Received: (qmail 22796 invoked by uid 500); 16 Dec 2013 22:13:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22699 invoked by uid 500); 16 Dec 2013 22:13:25 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 22691 invoked by uid 99); 16 Dec 2013 22:13:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 22:13:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 22:13:20 +0000
Received: by mail-ig0-f172.google.com with SMTP id hl1so4828762igb.5
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 14:12:59 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=+w20Fdw4vy3ajCmZ/Jep4p5BqEJpsOSCHTloUBUGTao=;
        b=IFCw6SSAiZXHcmPmbJx9IT+Mhepbmu+Sh5JTKZ5W+B9IhpyIAEZ8NsQGqaVxUaY+EU
         ggI84JSXEYQ5x3op/XhxJek2QhnVVUxyeRVsJxjPoItOafIJn9JolAjCFiBPVBbToP/k
         pvGqZNF4tLxi9C8PNNbgY88bwNnpKrliaKdlvH991yQsDyMmC1TtuZWwCysOFzuwhHH+
         wFKReYlS+f13egofzL5vv1/xEgjxGSh08STry2it50Jb+trB1rmQvT/WC32W7MFZV2/g
         XWQDU3iUKrt443U1oPdRnzwHtmAR13M6z1E7RPD7pm8XqxHgUJvbB8mIol1/RhzA5FJg
         IwEg==
X-Gm-Message-State: ALoCoQkwzwAMRiBUjVueUpFq3Xjp8m/onVx724zO//xC0Ucfei1/xAZa4OCG5fWlyqKtOp30/5ju
X-Received: by 10.50.119.4 with SMTP id kq4mr224928igb.40.1387231979687; Mon,
 16 Dec 2013 14:12:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.224.161 with HTTP; Mon, 16 Dec 2013 14:12:39 -0800 (PST)
In-Reply-To: <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
 <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
 <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com> <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
From: =?UTF-8?Q?Grega_Ke=C5=A1pret?= <grega@celtra.com>
Date: Mon, 16 Dec 2013 23:12:39 +0100
Message-ID: <CAMihvYbSBQ5OVy1-ffJ5BZbKNQWtJiABJce6M8k2UdF1kXAaxw@mail.gmail.com>
Subject: Re: spark.task.maxFailures
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013c6e4a5f129d04edae1d29
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6e4a5f129d04edae1d29
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Any news regarding this setting? Is this expected behaviour? Is there some
other way I can have Spark fail-fast?

Thanks!

On Mon, Dec 9, 2013 at 4:35 PM, Grega Ke=C5=A1pret <grega@celtra.com> wrote=
:

> Hi!
>
> I tried this (by setting spark.task.maxFailures to 1) and it still does
> not fail-fast. I started a job and after some time, I killed all JVMs
> running on one of the two workers. I was expecting Spark job to fail,
> however it re-fetched tasks to one of the two workers that was still aliv=
e
> and the job succeeded.
>
> Grega
>

--089e013c6e4a5f129d04edae1d29--

From dev-return-934-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 22:17:39 2013
Return-Path: <dev-return-934-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90DBB10F93
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 22:17:39 +0000 (UTC)
Received: (qmail 30532 invoked by uid 500); 16 Dec 2013 22:17:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30483 invoked by uid 500); 16 Dec 2013 22:17:39 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 30475 invoked by uid 99); 16 Dec 2013 22:17:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 22:17:39 +0000
X-ASF-Spam-Status: No, hits=-1998.3 required=5.0
	tests=ALL_TRUSTED,HTML_MESSAGE,RP_MATCHES_RCVD
X-Spam-Check-By: apache.org
Received: from [140.211.11.3] (HELO mail.apache.org) (140.211.11.3)
    by apache.org (qpsmtpd/0.29) with SMTP; Mon, 16 Dec 2013 22:17:38 +0000
Received: (qmail 30279 invoked by uid 99); 16 Dec 2013 22:17:18 -0000
Received: from minotaur.apache.org (HELO minotaur.apache.org) (140.211.11.9)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 22:17:18 +0000
Received: from localhost (HELO mail-ve0-f182.google.com) (127.0.0.1)
  (smtp-auth username rxin, mechanism plain)
  by minotaur.apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 22:17:18 +0000
Received: by mail-ve0-f182.google.com with SMTP id jy13so3733703veb.41
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 14:17:17 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=hiX5d6+BGuw6/KxPidQYdX0mX/qKuScjFVWM1PmFtRU=;
        b=Cwc74y8zrlLeSUf3L7BQd1uS0fbkZRXDj/byc/Sl3jgGBU+uuhahr/V3RHNQcGxFPz
         8e4k6kM15ZjPJ7znCrQwxxmX7FMMFrcJfLJPNMqEahnsXgHwSM4+LdlMC9i9GxAuCY0m
         t/H63VCffnmYX47N6Py4C20Zl/NVc5rjXDMrRKL9QUNL9tEjUdv8TSzWflF0bYdNmJ8R
         6f/cWWiuJh13lO0z7jPC1CMjdcDUnY3V4up8DXnT2XOOr/GK2gMnZwRbNLo1TqRN53KI
         Afn1cYqvpnQIpxAf9vDylrOicWaI/6MDZrD0ihWXc+6sq3yN+UPucG1Zf/dgxgInCpOo
         9ewg==
X-Received: by 10.58.241.135 with SMTP id wi7mr14566vec.70.1387232237051; Mon,
 16 Dec 2013 14:17:17 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.109.135 with HTTP; Mon, 16 Dec 2013 14:16:56 -0800 (PST)
In-Reply-To: <CAMihvYbSBQ5OVy1-ffJ5BZbKNQWtJiABJce6M8k2UdF1kXAaxw@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
 <CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
 <CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com>
 <CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com> <CAMihvYbSBQ5OVy1-ffJ5BZbKNQWtJiABJce6M8k2UdF1kXAaxw@mail.gmail.com>
From: Reynold Xin <rxin@apache.org>
Date: Mon, 16 Dec 2013 14:16:56 -0800
Message-ID: <CAC1ssC4=tWVwOdLAB1J+DLWrvVw1-zFmSWN3XsG1simL3zGAog@mail.gmail.com>
Subject: Re: spark.task.maxFailures
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e013a18ceb5ec1204edae2cfa
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013a18ceb5ec1204edae2cfa
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I just merged your pull request
https://github.com/apache/incubator-spark/pull/245


On Mon, Dec 16, 2013 at 2:12 PM, Grega Ke=C5=A1pret <grega@celtra.com> wrot=
e:

> Any news regarding this setting? Is this expected behaviour? Is there som=
e
> other way I can have Spark fail-fast?
>
> Thanks!
>
> On Mon, Dec 9, 2013 at 4:35 PM, Grega Ke=C5=A1pret <grega@celtra.com> wro=
te:
>
> > Hi!
> >
> > I tried this (by setting spark.task.maxFailures to 1) and it still does
> > not fail-fast. I started a job and after some time, I killed all JVMs
> > running on one of the two workers. I was expecting Spark job to fail,
> > however it re-fetched tasks to one of the two workers that was still
> alive
> > and the job succeeded.
> >
> > Grega
> >
>

--089e013a18ceb5ec1204edae2cfa--

From dev-return-935-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 23:06:37 2013
Return-Path: <dev-return-935-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C80F510154
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 23:06:37 +0000 (UTC)
Received: (qmail 7484 invoked by uid 500); 16 Dec 2013 23:06:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7445 invoked by uid 500); 16 Dec 2013 23:06:37 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 7437 invoked by uid 99); 16 Dec 2013 23:06:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 23:06:37 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.50 as permitted sender)
Received: from [209.85.219.50] (HELO mail-oa0-f50.google.com) (209.85.219.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 23:06:33 +0000
Received: by mail-oa0-f50.google.com with SMTP id n16so5757993oag.37
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 15:06:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type:content-transfer-encoding;
        bh=Tmao2KVbrbiccMkP+knOmFB9Eh689U4xmbG/T5aE0vY=;
        b=uOskNExlp6oJA7UrGdQ6dhXibhl5rSFsuMfkubUXa5Pid2k6BkHSdaO1QnHK7JB+2J
         /yIP5Dnk5unSTLlNj6YwKLWfwYISaVB32R3RSzhoJhIFWk06YaaLN2e0N703vW4JqnEY
         T/4TwsrJOpvqmCophWq4mOqQolWy+qr95ph8rMzPWPjAWLGLvuUPAiiLmLecXHPQGFc0
         tiDzAzoL6aPTWSd1GTxjyzEl5BsW+npQhRrZs2v17THxjttzBfVUhHI+Z8bpl1ogeTNU
         bMS1PDo+WzJRZWn2OHdPMoLnZXNZgxgilOzkA8iBsI+tA9/nNTZEIjsVtPBz23VVNRJN
         mNMg==
MIME-Version: 1.0
X-Received: by 10.182.24.69 with SMTP id s5mr13730800obf.35.1387235172763;
 Mon, 16 Dec 2013 15:06:12 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Mon, 16 Dec 2013 15:06:12 -0800 (PST)
In-Reply-To: <CAC1ssC4=tWVwOdLAB1J+DLWrvVw1-zFmSWN3XsG1simL3zGAog@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
	<CAC1ssC7RV88z79RVkn6vF46BYgujVimbku92p2S2RS0ygtTECg@mail.gmail.com>
	<CAMihvYYmPU+fH8Jht7e2y-J+AGo=xdixjpDnEuvSEQVWSL90Xg@mail.gmail.com>
	<CAMihvYa78HrsCU-RFquBasY2AtNBqYCdJshAsc7pcHPrstY+6A@mail.gmail.com>
	<CAMihvYbSBQ5OVy1-ffJ5BZbKNQWtJiABJce6M8k2UdF1kXAaxw@mail.gmail.com>
	<CAC1ssC4=tWVwOdLAB1J+DLWrvVw1-zFmSWN3XsG1simL3zGAog@mail.gmail.com>
Date: Mon, 16 Dec 2013 15:06:12 -0800
Message-ID: <CABPQxstQxpwiztdD37D4FEs9TpaYQqZV6oHt5YRur2Hon_mLiw@mail.gmail.com>
Subject: Re: spark.task.maxFailures
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

This was a good fix - thanks for the contribution.

On Mon, Dec 16, 2013 at 2:16 PM, Reynold Xin <rxin@apache.org> wrote:
> I just merged your pull request
> https://github.com/apache/incubator-spark/pull/245
>
>
> On Mon, Dec 16, 2013 at 2:12 PM, Grega Ke=C5=A1pret <grega@celtra.com> wr=
ote:
>
>> Any news regarding this setting? Is this expected behaviour? Is there so=
me
>> other way I can have Spark fail-fast?
>>
>> Thanks!
>>
>> On Mon, Dec 9, 2013 at 4:35 PM, Grega Ke=C5=A1pret <grega@celtra.com> wr=
ote:
>>
>> > Hi!
>> >
>> > I tried this (by setting spark.task.maxFailures to 1) and it still doe=
s
>> > not fail-fast. I started a job and after some time, I killed all JVMs
>> > running on one of the two workers. I was expecting Spark job to fail,
>> > however it re-fetched tasks to one of the two workers that was still
>> alive
>> > and the job succeeded.
>> >
>> > Grega
>> >
>>

From dev-return-936-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 16 23:39:38 2013
Return-Path: <dev-return-936-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7CFD41025B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Dec 2013 23:39:38 +0000 (UTC)
Received: (qmail 56843 invoked by uid 500); 16 Dec 2013 23:39:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56743 invoked by uid 500); 16 Dec 2013 23:39:38 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 56735 invoked by uid 99); 16 Dec 2013 23:39:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 23:39:38 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of dlieu.7@gmail.com designates 209.85.219.53 as permitted sender)
Received: from [209.85.219.53] (HELO mail-oa0-f53.google.com) (209.85.219.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Dec 2013 23:39:32 +0000
Received: by mail-oa0-f53.google.com with SMTP id m1so5704327oag.26
        for <dev@spark.incubator.apache.org>; Mon, 16 Dec 2013 15:39:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=jDtISOjSbHzCx2SMtO4c6LrClZeaHEg3szsqV19vB78=;
        b=PCObFiJBvvOhXbCrFmhiNgEg20vHb63u9lPl1JTvABxm9nEqIXcD4CllTgQWs/ikEo
         k5BKwtIN2cY4IkgvXzchsEzdJjnlKLWc48TvRJRQbn2Xhan9XIWaU2dLw4R3Ipue67sl
         NTJ3cTsA8PnAnfpjWf+iL1yfPqGBcnyZA8dx2UFK6pIiXxn9PNqOuqS53ED1XxITTXGI
         LBr81TL68Y8jVF07MXRQEY+ydUeixwb0ij8YZrnKq6ryuX6QVNuIA7S52/d+EEhXhIIG
         CyE+QlkjS++iaBSEeWFjRqTTqU2soqIHMdmIXwCTrHOGVi3uAuMX6bLzdabVG7TOHmFz
         9OCQ==
MIME-Version: 1.0
X-Received: by 10.182.72.234 with SMTP id g10mr13790594obv.21.1387237151055;
 Mon, 16 Dec 2013 15:39:11 -0800 (PST)
Received: by 10.76.87.200 with HTTP; Mon, 16 Dec 2013 15:39:10 -0800 (PST)
In-Reply-To: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
References: <CAMihvYb8aR4gBBtmD2R4ZvxYo8k8w7AsbFN+myaqm344yOMciA@mail.gmail.com>
Date: Mon, 16 Dec 2013 15:39:10 -0800
Message-ID: <CAPud8TqXBnBG2C-Q7OVSOL2rJNJ3sbJvpzJgE=Efc3_JW5hfSw@mail.gmail.com>
Subject: Re: spark.task.maxFailures
From: Dmitriy Lyubimov <dlieu.7@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2e0649ba6d204edaf513d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2e0649ba6d204edaf513d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

i guess it should really be "maximum number of total task run attempts".
 At least that's what it looks logically. in that sense, the rest of the
documentation is correct ( should be at least 1; 1 =3D task is allowed no
retries (1-1=3D0)).




On Fri, Nov 29, 2013 at 2:02 AM, Grega Ke=C5=A1pret <grega@celtra.com> wrot=
e:

> Looking at
> http://spark.incubator.apache.org/docs/latest/configuration.html
> docs says:
> Number of individual task failures before giving up on the job. Should be
> greater than or equal to 1. Number of allowed retries =3D this value - 1.
>
> However, looking at the code
>
> https://github.com/apache/incubator-spark/blob/master/core/src/main/scala=
/org/apache/spark/scheduler/cluster/ClusterTaskSetManager.scala#L532
>
> if I set spark.task.maxFailures to 1, this means that job will fail after
> task fails for the second time. Shouldn't this line be corrected to if (
> numFailures(index) >=3D MAX_TASK_FAILURES) {
> ?
>
> I can open a pull request if this is the case.
>
> Thanks,
> Grega
> --
> [image: Inline image 1]
> *Grega Ke=C5=A1pret*
> Analytics engineer
>
> Celtra =E2=80=94 Rich Media Mobile Advertising
> celtra.com <http://www.celtra.com/> | @celtramobile<http://www.twitter.co=
m/celtramobile>
>

--001a11c2e0649ba6d204edaf513d--

From dev-return-937-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 17 17:16:43 2013
Return-Path: <dev-return-937-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D51D5101D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Dec 2013 17:16:43 +0000 (UTC)
Received: (qmail 22868 invoked by uid 500); 17 Dec 2013 17:16:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22798 invoked by uid 500); 17 Dec 2013 17:16:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 22419 invoked by uid 99); 17 Dec 2013 17:16:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 17:16:30 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chris.mattmann@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 17:16:24 +0000
Received: by mail-pd0-f172.google.com with SMTP id g10so7014735pdj.17
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 09:16:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=user-agent:date:subject:from:to:cc:message-id:thread-topic
         :references:in-reply-to:mime-version:content-type
         :content-transfer-encoding;
        bh=S4vs+rQzuc8kIideHu6QwSXTow/q3USKFpWgbFxCULA=;
        b=lSEOW9DeOTFITEz+9gpeUqdEmzRCuqxFuuDyao/P0Y+nRD4rcqN69NS0+MXLf/6TMr
         aeQhqx1CWBQf1Y+9XepA6vtW4xypXd1vCESyBgzekYdqZE+ARLYVVnm4EAEd/scDu25p
         Dd9c0f0VpKkZGPDe89JAmvAiz6FLkFciY4CvEIOnqQD4B9PJq92dlueTu3AnxPzlc9+D
         dPVcAKLso9j+9AZIHysjx2Iphtem0VLDk0twoRW0Zjmk1rB9xr6Q9FpUU9L5zL1ur+NM
         nAfURG9u3+2swZ6e2v+nTUsTDHJZeGJMA73eI+2nnTqLgG8bKBkwhLcNrF0PK6Is3fES
         Myqw==
X-Received: by 10.68.143.196 with SMTP id sg4mr28555082pbb.155.1387300563765;
        Tue, 17 Dec 2013 09:16:03 -0800 (PST)
Received: from [137.79.16.80] ([137.79.16.80])
        by mx.google.com with ESMTPSA id lh13sm47673740pab.4.2013.12.17.09.16.00
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 17 Dec 2013 09:16:02 -0800 (PST)
User-Agent: Microsoft-MacOutlook/14.3.9.131030
Date: Tue, 17 Dec 2013 09:15:52 -0800
Subject: Re: [VOTE] Release Apache Spark 0.8.0-incubating (rc4)
From: Chris Mattmann <mattmann@apache.org>
To: "general@incubator.apache.org" <general@incubator.apache.org>
CC: <dev@spark.incubator.apache.org>
Message-ID: <CED5C4C8.1244A6%chris.a.mattmann@jpl.nasa.gov>
Thread-Topic: [VOTE] Release Apache Spark 0.8.0-incubating (rc4)
References: <CABPQxsuyLM_DuqZrisdMXWVgzM_BXTRzzDsMS7UhjKD9Jp=sDA@mail.gmail.com>
In-Reply-To: <CABPQxsuyLM_DuqZrisdMXWVgzM_BXTRzzDsMS7UhjKD9Jp=sDA@mail.gmail.com>
X-Priority: 2
Mime-version: 1.0
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Guys,

+1 from me (binding):

SIGS pass, CHECKSUMS pass:

[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-hadoop1
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100  131M  100  131M    0     0  1754k      0  0:01:16  0:01:16 --:--:--
1165k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   490  100   490    0     0   6965      0 --:--:-- --:--:-- --:--:--
13611
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   129  100   129    0     0   1839      0 --:--:-- --:--:-- --:--:--
3583
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-hadoop2
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100  215M  100  215M    0     0  1815k      0  0:02:01  0:02:01 --:--:--
1826k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   490  100   490    0     0   6831      0 --:--:-- --:--:-- --:--:--
13611
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   129  100   129    0     0   1819      0 --:--:-- --:--:-- --:--:--
3583
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-cdh
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-cdh4
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100  136M  100  136M    0     0  1757k      0  0:01:19  0:01:19 --:--:--
1502k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   490  100   490    0     0   6892      0 --:--:-- --:--:-- --:--:--
13611
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   123  100   123    0     0   1702      0 --:--:-- --:--:-- --:--:--
3514
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/stage_apache_rc spark 0.8.1-incubating
http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100 4565k  100 4565k    0     0  1636k      0  0:00:02  0:00:02 --:--:--
1656k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100   490  100   490    0     0   6949      0 --:--:-- --:--:-- --:--:--
13611
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
100    77  100    77    0     0   1109      0 --:--:-- --:--:-- --:--:--
2200
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/verify_gpg_sigs
Verifying Signature for file spark-0.8.1-incubating-bin-cdh4.tgz.asc
gpg: Signature made Tue Dec 10 15:03:24 2013 PST using RSA key ID 9E4FE3AF
gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the
owner.
Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
Verifying Signature for file spark-0.8.1-incubating-bin-hadoop1.tgz.asc
gpg: Signature made Tue Dec 10 14:58:15 2013 PST using RSA key ID 9E4FE3AF
gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the
owner.
Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
Verifying Signature for file spark-0.8.1-incubating-bin-hadoop2.tgz.asc
gpg: Signature made Tue Dec 10 15:09:16 2013 PST using RSA key ID 9E4FE3AF
gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the
owner.
Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
Verifying Signature for file spark-0.8.1-incubating.tgz.asc
gpg: Signature made Tue Dec 10 14:53:15 2013 PST using RSA key ID 9E4FE3AF
gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the
owner.
Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
$HOME/bin/verify_md5_checksums
md5sum: stat '*.tar.gz': No such file or directory
md5sum: stat '*.bz2': No such file or directory
md5sum: stat '*.zip': No such file or directory
spark-0.8.1-incubating-bin-cdh4.tgz: OK
spark-0.8.1-incubating-bin-hadoop1.tgz: OK
spark-0.8.1-incubating-bin-hadoop2.tgz: OK
spark-0.8.1-incubating.tgz: OK
[chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%



Thanks!

Cheers,
Chris


-----Original Message-----
From: Patrick Wendell <pwendell@gmail.com>
Reply-To: "general@incubator.apache.org" <general@incubator.apache.org>
Date: Friday, December 13, 2013 7:13 PM
To: "general@incubator.apache.org" <general@incubator.apache.org>
Subject: [VOTE] Release Apache Spark 0.8.0-incubating (rc4)

>Please vote on releasing the following candidate as Apache Spark
>(incubating) version 0.8.1.
>
>The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-s
>park.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>
>The release files, including signatures, digests, etc can be found at:
>http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>
>Release artifacts are signed with the following key:
>https://people.apache.org/keys/committer/pwendell.asc
>
>The staging repository for this release can be found at:
>https://repository.apache.org/content/repositories/orgapachespark-040/
>
>The documentation corresponding to this release can be found at:
>http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>
>For information about the contents of this release see:
>https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHA
>NGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>
>A vote on this release has passed within the Spark PPMC [1].
>
>Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>
>The vote is open until Tuesday, December 17th at 03:30 UTC and
>passes if a majority of at least 3 +1 IPMC votes are cast.
>
>[ ] +1 Release this package as Apache Spark 0.8.1-incubating
>[ ] -1 Do not release this package because ...
>
>To learn more about Apache Spark, please see
>http://spark.incubator.apache.org/
>
>[1]
>http://mail-archives.apache.org/mod_mbox/incubator-spark-dev/201312.mbox/%
>3CCABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA%40mail.gmail.com%3E
>
>(Note that at present the concluding message isn't shown due to lag in the
>mail archives.)



From dev-return-938-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 17 17:24:08 2013
Return-Path: <dev-return-938-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D28C110214
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Dec 2013 17:24:08 +0000 (UTC)
Received: (qmail 30951 invoked by uid 500); 17 Dec 2013 17:22:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30876 invoked by uid 500); 17 Dec 2013 17:21:59 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 30479 invoked by uid 99); 17 Dec 2013 17:21:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 17:21:43 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of shaposhnik@gmail.com designates 209.85.219.49 as permitted sender)
Received: from [209.85.219.49] (HELO mail-oa0-f49.google.com) (209.85.219.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 17:21:35 +0000
Received: by mail-oa0-f49.google.com with SMTP id i4so6814149oah.8
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 09:21:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=2u1spcNYwSux5u2CEoz7XKRQXdFuE0V3r+2LYPrqrB8=;
        b=ajr0EygF1Z2NQTnlaF0/D/LuahKZHDEyvEVGOXaSLPewArbrz5ISkpXdMknudJOU1h
         HXyCy5t+H0Y8To82/R1wTmUTOFWEqEf3ZElBTil/CprGGVuhR0pMCZHDeJG4iL/ao+uZ
         wj1b7o6AuKz06oV25j3eCPExNOL0/NaDElqWsigRVW9cBy0OUxVLx9hg79mQRqtVLbnW
         +VeMd+v4OlPl9VyHc2nTjjWUK2XLErNjTpWvBMOhxUvaLT9NNeTgzTfcJ3MQ7fwj8Cw6
         79Fbvp3x9CPwyee58R0ulPsddp5/QuFziQr0Pa1fvQkhhp9VJr7U1swFGaGD2jSnJAOg
         rsVA==
MIME-Version: 1.0
X-Received: by 10.60.70.134 with SMTP id m6mr16799533oeu.14.1387300874430;
 Tue, 17 Dec 2013 09:21:14 -0800 (PST)
Sender: shaposhnik@gmail.com
Received: by 10.182.133.101 with HTTP; Tue, 17 Dec 2013 09:21:14 -0800 (PST)
In-Reply-To: <CED5C4C8.1244A6%chris.a.mattmann@jpl.nasa.gov>
References: <CABPQxsuyLM_DuqZrisdMXWVgzM_BXTRzzDsMS7UhjKD9Jp=sDA@mail.gmail.com>
	<CED5C4C8.1244A6%chris.a.mattmann@jpl.nasa.gov>
Date: Tue, 17 Dec 2013 09:21:14 -0800
X-Google-Sender-Auth: 88r7lblXUNI58_NX8hyzvz1uUKs
Message-ID: <CA+ULb+uwB0aObuuwo1hZCEkuASaCOWsWFcqHcy0aTa1vy_3dPg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 0.8.0-incubating (rc4)
From: Roman Shaposhnik <rvs@apache.org>
To: dev@spark.incubator.apache.org
Cc: "general@incubator.apache.org" <general@incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

+1 (binding) from me as well.

That said, I'd expect the issues identified around
jar inclusion to be blocking for 0.9 (do we have
a blocker JIRA filed?). There's also a few issues
around the build but I need to spend time and file
JIRAs myself. Will do in time for 0.9

Thanks,
Roman.

On Tue, Dec 17, 2013 at 9:15 AM, Chris Mattmann <mattmann@apache.org> wrote:
> Hi Guys,
>
> +1 from me (binding):
>
> SIGS pass, CHECKSUMS pass:
>
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-hadoop1
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100  131M  100  131M    0     0  1754k      0  0:01:16  0:01:16 --:--:--
> 1165k
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   490  100   490    0     0   6965      0 --:--:-- --:--:-- --:--:--
> 13611
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   129  100   129    0     0   1839      0 --:--:-- --:--:-- --:--:--
> 3583
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-hadoop2
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100  215M  100  215M    0     0  1815k      0  0:02:01  0:02:01 --:--:--
> 1826k
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   490  100   490    0     0   6831      0 --:--:-- --:--:-- --:--:--
> 13611
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   129  100   129    0     0   1819      0 --:--:-- --:--:-- --:--:--
> 3583
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-cdh
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/stage_apache_rc spark 0.8.1-incubating-bin-cdh4
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100  136M  100  136M    0     0  1757k      0  0:01:19  0:01:19 --:--:--
> 1502k
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   490  100   490    0     0   6892      0 --:--:-- --:--:-- --:--:--
> 13611
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   123  100   123    0     0   1702      0 --:--:-- --:--:-- --:--:--
> 3514
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/stage_apache_rc spark 0.8.1-incubating
> http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100 4565k  100 4565k    0     0  1636k      0  0:00:02  0:00:02 --:--:--
> 1656k
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100   490  100   490    0     0   6949      0 --:--:-- --:--:-- --:--:--
> 13611
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                  Dload  Upload   Total   Spent    Left
> Speed
> 100    77  100    77    0     0   1109      0 --:--:-- --:--:-- --:--:--
> 2200
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/verify_gpg_sigs
> Verifying Signature for file spark-0.8.1-incubating-bin-cdh4.tgz.asc
> gpg: Signature made Tue Dec 10 15:03:24 2013 PST using RSA key ID 9E4FE3AF
> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
> gpg: WARNING: This key is not certified with a trusted signature!
> gpg:          There is no indication that the signature belongs to the
> owner.
> Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
> Verifying Signature for file spark-0.8.1-incubating-bin-hadoop1.tgz.asc
> gpg: Signature made Tue Dec 10 14:58:15 2013 PST using RSA key ID 9E4FE3AF
> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
> gpg: WARNING: This key is not certified with a trusted signature!
> gpg:          There is no indication that the signature belongs to the
> owner.
> Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
> Verifying Signature for file spark-0.8.1-incubating-bin-hadoop2.tgz.asc
> gpg: Signature made Tue Dec 10 15:09:16 2013 PST using RSA key ID 9E4FE3AF
> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
> gpg: WARNING: This key is not certified with a trusted signature!
> gpg:          There is no indication that the signature belongs to the
> owner.
> Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
> Verifying Signature for file spark-0.8.1-incubating.tgz.asc
> gpg: Signature made Tue Dec 10 14:53:15 2013 PST using RSA key ID 9E4FE3AF
> gpg: Good signature from "Patrick Wendell <pwendell@gmail.com>"
> gpg: WARNING: This key is not certified with a trusted signature!
> gpg:          There is no indication that the signature belongs to the
> owner.
> Primary key fingerprint: 5AA9 0E72 812F F246 7904  277D 548F 5FEE 9E4F E3AF
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
> $HOME/bin/verify_md5_checksums
> md5sum: stat '*.tar.gz': No such file or directory
> md5sum: stat '*.bz2': No such file or directory
> md5sum: stat '*.zip': No such file or directory
> spark-0.8.1-incubating-bin-cdh4.tgz: OK
> spark-0.8.1-incubating-bin-hadoop1.tgz: OK
> spark-0.8.1-incubating-bin-hadoop2.tgz: OK
> spark-0.8.1-incubating.tgz: OK
> [chipotle:~/tmp/apache-spark-0.8.1-incubating-rc4] mattmann%
>
>
>
> Thanks!
>
> Cheers,
> Chris
>
>
> -----Original Message-----
> From: Patrick Wendell <pwendell@gmail.com>
> Reply-To: "general@incubator.apache.org" <general@incubator.apache.org>
> Date: Friday, December 13, 2013 7:13 PM
> To: "general@incubator.apache.org" <general@incubator.apache.org>
> Subject: [VOTE] Release Apache Spark 0.8.0-incubating (rc4)
>
>>Please vote on releasing the following candidate as Apache Spark
>>(incubating) version 0.8.1.
>>
>>The tag to be voted on is v0.8.1-incubating (commit b87d31d):
>>https://git-wip-us.apache.org/repos/asf/incubator-spark/repo?p=incubator-s
>>park.git;a=commit;h=b87d31dd8eb4b4e47c0138e9242d0dd6922c8c4e
>>
>>The release files, including signatures, digests, etc can be found at:
>>http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4/
>>
>>Release artifacts are signed with the following key:
>>https://people.apache.org/keys/committer/pwendell.asc
>>
>>The staging repository for this release can be found at:
>>https://repository.apache.org/content/repositories/orgapachespark-040/
>>
>>The documentation corresponding to this release can be found at:
>>http://people.apache.org/~pwendell/spark-0.8.1-incubating-rc4-docs/
>>
>>For information about the contents of this release see:
>>https://git-wip-us.apache.org/repos/asf?p=incubator-spark.git;a=blob;f=CHA
>>NGES.txt;h=ce0aeab524505b63c7999e0371157ac2def6fe1c;hb=branch-0.8
>>
>>A vote on this release has passed within the Spark PPMC [1].
>>
>>Please vote on releasing this package as Apache Spark 0.8.1-incubating!
>>
>>The vote is open until Tuesday, December 17th at 03:30 UTC and
>>passes if a majority of at least 3 +1 IPMC votes are cast.
>>
>>[ ] +1 Release this package as Apache Spark 0.8.1-incubating
>>[ ] -1 Do not release this package because ...
>>
>>To learn more about Apache Spark, please see
>>http://spark.incubator.apache.org/
>>
>>[1]
>>http://mail-archives.apache.org/mod_mbox/incubator-spark-dev/201312.mbox/%
>>3CCABPQxsuEYMn_JE0qEOcrt4J5-N1PJWgGcN7m0qzNefW7fsz2PA%40mail.gmail.com%3E
>>
>>(Note that at present the concluding message isn't shown due to lag in the
>>mail archives.)
>
>

From dev-return-939-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 17 18:56:20 2013
Return-Path: <dev-return-939-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F0978105F2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Dec 2013 18:56:19 +0000 (UTC)
Received: (qmail 7030 invoked by uid 500); 17 Dec 2013 18:56:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6742 invoked by uid 500); 17 Dec 2013 18:56:19 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 73493 invoked by uid 99); 17 Dec 2013 18:43:48 -0000
X-ASF-Spam-Status: No, hits=-0.1 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mccheah@uwaterloo.ca designates 129.97.128.141 as permitted sender)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=4BQtJL9X7T9XwCWp3SIYo+ep4OYfBF2aCFC9LmwyshY=;
        b=fZo796oHAt9c2vkOVie/vUvUSSXOiWlVsDb/Dg5VZE1ibP2PSG4gfBfOlCJcyUNGH4
         +d4bKleIPo0GAyvQ6IPed45Em3TVW+vc/yyjYeBTm/AHwsRePkhh/qnO5GHuo2wbcDrr
         P2CMhCfI+LLnf88P2Q7lJ3AAQYKpBBCQ8+ZwMaNt+gEn+n5sA5S4uJntYYSgqpUCe7Hx
         QC6K8HaZ+LOGv8ZkBcO6NSOgHuOyicV6lhh2r4xGlpEPuas8XNeA+bUDGnaGSDrGgJN1
         BGwGtj3w5sGigCYmgHzloaCw+GJCAMYJ4oUhMii6R5S5oXmvN4639w7vSvIYl+OFWsV+
         mr9w==
MIME-Version: 1.0
X-Received: by 10.50.254.165 with SMTP id aj5mr4644699igd.0.1387305798003;
 Tue, 17 Dec 2013 10:43:18 -0800 (PST)
Date: Tue, 17 Dec 2013 10:43:17 -0800
Message-ID: <CAHH8_ON-2y69fBfVtt6pngWtEPOZdsmvt4hZ=dOE-DZSK6k3sA@mail.gmail.com>
Subject: Spark development for undergraduate project
From: Matthew Cheah <mccheah@uwaterloo.ca>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1135f6a048f77c04edbf4df7
X-UUID: 90129e01-87eb-457a-b6bf-c1509178ba9d
X-Miltered: at mailchk-m05 with ID 52B09B46.001 by Joe's j-chkmail (http://j-chkmail.ensmp.fr)!
X-Virus-Scanned: clamav-milter 0.98 at mailchk-m05
X-Virus-Status: Clean
X-Greylist: Sender succeeded SMTP AUTH, not delayed by milter-greylist-4.4.3 (mailchk-m05.uwaterloo.ca [129.97.128.141]); Tue, 17 Dec 2013 13:43:19 -0500 (EST)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	mailchk-r01.uwaterloo.ca
X-Virus-Checked: Checked by ClamAV on apache.org
X-Old-Spam-Status: No, score=-7.0 required=5.0 tests=ALL_TRUSTED,HTML_MESSAGE
	autolearn=disabled version=3.3.1

--001a1135f6a048f77c04edbf4df7
Content-Type: text/plain; charset=ISO-8859-1

Hi everyone,

During my most recent internship, I worked extensively with Apache Spark,
integrating it into a company's data analytics platform. I've now become
interested in contributing to Apache Spark.

I'm returning to undergraduate studies in January and there is an academic
course which is simply a standalone software engineering project. I was
thinking that some contribution to Apache Spark would satisfy my curiosity,
help continue support the company I interned at, and give me academic
credits required to graduate, all at the same time. It seems like too good
an opportunity to pass up.

With that in mind, I have the following questions:

   1. At this point, is there any self-contained project that I could work
   on within Spark? Ideally, I would work on it independently, in about a
   three month time frame. This time also needs to accommodate ramping up on
   the Spark codebase and adjusting to the Scala programming language and
   paradigms. The company I worked at primarily used the Java APIs. The output
   needs to be a technical report describing the project requirements, and the
   design process I took to engineer the solution for the requirements. In
   particular, it cannot just be a series of haphazard patches.
   2. How can I get started with contributing to Spark?
   3. Is there a high-level UML or some other design specification for the
   Spark architecture?

Thanks! I hope to be of some help =)

-Matt Cheah

--001a1135f6a048f77c04edbf4df7--

From dev-return-940-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 17 19:26:40 2013
Return-Path: <dev-return-940-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C842D1082E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Dec 2013 19:26:40 +0000 (UTC)
Received: (qmail 69006 invoked by uid 500); 17 Dec 2013 19:26:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68895 invoked by uid 500); 17 Dec 2013 19:26:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 68887 invoked by uid 99); 17 Dec 2013 19:26:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 19:26:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ctn@adatao.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Dec 2013 19:26:34 +0000
Received: by mail-ie0-f179.google.com with SMTP id x13so9024466ief.38
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 11:26:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=KtJDKQLYqVaZXeuYhraFuw6BbRe5uxFV1JmVSuB4+MA=;
        b=B4Jl+UBLI3HhpxAFlFBaht7nMEWQriRcWV4EYe+wbIOML6bryq6Tfz4rZ8lyezADoi
         hwpJLIl1kYeCe5PFxJASTm9YmZHKpKIkAS4l7wOEGLYQkz7mHV55gmuS1bblxwkhT/E3
         DQOxnNGYare/CkXAr5mjFlylKFtgHU1wnDHwg=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=KtJDKQLYqVaZXeuYhraFuw6BbRe5uxFV1JmVSuB4+MA=;
        b=TkZsJApAwhMWknnbSCTqpm7FMvGUf8mOWcM9lmrqbQjKKPcTsFwWPORLh2RX0G/k6s
         7Lxz5+ksSD2a6dsoiLAbvM5tCC248Kpdk+OzJb7mXiUDQkam7aqD4CGGEq3/j6i5uDSI
         eYmCE+g/UjKJW8H5JerxaeMmb6FTa3VLHWXAMe9CYM3au/qo61uYrJECBNNI/GbSxLm2
         ckCY74kkm5T+EUdg60MUYlDHiXy4xAZDAY6xMEcEN9lMvBMf9KXX7oFl86a/ZCBHsQUk
         STlNGO4mTDCwhYERWQaVPW7xk4n8CgDOaTaQ6Ti0VpirRQT45dxIIBHzp0MXE4UYvf78
         kjkQ==
X-Gm-Message-State: ALoCoQmZME1lEJv+qG5KVbAyJLApXONl+lIrX3w+/xrmCW5xZNNm93B2kmKmBBOlkqNlRw7QC0rd
X-Received: by 10.50.143.10 with SMTP id sa10mr4741603igb.8.1387308371208;
 Tue, 17 Dec 2013 11:26:11 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.20.78 with HTTP; Tue, 17 Dec 2013 11:25:51 -0800 (PST)
X-Originating-IP: [67.188.95.187]
In-Reply-To: <CAHH8_ON-2y69fBfVtt6pngWtEPOZdsmvt4hZ=dOE-DZSK6k3sA@mail.gmail.com>
References: <CAHH8_ON-2y69fBfVtt6pngWtEPOZdsmvt4hZ=dOE-DZSK6k3sA@mail.gmail.com>
From: Christopher Nguyen <ctn@adatao.com>
Date: Tue, 17 Dec 2013 11:25:51 -0800
Message-ID: <CAGh_TuNYNycRF-V-4+FO4BmitrTEvYUdfsDV-q+Z1AN_mE=6yg@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1135fe9aa9079a04edbfe6bb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fe9aa9079a04edbfe6bb
Content-Type: text/plain; charset=ISO-8859-1

Matt, some suggestions.

If you're interested in the machine-learning layer, perhaps you could look
into helping to harmonize our (Adatao) dataframe representation with
MLlib's, and base RDDs for that matter. It requires someone to spend some
dedicated time looking into the trade-offs between generalizability vs
performance issues, etc. It's something our groups have talked about doing
but haven't been able to invest the resources to do.

Separately, neural nets/deep learning is an area of emerging interest to
look into with Spark. It may drive some alternate optimization patterns for
Spark, e.g., sub-cluster communication. If interested, I can connect you to
some deep learning folks at UoT (not too far from you) and Google. Matei
may also have some interest in this.

--
Christopher T. Nguyen
Co-founder & CEO, Adatao <http://adatao.com>
linkedin.com/in/ctnguyen



On Tue, Dec 17, 2013 at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>wrote:

> Hi everyone,
>
> During my most recent internship, I worked extensively with Apache Spark,
> integrating it into a company's data analytics platform. I've now become
> interested in contributing to Apache Spark.
>
> I'm returning to undergraduate studies in January and there is an academic
> course which is simply a standalone software engineering project. I was
> thinking that some contribution to Apache Spark would satisfy my curiosity,
> help continue support the company I interned at, and give me academic
> credits required to graduate, all at the same time. It seems like too good
> an opportunity to pass up.
>
> With that in mind, I have the following questions:
>
>    1. At this point, is there any self-contained project that I could work
>    on within Spark? Ideally, I would work on it independently, in about a
>    three month time frame. This time also needs to accommodate ramping up
> on
>    the Spark codebase and adjusting to the Scala programming language and
>    paradigms. The company I worked at primarily used the Java APIs. The
> output
>    needs to be a technical report describing the project requirements, and
> the
>    design process I took to engineer the solution for the requirements. In
>    particular, it cannot just be a series of haphazard patches.
>    2. How can I get started with contributing to Spark?
>    3. Is there a high-level UML or some other design specification for the
>    Spark architecture?
>
> Thanks! I hope to be of some help =)
>
> -Matt Cheah
>

--001a1135fe9aa9079a04edbfe6bb--

From dev-return-941-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 17 19:32:04 2013
Return-Path: <dev-return-941-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8D03110854
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Dec 2013 19:32:04 +0000 (UTC)
Received: (qmail 74983 invoked by uid 500); 17 Dec 2013 19:32:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74947 invoked by uid 500); 17 Dec 2013 19:32:04 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 74535 invoked by uid 99); 17 Dec 2013 19:31:11 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.177 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=+E7lvVmxctz6Lmv9LHkbIGTkSmQxSXMTWrjmKCXE7tY=;
        b=lLG6RxtIgF9HOB+VTLIyFa7OD6Hjp75wnvoH1qPdYLibcdlTA3BbqJBQK1+WBTPPtC
         OLmfvyjjE23oe/EP/wVgVvJoSGbs5j4pMNPIz1hX4dfvqG97yGaNTS/KvNxWnGldZ7nF
         XzrgEgQK0cOrTiNDXB8uofdOHxaYvF/Dym96VFEJTwrVTOdOYDoxdBCs52cW1EytnpYQ
         Qe3gnj3s4hPVT4GaYo/no2NtbQcZqTL8VKPK4FrWiBsskFzrzrE5LPQFqFjO7PQzaRjx
         JaSRRhX3f7ZAuDzT4dz7ukdHhvPkNIasPNn/vLLBNkhcZWOo9ZJAnTcIzdjbfFL39TOR
         rrFw==
MIME-Version: 1.0
X-Received: by 10.50.87.4 with SMTP id t4mr4885265igz.18.1387308646075; Tue,
 17 Dec 2013 11:30:46 -0800 (PST)
Date: Tue, 17 Dec 2013 11:30:45 -0800
Message-ID: <CAHH8_OPG0jT9_1mPZQrwdhY4gfiQ7-gpwZFVHqz8hiUyfJ=3uA@mail.gmail.com>
Subject: Spark development for undergraduate project
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0111bb740b160e04edbff71d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0111bb740b160e04edbff71d
Content-Type: text/plain; charset=ISO-8859-1

Hi everyone,

During my most recent internship, I worked extensively with Apache Spark,
integrating it into a company's data analytics platform. I've now become
interested in contributing to Apache Spark.

I'm returning to undergraduate studies in January and there is an academic
course which is simply a standalone software engineering project. I was
thinking that some contribution to Apache Spark would satisfy my curiosity,
help continue support the company I interned at, and give me academic
credits required to graduate, all at the same time. It seems like too good
an opportunity to pass up.

With that in mind, I have the following questions:

   1. At this point, is there any self-contained project that I could work
   on within Spark? Ideally, I would work on it independently, in about a
   three month time frame. This time also needs to accommodate ramping up on
   the Spark codebase and adjusting to the Scala programming language and
   paradigms. The company I worked at primarily used the Java APIs. The output
   needs to be a technical report describing the project requirements, and the
   design process I took to engineer the solution for the requirements. In
   particular, it cannot just be a series of haphazard patches.
   2. How can I get started with contributing to Spark?
   3. Is there a high-level UML or some other design specification for the
   Spark architecture?

Thanks! I hope to be of some help =)

-Matt Cheah

--089e0111bb740b160e04edbff71d--

From dev-return-942-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 01:15:44 2013
Return-Path: <dev-return-942-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2D45F10636
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 01:15:44 +0000 (UTC)
Received: (qmail 37055 invoked by uid 500); 18 Dec 2013 01:15:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37010 invoked by uid 500); 18 Dec 2013 01:15:43 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 37002 invoked by uid 99); 18 Dec 2013 01:15:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 01:15:43 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 01:15:37 +0000
Received: by mail-ob0-f177.google.com with SMTP id vb8so7165250obc.36
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 17:15:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:cc:content-type;
        bh=hjJq6KBTXD0Xpm3EJvIYDePag1ingBhN+4zuSyxynfc=;
        b=Sgqor2EwsCQqUgEVMbQfiTLl5nHI9nSPwSWUIwxSMtsA3fyuJpefBKyPWAthxPVscK
         koubmEpTOlpB/FpmSCSRJbLkzLkACXjWIyhzArbS1txljpid5AlCjbjDRZHnWOMZtcmz
         ZLiVI/8EzXlYwe8zJ/qo1BVIermijcB3X77g2CpKICtyWSkv+hp/g21Q2h/QfoI7xgIE
         G+t/BDr+the0lTMXGEgPk/HnszcpeUEEzo2BmgEunvIf5klh9d3kiW7P/O8mm19xTf6C
         +cnPrhZ7gMOfG+I4xpB+KqGQtm+1caSdOp4c4ap9tEfIZizf0YrMYeN5sW1Sy5JOjmPG
         Yi0w==
MIME-Version: 1.0
X-Received: by 10.60.60.164 with SMTP id i4mr18648235oer.35.1387329316348;
 Tue, 17 Dec 2013 17:15:16 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Tue, 17 Dec 2013 17:15:16 -0800 (PST)
Date: Tue, 17 Dec 2013 17:15:16 -0800
Message-ID: <CABPQxsva1vY__ycxCViK0J8rbj+PS7+Bt23QyzKD7se49GxuQw@mail.gmail.com>
Subject: [RESULT] [VOTE] Release Apache Spark 0.8.1-incubating (rc4)
From: Patrick Wendell <pwendell@gmail.com>
To: general@incubator.apache.org
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

The vote is now closed. This vote passes with 4 IPMC +1's and no 0 or -1 votes.

+1 (4 Total)
Marvin Humphrey
Henry Saputra
Chris Mattmann
Roman Shaposhnik

0 (0 Total)

-1 (0 Total)

* = Binding Vote

Thanks to everyone who helped vet this release.

- Patrick

From dev-return-943-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 01:49:50 2013
Return-Path: <dev-return-943-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4E7B310734
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 01:49:50 +0000 (UTC)
Received: (qmail 93405 invoked by uid 500); 18 Dec 2013 01:49:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93361 invoked by uid 500); 18 Dec 2013 01:49:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 76398 invoked by uid 99); 18 Dec 2013 01:40:14 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.177 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=RzNOAE75IbrfPqUbAiiLsyvNpzer09ZZiDnVnaOQv74=;
        b=SjxSMl3aTD4fN5alsLfdXuS+LxKi3pKW5Cw7WuzbJ+VQE6LbI4e/nuMfwHuJpth7aL
         O/OOPQxG7QDYMc/gSCsDz9JRG0f4kwIWPAwzNX52KEOy1Ejc7O4KFy4VGFVk7LIy1I2w
         7HbRVz+Xmwx2g9Jh/OMhNT3LRVmGcdYVClBA/e9v7NZ2KNHSpyk7vj9HcnE77RgkIVq3
         rvxFXqbGbQOFyQxaGtEz78D8FbHNc+b1AV+76GGUF57k2YQZtCgXKxsReCZYd1V95TB4
         V9h2npMi3o8sM0aWwIT2DJfBdxoKW0EgpBnqst0UTNDZn2uxxHhXjWNLXZd0252ZWOsk
         Yy9A==
MIME-Version: 1.0
X-Received: by 10.50.108.235 with SMTP id hn11mr6009413igb.0.1387330788428;
 Tue, 17 Dec 2013 17:39:48 -0800 (PST)
In-Reply-To: <CAHH8_OPG0jT9_1mPZQrwdhY4gfiQ7-gpwZFVHqz8hiUyfJ=3uA@mail.gmail.com>
References: <CAHH8_OPG0jT9_1mPZQrwdhY4gfiQ7-gpwZFVHqz8hiUyfJ=3uA@mail.gmail.com>
Date: Tue, 17 Dec 2013 17:39:48 -0800
Message-ID: <CAHH8_ON6TnSnw0bRVAzVaRz_Z49-htU21UNzM6w_34YeeRC8_g@mail.gmail.com>
Subject: Fwd: Spark development for undergraduate project
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d0402aeefd49cfb04edc51e6f
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0402aeefd49cfb04edc51e6f
Content-Type: text/plain; charset=ISO-8859-1

Hi everyone,

During my most recent internship, I worked extensively with Apache Spark,
integrating it into a company's data analytics platform. I've now become
interested in contributing to Apache Spark.

I'm returning to undergraduate studies in January and there is an academic
course which is simply a standalone software engineering project. I was
thinking that some contribution to Apache Spark would satisfy my curiosity,
help continue support the company I interned at, and give me academic
credits required to graduate, all at the same time. It seems like too good
an opportunity to pass up.

With that in mind, I have the following questions:

   1. At this point, is there any self-contained project that I could work
   on within Spark? Ideally, I would work on it independently, in about a
   three month time frame. This time also needs to accommodate ramping up on
   the Spark codebase and adjusting to the Scala programming language and
   paradigms. The company I worked at primarily used the Java APIs. The output
   needs to be a technical report describing the project requirements, and the
   design process I took to engineer the solution for the requirements. In
   particular, it cannot just be a series of haphazard patches.
   2. How can I get started with contributing to Spark?
   3. Is there a high-level UML or some other design specification for the
   Spark architecture?

Thanks! I hope to be of some help =)

-Matt Cheah

--f46d0402aeefd49cfb04edc51e6f--

From dev-return-944-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 05:55:30 2013
Return-Path: <dev-return-944-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 71A4C10E34
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 05:55:30 +0000 (UTC)
Received: (qmail 29533 invoked by uid 500); 18 Dec 2013 05:55:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29426 invoked by uid 500); 18 Dec 2013 05:55:23 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 29417 invoked by uid 99); 18 Dec 2013 05:55:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 05:55:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of azuryyyu@gmail.com designates 209.85.212.68 as permitted sender)
Received: from [209.85.212.68] (HELO mail-vb0-f68.google.com) (209.85.212.68)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 05:55:16 +0000
Received: by mail-vb0-f68.google.com with SMTP id x8so1043153vbf.7
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 21:54:56 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=oJB+HMELNOr+TXzmnxIbQkf0peyJwMUYhaOXmxSnQ9s=;
        b=oLpvQm1fhM27al/ePa0G+p3yERZGDANXef+i0bpcbxlToWYE9DtZxaVvcjOiRJiKMN
         djpz0iz98sRyEYkVR0tMZx/gP4GT7B80jZxTKoBojf21ueBYXykM68hK9zSrZka4bkiZ
         ba7bbXCg/Q7at4czRvBIBUIUS7geUq00klb0TezM56duydxqWTeyza7qpU/wPwklbM5j
         lOPIChsPR7iaO5SkwzG+1eSwXtb3SddDjulNS/lbzDlm759QnNzghg2K+yga14mvwpoJ
         OUMtcMza0t+3kZ49XddwlH++upVsrHPVgJ3ltxLUbUsHPezwDOO8e01pb5WMpSbrvfRf
         01cg==
MIME-Version: 1.0
X-Received: by 10.52.166.6 with SMTP id zc6mr10563039vdb.10.1387346096111;
 Tue, 17 Dec 2013 21:54:56 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Tue, 17 Dec 2013 21:54:56 -0800 (PST)
Date: Wed, 18 Dec 2013 13:54:56 +0800
Message-ID: <CALr1C9qaExFd5tH5bX0614wsPtY2GpGgjC3tkdDXf-qpt5BQcg@mail.gmail.com>
Subject: Contribute to Spark
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c2c5443d463c04edc8af5b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c5443d463c04edc8af5b
Content-Type: text/plain; charset=ISO-8859-1

Hi,

I make my first pull request here(just a minor fix):
https://github.com/apache/incubator-spark/pull/274

Another:
Spark use assemble plug in to generate a fat jar during build,
We should specify SPARK_JAR  in the command line, then Spark upload spark
jar and user jar to the HDFS,

but yarn has a configurable option:
  <property>
    <name>yarn.application.classpath</name>
  </property>

so we can do another way:
Exclude hadoop-* jar and hadoop related jars during build, which can
decreash the fat jar size. then put spark-fat-jar under HADOOP_LIB_DIR,
then Spark don't need to update spark jar to the HDFS, also we don't need
to specify SPARK_JAR in the command line.


If there is no problem, I want to do this change.

--001a11c2c5443d463c04edc8af5b--

From dev-return-945-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 06:10:02 2013
Return-Path: <dev-return-945-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 93D1510ECA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 06:10:02 +0000 (UTC)
Received: (qmail 45584 invoked by uid 500); 18 Dec 2013 06:10:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45534 invoked by uid 500); 18 Dec 2013 06:10:01 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 41057 invoked by uid 99); 18 Dec 2013 06:04:09 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of clseer@gmail.com designates 209.85.216.54 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=hregxNKzqdyz/5u/5//NMmgTLN94xjOFOXbYdsQXzrQ=;
        b=Z/KT5C3PE43lkzivZU0iWKW/32j2TlQCzBlHXQT9fDasykYdnQcRZayrqc7TGQu4xO
         joMC1MQj8brmM+AWsu4m8HENYdsMxc6zTnRZUZ2mlRNe/wzpnyW09y7JPnkOyLVUkBbG
         kp5oB+LxjKPFJxSAvLFCY8e2TTLtEleMeFvis80Za6TEexvRVlotxX48Kx4ujIa/nx9Q
         D8gQIXWgj+EPp3CYStXiMq0qnx4crTFw/W72gc4ExHRdeAK94X54huOgj+gnIuo8YY2f
         W++d9B1MdPr+zYhqUDkC2nyyYm7NipF1LMm63QmAkVTXSCEd7niGG59ZcL62gkz5wuZg
         G49w==
MIME-Version: 1.0
X-Received: by 10.49.1.35 with SMTP id 3mr50144243qej.43.1387346623776; Tue,
 17 Dec 2013 22:03:43 -0800 (PST)
Date: Wed, 18 Dec 2013 14:03:43 +0800
Message-ID: <CAODJPGFFPKns46ar=9-KCxobsY2SRo1enQ3Drt0Jd7qd3yV=5Q@mail.gmail.com>
Subject: spark developer from China
From: =?GB2312?B?tq3O97PJKGNsc2Vlcik=?= <clseer@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b6773a0b1143f04edc8cef7
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6773a0b1143f04edc8cef7
Content-Type: text/plain; charset=GB2312
Content-Transfer-Encoding: base64

SGksIGFsbCwNCiAgSSdtIGEgc3BhcmsgZGV2ZWxwb3IgaW4gQ2hpbmEsIGFuZCB3YW50IHRvIGpv
aW4gdGhpcyBTcGFyayBNYWlsaW5nIExpc3QuDQotLSANCg0KQmVzdCByZWdhcmRzLA0KWGljaGVu
ZyBEb25nDQoNCj09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09
PT09PT09PT0NCiq8vMr1sqm/zSo6IGh0dHA6Ly9kb25neGljaGVuZy5vcmcvDQoqvLzK9crpvK4q
OiBodHRwOi8vaGFkb29wMTIzLmNvbS8NCirOorKpKjogaHR0cDovL3dlaWJvLmNvbS9jbHNlZXIN
Ciq52Lz8tMoqOiBZQVJOL01lc29zLE1hcFJlZHVjZSxUZXosU3Rvcm0NCj09PT09PT09PT09PT09
PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PQ0K
--047d7b6773a0b1143f04edc8cef7--

From dev-return-946-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 06:18:04 2013
Return-Path: <dev-return-946-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BF7BF10F02
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 06:18:04 +0000 (UTC)
Received: (qmail 51239 invoked by uid 500); 18 Dec 2013 06:18:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51198 invoked by uid 500); 18 Dec 2013 06:18:04 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 51190 invoked by uid 99); 18 Dec 2013 06:18:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 06:18:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of azuryyyu@gmail.com designates 209.85.220.171 as permitted sender)
Received: from [209.85.220.171] (HELO mail-vc0-f171.google.com) (209.85.220.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 06:17:58 +0000
Received: by mail-vc0-f171.google.com with SMTP id ik5so4792361vcb.16
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 22:17:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=vV9Df4y0m6OUEr1N6PWQ5QfaAcfDstn1Ucrzn9ylI9I=;
        b=jXBl+ZQKkyqwhC0vsJQSiI1wjqyc5dGnboxji4t3SqrveoTMs9JLwItQwvPjvlhH44
         8duglmncKl9Jgskg7ujLO3TNaStCslt5/5stcEZB63IOa6b+jN9Z8hMbCgcoKtqShkGY
         oo4Q9LBmwmm8C8vYZw8hWmaSrteZFmOvEW3DXbMm/KjNLt/WMmfx9vma1TKsBihZ42c5
         dQvIF7mqp/LutIourK9eRQllZGsOTP9xzEVQRRAkkHmur1frA1BShO9ekBkitXS62jVp
         LVLBc60Ui/SzoezDF8krQLLNaDG7eKMN8n0tzBDzDtstgKJX2Tg1sg8i+lXzx3za7IEP
         d71g==
MIME-Version: 1.0
X-Received: by 10.221.42.133 with SMTP id ty5mr2133vcb.61.1387347457298; Tue,
 17 Dec 2013 22:17:37 -0800 (PST)
Received: by 10.220.4.135 with HTTP; Tue, 17 Dec 2013 22:17:37 -0800 (PST)
In-Reply-To: <CAODJPGFFPKns46ar=9-KCxobsY2SRo1enQ3Drt0Jd7qd3yV=5Q@mail.gmail.com>
References: <CAODJPGFFPKns46ar=9-KCxobsY2SRo1enQ3Drt0Jd7qd3yV=5Q@mail.gmail.com>
Date: Wed, 18 Dec 2013 14:17:37 +0800
Message-ID: <CALr1C9o31D2hkF-xc+D6Oxdy1-yq7wRsFVVhBdu_UCYeR9ereg@mail.gmail.com>
Subject: Re: spark developer from China
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11337c205f573e04edc900ad
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11337c205f573e04edc900ad
Content-Type: text/plain; charset=GB2312
Content-Transfer-Encoding: base64

SGkgQ2xzZWVyLA0KDQpQbGVhc2UgcmVhZCBoZXJlIHRvIHN1YnNjcmliZSB0aGUgbWFpbGluZyBs
aXN0Lg0KaHR0cDovL3NwYXJrLmluY3ViYXRvci5hcGFjaGUub3JnL21haWxpbmctbGlzdHMuaHRt
bA0KDQoNCg0KT24gV2VkLCBEZWMgMTgsIDIwMTMgYXQgMjowMyBQTSwgtq3O97PJKGNsc2Vlcikg
PGNsc2VlckBnbWFpbC5jb20+IHdyb3RlOg0KDQo+IEhpLCBhbGwsDQo+ICAgSSdtIGEgc3Bhcmsg
ZGV2ZWxwb3IgaW4gQ2hpbmEsIGFuZCB3YW50IHRvIGpvaW4gdGhpcyBTcGFyayBNYWlsaW5nIExp
c3QuDQo+IC0tDQo+DQo+IEJlc3QgcmVnYXJkcywNCj4gWGljaGVuZyBEb25nDQo+DQo+ID09PT09
PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT0NCj4gKry8
yvWyqb/NKjogaHR0cDovL2Rvbmd4aWNoZW5nLm9yZy8NCj4gKry8yvXK6byuKjogaHR0cDovL2hh
ZG9vcDEyMy5jb20vDQo+ICrOorKpKjogaHR0cDovL3dlaWJvLmNvbS9jbHNlZXINCj4gKrnYvPy0
yio6IFlBUk4vTWVzb3MsTWFwUmVkdWNlLFRleixTdG9ybQ0KPiA9PT09PT09PT09PT09PT09PT09
PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT0NCj4NCg==
--001a11337c205f573e04edc900ad--

From dev-return-947-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 18 07:05:41 2013
Return-Path: <dev-return-947-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CDFAE10053
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Dec 2013 07:05:41 +0000 (UTC)
Received: (qmail 4389 invoked by uid 500); 18 Dec 2013 07:05:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4130 invoked by uid 500); 18 Dec 2013 07:05:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 4122 invoked by uid 99); 18 Dec 2013 07:05:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 07:05:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 209.85.212.172 as permitted sender)
Received: from [209.85.212.172] (HELO mail-wi0-f172.google.com) (209.85.212.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Dec 2013 07:05:36 +0000
Received: by mail-wi0-f172.google.com with SMTP id en1so4812519wid.11
        for <dev@spark.incubator.apache.org>; Tue, 17 Dec 2013 23:05:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=BtKhvKvjuWKeWq60/sTzBqYNy9Mt5mNgDxthaMLLoKQ=;
        b=kwDGOxFLHVf7pwPprhddg6IMfNM5hKNCiZFlIxU/lzvQvEVUYXKMI6coXW79dofDyM
         8h8UpuLyCjsUBvbl3ruR4+c1p6z50a2az3Jcsp/ptlAoHDGCbkIONK031A60Mso/2eCB
         OrG0bLpfyhVNZfdP75zOgEOOrQz2mlphJtIIyI+GHENsqySxcU4ftOFDSdofO28GZifa
         YnOnO9sPfi7d4DR8KFBst/4Ln/8N3I2hJv+kPgayBgc0+EXdHpscWdlK640bVj3KKz06
         4cgMtSFRV24cZMHGnzWu2PlYmXiV5laUtC17DAN+Icp0jZVV5sSXuQoGkBOJvqwbAt/M
         yQHg==
MIME-Version: 1.0
X-Received: by 10.194.202.230 with SMTP id kl6mr22965528wjc.9.1387350314832;
 Tue, 17 Dec 2013 23:05:14 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Tue, 17 Dec 2013 23:05:14 -0800 (PST)
In-Reply-To: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
References: <CABPQxsvMZbfBBkHSGAXBK2-NP=rkfbGoF1znd8s6u8YMNqzpCQ@mail.gmail.com>
Date: Tue, 17 Dec 2013 23:05:14 -0800
Message-ID: <CALuGr6ZQrKiCtB0j=jAvWOcRUsweQ4qRx6A-Q8BrmXS1VQ31pA@mail.gmail.com>
Subject: Re: Scala 2.10 Merge
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b873a10b1db0d04edc9aa3d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b873a10b1db0d04edc9aa3d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

W00t :)

On Thursday, December 12, 2013, Patrick Wendell wrote:

> Hi Developers,
>
> In the next few days we are planning to merge Scala 2.10 support into
> Spark. For those that haven't been following this, Prashant Sharma has be=
en
> maintaining the scala-2.10 branch of Spark for several months. This branc=
h
> is current with master and has been reviewed for merging:
>
> https://github.com/apache/incubator-spark/tree/scala-2.10
>
> Scala 2.10 support is one of the most requested features for Spark - it
> will be great to get this into Spark 0.9! Please note that *Scala 2.10 is
> not binary compatible with Scala 2.9*. With that in mind, I wanted to giv=
e
> a few heads-up/requests to developers:
>
> If you are developing applications on top of Spark=E2=80=99s master branc=
h, those
> will need to migrate to Scala 2.10. You may want to download and test the
> current scala-2.10 branch in order to make sure you will be okay as Spark
> developments move forward. Of course, you can always stick with the curre=
nt
> master commit and be fine (I=E2=80=99ll cut a tag when we do the merge in=
 order to
> delineate where the version changes). Please open new threads on the dev
> list to report and discuss any issues.
>
> This merge will temporarily drop support for YARN 2.2 on the master branc=
h.
> This is because the workaround we used was only compiled for Scala 2.9. W=
e
> are going to come up with a more robust solution to YARN 2.2 support befo=
re
> releasing 0.9.
>
> Going forward, we will continue to make maintenance releases on branch-0.=
8
> which will remain compatible with Scala 2.9.
>
> For those interested, the primary code changes in this merge are upgradin=
g
> the akka version, changing the use of Scala 2.9=E2=80=99s ClassManifest c=
onstruct
> to Scala 2.10=E2=80=99s ClassTag, and updating the spark shell to work wi=
th Scala
> 2.10's repl.
>
> - Patrick
>

--047d7b873a10b1db0d04edc9aa3d--

From dev-return-948-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 17:28:01 2013
Return-Path: <dev-return-948-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0FD9010C31
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 17:28:01 +0000 (UTC)
Received: (qmail 70178 invoked by uid 500); 19 Dec 2013 17:27:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69802 invoked by uid 500); 19 Dec 2013 17:27:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 69786 invoked by uid 99); 19 Dec 2013 17:27:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 17:27:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mkolod@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 17:27:45 +0000
Received: by mail-ob0-f171.google.com with SMTP id wp18so1496730obc.2
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 09:27:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=7an2cOUlnUVjLQfMk/h78bXKzudfnIc1k8OGKHiWlq4=;
        b=iI9KUhdfNFzsK3F11cezc1VUxrMtTBMrwUNvg05ZYZBdu+cQBDh8/wZQiK/8Tba50r
         xb9DI6QGoWnedEycbu42dgYx6joP22b+Pw/zNrPwc6cwei3LOZ9GnYe4usF6NVUewy6o
         /wTkxVKWG1IcGfQf8WjeYXHFO9ZvgLZS22P4Q89gyIVlKb7rIzBLoQ8Crl7f5OrJjr/6
         Gz9u24c5BPN+RsWGcnkwfRQWmXMkOMW0CWMjnJ6pgyd+AZC5nhUPnDxLNhZGWsOM04Bd
         jsXdUjJs5dfXwy2K5e9mE1ZCANaxhry8IAIjkC+EuZkzC3wwd8uoD83BWCm1BnWhDpP8
         hvMA==
MIME-Version: 1.0
X-Received: by 10.183.3.102 with SMTP id bv6mr2246028obd.18.1387474044388;
 Thu, 19 Dec 2013 09:27:24 -0800 (PST)
Received: by 10.76.85.133 with HTTP; Thu, 19 Dec 2013 09:27:24 -0800 (PST)
Date: Thu, 19 Dec 2013 12:27:24 -0500
Message-ID: <CANBKJfp_sbL2U8un1w9KCOUJRF1vR7bdDP8HvUE93Y24htuHLw@mail.gmail.com>
Subject: View bound deprecation (Scala 2.11+)
From: Marek Kolodziej <mkolod@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1134a45c8d0c3304ede67940
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134a45c8d0c3304ede67940
Content-Type: text/plain; charset=ISO-8859-1

All,

Apparently view bounds will be deprecated going forward. Hopefully they'll
be around for a while after deprecation, but I wanted to raise this issue
for consideration. Here's the SIP:
https://issues.scala-lang.org/browse/SI-7629

Shall I file a Jira for that?

Thanks!

Marek

--001a1134a45c8d0c3304ede67940--

From dev-return-949-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 18:30:28 2013
Return-Path: <dev-return-949-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9E4EA10F54
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 18:30:28 +0000 (UTC)
Received: (qmail 36785 invoked by uid 500); 19 Dec 2013 18:30:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36752 invoked by uid 500); 19 Dec 2013 18:30:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 36744 invoked by uid 99); 19 Dec 2013 18:30:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:30:27 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.160.48 as permitted sender)
Received: from [209.85.160.48] (HELO mail-pb0-f48.google.com) (209.85.160.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:30:22 +0000
Received: by mail-pb0-f48.google.com with SMTP id md12so1496505pbc.7
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:30:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=blQAYfzbwFzNvs7HodGodwdt/tNalsM8gfA9oI2UTtI=;
        b=zk6fkGnpAqKv09vYkO/yUFrHTJAlVt2A5Dj40PyxIHmMugH04BHkuMmBi/RB36a075
         olmhLFmUIuS3LdfJ4Pbbx07c2lizAAvRvDlZMsLBu23yg4qCEbaYRL8L7hc6RhcZ832b
         mTH7Mb9xFvp0mt4zdkJGGjMJP2ByiJSE69Al651mtMtRlfAx9PYsgbCpssezjRFIcbaG
         T1NRDs5FPuNdYiRyHiamjmLt6HFCf21S6iHlvXLbEEuc+X2CxBVeVi/sd4RfNEPz+HuL
         6h/zlmsf4saSx9gS/5XoM1H3LcuaoEi12QTWURkdRqiy5ioJUrOKHhNqAdKVQEDD1Whn
         qx6g==
X-Received: by 10.68.106.98 with SMTP id gt2mr3347196pbb.61.1387477800692;
        Thu, 19 Dec 2013 10:30:00 -0800 (PST)
Received: from [192.168.1.105] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id tu6sm8889131pbc.41.2013.12.19.10.29.57
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 10:29:58 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: Spark development for undergraduate project
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAHH8_ON-2y69fBfVtt6pngWtEPOZdsmvt4hZ=dOE-DZSK6k3sA@mail.gmail.com>
Date: Thu, 19 Dec 2013 10:29:56 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
References: <CAHH8_ON-2y69fBfVtt6pngWtEPOZdsmvt4hZ=dOE-DZSK6k3sA@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Matt,

If you want to get started looking at Spark, I recommend the following =
resources:

- Our issue tracker at http://spark-project.atlassian.net contains some =
issues marked =93Starter=94 that are good places to jump into. You might =
be able to take one of those and extend it into a bigger project.

- The =93contributing to Spark=94 wiki page covers how to send patches =
and set up development: =
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark=20=


- This talk has an intro to Spark internals (video and slides are in the =
comments): http://www.meetup.com/spark-users/events/94101942/

For a longer project, here are some possible ones:

- Create a tool that automatically checks which Scala API methods are =
missing in Python. We had a similar one for Java that was very useful. =
Even better would be to automatically create wrappers for the Scala =
ones.

- Extend the Spark monitoring UI with profiling information (to sample =
the workers and say where they=92re spending time, or what data =
structures consume the most memory).

- Pick and implement a new machine learning algorithm for MLlib.

Matei

On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca> =
wrote:

> Hi everyone,
>=20
> During my most recent internship, I worked extensively with Apache =
Spark,
> integrating it into a company's data analytics platform. I've now =
become
> interested in contributing to Apache Spark.
>=20
> I'm returning to undergraduate studies in January and there is an =
academic
> course which is simply a standalone software engineering project. I =
was
> thinking that some contribution to Apache Spark would satisfy my =
curiosity,
> help continue support the company I interned at, and give me academic
> credits required to graduate, all at the same time. It seems like too =
good
> an opportunity to pass up.
>=20
> With that in mind, I have the following questions:
>=20
>   1. At this point, is there any self-contained project that I could =
work
>   on within Spark? Ideally, I would work on it independently, in about =
a
>   three month time frame. This time also needs to accommodate ramping =
up on
>   the Spark codebase and adjusting to the Scala programming language =
and
>   paradigms. The company I worked at primarily used the Java APIs. The =
output
>   needs to be a technical report describing the project requirements, =
and the
>   design process I took to engineer the solution for the requirements. =
In
>   particular, it cannot just be a series of haphazard patches.
>   2. How can I get started with contributing to Spark?
>   3. Is there a high-level UML or some other design specification for =
the
>   Spark architecture?
>=20
> Thanks! I hope to be of some help =3D)
>=20
> -Matt Cheah


From dev-return-950-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 18:31:15 2013
Return-Path: <dev-return-950-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D620D10F73
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 18:31:15 +0000 (UTC)
Received: (qmail 42183 invoked by uid 500); 19 Dec 2013 18:31:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42146 invoked by uid 500); 19 Dec 2013 18:31:15 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 42138 invoked by uid 99); 19 Dec 2013 18:31:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:31:15 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.180 as permitted sender)
Received: from [209.85.192.180] (HELO mail-pd0-f180.google.com) (209.85.192.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:31:08 +0000
Received: by mail-pd0-f180.google.com with SMTP id q10so1455144pdj.39
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:30:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=Vy6o5NL7MU533A0CBdFl+eWbopkeAadIJgofYnN7/do=;
        b=jpnDJjXjV7wMnEyDgm9zhepYTVV400F5AcnwzDg2/j5G9GMzpAKxZ9FcxSGKMfxhQq
         Ctc+yUtU1NmSikqk6DPYG+Aom81TsAPtWwCTA5d0rCWhJMIcuFqMUwCpa8a7QpMMqLL3
         IqQcbsKWMtZ5/1XFowRf2nq463BD1L62BIpmy3jbMNckC5GyW4rer8wZR6KQ1eFdeSRS
         QlNsKCBBiELYij1ViaviJYIBvirmJXy6wwwvBaEKLM+JxZFeZ9AcrpB+v12Io4mx68L4
         0yhHEmyJCs+Q0PXfVREAM+x84R5vd9CT8PwvcBFf75t8BYS54XGUwujOp3c9MsxShfRp
         b4SQ==
X-Received: by 10.67.3.34 with SMTP id bt2mr3314782pad.3.1387477847795;
        Thu, 19 Dec 2013 10:30:47 -0800 (PST)
Received: from [192.168.1.105] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id tu6sm8889131pbc.41.2013.12.19.10.30.46
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 10:30:46 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: View bound deprecation (Scala 2.11+)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CANBKJfp_sbL2U8un1w9KCOUJRF1vR7bdDP8HvUE93Y24htuHLw@mail.gmail.com>
Date: Thu, 19 Dec 2013 10:30:46 -0800
Content-Transfer-Encoding: quoted-printable
Message-Id: <A9F3883D-6F79-434A-BA6A-80D6FDDB4313@gmail.com>
References: <CANBKJfp_sbL2U8un1w9KCOUJRF1vR7bdDP8HvUE93Y24htuHLw@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

We can open a JIRA but let=92s wait to see what the Scala guys decide. =
I=92m sure they=92ll recommend some alternatives.

Matei

On Dec 19, 2013, at 9:27 AM, Marek Kolodziej <mkolod@gmail.com> wrote:

> All,
>=20
> Apparently view bounds will be deprecated going forward. Hopefully =
they'll
> be around for a while after deprecation, but I wanted to raise this =
issue
> for consideration. Here's the SIP:
> https://issues.scala-lang.org/browse/SI-7629
>=20
> Shall I file a Jira for that?
>=20
> Thanks!
>=20
> Marek


From dev-return-951-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 18:38:52 2013
Return-Path: <dev-return-951-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 16A9110FBE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 18:38:52 +0000 (UTC)
Received: (qmail 61507 invoked by uid 500); 19 Dec 2013 18:38:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61474 invoked by uid 500); 19 Dec 2013 18:38:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 61466 invoked by uid 99); 19 Dec 2013 18:38:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:38:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.49 as permitted sender)
Received: from [209.85.216.49] (HELO mail-qa0-f49.google.com) (209.85.216.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:38:47 +0000
Received: by mail-qa0-f49.google.com with SMTP id ii20so1798152qab.8
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:38:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:in-reply-to:references:from:to:subject
         :content-type;
        bh=vBaSxleOAJZn+7qnPL1Cchh3PfnbhiNDJAc/JuffVSg=;
        b=dpWYO6tOXcnh7mn6WinaE6DrTCe1SNgSfI99euTgpvlksIQkbIZ2y/iFWDe352bR3h
         yiZMFvUh0hX5jqrYw3UoyzxMtIDy6BGAp0FIpheNilqgXmAwLDSWbsmOZq6qBno8gv53
         C0Aje9LAuyJk07xcBjCtYYP7xtusMLqok0yfvL3MyW7GP4pWsI56Uv7UA9+Dh0ZauwF4
         nprAgcNSVmQof6W0e1Vu+dKpyXt9WCeJCEVSfdaV5chA35hJXPkdeWbjClAiPhuwGsct
         IlBs9EvPHcp+1rdCyQKXgLxHCP0Zi4hl5N4lHUlqtFoLG0ZoHqZXmNGFe4NddGMXVm8k
         a9Ag==
X-Received: by 10.224.8.132 with SMTP id h4mr5605802qah.103.1387478307048;
        Thu, 19 Dec 2013 10:38:27 -0800 (PST)
Received: from [127.0.0.1] (ec2-54-235-159-161.compute-1.amazonaws.com. [54.235.159.161])
        by mx.google.com with ESMTPSA id s14sm1948671qad.20.2013.12.19.10.38.26
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 10:38:26 -0800 (PST)
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Date: Thu, 19 Dec 2013 10:38:26 -0800 (PST)
Message-Id: <1387478305969.35e7931@Nodemailer>
In-Reply-To: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
X-Orchestra-Oid: 0F8C0FDA-A07E-4676-97AE-F5F44F9A1CDA
X-Orchestra-Sig: e269668e8a4a0b7322c3310983bccc727a8f0b84
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1454696384561327324
X-Orchestra-Thrid-Sig: 50b128ea59361b7bf3a8bdf0d7b273b442e10739
X-Orchestra-Account: 4ce12bc1b98c1c47f27c7a22fac70eb9130db7bf
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Subject: Re: Spark development for undergraduate project
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1387478306369"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1387478306369
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Or if you're extremely ambitious work in implementing Spark Streaming in =
Python=E2=80=94
Sent from Mailbox for iPhone

On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Hi Matt,
> If you want to get started looking at Spark, I recommend the following =
resources:
> - Our issue tracker at http://spark-project.atlassian.net contains some =
issues marked =E2=80=9CStarter=E2=80=9D that are good places to jump into. =
You might be able to take one of those and extend it into a bigger project.=

> - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers how to =
send patches and set up development: https://cwiki.apache.=
org/confluence/display/SPARK/Contributing+to+Spark=20
> - This talk has an intro to Spark internals (video and slides are in the =
comments): http://www.meetup.com/spark-users/events/94101942/
> For a longer project, here are some possible ones:
> - Create a tool that automatically checks which Scala API methods are =
missing in Python. We had a similar one for Java that was very useful. Even=
 better would be to automatically create wrappers for the Scala ones.
> - Extend the Spark monitoring UI with profiling information (to sample =
the workers and say where they=E2=80=99re spending time, or what data =
structures consume the most memory).
> - Pick and implement a new machine learning algorithm for MLlib.
> Matei
> On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca> =
wrote:
>> Hi everyone,
>>=20
>> During my most recent internship, I worked extensively with Apache Spark=
,
>> integrating it into a company's data analytics platform. I've now =
become
>> interested in contributing to Apache Spark.
>>=20
>> I'm returning to undergraduate studies in January and there is an =
academic
>> course which is simply a standalone software engineering project. I was
>> thinking that some contribution to Apache Spark would satisfy my =
curiosity,
>> help continue support the company I interned at, and give me academic
>> credits required to graduate, all at the same time. It seems like too =
good
>> an opportunity to pass up.
>>=20
>> With that in mind, I have the following questions:
>>=20
>>   1. At this point, is there any self-contained project that I could =
work
>>   on within Spark=3F Ideally, I would work on it independently, in about=
 a
>>   three month time frame. This time also needs to accommodate ramping up=
 on
>>   the Spark codebase and adjusting to the Scala programming language =
and
>>   paradigms. The company I worked at primarily used the Java APIs. The =
output
>>   needs to be a technical report describing the project requirements, =
and the
>>   design process I took to engineer the solution for the requirements. =
In
>>   particular, it cannot just be a series of haphazard patches.
>>   2. How can I get started with contributing to Spark=3F
>>   3. Is there a high-level UML or some other design specification for =
the
>>   Spark architecture=3F
>>=20
>> Thanks! I hope to be of some help =3D)
>>=20
>> -Matt Cheah
------Nodemailer-0.5.0-?=_1-1387478306369--

From dev-return-952-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 18:57:37 2013
Return-Path: <dev-return-952-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 921BA100C1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 18:57:37 +0000 (UTC)
Received: (qmail 13486 invoked by uid 500); 19 Dec 2013 18:57:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13444 invoked by uid 500); 19 Dec 2013 18:57:37 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 13435 invoked by uid 99); 19 Dec 2013 18:57:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:57:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.128.179] (HELO mail-ve0-f179.google.com) (209.85.128.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:57:33 +0000
Received: by mail-ve0-f179.google.com with SMTP id jw12so885301veb.24
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:57:12 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=nYQtYbQvqYrVGtaD3adqU6tY95qih9w90VBHOW9GSYs=;
        b=YtcT0p+SdiEcow/YIN5JALFD9Lj2Bp7J6JCLggiGQwGAq/tMXam97WGLoM07wXtxm6
         4mv9OqMBxriuJAlL+EFP/3nFReAWxWciF7Jw4UGXtzW8cNMoQg724PKVQQim/Px25gZR
         O6KUfqO9NL/gXWL6xLE3up+U8DDsOml7KPVv0m9cvqdRo6kvU4X3hnAGEUbjM+ZkFAZg
         vSMcTaGVEbLNaf3qPO0VaWljmfpShIkohL/YQoi01M7pQMb/rrbtquNAVbAsJf17+HUL
         vUfJ659MpSX0ClQYvilmpqrWjhORZbG8U8FRTNf2AsWyhmqDlk3doJoXr1rMDQ/yQ/hQ
         R0Qw==
X-Gm-Message-State: ALoCoQk4fk5aAg898d6qZOnXtuiGc0aiStQvMWeIsGJU1tRLRaImWF5R2m8tkFjjagR/ONMtRZ3C
X-Received: by 10.58.210.39 with SMTP id mr7mr2014931vec.18.1387479431953;
        Thu, 19 Dec 2013 10:57:11 -0800 (PST)
Received: from mail-vc0-f175.google.com (mail-vc0-f175.google.com [209.85.220.175])
        by mx.google.com with ESMTPSA id xa5sm5959974vdc.7.2013.12.19.10.57.10
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 10:57:10 -0800 (PST)
Received: by mail-vc0-f175.google.com with SMTP id ld13so890803vcb.34
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:57:09 -0800 (PST)
X-Received: by 10.52.231.130 with SMTP id tg2mr1677143vdc.16.1387479429600;
 Thu, 19 Dec 2013 10:57:09 -0800 (PST)
MIME-Version: 1.0
Received: by 10.220.249.9 with HTTP; Thu, 19 Dec 2013 10:56:49 -0800 (PST)
In-Reply-To: <1387478305969.35e7931@Nodemailer>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com> <1387478305969.35e7931@Nodemailer>
From: Andrew Ash <andrew@andrewash.com>
Date: Thu, 19 Dec 2013 13:56:49 -0500
Message-ID: <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0102f832890b5f04ede7bac7
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0102f832890b5f04ede7bac7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I think there are also some improvements that could be made to
deployability in an enterprise setting.  From my experience:

1. Most places I deploy Spark in don't have internet access.  So I can't
build from source, compile against a different version of Hadoop, etc
without doing it locally and then getting that onto my servers manually.
 This is less a problem with Spark now that there are binary distributions,
but it's still a problem for using Mesos with Spark.
2. Configuration of Spark is confusing -- you can make configuration in
Java system properties, environment variables, command line parameters, and
for the standalone cluster deployment mode you need to worry about whether
these need to be set on the master, the worker, the executor, or the
application/driver program.  Also because spark-shell automatically
instantiates a SparkContext you have to set up any system properties in the
init scripts or on the command line with
JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what needs to=
 be
done, but it feels that there are gains to be made in configuration options
here.  Ideally, I would have one configuration file that can be used in all
4 places and that's the only place to make configuration changes.
3. Standalone cluster mode could use improved resiliency for starting,
stopping, and keeping alive a service -- there are custom init scripts that
call each other in a mess of ways: spark-shell, spark-daemon.sh,
spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh,
spark-executor, spark-class, run-example, and several others in the bin/
directory.  I would love it if Spark used the Tanuki Service Wrapper, which
is widely-used for Java service daemons, supports retries, installation as
init scripts that can be chkconfig'd, etc.  Let's not re-solve the "how do
I keep a service running?" problem when it's been done so well by Tanuki --
we use it at my day job for all our services, plus it's used by
Elasticsearch.  This would help solve the problem where a quick bounce of
the master causes all the workers to self-destruct.
4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this is
entirely an Akka bug based on previous mailing list discussion with Matei,
but it'd be awesome if you could use either the hostname or the FQDN or the
IP address in the Spark URL and not have Akka barf at you.

I've been telling myself I'd look into these at some point but just haven't
gotten around to them myself yet.  Some day!  I would prioritize these
requests from most- to least-important as 3, 2, 4, 1.

Andrew


On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <nick.pentreath@gmail.com>w=
rote:

> Or if you're extremely ambitious work in implementing Spark Streaming in
> Python=E2=80=94
> Sent from Mailbox for iPhone
>
> On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>
> > Hi Matt,
> > If you want to get started looking at Spark, I recommend the following
> resources:
> > - Our issue tracker at http://spark-project.atlassian.net contains some
> issues marked =E2=80=9CStarter=E2=80=9D that are good places to jump into=
. You might be
> able to take one of those and extend it into a bigger project.
> > - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers how to s=
end patches and
> set up development:
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
> > - This talk has an intro to Spark internals (video and slides are in th=
e
> comments): http://www.meetup.com/spark-users/events/94101942/
> > For a longer project, here are some possible ones:
> > - Create a tool that automatically checks which Scala API methods are
> missing in Python. We had a similar one for Java that was very useful. Ev=
en
> better would be to automatically create wrappers for the Scala ones.
> > - Extend the Spark monitoring UI with profiling information (to sample
> the workers and say where they=E2=80=99re spending time, or what data str=
uctures
> consume the most memory).
> > - Pick and implement a new machine learning algorithm for MLlib.
> > Matei
> > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>
> wrote:
> >> Hi everyone,
> >>
> >> During my most recent internship, I worked extensively with Apache
> Spark,
> >> integrating it into a company's data analytics platform. I've now beco=
me
> >> interested in contributing to Apache Spark.
> >>
> >> I'm returning to undergraduate studies in January and there is an
> academic
> >> course which is simply a standalone software engineering project. I wa=
s
> >> thinking that some contribution to Apache Spark would satisfy my
> curiosity,
> >> help continue support the company I interned at, and give me academic
> >> credits required to graduate, all at the same time. It seems like too
> good
> >> an opportunity to pass up.
> >>
> >> With that in mind, I have the following questions:
> >>
> >>   1. At this point, is there any self-contained project that I could
> work
> >>   on within Spark? Ideally, I would work on it independently, in about=
 a
> >>   three month time frame. This time also needs to accommodate ramping
> up on
> >>   the Spark codebase and adjusting to the Scala programming language a=
nd
> >>   paradigms. The company I worked at primarily used the Java APIs. The
> output
> >>   needs to be a technical report describing the project requirements,
> and the
> >>   design process I took to engineer the solution for the requirements.
> In
> >>   particular, it cannot just be a series of haphazard patches.
> >>   2. How can I get started with contributing to Spark?
> >>   3. Is there a high-level UML or some other design specification for
> the
> >>   Spark architecture?
> >>
> >> Thanks! I hope to be of some help =3D)
> >>
> >> -Matt Cheah
>

--089e0102f832890b5f04ede7bac7--

From dev-return-953-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 18:58:27 2013
Return-Path: <dev-return-953-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 647D1100D6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 18:58:27 +0000 (UTC)
Received: (qmail 18880 invoked by uid 500); 19 Dec 2013 18:58:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18840 invoked by uid 500); 19 Dec 2013 18:58:27 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 18832 invoked by uid 99); 19 Dec 2013 18:58:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:58:27 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.181 as permitted sender)
Received: from [209.85.216.181] (HELO mail-qc0-f181.google.com) (209.85.216.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 18:58:20 +0000
Received: by mail-qc0-f181.google.com with SMTP id e9so1283450qcy.40
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 10:57:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:in-reply-to:references:from:to:subject
         :content-type;
        bh=DUboIZ5hJT6e7qZ2CdjeM7W5ZeX1zBQs66GFkjvJaG0=;
        b=wdCZZsQgdkb16CtfCbfVPKsDAkm1YjCAiJZ88MZyVqHy2WB/Y1s/iBsL3HsAmH+QJ6
         5hm6nbWgXXccT5aMB0kvabOadxWu8aiXZL+KosaqaCZlTYodtCGDPH70PHdHYrem26BG
         /sPKw5oqK1JjJddbRmOFx+CRD5GG+HjWzivG90I+ATkqPc0vCu9i2lUxbONRXWPTe9bk
         VFzySCjdvA/65+lGMK892rUCsL/a6AVUnB7ETRGQ+ELYSKtv2Sqml5iqrNPs9YHdPhZj
         FpjJfcWNEVfWpqe3x9lvl0ay23eZ9HR5zv+HacFm0TRq31z5y9S1GS38teflh3MMQ4PJ
         6bNQ==
X-Received: by 10.224.124.16 with SMTP id s16mr5932231qar.78.1387479479025;
        Thu, 19 Dec 2013 10:57:59 -0800 (PST)
Received: from [127.0.0.1] (ec2-54-235-159-161.compute-1.amazonaws.com. [54.235.159.161])
        by mx.google.com with ESMTPSA id z4sm1924044qeq.11.2013.12.19.10.57.58
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 10:57:58 -0800 (PST)
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Date: Thu, 19 Dec 2013 10:57:58 -0800 (PST)
Message-Id: <1387479478000.3afa05e2@Nodemailer>
In-Reply-To: <CALD+6GNSPSWFujzvRcCbk_zXxd9yfdKpFRKfLOOER3m2KvL7sQ@mail.gmail.com>
References: <CALD+6GNSPSWFujzvRcCbk_zXxd9yfdKpFRKfLOOER3m2KvL7sQ@mail.gmail.com>
X-Orchestra-Oid: AFDB3057-A671-4E48-9E6C-564E70AB9D14
X-Orchestra-Sig: fb73a379bf6e34d74dc0c4f32f1f4166512376d7
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1449847038745203630
X-Orchestra-Thrid-Sig: 4de32dfc98b863a7bea94a34bed107b024fc035a
X-Orchestra-Account: 6260f21df722693bb60d54b645d8d27f08500036
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Subject: Re: [PySpark]: reading arbitrary Hadoop InputFormats
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1387479478322"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1387479478322
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hi


I managed to find the time to put together a PR on this:=C2=A0https://githu=
b.com/apache/incubator-spark/pull/263




Josh has had a look over it - if anyone else with an interest could give =
some feedback that would be great.




As mentioned in the PR it's more of an RFC and certainly still needs a bit =
of clean up work, and I need to add the concept of =22wrapper functions=22 =
to deserialize classes that MsgPack can't handle out the box.




N
=E2=80=94
Sent from Mailbox for iPhone

On Fri, Nov 8, 2013 at 12:20 PM, Nick Pentreath <nick.pentreath@gmail.com>
wrote:

> Wow Josh, that looks great. I've been a bit swamped this week but as =
soon
> as I get a chance I'll test out the PR in more detail and port over the
> InputFormat stuff to use the new framework (including the changes you
> suggested).
> I can then look deeper into the MsgPack functionality to see if it can =
be
> made to work in a generic enough manner without requiring huge amounts =
of
> custom Templates to be written by users.
> Will feed back asap.
> N
> On Thu, Nov 7, 2013 at 5:03 AM, Josh Rosen <rosenville@gmail.com> wrote:
>> I opened a pull request to add custom serializer support to PySpark:
>> https://github.com/apache/incubator-spark/pull/146
>>
>> My pull request adds the plumbing for transferring data from Java to =
Python
>> using formats other than Pickle.  For example, look at how textFile() =
uses
>> MUTF8Deserializer to read strings from Java.  Hopefully this provides =
all
>> of the functionality needed to support MsgPack.
>>
>> - Josh
>>
>>
>> On Thu, Oct 31, 2013 at 11:11 AM, Josh Rosen <rosenville@gmail.com> =
wrote:
>>
>> > Hi Nick,
>> >
>> > This is a nice start.  I'd prefer to keep the Java =
sequenceFileAsText()
>> > and newHadoopFileAsText() methods inside PythonRDD instead of adding =
them
>> > to JavaSparkContext, since I think these methods are unlikely to be =
used
>> > directly by Java users (you can add these methods to the PythonRDD
>> > companion object, which is how readRDDFromPickleFile is implemented:
>> >
>> https://github.com/apache/incubator-spark/blob/branch-0.=
8/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala#L255
>> > )
>> >
>> > For MsgPack, the UnpicklingError is because the Python worker expects =
to
>> > receive its input in a pickled format.  In my prototype of custom
>> > serializers, I modified the PySpark worker to receive its
>> > serialization/deserialization function as input (
>> >
>> https://github.com/JoshRosen/spark/blob/59b6b43916dc84fc8b83f22eb9ce13a2=
7bc51ec0/python/pyspark/worker.py#L41
>> )
>> > and added logic to pass the appropriate serializers based on each =
stage's
>> > input and output formats (
>> >
>> https://github.com/JoshRosen/spark/blob/59b6b43916dc84fc8b83f22eb9ce13a2=
7bc51ec0/python/pyspark/rdd.py#L42
>> > ).
>> >
>> > At some point, I'd like to port my custom serializers code to PySpark;=
 if
>> > anyone's interested in helping, I'd be glad to write up some =
additional
>> > notes on how this should work.
>> >
>> > - Josh
>> >
>> > On Wed, Oct 30, 2013 at 2:25 PM, Nick Pentreath <
>> nick.pentreath@gmail.com>wrote:
>> >
>> >> Thanks Josh, Patrick for the feedback.
>> >>
>> >> Based on Josh's pointers I have something working for JavaPairRDD ->
>> >> PySpark RDD[(String, String)]. This just calls the toString method =
on
>> each
>> >> key and value as before, but without the need for a delimiter. For
>> >> SequenceFile, it uses SequenceFileAsTextInputFormat which itself =
calls
>> >> toString to convert to Text for keys and values. We then call =
toString
>> >> (again) ourselves to get Strings to feed to writeAsPickle.
>> >>
>> >> Details here: https://gist.github.com/MLnick/7230588
>> >>
>> >> This also illustrates where the =22wrapper function=22 api would fit =
in. All
>> >> that is required is to define a T =3D> String for key and value.
>> >>
>> >> I started playing around with MsgPack and can sort of get things to =
work
>> >> in
>> >> Scala, but am struggling with getting the raw bytes to be written
>> properly
>> >> in PythonRDD (I think it is treating them as pickled byte arrays =
when
>> they
>> >> are not, but when I removed the 'stripPickle' calls and amended the
>> length
>> >> (-6) I got =22UnpicklingError: invalid load key, ' '. =22).
>> >>
>> >> Another issue is that MsgPack does well at writing =22structures=22 -=
 like
>> >> Java
>> >> classes with public fields that are fairly simple - but for example =
the
>> >> Writables have private fields so you end up with nothing being =
written.
>> >> This looks like it would require custom =22Templates=22 =
(serialization
>> >> functions effectively) for many classes, which means a lot of custom
>> code
>> >> for a user to write to use it. Fortunately for most of the common
>> >> Writables
>> >> a toString does the job. Will keep looking into it though.
>> >>
>> >> Anyway, Josh if you have ideas or examples on the =22Wrapper API =
from
>> >> Python=22
>> >> that you mentioned, I'd be interested to hear them.
>> >>
>> >> If you think this is worth working up as a Pull Request covering
>> >> SequenceFiles and custom InputFormats with default toString =
conversions
>> >> and
>> >> the ability to specify Wrapper functions, I can clean things up more,=

>> add
>> >> some functionality and tests, and also test to see if common things =
like
>> >> the =22normal=22 Writables and reading from things like HBase and =
Cassandra
>> >> can
>> >> be made to work nicely (any other common use cases that you think =
make
>> >> sense=3F).
>> >>
>> >> Thoughts, comments etc welcome.
>> >>
>> >> Nick
>> >>
>> >>
>> >>
>> >> On Fri, Oct 25, 2013 at 11:03 PM, Patrick Wendell <pwendell@gmail.=
com
>> >> >wrote:
>> >>
>> >> > As a starting point, a version where people just write their own
>> >> =22wrapper=22
>> >> > functions to convert various HadoopFiles into String <K, V> files
>> could
>> >> go
>> >> > a long way. We could even have a few built-in versions, such as
>> dealing
>> >> > with Sequence files that are <String, String>. Basically, the user
>> >> needs to
>> >> > write a translator in Java/Scala that produces textual records =
from
>> >> > whatever format that want. Then, they make sure this is included =
in
>> the
>> >> > classpath when running PySpark.
>> >> >
>> >> > As Josh is saying, I'm pretty sure this is already possible, but =
we
>> may
>> >> > want to document it for users. In many organizations they might =
have
>> 1-2
>> >> > people who can write the Java/Scala to do this but then many more
>> people
>> >> > who are comfortable using python once it's setup.
>> >> >
>> >> > - Patrick
>> >> >
>> >> > On Fri, Oct 25, 2013 at 11:00 AM, Josh Rosen <rosenville@gmail.=
com>
>> >> wrote:
>> >> >
>> >> > > Hi Nick,
>> >> > >
>> >> > > I've seen several requests for SequenceFile support in PySpark, =
so
>> >> > there's
>> >> > > definitely demand for this feature.
>> >> > >
>> >> > > I like the idea of passing MsgPack'ed data (or some other =
structured
>> >> > > format) from Java to the Python workers.  My early prototype of
>> custom
>> >> > > serializers (described at
>> >> > >
>> >> > >
>> >> >
>> >>
>> https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals#PySp=
arkInternals-customserializers
>> >> > > )
>> >> > > might be useful for implementing this.  Proper custom serializer
>> >> support
>> >> > > would handle the bookkeeping for tracking each stage's input and
>> >> output
>> >> > > formats and supplying the appropriate deserialization functions =
to
>> the
>> >> > > Python worker, so the Python worker would be able to directly =
read
>> the
>> >> > > MsgPack'd data that's sent to it.
>> >> > >
>> >> > > Regarding a wrapper API, it's actually possible to initially
>> transform
>> >> > data
>> >> > > using Scala/Java and perform the remainder of the processing in
>> >> PySpark.
>> >> > >  This involves adding the appropriate compiled to the Java =
classpath
>> >> and
>> >> > a
>> >> > > bit of work in Py4J to create the Java/Scala RDD and wrap it for =
use
>> >> by
>> >> > > PySpark.  I can hack together a rough example of this if =
anyone's
>> >> > > interested, but it would need some work to be developed into a
>> >> > > user-friendly API.
>> >> > >
>> >> > > If you wanted to extend your proof-of-concept to handle the =
cases
>> >> where
>> >> > > keys and values have parseable toString() values, I think you =
could
>> >> > remove
>> >> > > the need for a delimiter by creating a PythonRDD from the
>> >> newHadoopFile
>> >> > > JavaPairRDD and adding a new method to writeAsPickle (
>> >> > >
>> >> > >
>> >> >
>> >>
>> https://github.com/apache/incubator-spark/blob/master/core/src/main/scal=
a/org/apache/spark/api/python/PythonRDD.scala#L224
>> >> > > )
>> >> > > to dump its contents as a pickled pair of strings.  (Aside: most =
of
>> >> > > writeAsPickle() would probably need be eliminated or refactored =
when
>> >> > adding
>> >> > > general custom serializer support).
>> >> > >
>> >> > > - Josh
>> >> > >
>> >> > > On Thu, Oct 24, 2013 at 11:18 PM, Nick Pentreath
>> >> > > <nick.pentreath@gmail.com>wrote:
>> >> > >
>> >> > > > Hi Spark Devs
>> >> > > >
>> >> > > > I was wondering what appetite there may be to add the ability =
for
>> >> > PySpark
>> >> > > > users to create RDDs from (somewhat) arbitrary Hadoop
>> InputFormats.
>> >> > > >
>> >> > > > In my data pipeline for example, I'm currently just using =
Scala
>> >> (partly
>> >> > > > because I love it but also because I am heavily reliant on =
quite
>> >> custom
>> >> > > > Hadoop InputFormats for reading data). However, many users may
>> >> prefer
>> >> > to
>> >> > > > use PySpark as much as possible (if not for everything). =
Reasons
>> >> might
>> >> > > > include the need to use some Python library. While I don't do =
it
>> >> yet, I
>> >> > > can
>> >> > > > certainly see an attractive use case for using say scikit-learn=
 /
>> >> numpy
>> >> > > to
>> >> > > > do data analysis & machine learning in Python. Added to this =
my
>> >> > cofounder
>> >> > > > knows Python well but not Scala so it can be very beneficial =
to
>> do a
>> >> > lot
>> >> > > of
>> >> > > > stuff in Python.
>> >> > > >
>> >> > > > For text-based data this is fine, but reading data in from =
more
>> >> complex
>> >> > > > Hadoop formats is an issue.
>> >> > > >
>> >> > > > The current approach would of course be to write an ETL-style
>> >> > Java/Scala
>> >> > > > job and then process in Python. Nothing wrong with this, but I =
was
>> >> > > thinking
>> >> > > > about ways to allow Python to access arbitrary Hadoop
>> InputFormats.
>> >> > > >
>> >> > > > Here is a quick proof of concept:
>> >> > https://gist.github.com/MLnick/7150058
>> >> > > >
>> >> > > > This works for simple stuff like SequenceFile with simple =
Writable
>> >> > > > key/values.
>> >> > > >
>> >> > > > To work with more complex files, perhaps an approach is to
>> >> manipulate
>> >> > > > Hadoop JobConf via Python and pass that in. The one downside is=
 of
>> >> > course
>> >> > > > that the InputFormat (well actually the Key/Value classes) =
must
>> >> have a
>> >> > > > toString that makes sense so very custom stuff might not work.
>> >> > > >
>> >> > > > I wonder if it would be possible to take the objects that are
>> >> yielded
>> >> > via
>> >> > > > the InputFormat and convert them into some representation like
>> >> > ProtoBuf,
>> >> > > > MsgPack, Avro, JSON, that can be read relatively more easily =
from
>> >> > Python=3F
>> >> > > >
>> >> > > > Another approach could be to allow a simple =22wrapper API=22 =
such
>> that
>> >> one
>> >> > > can
>> >> > > > write a wrapper function T =3D> String and pass that into an
>> >> > > > InputFormatWrapper that takes an arbitrary InputFormat and =
yields
>> >> > Strings
>> >> > > > for the keys and values. Then all that is required is to =
compile
>> >> that
>> >> > > > function and add it to the SPARK=5FCLASSPATH and away you go!
>> >> > > >
>> >> > > > Thoughts=3F
>> >> > > >
>> >> > > > Nick
>> >> > > >
>> >> > >
>> >> >
>> >>
>> >
>> >
>>
------Nodemailer-0.5.0-?=_1-1387479478322--

From dev-return-954-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 19:02:54 2013
Return-Path: <dev-return-954-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 490FA10104
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 19:02:54 +0000 (UTC)
Received: (qmail 27363 invoked by uid 500); 19 Dec 2013 19:02:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27320 invoked by uid 500); 19 Dec 2013 19:02:54 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 27312 invoked by uid 99); 19 Dec 2013 19:02:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 19:02:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.48 as permitted sender)
Received: from [209.85.216.48] (HELO mail-qa0-f48.google.com) (209.85.216.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 19:02:50 +0000
Received: by mail-qa0-f48.google.com with SMTP id w5so1838933qac.14
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 11:02:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:in-reply-to:references:from:to:subject
         :content-type;
        bh=I4ZLQ49AHuoVbrUWRaYPrJKHsmqgXRIlcGKKIz/1iyY=;
        b=P+OxsPgTys0BOJLUOkYpuy5VfFtOcmGYpnUqEqmez1fgC7kg3WIl3ks0uKgX1+kGfP
         Hxd3dGOPAq7u8qSuItfI9iovvVZkGMqnmPniMEL8QcBvYgCUa0B5FwroX7UXet/EJJvz
         dmUFuj+OjRZrnV9xAF+qkul7eKygTpuIA3OtQUSQlfv2lq85k/V4v5cRg5gwYHSQ7DWD
         Sdh1++XLhmAJdKa0I0wWAtCH+XEGt9ze3434y2DWs5SUdr7eSzPjf49ExtBXP8MCQV3D
         ElWkHp5kX4ejlnUj2yk6ZC0Vcp39VupozC0OVax7GY4No5IGxbqiG+BdHWdCBDH1A2KP
         lcbw==
X-Received: by 10.49.74.138 with SMTP id t10mr5962170qev.21.1387479749375;
        Thu, 19 Dec 2013 11:02:29 -0800 (PST)
Received: from [127.0.0.1] (ec2-54-235-159-161.compute-1.amazonaws.com. [54.235.159.161])
        by mx.google.com with ESMTPSA id m8sm2058054qac.22.2013.12.19.11.02.28
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 11:02:28 -0800 (PST)
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Date: Thu, 19 Dec 2013 11:02:28 -0800 (PST)
Message-Id: <1387479748205.97d3e4de@Nodemailer>
In-Reply-To: <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
References: <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
X-Orchestra-Oid: 87BA36C0-5B3F-42C4-AC6A-080D95D7E693
X-Orchestra-Sig: 570548f5dc152f5f9ad426ebadf9f8df4ebb604c
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1454696384561327324
X-Orchestra-Thrid-Sig: 50b128ea59361b7bf3a8bdf0d7b273b442e10739
X-Orchestra-Account: b8896a1c5c7bb2d0224055f09ebaed33f1e85987
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Subject: Re: Spark development for undergraduate project
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1387479748640"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1387479748640
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Some good things to look at though hopefully #2 will be largely addressed =
by:=C2=A0https://github.com/apache/incubator-spark/pull/230=E2=80=94
Sent from Mailbox for iPhone

On Thu, Dec 19, 2013 at 8:57 PM, Andrew Ash <andrew@andrewash.com> wrote:

> I think there are also some improvements that could be made to
> deployability in an enterprise setting.  From my experience:
> 1. Most places I deploy Spark in don't have internet access.  So I can't
> build from source, compile against a different version of Hadoop, etc
> without doing it locally and then getting that onto my servers manually.
>  This is less a problem with Spark now that there are binary =
distributions,
> but it's still a problem for using Mesos with Spark.
> 2. Configuration of Spark is confusing -- you can make configuration in
> Java system properties, environment variables, command line parameters, =
and
> for the standalone cluster deployment mode you need to worry about =
whether
> these need to be set on the master, the worker, the executor, or the
> application/driver program.  Also because spark-shell automatically
> instantiates a SparkContext you have to set up any system properties in =
the
> init scripts or on the command line with
> JAVA=5FOPTS=3D=22-Dspark.executor.memory=3D8g=22 etc.  I'm not sure what =
needs to be
> done, but it feels that there are gains to be made in configuration =
options
> here.  Ideally, I would have one configuration file that can be used in =
all
> 4 places and that's the only place to make configuration changes.
> 3. Standalone cluster mode could use improved resiliency for starting,
> stopping, and keeping alive a service -- there are custom init scripts =
that
> call each other in a mess of ways: spark-shell, spark-daemon.sh,
> spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh,
> spark-executor, spark-class, run-example, and several others in the bin/
> directory.  I would love it if Spark used the Tanuki Service Wrapper, =
which
> is widely-used for Java service daemons, supports retries, installation =
as
> init scripts that can be chkconfig'd, etc.  Let's not re-solve the =22how=
 do
> I keep a service running=3F=22 problem when it's been done so well by =
Tanuki --
> we use it at my day job for all our services, plus it's used by
> Elasticsearch.  This would help solve the problem where a quick bounce =
of
> the master causes all the workers to self-destruct.
> 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this is
> entirely an Akka bug based on previous mailing list discussion with Matei=
,
> but it'd be awesome if you could use either the hostname or the FQDN or =
the
> IP address in the Spark URL and not have Akka barf at you.
> I've been telling myself I'd look into these at some point but just =
haven't
> gotten around to them myself yet.  Some day!  I would prioritize these
> requests from most- to least-important as 3, 2, 4, 1.
> Andrew
> On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <nick.pentreath@gmail.=
com>wrote:
>> Or if you're extremely ambitious work in implementing Spark Streaming =
in
>> Python=E2=80=94
>> Sent from Mailbox for iPhone
>>
>> On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <matei.zaharia@gmail.=
com>
>> wrote:
>>
>> > Hi Matt,
>> > If you want to get started looking at Spark, I recommend the =
following
>> resources:
>> > - Our issue tracker at http://spark-project.atlassian.net contains =
some
>> issues marked =E2=80=9CStarter=E2=80=9D that are good places to jump =
into. You might be
>> able to take one of those and extend it into a bigger project.
>> > - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers how to =
send patches and
>> set up development:
>> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
>> > - This talk has an intro to Spark internals (video and slides are in =
the
>> comments): http://www.meetup.com/spark-users/events/94101942/
>> > For a longer project, here are some possible ones:
>> > - Create a tool that automatically checks which Scala API methods are
>> missing in Python. We had a similar one for Java that was very useful. =
Even
>> better would be to automatically create wrappers for the Scala ones.
>> > - Extend the Spark monitoring UI with profiling information (to =
sample
>> the workers and say where they=E2=80=99re spending time, or what data =
structures
>> consume the most memory).
>> > - Pick and implement a new machine learning algorithm for MLlib.
>> > Matei
>> > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>
>> wrote:
>> >> Hi everyone,
>> >>
>> >> During my most recent internship, I worked extensively with Apache
>> Spark,
>> >> integrating it into a company's data analytics platform. I've now =
become
>> >> interested in contributing to Apache Spark.
>> >>
>> >> I'm returning to undergraduate studies in January and there is an
>> academic
>> >> course which is simply a standalone software engineering project. I =
was
>> >> thinking that some contribution to Apache Spark would satisfy my
>> curiosity,
>> >> help continue support the company I interned at, and give me =
academic
>> >> credits required to graduate, all at the same time. It seems like =
too
>> good
>> >> an opportunity to pass up.
>> >>
>> >> With that in mind, I have the following questions:
>> >>
>> >>   1. At this point, is there any self-contained project that I could
>> work
>> >>   on within Spark=3F Ideally, I would work on it independently, in =
about a
>> >>   three month time frame. This time also needs to accommodate =
ramping
>> up on
>> >>   the Spark codebase and adjusting to the Scala programming language =
and
>> >>   paradigms. The company I worked at primarily used the Java APIs. =
The
>> output
>> >>   needs to be a technical report describing the project requirements,=

>> and the
>> >>   design process I took to engineer the solution for the requirements=
.
>> In
>> >>   particular, it cannot just be a series of haphazard patches.
>> >>   2. How can I get started with contributing to Spark=3F
>> >>   3. Is there a high-level UML or some other design specification =
for
>> the
>> >>   Spark architecture=3F
>> >>
>> >> Thanks! I hope to be of some help =3D)
>> >>
>> >> -Matt Cheah
>>
------Nodemailer-0.5.0-?=_1-1387479748640--

From dev-return-955-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 19:20:05 2013
Return-Path: <dev-return-955-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E0BE710179
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 19:20:04 +0000 (UTC)
Received: (qmail 57814 invoked by uid 500); 19 Dec 2013 19:20:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57775 invoked by uid 500); 19 Dec 2013 19:20:04 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 57767 invoked by uid 99); 19 Dec 2013 19:20:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 19:20:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.220.178] (HELO mail-vc0-f178.google.com) (209.85.220.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 19:20:00 +0000
Received: by mail-vc0-f178.google.com with SMTP id lh4so886332vcb.37
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 11:19:39 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=vPcqsO82JOME0SHaXYInv1pA9rkeEnnNlJbe8DGhWWk=;
        b=d8OqBoF8Mh7wEwjTIP2jjKc4aVca+Rwm1c6EGIRXmptnDMHheVG+EEv3tqAU62x4G1
         ixMqT6bP9GGLz1IQTumLDW2BrBPP4kIQHDmIbWkXcMqBKfg5EhzXl0bK2DKngSoaORt0
         56rihb3W40FDSDP8dCbgp4iW1AdGpI68pxKjs7/JFmltHN97SQVJFO6MQ+bPfOLnQMmf
         Cues2dIS/9c702SqhUe0CG0FX6vQ4cxnqTkIebPJaTYpdSC1ZYUsW/OwAgZ0o8oZtLqO
         Sn64nWYgChZFlLuod2CfUssH4KPDhKyfikLhky4lTGV5LU+Lm6uLvdEwkXOmc5+IR7VD
         Jigw==
X-Gm-Message-State: ALoCoQnc6Dg2YsdEU65XzSfxW7CWmYmhhV6vwXFHF4qdONYsZOAt5Q164Ua22ZlLhNAq9lFx9Ke3
X-Received: by 10.221.39.195 with SMTP id tn3mr2064198vcb.2.1387480779744;
        Thu, 19 Dec 2013 11:19:39 -0800 (PST)
Received: from mail-vb0-f46.google.com (mail-vb0-f46.google.com [209.85.212.46])
        by mx.google.com with ESMTPSA id yu18sm6059634vdb.4.2013.12.19.11.19.38
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 11:19:38 -0800 (PST)
Received: by mail-vb0-f46.google.com with SMTP id w20so862684vbb.5
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 11:19:37 -0800 (PST)
X-Received: by 10.52.50.177 with SMTP id d17mr1718009vdo.23.1387480777889;
 Thu, 19 Dec 2013 11:19:37 -0800 (PST)
MIME-Version: 1.0
Received: by 10.220.249.9 with HTTP; Thu, 19 Dec 2013 11:19:17 -0800 (PST)
In-Reply-To: <1387479748205.97d3e4de@Nodemailer>
References: <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
 <1387479748205.97d3e4de@Nodemailer>
From: Andrew Ash <andrew@andrewash.com>
Date: Thu, 19 Dec 2013 14:19:17 -0500
Message-ID: <CA+-p3AFsqtPFwZ=vhgYB_OPAHcOxBjQJ1OuQKxkpdiJLaHprmA@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0111c2dce6215c04ede80aab
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0111c2dce6215c04ede80aab
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Wow yes, that PR#230 looks like exactly what I outlined in #2!  I'll leave
some comments on there.

Anything going on for service reliability (#3) since apparently someone is
reading my mind?


On Thu, Dec 19, 2013 at 2:02 PM, Nick Pentreath <nick.pentreath@gmail.com>w=
rote:

> Some good things to look at though hopefully #2 will be largely addressed
> by: https://github.com/apache/incubator-spark/pull/230=E2=80=94
> Sent from Mailbox for iPhone
>
> On Thu, Dec 19, 2013 at 8:57 PM, Andrew Ash <andrew@andrewash.com> wrote:
>
> > I think there are also some improvements that could be made to
> > deployability in an enterprise setting.  From my experience:
> > 1. Most places I deploy Spark in don't have internet access.  So I can'=
t
> > build from source, compile against a different version of Hadoop, etc
> > without doing it locally and then getting that onto my servers manually=
.
> >  This is less a problem with Spark now that there are binary
> distributions,
> > but it's still a problem for using Mesos with Spark.
> > 2. Configuration of Spark is confusing -- you can make configuration in
> > Java system properties, environment variables, command line parameters,
> and
> > for the standalone cluster deployment mode you need to worry about
> whether
> > these need to be set on the master, the worker, the executor, or the
> > application/driver program.  Also because spark-shell automatically
> > instantiates a SparkContext you have to set up any system properties in
> the
> > init scripts or on the command line with
> > JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what need=
s to
> be
> > done, but it feels that there are gains to be made in configuration
> options
> > here.  Ideally, I would have one configuration file that can be used in
> all
> > 4 places and that's the only place to make configuration changes.
> > 3. Standalone cluster mode could use improved resiliency for starting,
> > stopping, and keeping alive a service -- there are custom init scripts
> that
> > call each other in a mess of ways: spark-shell, spark-daemon.sh,
> > spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh,
> > spark-executor, spark-class, run-example, and several others in the bin=
/
> > directory.  I would love it if Spark used the Tanuki Service Wrapper,
> which
> > is widely-used for Java service daemons, supports retries, installation
> as
> > init scripts that can be chkconfig'd, etc.  Let's not re-solve the "how
> do
> > I keep a service running?" problem when it's been done so well by Tanuk=
i
> --
> > we use it at my day job for all our services, plus it's used by
> > Elasticsearch.  This would help solve the problem where a quick bounce =
of
> > the master causes all the workers to self-destruct.
> > 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this i=
s
> > entirely an Akka bug based on previous mailing list discussion with
> Matei,
> > but it'd be awesome if you could use either the hostname or the FQDN or
> the
> > IP address in the Spark URL and not have Akka barf at you.
> > I've been telling myself I'd look into these at some point but just
> haven't
> > gotten around to them myself yet.  Some day!  I would prioritize these
> > requests from most- to least-important as 3, 2, 4, 1.
> > Andrew
> > On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
> nick.pentreath@gmail.com>wrote:
> >> Or if you're extremely ambitious work in implementing Spark Streaming =
in
> >> Python=E2=80=94
> >> Sent from Mailbox for iPhone
> >>
> >> On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <matei.zaharia@gmail.co=
m
> >
> >> wrote:
> >>
> >> > Hi Matt,
> >> > If you want to get started looking at Spark, I recommend the followi=
ng
> >> resources:
> >> > - Our issue tracker at http://spark-project.atlassian.net contains
> some
> >> issues marked =E2=80=9CStarter=E2=80=9D that are good places to jump i=
nto. You might be
> >> able to take one of those and extend it into a bigger project.
> >> > - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers how t=
o send patches and
> >> set up development:
> >> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spar=
k
> >> > - This talk has an intro to Spark internals (video and slides are in
> the
> >> comments): http://www.meetup.com/spark-users/events/94101942/
> >> > For a longer project, here are some possible ones:
> >> > - Create a tool that automatically checks which Scala API methods ar=
e
> >> missing in Python. We had a similar one for Java that was very useful.
> Even
> >> better would be to automatically create wrappers for the Scala ones.
> >> > - Extend the Spark monitoring UI with profiling information (to samp=
le
> >> the workers and say where they=E2=80=99re spending time, or what data =
structures
> >> consume the most memory).
> >> > - Pick and implement a new machine learning algorithm for MLlib.
> >> > Matei
> >> > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>
> >> wrote:
> >> >> Hi everyone,
> >> >>
> >> >> During my most recent internship, I worked extensively with Apache
> >> Spark,
> >> >> integrating it into a company's data analytics platform. I've now
> become
> >> >> interested in contributing to Apache Spark.
> >> >>
> >> >> I'm returning to undergraduate studies in January and there is an
> >> academic
> >> >> course which is simply a standalone software engineering project. I
> was
> >> >> thinking that some contribution to Apache Spark would satisfy my
> >> curiosity,
> >> >> help continue support the company I interned at, and give me academ=
ic
> >> >> credits required to graduate, all at the same time. It seems like t=
oo
> >> good
> >> >> an opportunity to pass up.
> >> >>
> >> >> With that in mind, I have the following questions:
> >> >>
> >> >>   1. At this point, is there any self-contained project that I coul=
d
> >> work
> >> >>   on within Spark? Ideally, I would work on it independently, in
> about a
> >> >>   three month time frame. This time also needs to accommodate rampi=
ng
> >> up on
> >> >>   the Spark codebase and adjusting to the Scala programming languag=
e
> and
> >> >>   paradigms. The company I worked at primarily used the Java APIs.
> The
> >> output
> >> >>   needs to be a technical report describing the project requirement=
s,
> >> and the
> >> >>   design process I took to engineer the solution for the
> requirements.
> >> In
> >> >>   particular, it cannot just be a series of haphazard patches.
> >> >>   2. How can I get started with contributing to Spark?
> >> >>   3. Is there a high-level UML or some other design specification f=
or
> >> the
> >> >>   Spark architecture?
> >> >>
> >> >> Thanks! I hope to be of some help =3D)
> >> >>
> >> >> -Matt Cheah
> >>
>

--089e0111c2dce6215c04ede80aab--

From dev-return-956-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 20:53:23 2013
Return-Path: <dev-return-956-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2BF3D10586
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 20:53:23 +0000 (UTC)
Received: (qmail 50410 invoked by uid 500); 19 Dec 2013 20:53:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50337 invoked by uid 500); 19 Dec 2013 20:53:22 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50329 invoked by uid 99); 19 Dec 2013 20:53:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 20:53:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ctn@adatao.com designates 209.85.213.169 as permitted sender)
Received: from [209.85.213.169] (HELO mail-ig0-f169.google.com) (209.85.213.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 20:53:19 +0000
Received: by mail-ig0-f169.google.com with SMTP id hk11so13021936igb.0
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 12:52:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=UOpd61WxXHXZSgB3e3FBT08as26MgJCHiVA8GMLJvPA=;
        b=LH7Z2jUleOHXFUzy2mRk8lccV2KhpOG3xatvxHKcQxIEu5+mkmGGMnS1CtCd0/L7YW
         b/vOOzHSglkVC0D5XhZLCyrEjx2t+VK5/HXDGOjUjVoHHB4N4UVHmimhuNYQizMvVUr5
         aiMst1VYP5s75k10aRJ6Tjajy6qkX2ItKMIa4=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=UOpd61WxXHXZSgB3e3FBT08as26MgJCHiVA8GMLJvPA=;
        b=mJgPwqkrnxRAGwV7U7y4/9oL/k9NRR/ewF/XniQ3i1alJ7dj10b9xcCKV6WzFeRpwu
         QGjCoYGsrltl2fDsknnA1mGNQDGaGbw/4IvJrFSeH9mYb2iY12d0DiJiOadRMnCa6sC0
         Sjj3CaevJAXujlXfWoZ3tERoRfbYqYram2w3ditQsUEUAE/oB7Q/OPt0k6Jv5vzZ2muw
         P7K0VSdgXFMD4xnxCNaCrXwA8TZokcDx+Lioe+z5empCqZeKpLcA+gQQBYBlG370Vgjx
         wlhPfvtM8xmNAR/9u0zGMdE4xXAxjJLjhEVaUwEDXSJxg+m6TIAhKs9osWAcfpVswJm9
         XTHQ==
X-Gm-Message-State: ALoCoQlTi0V0Dw/eX8sqlxqPCydAkedDVfmzaEF0GiYkdpKPr7/QqSpHnf8ku62ZSaU3FjCitCuU
X-Received: by 10.50.143.10 with SMTP id sa10mr4265559igb.8.1387486377101;
 Thu, 19 Dec 2013 12:52:57 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.20.78 with HTTP; Thu, 19 Dec 2013 12:52:36 -0800 (PST)
X-Originating-IP: [67.188.95.187]
In-Reply-To: <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
 <1387478305969.35e7931@Nodemailer> <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
From: Christopher Nguyen <ctn@adatao.com>
Date: Thu, 19 Dec 2013 12:52:36 -0800
Message-ID: <CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1135fe9aa365aa04ede9584b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fe9aa365aa04ede9584b
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

+1 to most of Andrew's suggestions here, and while we're in that
neighborhood, how about generalizing something like "wtf-spark" (from the
Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of high
academic interest, but it's something people would use many times a
debugging day.

Or am I behind and something like that is already there in 0.8?

--
Christopher T. Nguyen
Co-founder & CEO, Adatao <http://adatao.com>
linkedin.com/in/ctnguyen



On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com> wrote:

> I think there are also some improvements that could be made to
> deployability in an enterprise setting.  From my experience:
>
> 1. Most places I deploy Spark in don't have internet access.  So I can't
> build from source, compile against a different version of Hadoop, etc
> without doing it locally and then getting that onto my servers manually.
>  This is less a problem with Spark now that there are binary distribution=
s,
> but it's still a problem for using Mesos with Spark.
> 2. Configuration of Spark is confusing -- you can make configuration in
> Java system properties, environment variables, command line parameters, a=
nd
> for the standalone cluster deployment mode you need to worry about whethe=
r
> these need to be set on the master, the worker, the executor, or the
> application/driver program.  Also because spark-shell automatically
> instantiates a SparkContext you have to set up any system properties in t=
he
> init scripts or on the command line with
> JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what needs =
to be
> done, but it feels that there are gains to be made in configuration optio=
ns
> here.  Ideally, I would have one configuration file that can be used in a=
ll
> 4 places and that's the only place to make configuration changes.
> 3. Standalone cluster mode could use improved resiliency for starting,
> stopping, and keeping alive a service -- there are custom init scripts th=
at
> call each other in a mess of ways: spark-shell, spark-daemon.sh,
> spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh,
> spark-executor, spark-class, run-example, and several others in the bin/
> directory.  I would love it if Spark used the Tanuki Service Wrapper, whi=
ch
> is widely-used for Java service daemons, supports retries, installation a=
s
> init scripts that can be chkconfig'd, etc.  Let's not re-solve the "how d=
o
> I keep a service running?" problem when it's been done so well by Tanuki =
--
> we use it at my day job for all our services, plus it's used by
> Elasticsearch.  This would help solve the problem where a quick bounce of
> the master causes all the workers to self-destruct.
> 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this is
> entirely an Akka bug based on previous mailing list discussion with Matei=
,
> but it'd be awesome if you could use either the hostname or the FQDN or t=
he
> IP address in the Spark URL and not have Akka barf at you.
>
> I've been telling myself I'd look into these at some point but just haven=
't
> gotten around to them myself yet.  Some day!  I would prioritize these
> requests from most- to least-important as 3, 2, 4, 1.
>
> Andrew
>
>
> On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <nick.pentreath@gmail.com
> >wrote:
>
> > Or if you're extremely ambitious work in implementing Spark Streaming i=
n
> > Python=97
> > Sent from Mailbox for iPhone
> >
> > On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <matei.zaharia@gmail.com=
>
> > wrote:
> >
> > > Hi Matt,
> > > If you want to get started looking at Spark, I recommend the followin=
g
> > resources:
> > > - Our issue tracker at http://spark-project.atlassian.net contains
> some
> > issues marked =93Starter=94 that are good places to jump into. You migh=
t be
> > able to take one of those and extend it into a bigger project.
> > > - The =93contributing to Spark=94 wiki page covers how to send patche=
s and
> > set up development:
> > https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
> > > - This talk has an intro to Spark internals (video and slides are in
> the
> > comments): http://www.meetup.com/spark-users/events/94101942/
> > > For a longer project, here are some possible ones:
> > > - Create a tool that automatically checks which Scala API methods are
> > missing in Python. We had a similar one for Java that was very useful.
> Even
> > better would be to automatically create wrappers for the Scala ones.
> > > - Extend the Spark monitoring UI with profiling information (to sampl=
e
> > the workers and say where they=92re spending time, or what data structu=
res
> > consume the most memory).
> > > - Pick and implement a new machine learning algorithm for MLlib.
> > > Matei
> > > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>
> > wrote:
> > >> Hi everyone,
> > >>
> > >> During my most recent internship, I worked extensively with Apache
> > Spark,
> > >> integrating it into a company's data analytics platform. I've now
> become
> > >> interested in contributing to Apache Spark.
> > >>
> > >> I'm returning to undergraduate studies in January and there is an
> > academic
> > >> course which is simply a standalone software engineering project. I
> was
> > >> thinking that some contribution to Apache Spark would satisfy my
> > curiosity,
> > >> help continue support the company I interned at, and give me academi=
c
> > >> credits required to graduate, all at the same time. It seems like to=
o
> > good
> > >> an opportunity to pass up.
> > >>
> > >> With that in mind, I have the following questions:
> > >>
> > >>   1. At this point, is there any self-contained project that I could
> > work
> > >>   on within Spark? Ideally, I would work on it independently, in
> about a
> > >>   three month time frame. This time also needs to accommodate rampin=
g
> > up on
> > >>   the Spark codebase and adjusting to the Scala programming language
> and
> > >>   paradigms. The company I worked at primarily used the Java APIs. T=
he
> > output
> > >>   needs to be a technical report describing the project requirements=
,
> > and the
> > >>   design process I took to engineer the solution for the requirement=
s.
> > In
> > >>   particular, it cannot just be a series of haphazard patches.
> > >>   2. How can I get started with contributing to Spark?
> > >>   3. Is there a high-level UML or some other design specification fo=
r
> > the
> > >>   Spark architecture?
> > >>
> > >> Thanks! I hope to be of some help =3D)
> > >>
> > >> -Matt Cheah
> >
>

--001a1135fe9aa365aa04ede9584b--

From dev-return-957-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 21:39:06 2013
Return-Path: <dev-return-957-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9C7CB106F6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 21:39:06 +0000 (UTC)
Received: (qmail 27011 invoked by uid 500); 19 Dec 2013 21:39:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26975 invoked by uid 500); 19 Dec 2013 21:39:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 57629 invoked by uid 99); 19 Dec 2013 20:58:58 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of conexiongill@gmail.com designates 209.85.216.170 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=sf1BFCaSlkQzRbqzBGmWWQlVlcx8Rwxd43x3XE2Cp9A=;
        b=VjBw5DPa9Ci6ZbnB2EDor5DhauqlIuy6d0PW12uYGMgPtoi/yosE7OsbOj3r5v9qmf
         J1f42i7imNNfSAt2tbDaz9cFQz2iB2sRTo31P1FS3DHVPQuvzxaJb+kFuSD+kLxI3Gns
         BCmmm6bxa7VUA3OvI32JACs+XG1wbxUfNNRaI/DaGhjcq14HMUAbRWJydcD6EechuGhj
         LjqApqRRKiqInd2SOdtGFgYXAFzAIFKes0/2/yogO1C7fJD0pwx8j/UnXphtAfz/DhQT
         8v7oRV0xePPFKlayFqywqIz1NKFjNiynn+Og6XmzTYEaT5dVuZH7pFpieOFtcfRzna8O
         w3mg==
MIME-Version: 1.0
X-Received: by 10.224.151.212 with SMTP id d20mr7048067qaw.87.1387486711145;
 Thu, 19 Dec 2013 12:58:31 -0800 (PST)
Date: Thu, 19 Dec 2013 12:58:31 -0800
Message-ID: <CAEVroHHyWjVTAsJwEtpdwYJSxqueW_qwonSmuvPJ9FHS2dsmZA@mail.gmail.com>
Subject: How to contribute to the spark project
From: Gill <conexiongill@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0149cac28c673e04ede96cfb
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149cac28c673e04ede96cfb
Content-Type: text/plain; charset=ISO-8859-1

Hi,

I attended the spark summit and have been curios to know that how can I
contribute to the spark project. I'm working on query engine optimizations
so can help with spark query engine optimizations or with other query
engine features.

Thanks
Gurbir
510 410 5108

--089e0149cac28c673e04ede96cfb--

From dev-return-958-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 19 23:25:50 2013
Return-Path: <dev-return-958-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A1890109ED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Dec 2013 23:25:50 +0000 (UTC)
Received: (qmail 73207 invoked by uid 500); 19 Dec 2013 23:25:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73107 invoked by uid 500); 19 Dec 2013 23:25:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 73099 invoked by uid 99); 19 Dec 2013 23:25:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 23:25:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of azuryyyu@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Dec 2013 23:25:45 +0000
Received: by mail-ig0-f180.google.com with SMTP id uq1so5451740igb.1
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 15:25:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=6ZcPvqfuyq6MXw1Mgh58jrfKyqJQS7x8RaOIgQR0sok=;
        b=eL6SkQa88lawVcoltT1eP0dn1yI2b8bKTGuK7RcOAVn9HTHmneOS6dfrQxy+zsQro1
         qI5pRVsys0w4A43mgiiLnXMjEVWLzbQv7razhR+UkY/S7HVjlCgUnIAQ7hJmRQWTiJaL
         jRi9bxu6owvlt6SwyhQJp49NEflaMUZWUxpvoRUvwCYlvYPj30IGCz/7sot/A9Hq+Emn
         dcRQA7s1aJlJwwqPaI4H87kRCImJj2493Ez9ES6KERN3KRd8LubZWo6/+AtQFRaz7Gx9
         YHrqo2uWdNfuELM8TOEiIC9Cc121x4TXaAN2UXQyQns7xQNLow4a30t4gnRhet3M+3Tr
         K2hw==
MIME-Version: 1.0
X-Received: by 10.50.141.133 with SMTP id ro5mr4684448igb.35.1387495524562;
 Thu, 19 Dec 2013 15:25:24 -0800 (PST)
Received: by 10.64.251.8 with HTTP; Thu, 19 Dec 2013 15:25:24 -0800 (PST)
Received: by 10.64.251.8 with HTTP; Thu, 19 Dec 2013 15:25:24 -0800 (PST)
In-Reply-To: <CAEVroHHyWjVTAsJwEtpdwYJSxqueW_qwonSmuvPJ9FHS2dsmZA@mail.gmail.com>
References: <CAEVroHHyWjVTAsJwEtpdwYJSxqueW_qwonSmuvPJ9FHS2dsmZA@mail.gmail.com>
Date: Fri, 20 Dec 2013 07:25:24 +0800
Message-ID: <CALr1C9rg_WSmQe_TkBNrgcJQoKnkea+doPxwhutGx+HRo2x3Hg@mail.gmail.com>
Subject: Re: How to contribute to the spark project
From: Azuryy Yu <azuryyyu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0122f6aede90e904edeb7962
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122f6aede90e904edeb7962
Content-Type: text/plain; charset=ISO-8859-1

Hi Gill,
please read here:

https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
 On Dec 20, 2013 5:39 AM, "Gill" <conexiongill@gmail.com> wrote:

> Hi,
>
> I attended the spark summit and have been curios to know that how can I
> contribute to the spark project. I'm working on query engine optimizations
> so can help with spark query engine optimizations or with other query
> engine features.
>
> Thanks
> Gurbir
> 510 410 5108
>

--089e0122f6aede90e904edeb7962--

From dev-return-959-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 01:16:04 2013
Return-Path: <dev-return-959-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8AFD010D29
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 01:16:04 +0000 (UTC)
Received: (qmail 36332 invoked by uid 500); 20 Dec 2013 01:16:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36287 invoked by uid 500); 20 Dec 2013 01:16:04 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 36272 invoked by uid 99); 20 Dec 2013 01:16:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:16:04 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.44 as permitted sender)
Received: from [209.85.219.44] (HELO mail-oa0-f44.google.com) (209.85.219.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:15:59 +0000
Received: by mail-oa0-f44.google.com with SMTP id m1so2142574oag.17
        for <multiple recipients>; Thu, 19 Dec 2013 17:15:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=g3yyKNTRnkfvFL1zYZU/6MRLZ++KDgvGT7nSHl4tXqc=;
        b=dhxP+tasiMGgxaaxHFFwO2mH2qEPij3TpRYpGdzA2e/vGlJxxiHHmqwZS82KvCQG0t
         nUP7fO3mN3jkhFqVYmvF+V4TsEJvh72MMWWcBosWMU0JsrAAMmQX9shESDSoGsXAtMWP
         UDwF6w1JKzhr+cMJPuhzK9KR3vQJ4FhLBubLjBdBp3p2m6erZwilC9oo41hWuuILpS4A
         EATWEsh/d78aebLEPjhsM2xQPPshYVap4bEiBvXkbpLZ8XaRsAw/dDg0sDgtpCxlst90
         sHDhywd8NQQb5hTlrAMmcxLkYQL8hPCVcYKnXeIMw3pNowXL/X6A/89vG9TuIZ4Qsnji
         nxbg==
MIME-Version: 1.0
X-Received: by 10.182.19.132 with SMTP id f4mr3940607obe.14.1387502138325;
 Thu, 19 Dec 2013 17:15:38 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Thu, 19 Dec 2013 17:15:38 -0800 (PST)
Date: Thu, 19 Dec 2013 17:15:38 -0800
Message-ID: <CABPQxsuzAV5hdDQYjgfgSVF=j=7vDO=N=UshGj+6HCZuRvuNGQ@mail.gmail.com>
Subject: Spark 0.8.1 Released
From: Patrick Wendell <pwendell@gmail.com>
To: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hi everyone,

We've just posted Spark 0.8.1, a new maintenance release that contains
some bug fixes and improvements to the 0.8 branch. The full release
notes are available at [1]. Apart from various bug fixes, 0.8.1
includes support for YARN 2.2, a high availability mode for the
standalone scheduler, and optimizations to the shuffle. We recommend
that current users update to this release. You can grab the release at
[2].

[1] http://spark.incubator.apache.org/releases/spark-release-0-8-1.html
[2] http://spark.incubator.apache.org/downloads

Thanks to the following people who contributed to this release:

Michael Armbrust, Pierre Borckmans, Evan Chan, Ewen Cheslack, Mosharaf
Chowdhury, Frank Dai, Aaron Davidson, Tathagata Das, Ankur Dave,
Harvey Feng, Ali Ghodsi, Thomas Graves, Li Guoqiang, Stephen Haberman,
Haidar Hadi, Nathan Howell, Holden Karau, Du Li, Raymond Liu, Xi Liu,
David McCauley, Michael (wannabeast), Fabrizio Milo, Mridul
Muralidharan, Sundeep Narravula, Kay Ousterhout, Nick Pentreath, Imran
Rashid, Ahir Reddy, Josh Rosen, Henry Saputra, Jerry Shao, Mingfei
Shi, Andre Schumacher, Karthik Tunga, Patrick Wendell, Neal Wiggins,
Andrew Xia, Reynold Xin, Matei Zaharia, and Wu Zeming

- Patrick

From dev-return-960-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 01:27:33 2013
Return-Path: <dev-return-960-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E0FB110D7D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 01:27:33 +0000 (UTC)
Received: (qmail 54479 invoked by uid 500); 20 Dec 2013 01:27:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54434 invoked by uid 500); 20 Dec 2013 01:27:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 54426 invoked by uid 99); 20 Dec 2013 01:27:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:27:33 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mccheah@uwaterloo.ca designates 129.97.128.141 as permitted sender)
Received: from [129.97.128.141] (HELO mailchk-m02.uwaterloo.ca) (129.97.128.141)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:27:27 +0000
Received: from mail-ie0-f171.google.com (mail-ie0-f171.google.com [209.85.223.171])
	(authenticated bits=0)
	by mailchk-m02.uwaterloo.ca (8.14.4/8.14.4) with ESMTP id rBK1R3aN006570
	(version=TLSv1/SSLv3 cipher=RC4-SHA bits=128 verify=OK)
	for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 20:27:04 -0500
Received: by mail-ie0-f171.google.com with SMTP id ar20so2410421iec.2
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 17:27:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=Ly129aYl5FccGC9qvDE2QXgM1csBdOWkgKNqSJW/lFs=;
        b=j5sA2hSAWQuCGei3jcm5HnOo6/7DTaKWOaR/AzWN8lvi77ejw+7raCUkgQy3YU18f5
         52Uqtr8JeVd3ZcPcV7ch5Hs5hCa+WmnOwqF8E/+hF5/mnfDF+PrxdNHhKfeFjb/vMOQR
         bJB131wj+JcGfp79YghFrFd7D0cfzjqBJ05Kl7s82vcbMbHnPQJUet6eZE7m+xbKwEgW
         M/eOi9vbZzy6gfsyjc5fLas8kw4jIVbcA+88Iz5wnx82yRRJ4ynQgs690+bxLJf7toYS
         cf182Q88eQUKZ4VnF8Qiv1LAW6UsfUC+XvfgFavWibEYagnMCuCbtHkyqIdqs8LIHk+l
         fv2Q==
MIME-Version: 1.0
X-Received: by 10.42.177.10 with SMTP id bg10mr3597130icb.18.1387502823417;
 Thu, 19 Dec 2013 17:27:03 -0800 (PST)
Received: by 10.64.231.3 with HTTP; Thu, 19 Dec 2013 17:27:03 -0800 (PST)
In-Reply-To: <CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
	<1387478305969.35e7931@Nodemailer>
	<CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
	<CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com>
Date: Thu, 19 Dec 2013 17:27:03 -0800
Message-ID: <CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
From: Matthew Cheah <mccheah@uwaterloo.ca>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=90e6ba6e89a2ea312a04eded2c5b
X-UUID: c1f28508-542f-41ba-a6a2-5cb3bdd02346
X-Miltered: at mailchk-m02 with ID 52B39CE7.001 by Joe's j-chkmail (http://j-chkmail.ensmp.fr)!
X-Virus-Scanned: clamav-milter 0.98 at mailchk-m02
X-Virus-Status: Clean
X-Greylist: Sender succeeded SMTP AUTH, not delayed by milter-greylist-4.4.3 (mailchk-m02.uwaterloo.ca [129.97.128.141]); Thu, 19 Dec 2013 20:27:04 -0500 (EST)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	mailchk-r02.uwaterloo.ca
X-Virus-Checked: Checked by ClamAV on apache.org
X-Old-Spam-Status: No, score=-7.0 required=5.0 tests=ALL_TRUSTED,HTML_MESSAGE
	autolearn=disabled version=3.3.1

--90e6ba6e89a2ea312a04eded2c5b
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Thanks a lot everyone! I'm looking into adding an algorithm to MLib for the
project. Nice and self-contained.

-Matt Cheah


On Thu, Dec 19, 2013 at 12:52 PM, Christopher Nguyen <ctn@adatao.com> wrote=
:

> +1 to most of Andrew's suggestions here, and while we're in that
> neighborhood, how about generalizing something like "wtf-spark" (from the
> Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of high
> academic interest, but it's something people would use many times a
> debugging day.
>
> Or am I behind and something like that is already there in 0.8?
>
> --
> Christopher T. Nguyen
> Co-founder & CEO, Adatao <http://adatao.com>
> linkedin.com/in/ctnguyen
>
>
>
> On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com> wrote=
:
>
> > I think there are also some improvements that could be made to
> > deployability in an enterprise setting.  From my experience:
> >
> > 1. Most places I deploy Spark in don't have internet access.  So I can'=
t
> > build from source, compile against a different version of Hadoop, etc
> > without doing it locally and then getting that onto my servers manually=
.
> >  This is less a problem with Spark now that there are binary
> distributions,
> > but it's still a problem for using Mesos with Spark.
> > 2. Configuration of Spark is confusing -- you can make configuration in
> > Java system properties, environment variables, command line parameters,
> and
> > for the standalone cluster deployment mode you need to worry about
> whether
> > these need to be set on the master, the worker, the executor, or the
> > application/driver program.  Also because spark-shell automatically
> > instantiates a SparkContext you have to set up any system properties in
> the
> > init scripts or on the command line with
> > JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what need=
s to
> be
> > done, but it feels that there are gains to be made in configuration
> options
> > here.  Ideally, I would have one configuration file that can be used in
> all
> > 4 places and that's the only place to make configuration changes.
> > 3. Standalone cluster mode could use improved resiliency for starting,
> > stopping, and keeping alive a service -- there are custom init scripts
> that
> > call each other in a mess of ways: spark-shell, spark-daemon.sh,
> > spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh,
> > spark-executor, spark-class, run-example, and several others in the bin=
/
> > directory.  I would love it if Spark used the Tanuki Service Wrapper,
> which
> > is widely-used for Java service daemons, supports retries, installation
> as
> > init scripts that can be chkconfig'd, etc.  Let's not re-solve the "how
> do
> > I keep a service running?" problem when it's been done so well by Tanuk=
i
> --
> > we use it at my day job for all our services, plus it's used by
> > Elasticsearch.  This would help solve the problem where a quick bounce =
of
> > the master causes all the workers to self-destruct.
> > 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this i=
s
> > entirely an Akka bug based on previous mailing list discussion with
> Matei,
> > but it'd be awesome if you could use either the hostname or the FQDN or
> the
> > IP address in the Spark URL and not have Akka barf at you.
> >
> > I've been telling myself I'd look into these at some point but just
> haven't
> > gotten around to them myself yet.  Some day!  I would prioritize these
> > requests from most- to least-important as 3, 2, 4, 1.
> >
> > Andrew
> >
> >
> > On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
> nick.pentreath@gmail.com
> > >wrote:
> >
> > > Or if you're extremely ambitious work in implementing Spark Streaming
> in
> > > Python=97
> > > Sent from Mailbox for iPhone
> > >
> > > On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <
> matei.zaharia@gmail.com>
> > > wrote:
> > >
> > > > Hi Matt,
> > > > If you want to get started looking at Spark, I recommend the
> following
> > > resources:
> > > > - Our issue tracker at http://spark-project.atlassian.net contains
> > some
> > > issues marked =93Starter=94 that are good places to jump into. You mi=
ght be
> > > able to take one of those and extend it into a bigger project.
> > > > - The =93contributing to Spark=94 wiki page covers how to send patc=
hes
> and
> > > set up development:
> > >
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
> > > > - This talk has an intro to Spark internals (video and slides are i=
n
> > the
> > > comments): http://www.meetup.com/spark-users/events/94101942/
> > > > For a longer project, here are some possible ones:
> > > > - Create a tool that automatically checks which Scala API methods a=
re
> > > missing in Python. We had a similar one for Java that was very useful=
.
> > Even
> > > better would be to automatically create wrappers for the Scala ones.
> > > > - Extend the Spark monitoring UI with profiling information (to
> sample
> > > the workers and say where they=92re spending time, or what data
> structures
> > > consume the most memory).
> > > > - Pick and implement a new machine learning algorithm for MLlib.
> > > > Matei
> > > > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca>
> > > wrote:
> > > >> Hi everyone,
> > > >>
> > > >> During my most recent internship, I worked extensively with Apache
> > > Spark,
> > > >> integrating it into a company's data analytics platform. I've now
> > become
> > > >> interested in contributing to Apache Spark.
> > > >>
> > > >> I'm returning to undergraduate studies in January and there is an
> > > academic
> > > >> course which is simply a standalone software engineering project. =
I
> > was
> > > >> thinking that some contribution to Apache Spark would satisfy my
> > > curiosity,
> > > >> help continue support the company I interned at, and give me
> academic
> > > >> credits required to graduate, all at the same time. It seems like
> too
> > > good
> > > >> an opportunity to pass up.
> > > >>
> > > >> With that in mind, I have the following questions:
> > > >>
> > > >>   1. At this point, is there any self-contained project that I cou=
ld
> > > work
> > > >>   on within Spark? Ideally, I would work on it independently, in
> > about a
> > > >>   three month time frame. This time also needs to accommodate
> ramping
> > > up on
> > > >>   the Spark codebase and adjusting to the Scala programming langua=
ge
> > and
> > > >>   paradigms. The company I worked at primarily used the Java APIs.
> The
> > > output
> > > >>   needs to be a technical report describing the project
> requirements,
> > > and the
> > > >>   design process I took to engineer the solution for the
> requirements.
> > > In
> > > >>   particular, it cannot just be a series of haphazard patches.
> > > >>   2. How can I get started with contributing to Spark?
> > > >>   3. Is there a high-level UML or some other design specification
> for
> > > the
> > > >>   Spark architecture?
> > > >>
> > > >> Thanks! I hope to be of some help =3D)
> > > >>
> > > >> -Matt Cheah
> > >
> >
>

--90e6ba6e89a2ea312a04eded2c5b--

From dev-return-961-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 01:34:32 2013
Return-Path: <dev-return-961-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EACDA10DA7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 01:34:32 +0000 (UTC)
Received: (qmail 60336 invoked by uid 500); 20 Dec 2013 01:34:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60305 invoked by uid 500); 20 Dec 2013 01:34:32 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 60297 invoked by uid 99); 20 Dec 2013 01:34:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:34:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.212.47] (HELO mail-vb0-f47.google.com) (209.85.212.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:34:28 +0000
Received: by mail-vb0-f47.google.com with SMTP id q12so1108221vbe.34
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 17:34:08 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=pAE6YyvDGcBupa8xQdat1AJQ7fCADAZ+yiOr2pCVMfM=;
        b=lGy1Jmm9rohYnaT8pSkYMZtA5EGA5xCmwegONeUIszGSIm5Mo531au9q2fO2V5prN3
         60WVrI9SlCq3HdzEc/Ez8dLbsbRhBCM6GaaewYK8fpWaDg/r70aQhZdDF2VMit00uzy4
         HMXghFtg6cCAZgNsRJeavN1rGUrNphfuCSMcuSZwOlkDKByqhtf6weHPYfZRk6H6l+5m
         A3tqbqecXU6cu9hkUMSFeTWnD2YFjDUhWmrGyUkyC6ycme8WaoVMrq39XfhePPCxvVCh
         y6YeFitAlRwJfXkLK/q8ClY9DEONgUytOM3CLKhRilBLC5tEvxZIk3KD6hs/AuKAiMAF
         3C7A==
X-Gm-Message-State: ALoCoQkeH1130A4fYKDswBNzG/YfRA9WRigcAuv5rSjXiNwHZkqqXTMk9MGCQqr8u4bRQDkpRSKB
X-Received: by 10.58.254.200 with SMTP id ak8mr3386571ved.12.1387503247872;
        Thu, 19 Dec 2013 17:34:07 -0800 (PST)
Received: from mail-vb0-f53.google.com (mail-vb0-f53.google.com [209.85.212.53])
        by mx.google.com with ESMTPSA id jw6sm4038889veb.3.2013.12.19.17.34.06
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 17:34:06 -0800 (PST)
Received: by mail-vb0-f53.google.com with SMTP id o19so1050883vbm.26
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 17:34:06 -0800 (PST)
X-Received: by 10.58.208.130 with SMTP id me2mr3538225vec.13.1387503245990;
 Thu, 19 Dec 2013 17:34:05 -0800 (PST)
MIME-Version: 1.0
Received: by 10.220.249.9 with HTTP; Thu, 19 Dec 2013 17:33:45 -0800 (PST)
In-Reply-To: <CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
 <1387478305969.35e7931@Nodemailer> <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
 <CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com> <CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Thu, 19 Dec 2013 20:33:45 -0500
Message-ID: <CA+-p3AG00DDCCgkjdoW4m2g+vkbktwcfDa_p0C8Akcnr1ef_nA@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bdc192c1a24c604eded46ec
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc192c1a24c604eded46ec
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Sounds like a great choice.  It would be particularly impressive if you
could add the first online learning algorithm (all the current ones are
offline I believe) to pave the way for future contributions.


On Thu, Dec 19, 2013 at 8:27 PM, Matthew Cheah <mccheah@uwaterloo.ca> wrote=
:

> Thanks a lot everyone! I'm looking into adding an algorithm to MLib for t=
he
> project. Nice and self-contained.
>
> -Matt Cheah
>
>
> On Thu, Dec 19, 2013 at 12:52 PM, Christopher Nguyen <ctn@adatao.com>
> wrote:
>
> > +1 to most of Andrew's suggestions here, and while we're in that
> > neighborhood, how about generalizing something like "wtf-spark" (from t=
he
> > Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of hi=
gh
> > academic interest, but it's something people would use many times a
> > debugging day.
> >
> > Or am I behind and something like that is already there in 0.8?
> >
> > --
> > Christopher T. Nguyen
> > Co-founder & CEO, Adatao <http://adatao.com>
> > linkedin.com/in/ctnguyen
> >
> >
> >
> > On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com>
> wrote:
> >
> > > I think there are also some improvements that could be made to
> > > deployability in an enterprise setting.  From my experience:
> > >
> > > 1. Most places I deploy Spark in don't have internet access.  So I
> can't
> > > build from source, compile against a different version of Hadoop, etc
> > > without doing it locally and then getting that onto my servers
> manually.
> > >  This is less a problem with Spark now that there are binary
> > distributions,
> > > but it's still a problem for using Mesos with Spark.
> > > 2. Configuration of Spark is confusing -- you can make configuration =
in
> > > Java system properties, environment variables, command line parameter=
s,
> > and
> > > for the standalone cluster deployment mode you need to worry about
> > whether
> > > these need to be set on the master, the worker, the executor, or the
> > > application/driver program.  Also because spark-shell automatically
> > > instantiates a SparkContext you have to set up any system properties =
in
> > the
> > > init scripts or on the command line with
> > > JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what ne=
eds to
> > be
> > > done, but it feels that there are gains to be made in configuration
> > options
> > > here.  Ideally, I would have one configuration file that can be used =
in
> > all
> > > 4 places and that's the only place to make configuration changes.
> > > 3. Standalone cluster mode could use improved resiliency for starting=
,
> > > stopping, and keeping alive a service -- there are custom init script=
s
> > that
> > > call each other in a mess of ways: spark-shell, spark-daemon.sh,
> > > spark-daemons.sh, spark-config.sh, spark-env.sh, compute-classpath.sh=
,
> > > spark-executor, spark-class, run-example, and several others in the
> bin/
> > > directory.  I would love it if Spark used the Tanuki Service Wrapper,
> > which
> > > is widely-used for Java service daemons, supports retries, installati=
on
> > as
> > > init scripts that can be chkconfig'd, etc.  Let's not re-solve the "h=
ow
> > do
> > > I keep a service running?" problem when it's been done so well by
> Tanuki
> > --
> > > we use it at my day job for all our services, plus it's used by
> > > Elasticsearch.  This would help solve the problem where a quick bounc=
e
> of
> > > the master causes all the workers to self-destruct.
> > > 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this
> is
> > > entirely an Akka bug based on previous mailing list discussion with
> > Matei,
> > > but it'd be awesome if you could use either the hostname or the FQDN =
or
> > the
> > > IP address in the Spark URL and not have Akka barf at you.
> > >
> > > I've been telling myself I'd look into these at some point but just
> > haven't
> > > gotten around to them myself yet.  Some day!  I would prioritize thes=
e
> > > requests from most- to least-important as 3, 2, 4, 1.
> > >
> > > Andrew
> > >
> > >
> > > On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
> > nick.pentreath@gmail.com
> > > >wrote:
> > >
> > > > Or if you're extremely ambitious work in implementing Spark Streami=
ng
> > in
> > > > Python=E2=80=94
> > > > Sent from Mailbox for iPhone
> > > >
> > > > On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <
> > matei.zaharia@gmail.com>
> > > > wrote:
> > > >
> > > > > Hi Matt,
> > > > > If you want to get started looking at Spark, I recommend the
> > following
> > > > resources:
> > > > > - Our issue tracker at http://spark-project.atlassian.net contain=
s
> > > some
> > > > issues marked =E2=80=9CStarter=E2=80=9D that are good places to jum=
p into. You might
> be
> > > > able to take one of those and extend it into a bigger project.
> > > > > - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers ho=
w to send patches
> > and
> > > > set up development:
> > > >
> > https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
> > > > > - This talk has an intro to Spark internals (video and slides are
> in
> > > the
> > > > comments): http://www.meetup.com/spark-users/events/94101942/
> > > > > For a longer project, here are some possible ones:
> > > > > - Create a tool that automatically checks which Scala API methods
> are
> > > > missing in Python. We had a similar one for Java that was very
> useful.
> > > Even
> > > > better would be to automatically create wrappers for the Scala ones=
.
> > > > > - Extend the Spark monitoring UI with profiling information (to
> > sample
> > > > the workers and say where they=E2=80=99re spending time, or what da=
ta
> > structures
> > > > consume the most memory).
> > > > > - Pick and implement a new machine learning algorithm for MLlib.
> > > > > Matei
> > > > > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <mccheah@uwaterloo.ca=
>
> > > > wrote:
> > > > >> Hi everyone,
> > > > >>
> > > > >> During my most recent internship, I worked extensively with Apac=
he
> > > > Spark,
> > > > >> integrating it into a company's data analytics platform. I've no=
w
> > > become
> > > > >> interested in contributing to Apache Spark.
> > > > >>
> > > > >> I'm returning to undergraduate studies in January and there is a=
n
> > > > academic
> > > > >> course which is simply a standalone software engineering project=
.
> I
> > > was
> > > > >> thinking that some contribution to Apache Spark would satisfy my
> > > > curiosity,
> > > > >> help continue support the company I interned at, and give me
> > academic
> > > > >> credits required to graduate, all at the same time. It seems lik=
e
> > too
> > > > good
> > > > >> an opportunity to pass up.
> > > > >>
> > > > >> With that in mind, I have the following questions:
> > > > >>
> > > > >>   1. At this point, is there any self-contained project that I
> could
> > > > work
> > > > >>   on within Spark? Ideally, I would work on it independently, in
> > > about a
> > > > >>   three month time frame. This time also needs to accommodate
> > ramping
> > > > up on
> > > > >>   the Spark codebase and adjusting to the Scala programming
> language
> > > and
> > > > >>   paradigms. The company I worked at primarily used the Java API=
s.
> > The
> > > > output
> > > > >>   needs to be a technical report describing the project
> > requirements,
> > > > and the
> > > > >>   design process I took to engineer the solution for the
> > requirements.
> > > > In
> > > > >>   particular, it cannot just be a series of haphazard patches.
> > > > >>   2. How can I get started with contributing to Spark?
> > > > >>   3. Is there a high-level UML or some other design specificatio=
n
> > for
> > > > the
> > > > >>   Spark architecture?
> > > > >>
> > > > >> Thanks! I hope to be of some help =3D)
> > > > >>
> > > > >> -Matt Cheah
> > > >
> > >
> >
>

--047d7bdc192c1a24c604eded46ec--

From dev-return-962-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 01:47:06 2013
Return-Path: <dev-return-962-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7183C10DE4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 01:47:06 +0000 (UTC)
Received: (qmail 71242 invoked by uid 500); 20 Dec 2013 01:47:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71130 invoked by uid 500); 20 Dec 2013 01:47:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 71121 invoked by uid 99); 20 Dec 2013 01:47:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:47:05 +0000
X-ASF-Spam-Status: No, hits=2.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.128.171 as permitted sender)
Received: from [209.85.128.171] (HELO mail-ve0-f171.google.com) (209.85.128.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 01:47:00 +0000
Received: by mail-ve0-f171.google.com with SMTP id pa12so1168238veb.16
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 17:46:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=HjjoSMJBF4OLK3R2yROFkNRUf4wCdkhzfTQf4ITukPA=;
        b=zBvu+CV2I82zFQr8uzidjOvY2Qssl4OmDEmPWp+uGu+5SfywnDEmwwH6IojKE+jRA1
         iMIV0vAjtrLZvTOS07F68jspeWtzwwJXeiccsfjR2WYRkat7lR/GFwYBcAjv3ZQCUv3h
         7ON4oHbUdnbRQm2O81MG/HNnKiKbJJyrFtdt9a/60sDdG74OwimiwJ8eZfPXgBbqETUT
         AUkw3nGQkVTA4MRO6UkX9UbQzXamcOW9YjRPSh2HBY5a02tz704tzKPXilvHA1Wj/Lvv
         bECcSzmVRXuC7WeR716GNQKehOo7lFMNfmktr0OC5irDnOWtyHH4BX89yqkyI0SW/nNw
         spmQ==
X-Received: by 10.220.174.200 with SMTP id u8mr3519211vcz.6.1387503999261;
 Thu, 19 Dec 2013 17:46:39 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.106.52 with HTTP; Thu, 19 Dec 2013 17:46:09 -0800 (PST)
In-Reply-To: <CA+-p3AG00DDCCgkjdoW4m2g+vkbktwcfDa_p0C8Akcnr1ef_nA@mail.gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
 <1387478305969.35e7931@Nodemailer> <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
 <CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com>
 <CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com> <CA+-p3AG00DDCCgkjdoW4m2g+vkbktwcfDa_p0C8Akcnr1ef_nA@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Thu, 19 Dec 2013 17:46:09 -0800
Message-ID: <CAMwrk0kzw1bKYyt=hd2NyiyZyUVs+pqh9biSSLL5rmmpfecWzQ@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0149ca3a00228d04eded73c3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149ca3a00228d04eded73c3
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

+1 to that (assuming by 'online' Andrew meant MLLib algorithm from Spark
Streaming)

Something you can look into is implementing a streaming KMeans. Maybe you
can re-use a lot of the offline KMeans code in MLLib.

TD


On Thu, Dec 19, 2013 at 5:33 PM, Andrew Ash <andrew@andrewash.com> wrote:

> Sounds like a great choice.  It would be particularly impressive if you
> could add the first online learning algorithm (all the current ones are
> offline I believe) to pave the way for future contributions.
>
>
> On Thu, Dec 19, 2013 at 8:27 PM, Matthew Cheah <mccheah@uwaterloo.ca>
> wrote:
>
> > Thanks a lot everyone! I'm looking into adding an algorithm to MLib for
> the
> > project. Nice and self-contained.
> >
> > -Matt Cheah
> >
> >
> > On Thu, Dec 19, 2013 at 12:52 PM, Christopher Nguyen <ctn@adatao.com>
> > wrote:
> >
> > > +1 to most of Andrew's suggestions here, and while we're in that
> > > neighborhood, how about generalizing something like "wtf-spark" (from
> the
> > > Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of
> high
> > > academic interest, but it's something people would use many times a
> > > debugging day.
> > >
> > > Or am I behind and something like that is already there in 0.8?
> > >
> > > --
> > > Christopher T. Nguyen
> > > Co-founder & CEO, Adatao <http://adatao.com>
> > > linkedin.com/in/ctnguyen
> > >
> > >
> > >
> > > On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com>
> > wrote:
> > >
> > > > I think there are also some improvements that could be made to
> > > > deployability in an enterprise setting.  From my experience:
> > > >
> > > > 1. Most places I deploy Spark in don't have internet access.  So I
> > can't
> > > > build from source, compile against a different version of Hadoop, e=
tc
> > > > without doing it locally and then getting that onto my servers
> > manually.
> > > >  This is less a problem with Spark now that there are binary
> > > distributions,
> > > > but it's still a problem for using Mesos with Spark.
> > > > 2. Configuration of Spark is confusing -- you can make configuratio=
n
> in
> > > > Java system properties, environment variables, command line
> parameters,
> > > and
> > > > for the standalone cluster deployment mode you need to worry about
> > > whether
> > > > these need to be set on the master, the worker, the executor, or th=
e
> > > > application/driver program.  Also because spark-shell automatically
> > > > instantiates a SparkContext you have to set up any system propertie=
s
> in
> > > the
> > > > init scripts or on the command line with
> > > > JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what =
needs
> to
> > > be
> > > > done, but it feels that there are gains to be made in configuration
> > > options
> > > > here.  Ideally, I would have one configuration file that can be use=
d
> in
> > > all
> > > > 4 places and that's the only place to make configuration changes.
> > > > 3. Standalone cluster mode could use improved resiliency for
> starting,
> > > > stopping, and keeping alive a service -- there are custom init
> scripts
> > > that
> > > > call each other in a mess of ways: spark-shell, spark-daemon.sh,
> > > > spark-daemons.sh, spark-config.sh, spark-env.sh,
> compute-classpath.sh,
> > > > spark-executor, spark-class, run-example, and several others in the
> > bin/
> > > > directory.  I would love it if Spark used the Tanuki Service Wrappe=
r,
> > > which
> > > > is widely-used for Java service daemons, supports retries,
> installation
> > > as
> > > > init scripts that can be chkconfig'd, etc.  Let's not re-solve the
> "how
> > > do
> > > > I keep a service running?" problem when it's been done so well by
> > Tanuki
> > > --
> > > > we use it at my day job for all our services, plus it's used by
> > > > Elasticsearch.  This would help solve the problem where a quick
> bounce
> > of
> > > > the master causes all the workers to self-destruct.
> > > > 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- th=
is
> > is
> > > > entirely an Akka bug based on previous mailing list discussion with
> > > Matei,
> > > > but it'd be awesome if you could use either the hostname or the FQD=
N
> or
> > > the
> > > > IP address in the Spark URL and not have Akka barf at you.
> > > >
> > > > I've been telling myself I'd look into these at some point but just
> > > haven't
> > > > gotten around to them myself yet.  Some day!  I would prioritize
> these
> > > > requests from most- to least-important as 3, 2, 4, 1.
> > > >
> > > > Andrew
> > > >
> > > >
> > > > On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
> > > nick.pentreath@gmail.com
> > > > >wrote:
> > > >
> > > > > Or if you're extremely ambitious work in implementing Spark
> Streaming
> > > in
> > > > > Python=97
> > > > > Sent from Mailbox for iPhone
> > > > >
> > > > > On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <
> > > matei.zaharia@gmail.com>
> > > > > wrote:
> > > > >
> > > > > > Hi Matt,
> > > > > > If you want to get started looking at Spark, I recommend the
> > > following
> > > > > resources:
> > > > > > - Our issue tracker at http://spark-project.atlassian.netcontai=
ns
> > > > some
> > > > > issues marked =93Starter=94 that are good places to jump into. Yo=
u
> might
> > be
> > > > > able to take one of those and extend it into a bigger project.
> > > > > > - The =93contributing to Spark=94 wiki page covers how to send
> patches
> > > and
> > > > > set up development:
> > > > >
> > >
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
> > > > > > - This talk has an intro to Spark internals (video and slides a=
re
> > in
> > > > the
> > > > > comments): http://www.meetup.com/spark-users/events/94101942/
> > > > > > For a longer project, here are some possible ones:
> > > > > > - Create a tool that automatically checks which Scala API metho=
ds
> > are
> > > > > missing in Python. We had a similar one for Java that was very
> > useful.
> > > > Even
> > > > > better would be to automatically create wrappers for the Scala
> ones.
> > > > > > - Extend the Spark monitoring UI with profiling information (to
> > > sample
> > > > > the workers and say where they=92re spending time, or what data
> > > structures
> > > > > consume the most memory).
> > > > > > - Pick and implement a new machine learning algorithm for MLlib=
.
> > > > > > Matei
> > > > > > On Dec 17, 2013, at 10:43 AM, Matthew Cheah <
> mccheah@uwaterloo.ca>
> > > > > wrote:
> > > > > >> Hi everyone,
> > > > > >>
> > > > > >> During my most recent internship, I worked extensively with
> Apache
> > > > > Spark,
> > > > > >> integrating it into a company's data analytics platform. I've
> now
> > > > become
> > > > > >> interested in contributing to Apache Spark.
> > > > > >>
> > > > > >> I'm returning to undergraduate studies in January and there is
> an
> > > > > academic
> > > > > >> course which is simply a standalone software engineering
> project.
> > I
> > > > was
> > > > > >> thinking that some contribution to Apache Spark would satisfy =
my
> > > > > curiosity,
> > > > > >> help continue support the company I interned at, and give me
> > > academic
> > > > > >> credits required to graduate, all at the same time. It seems
> like
> > > too
> > > > > good
> > > > > >> an opportunity to pass up.
> > > > > >>
> > > > > >> With that in mind, I have the following questions:
> > > > > >>
> > > > > >>   1. At this point, is there any self-contained project that I
> > could
> > > > > work
> > > > > >>   on within Spark? Ideally, I would work on it independently, =
in
> > > > about a
> > > > > >>   three month time frame. This time also needs to accommodate
> > > ramping
> > > > > up on
> > > > > >>   the Spark codebase and adjusting to the Scala programming
> > language
> > > > and
> > > > > >>   paradigms. The company I worked at primarily used the Java
> APIs.
> > > The
> > > > > output
> > > > > >>   needs to be a technical report describing the project
> > > requirements,
> > > > > and the
> > > > > >>   design process I took to engineer the solution for the
> > > requirements.
> > > > > In
> > > > > >>   particular, it cannot just be a series of haphazard patches.
> > > > > >>   2. How can I get started with contributing to Spark?
> > > > > >>   3. Is there a high-level UML or some other design
> specification
> > > for
> > > > > the
> > > > > >>   Spark architecture?
> > > > > >>
> > > > > >> Thanks! I hope to be of some help =3D)
> > > > > >>
> > > > > >> -Matt Cheah
> > > > >
> > > >
> > >
> >
>

--089e0149ca3a00228d04eded73c3--

From dev-return-963-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 02:09:08 2013
Return-Path: <dev-return-963-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B1A8710E2D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 02:09:08 +0000 (UTC)
Received: (qmail 82275 invoked by uid 500); 20 Dec 2013 02:09:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82221 invoked by uid 500); 20 Dec 2013 02:09:08 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 81939 invoked by uid 99); 20 Dec 2013 02:09:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 02:09:07 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.173 as permitted sender)
Received: from [209.85.192.173] (HELO mail-pd0-f173.google.com) (209.85.192.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 02:09:01 +0000
Received: by mail-pd0-f173.google.com with SMTP id p10so1883185pdj.18
        for <multiple recipients>; Thu, 19 Dec 2013 18:08:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=VRPuonkJDZXhkQfcTNdvcu42gPxASihCsytALfZHOH4=;
        b=SojansFU9kSYlUvk+2jXuKl/JYB1jWHMIlWwGSm02cGqEdFXonsrF84hOnDB8yv1NG
         nVCfhwvTZMrfpwBpcr4dFjOqrukmMustNSAi9MKOYctsUxzhxi+I6GGsLXlLgth+woSX
         andn7m8smbGh7qI+NPFLaobCd+rtyFq/ahp7ZAXrU3rwjxpyhFz05CYL1YpxH0XcYfQn
         u8cokW1GJpe0/Ir2dfEka8JVRnvUC/+g9fvY9r5A1S7rp9b3IiOoA2AhBeWyK0Q6B7LZ
         9GHlxFv3AV0LAss6Tz0osx2t3892Zvaw67fupxLJPIDZX57p2w0six0ppupnPELzSJAR
         ZmOA==
X-Received: by 10.66.226.46 with SMTP id rp14mr5331118pac.133.1387505321382;
        Thu, 19 Dec 2013 18:08:41 -0800 (PST)
Received: from [192.168.1.105] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id rz6sm13573977pab.22.2013.12.19.18.08.40
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 18:08:40 -0800 (PST)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: Spark 0.8.1 Released
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CABPQxsuzAV5hdDQYjgfgSVF=j=7vDO=N=UshGj+6HCZuRvuNGQ@mail.gmail.com>
Date: Thu, 19 Dec 2013 18:08:38 -0800
Cc: user@spark.incubator.apache.org
Content-Transfer-Encoding: 7bit
Message-Id: <EDA4F008-982B-46B8-A53D-85A841C8FF8B@gmail.com>
References: <CABPQxsuzAV5hdDQYjgfgSVF=j=7vDO=N=UshGj+6HCZuRvuNGQ@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Patrick for coordinating this release!

Matei

On Dec 19, 2013, at 5:15 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hi everyone,
> 
> We've just posted Spark 0.8.1, a new maintenance release that contains
> some bug fixes and improvements to the 0.8 branch. The full release
> notes are available at [1]. Apart from various bug fixes, 0.8.1
> includes support for YARN 2.2, a high availability mode for the
> standalone scheduler, and optimizations to the shuffle. We recommend
> that current users update to this release. You can grab the release at
> [2].
> 
> [1] http://spark.incubator.apache.org/releases/spark-release-0-8-1.html
> [2] http://spark.incubator.apache.org/downloads
> 
> Thanks to the following people who contributed to this release:
> 
> Michael Armbrust, Pierre Borckmans, Evan Chan, Ewen Cheslack, Mosharaf
> Chowdhury, Frank Dai, Aaron Davidson, Tathagata Das, Ankur Dave,
> Harvey Feng, Ali Ghodsi, Thomas Graves, Li Guoqiang, Stephen Haberman,
> Haidar Hadi, Nathan Howell, Holden Karau, Du Li, Raymond Liu, Xi Liu,
> David McCauley, Michael (wannabeast), Fabrizio Milo, Mridul
> Muralidharan, Sundeep Narravula, Kay Ousterhout, Nick Pentreath, Imran
> Rashid, Ahir Reddy, Josh Rosen, Henry Saputra, Jerry Shao, Mingfei
> Shi, Andre Schumacher, Karthik Tunga, Patrick Wendell, Neal Wiggins,
> Andrew Xia, Reynold Xin, Matei Zaharia, and Wu Zeming
> 
> - Patrick


From dev-return-964-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 03:19:42 2013
Return-Path: <dev-return-964-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4CCC410FB2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 03:19:42 +0000 (UTC)
Received: (qmail 48957 invoked by uid 500); 20 Dec 2013 03:19:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48745 invoked by uid 500); 20 Dec 2013 03:19:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 48727 invoked by uid 99); 20 Dec 2013 03:19:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 03:19:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andykonwinski@gmail.com designates 74.125.82.177 as permitted sender)
Received: from [74.125.82.177] (HELO mail-we0-f177.google.com) (74.125.82.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 03:19:27 +0000
Received: by mail-we0-f177.google.com with SMTP id u56so1950152wes.36
        for <multiple recipients>; Thu, 19 Dec 2013 19:19:06 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=aqjyvTJYGuULYq3kU4Monmop5q7dDtxVPyr3v2NWj9I=;
        b=lqX3gFx45VoQGLq1Zj/jTNachBfuVzMKOfNy00UBtWEM9sTuHLZGANUQI2Tdwdh8KQ
         5gdjCyh9RCMsqaafYQ7kjR1eby/MzM7SbRJnW4NxIlQwegRuFj83SDs2a7VCU2Fk4bxV
         3xj0fR8YD75KtPv/9x26C41r+lpQylxiA53nq+GRUsyYnrhNSNIi7r2FJQULOBt1prgO
         OpM6aP356QXWNy38k6Nx1SLayyF2/TEP4uMBW8xfa8AfWm1hgn6h1BUtcUvd1RIxOUpY
         GEuUvj9WTzVATJRriE4HmzkcP06Gh5XBuFNF4pJUiutMKYsO+MzV9uJLAR63gZl0Utfd
         1sFA==
MIME-Version: 1.0
X-Received: by 10.180.160.210 with SMTP id xm18mr5418102wib.45.1387509546552;
 Thu, 19 Dec 2013 19:19:06 -0800 (PST)
Received: by 10.216.26.1 with HTTP; Thu, 19 Dec 2013 19:19:06 -0800 (PST)
In-Reply-To: <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
Date: Thu, 19 Dec 2013 19:19:06 -0800
Message-ID: <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: user@spark.incubator.apache.org
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, 
	"spark-users@googlegroups.com" <spark-users@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7b6222e4a515c804edeebd4c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6222e4a515c804edeebd4c
Content-Type: text/plain; charset=ISO-8859-1

Hey Mike,

As you probably noticed when you CC'd spark-developers@googlegroups.com,
that list has already be reconfigured so that it no longer allows posting
(and bounces emails sent to it).

We will be doing the same thing to the spark-users@googlegroups.com list
too (we'll announce a date for that soon).

That may sound very frustrating, and you are *not* alone feeling that way.
We've had a long conversation with our mentors about this, and I've felt
very similar to you, so I'd like to give you background.

As I'm coming to see it, part of becoming an Apache project is moving the
community *fully* over to Apache infrastructure, and more generally the
Apache way of organizing the community.

This applies in both the nuts-and-bolts sense of being on apache infra, but
possibly more importantly, it is also a guiding principle and way of
thinking.

In various ways, moving to apache Infra can be a painful process, and IMO
the loss of all the great mailing list functionality that comes with using
Google Groups is perhaps the most painful step. But basically, the de facto
mailing lists need to be the Apache ones, and not Google Groups. The
underlying reason is that Apache needs to take full accountability for
recording and publishing the mailing lists, it has to be able to
institutionally guarantee this. This is because discussion on mailing lists
is one of the core things that defines an Apache community. So at a minimum
this means Apache owning the master copy of the bits.

All that said, we are discussing the possibility of having a google group
that subscribes to each list that would provide an easier to use and
prettier archive for each list (so far we haven't gotten that to work).

I hope this was helpful. It has taken me a few years now, and a lot of
conversations with experienced (and patient!) Apache mentors, to
internalize some of the nuance about "the Apache way". That's why I wanted
to share.

Andy

On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <maspotts@gmail.com> wrote:

> I notice that there are still a lot of active topics in this group: and
> also activity on the apache mailing list (which is a really horrible
> experience!).  Is it a firm policy on apache's front to disallow external
> groups?  I'm going to be ramping up on spark, and I really hate the idea of
> having to rely on the apache archives and my mail client.  Also: having to
> search for topics/keywords both in old threads (here) as well as new
> threads in apache's (clunky) archive, is going to be a pain!  I almost feel
> like I must be missing something because the current solution seems
> unfeasibly awkward!
>
>  --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>

--047d7b6222e4a515c804edeebd4c--

From dev-return-965-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 04:10:34 2013
Return-Path: <dev-return-965-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 64DD410117
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 04:10:34 +0000 (UTC)
Received: (qmail 89660 invoked by uid 500); 20 Dec 2013 04:10:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89428 invoked by uid 500); 20 Dec 2013 04:10:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 81932 invoked by uid 99); 20 Dec 2013 03:58:37 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of maspotts@gmail.com designates 209.85.216.60 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=WRp+fQ1He4k9F//GRY1LD4AvIjU/j6kjZ4Ed60gB09k=;
        b=w5EpDesKEQr351JXbZ/kzwgUaYhrbGS4JAeLbOWjPnz4ELw7aexSD8YHN5R4q65Wm+
         ZvwDXemStZi+Xef1mYTV0x7b9ZgiQObcRFfRyYEmijCNcg402guEB4/6LxHUUBI7LpkP
         DhSboNJOHzJXipAK2burOUIQZmOfqr8aeWtuOjNoXZaZhfG0B++hL1jaJkpGbCt2D3sg
         bsf6NpRTmVYRXjn7Klu4TYyyaMQ/oStvKgcTBW2VadEavgUIiduS3LKwi3Otz2Kd64Qc
         Q5jKM7UrFcHNEybhYtDbBkhkSsMFa0tTewpT3w2e69cpsozSrJVVFj9gADOCiSf1FbNT
         UiJw==
X-Received: by 10.50.79.228 with SMTP id m4mr149284igx.9.1387511890974;
        Thu, 19 Dec 2013 19:58:10 -0800 (PST)
X-Google-Doc-Id: 3d5dcf6123d3e37e
X-Google-Web-Client: true
Date: Thu, 19 Dec 2013 19:58:09 -0800 (PST)
From: Mike Potts <maspotts@gmail.com>
To: spark-users@googlegroups.com
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Message-Id: <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
In-Reply-To: <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
 <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
 <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
 <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
 <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
 <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September
 1st
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_146_17939370.1387511889909"
X-Google-Token: ENGAz5UFBa5LiuxHjO40
X-Google-IP: 75.25.125.13
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_146_17939370.1387511889909
Content-Type: multipart/alternative; 
	boundary="----=_Part_147_10936904.1387511889909"

------=_Part_147_10936904.1387511889909
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Thanks very much for the prompt and comprehensive reply!  I appreciate the 
overarching desire to integrate with apache: I'm very happy to hear that 
there's a move to use the existing groups as mirrors: that will overcome 
all of my objections: particularly if it's bidirectional! :)

On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>
> Hey Mike,
>
> As you probably noticed when you CC'd spark-de...@googlegroups.com<javascript:>, 
> that list has already be reconfigured so that it no longer allows posting 
> (and bounces emails sent to it).
>
> We will be doing the same thing to the spark...@googlegroups.com<javascript:>list too (we'll announce a date for that soon).
>
> That may sound very frustrating, and you are *not* alone feeling that way. 
> We've had a long conversation with our mentors about this, and I've felt 
> very similar to you, so I'd like to give you background.
>
> As I'm coming to see it, part of becoming an Apache project is moving the 
> community *fully* over to Apache infrastructure, and more generally the 
> Apache way of organizing the community.
>
> This applies in both the nuts-and-bolts sense of being on apache infra, 
> but possibly more importantly, it is also a guiding principle and way of 
> thinking.
>
> In various ways, moving to apache Infra can be a painful process, and IMO 
> the loss of all the great mailing list functionality that comes with using 
> Google Groups is perhaps the most painful step. But basically, the de facto 
> mailing lists need to be the Apache ones, and not Google Groups. The 
> underlying reason is that Apache needs to take full accountability for 
> recording and publishing the mailing lists, it has to be able to 
> institutionally guarantee this. This is because discussion on mailing lists 
> is one of the core things that defines an Apache community. So at a minimum 
> this means Apache owning the master copy of the bits. 
>
> All that said, we are discussing the possibility of having a google group 
> that subscribes to each list that would provide an easier to use and 
> prettier archive for each list (so far we haven't gotten that to work).
>
> I hope this was helpful. It has taken me a few years now, and a lot of 
> conversations with experienced (and patient!) Apache mentors, to 
> internalize some of the nuance about "the Apache way". That's why I wanted 
> to share.
>
> Andy
>
> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com<javascript:>
> > wrote:
>
>> I notice that there are still a lot of active topics in this group: and 
>> also activity on the apache mailing list (which is a really horrible 
>> experience!).  Is it a firm policy on apache's front to disallow external 
>> groups?  I'm going to be ramping up on spark, and I really hate the idea of 
>> having to rely on the apache archives and my mail client.  Also: having to 
>> search for topics/keywords both in old threads (here) as well as new 
>> threads in apache's (clunky) archive, is going to be a pain!  I almost feel 
>> like I must be missing something because the current solution seems 
>> unfeasibly awkward!
>>
>>  -- 
>> You received this message because you are subscribed to the Google Groups 
>> "Spark Users" group.
>> To unsubscribe from this group and stop receiving emails from it, send an 
>> email to spark-users...@googlegroups.com <javascript:>.
>> For more options, visit https://groups.google.com/groups/opt_out.
>>
>
>
------=_Part_147_10936904.1387511889909
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<div dir="ltr">Thanks very much for the prompt and comprehensive reply! &nbsp;I appreciate the overarching desire to integrate with apache: I'm very happy to hear that there's a move to use the existing groups as mirrors: that will overcome all of my objections: particularly if it's bidirectional! :)<br><br>On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:<blockquote class="gmail_quote" style="margin: 0;margin-left: 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;"><div dir="ltr"><div>Hey Mike,<br><br>As you probably noticed when you CC'd <a href="javascript:" target="_blank" gdf-obfuscated-mailto="eV1C8tkdI00J" onmousedown="this.href='javascript:';return true;" onclick="this.href='javascript:';return true;">spark-de...@googlegroups.<wbr>com</a>, that list has already be reconfigured so that it no longer allows posting (and bounces emails sent to it).</div>
<div><br></div><div>We will be doing the same thing to the <a href="javascript:" target="_blank" gdf-obfuscated-mailto="eV1C8tkdI00J" onmousedown="this.href='javascript:';return true;" onclick="this.href='javascript:';return true;">spark...@googlegroups.com</a> list too (we'll announce a date for that soon).</div>
<div><br></div><div>That may sound very frustrating, and you are *not* alone feeling that way. We've had a long conversation with our mentors about this, and I've felt very similar to you, so I'd like to give you background.</div>
<div><br></div><div>As I'm coming to see it, part of becoming an Apache project is moving the community *fully* over to Apache infrastructure, and more generally the Apache way of organizing the community.</div>
<div><br></div><div>This applies in both the nuts-and-bolts sense of being on apache infra, but possibly more importantly, it is also a guiding principle and way of thinking.</div><div>
<br></div><div>In various ways, moving to apache Infra can be a painful process, and IMO the loss of all the great mailing list functionality that comes with using Google Groups is perhaps the most painful step. But basically, the de facto mailing lists need to be the Apache ones, and not Google Groups. The underlying reason is that Apache needs to take full accountability for recording and publishing the mailing lists, it has to be able to institutionally guarantee this. This is because discussion on mailing lists is one of the core things that defines an Apache community. So at a minimum this means Apache owning the master copy of the bits. <br>
</div><div><br></div><div>All that said, we are discussing the possibility of having a google group that subscribes to each list that would provide an easier to use and prettier archive for each list (so far we haven't gotten that to work).</div>
<div><br></div><div>I hope this was helpful. It has taken me a few years now, and a lot of conversations with experienced (and patient!) Apache mentors, to internalize some of the nuance about "the Apache way". That's why I wanted to share.</div>
<div><br></div><div>Andy<br><br><div class="gmail_quote">On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <span dir="ltr">&lt;<a href="javascript:" target="_blank" gdf-obfuscated-mailto="eV1C8tkdI00J" onmousedown="this.href='javascript:';return true;" onclick="this.href='javascript:';return true;">masp...@gmail.com</a>&gt;</span> wrote:<br>
<blockquote class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div dir="ltr">I notice that there are still a lot of active topics in this group: and also activity on the apache mailing list (which is a really horrible experience!). &nbsp;Is it a firm policy on apache's front to disallow external groups? &nbsp;I'm going to be ramping up on spark, and I really hate the idea of having to rely on the apache archives and my mail client. &nbsp;Also: having to search for topics/keywords both in old threads (here) as well as new threads in apache's (clunky) archive, is going to be a pain! &nbsp;I almost feel like I must be missing something because the current solution seems unfeasibly awkward!<div>
<br></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "Spark Users" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an email to <a href="javascript:" target="_blank" gdf-obfuscated-mailto="eV1C8tkdI00J" onmousedown="this.href='javascript:';return true;" onclick="this.href='javascript:';return true;">spark-users...@<wbr>googlegroups.com</a>.<br>
For more options, visit <a href="https://groups.google.com/groups/opt_out" target="_blank" onmousedown="this.href='https://groups.google.com/groups/opt_out';return true;" onclick="this.href='https://groups.google.com/groups/opt_out';return true;">https://groups.google.com/<wbr>groups/opt_out</a>.<br>
</div></div></blockquote></div><br></div></div>
</blockquote></div>
------=_Part_147_10936904.1387511889909--

------=_Part_146_17939370.1387511889909--

From dev-return-966-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 04:47:11 2013
Return-Path: <dev-return-966-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 119861020A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 04:47:11 +0000 (UTC)
Received: (qmail 21882 invoked by uid 500); 20 Dec 2013 04:47:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21780 invoked by uid 500); 20 Dec 2013 04:47:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 21761 invoked by uid 99); 20 Dec 2013 04:47:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 04:47:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ilikerps@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 04:46:58 +0000
Received: by mail-wg0-f45.google.com with SMTP id y10so1986983wgg.12
        for <multiple recipients>; Thu, 19 Dec 2013 20:46:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=uSiAetqTi+VgBlaKNZZuSTsJRvq9U7GkyE9lk6uza4A=;
        b=ReriaOSllzfsOVO+w6nmBdMG1Z8gY7uQrquf+LV/F2M2+hl+ZYZPhPbxzbL0WtYLCl
         EBbbsyLOZ9+z0eAuF4TejBfk5K8qv/qeRlYcHtMPn/8xWGbThsq0P0paT1vCBw6rZpSu
         emkFpbYyA4LDI9GnYTbxl3Dc0linKWQtmxA7LGvg5F2LzbRIdTrDFWxfW08L6eyI/Z6G
         stzIrQOXBmAWkocB99ol3iBPbwjPNPqA8OopC+BasQ4hgvTBR1xQL9i/HqjfPNUvXaOK
         9J4AWpKPexmZsAi0Xh4M8oT9fr1SX1Fk3eSFwQPliIQ6WhfSha9626XmnXt4SXx6kz3J
         goHQ==
X-Received: by 10.194.120.164 with SMTP id ld4mr4868747wjb.47.1387514797556;
 Thu, 19 Dec 2013 20:46:37 -0800 (PST)
MIME-Version: 1.0
Received: by 10.194.119.228 with HTTP; Thu, 19 Dec 2013 20:46:17 -0800 (PST)
In-Reply-To: <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
 <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
 <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
 <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
From: Aaron Davidson <ilikerps@gmail.com>
Date: Thu, 19 Dec 2013 20:46:17 -0800
Message-ID: <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
To: dev@spark.incubator.apache.org
Cc: spark-users@googlegroups.com, user@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e01175e5fa10aff04edeff61d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01175e5fa10aff04edeff61d
Content-Type: text/plain; charset=ISO-8859-1

I'd be fine with one-way mirrors here (Apache threads being reflected in
Google groups) -- I have no idea how one is supposed to navigate the Apache
list to look for historic threads.


On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote:

> Thanks very much for the prompt and comprehensive reply!  I appreciate the
> overarching desire to integrate with apache: I'm very happy to hear that
> there's a move to use the existing groups as mirrors: that will overcome
> all of my objections: particularly if it's bidirectional! :)
>
>
> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>
>> Hey Mike,
>>
>> As you probably noticed when you CC'd spark-de...@googlegroups.com, that
>> list has already be reconfigured so that it no longer allows posting (and
>> bounces emails sent to it).
>>
>> We will be doing the same thing to the spark...@googlegroups.com list
>> too (we'll announce a date for that soon).
>>
>> That may sound very frustrating, and you are *not* alone feeling that
>> way. We've had a long conversation with our mentors about this, and I've
>> felt very similar to you, so I'd like to give you background.
>>
>> As I'm coming to see it, part of becoming an Apache project is moving the
>> community *fully* over to Apache infrastructure, and more generally the
>> Apache way of organizing the community.
>>
>> This applies in both the nuts-and-bolts sense of being on apache infra,
>> but possibly more importantly, it is also a guiding principle and way of
>> thinking.
>>
>> In various ways, moving to apache Infra can be a painful process, and IMO
>> the loss of all the great mailing list functionality that comes with using
>> Google Groups is perhaps the most painful step. But basically, the de facto
>> mailing lists need to be the Apache ones, and not Google Groups. The
>> underlying reason is that Apache needs to take full accountability for
>> recording and publishing the mailing lists, it has to be able to
>> institutionally guarantee this. This is because discussion on mailing lists
>> is one of the core things that defines an Apache community. So at a minimum
>> this means Apache owning the master copy of the bits.
>>
>> All that said, we are discussing the possibility of having a google group
>> that subscribes to each list that would provide an easier to use and
>> prettier archive for each list (so far we haven't gotten that to work).
>>
>> I hope this was helpful. It has taken me a few years now, and a lot of
>> conversations with experienced (and patient!) Apache mentors, to
>> internalize some of the nuance about "the Apache way". That's why I wanted
>> to share.
>>
>> Andy
>>
>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:
>>
>>> I notice that there are still a lot of active topics in this group: and
>>> also activity on the apache mailing list (which is a really horrible
>>> experience!).  Is it a firm policy on apache's front to disallow external
>>> groups?  I'm going to be ramping up on spark, and I really hate the idea of
>>> having to rely on the apache archives and my mail client.  Also: having to
>>> search for topics/keywords both in old threads (here) as well as new
>>> threads in apache's (clunky) archive, is going to be a pain!  I almost feel
>>> like I must be missing something because the current solution seems
>>> unfeasibly awkward!
>>>
>>>  --
>>> You received this message because you are subscribed to the Google
>>> Groups "Spark Users" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to spark-users...@googlegroups.com.
>>>
>>> For more options, visit https://groups.google.com/groups/opt_out.
>>>
>>
>>

--089e01175e5fa10aff04edeff61d--

From dev-return-967-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 06:11:05 2013
Return-Path: <dev-return-967-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 772E8103E2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 06:11:05 +0000 (UTC)
Received: (qmail 1261 invoked by uid 500); 20 Dec 2013 06:11:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1114 invoked by uid 500); 20 Dec 2013 06:10:57 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 1094 invoked by uid 99); 20 Dec 2013 06:10:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:10:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:10:49 +0000
Received: by mail-we0-f169.google.com with SMTP id w61so2050352wes.28
        for <multiple recipients>; Thu, 19 Dec 2013 22:10:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=Ihw3XzgGJ/UB785HtbQlq/FRArSkF28WzkFhtXuQpoU=;
        b=JtJSBjGTCA3CumTUAVz2pUuo0/2TJ4ei03ZEJi0lXz4nr/K0bzJneHDgeTvGDlY0R/
         GhDH5Yok8C1tlX8NcW8VeLt78StkCBpob4kMq+9EaRw2aClMWJSbQBS4rN+Q1OHzQnxW
         hOJy0oM7z820Z7h0LtQ7elsNOjqGCWWoxVktaE7nZbPjuuVM8rgmkIWUriWy5FM8Qb3K
         RD2wchBNBGZZXBQ8QVj76COqQBJ41wgix9vH5QjTLMbE4pNUYbjK7s2X0zv8r8FbTG/Q
         qW0UkorIBhnfIL6k4Aq6JLIVXJmRmSZd1QD3elXNEhcSk1WeSywDmO1wg+JgEPby9SOg
         axCg==
X-Received: by 10.194.58.136 with SMTP id r8mr5257575wjq.4.1387519828456;
        Thu, 19 Dec 2013 22:10:28 -0800 (PST)
Received: from [10.0.0.3] ([197.87.219.237])
        by mx.google.com with ESMTPSA id r10sm1649535wje.10.2013.12.19.22.10.25
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 22:10:27 -0800 (PST)
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com> <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com> <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com> <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com> <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Message-Id: <3BF29572-8A91-41C6-9048-1708FBFBCE24@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>,
 "spark-users@googlegroups.com" <spark-users@googlegroups.com>,
 "user@spark.incubator.apache.org" <user@spark.incubator.apache.org>,
 Otis Gospodnetic <otis@sematext.com>
X-Mailer: iPad Mail (11B554a)
From: Nick Pentreath <nick.pentreath@gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
Date: Fri, 20 Dec 2013 08:10:22 +0200
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

One option that is 3rd party that works nicely for the Hadoop project and it=
's related projects is http://search-hadoop.com - managed by sematext. Perha=
ps we can plead with Otis to add Spark lists to search-spark.com, or the exi=
sting site?

Just throwing it out there as a potential solution to at least searching and=
 navigating the Apache lists

Sent from my iPad

> On 20 Dec 2013, at 6:46 AM, Aaron Davidson <ilikerps@gmail.com> wrote:
>=20
> I'd be fine with one-way mirrors here (Apache threads being reflected in
> Google groups) -- I have no idea how one is supposed to navigate the Apach=
e
> list to look for historic threads.
>=20
>=20
>> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote:
>>=20
>> Thanks very much for the prompt and comprehensive reply!  I appreciate th=
e
>> overarching desire to integrate with apache: I'm very happy to hear that
>> there's a move to use the existing groups as mirrors: that will overcome
>> all of my objections: particularly if it's bidirectional! :)
>>=20
>>=20
>>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>>>=20
>>> Hey Mike,
>>>=20
>>> As you probably noticed when you CC'd spark-de...@googlegroups.com, that=

>>> list has already be reconfigured so that it no longer allows posting (an=
d
>>> bounces emails sent to it).
>>>=20
>>> We will be doing the same thing to the spark...@googlegroups.com list
>>> too (we'll announce a date for that soon).
>>>=20
>>> That may sound very frustrating, and you are *not* alone feeling that
>>> way. We've had a long conversation with our mentors about this, and I've=

>>> felt very similar to you, so I'd like to give you background.
>>>=20
>>> As I'm coming to see it, part of becoming an Apache project is moving th=
e
>>> community *fully* over to Apache infrastructure, and more generally the
>>> Apache way of organizing the community.
>>>=20
>>> This applies in both the nuts-and-bolts sense of being on apache infra,
>>> but possibly more importantly, it is also a guiding principle and way of=

>>> thinking.
>>>=20
>>> In various ways, moving to apache Infra can be a painful process, and IM=
O
>>> the loss of all the great mailing list functionality that comes with usi=
ng
>>> Google Groups is perhaps the most painful step. But basically, the de fa=
cto
>>> mailing lists need to be the Apache ones, and not Google Groups. The
>>> underlying reason is that Apache needs to take full accountability for
>>> recording and publishing the mailing lists, it has to be able to
>>> institutionally guarantee this. This is because discussion on mailing li=
sts
>>> is one of the core things that defines an Apache community. So at a mini=
mum
>>> this means Apache owning the master copy of the bits.
>>>=20
>>> All that said, we are discussing the possibility of having a google grou=
p
>>> that subscribes to each list that would provide an easier to use and
>>> prettier archive for each list (so far we haven't gotten that to work).
>>>=20
>>> I hope this was helpful. It has taken me a few years now, and a lot of
>>> conversations with experienced (and patient!) Apache mentors, to
>>> internalize some of the nuance about "the Apache way". That's why I want=
ed
>>> to share.
>>>=20
>>> Andy
>>>=20
>>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:
>>>>=20
>>>> I notice that there are still a lot of active topics in this group: and=

>>>> also activity on the apache mailing list (which is a really horrible
>>>> experience!).  Is it a firm policy on apache's front to disallow extern=
al
>>>> groups?  I'm going to be ramping up on spark, and I really hate the ide=
a of
>>>> having to rely on the apache archives and my mail client.  Also: having=
 to
>>>> search for topics/keywords both in old threads (here) as well as new
>>>> threads in apache's (clunky) archive, is going to be a pain!  I almost f=
eel
>>>> like I must be missing something because the current solution seems
>>>> unfeasibly awkward!
>>>>=20
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "Spark Users" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to spark-users...@googlegroups.com.
>>>>=20
>>>> For more options, visit https://groups.google.com/groups/opt_out.
>>>=20
>>>=20

From dev-return-968-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 06:18:13 2013
Return-Path: <dev-return-968-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 853C11040E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 06:18:13 +0000 (UTC)
Received: (qmail 8621 invoked by uid 500); 20 Dec 2013 06:18:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8379 invoked by uid 500); 20 Dec 2013 06:18:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 8365 invoked by uid 99); 20 Dec 2013 06:18:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:18:05 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=5.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.192.181 as permitted sender)
Received: from [209.85.192.181] (HELO mail-pd0-f181.google.com) (209.85.192.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:18:00 +0000
Received: by mail-pd0-f181.google.com with SMTP id p10so2118569pdj.12
        for <multiple recipients>; Thu, 19 Dec 2013 22:17:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=iclXtyzFBOnt4bRtRXiDmMksnbKrlG0SR8/8tEQrqlE=;
        b=MYQ3BZf3Ao48LX8G4Gk7B/I6sn2Wp7pieTpMJJQBJdAUXi1+KbVD513pw4ZT8Ynwfj
         ggnAcwbRzQHg7jkZep4hyAEe80OIoi57dmlgd8z2HQnybI+k/lwrAT1KfYpfQrEf9NuC
         ocfvhR1WFo+eMGJmLQZoB3bypKqEC8dMOLKC+TdvaKz2cLHD7XSLiZWFyfgOUL0zcoQK
         v9MN5H7BMH/yEUJ1cGhkGHi0CM8uIuNslqmeY3YrjQjccPPqfn0J1Qn9qaXhgYTM7J2b
         ZMFaOqPXp4BLr/6BKUkCgWc4eeyxPmLQVFemhy8bNLEyyqVYKCY5Ltjn6sBcihKgYqzL
         A76g==
X-Received: by 10.68.196.69 with SMTP id ik5mr6564564pbc.132.1387520259787;
        Thu, 19 Dec 2013 22:17:39 -0800 (PST)
Received: from [192.168.0.10] (c-24-130-236-83.hsd1.ca.comcast.net. [24.130.236.83])
        by mx.google.com with ESMTPSA id vf7sm11722918pbc.5.2013.12.19.22.17.38
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 22:17:38 -0800 (PST)
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com> <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com> <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com> <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com> <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com> <3BF29572-8A91-41C6-9048-1708FBFBCE24@gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <3BF29572-8A91-41C6-9048-1708FBFBCE24@gmail.com>
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Message-Id: <DC42DA9F-7EBF-4BD1-9353-5AD3D39F4A04@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>,
 "spark-users@googlegroups.com" <spark-users@googlegroups.com>,
 "user@spark.incubator.apache.org" <user@spark.incubator.apache.org>,
 Otis Gospodnetic <otis@sematext.com>
X-Mailer: iPhone Mail (10B146)
From: Ted Yu <yuzhihong@gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
Date: Thu, 19 Dec 2013 22:17:38 -0800
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

You may have noticed that the counter of searchable items for last 7 days on=
 search-Hadoop is 0 and the counter for last 30 days is declining quickly.=20=


Cheers

On Dec 19, 2013, at 10:10 PM, Nick Pentreath <nick.pentreath@gmail.com> wrot=
e:

> One option that is 3rd party that works nicely for the Hadoop project and i=
t's related projects is http://search-hadoop.com - managed by sematext. Perh=
aps we can plead with Otis to add Spark lists to search-spark.com, or the ex=
isting site?
>=20
> Just throwing it out there as a potential solution to at least searching a=
nd navigating the Apache lists
>=20
> Sent from my iPad
>=20
>> On 20 Dec 2013, at 6:46 AM, Aaron Davidson <ilikerps@gmail.com> wrote:
>>=20
>> I'd be fine with one-way mirrors here (Apache threads being reflected in
>> Google groups) -- I have no idea how one is supposed to navigate the Apac=
he
>> list to look for historic threads.
>>=20
>>=20
>>> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote:
>>>=20
>>> Thanks very much for the prompt and comprehensive reply!  I appreciate t=
he
>>> overarching desire to integrate with apache: I'm very happy to hear that=

>>> there's a move to use the existing groups as mirrors: that will overcome=

>>> all of my objections: particularly if it's bidirectional! :)
>>>=20
>>>=20
>>>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>>>>=20
>>>> Hey Mike,
>>>>=20
>>>> As you probably noticed when you CC'd spark-de...@googlegroups.com, tha=
t
>>>> list has already be reconfigured so that it no longer allows posting (a=
nd
>>>> bounces emails sent to it).
>>>>=20
>>>> We will be doing the same thing to the spark...@googlegroups.com list
>>>> too (we'll announce a date for that soon).
>>>>=20
>>>> That may sound very frustrating, and you are *not* alone feeling that
>>>> way. We've had a long conversation with our mentors about this, and I'v=
e
>>>> felt very similar to you, so I'd like to give you background.
>>>>=20
>>>> As I'm coming to see it, part of becoming an Apache project is moving t=
he
>>>> community *fully* over to Apache infrastructure, and more generally the=

>>>> Apache way of organizing the community.
>>>>=20
>>>> This applies in both the nuts-and-bolts sense of being on apache infra,=

>>>> but possibly more importantly, it is also a guiding principle and way o=
f
>>>> thinking.
>>>>=20
>>>> In various ways, moving to apache Infra can be a painful process, and I=
MO
>>>> the loss of all the great mailing list functionality that comes with us=
ing
>>>> Google Groups is perhaps the most painful step. But basically, the de f=
acto
>>>> mailing lists need to be the Apache ones, and not Google Groups. The
>>>> underlying reason is that Apache needs to take full accountability for
>>>> recording and publishing the mailing lists, it has to be able to
>>>> institutionally guarantee this. This is because discussion on mailing l=
ists
>>>> is one of the core things that defines an Apache community. So at a min=
imum
>>>> this means Apache owning the master copy of the bits.
>>>>=20
>>>> All that said, we are discussing the possibility of having a google gro=
up
>>>> that subscribes to each list that would provide an easier to use and
>>>> prettier archive for each list (so far we haven't gotten that to work).=

>>>>=20
>>>> I hope this was helpful. It has taken me a few years now, and a lot of
>>>> conversations with experienced (and patient!) Apache mentors, to
>>>> internalize some of the nuance about "the Apache way". That's why I wan=
ted
>>>> to share.
>>>>=20
>>>> Andy
>>>>=20
>>>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:=

>>>>>=20
>>>>> I notice that there are still a lot of active topics in this group: an=
d
>>>>> also activity on the apache mailing list (which is a really horrible
>>>>> experience!).  Is it a firm policy on apache's front to disallow exter=
nal
>>>>> groups?  I'm going to be ramping up on spark, and I really hate the id=
ea of
>>>>> having to rely on the apache archives and my mail client.  Also: havin=
g to
>>>>> search for topics/keywords both in old threads (here) as well as new
>>>>> threads in apache's (clunky) archive, is going to be a pain!  I almost=
 feel
>>>>> like I must be missing something because the current solution seems
>>>>> unfeasibly awkward!
>>>>>=20
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "Spark Users" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send=

>>>>> an email to spark-users...@googlegroups.com.
>>>>>=20
>>>>> For more options, visit https://groups.google.com/groups/opt_out.
>>>>=20
>>>>=20

From dev-return-969-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 06:18:46 2013
Return-Path: <dev-return-969-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF3E710412
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 06:18:46 +0000 (UTC)
Received: (qmail 12089 invoked by uid 500); 20 Dec 2013 06:18:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12067 invoked by uid 500); 20 Dec 2013 06:18:45 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 12059 invoked by uid 99); 20 Dec 2013 06:18:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:18:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:18:40 +0000
Received: by mail-wg0-f46.google.com with SMTP id m15so1998516wgh.25
        for <dev@spark.incubator.apache.org>; Thu, 19 Dec 2013 22:18:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=K9IG7Wn7XF0Ux0zW/zDx5VtKPVWL6RDMn2I3Hjzy8dE=;
        b=d1NDjS8v94me9qX5WUihrnODYlg15Ag1FnU8HulxvTEtPHqjtxbuswj8Av3Ry36E3Y
         pfaR3YzSiPrsr43a1XKMcbXNVI3/F9tDOvimAFdrO/E1AXkdIaKjPfNq/oFSMn/B2wZO
         pzPZiDuu5sQPvPyKPpR55p8/Idt2QY21gYjyM3/E56Q+OoMU6pRtIhHn8Pc9Azt/fdJx
         +v3KBOE61BvFkoj3rbmK58KsuRXDHj2r1ww8ABIcsxlFwlLhgkCZi8CcuvTmGMyFf/UU
         aa/C36qUPs46iX0279u6rp6VS5Bba1o9ANRp66nkyIgwShYOC8bQbR6BxkVvMph/CEYu
         9s6A==
X-Received: by 10.194.123.8 with SMTP id lw8mr5178733wjb.40.1387520299306;
        Thu, 19 Dec 2013 22:18:19 -0800 (PST)
Received: from [10.0.0.3] ([197.87.219.237])
        by mx.google.com with ESMTPSA id kr10sm1661793wjc.22.2013.12.19.22.18.17
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 22:18:18 -0800 (PST)
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com> <1387478305969.35e7931@Nodemailer> <CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com> <CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com> <CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com> <CA+-p3AG00DDCCgkjdoW4m2g+vkbktwcfDa_p0C8Akcnr1ef_nA@mail.gmail.com> <CAMwrk0kzw1bKYyt=hd2NyiyZyUVs+pqh9biSSLL5rmmpfecWzQ@mail.gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <CAMwrk0kzw1bKYyt=hd2NyiyZyUVs+pqh9biSSLL5rmmpfecWzQ@mail.gmail.com>
Content-Type: text/plain;
	charset=utf-8
Content-Transfer-Encoding: quoted-printable
Message-Id: <C6A9C8CF-9015-4111-B35A-19FA44A55D79@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Mailer: iPad Mail (11B554a)
From: Nick Pentreath <nick.pentreath@gmail.com>
Subject: Re: Spark development for undergraduate project
Date: Fri, 20 Dec 2013 08:18:13 +0200
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

Another option would be:
1. Add another recommendation model based on mrec's sgd based model: https:/=
/github.com/mendeley/mrec
2. Look at the streaming K-means from Mahout and see if that might be integr=
ated or adapted into MLlib
3. Work on adding to or refactoring the existing linear model framework, for=
 example adaptive learning rate schedules, adaptive norm stuff from John Lan=
gford et al
4. Adding sparse vector/matrix support to MLlib?

Sent from my iPad

> On 20 Dec 2013, at 3:46 AM, Tathagata Das <tathagata.das1565@gmail.com> wr=
ote:
>=20
> +1 to that (assuming by 'online' Andrew meant MLLib algorithm from Spark
> Streaming)
>=20
> Something you can look into is implementing a streaming KMeans. Maybe you
> can re-use a lot of the offline KMeans code in MLLib.
>=20
> TD
>=20
>=20
>> On Thu, Dec 19, 2013 at 5:33 PM, Andrew Ash <andrew@andrewash.com> wrote:=

>>=20
>> Sounds like a great choice.  It would be particularly impressive if you
>> could add the first online learning algorithm (all the current ones are
>> offline I believe) to pave the way for future contributions.
>>=20
>>=20
>> On Thu, Dec 19, 2013 at 8:27 PM, Matthew Cheah <mccheah@uwaterloo.ca>
>> wrote:
>>=20
>>> Thanks a lot everyone! I'm looking into adding an algorithm to MLib for
>> the
>>> project. Nice and self-contained.
>>>=20
>>> -Matt Cheah
>>>=20
>>>=20
>>> On Thu, Dec 19, 2013 at 12:52 PM, Christopher Nguyen <ctn@adatao.com>
>>> wrote:
>>>=20
>>>> +1 to most of Andrew's suggestions here, and while we're in that
>>>> neighborhood, how about generalizing something like "wtf-spark" (from
>> the
>>>> Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of
>> high
>>>> academic interest, but it's something people would use many times a
>>>> debugging day.
>>>>=20
>>>> Or am I behind and something like that is already there in 0.8?
>>>>=20
>>>> --
>>>> Christopher T. Nguyen
>>>> Co-founder & CEO, Adatao <http://adatao.com>
>>>> linkedin.com/in/ctnguyen
>>>>=20
>>>>=20
>>>>=20
>>>>> On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com>
>>>> wrote:
>>>>=20
>>>>> I think there are also some improvements that could be made to
>>>>> deployability in an enterprise setting.  =46rom my experience:
>>>>>=20
>>>>> 1. Most places I deploy Spark in don't have internet access.  So I
>>> can't
>>>>> build from source, compile against a different version of Hadoop, etc
>>>>> without doing it locally and then getting that onto my servers
>>> manually.
>>>>> This is less a problem with Spark now that there are binary
>>>> distributions,
>>>>> but it's still a problem for using Mesos with Spark.
>>>>> 2. Configuration of Spark is confusing -- you can make configuration
>> in
>>>>> Java system properties, environment variables, command line
>> parameters,
>>>> and
>>>>> for the standalone cluster deployment mode you need to worry about
>>>> whether
>>>>> these need to be set on the master, the worker, the executor, or the
>>>>> application/driver program.  Also because spark-shell automatically
>>>>> instantiates a SparkContext you have to set up any system properties
>> in
>>>> the
>>>>> init scripts or on the command line with
>>>>> JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what nee=
ds
>> to
>>>> be
>>>>> done, but it feels that there are gains to be made in configuration
>>>> options
>>>>> here.  Ideally, I would have one configuration file that can be used
>> in
>>>> all
>>>>> 4 places and that's the only place to make configuration changes.
>>>>> 3. Standalone cluster mode could use improved resiliency for
>> starting,
>>>>> stopping, and keeping alive a service -- there are custom init
>> scripts
>>>> that
>>>>> call each other in a mess of ways: spark-shell, spark-daemon.sh,
>>>>> spark-daemons.sh, spark-config.sh, spark-env.sh,
>> compute-classpath.sh,
>>>>> spark-executor, spark-class, run-example, and several others in the
>>> bin/
>>>>> directory.  I would love it if Spark used the Tanuki Service Wrapper,
>>>> which
>>>>> is widely-used for Java service daemons, supports retries,
>> installation
>>>> as
>>>>> init scripts that can be chkconfig'd, etc.  Let's not re-solve the
>> "how
>>>> do
>>>>> I keep a service running?" problem when it's been done so well by
>>> Tanuki
>>>> --
>>>>> we use it at my day job for all our services, plus it's used by
>>>>> Elasticsearch.  This would help solve the problem where a quick
>> bounce
>>> of
>>>>> the master causes all the workers to self-destruct.
>>>>> 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- this
>>> is
>>>>> entirely an Akka bug based on previous mailing list discussion with
>>>> Matei,
>>>>> but it'd be awesome if you could use either the hostname or the FQDN
>> or
>>>> the
>>>>> IP address in the Spark URL and not have Akka barf at you.
>>>>>=20
>>>>> I've been telling myself I'd look into these at some point but just
>>>> haven't
>>>>> gotten around to them myself yet.  Some day!  I would prioritize
>> these
>>>>> requests from most- to least-important as 3, 2, 4, 1.
>>>>>=20
>>>>> Andrew
>>>>>=20
>>>>>=20
>>>>> On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
>>>> nick.pentreath@gmail.com
>>>>>> wrote:
>>>>>=20
>>>>>> Or if you're extremely ambitious work in implementing Spark
>> Streaming
>>>> in
>>>>>> Python=E2=80=94
>>>>>> Sent from Mailbox for iPhone
>>>>>>=20
>>>>>> On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <
>>>> matei.zaharia@gmail.com>
>>>>>> wrote:
>>>>>>=20
>>>>>>> Hi Matt,
>>>>>>> If you want to get started looking at Spark, I recommend the
>>>> following
>>>>>> resources:
>>>>>>> - Our issue tracker at http://spark-project.atlassian.netcontains
>>>>> some
>>>>>> issues marked =E2=80=9CStarter=E2=80=9D that are good places to jump i=
nto. You
>> might
>>> be
>>>>>> able to take one of those and extend it into a bigger project.
>>>>>>> - The =E2=80=9Ccontributing to Spark=E2=80=9D wiki page covers how t=
o send
>> patches
>>>> and
>>>>>> set up development:
>> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
>>>>>>> - This talk has an intro to Spark internals (video and slides are
>>> in
>>>>> the
>>>>>> comments): http://www.meetup.com/spark-users/events/94101942/
>>>>>>> For a longer project, here are some possible ones:
>>>>>>> - Create a tool that automatically checks which Scala API methods
>>> are
>>>>>> missing in Python. We had a similar one for Java that was very
>>> useful.
>>>>> Even
>>>>>> better would be to automatically create wrappers for the Scala
>> ones.
>>>>>>> - Extend the Spark monitoring UI with profiling information (to
>>>> sample
>>>>>> the workers and say where they=E2=80=99re spending time, or what data=

>>>> structures
>>>>>> consume the most memory).
>>>>>>> - Pick and implement a new machine learning algorithm for MLlib.
>>>>>>> Matei
>>>>>>> On Dec 17, 2013, at 10:43 AM, Matthew Cheah <
>> mccheah@uwaterloo.ca>
>>>>>> wrote:
>>>>>>>> Hi everyone,
>>>>>>>>=20
>>>>>>>> During my most recent internship, I worked extensively with
>> Apache
>>>>>> Spark,
>>>>>>>> integrating it into a company's data analytics platform. I've
>> now
>>>>> become
>>>>>>>> interested in contributing to Apache Spark.
>>>>>>>>=20
>>>>>>>> I'm returning to undergraduate studies in January and there is
>> an
>>>>>> academic
>>>>>>>> course which is simply a standalone software engineering
>> project.
>>> I
>>>>> was
>>>>>>>> thinking that some contribution to Apache Spark would satisfy my
>>>>>> curiosity,
>>>>>>>> help continue support the company I interned at, and give me
>>>> academic
>>>>>>>> credits required to graduate, all at the same time. It seems
>> like
>>>> too
>>>>>> good
>>>>>>>> an opportunity to pass up.
>>>>>>>>=20
>>>>>>>> With that in mind, I have the following questions:
>>>>>>>>=20
>>>>>>>>  1. At this point, is there any self-contained project that I
>>> could
>>>>>> work
>>>>>>>>  on within Spark? Ideally, I would work on it independently, in
>>>>> about a
>>>>>>>>  three month time frame. This time also needs to accommodate
>>>> ramping
>>>>>> up on
>>>>>>>>  the Spark codebase and adjusting to the Scala programming
>>> language
>>>>> and
>>>>>>>>  paradigms. The company I worked at primarily used the Java
>> APIs.
>>>> The
>>>>>> output
>>>>>>>>  needs to be a technical report describing the project
>>>> requirements,
>>>>>> and the
>>>>>>>>  design process I took to engineer the solution for the
>>>> requirements.
>>>>>> In
>>>>>>>>  particular, it cannot just be a series of haphazard patches.
>>>>>>>>  2. How can I get started with contributing to Spark?
>>>>>>>>  3. Is there a high-level UML or some other design
>> specification
>>>> for
>>>>>> the
>>>>>>>>  Spark architecture?
>>>>>>>>=20
>>>>>>>> Thanks! I hope to be of some help =3D)
>>>>>>>>=20
>>>>>>>> -Matt Cheah
>>=20

From dev-return-970-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 06:49:38 2013
Return-Path: <dev-return-970-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A48D5104C1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 06:49:38 +0000 (UTC)
Received: (qmail 43574 invoked by uid 500); 20 Dec 2013 06:49:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43528 invoked by uid 500); 20 Dec 2013 06:49:31 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 43507 invoked by uid 99); 20 Dec 2013 06:49:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:49:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of andykonwinski@gmail.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 06:49:22 +0000
Received: by mail-we0-f169.google.com with SMTP id w61so2076007wes.28
        for <multiple recipients>; Thu, 19 Dec 2013 22:49:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/8Ov9KEHNln3Tty8EmJpCs93uAd3zZau1RDR5UbYjVM=;
        b=n+YzXbzF9KlfaMBZQ3nRPGuudF/rLzQ4G4GIJy9X5rsxmnQRccqTGJEB3kt4p3vkBE
         N1seO9yOisMklKuHaamTPq2ZWBntzgpwjGqVZ/7VQzLlHb8QidqGC+CgjPbgFe0cdzHX
         ONA1y3Ua7FrgPsdBe2Kmv0U5Q6qxcdNZgtlrdgT1HeAH+pomEFX2zrSzSEwKMmRePzdX
         psaT6Asu5rqxYg/TwTUUsjVyCBc8iYEuk6/AtBSh2Vejtj0XgodRN/PTC8o+BCoFaYM5
         UgtB9tS82CMjdl6VlfwbA8AguK7b0qtF7b6jqc63+VhcV2zrYdfi+FfT/6cwvQ1FkZ3f
         0YEA==
MIME-Version: 1.0
X-Received: by 10.194.189.42 with SMTP id gf10mr5285389wjc.24.1387522141989;
 Thu, 19 Dec 2013 22:49:01 -0800 (PST)
Received: by 10.216.26.1 with HTTP; Thu, 19 Dec 2013 22:49:01 -0800 (PST)
In-Reply-To: <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
Date: Thu, 19 Dec 2013 22:49:01 -0800
Message-ID: <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: user@spark.incubator.apache.org
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, 
	"spark-users@googlegroups.com" <spark-users@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7bb04bd264311604edf1ac71
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bb04bd264311604edf1ac71
Content-Type: text/plain; charset=ISO-8859-1

I've set up two new unofficial google groups to mirror the Apache Spark
user and dev lists:

https://groups.google.com/forum/#!forum/apache-spark-dev-mirror
https://groups.google.com/forum/#!forum/apache-spark-user-mirror

Basically these lists each subscribe to the corresponding Apache list.

They do not allow folks to subscribe directly to them. Getting emails from
the Google Group would offer no advantages that I can think of and we
really want to encourage folks to sign up for the official mailing list
instead.

The lists do allow the public to send email to them, which I think might be
necessary since the "from:" field for all emails that get distributed via
the Apache mailing list is set to the author of the email.

I think this might be a great compromise. At least we can try this out and
see how it goes.

Matei, can you confirm that Jan 1 is the date we want to turn off the
existing spark-users google group?

We could consider using the existing spark-developers and spark-users
google groups instead of the two new ones I just created but I think that
it is much more obvious to have the lists include the word mirror in their
names.

The dev list mirror seems to be working, because I see the last couple
emails from this thread in it already. I'll confirm and ensure that the
user list mirror is working too.

Thoughts?

Andy

P.S. Thanks to Patrick for suggesting this to me originally.

On Thu, Dec 19, 2013 at 8:46 PM, Aaron Davidson <ilikerps@gmail.com> wrote:

> I'd be fine with one-way mirrors here (Apache threads being reflected in
> Google groups) -- I have no idea how one is supposed to navigate the Apache
> list to look for historic threads.
>
>
> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote:
>
>> Thanks very much for the prompt and comprehensive reply!  I appreciate
>> the overarching desire to integrate with apache: I'm very happy to hear
>> that there's a move to use the existing groups as mirrors: that will
>> overcome all of my objections: particularly if it's bidirectional! :)
>>
>>
>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>>
>>> Hey Mike,
>>>
>>> As you probably noticed when you CC'd spark-de...@googlegroups.com,
>>> that list has already be reconfigured so that it no longer allows posting
>>> (and bounces emails sent to it).
>>>
>>> We will be doing the same thing to the spark...@googlegroups.com list
>>> too (we'll announce a date for that soon).
>>>
>>> That may sound very frustrating, and you are *not* alone feeling that
>>> way. We've had a long conversation with our mentors about this, and I've
>>> felt very similar to you, so I'd like to give you background.
>>>
>>> As I'm coming to see it, part of becoming an Apache project is moving
>>> the community *fully* over to Apache infrastructure, and more generally the
>>> Apache way of organizing the community.
>>>
>>> This applies in both the nuts-and-bolts sense of being on apache infra,
>>> but possibly more importantly, it is also a guiding principle and way of
>>> thinking.
>>>
>>> In various ways, moving to apache Infra can be a painful process, and
>>> IMO the loss of all the great mailing list functionality that comes with
>>> using Google Groups is perhaps the most painful step. But basically, the de
>>> facto mailing lists need to be the Apache ones, and not Google Groups. The
>>> underlying reason is that Apache needs to take full accountability for
>>> recording and publishing the mailing lists, it has to be able to
>>> institutionally guarantee this. This is because discussion on mailing lists
>>> is one of the core things that defines an Apache community. So at a minimum
>>> this means Apache owning the master copy of the bits.
>>>
>>> All that said, we are discussing the possibility of having a google
>>> group that subscribes to each list that would provide an easier to use and
>>> prettier archive for each list (so far we haven't gotten that to work).
>>>
>>> I hope this was helpful. It has taken me a few years now, and a lot of
>>> conversations with experienced (and patient!) Apache mentors, to
>>> internalize some of the nuance about "the Apache way". That's why I wanted
>>> to share.
>>>
>>> Andy
>>>
>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:
>>>
>>>> I notice that there are still a lot of active topics in this group: and
>>>> also activity on the apache mailing list (which is a really horrible
>>>> experience!).  Is it a firm policy on apache's front to disallow external
>>>> groups?  I'm going to be ramping up on spark, and I really hate the idea of
>>>> having to rely on the apache archives and my mail client.  Also: having to
>>>> search for topics/keywords both in old threads (here) as well as new
>>>> threads in apache's (clunky) archive, is going to be a pain!  I almost feel
>>>> like I must be missing something because the current solution seems
>>>> unfeasibly awkward!
>>>>
>>>>  --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "Spark Users" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to spark-users...@googlegroups.com.
>>>>
>>>> For more options, visit https://groups.google.com/groups/opt_out.
>>>>
>>>
>>>
>

--047d7bb04bd264311604edf1ac71--

From dev-return-971-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 07:10:01 2013
Return-Path: <dev-return-971-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9CAB010571
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 07:10:01 +0000 (UTC)
Received: (qmail 65273 invoked by uid 500); 20 Dec 2013 07:09:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65169 invoked by uid 500); 20 Dec 2013 07:09:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 65130 invoked by uid 99); 20 Dec 2013 07:09:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 07:09:57 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.173 as permitted sender)
Received: from [209.85.192.173] (HELO mail-pd0-f173.google.com) (209.85.192.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 07:09:50 +0000
Received: by mail-pd0-f173.google.com with SMTP id p10so2169095pdj.32
        for <multiple recipients>; Thu, 19 Dec 2013 23:09:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=hoEAx9y/1VFIw1j6nSF1oaslAgeDdI5L+fQQFUs4Ucc=;
        b=P+WZeUEpO3d0ENxeyX2c999DWm6PENTg2BtjtdljS8LDSsM1EFwUyQr6NPnK6jShok
         THHlFwVCJw4BLHPKDu+bMotg+/86L7V0DnraPntGoMTzU/4NmUa1522SgEM6iGR7fmeq
         8RHvVq8C0cNlA3UJQNRgVl9QjF3aBkb74u1atX0vbFFu1jUN3XA7/JCclVcFCwNrsljI
         5OxBw3I7hgGPEHRlORetbtQTTHlKxPKFnSBOO+6EkUH5plOmjI3PT8Vww7SHesQ4p3l9
         CG36QqXVleK4Iyr3URg6O11gMd8YQBvvIrcqqMS67GGzztorBee+Hk++ei3FkK0bgvvu
         +hSA==
X-Received: by 10.66.154.75 with SMTP id vm11mr6807174pab.124.1387523369023;
        Thu, 19 Dec 2013 23:09:29 -0800 (PST)
Received: from [192.168.1.106] (c-24-7-114-112.hsd1.ca.comcast.net. [24.7.114.112])
        by mx.google.com with ESMTPSA id hw10sm12040095pbc.24.2013.12.19.23.09.26
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 19 Dec 2013 23:09:27 -0800 (PST)
Content-Type: multipart/alternative; boundary="Apple-Mail=_BF8A1AA6-08DD-465B-B322-712AA58BD409"
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
Date: Thu, 19 Dec 2013 23:09:25 -0800
Cc: user@spark.incubator.apache.org,
 "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Message-Id: <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com> <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com> <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com> <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com> <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com> <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
To: spark-users@googlegroups.com
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_BF8A1AA6-08DD-465B-B322-712AA58BD409
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

Yes, I agree that we should close down the existing Google group on Jan =
1st. While it=92s more convenient to use, it=92s created confusion. I =
hope that we can get the ASF to support better search interfaces in the =
future too. I think we just have to drive this from within.

The Google Group should be a nice way to make the content searchable =
from the web. We should also see what it takes to make it mirrored on =
Nabble (http://www.nabble.com). I=92ve found a lot of information about =
other projects there, and other Apache projects do use it.

Matei

On Dec 19, 2013, at 10:49 PM, Andy Konwinski <andykonwinski@gmail.com> =
wrote:

> I've set up two new unofficial google groups to mirror the Apache =
Spark user and dev lists:
>=20
> https://groups.google.com/forum/#!forum/apache-spark-dev-mirror
> https://groups.google.com/forum/#!forum/apache-spark-user-mirror
>=20
> Basically these lists each subscribe to the corresponding Apache list.
>=20
> They do not allow folks to subscribe directly to them. Getting emails =
from the Google Group would offer no advantages that I can think of and =
we really want to encourage folks to sign up for the official mailing =
list instead.
>=20
> The lists do allow the public to send email to them, which I think =
might be necessary since the "from:" field for all emails that get =
distributed via the Apache mailing list is set to the author of the =
email.
>=20
> I think this might be a great compromise. At least we can try this out =
and see how it goes.
>=20
> Matei, can you confirm that Jan 1 is the date we want to turn off the =
existing spark-users google group?
>=20
> We could consider using the existing spark-developers and spark-users =
google groups instead of the two new ones I just created but I think =
that it is much more obvious to have the lists include the word mirror =
in their names.
>=20
> The dev list mirror seems to be working, because I see the last couple =
emails from this thread in it already. I'll confirm and ensure that the =
user list mirror is working too.
>=20
> Thoughts?
>=20
> Andy
>=20
> P.S. Thanks to Patrick for suggesting this to me originally.
>=20
> On Thu, Dec 19, 2013 at 8:46 PM, Aaron Davidson <ilikerps@gmail.com> =
wrote:
> I'd be fine with one-way mirrors here (Apache threads being reflected =
in Google groups) -- I have no idea how one is supposed to navigate the =
Apache list to look for historic threads.
>=20
>=20
> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> =
wrote:
> Thanks very much for the prompt and comprehensive reply!  I appreciate =
the overarching desire to integrate with apache: I'm very happy to hear =
that there's a move to use the existing groups as mirrors: that will =
overcome all of my objections: particularly if it's bidirectional! :)
>=20
>=20
> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
> Hey Mike,
>=20
> As you probably noticed when you CC'd spark-de...@googlegroups.com, =
that list has already be reconfigured so that it no longer allows =
posting (and bounces emails sent to it).
>=20
> We will be doing the same thing to the spark...@googlegroups.com list =
too (we'll announce a date for that soon).
>=20
> That may sound very frustrating, and you are *not* alone feeling that =
way. We've had a long conversation with our mentors about this, and I've =
felt very similar to you, so I'd like to give you background.
>=20
> As I'm coming to see it, part of becoming an Apache project is moving =
the community *fully* over to Apache infrastructure, and more generally =
the Apache way of organizing the community.
>=20
> This applies in both the nuts-and-bolts sense of being on apache =
infra, but possibly more importantly, it is also a guiding principle and =
way of thinking.
>=20
> In various ways, moving to apache Infra can be a painful process, and =
IMO the loss of all the great mailing list functionality that comes with =
using Google Groups is perhaps the most painful step. But basically, the =
de facto mailing lists need to be the Apache ones, and not Google =
Groups. The underlying reason is that Apache needs to take full =
accountability for recording and publishing the mailing lists, it has to =
be able to institutionally guarantee this. This is because discussion on =
mailing lists is one of the core things that defines an Apache =
community. So at a minimum this means Apache owning the master copy of =
the bits.=20
>=20
> All that said, we are discussing the possibility of having a google =
group that subscribes to each list that would provide an easier to use =
and prettier archive for each list (so far we haven't gotten that to =
work).
>=20
> I hope this was helpful. It has taken me a few years now, and a lot of =
conversations with experienced (and patient!) Apache mentors, to =
internalize some of the nuance about "the Apache way". That's why I =
wanted to share.
>=20
> Andy
>=20
> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:
> I notice that there are still a lot of active topics in this group: =
and also activity on the apache mailing list (which is a really horrible =
experience!).  Is it a firm policy on apache's front to disallow =
external groups?  I'm going to be ramping up on spark, and I really hate =
the idea of having to rely on the apache archives and my mail client.  =
Also: having to search for topics/keywords both in old threads (here) as =
well as new threads in apache's (clunky) archive, is going to be a pain! =
 I almost feel like I must be missing something because the current =
solution seems unfeasibly awkward!
>=20
>=20
> --=20
> You received this message because you are subscribed to the Google =
Groups "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send =
an email to spark-users...@googlegroups.com.
>=20
> For more options, visit https://groups.google.com/groups/opt_out.
>=20
>=20
>=20
>=20
> --=20
> You received this message because you are subscribed to the Google =
Groups "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send =
an email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.


--Apple-Mail=_BF8A1AA6-08DD-465B-B322-712AA58BD409--

From dev-return-972-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 08:16:12 2013
Return-Path: <dev-return-972-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E8EE3106A7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 08:16:12 +0000 (UTC)
Received: (qmail 35887 invoked by uid 500); 20 Dec 2013 08:16:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35711 invoked by uid 500); 20 Dec 2013 08:16:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 35695 invoked by uid 99); 20 Dec 2013 08:16:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 08:16:01 +0000
X-ASF-Spam-Status: No, hits=2.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.160.53 as permitted sender)
Received: from [209.85.160.53] (HELO mail-pb0-f53.google.com) (209.85.160.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 08:15:55 +0000
Received: by mail-pb0-f53.google.com with SMTP id ma3so2288600pbc.12
        for <dev@spark.incubator.apache.org>; Fri, 20 Dec 2013 00:15:33 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=USRWZvUTCHzLiJXaauaT8W/qmjGeJlZ2pitKz2ESY0s=;
        b=lpqT78RpN93tu17PYRIGbMNuS/zWuR3/zx/lVgEpejUva60GnlFwiTWd7A3lEXqOG2
         eGaptoubxsJDujS3WgCmeuYSOuSBlY1Qp7xQsRYpEcalvHs2GkYCITWPSiM5TDFWNQht
         hOOwRBzj8rBmBM3RH5HvSaCv0VN6RfJIbRjues8i7ZNFCrpHhPPqETLfoe4k7qjJ0s1x
         3jGYfaql3ygksJnKlMHoIpZSMuKXOlCnY8pbN0FipQ1GEnKXlEdSFo/JLgIYRaKbFeKZ
         jOXGAHxArV7kjnRhRnyAcJ/cL+avG3V7TSyxoTPo0hfbXAhA8+SeaQfmhBqJNvuE9Uzl
         XCBA==
MIME-Version: 1.0
X-Received: by 10.68.29.4 with SMTP id f4mr6935874pbh.85.1387527333757; Fri,
 20 Dec 2013 00:15:33 -0800 (PST)
Received: by 10.68.245.69 with HTTP; Fri, 20 Dec 2013 00:15:33 -0800 (PST)
Received: by 10.68.245.69 with HTTP; Fri, 20 Dec 2013 00:15:33 -0800 (PST)
In-Reply-To: <C6A9C8CF-9015-4111-B35A-19FA44A55D79@gmail.com>
References: <93F5136B-239D-4960-95B3-727046C75172@gmail.com>
	<1387478305969.35e7931@Nodemailer>
	<CA+-p3AH-asPsqJ8yzDUzBYy9+6H3-=ua6CyMSiv80zG8zJAy-Q@mail.gmail.com>
	<CAGh_TuM5gqo0eORuiYhBCFbn4DTE3F1rYrpYnOhLh7j0ScHDxg@mail.gmail.com>
	<CAHH8_OM=smwpw3++ROy38d05ieYBoHK64G-dWysJu21Nd3=Tzw@mail.gmail.com>
	<CA+-p3AG00DDCCgkjdoW4m2g+vkbktwcfDa_p0C8Akcnr1ef_nA@mail.gmail.com>
	<CAMwrk0kzw1bKYyt=hd2NyiyZyUVs+pqh9biSSLL5rmmpfecWzQ@mail.gmail.com>
	<C6A9C8CF-9015-4111-B35A-19FA44A55D79@gmail.com>
Date: Fri, 20 Dec 2013 00:15:33 -0800
Message-ID: <CA+B-+fxOoux2k4ij2vSnnJUjw0DKxZv3AEuPgtUihQ22sVXTkg@mail.gmail.com>
Subject: Re: Spark development for undergraduate project
From: Debasish Das <debasish.das83@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=bcaec520f3f1d84b7b04edf2e11a
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec520f3f1d84b7b04edf2e11a
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Decision trees, random forest, professor Hastie's gbdt R package are also
nice to have...

Gbdt 1 algorithm is in 0xdata and that too netflix guys were complaining it
does not scale beyond 1000 trees :)
 On Dec 19, 2013 10:18 PM, "Nick Pentreath" <nick.pentreath@gmail.com>
wrote:

> Another option would be:
> 1. Add another recommendation model based on mrec's sgd based model:
> https://github.com/mendeley/mrec
> 2. Look at the streaming K-means from Mahout and see if that might be
> integrated or adapted into MLlib
> 3. Work on adding to or refactoring the existing linear model framework,
> for example adaptive learning rate schedules, adaptive norm stuff from Jo=
hn
> Langford et al
> 4. Adding sparse vector/matrix support to MLlib?
>
> Sent from my iPad
>
> > On 20 Dec 2013, at 3:46 AM, Tathagata Das <tathagata.das1565@gmail.com>
> wrote:
> >
> > +1 to that (assuming by 'online' Andrew meant MLLib algorithm from Spar=
k
> > Streaming)
> >
> > Something you can look into is implementing a streaming KMeans. Maybe y=
ou
> > can re-use a lot of the offline KMeans code in MLLib.
> >
> > TD
> >
> >
> >> On Thu, Dec 19, 2013 at 5:33 PM, Andrew Ash <andrew@andrewash.com>
> wrote:
> >>
> >> Sounds like a great choice.  It would be particularly impressive if yo=
u
> >> could add the first online learning algorithm (all the current ones ar=
e
> >> offline I believe) to pave the way for future contributions.
> >>
> >>
> >> On Thu, Dec 19, 2013 at 8:27 PM, Matthew Cheah <mccheah@uwaterloo.ca>
> >> wrote:
> >>
> >>> Thanks a lot everyone! I'm looking into adding an algorithm to MLib f=
or
> >> the
> >>> project. Nice and self-contained.
> >>>
> >>> -Matt Cheah
> >>>
> >>>
> >>> On Thu, Dec 19, 2013 at 12:52 PM, Christopher Nguyen <ctn@adatao.com>
> >>> wrote:
> >>>
> >>>> +1 to most of Andrew's suggestions here, and while we're in that
> >>>> neighborhood, how about generalizing something like "wtf-spark" (fro=
m
> >> the
> >>>> Bizo team (http://youtu.be/6Sn1xs5DN1Y?t=3D38m36s)? It may not be of
> >> high
> >>>> academic interest, but it's something people would use many times a
> >>>> debugging day.
> >>>>
> >>>> Or am I behind and something like that is already there in 0.8?
> >>>>
> >>>> --
> >>>> Christopher T. Nguyen
> >>>> Co-founder & CEO, Adatao <http://adatao.com>
> >>>> linkedin.com/in/ctnguyen
> >>>>
> >>>>
> >>>>
> >>>>> On Thu, Dec 19, 2013 at 10:56 AM, Andrew Ash <andrew@andrewash.com>
> >>>> wrote:
> >>>>
> >>>>> I think there are also some improvements that could be made to
> >>>>> deployability in an enterprise setting.  From my experience:
> >>>>>
> >>>>> 1. Most places I deploy Spark in don't have internet access.  So I
> >>> can't
> >>>>> build from source, compile against a different version of Hadoop, e=
tc
> >>>>> without doing it locally and then getting that onto my servers
> >>> manually.
> >>>>> This is less a problem with Spark now that there are binary
> >>>> distributions,
> >>>>> but it's still a problem for using Mesos with Spark.
> >>>>> 2. Configuration of Spark is confusing -- you can make configuratio=
n
> >> in
> >>>>> Java system properties, environment variables, command line
> >> parameters,
> >>>> and
> >>>>> for the standalone cluster deployment mode you need to worry about
> >>>> whether
> >>>>> these need to be set on the master, the worker, the executor, or th=
e
> >>>>> application/driver program.  Also because spark-shell automatically
> >>>>> instantiates a SparkContext you have to set up any system propertie=
s
> >> in
> >>>> the
> >>>>> init scripts or on the command line with
> >>>>> JAVA_OPTS=3D"-Dspark.executor.memory=3D8g" etc.  I'm not sure what =
needs
> >> to
> >>>> be
> >>>>> done, but it feels that there are gains to be made in configuration
> >>>> options
> >>>>> here.  Ideally, I would have one configuration file that can be use=
d
> >> in
> >>>> all
> >>>>> 4 places and that's the only place to make configuration changes.
> >>>>> 3. Standalone cluster mode could use improved resiliency for
> >> starting,
> >>>>> stopping, and keeping alive a service -- there are custom init
> >> scripts
> >>>> that
> >>>>> call each other in a mess of ways: spark-shell, spark-daemon.sh,
> >>>>> spark-daemons.sh, spark-config.sh, spark-env.sh,
> >> compute-classpath.sh,
> >>>>> spark-executor, spark-class, run-example, and several others in the
> >>> bin/
> >>>>> directory.  I would love it if Spark used the Tanuki Service Wrappe=
r,
> >>>> which
> >>>>> is widely-used for Java service daemons, supports retries,
> >> installation
> >>>> as
> >>>>> init scripts that can be chkconfig'd, etc.  Let's not re-solve the
> >> "how
> >>>> do
> >>>>> I keep a service running?" problem when it's been done so well by
> >>> Tanuki
> >>>> --
> >>>>> we use it at my day job for all our services, plus it's used by
> >>>>> Elasticsearch.  This would help solve the problem where a quick
> >> bounce
> >>> of
> >>>>> the master causes all the workers to self-destruct.
> >>>>> 4. Sensitivity to hostname vs FQDN vs IP address in spark URL -- th=
is
> >>> is
> >>>>> entirely an Akka bug based on previous mailing list discussion with
> >>>> Matei,
> >>>>> but it'd be awesome if you could use either the hostname or the FQD=
N
> >> or
> >>>> the
> >>>>> IP address in the Spark URL and not have Akka barf at you.
> >>>>>
> >>>>> I've been telling myself I'd look into these at some point but just
> >>>> haven't
> >>>>> gotten around to them myself yet.  Some day!  I would prioritize
> >> these
> >>>>> requests from most- to least-important as 3, 2, 4, 1.
> >>>>>
> >>>>> Andrew
> >>>>>
> >>>>>
> >>>>> On Thu, Dec 19, 2013 at 1:38 PM, Nick Pentreath <
> >>>> nick.pentreath@gmail.com
> >>>>>> wrote:
> >>>>>
> >>>>>> Or if you're extremely ambitious work in implementing Spark
> >> Streaming
> >>>> in
> >>>>>> Python=97
> >>>>>> Sent from Mailbox for iPhone
> >>>>>>
> >>>>>> On Thu, Dec 19, 2013 at 8:30 PM, Matei Zaharia <
> >>>> matei.zaharia@gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> Hi Matt,
> >>>>>>> If you want to get started looking at Spark, I recommend the
> >>>> following
> >>>>>> resources:
> >>>>>>> - Our issue tracker at http://spark-project.atlassian.netcontains
> >>>>> some
> >>>>>> issues marked =93Starter=94 that are good places to jump into. You
> >> might
> >>> be
> >>>>>> able to take one of those and extend it into a bigger project.
> >>>>>>> - The =93contributing to Spark=94 wiki page covers how to send
> >> patches
> >>>> and
> >>>>>> set up development:
> >> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spar=
k
> >>>>>>> - This talk has an intro to Spark internals (video and slides are
> >>> in
> >>>>> the
> >>>>>> comments): http://www.meetup.com/spark-users/events/94101942/
> >>>>>>> For a longer project, here are some possible ones:
> >>>>>>> - Create a tool that automatically checks which Scala API methods
> >>> are
> >>>>>> missing in Python. We had a similar one for Java that was very
> >>> useful.
> >>>>> Even
> >>>>>> better would be to automatically create wrappers for the Scala
> >> ones.
> >>>>>>> - Extend the Spark monitoring UI with profiling information (to
> >>>> sample
> >>>>>> the workers and say where they=92re spending time, or what data
> >>>> structures
> >>>>>> consume the most memory).
> >>>>>>> - Pick and implement a new machine learning algorithm for MLlib.
> >>>>>>> Matei
> >>>>>>> On Dec 17, 2013, at 10:43 AM, Matthew Cheah <
> >> mccheah@uwaterloo.ca>
> >>>>>> wrote:
> >>>>>>>> Hi everyone,
> >>>>>>>>
> >>>>>>>> During my most recent internship, I worked extensively with
> >> Apache
> >>>>>> Spark,
> >>>>>>>> integrating it into a company's data analytics platform. I've
> >> now
> >>>>> become
> >>>>>>>> interested in contributing to Apache Spark.
> >>>>>>>>
> >>>>>>>> I'm returning to undergraduate studies in January and there is
> >> an
> >>>>>> academic
> >>>>>>>> course which is simply a standalone software engineering
> >> project.
> >>> I
> >>>>> was
> >>>>>>>> thinking that some contribution to Apache Spark would satisfy my
> >>>>>> curiosity,
> >>>>>>>> help continue support the company I interned at, and give me
> >>>> academic
> >>>>>>>> credits required to graduate, all at the same time. It seems
> >> like
> >>>> too
> >>>>>> good
> >>>>>>>> an opportunity to pass up.
> >>>>>>>>
> >>>>>>>> With that in mind, I have the following questions:
> >>>>>>>>
> >>>>>>>>  1. At this point, is there any self-contained project that I
> >>> could
> >>>>>> work
> >>>>>>>>  on within Spark? Ideally, I would work on it independently, in
> >>>>> about a
> >>>>>>>>  three month time frame. This time also needs to accommodate
> >>>> ramping
> >>>>>> up on
> >>>>>>>>  the Spark codebase and adjusting to the Scala programming
> >>> language
> >>>>> and
> >>>>>>>>  paradigms. The company I worked at primarily used the Java
> >> APIs.
> >>>> The
> >>>>>> output
> >>>>>>>>  needs to be a technical report describing the project
> >>>> requirements,
> >>>>>> and the
> >>>>>>>>  design process I took to engineer the solution for the
> >>>> requirements.
> >>>>>> In
> >>>>>>>>  particular, it cannot just be a series of haphazard patches.
> >>>>>>>>  2. How can I get started with contributing to Spark?
> >>>>>>>>  3. Is there a high-level UML or some other design
> >> specification
> >>>> for
> >>>>>> the
> >>>>>>>>  Spark architecture?
> >>>>>>>>
> >>>>>>>> Thanks! I hope to be of some help =3D)
> >>>>>>>>
> >>>>>>>> -Matt Cheah
> >>
>

--bcaec520f3f1d84b7b04edf2e11a--

From dev-return-973-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 16:19:32 2013
Return-Path: <dev-return-973-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 29EB91076E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 16:19:32 +0000 (UTC)
Received: (qmail 21877 invoked by uid 500); 20 Dec 2013 16:18:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21835 invoked by uid 500); 20 Dec 2013 16:18:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 21811 invoked by uid 99); 20 Dec 2013 16:18:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:18:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of maspotts@gmail.com designates 209.85.220.60 as permitted sender)
Received: from [209.85.220.60] (HELO mail-pa0-f60.google.com) (209.85.220.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:18:32 +0000
Received: by mail-pa0-f60.google.com with SMTP id fa1so446822pad.15
        for <multiple recipients>; Fri, 20 Dec 2013 08:18:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=JEHDb/PgCxnNqbW9dY1l14Gq82qs2jvIQJIN9Weemnk=;
        b=CdGAZhWUKxbaou71fbz+cpniZBQvlSQZvUTcZGiWBoTPOXA79dwzAzi4f2S08onRxh
         lfQQ6jNkXiokdypHZ8SwY3Z+2fZ4xvepbY71KM+Rrpqhvhlv37mXvjYRz1BGnvnVises
         rcCtWg3Cb/J3N76PpZ5ajjHU5n+q+rbpjeEo2BaXYr4Ed1ysZ/lNmFkzlD7fXayYpSOA
         ixRJu5JjCeqgB915sRBFBxgkUyBjWkj5oAsfnJjm+yGcLaNJEWjhVFiDeTYZYYNH++tD
         otf6qqnsK0hhilJVnk1sWxC82ohXEigLbo7E4IFIxwNtqUhkMVgTum/iX3+zkHn51aOW
         Z4cw==
X-Received: by 10.50.239.132 with SMTP id vs4mr205479igc.4.1387556291776;
        Fri, 20 Dec 2013 08:18:11 -0800 (PST)
X-Google-Doc-Id: caa9699bffaf22ae
X-Google-Web-Client: true
Date: Fri, 20 Dec 2013 08:18:10 -0800 (PST)
From: Mike Potts <maspotts@gmail.com>
To: spark-users@googlegroups.com
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Message-Id: <5c6028f9-b470-41ed-99d4-88f41df4bd00@googlegroups.com>
In-Reply-To: <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com> <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com> <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com> <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com> <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com> <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
 <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September
 1st
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_794_5487781.1387556290663"
X-Google-Token: EMLb0ZUFT69DB3CcnSY0
X-Google-IP: 75.25.125.13
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_794_5487781.1387556290663
Content-Type: multipart/alternative; 
	boundary="----=_Part_795_25565890.1387556290663"

------=_Part_795_25565890.1387556290663
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

This is great!  Could the new *-mirror groups start off with a complete 
copy of the (closed) original groups and the apache lists?  (So as to avoid 
having to search 3 different sources for historical information.)

------=_Part_795_25565890.1387556290663
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<div dir="ltr">This is great! &nbsp;Could the new *-mirror groups start off with a complete copy of the (closed) original groups and the apache lists? &nbsp;(So as to avoid having to search 3 different sources for historical information.)</div>
------=_Part_795_25565890.1387556290663--

------=_Part_794_5487781.1387556290663--

From dev-return-974-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 16:30:24 2013
Return-Path: <dev-return-974-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 78AA1107E1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 16:30:24 +0000 (UTC)
Received: (qmail 43778 invoked by uid 500); 20 Dec 2013 16:30:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43712 invoked by uid 500); 20 Dec 2013 16:30:08 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 43692 invoked by uid 99); 20 Dec 2013 16:30:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:30:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of andykonwinski@gmail.com designates 74.125.82.177 as permitted sender)
Received: from [74.125.82.177] (HELO mail-we0-f177.google.com) (74.125.82.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:30:00 +0000
Received: by mail-we0-f177.google.com with SMTP id u56so2623051wes.8
        for <multiple recipients>; Fri, 20 Dec 2013 08:29:40 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=pZwFaKmG4GuWiUB3lk4jh4oyd/xLPiBGfk0j6XHeCqU=;
        b=BaBDCd3vmCbJm0W5TGbJ+zY6Xpt7qjvxJpQF0Ax4Km9kiX4uWGJAm1vYbEh6y6xF1g
         WLFck3RmqotVVxgx/2y4mC0PD179bIIy6DYOAnASYtzmWs3+3dr6U8JjosaNYHpjCOII
         +kZ6hGQ7NhrTYp32xtg2RiZa9pUKkK8fKZ0AWmznh1zpewz3cDGpvo2pa7Fra9N/Mp3U
         viz3yiWsf1MGu7ChHW6QizDFzT6778iM3XyUgA1uRG8McIyE5i6STisouWpOE7WCRpQC
         9CmkSynLSuF8pgvHjAfHnIuoCoi/DpeXP2immX3nowXCzudhy4ImgOhwNLrpdcPSWFp/
         hGeA==
MIME-Version: 1.0
X-Received: by 10.194.142.174 with SMTP id rx14mr7492178wjb.45.1387556980404;
 Fri, 20 Dec 2013 08:29:40 -0800 (PST)
Received: by 10.216.26.1 with HTTP; Fri, 20 Dec 2013 08:29:40 -0800 (PST)
Received: by 10.216.26.1 with HTTP; Fri, 20 Dec 2013 08:29:40 -0800 (PST)
In-Reply-To: <5c6028f9-b470-41ed-99d4-88f41df4bd00@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<5c6028f9-b470-41ed-99d4-88f41df4bd00@googlegroups.com>
Date: Fri, 20 Dec 2013 08:29:40 -0800
Message-ID: <CALEZFQwiOibtj3HYY-Dx3sQszEgxJjO=3WirznUp0nNO0fasyw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: spark-users@googlegroups.com
Cc: dev@spark.incubator.apache.org, user@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e01176ee3ec37f704edf9c879
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01176ee3ec37f704edf9c879
Content-Type: text/plain; charset=ISO-8859-1

That would be really awesome. I'm not familiar with any Google Groups
functionality that supports that but I'll look.

That's an argument for maybe just changing the names of the existing groups
to something with mirror in them instead of using newly created ones.
On Dec 20, 2013 8:18 AM, "Mike Potts" <maspotts@gmail.com> wrote:

> This is great!  Could the new *-mirror groups start off with a complete
> copy of the (closed) original groups and the apache lists?  (So as to avoid
> having to search 3 different sources for historical information.)
>
> --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>

--089e01176ee3ec37f704edf9c879--

From dev-return-975-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 16:36:00 2013
Return-Path: <dev-return-975-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2B68B1081E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 16:36:00 +0000 (UTC)
Received: (qmail 55610 invoked by uid 500); 20 Dec 2013 16:35:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55571 invoked by uid 500); 20 Dec 2013 16:35:44 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 55410 invoked by uid 99); 20 Dec 2013 16:35:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:35:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of maspotts@gmail.com designates 209.85.213.192 as permitted sender)
Received: from [209.85.213.192] (HELO mail-ig0-f192.google.com) (209.85.213.192)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:35:31 +0000
Received: by mail-ig0-f192.google.com with SMTP id uq10so636289igb.9
        for <multiple recipients>; Fri, 20 Dec 2013 08:35:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=YePLfk497Qw35Uu2TBuGzTfm9dAppPEx9YMFU1QyQsQ=;
        b=XTa1uY/OLrRrGusMhmJoeL3ndSDN4qd5WAVV+BXNGJn01QXdbxRbhknVFLzzx9okrl
         RaYsvVycKg+SuedYavnjW6cLySXxBIjUCtXkBX+4j1ok7zN9FZgFOz0dBjKgu8gFEez+
         vKWHC2NUhYXzkEtp5GYTx0c4sjT3cQsTfjsm7BCxzOmJo8ucbyP3+ZeIX4OFpa4h4gdW
         DroSmNl5rYjV7gkgNXB6+JYxeRBjQ2LZyjcRozd/FEk9du3XcKYtniiISb/ht/r9oJKp
         3HxbWZl3E0e3k55xwXzsXQWU5jlYoLfdm2a7U9GgAUbcOGyMOO+K033yy6n5s3IcTAo7
         51TA==
X-Received: by 10.182.72.131 with SMTP id d3mr10537obv.39.1387557310832;
        Fri, 20 Dec 2013 08:35:10 -0800 (PST)
X-Google-Doc-Id: 6fa6995a4880cc27
X-Google-Web-Client: true
Date: Fri, 20 Dec 2013 08:35:10 -0800 (PST)
From: Mike Potts <maspotts@gmail.com>
To: spark-users@googlegroups.com
Cc: dev@spark.incubator.apache.org, user@spark.incubator.apache.org
Message-Id: <3015f716-41d1-477d-9ac7-7dc15dcdfa81@googlegroups.com>
In-Reply-To: <CALEZFQwiOibtj3HYY-Dx3sQszEgxJjO=3WirznUp0nNO0fasyw@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
 <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
 <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
 <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
 <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
 <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
 <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
 <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
 <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
 <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
 <5c6028f9-b470-41ed-99d4-88f41df4bd00@googlegroups.com>
 <CALEZFQwiOibtj3HYY-Dx3sQszEgxJjO=3WirznUp0nNO0fasyw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September
 1st
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="----=_Part_2_1672315.1387557310422"
X-Google-Token: EL7j0ZUFFc-O_BUmld40
X-Google-IP: 75.25.125.13
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_2_1672315.1387557310422
Content-Type: multipart/alternative; 
	boundary="----=_Part_3_21545724.1387557310422"

------=_Part_3_21545724.1387557310422
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I actually prefer that, but I didn't want my preference to get in the way 
of creating mirror groups, one way or the other :)  (My argument would be 
that since the old groups would be closing anyway, re-purposing them as 
mirrors is fair use: and less work/confusing than creating new *-mirror 
groups instead.)

On Friday, December 20, 2013 8:29:40 AM UTC-8, Andy Konwinski wrote:
>
> That would be really awesome. I'm not familiar with any Google Groups 
> functionality that supports that but I'll look.
>
> That's an argument for maybe just changing the names of the existing 
> groups to something with mirror in them instead of using newly created ones.
>

------=_Part_3_21545724.1387557310422
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<div dir="ltr">I actually prefer that, but I didn't want my preference to get in the way of creating mirror groups, one way or the other :) &nbsp;(My argument would be that since the old groups would be closing anyway, re-purposing them as mirrors is fair use: and less work/confusing than creating new *-mirror groups instead.)<br><br>On Friday, December 20, 2013 8:29:40 AM UTC-8, Andy Konwinski wrote:<blockquote class="gmail_quote" style="margin: 0;margin-left: 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;"><p dir="ltr">That would be really awesome. I'm not familiar with any Google Groups functionality that supports that but I'll look.</p>
<p dir="ltr">That's an argument for maybe just changing the names of the existing groups to something with mirror in them instead of using newly created ones.</p>
</blockquote></div>
------=_Part_3_21545724.1387557310422--

------=_Part_2_1672315.1387557310422--

From dev-return-976-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 16:37:58 2013
Return-Path: <dev-return-976-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B875710827
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 16:37:58 +0000 (UTC)
Received: (qmail 60129 invoked by uid 500); 20 Dec 2013 16:37:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60097 invoked by uid 500); 20 Dec 2013 16:37:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 60089 invoked by uid 99); 20 Dec 2013 16:37:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:37:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 74.125.82.179 as permitted sender)
Received: from [74.125.82.179] (HELO mail-we0-f179.google.com) (74.125.82.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 16:37:45 +0000
Received: by mail-we0-f179.google.com with SMTP id q59so2689917wes.38
        for <dev@spark.incubator.apache.org>; Fri, 20 Dec 2013 08:37:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=EGfcXgEJ3/swLT0+ytx7K5HyiF1mQ9uaAQ3Vz0ozTHk=;
        b=TDV2Xp7mr7FCus+1o3I33BUoY5DTmtX+isvxwOQFbCgCMkjHEYc8fiK+1Wc4IBQAQi
         cH5qmXOkpbIT6pePDDyTIgoQLC8sD1JUTxonT5HXzz7sAsNHqXVdT6ybV4ZJ4W4k17Cj
         WMHqLgAiApFvodK9GZ33nzhrf6g90W5hQOZjprwrmsreBdj10Zi7IavQ9IYRHlvWsJzH
         bdVCo76nZctNELMj2sImWKYLFv4rsKjSlBgWjmOO3fA0TFN7Y93y6dh5yGKh+lO455XD
         AuG8tc5OGjFgSn26lsrsD3A/CeCHoeBVKoBhFAjJvIwD/+HS0bSeMSdbkhk+gWTmOTUG
         iieQ==
MIME-Version: 1.0
X-Received: by 10.180.160.212 with SMTP id xm20mr8451935wib.33.1387557443935;
 Fri, 20 Dec 2013 08:37:23 -0800 (PST)
Received: by 10.217.132.69 with HTTP; Fri, 20 Dec 2013 08:37:23 -0800 (PST)
In-Reply-To: <CABPQxsuzAV5hdDQYjgfgSVF=j=7vDO=N=UshGj+6HCZuRvuNGQ@mail.gmail.com>
References: <CABPQxsuzAV5hdDQYjgfgSVF=j=7vDO=N=UshGj+6HCZuRvuNGQ@mail.gmail.com>
Date: Fri, 20 Dec 2013 08:37:23 -0800
Message-ID: <CALuGr6Z0a0rEp7dTLx3mk7dzpo1h_MT4XO_ESUUFrH4X5OHHWg@mail.gmail.com>
Subject: Re: Spark 0.8.1 Released
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Awesome as usual Patrick.

Thanks for driving the release as RM =)

- Henry

On Thu, Dec 19, 2013 at 5:15 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hi everyone,
>
> We've just posted Spark 0.8.1, a new maintenance release that contains
> some bug fixes and improvements to the 0.8 branch. The full release
> notes are available at [1]. Apart from various bug fixes, 0.8.1
> includes support for YARN 2.2, a high availability mode for the
> standalone scheduler, and optimizations to the shuffle. We recommend
> that current users update to this release. You can grab the release at
> [2].
>
> [1] http://spark.incubator.apache.org/releases/spark-release-0-8-1.html
> [2] http://spark.incubator.apache.org/downloads
>
> Thanks to the following people who contributed to this release:
>
> Michael Armbrust, Pierre Borckmans, Evan Chan, Ewen Cheslack, Mosharaf
> Chowdhury, Frank Dai, Aaron Davidson, Tathagata Das, Ankur Dave,
> Harvey Feng, Ali Ghodsi, Thomas Graves, Li Guoqiang, Stephen Haberman,
> Haidar Hadi, Nathan Howell, Holden Karau, Du Li, Raymond Liu, Xi Liu,
> David McCauley, Michael (wannabeast), Fabrizio Milo, Mridul
> Muralidharan, Sundeep Narravula, Kay Ousterhout, Nick Pentreath, Imran
> Rashid, Ahir Reddy, Josh Rosen, Henry Saputra, Jerry Shao, Mingfei
> Shi, Andre Schumacher, Karthik Tunga, Patrick Wendell, Neal Wiggins,
> Andrew Xia, Reynold Xin, Matei Zaharia, and Wu Zeming
>
> - Patrick

From dev-return-977-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 18:15:14 2013
Return-Path: <dev-return-977-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E576410ECB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 18:15:14 +0000 (UTC)
Received: (qmail 7881 invoked by uid 500); 20 Dec 2013 18:15:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7725 invoked by uid 500); 20 Dec 2013 18:15:14 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 92960 invoked by uid 99); 20 Dec 2013 18:08:45 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=dDQ3NnDXm/FS4Gp1z+68CPP4ZQ1aPjrLumg2dZJG1I0=;
        b=GDwWYeiavzgdEnZm/yToIJoLqfJLYCiRM5Vk5804Mzlig6Fdbvovj5WIhJ7I84mj2l
         XzIMwYVnZ2+OnCcETijEDbb+tCH9j+Ab1KF60r5pzKI5HwqiolnQLVCcjthfHn/B14Gx
         oTzyeUaVFG0WjPa/qckTfnXchDvMIYH3uw1OPyvKeQlAjkGLb5fH6ZCAwA4Yl4sXFGRc
         muGOG2j7ZBHArAw1VJrkJHA+fLLqnPUrO/t3fpaFGxaJh2JZrtrk1VEAAX1mJ13pFVMJ
         XFma0ZHal5DpX69avX7EdMMINhkkw9TlVzCIzb6gZuatlL8dNUVNOIaQQfDfNk2ub90H
         Honw==
X-Gm-Message-State: ALoCoQnD3tRoAMHSNhK0DnogEqF9Nd0y1kArDys2yxMQpJwuI9uSdNcJY5Lmzl0tyNDdxd+kQjGr
MIME-Version: 1.0
X-Received: by 10.42.82.196 with SMTP id e4mr2089213icl.58.1387562900720; Fri,
 20 Dec 2013 10:08:20 -0800 (PST)
In-Reply-To: <DC42DA9F-7EBF-4BD1-9353-5AD3D39F4A04@gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<3BF29572-8A91-41C6-9048-1708FBFBCE24@gmail.com>
	<DC42DA9F-7EBF-4BD1-9353-5AD3D39F4A04@gmail.com>
Date: Fri, 20 Dec 2013 13:08:20 -0500
Message-ID: <CAABMOrr7==icJQ3eqMd51sZzkAS37zX_Fenmw18p7UTE4yCFjw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Otis Gospodnetic <otis@sematext.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, 
	"spark-users@googlegroups.com" <spark-users@googlegroups.com>, 
	"user@spark.incubator.apache.org" <user@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=20cf30363fa1cd14a904edfb29a7
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf30363fa1cd14a904edfb29a7
Content-Type: text/plain; charset=ISO-8859-1

Hi,

That's a Solr bug Ted, we'll fix in the coming days.

I assume Spark devs would like us to index Spark email, Wiki, JIRA, etc.?

Otis
--
Performance Monitoring * Log Analytics * Search Analytics
Solr & Elasticsearch Support * http://sematext.com/

tel: +1 347 480 1610   fax: +1 718 679 9190



On Fri, Dec 20, 2013 at 1:17 AM, Ted Yu <yuzhihong@gmail.com> wrote:

> You may have noticed that the counter of searchable items for last 7 days
> on search-Hadoop is 0 and the counter for last 30 days is declining quickly.
>
> Cheers
>
> On Dec 19, 2013, at 10:10 PM, Nick Pentreath <nick.pentreath@gmail.com>
> wrote:
>
> > One option that is 3rd party that works nicely for the Hadoop project
> and it's related projects is http://search-hadoop.com - managed by
> sematext. Perhaps we can plead with Otis to add Spark lists to
> search-spark.com, or the existing site?
> >
> > Just throwing it out there as a potential solution to at least searching
> and navigating the Apache lists
> >
> > Sent from my iPad
> >
> >> On 20 Dec 2013, at 6:46 AM, Aaron Davidson <ilikerps@gmail.com> wrote:
> >>
> >> I'd be fine with one-way mirrors here (Apache threads being reflected in
> >> Google groups) -- I have no idea how one is supposed to navigate the
> Apache
> >> list to look for historic threads.
> >>
> >>
> >>> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com>
> wrote:
> >>>
> >>> Thanks very much for the prompt and comprehensive reply!  I appreciate
> the
> >>> overarching desire to integrate with apache: I'm very happy to hear
> that
> >>> there's a move to use the existing groups as mirrors: that will
> overcome
> >>> all of my objections: particularly if it's bidirectional! :)
> >>>
> >>>
> >>>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
> >>>>
> >>>> Hey Mike,
> >>>>
> >>>> As you probably noticed when you CC'd spark-de...@googlegroups.com,
> that
> >>>> list has already be reconfigured so that it no longer allows posting
> (and
> >>>> bounces emails sent to it).
> >>>>
> >>>> We will be doing the same thing to the spark...@googlegroups.com list
> >>>> too (we'll announce a date for that soon).
> >>>>
> >>>> That may sound very frustrating, and you are *not* alone feeling that
> >>>> way. We've had a long conversation with our mentors about this, and
> I've
> >>>> felt very similar to you, so I'd like to give you background.
> >>>>
> >>>> As I'm coming to see it, part of becoming an Apache project is moving
> the
> >>>> community *fully* over to Apache infrastructure, and more generally
> the
> >>>> Apache way of organizing the community.
> >>>>
> >>>> This applies in both the nuts-and-bolts sense of being on apache
> infra,
> >>>> but possibly more importantly, it is also a guiding principle and way
> of
> >>>> thinking.
> >>>>
> >>>> In various ways, moving to apache Infra can be a painful process, and
> IMO
> >>>> the loss of all the great mailing list functionality that comes with
> using
> >>>> Google Groups is perhaps the most painful step. But basically, the de
> facto
> >>>> mailing lists need to be the Apache ones, and not Google Groups. The
> >>>> underlying reason is that Apache needs to take full accountability for
> >>>> recording and publishing the mailing lists, it has to be able to
> >>>> institutionally guarantee this. This is because discussion on mailing
> lists
> >>>> is one of the core things that defines an Apache community. So at a
> minimum
> >>>> this means Apache owning the master copy of the bits.
> >>>>
> >>>> All that said, we are discussing the possibility of having a google
> group
> >>>> that subscribes to each list that would provide an easier to use and
> >>>> prettier archive for each list (so far we haven't gotten that to
> work).
> >>>>
> >>>> I hope this was helpful. It has taken me a few years now, and a lot of
> >>>> conversations with experienced (and patient!) Apache mentors, to
> >>>> internalize some of the nuance about "the Apache way". That's why I
> wanted
> >>>> to share.
> >>>>
> >>>> Andy
> >>>>
> >>>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com>
> wrote:
> >>>>>
> >>>>> I notice that there are still a lot of active topics in this group:
> and
> >>>>> also activity on the apache mailing list (which is a really horrible
> >>>>> experience!).  Is it a firm policy on apache's front to disallow
> external
> >>>>> groups?  I'm going to be ramping up on spark, and I really hate the
> idea of
> >>>>> having to rely on the apache archives and my mail client.  Also:
> having to
> >>>>> search for topics/keywords both in old threads (here) as well as new
> >>>>> threads in apache's (clunky) archive, is going to be a pain!  I
> almost feel
> >>>>> like I must be missing something because the current solution seems
> >>>>> unfeasibly awkward!
> >>>>>
> >>>>> --
> >>>>> You received this message because you are subscribed to the Google
> >>>>> Groups "Spark Users" group.
> >>>>> To unsubscribe from this group and stop receiving emails from it,
> send
> >>>>> an email to spark-users...@googlegroups.com.
> >>>>>
> >>>>> For more options, visit https://groups.google.com/groups/opt_out.
> >>>>
> >>>>
>

--20cf30363fa1cd14a904edfb29a7--

From dev-return-978-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 20 19:41:36 2013
Return-Path: <dev-return-978-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D93C11021F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Dec 2013 19:41:36 +0000 (UTC)
Received: (qmail 68297 invoked by uid 500); 20 Dec 2013 19:41:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68164 invoked by uid 500); 20 Dec 2013 19:41:36 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 68148 invoked by uid 99); 20 Dec 2013 19:41:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 19:41:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.219.47 as permitted sender)
Received: from [209.85.219.47] (HELO mail-oa0-f47.google.com) (209.85.219.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Dec 2013 19:41:31 +0000
Received: by mail-oa0-f47.google.com with SMTP id k1so3347978oag.34
        for <multiple recipients>; Fri, 20 Dec 2013 11:41:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=JJc1UXxRh1Nw85tAlX8Drv+aRm+Szac0UIZtqkbsp2I=;
        b=xHufM+v4lpZfN723sCizmM8vLGMw/PpyfVprsREFY4knSxc/jHejA0rjdNedVUDTKI
         ycW2abD4MV9PBsfsechhKpk++deCJyDfQgGy5rTCxVjRyuf18SxvmiNBxlP9OgQYxJi/
         p9qCGu1aGjYbDoJUgbXp8VkUqxJZMa31s2/uxxjzS+9Q+LHrxtsXYN9StTw7MxWbK7Mx
         QRkWKuOLX2Ud+zt9TIDUCWqHyIlCdqcgQKMvrjTfWtVE7gCApZeDEnXnMcB6noGFoxea
         X7u+DHgklKUIgdhPDcjM7sCjSImKxvTMBXWUOEHaOEC8AWUDI1mb8MTMzNO13WAtZ54F
         3cpA==
MIME-Version: 1.0
X-Received: by 10.60.16.201 with SMTP id i9mr7591820oed.14.1387568470483; Fri,
 20 Dec 2013 11:41:10 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Fri, 20 Dec 2013 11:41:10 -0800 (PST)
In-Reply-To: <3015f716-41d1-477d-9ac7-7dc15dcdfa81@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<5c6028f9-b470-41ed-99d4-88f41df4bd00@googlegroups.com>
	<CALEZFQwiOibtj3HYY-Dx3sQszEgxJjO=3WirznUp0nNO0fasyw@mail.gmail.com>
	<3015f716-41d1-477d-9ac7-7dc15dcdfa81@googlegroups.com>
Date: Fri, 20 Dec 2013 11:41:10 -0800
Message-ID: <CABPQxstsMYrBfU=aB_y=OwExkhr3kRFbm2DuzQLK31wUTTMOwA@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Patrick Wendell <pwendell@gmail.com>
To: "spark-users@googlegroups.com" <spark-users@googlegroups.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, user@spark.incubator.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Andy and Mike,

I'd also prefer to just convert the old groups into mirrors. That way
people who are still subscribed to them will continue to get e-mails
(and most people on the list are read-only users).

Ideally we'd have the behavior that users who try to e-mail the google
group get a bounce back saying "this is now a read only mirror".

That said I have *no idea* of this is possible to set-up nicely within
google groups. I defer to Andy! Having the new mirror groups also
seems like a decent solution as well...

- Patrick

On Fri, Dec 20, 2013 at 8:35 AM, Mike Potts <maspotts@gmail.com> wrote:
> I actually prefer that, but I didn't want my preference to get in the way of
> creating mirror groups, one way or the other :)  (My argument would be that
> since the old groups would be closing anyway, re-purposing them as mirrors
> is fair use: and less work/confusing than creating new *-mirror groups
> instead.)
>
>
> On Friday, December 20, 2013 8:29:40 AM UTC-8, Andy Konwinski wrote:
>>
>> That would be really awesome. I'm not familiar with any Google Groups
>> functionality that supports that but I'll look.
>>
>> That's an argument for maybe just changing the names of the existing
>> groups to something with mirror in them instead of using newly created ones.
>
> --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.

From dev-return-979-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 21 07:37:09 2013
Return-Path: <dev-return-979-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5DA2710220
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 21 Dec 2013 07:37:09 +0000 (UTC)
Received: (qmail 36781 invoked by uid 500); 21 Dec 2013 07:37:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36401 invoked by uid 500); 21 Dec 2013 07:36:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 36393 invoked by uid 99); 21 Dec 2013 07:36:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Dec 2013 07:36:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.128.52] (HELO mail-qe0-f52.google.com) (209.85.128.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Dec 2013 07:36:49 +0000
Received: by mail-qe0-f52.google.com with SMTP id ne12so3388855qeb.11
        for <dev@spark.incubator.apache.org>; Fri, 20 Dec 2013 23:36:28 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to:cc
         :content-type;
        bh=8KTN126tiocqtNiV7ySro4897rVHYeW9YgkHU7wghVk=;
        b=FIm+GlDMZjNouxQdRFhu6K0lunve/qVYdv4d+ShZ6upEP3J0pyPmXGnsMuB4qc+mbU
         lVoyOB5unRRLpoUsc3YIXYK4hA5hL45yEdvsUEvlyB+cfwpnCN1IcSXpRprVesAtJxY/
         HIq7n9q3rUj5VeDYckULxq7PqCgSAWeNckqzLocB8S7TgrJDXaiZ2M6tSzDz9hVh8iqn
         b/ZKUGFUsE4+A8QMHvdoTcu55rtFGmx2ZpRUfmLzynf5Gbm48mKx7+lNlGcDtjqrE+Cq
         vOAxk7VopanQRU3HIHMLVxo5Gv9S9hlBousK+vsNU9Ir77IDpsjhp6YK6DhvBV2W/X59
         oGag==
X-Gm-Message-State: ALoCoQmsChT/dTBmmAbViTtgJbkqkbc6V9COpcnUZSAx5DqtO5opDO4eEilu/NOPVES7FQbh05go
MIME-Version: 1.0
X-Received: by 10.224.11.68 with SMTP id s4mr22115825qas.88.1387611388433;
 Fri, 20 Dec 2013 23:36:28 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Fri, 20 Dec 2013 23:36:28 -0800 (PST)
Date: Fri, 20 Dec 2013 23:36:28 -0800
Message-ID: <CAPh_B=ass2NcrN41t7KTSoF1SFGce=N57YMVyukX4hPcO5YN2Q@mail.gmail.com>
Subject: Akka problem when using scala command to launch Spark applications in
 the current 0.9.0-SNAPSHOT
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Cc: Patrick Wendell <patrick@databricks.com>, Tathagata Das <tdas@eecs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c2c370e504e904ee06732c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c370e504e904ee06732c
Content-Type: text/plain; charset=ISO-8859-1

It took me hours to debug a problem yesterday on the latest master branch
(0.9.0-SNAPSHOT), and I would like to share with the dev list in case
anybody runs into this Akka problem.

A little background for those of you who haven't followed closely the
development of Spark and YARN 2.2: YARN 2.2 uses protobuf 2.5, and Akka
uses an older version of protobuf that is not binary compatible. In order
to have a single build that is compatible for both YARN 2.2 and pre-2.2
YARN/Hadoop, we published a special version of Akka that builds with
protobuf shaded (i.e. using a different package name for the protobuf
stuff).

However, it turned out Scala 2.10 includes a version of Akka jar in its
default classpath (look at the lib folder in Scala 2.10 binary
distribution). If you use the scala command to launch any Spark application
on the current master branch, there is a pretty high chance that you
wouldn't be able to create the SparkContext (stack trace at the end of the
email). The problem is that the Akka packaged with Scala 2.10 takes
precedence in the classloader over the special Akka version Spark includes.

Before we have a good solution for this, the workaround is to use java to
launch the application instead of scala. All you need to do is to include
the right Scala jars (scala-library and scala-compiler) in the classpath.
Note that the scala command is really just a simple script that calls java
with the right classpath.


Stack trace:

java.lang.NoSuchMethodException:
akka.remote.RemoteActorRefProvider.<init>(java.lang.String,
akka.actor.ActorSystem$Settings, akka.event.EventStream,
akka.actor.Scheduler, akka.actor.DynamicAccess)
at java.lang.Class.getConstructor0(Class.java:2763)
at java.lang.Class.getDeclaredConstructor(Class.java:2021)
at
akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$2.apply(DynamicAccess.scala:77)
at scala.util.Try$.apply(Try.scala:161)
at
akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:74)
at
akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
at
akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
at scala.util.Success.flatMap(Try.scala:200)
at
akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:85)
at akka.actor.ActorSystemImpl.<init>(ActorSystem.scala:546)
at akka.actor.ActorSystem$.apply(ActorSystem.scala:111)
at akka.actor.ActorSystem$.apply(ActorSystem.scala:104)
at org.apache.spark.util.AkkaUtils$.createActorSystem(AkkaUtils.scala:79)
at org.apache.spark.SparkEnv$.createFromSystemProperties(SparkEnv.scala:120)
at org.apache.spark.SparkContext.<init>(SparkContext.scala:106)

--001a11c2c370e504e904ee06732c--

From dev-return-980-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 22 22:47:44 2013
Return-Path: <dev-return-980-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7DD4510177
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Dec 2013 22:47:44 +0000 (UTC)
Received: (qmail 78305 invoked by uid 500); 22 Dec 2013 22:47:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77799 invoked by uid 500); 22 Dec 2013 22:47:43 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 77783 invoked by uid 99); 22 Dec 2013 22:47:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Dec 2013 22:47:42 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of andykonwinski@gmail.com designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Dec 2013 22:47:36 +0000
Received: by mail-lb0-f172.google.com with SMTP id x18so2021318lbi.31
        for <multiple recipients>; Sun, 22 Dec 2013 14:47:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=xJ/fbmwuxxiw53WnH0Zo9XUIekb3nZ13YzsNeWRwNJE=;
        b=GsTaJIPKabfbkAI08TVT9MXvykb3c0bS8pBuf1ejtw8L4BVnEXoaqisFZuLP821d6/
         /vsVn8piJTZB2+/jBBDYljc75xQUFgUuiqLGLF/O6Df6T7ZrktgUYK9MT2sekmGuHF6t
         8BlyfXlZixd/4lTy0UuqJM4+gCMxndy/lncIwhO/cM9npjUYY6YkT+PzYaBwuZ0iXwrn
         Lel7Tpx915NZ8uufYK3gGK2zhwb+AtT7SjKC7t/O+9P+6oQVz2rjaeA2+L22hb6lr8Ps
         mQLU16XK4sgjVZakC+Q4KiJp43QqpSE4asfAUvlxKZvvlxSxlcoSYWFwY0IkYdR1uZw6
         GaGw==
MIME-Version: 1.0
X-Received: by 10.112.158.231 with SMTP id wx7mr6462204lbb.27.1387752435415;
 Sun, 22 Dec 2013 14:47:15 -0800 (PST)
Received: by 10.112.18.195 with HTTP; Sun, 22 Dec 2013 14:47:15 -0800 (PST)
In-Reply-To: <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
Date: Sun, 22 Dec 2013 14:47:15 -0800
Message-ID: <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: "spark-users@googlegroups.com" <spark-users@googlegroups.com>
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c268a4f3004604ee274a10
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c268a4f3004604ee274a10
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Per Matei's suggestion, I've set up two nabble archive lists, one to
archive the apache dev list and one to archive the apache user list.

user list archive: http://apache-spark-user-list.1001560.n3.nabble.com
dev list archive: http://apache-spark-developers-list.1001551.n3.nabble.com

Between these and whatever solution we end up with for the google group
mirrors, we should have decent enough alternatives to reading via the
apache list archives going forward.


On Thu, Dec 19, 2013 at 11:09 PM, Matei Zaharia <matei.zaharia@gmail.com>wr=
ote:

> Yes, I agree that we should close down the existing Google group on Jan
> 1st. While it=92s more convenient to use, it=92s created confusion. I hop=
e that
> we can get the ASF to support better search interfaces in the future too.=
 I
> think we just have to drive this from within.
>
> The Google Group should be a nice way to make the content searchable from
> the web. We should also see what it takes to make it mirrored on Nabble (
> http://www.nabble.com). I=92ve found a lot of information about other
> projects there, and other Apache projects do use it.
>
> Matei
>
> On Dec 19, 2013, at 10:49 PM, Andy Konwinski <andykonwinski@gmail.com>
> wrote:
>
> I've set up two new unofficial google groups to mirror the Apache Spark
> user and dev lists:
>
> https://groups.google.com/forum/#!forum/apache-spark-dev-mirror
> https://groups.google.com/forum/#!forum/apache-spark-user-mirror
>
> Basically these lists each subscribe to the corresponding Apache list.
>
> They do not allow folks to subscribe directly to them. Getting emails fro=
m
> the Google Group would offer no advantages that I can think of and we
> really want to encourage folks to sign up for the official mailing list
> instead.
>
> The lists do allow the public to send email to them, which I think might
> be necessary since the "from:" field for all emails that get distributed
> via the Apache mailing list is set to the author of the email.
>
> I think this might be a great compromise. At least we can try this out an=
d
> see how it goes.
>
> Matei, can you confirm that Jan 1 is the date we want to turn off the
> existing spark-users google group?
>
> We could consider using the existing spark-developers and spark-users
> google groups instead of the two new ones I just created but I think that
> it is much more obvious to have the lists include the word mirror in thei=
r
> names.
>
> The dev list mirror seems to be working, because I see the last couple
> emails from this thread in it already. I'll confirm and ensure that the
> user list mirror is working too.
>
> Thoughts?
>
> Andy
>
> P.S. Thanks to Patrick for suggesting this to me originally.
>
> On Thu, Dec 19, 2013 at 8:46 PM, Aaron Davidson <ilikerps@gmail.com>wrote=
:
>
>> I'd be fine with one-way mirrors here (Apache threads being reflected in
>> Google groups) -- I have no idea how one is supposed to navigate the Apa=
che
>> list to look for historic threads.
>>
>>
>> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote:
>>
>>> Thanks very much for the prompt and comprehensive reply!  I appreciate
>>> the overarching desire to integrate with apache: I'm very happy to hear
>>> that there's a move to use the existing groups as mirrors: that will
>>> overcome all of my objections: particularly if it's bidirectional! :)
>>>
>>>
>>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote:
>>>
>>>> Hey Mike,
>>>>
>>>> As you probably noticed when you CC'd spark-de...@googlegroups.com,
>>>> that list has already be reconfigured so that it no longer allows post=
ing
>>>> (and bounces emails sent to it).
>>>>
>>>> We will be doing the same thing to the spark...@googlegroups.com list
>>>> too (we'll announce a date for that soon).
>>>>
>>>> That may sound very frustrating, and you are *not* alone feeling that
>>>> way. We've had a long conversation with our mentors about this, and I'=
ve
>>>> felt very similar to you, so I'd like to give you background.
>>>>
>>>> As I'm coming to see it, part of becoming an Apache project is moving
>>>> the community *fully* over to Apache infrastructure, and more generall=
y the
>>>> Apache way of organizing the community.
>>>>
>>>> This applies in both the nuts-and-bolts sense of being on apache infra=
,
>>>> but possibly more importantly, it is also a guiding principle and way =
of
>>>> thinking.
>>>>
>>>> In various ways, moving to apache Infra can be a painful process, and
>>>> IMO the loss of all the great mailing list functionality that comes wi=
th
>>>> using Google Groups is perhaps the most painful step. But basically, t=
he de
>>>> facto mailing lists need to be the Apache ones, and not Google Groups.=
 The
>>>> underlying reason is that Apache needs to take full accountability for
>>>> recording and publishing the mailing lists, it has to be able to
>>>> institutionally guarantee this. This is because discussion on mailing =
lists
>>>> is one of the core things that defines an Apache community. So at a mi=
nimum
>>>> this means Apache owning the master copy of the bits.
>>>>
>>>> All that said, we are discussing the possibility of having a google
>>>> group that subscribes to each list that would provide an easier to use=
 and
>>>> prettier archive for each list (so far we haven't gotten that to work)=
.
>>>>
>>>> I hope this was helpful. It has taken me a few years now, and a lot of
>>>> conversations with experienced (and patient!) Apache mentors, to
>>>> internalize some of the nuance about "the Apache way". That's why I wa=
nted
>>>> to share.
>>>>
>>>> Andy
>>>>
>>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com> wrote:
>>>>
>>>>> I notice that there are still a lot of active topics in this group:
>>>>> and also activity on the apache mailing list (which is a really horri=
ble
>>>>> experience!).  Is it a firm policy on apache's front to disallow exte=
rnal
>>>>> groups?  I'm going to be ramping up on spark, and I really hate the i=
dea of
>>>>> having to rely on the apache archives and my mail client.  Also: havi=
ng to
>>>>> search for topics/keywords both in old threads (here) as well as new
>>>>> threads in apache's (clunky) archive, is going to be a pain!  I almos=
t feel
>>>>> like I must be missing something because the current solution seems
>>>>> unfeasibly awkward!
>>>>>
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "Spark Users" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to spark-users...@googlegroups.com.
>>>>>
>>>>> For more options, visit https://groups.google.com/groups/opt_out.
>>>>>
>>>>
>>>>
>>
>
> --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
>
> For more options, visit https://groups.google.com/groups/opt_out.
>
>
>  --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
>
> For more options, visit https://groups.google.com/groups/opt_out.
>

--001a11c268a4f3004604ee274a10--

From dev-return-981-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 22 23:51:57 2013
Return-Path: <dev-return-981-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47DCB101FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Dec 2013 23:51:57 +0000 (UTC)
Received: (qmail 98533 invoked by uid 500); 22 Dec 2013 23:51:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98489 invoked by uid 500); 22 Dec 2013 23:51:57 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 98474 invoked by uid 99); 22 Dec 2013 23:51:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Dec 2013 23:51:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of maspotts@gmail.com designates 209.85.213.64 as permitted sender)
Received: from [209.85.213.64] (HELO mail-yh0-f64.google.com) (209.85.213.64)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Dec 2013 23:51:51 +0000
Received: by mail-yh0-f64.google.com with SMTP id b20so915827yha.19
        for <multiple recipients>; Sun, 22 Dec 2013 15:51:31 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=hRAT2bHGP/9EjfyNFraocHyX1jRULJdefipwHZphwSQ=;
        b=lgT7HE16FpGDnjMCFnW5AKD55YdAF6f7veMlvMo57h9VRQikk2d+eXM18mCY4uPBxb
         C0TcqwDOjfgoqRTH0sY3y6KURdRJ5dvWg2oQT2ziUB0jHfZB3We+Gj035Dx0caQpJ9oG
         1IwedbhgojpP8iUZkfs8tzsmzztniZ0F1+FR+tmcHoG8YEN2ndVseqb8iMR4OiEXRnSY
         9CpunHiVcupM3h+InmN11wAj9liCh+w/iV04IRjHEUVAq+mR6ZTUU9NhcHpSPCD2noT7
         bFqGCW4YeUazOuVyeFFJqDjvJ61/8ThAlDjpaXEYLTdO93FGQ/1ex/A09MlTRcvCiIej
         CFZg==
X-Received: by 10.50.239.132 with SMTP id vs4mr364479igc.4.1387756290975;
        Sun, 22 Dec 2013 15:51:30 -0800 (PST)
X-Google-Doc-Id: 7e58b38d63fca423
X-Google-Web-Client: true
Date: Sun, 22 Dec 2013 15:51:29 -0800 (PST)
From: Mike Potts <maspotts@gmail.com>
To: spark-users@googlegroups.com
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Message-Id: <914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com>
In-Reply-To: <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
 <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
 <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
 <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
 <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
 <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
 <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
 <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
 <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
 <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
 <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September
 1st
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_1504_17866164.1387756289808"
X-Google-Token: EIH23ZUFQSV-7r-B1Wo0
X-Google-IP: 75.25.125.13
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_1504_17866164.1387756289808
Content-Type: multipart/alternative; 
	boundary="----=_Part_1505_31563840.1387756289808"

------=_Part_1505_31563840.1387756289808
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Thanks!!  Is is straightforward to pre-populate it with all the existing 
threads from apache?


------=_Part_1505_31563840.1387756289808
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<div dir="ltr">Thanks!! &nbsp;Is is straightforward to pre-populate it with all the existing threads from apache?<br><br></div>
------=_Part_1505_31563840.1387756289808--

------=_Part_1504_17866164.1387756289808--

From dev-return-982-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 00:23:47 2013
Return-Path: <dev-return-982-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D1593102D7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 00:23:47 +0000 (UTC)
Received: (qmail 12400 invoked by uid 500); 23 Dec 2013 00:23:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12335 invoked by uid 500); 23 Dec 2013 00:23:47 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 12319 invoked by uid 99); 23 Dec 2013 00:23:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 00:23:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of andykonwinski@gmail.com designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 00:23:41 +0000
Received: by mail-la0-f47.google.com with SMTP id ep20so1957233lab.6
        for <multiple recipients>; Sun, 22 Dec 2013 16:23:20 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=WEAGBiax4ma8p/C7LCwEmzKWV+08FXr77B2B+kqSHas=;
        b=Qogc0nVfI3OJZ5uSxTdUq78SXzZ233Lp7CPbmHCWMScRnOw/j1HTxAIr1yJSulPEcd
         4I2kY6ibbkAiKqm7MCdqe4KoANpwhXo1lTnx3WhoSpRKqX2Q9uAjuk1RNXeHi55Sk874
         LbuMZvhfkKvtaPlaDcJaJFk4porEJwZZLtR75ssAOCcLfwxc/TUK+ORgu7/2heAE15FT
         qc3CwhDznY8zaoOqhMHCdbfCkK8IdrbHt4OQDghq69kml0Uj8fCtEITmTtov0pMt+LTa
         T68LggIUPiGjqL4ep2Ddt5vFoFL+CuEE0QEheH2fAmlo8Oa6ah/yNC5yACbCScplzUhJ
         RAJQ==
MIME-Version: 1.0
X-Received: by 10.112.168.199 with SMTP id zy7mr5638lbb.68.1387758200523; Sun,
 22 Dec 2013 16:23:20 -0800 (PST)
Received: by 10.112.18.195 with HTTP; Sun, 22 Dec 2013 16:23:20 -0800 (PST)
In-Reply-To: <914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
	<914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com>
Date: Sun, 22 Dec 2013 16:23:20 -0800
Message-ID: <CALEZFQx51sCLDRd8O7GyOwdues3P5AXPbFbxWG5sF1WzCzDzVw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: "spark-users@googlegroups.com" <spark-users@googlegroups.com>
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2691493e57304ee28a203
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2691493e57304ee28a203
Content-Type: text/plain; charset=ISO-8859-1

Unfortunately, I don't see that as an option for either these nabble lists
or the google groups.

For the google groups, we we could subscribe the old spark google groups to
the apache lists (instead of using the new mirror groups I created).

However the tradeoff is that as far as I can tell, we wouldn't be able to
have posting disabled or even subscriber only for those groups (since the
emails from the apache lists would then get bounced). In this case, I'm
concerned that if it remains possible to post to the google groups, then
people will continue posting to them, which would be confusing to everybody.

We could rename the old groups to make it clear they are the mirrors,
however then the people who are subscribed to them and have rules setup for
dealing with them would have to change their rules.

Finally, we could unsubscribe everybody from the old google groups and then
rename them to have the word mirror in them which would preserve history
and be no worse than if they just became silent and activity moved to the
new mirror groups i created (which as I mentioned, must allow posting by
anybody). So I guess this last option is what I propose we do.

Andy


On Sun, Dec 22, 2013 at 3:51 PM, Mike Potts <maspotts@gmail.com> wrote:

> Thanks!!  Is is straightforward to pre-populate it with all the existing
> threads from apache?
>
>  --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>

--001a11c2691493e57304ee28a203--

From dev-return-983-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 00:30:23 2013
Return-Path: <dev-return-983-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E4643102E3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 00:30:23 +0000 (UTC)
Received: (qmail 15969 invoked by uid 500); 23 Dec 2013 00:30:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15934 invoked by uid 500); 23 Dec 2013 00:30:23 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 15926 invoked by uid 99); 23 Dec 2013 00:30:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 00:30:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of laserson@cloudera.com designates 209.85.216.179 as permitted sender)
Received: from [209.85.216.179] (HELO mail-qc0-f179.google.com) (209.85.216.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 00:30:18 +0000
Received: by mail-qc0-f179.google.com with SMTP id i8so4266765qcq.38
        for <dev@spark.incubator.apache.org>; Sun, 22 Dec 2013 16:29:57 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=8PoDDnRSnVOe14UmuQE/8jeTKpgqdRisKysR/m9cLSk=;
        b=AvJMc07VaQbdj0iDHsJCZE3seLStuTbLZ7q/Uk0TwP0HzkcWINBGY7atYDORp64Rqc
         dA+4jEQ6wS/QPZECss2vnIl19DNP71XplQ+kLw2G7ozj9CS4rArFz2DaKPSh4Uals7QA
         R56oT/J/CA8vro0rhB9tcgOh0fa7vQEFyjN3ZCASww6I8DZsWE0mQvATOO5iWNFp4cHY
         QANXXgL5cfGIUKtl7fg9hEA6wVEaOLz95zKEppxM01ZercSROGHDfIoRzguWBPl1gHwX
         EsvErjg5RCQvaasMMKwzMjxtJHBO82jxcXS/1fs1jW1M6zL3ajZ/dfPfb0Af3Z+cb+TC
         nHLQ==
X-Gm-Message-State: ALoCoQlJq4ogiH1gaFF3xmqEetIlqwnxhIjLvI3OtLz0xy4vfRzWXd5qqg2VcDZOvBJQuWufy1Sg
X-Received: by 10.49.76.7 with SMTP id g7mr37407086qew.25.1387758597348; Sun,
 22 Dec 2013 16:29:57 -0800 (PST)
MIME-Version: 1.0
Received: by 10.229.14.73 with HTTP; Sun, 22 Dec 2013 16:29:37 -0800 (PST)
From: Uri Laserson <laserson@cloudera.com>
Date: Sun, 22 Dec 2013 18:29:37 -0600
Message-ID: <CAF8NrwFH2ENyD_s4XPLsk71CZ=VgifVesTs0DcPxLK7AN_f+Ow@mail.gmail.com>
Subject: Installing PySpark on a local machine
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bea3f463ab85e04ee28ba5e
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea3f463ab85e04ee28ba5e
Content-Type: text/plain; charset=UTF-8

Is there a documented/preferred method for installing PySpark on a local
machine?  I want to be able to run a Python interpreter on my local
machine, point it to my Spark cluster and go.  There doesn't appear to be a
setup.py file anywhere, nor is pyspark registered with PyPI.  I'm happy to
contribute these, but want to hear what the preferred method is first.

Uri

-- 
Uri Laserson, PhD
Data Scientist, Cloudera
Twitter/GitHub: @laserson
+1 617 910 0447
laserson@cloudera.com

--047d7bea3f463ab85e04ee28ba5e--

From dev-return-984-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 01:01:48 2013
Return-Path: <dev-return-984-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E64E310341
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 01:01:48 +0000 (UTC)
Received: (qmail 25935 invoked by uid 500); 23 Dec 2013 01:01:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25897 invoked by uid 500); 23 Dec 2013 01:01:48 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 25889 invoked by uid 99); 23 Dec 2013 01:01:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 01:01:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.160.46 as permitted sender)
Received: from [209.85.160.46] (HELO mail-pb0-f46.google.com) (209.85.160.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 01:01:44 +0000
Received: by mail-pb0-f46.google.com with SMTP id md12so4649243pbc.5
        for <dev@spark.incubator.apache.org>; Sun, 22 Dec 2013 17:01:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=VVJM33tkDgrAolMmXxFLVI+idEsWmQtTfQ57V7ywNVE=;
        b=Fbm1B1lLgQ0IriBR6rze7AtHFGLq3eVsCpFl1CzyyrWqzfwKacson4iX2UBSIeHyxO
         Ms89OMKa6RHtX9wNTxeF4DLFjqXZRiSqxXgsHXX2kmcuCcuhcesROwloSuBO6aqdKQhu
         WzZyUb4/40R4E9YXoklCBc6Z2OJIn8T7z9ouBaiSwXj1TBEgIIjsuWfcAAwlpXvDe+2F
         IdUW3uU3BdlGnD4c3hWZ8CdnMBG915dE973euYH1nAMZbjLyp2TRhC6iT/TQMJburBEG
         zOmC1WYhpQVBvNCvYJsf/kEV+Dk7dp1ARNy0F8NWoaenI13mDycNjdzMM8r30NP1iFcl
         9ILw==
MIME-Version: 1.0
X-Received: by 10.66.179.143 with SMTP id dg15mr22998287pac.52.1387760484113;
 Sun, 22 Dec 2013 17:01:24 -0800 (PST)
Received: by 10.70.10.101 with HTTP; Sun, 22 Dec 2013 17:01:24 -0800 (PST)
In-Reply-To: <CAF8NrwFH2ENyD_s4XPLsk71CZ=VgifVesTs0DcPxLK7AN_f+Ow@mail.gmail.com>
References: <CAF8NrwFH2ENyD_s4XPLsk71CZ=VgifVesTs0DcPxLK7AN_f+Ow@mail.gmail.com>
Date: Sun, 22 Dec 2013 17:01:24 -0800
Message-ID: <CAOEPXP4RitqyT4PAJMre8CtNM9-zPqn9B65fPiEh+uxtO2UufQ@mail.gmail.com>
Subject: Re: Installing PySpark on a local machine
From: Josh Rosen <rosenville@gmail.com>
To: "Spark Dev (Apache Incubator)" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7bea3f64b0617804ee292a42
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea3f64b0617804ee292a42
Content-Type: text/plain; charset=ISO-8859-1

I've thought about creating a setup.py file for PySpark; there are a couple
of subtleties involved:

   - PySpark's uses Py4J to create a regular Java Spark driver, so it's
   subject to the same limitations that Scala / Java Spark have when
   connecting from a local machine to a remote cluster; a number of ports need
   to be opened (this is discussed in more detail in other posts on this list;
   try searching for "connect to remote cluster" or something like that).
   - PySpark needs the Spark assembly JAR, so you'd still have to point the
   SPARK_HOME environment variable to local copy of the Spark assemblies.
   - We need to be careful about communication between incompatible
   versions of the Python and Java portions of the library.  We can probably
   fix this by embedding version numbers in the Python and Java libraries and
   comparing those numbers when launching the Java gateway.

If we decide to distribute a PySpark package on PyPI, we should integrate
its release with the regular Apache release process for Spark.

Does anyone know how other projects like Mesos distribute their Python
bindings?  Is there a good existing model that we should emulate?

- Josh


On Sun, Dec 22, 2013 at 4:29 PM, Uri Laserson <laserson@cloudera.com> wrote:

> Is there a documented/preferred method for installing PySpark on a local
> machine?  I want to be able to run a Python interpreter on my local
> machine, point it to my Spark cluster and go.  There doesn't appear to be a
> setup.py file anywhere, nor is pyspark registered with PyPI.  I'm happy to
> contribute these, but want to hear what the preferred method is first.
>
> Uri
>
> --
> Uri Laserson, PhD
> Data Scientist, Cloudera
> Twitter/GitHub: @laserson
> +1 617 910 0447
> laserson@cloudera.com
>

--047d7bea3f64b0617804ee292a42--

From dev-return-985-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 03:12:35 2013
Return-Path: <dev-return-985-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3108510591
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 03:12:35 +0000 (UTC)
Received: (qmail 84292 invoked by uid 500); 23 Dec 2013 03:12:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84269 invoked by uid 500); 23 Dec 2013 03:12:30 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 84246 invoked by uid 99); 23 Dec 2013 03:12:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:12:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of maspotts@gmail.com designates 209.85.128.60 as permitted sender)
Received: from [209.85.128.60] (HELO mail-qe0-f60.google.com) (209.85.128.60)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:12:23 +0000
Received: by mail-qe0-f60.google.com with SMTP id k5so926854qej.25
        for <multiple recipients>; Sun, 22 Dec 2013 19:12:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=GMn30Ci1iokAh0ZnzdlwDuNpIp55e034CLLACERRdqk=;
        b=royihuipWhauco8oH0/WgVOOl/H7TmBp8DAUygzTwbdAcpYdFdHyPv7GZm2371l3nf
         ePUVV5JObo7udWdhakQX/l2RBeznJCjO3q6tsKK5v/lJ1nC6fiK092OREgEuRHF7dqQu
         h9nEytem79Fl9EzIcnoOY14W0x60RQUGWNPeuSt6J1+AxMOMVLngluX57svawz1nWc1g
         9d0wsJne7LIqr0rIou0gWuMFiyr8QGCpCrZuSE7XftfkQwi2yAh1VvFnE2V/TibfBxiU
         j7TJhq4jGjCxe/wv6K38mKmIuL0lnn4zBKWNFTUQy0k1CAT7ZOZWVempNdS5ufz+7r+a
         NE4A==
X-Received: by 10.50.131.134 with SMTP id om6mr380417igb.11.1387768322663;
        Sun, 22 Dec 2013 19:12:02 -0800 (PST)
X-Google-Doc-Id: bd52d26cc27e67
X-Google-Web-Client: true
Date: Sun, 22 Dec 2013 19:12:01 -0800 (PST)
From: Mike Potts <maspotts@gmail.com>
To: spark-users@googlegroups.com
Cc: user@spark.incubator.apache.org, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Message-Id: <3c61bf58-dbf6-4f28-8f60-830e1dca5266@googlegroups.com>
In-Reply-To: <CALEZFQx51sCLDRd8O7GyOwdues3P5AXPbFbxWG5sF1WzCzDzVw@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
 <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
 <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
 <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
 <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
 <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
 <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
 <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
 <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
 <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
 <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
 <914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com>
 <CALEZFQx51sCLDRd8O7GyOwdues3P5AXPbFbxWG5sF1WzCzDzVw@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September
 1st
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_53_21086561.1387768321643"
X-Google-Token: EIHU3pUFGS9YCduH6F40
X-Google-IP: 75.25.125.13
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_53_21086561.1387768321643
Content-Type: multipart/alternative; 
	boundary="----=_Part_54_33490296.1387768321644"

------=_Part_54_33490296.1387768321644
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Just a thought: if the mirroring was bidirectional (between apache lists 
and google groups) -- meaning that you could read/write via either channel 
and everything would be mirrored in both groups -- would that be a bad 
thing?  The apache lists would be comprehensive and available as a 
first-class communications channel; and so would the google groups: I would 
have thought the benefits of maintaining both channels (fully mirrored) 
would outweigh any drawbacks... but again I'm probably missing something :)


------=_Part_54_33490296.1387768321644
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<div dir="ltr">Just a thought: if the mirroring was bidirectional (between apache lists and google groups) -- meaning that you could read/write via either channel and everything would be mirrored in both groups -- would that be a bad thing? &nbsp;The apache lists would be comprehensive and available as a first-class communications channel; and so would the google groups: I would have thought the benefits of maintaining both channels (fully mirrored) would outweigh any drawbacks... but again I'm probably missing something :)<div><br></div></div>
------=_Part_54_33490296.1387768321644--

------=_Part_53_21086561.1387768321643--

From dev-return-986-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 03:25:32 2013
Return-Path: <dev-return-986-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD2AF10661
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 03:25:32 +0000 (UTC)
Received: (qmail 99856 invoked by uid 500); 23 Dec 2013 03:25:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99805 invoked by uid 500); 23 Dec 2013 03:25:27 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 99782 invoked by uid 99); 23 Dec 2013 03:25:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:25:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andykonwinski@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:25:21 +0000
Received: by mail-la0-f51.google.com with SMTP id ec20so1994551lab.24
        for <multiple recipients>; Sun, 22 Dec 2013 19:25:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=purBCft5JRcyrvRe+s2mKZdtT2sp2Bod06iOlDmrs6U=;
        b=vl29YMOLB1MRiYnrRMtib1JbymeJD0mKt/PJjF4DATD9N7H7APQ4naghKEyYblwknc
         Yv4nGUgfg0LKNqTaWtTrz7BsGQq+D8RBe0MRzMfs5jc7nm431LtJR5CtSxaeKOvI99n4
         y1L72IwTIocSfkPnA4eEyMfzB4bw3FNBGvt1oPxVhn+s5CP8ZSRwXFQlDD21sZP5YkF4
         zB7v53WogjtFJ79/jztrVHkHCBy0xt8yPVTfGVX7kzBhn9cd9tfl1p0pNlHbfrxGWovm
         sM/hnupZjV7rM/x3YsId5PTlNpiOix0s18i/hb/bfWFBtld4rdbAeOTpxph3zIHgNU5b
         x7gQ==
MIME-Version: 1.0
X-Received: by 10.112.52.74 with SMTP id r10mr4188362lbo.36.1387769100247;
 Sun, 22 Dec 2013 19:25:00 -0800 (PST)
Received: by 10.112.18.195 with HTTP; Sun, 22 Dec 2013 19:25:00 -0800 (PST)
Received: by 10.112.18.195 with HTTP; Sun, 22 Dec 2013 19:25:00 -0800 (PST)
In-Reply-To: <3c61bf58-dbf6-4f28-8f60-830e1dca5266@googlegroups.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
	<914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com>
	<CALEZFQx51sCLDRd8O7GyOwdues3P5AXPbFbxWG5sF1WzCzDzVw@mail.gmail.com>
	<3c61bf58-dbf6-4f28-8f60-830e1dca5266@googlegroups.com>
Date: Sun, 22 Dec 2013 19:25:00 -0800
Message-ID: <CALEZFQyGzv5DSouiEkCd4Xz4bm45xt0pkg7Re=Vw=nkF_-OQGg@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Andy Konwinski <andykonwinski@gmail.com>
To: spark-users@googlegroups.com
Cc: dev@spark.incubator.apache.org, user@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c3f8aa40286704ee2b2c0f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f8aa40286704ee2b2c0f
Content-Type: text/plain; charset=ISO-8859-1

It would be a good thing, I'm just not sure how to achieve it, or if it's
possible. AFAIK, you cannot simply subscribe the lists to each other. Have
you heard of a setup like this being used before?
On Dec 22, 2013 7:12 PM, "Mike Potts" <maspotts@gmail.com> wrote:

> Just a thought: if the mirroring was bidirectional (between apache lists
> and google groups) -- meaning that you could read/write via either channel
> and everything would be mirrored in both groups -- would that be a bad
> thing?  The apache lists would be comprehensive and available as a
> first-class communications channel; and so would the google groups: I would
> have thought the benefits of maintaining both channels (fully mirrored)
> would outweigh any drawbacks... but again I'm probably missing something :)
>
>  --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>

--001a11c3f8aa40286704ee2b2c0f--

From dev-return-987-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Mon Dec 23 03:28:52 2013
Return-Path: <dev-return-987-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E1F1410679
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Dec 2013 03:28:52 +0000 (UTC)
Received: (qmail 2305 invoked by uid 500); 23 Dec 2013 03:28:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2261 invoked by uid 500); 23 Dec 2013 03:28:47 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 2235 invoked by uid 99); 23 Dec 2013 03:28:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:28:45 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of maspotts@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Dec 2013 03:28:38 +0000
Received: by mail-pa0-f44.google.com with SMTP id fa1so4818379pad.31
        for <multiple recipients>; Sun, 22 Dec 2013 19:28:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=8pgGjQGqhPbEee6laGysHsafa7DPQ41ecWjIwhGqehw=;
        b=iH6ZG+MmrklVZMC4/mrXFLD93l/wkA3DMGtZzZ/4BuDX1i/9zt497fZce6hYdIcKy/
         Cu0Auz5Y9/cT2VEs/8XpsnNn4D3LKIHfx6Jvmp8DEj6mmFbRItyZs9xdnxdfQgd1wNhi
         4IKYg7O0KUTTI8BlTPwxYRKlWxJ0oM07740PZf4+jAc0hWsPqOTZfqymHRtcD0NSbdbv
         R7mG6mltJLGZtLJZ1RQYinydslVCCGviu4jrLrNEoVXP8SE1wpZr1EHPkFg4J3Y1C0Me
         8KfeZRl/MWG1NGTzeqvQ4xBNH4WMagzK90bUP8ZsSXlK7tKTKrVSfyk3M9l3Zshar3ak
         airQ==
X-Received: by 10.68.247.6 with SMTP id ya6mr17897520pbc.45.1387769297135;
        Sun, 22 Dec 2013 19:28:17 -0800 (PST)
Received: from [192.168.1.81] (75-25-125-13.lightspeed.sjcpca.sbcglobal.net. [75.25.125.13])
        by mx.google.com with ESMTPSA id ha10sm30497208pbd.17.2013.12.22.19.28.15
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 22 Dec 2013 19:28:16 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.1 \(1827\))
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Mike Potts <maspotts@gmail.com>
In-Reply-To: <CALEZFQyGzv5DSouiEkCd4Xz4bm45xt0pkg7Re=Vw=nkF_-OQGg@mail.gmail.com>
Date: Sun, 22 Dec 2013 19:28:14 -0800
Cc: dev@spark.incubator.apache.org,
 user@spark.incubator.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <865D3C47-714B-4553-ADBF-1966B8238E15@gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com> <cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com> <CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com> <B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com> <b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com> <CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com> <9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com> <CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com> <CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com> <381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com> <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com> <914bf928-715e-4a7e-bf22-875f53ce9a2f@googlegroups.com> <CALEZFQx51sCLDRd8O7GyOwdues3P5AXPbFbxWG5sF1WzCzDzVw@mail.gmail.com> <3c61bf58-dbf6-4f28-8f60-830e1dca5266@googlegroups.com> <CALEZFQyGzv5DSouiEkCd4Xz4bm45xt0pkg7Re=Vw=nkF_-OQGg@mail.gmail.com>
To: spark-users@googlegroups.com
X-Mailer: Apple Mail (2.1827)
X-Virus-Checked: Checked by ClamAV on apache.org


Haha, no: I=92m afraid there my reach exceeds my grasp :(

On Dec 22, 2013, at 7:25 PM, Andy Konwinski <andykonwinski@gmail.com> =
wrote:

> It would be a good thing, I'm just not sure how to achieve it, or if =
it's possible. AFAIK, you cannot simply subscribe the lists to each =
other. Have you heard of a setup like this being used before?
>=20
> On Dec 22, 2013 7:12 PM, "Mike Potts" <maspotts@gmail.com> wrote:
> Just a thought: if the mirroring was bidirectional (between apache =
lists and google groups) -- meaning that you could read/write via either =
channel and everything would be mirrored in both groups -- would that be =
a bad thing?  The apache lists would be comprehensive and available as a =
first-class communications channel; and so would the google groups: I =
would have thought the benefits of maintaining both channels (fully =
mirrored) would outweigh any drawbacks... but again I'm probably missing =
something :)
>=20
>=20
> --=20
> You received this message because you are subscribed to the Google =
Groups "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send =
an email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>=20
> --=20
> You received this message because you are subscribed to a topic in the =
Google Groups "Spark Users" group.
> To unsubscribe from this topic, visit =
https://groups.google.com/d/topic/spark-users/vtg-5db8JWY/unsubscribe.
> To unsubscribe from this group and all its topics, send an email to =
spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.


From dev-return-988-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 16:27:56 2013
Return-Path: <dev-return-988-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B89C51061A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 16:27:56 +0000 (UTC)
Received: (qmail 26088 invoked by uid 500); 24 Dec 2013 16:27:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26034 invoked by uid 500); 24 Dec 2013 16:27:40 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 26023 invoked by uid 99); 24 Dec 2013 16:27:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 16:27:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 16:27:33 +0000
Received: by mail-lb0-f180.google.com with SMTP id x18so2929756lbi.39
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 08:27:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=pkdq15GOqZoTI4Bg7bX7nkQShvv/OO69MCo7j7Cj4hs=;
        b=bUCcRFvWu3s2jhIYw5aZER+Fjoe+MSFZwE/71qNIAYSNBryHEJpZORPJFyHy+kcUem
         Z2UH8IJ22b89dFOiWoGvBBvQ8LL/8slkgIO1kgv2EDdG88etYdMAfgTM4i1yzF0F5n3I
         arnl+AJiRQ1EG0fhmsNjM63Q6OYpM5WSa1j6fTpMC7XRFgIoP7xLBjwdUK+M3p27jRk9
         2TagCUSypcKPIeWV564j4PYJwq3iisOLbFwJK1GxWT0MSXlGSIeDzGD6na2qGwa8xdY3
         1m2AMFYPCXUtRYdWwamy8lN4KBLQKopVms8Yo771SN5exJwa7Oo5hzIn+UzKDjdL5jwe
         NZrA==
MIME-Version: 1.0
X-Received: by 10.112.133.3 with SMTP id oy3mr1242051lbb.63.1387902431492;
 Tue, 24 Dec 2013 08:27:11 -0800 (PST)
Received: by 10.112.138.234 with HTTP; Tue, 24 Dec 2013 08:27:11 -0800 (PST)
Date: Tue, 24 Dec 2013 08:27:11 -0800
Message-ID: <CALte62yWiN2YL=EY491eKZ7S-=giUL8bzpYNj_Gm41DmsDJnyw@mail.gmail.com>
Subject: NullPointerException when running TaskResultGetterSuite
From: Ted Yu <yuzhihong@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b33dc4a697f4004ee4a3776
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b33dc4a697f4004ee4a3776
Content-Type: text/plain; charset=ISO-8859-1

Hi,
In test output, I saw:

^[[32mTaskResultGetterSuite:^[[0m
^[[32m- handling results smaller than Akka frame size^[[0m
^[[32m- handling results larger than Akka frame size^[[0m
Exception in thread "SparkListenerBus" java.lang.NullPointerException
  at
org.apache.spark.ui.jobs.JobProgressListener.onTaskEnd(JobProgressListener.scala:149)
  at
org.apache.spark.scheduler.SparkListenerBus$$anon$2$$anonfun$run$7.apply(SparkListenerBus.scala:55)
  at
org.apache.spark.scheduler.SparkListenerBus$$anon$2$$anonfun$run$7.apply(SparkListenerBus.scala:55)
  at
scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
  at
org.apache.spark.scheduler.SparkListenerBus$$anon$2.run(SparkListenerBus.scala:55)

Has anyone else seen similar stack trace ?

Cheers

--047d7b33dc4a697f4004ee4a3776--

From dev-return-989-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 17:06:33 2013
Return-Path: <dev-return-989-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B8448106BA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 17:06:33 +0000 (UTC)
Received: (qmail 54461 invoked by uid 500); 24 Dec 2013 17:06:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54285 invoked by uid 500); 24 Dec 2013 17:06:06 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 54107 invoked by uid 99); 24 Dec 2013 17:06:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 17:06:05 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hdc1112@gmail.com designates 209.85.212.47 as permitted sender)
Received: from [209.85.212.47] (HELO mail-vb0-f47.google.com) (209.85.212.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 17:05:48 +0000
Received: by mail-vb0-f47.google.com with SMTP id q12so3431882vbe.20
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 09:05:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:date:message-id:subject:from:to:content-type;
        bh=8wwR3eV2MEnGgYXKQMyy1EaabPNSNRfdqWDMy4V34pU=;
        b=Fchos2+rF20UqQ25J8fLwbCzHFxH62/eBkzvZcqbHI4uOaV0H87KegUZ9+xvHIQ78h
         crFCd5sfwqIM3BTHCymthX4Kx7wTHF3mP7mMcuSTc5YjwlLpARilvnbQrMp+Luoey3e1
         kyfsO6LWrdE5I6i6EioBOX/Fhh1JrJM7uVqMh0RlKks+UByYZkpaGlvKKyPgOrsEmutM
         p/R4XvMJbBTGr/QrnhLzozlw3DQWX/w+0u3wiM6Ba9pCnQ6kecF6BKzb/1mUopGuiaas
         BQqBGMlYL91YqagCN/4oKdV6PmEgbFQAguBO4K+nB8B+9T+5ZIS1YUYuLFDgCp5hoaW2
         /Z1w==
MIME-Version: 1.0
X-Received: by 10.58.235.129 with SMTP id um1mr6149527vec.17.1387904726850;
 Tue, 24 Dec 2013 09:05:26 -0800 (PST)
Sender: hdc1112@gmail.com
Received: by 10.58.32.199 with HTTP; Tue, 24 Dec 2013 09:05:26 -0800 (PST)
Date: Tue, 24 Dec 2013 12:05:26 -0500
X-Google-Sender-Auth: oZIHbrQ-HQE_Fazz1A_ax_NnIKw
Message-ID: <CAAzo=r92Fy4N6TWYya_EuhwZgBK4trZ28cY_eg_g1Nz9QO=raQ@mail.gmail.com>
Subject: Stackoverflow after a small change by me
From: Dachuan Huang <huangda@cse.ohio-state.edu>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bd6bb5639e44c04ee4ac022
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd6bb5639e44c04ee4ac022
Content-Type: text/plain; charset=ISO-8859-1

Hello, developers,

Just out of curiosity, I have changed the "mustCheckpoint" in
StateDStream.scala to "false" by default. And run the
StatefulNetworkWordCount.scala example.

My input is a 3MB/s speed Serversocket.

It reports the following error after some time, the exception trace didn't
say anything about the spark code, so I don't know how to nail down the
root cause, can anybody help me with this? thanks.

Exception in thread "DAGScheduler" java.lang.StackOverflowError
at java.io.ObjectStreamClass.getPrimFieldValues(ObjectStreamClass.java:1233)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1532)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
at
java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
at
java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)

--047d7bd6bb5639e44c04ee4ac022--

From dev-return-990-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 18:49:53 2013
Return-Path: <dev-return-990-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB91B1089D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 18:49:53 +0000 (UTC)
Received: (qmail 24613 invoked by uid 500); 24 Dec 2013 18:49:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24564 invoked by uid 500); 24 Dec 2013 18:49:52 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 24551 invoked by uid 99); 24 Dec 2013 18:49:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:49:52 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.217.178 as permitted sender)
Received: from [209.85.217.178] (HELO mail-lb0-f178.google.com) (209.85.217.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:49:47 +0000
Received: by mail-lb0-f178.google.com with SMTP id c11so2948551lbj.23
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 10:49:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=jmqlDyrg0RTwIlzPJQBQKMhoFpCJ3WPKspf8T/lFKdo=;
        b=Fky6jceb4E9vmlKLkW+kdg5BlrcXssIhekgK5wkyvDCIpMIksMTOrYVVWn/sFQ/pqy
         /MMEIsLzZo76Ute49hu1bqtBxgYCEQzq4I5lAULPIDlisdsfQm3jnntTmAFpKyGxllnw
         jQWWiJX5EnBbFlDYKyyke7iWq9px1Ktfkie/k=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=jmqlDyrg0RTwIlzPJQBQKMhoFpCJ3WPKspf8T/lFKdo=;
        b=NaYzNXd6hCafbcqL883S5A1YGjwazzxUQKQkNXicmnsOK7XyuJAhRR+JeXlXjC4Lxi
         NAC+vS77HsMzCgEK3WbhGVDGPWvqiQXCLpIo2bZ7ema7EyyLwa1HIsI2fQTcrLTczZzl
         qlnFE8V2tWz92UjFgbMNzXF/0VPy1OyBZK0LIJwgHnmjaKZPBZFqzPTVdo+7gtsCwv9I
         /LHgmY1kUtpHbnBBTpjmkgIQcLja46Qf/omwIngguP7oOj5Gy23agsdE2z+66baNNksX
         wVjh+WMj/6EK6S9/oHTx3UjkXKoNaIv4gorsheYJZVAwzAsi+8hka4WrDBellVEC6cZx
         /4zw==
X-Gm-Message-State: ALoCoQm0kjIh4BIygPBa4XGuDeeoMYx6er6icD9KgdPLGsKYAkW2/n2v7J9+bmlLak9A3x+gpuFM
MIME-Version: 1.0
X-Received: by 10.152.203.129 with SMTP id kq1mr150543lac.77.1387910966057;
 Tue, 24 Dec 2013 10:49:26 -0800 (PST)
Received: by 10.112.20.10 with HTTP; Tue, 24 Dec 2013 10:49:25 -0800 (PST)
In-Reply-To: <CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
Date: Tue, 24 Dec 2013 10:49:25 -0800
Message-ID: <CADWPM3h2t5_SAy05_bVpBAWfTAMoM4u+ghAoPY2B5NnANgJ9cQ@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Cc: "spark-users@googlegroups.com" <spark-users@googlegroups.com>, user@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a113480a01cadec04ee4c340b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113480a01cadec04ee4c340b
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Thanks Andy, at first glance nabble seems great, it allows search plus
posting new topics, so it appears to be bidirectional.    Now just have to
register an account on there.


On Sun, Dec 22, 2013 at 2:47 PM, Andy Konwinski <andykonwinski@gmail.com>wr=
ote:

> Per Matei's suggestion, I've set up two nabble archive lists, one to
> archive the apache dev list and one to archive the apache user list.
>
> user list archive: http://apache-spark-user-list.1001560.n3.nabble.com
> dev list archive:
> http://apache-spark-developers-list.1001551.n3.nabble.com
>
> Between these and whatever solution we end up with for the google group
> mirrors, we should have decent enough alternatives to reading via the
> apache list archives going forward.
>
>
> On Thu, Dec 19, 2013 at 11:09 PM, Matei Zaharia <matei.zaharia@gmail.com
> >wrote:
>
> > Yes, I agree that we should close down the existing Google group on Jan
> > 1st. While it=92s more convenient to use, it=92s created confusion. I h=
ope
> that
> > we can get the ASF to support better search interfaces in the future
> too. I
> > think we just have to drive this from within.
> >
> > The Google Group should be a nice way to make the content searchable fr=
om
> > the web. We should also see what it takes to make it mirrored on Nabble=
 (
> > http://www.nabble.com). I=92ve found a lot of information about other
> > projects there, and other Apache projects do use it.
> >
> > Matei
> >
> > On Dec 19, 2013, at 10:49 PM, Andy Konwinski <andykonwinski@gmail.com>
> > wrote:
> >
> > I've set up two new unofficial google groups to mirror the Apache Spark
> > user and dev lists:
> >
> > https://groups.google.com/forum/#!forum/apache-spark-dev-mirror
> > https://groups.google.com/forum/#!forum/apache-spark-user-mirror
> >
> > Basically these lists each subscribe to the corresponding Apache list.
> >
> > They do not allow folks to subscribe directly to them. Getting emails
> from
> > the Google Group would offer no advantages that I can think of and we
> > really want to encourage folks to sign up for the official mailing list
> > instead.
> >
> > The lists do allow the public to send email to them, which I think migh=
t
> > be necessary since the "from:" field for all emails that get distribute=
d
> > via the Apache mailing list is set to the author of the email.
> >
> > I think this might be a great compromise. At least we can try this out
> and
> > see how it goes.
> >
> > Matei, can you confirm that Jan 1 is the date we want to turn off the
> > existing spark-users google group?
> >
> > We could consider using the existing spark-developers and spark-users
> > google groups instead of the two new ones I just created but I think th=
at
> > it is much more obvious to have the lists include the word mirror in
> their
> > names.
> >
> > The dev list mirror seems to be working, because I see the last couple
> > emails from this thread in it already. I'll confirm and ensure that the
> > user list mirror is working too.
> >
> > Thoughts?
> >
> > Andy
> >
> > P.S. Thanks to Patrick for suggesting this to me originally.
> >
> > On Thu, Dec 19, 2013 at 8:46 PM, Aaron Davidson <ilikerps@gmail.com
> >wrote:
> >
> >> I'd be fine with one-way mirrors here (Apache threads being reflected =
in
> >> Google groups) -- I have no idea how one is supposed to navigate the
> Apache
> >> list to look for historic threads.
> >>
> >>
> >> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com> wrote=
:
> >>
> >>> Thanks very much for the prompt and comprehensive reply!  I appreciat=
e
> >>> the overarching desire to integrate with apache: I'm very happy to he=
ar
> >>> that there's a move to use the existing groups as mirrors: that will
> >>> overcome all of my objections: particularly if it's bidirectional! :)
> >>>
> >>>
> >>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrote=
:
> >>>
> >>>> Hey Mike,
> >>>>
> >>>> As you probably noticed when you CC'd spark-de...@googlegroups.com,
> >>>> that list has already be reconfigured so that it no longer allows
> posting
> >>>> (and bounces emails sent to it).
> >>>>
> >>>> We will be doing the same thing to the spark...@googlegroups.com lis=
t
> >>>> too (we'll announce a date for that soon).
> >>>>
> >>>> That may sound very frustrating, and you are *not* alone feeling tha=
t
> >>>> way. We've had a long conversation with our mentors about this, and
> I've
> >>>> felt very similar to you, so I'd like to give you background.
> >>>>
> >>>> As I'm coming to see it, part of becoming an Apache project is movin=
g
> >>>> the community *fully* over to Apache infrastructure, and more
> generally the
> >>>> Apache way of organizing the community.
> >>>>
> >>>> This applies in both the nuts-and-bolts sense of being on apache
> infra,
> >>>> but possibly more importantly, it is also a guiding principle and wa=
y
> of
> >>>> thinking.
> >>>>
> >>>> In various ways, moving to apache Infra can be a painful process, an=
d
> >>>> IMO the loss of all the great mailing list functionality that comes
> with
> >>>> using Google Groups is perhaps the most painful step. But basically,
> the de
> >>>> facto mailing lists need to be the Apache ones, and not Google
> Groups. The
> >>>> underlying reason is that Apache needs to take full accountability f=
or
> >>>> recording and publishing the mailing lists, it has to be able to
> >>>> institutionally guarantee this. This is because discussion on mailin=
g
> lists
> >>>> is one of the core things that defines an Apache community. So at a
> minimum
> >>>> this means Apache owning the master copy of the bits.
> >>>>
> >>>> All that said, we are discussing the possibility of having a google
> >>>> group that subscribes to each list that would provide an easier to
> use and
> >>>> prettier archive for each list (so far we haven't gotten that to
> work).
> >>>>
> >>>> I hope this was helpful. It has taken me a few years now, and a lot =
of
> >>>> conversations with experienced (and patient!) Apache mentors, to
> >>>> internalize some of the nuance about "the Apache way". That's why I
> wanted
> >>>> to share.
> >>>>
> >>>> Andy
> >>>>
> >>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com>
> wrote:
> >>>>
> >>>>> I notice that there are still a lot of active topics in this group:
> >>>>> and also activity on the apache mailing list (which is a really
> horrible
> >>>>> experience!).  Is it a firm policy on apache's front to disallow
> external
> >>>>> groups?  I'm going to be ramping up on spark, and I really hate the
> idea of
> >>>>> having to rely on the apache archives and my mail client.  Also:
> having to
> >>>>> search for topics/keywords both in old threads (here) as well as ne=
w
> >>>>> threads in apache's (clunky) archive, is going to be a pain!  I
> almost feel
> >>>>> like I must be missing something because the current solution seems
> >>>>> unfeasibly awkward!
> >>>>>
> >>>>>
> >>>>> --
> >>>>> You received this message because you are subscribed to the Google
> >>>>> Groups "Spark Users" group.
> >>>>> To unsubscribe from this group and stop receiving emails from it,
> send
> >>>>> an email to spark-users...@googlegroups.com.
> >>>>>
> >>>>> For more options, visit https://groups.google.com/groups/opt_out.
> >>>>>
> >>>>
> >>>>
> >>
> >
> > --
> > You received this message because you are subscribed to the Google Grou=
ps
> > "Spark Users" group.
> > To unsubscribe from this group and stop receiving emails from it, send =
an
> > email to spark-users+unsubscribe@googlegroups.com.
> >
> > For more options, visit https://groups.google.com/groups/opt_out.
> >
> >
> >  --
> > You received this message because you are subscribed to the Google Grou=
ps
> > "Spark Users" group.
> > To unsubscribe from this group and stop receiving emails from it, send =
an
> > email to spark-users+unsubscribe@googlegroups.com.
> >
> > For more options, visit https://groups.google.com/groups/opt_out.
> >
>



--=20
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><ht=
tp://www.twitter.com/ooyala>

--001a113480a01cadec04ee4c340b--

From dev-return-991-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 18:51:08 2013
Return-Path: <dev-return-991-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 071E5108A1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 18:51:08 +0000 (UTC)
Received: (qmail 25230 invoked by uid 500); 24 Dec 2013 18:51:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25188 invoked by uid 500); 24 Dec 2013 18:51:07 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 25180 invoked by uid 99); 24 Dec 2013 18:51:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:51:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ev@ooyala.com designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:51:04 +0000
Received: by mail-lb0-f180.google.com with SMTP id x18so2920354lbi.25
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 10:50:42 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=PwYhJu03tYacNvywg9GFzOzSmXl+NaL1/gxD4UhMZZk=;
        b=Jk94HhZLGhRwTW/pOH9UUWc2ubokP9SnSBEtPOdyFeyyKoQZnaM9pZwJ1tZYFBC0wS
         FTheiw1grQ0WROnrIJSKKm0Wgrpym6SakxpPnTwQ5lW4Pg897kcoLzZ6zrgA6gVcKijv
         rl/4buMD+kaySN2JKc8UF2EEX+EKIqozGH5AM=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=PwYhJu03tYacNvywg9GFzOzSmXl+NaL1/gxD4UhMZZk=;
        b=aD6N6575LR39eDXfhRFVu3gCjnBDiyP+sBFs7hZH3lPO7Mg3TIR+izhFf+q+QBQ68j
         T8kGbz0vY9ulRSi3YAEMZPCubzMls7tZcQqwmtHkQmIeAsgtDWG+Xz/G0wrBj7YGYlY7
         UIepCwzaMi7Ti5RyzXTl6pKKE9ltmw8aDLWSE+81oerPmHHHvPEmBflbvnY90mRL/b41
         I5ZAs+8JsmKztPcUr4WIwwfEXljrDtxgbM3fXi9Zk5Q2jJTIG23lolB5WDWXNodCXW60
         Vj1uyt9ZozHyzLiIkPev7zWPWEKV1dj2oN0k/KkbHq2ZEwi55TMeRBhpgnxyz6XA9jV/
         ZFfw==
X-Gm-Message-State: ALoCoQkao1JuDZnble9oq4hL02q4zdraEceAEDEfcbwD+uw0hd+MrbW9AYS3YiOdBkJ0EIwUNGHI
MIME-Version: 1.0
X-Received: by 10.112.157.234 with SMTP id wp10mr1500356lbb.50.1387911042373;
 Tue, 24 Dec 2013 10:50:42 -0800 (PST)
Received: by 10.112.20.10 with HTTP; Tue, 24 Dec 2013 10:50:42 -0800 (PST)
In-Reply-To: <CAPh_B=ass2NcrN41t7KTSoF1SFGce=N57YMVyukX4hPcO5YN2Q@mail.gmail.com>
References: <CAPh_B=ass2NcrN41t7KTSoF1SFGce=N57YMVyukX4hPcO5YN2Q@mail.gmail.com>
Date: Tue, 24 Dec 2013 10:50:42 -0800
Message-ID: <CADWPM3hLv_76=K=nJFmLnDLv9UCUZpYpf+6f6WLd=5dru5ssNQ@mail.gmail.com>
Subject: Re: Akka problem when using scala command to launch Spark
 applications in the current 0.9.0-SNAPSHOT
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Cc: Patrick Wendell <patrick@databricks.com>, Tathagata Das <tdas@eecs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a11c26b12a9303004ee4c3883
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c26b12a9303004ee4c3883
Content-Type: text/plain; charset=ISO-8859-1

Hi Reynold,

The default, documented methods of starting Spark all use the assembly jar,
and thus java, right?

-Evan



On Fri, Dec 20, 2013 at 11:36 PM, Reynold Xin <rxin@databricks.com> wrote:

> It took me hours to debug a problem yesterday on the latest master branch
> (0.9.0-SNAPSHOT), and I would like to share with the dev list in case
> anybody runs into this Akka problem.
>
> A little background for those of you who haven't followed closely the
> development of Spark and YARN 2.2: YARN 2.2 uses protobuf 2.5, and Akka
> uses an older version of protobuf that is not binary compatible. In order
> to have a single build that is compatible for both YARN 2.2 and pre-2.2
> YARN/Hadoop, we published a special version of Akka that builds with
> protobuf shaded (i.e. using a different package name for the protobuf
> stuff).
>
> However, it turned out Scala 2.10 includes a version of Akka jar in its
> default classpath (look at the lib folder in Scala 2.10 binary
> distribution). If you use the scala command to launch any Spark application
> on the current master branch, there is a pretty high chance that you
> wouldn't be able to create the SparkContext (stack trace at the end of the
> email). The problem is that the Akka packaged with Scala 2.10 takes
> precedence in the classloader over the special Akka version Spark includes.
>
> Before we have a good solution for this, the workaround is to use java to
> launch the application instead of scala. All you need to do is to include
> the right Scala jars (scala-library and scala-compiler) in the classpath.
> Note that the scala command is really just a simple script that calls java
> with the right classpath.
>
>
> Stack trace:
>
> java.lang.NoSuchMethodException:
> akka.remote.RemoteActorRefProvider.<init>(java.lang.String,
> akka.actor.ActorSystem$Settings, akka.event.EventStream,
> akka.actor.Scheduler, akka.actor.DynamicAccess)
> at java.lang.Class.getConstructor0(Class.java:2763)
> at java.lang.Class.getDeclaredConstructor(Class.java:2021)
> at
>
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$2.apply(DynamicAccess.scala:77)
> at scala.util.Try$.apply(Try.scala:161)
> at
>
> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:74)
> at
>
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
> at
>
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
> at scala.util.Success.flatMap(Try.scala:200)
> at
>
> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:85)
> at akka.actor.ActorSystemImpl.<init>(ActorSystem.scala:546)
> at akka.actor.ActorSystem$.apply(ActorSystem.scala:111)
> at akka.actor.ActorSystem$.apply(ActorSystem.scala:104)
> at org.apache.spark.util.AkkaUtils$.createActorSystem(AkkaUtils.scala:79)
> at
> org.apache.spark.SparkEnv$.createFromSystemProperties(SparkEnv.scala:120)
> at org.apache.spark.SparkContext.<init>(SparkContext.scala:106)
>



-- 
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><http://www.twitter.com/ooyala>

--001a11c26b12a9303004ee4c3883--

From dev-return-992-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 18:57:50 2013
Return-Path: <dev-return-992-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3912F108AB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 18:57:50 +0000 (UTC)
Received: (qmail 27665 invoked by uid 500); 24 Dec 2013 18:57:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27627 invoked by uid 500); 24 Dec 2013 18:57:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 27619 invoked by uid 99); 24 Dec 2013 18:57:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:57:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 18:57:44 +0000
Received: by mail-qc0-f177.google.com with SMTP id m20so6283333qcx.8
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 10:57:23 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=pPKxM+w/QMB5eK7w4XnmrCVKPiBJ2MySjIm4kDiFumw=;
        b=Ix1nCOP1l8kHVQvHgueuFHZYNXwaKutCH/cRAjt3YojrmLl5SREEEBPABwDLun92LE
         GQZccrbImOpWU0wigX/RyzWTCsAYMPtpBl1TDbRxviLYqdnmUslmIdkud2r2J5F+hhIi
         CNAhmBT4wJK4i/jOpou+vTKhsTAtwkcTHErAl2LXvGIEkXFszo46wR0vWA8Q1hKK2YcU
         TfagEkxmnol4odDZ+EHjCX5jwUwnQSNwDfzesbUWl0CINMDfow6feaOKjHVZQiR7BiHM
         WWcnNkA1ZlNR6c7YQnHRiJoKnu/phGLxTQDZ9o3qD7bQpI0/6oIGRkNDFyi6pz3QPHLr
         s5yQ==
X-Gm-Message-State: ALoCoQlep6MkQZreKMQaH9hlHyYEMosoVklWUJrsTS2Y4Ru2loc0t7D1G723dQqprn89dZnq8Tc2
MIME-Version: 1.0
X-Received: by 10.224.79.196 with SMTP id q4mr6407540qak.86.1387911443014;
 Tue, 24 Dec 2013 10:57:23 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Tue, 24 Dec 2013 10:57:22 -0800 (PST)
In-Reply-To: <CADWPM3hLv_76=K=nJFmLnDLv9UCUZpYpf+6f6WLd=5dru5ssNQ@mail.gmail.com>
References: <CAPh_B=ass2NcrN41t7KTSoF1SFGce=N57YMVyukX4hPcO5YN2Q@mail.gmail.com>
	<CADWPM3hLv_76=K=nJFmLnDLv9UCUZpYpf+6f6WLd=5dru5ssNQ@mail.gmail.com>
Date: Tue, 24 Dec 2013 10:57:22 -0800
Message-ID: <CAPh_B=YmH+588wP-ZJDgfUzCM3UjUGGUYvp6=J0VGgh=embjMw@mail.gmail.com>
Subject: Re: Akka problem when using scala command to launch Spark
 applications in the current 0.9.0-SNAPSHOT
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bf0eb9e8aaf8104ee4c508c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0eb9e8aaf8104ee4c508c
Content-Type: text/plain; charset=ISO-8859-1

Yup - you are safe if you stick to the official documented method.

A lot of users also use scala for a variety of reasons (e.g. old script)
and that used to work also.


On Tue, Dec 24, 2013 at 10:50 AM, Evan Chan <ev@ooyala.com> wrote:

> Hi Reynold,
>
> The default, documented methods of starting Spark all use the assembly jar,
> and thus java, right?
>
> -Evan
>
>
>
> On Fri, Dec 20, 2013 at 11:36 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > It took me hours to debug a problem yesterday on the latest master branch
> > (0.9.0-SNAPSHOT), and I would like to share with the dev list in case
> > anybody runs into this Akka problem.
> >
> > A little background for those of you who haven't followed closely the
> > development of Spark and YARN 2.2: YARN 2.2 uses protobuf 2.5, and Akka
> > uses an older version of protobuf that is not binary compatible. In order
> > to have a single build that is compatible for both YARN 2.2 and pre-2.2
> > YARN/Hadoop, we published a special version of Akka that builds with
> > protobuf shaded (i.e. using a different package name for the protobuf
> > stuff).
> >
> > However, it turned out Scala 2.10 includes a version of Akka jar in its
> > default classpath (look at the lib folder in Scala 2.10 binary
> > distribution). If you use the scala command to launch any Spark
> application
> > on the current master branch, there is a pretty high chance that you
> > wouldn't be able to create the SparkContext (stack trace at the end of
> the
> > email). The problem is that the Akka packaged with Scala 2.10 takes
> > precedence in the classloader over the special Akka version Spark
> includes.
> >
> > Before we have a good solution for this, the workaround is to use java to
> > launch the application instead of scala. All you need to do is to include
> > the right Scala jars (scala-library and scala-compiler) in the classpath.
> > Note that the scala command is really just a simple script that calls
> java
> > with the right classpath.
> >
> >
> > Stack trace:
> >
> > java.lang.NoSuchMethodException:
> > akka.remote.RemoteActorRefProvider.<init>(java.lang.String,
> > akka.actor.ActorSystem$Settings, akka.event.EventStream,
> > akka.actor.Scheduler, akka.actor.DynamicAccess)
> > at java.lang.Class.getConstructor0(Class.java:2763)
> > at java.lang.Class.getDeclaredConstructor(Class.java:2021)
> > at
> >
> >
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$2.apply(DynamicAccess.scala:77)
> > at scala.util.Try$.apply(Try.scala:161)
> > at
> >
> >
> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:74)
> > at
> >
> >
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
> > at
> >
> >
> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
> > at scala.util.Success.flatMap(Try.scala:200)
> > at
> >
> >
> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:85)
> > at akka.actor.ActorSystemImpl.<init>(ActorSystem.scala:546)
> > at akka.actor.ActorSystem$.apply(ActorSystem.scala:111)
> > at akka.actor.ActorSystem$.apply(ActorSystem.scala:104)
> > at org.apache.spark.util.AkkaUtils$.createActorSystem(AkkaUtils.scala:79)
> > at
> > org.apache.spark.SparkEnv$.createFromSystemProperties(SparkEnv.scala:120)
> > at org.apache.spark.SparkContext.<init>(SparkContext.scala:106)
> >
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/>
> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><
> http://www.twitter.com/ooyala>
>

--047d7bf0eb9e8aaf8104ee4c508c--

From dev-return-993-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 19:34:10 2013
Return-Path: <dev-return-993-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 34A0510926
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 19:34:10 +0000 (UTC)
Received: (qmail 43562 invoked by uid 500); 24 Dec 2013 19:34:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43527 invoked by uid 500); 24 Dec 2013 19:34:10 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 43518 invoked by uid 99); 24 Dec 2013 19:34:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 19:34:09 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.220.180 as permitted sender)
Received: from [209.85.220.180] (HELO mail-vc0-f180.google.com) (209.85.220.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 19:34:05 +0000
Received: by mail-vc0-f180.google.com with SMTP id ia6so3297924vcb.25
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 11:33:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=ebAD6z7T3lsM7vYSSq+E4g6FguJm4lf8RZWVvrx2HS8=;
        b=x2UVsyKSLqUA4fHeJQR2QZ4CRCS5pBOBFck6sMZd5r20o8butQgGy/rlurE99BISV4
         23PUO09FvpsVy/UoONAhcX0/tB6t6pr/1oteiPzQCnY5Ugol5arBcE6NmuVZlwZ2uAG5
         pa+ZKkOHA37LNk1KMX3+XY7KpXxLAUkY4tB2kEO3V+oDv7zEML1BalmklzqDe+xgrwl0
         4NjkLo4lycVPi9zd5O2W+IOzvg44gL+hZEObp4GrOFxHIm7HSszC5Ka92sXRqWd+mgp5
         r9DInbm0s1SL/3PLUnOO6PAmHqXn1FqNUaM1L5/KR3PW9qBqjO3fUXjnXepNW6IirD4u
         pAbQ==
X-Received: by 10.221.4.129 with SMTP id oc1mr207607vcb.32.1387913624749; Tue,
 24 Dec 2013 11:33:44 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.106.52 with HTTP; Tue, 24 Dec 2013 11:33:14 -0800 (PST)
In-Reply-To: <CAAzo=r92Fy4N6TWYya_EuhwZgBK4trZ28cY_eg_g1Nz9QO=raQ@mail.gmail.com>
References: <CAAzo=r92Fy4N6TWYya_EuhwZgBK4trZ28cY_eg_g1Nz9QO=raQ@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Tue, 24 Dec 2013 11:33:14 -0800
Message-ID: <CAMwrk0=ECphTo5oSbGO9DZD7Q7us_49nq1VpoVvX37rS8n4E-w@mail.gmail.com>
Subject: Re: Stackoverflow after a small change by me
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0115f614950c8a04ee4cd22c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0115f614950c8a04ee4cd22c
Content-Type: text/plain; charset=ISO-8859-1

Hello Dachuan,

RDDs generated by StateDStream are checkpointed because the tree of RDD
dependencies (i.e. the RDD lineage) can grow indefinitely as each state RDD
depends on the state RDD from the previous batch of data. Checkpointing
save an RDD to HDFS to cuts of all ties to its parent RDDs (i.e. truncates
the lineage). If you do not periodically checkpoint of the state RDDs,
these really large lineages can lead to all sorts of problems. The
"mustCheckpoint" field ensures that state RDDs are automatically
checkpointed with some periodicity even if the user does not explicitly
specify one. Setting mustCheckpoint to false disables this automatic
checkpointing. I think that is leading to really large lineages, and
serializing the RDD with its lineage is causing the stack to overflow.

On that note, what are you trying to achieve by setting mustCheckpoint =
false? Maybe there is another way of achieving what you are trying to
achieve.

TD


On Tue, Dec 24, 2013 at 9:05 AM, Dachuan Huang
<huangda@cse.ohio-state.edu>wrote:

> Hello, developers,
>
> Just out of curiosity, I have changed the "mustCheckpoint" in
> StateDStream.scala to "false" by default. And run the
> StatefulNetworkWordCount.scala example.
>
> My input is a 3MB/s speed Serversocket.
>
> It reports the following error after some time, the exception trace didn't
> say anything about the spark code, so I don't know how to nail down the
> root cause, can anybody help me with this? thanks.
>
> Exception in thread "DAGScheduler" java.lang.StackOverflowError
> at
> java.io.ObjectStreamClass.getPrimFieldValues(ObjectStreamClass.java:1233)
> at
> java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1532)
> at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
> at
>
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> at
> java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
> at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
> at
>
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
> at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
> at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
> at
>
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
> at java.lang.reflect.Method.invoke(Method.java:606)
> at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
> at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
> at
>
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> at
>

--089e0115f614950c8a04ee4cd22c--

From dev-return-994-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 20:01:51 2013
Return-Path: <dev-return-994-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AE1CA1098E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 20:01:51 +0000 (UTC)
Received: (qmail 57691 invoked by uid 500); 24 Dec 2013 20:01:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57625 invoked by uid 500); 24 Dec 2013 20:01:50 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 57609 invoked by uid 99); 24 Dec 2013 20:01:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 20:01:50 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 20:01:45 +0000
Received: by mail-ob0-f172.google.com with SMTP id gq1so7038112obb.3
        for <multiple recipients>; Tue, 24 Dec 2013 12:01:23 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ZYH5lwHiCtgc8Cq6y2zHP2solxLGtI4P2FHCEMSjBIM=;
        b=vNSHznrCREIGKed6bt/mi0AHj1qN2XQlw3gNeIJ0Lf2GVt9jUMEditnwbUSqvWRfrh
         mGPFbgjg1X6v1avUmyoNEvj3RBh1QaEaWdLTDlFbAI/gI7TG3ncvr32Gy6rHXtYl2Ys1
         rwkyA6fMJstPas6s1IJPmMbwCTSaecVxefnBENntpMQCKL9/5/RJ/CRe8v6yE7z+E3ts
         vBzB9Srfdoxv/mXnhzvjsCjUDtAY0tcr15vYGRT+F6sWi50mBmjXYlYiLaHPhoN0CwJC
         9Z9dppjmskVNcYqjCByrwsImdUqxy4s9//YhH5ZxB8T+JvB+hzOKMcwL9OAdaksdVzkR
         hwlA==
MIME-Version: 1.0
X-Received: by 10.182.194.5 with SMTP id hs5mr23486420obc.19.1387915283657;
 Tue, 24 Dec 2013 12:01:23 -0800 (PST)
Received: by 10.182.132.46 with HTTP; Tue, 24 Dec 2013 12:01:23 -0800 (PST)
In-Reply-To: <CADWPM3h2t5_SAy05_bVpBAWfTAMoM4u+ghAoPY2B5NnANgJ9cQ@mail.gmail.com>
References: <92A94BB6-C42B-47B3-836C-321D61FEB645@gmail.com>
	<cbf2d069-ad50-470c-a278-15f1bde8c37b@googlegroups.com>
	<CALEZFQz2-dS5TkFGGXE2cxj2bMxeO1BC=s-wR0s1hU6j4KQZLw@mail.gmail.com>
	<B186D062-82AA-4538-99B5-A6E4DAD42AAC@gmail.com>
	<b875e357-24ba-4e84-9c37-505c05805e06@googlegroups.com>
	<CALEZFQzxxCe=4UxCZa8eD9du_WbcBJPh1dtb+1ZYF6NR3NTUMw@mail.gmail.com>
	<9b091e58-1f23-4228-a3b2-28ec57c91115@googlegroups.com>
	<CANGvG8qwUvE0qZfgT5eBB8Y-vU4BAhG3v8XHvvbi_0MmCW3_oA@mail.gmail.com>
	<CALEZFQzH9pEydhxt1esaswbwyyaeiPNi6ytvJbjdw4nGun2Mrw@mail.gmail.com>
	<381CA8AD-B194-4D63-A20D-6B2C0B215A18@gmail.com>
	<CALEZFQzZbfNB0HDra5_G5kfbi-acSUXWB6N0TF+n0PC4L1z-yA@mail.gmail.com>
	<CADWPM3h2t5_SAy05_bVpBAWfTAMoM4u+ghAoPY2B5NnANgJ9cQ@mail.gmail.com>
Date: Tue, 24 Dec 2013 12:01:23 -0800
Message-ID: <CABPQxstBrjOH-hFM9hEUSiGQLaT0wyt4VwFgOv8A_dW8UfEJOA@mail.gmail.com>
Subject: Re: IMPORTANT: Spark mailing lists moving to Apache by September 1st
From: Patrick Wendell <pwendell@gmail.com>
To: "spark-users@googlegroups.com" <spark-users@googlegroups.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, user@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d0444eb2975fd0104ee4d35c8
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0444eb2975fd0104ee4d35c8
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Hey Andy - these Nabble groups look great! Thanks for setting them up.


On Tue, Dec 24, 2013 at 10:49 AM, Evan Chan <ev@ooyala.com> wrote:

> Thanks Andy, at first glance nabble seems great, it allows search plus
> posting new topics, so it appears to be bidirectional.    Now just have t=
o
> register an account on there.
>
>
> On Sun, Dec 22, 2013 at 2:47 PM, Andy Konwinski <andykonwinski@gmail.com>=
wrote:
>
>> Per Matei's suggestion, I've set up two nabble archive lists, one to
>> archive the apache dev list and one to archive the apache user list.
>>
>> user list archive: http://apache-spark-user-list.1001560.n3.nabble.com
>> dev list archive:
>> http://apache-spark-developers-list.1001551.n3.nabble.com
>>
>> Between these and whatever solution we end up with for the google group
>> mirrors, we should have decent enough alternatives to reading via the
>> apache list archives going forward.
>>
>>
>> On Thu, Dec 19, 2013 at 11:09 PM, Matei Zaharia <matei.zaharia@gmail.com
>> >wrote:
>>
>> > Yes, I agree that we should close down the existing Google group on Ja=
n
>> > 1st. While it=92s more convenient to use, it=92s created confusion. I =
hope
>> that
>> > we can get the ASF to support better search interfaces in the future
>> too. I
>> > think we just have to drive this from within.
>> >
>> > The Google Group should be a nice way to make the content searchable
>> from
>> > the web. We should also see what it takes to make it mirrored on Nabbl=
e
>> (
>> > http://www.nabble.com). I=92ve found a lot of information about other
>> > projects there, and other Apache projects do use it.
>> >
>> > Matei
>> >
>> > On Dec 19, 2013, at 10:49 PM, Andy Konwinski <andykonwinski@gmail.com>
>> > wrote:
>> >
>> > I've set up two new unofficial google groups to mirror the Apache Spar=
k
>> > user and dev lists:
>> >
>> > https://groups.google.com/forum/#!forum/apache-spark-dev-mirror
>> > https://groups.google.com/forum/#!forum/apache-spark-user-mirror
>> >
>> > Basically these lists each subscribe to the corresponding Apache list.
>> >
>> > They do not allow folks to subscribe directly to them. Getting emails
>> from
>> > the Google Group would offer no advantages that I can think of and we
>> > really want to encourage folks to sign up for the official mailing lis=
t
>> > instead.
>> >
>> > The lists do allow the public to send email to them, which I think mig=
ht
>> > be necessary since the "from:" field for all emails that get distribut=
ed
>> > via the Apache mailing list is set to the author of the email.
>> >
>> > I think this might be a great compromise. At least we can try this out
>> and
>> > see how it goes.
>> >
>> > Matei, can you confirm that Jan 1 is the date we want to turn off the
>> > existing spark-users google group?
>> >
>> > We could consider using the existing spark-developers and spark-users
>> > google groups instead of the two new ones I just created but I think
>> that
>> > it is much more obvious to have the lists include the word mirror in
>> their
>> > names.
>> >
>> > The dev list mirror seems to be working, because I see the last couple
>> > emails from this thread in it already. I'll confirm and ensure that th=
e
>> > user list mirror is working too.
>> >
>> > Thoughts?
>> >
>> > Andy
>> >
>> > P.S. Thanks to Patrick for suggesting this to me originally.
>> >
>> > On Thu, Dec 19, 2013 at 8:46 PM, Aaron Davidson <ilikerps@gmail.com
>> >wrote:
>> >
>> >> I'd be fine with one-way mirrors here (Apache threads being reflected
>> in
>> >> Google groups) -- I have no idea how one is supposed to navigate the
>> Apache
>> >> list to look for historic threads.
>> >>
>> >>
>> >> On Thu, Dec 19, 2013 at 7:58 PM, Mike Potts <maspotts@gmail.com>
>> wrote:
>> >>
>> >>> Thanks very much for the prompt and comprehensive reply!  I apprecia=
te
>> >>> the overarching desire to integrate with apache: I'm very happy to
>> hear
>> >>> that there's a move to use the existing groups as mirrors: that will
>> >>> overcome all of my objections: particularly if it's bidirectional! :=
)
>> >>>
>> >>>
>> >>> On Thursday, December 19, 2013 7:19:06 PM UTC-8, Andy Konwinski wrot=
e:
>> >>>
>> >>>> Hey Mike,
>> >>>>
>> >>>> As you probably noticed when you CC'd spark-de...@googlegroups.com,
>> >>>> that list has already be reconfigured so that it no longer allows
>> posting
>> >>>> (and bounces emails sent to it).
>> >>>>
>> >>>> We will be doing the same thing to the spark...@googlegroups.comlis=
t
>> >>>> too (we'll announce a date for that soon).
>> >>>>
>> >>>> That may sound very frustrating, and you are *not* alone feeling th=
at
>> >>>> way. We've had a long conversation with our mentors about this, and
>> I've
>> >>>> felt very similar to you, so I'd like to give you background.
>> >>>>
>> >>>> As I'm coming to see it, part of becoming an Apache project is movi=
ng
>> >>>> the community *fully* over to Apache infrastructure, and more
>> generally the
>> >>>> Apache way of organizing the community.
>> >>>>
>> >>>> This applies in both the nuts-and-bolts sense of being on apache
>> infra,
>> >>>> but possibly more importantly, it is also a guiding principle and
>> way of
>> >>>> thinking.
>> >>>>
>> >>>> In various ways, moving to apache Infra can be a painful process, a=
nd
>> >>>> IMO the loss of all the great mailing list functionality that comes
>> with
>> >>>> using Google Groups is perhaps the most painful step. But basically=
,
>> the de
>> >>>> facto mailing lists need to be the Apache ones, and not Google
>> Groups. The
>> >>>> underlying reason is that Apache needs to take full accountability
>> for
>> >>>> recording and publishing the mailing lists, it has to be able to
>> >>>> institutionally guarantee this. This is because discussion on
>> mailing lists
>> >>>> is one of the core things that defines an Apache community. So at a
>> minimum
>> >>>> this means Apache owning the master copy of the bits.
>> >>>>
>> >>>> All that said, we are discussing the possibility of having a google
>> >>>> group that subscribes to each list that would provide an easier to
>> use and
>> >>>> prettier archive for each list (so far we haven't gotten that to
>> work).
>> >>>>
>> >>>> I hope this was helpful. It has taken me a few years now, and a lot
>> of
>> >>>> conversations with experienced (and patient!) Apache mentors, to
>> >>>> internalize some of the nuance about "the Apache way". That's why I
>> wanted
>> >>>> to share.
>> >>>>
>> >>>> Andy
>> >>>>
>> >>>> On Thu, Dec 19, 2013 at 6:28 PM, Mike Potts <masp...@gmail.com>
>> wrote:
>> >>>>
>> >>>>> I notice that there are still a lot of active topics in this group=
:
>> >>>>> and also activity on the apache mailing list (which is a really
>> horrible
>> >>>>> experience!).  Is it a firm policy on apache's front to disallow
>> external
>> >>>>> groups?  I'm going to be ramping up on spark, and I really hate th=
e
>> idea of
>> >>>>> having to rely on the apache archives and my mail client.  Also:
>> having to
>> >>>>> search for topics/keywords both in old threads (here) as well as n=
ew
>> >>>>> threads in apache's (clunky) archive, is going to be a pain!  I
>> almost feel
>> >>>>> like I must be missing something because the current solution seem=
s
>> >>>>> unfeasibly awkward!
>> >>>>>
>> >>>>>
>> >>>>> --
>> >>>>> You received this message because you are subscribed to the Google
>> >>>>> Groups "Spark Users" group.
>> >>>>> To unsubscribe from this group and stop receiving emails from it,
>> send
>> >>>>> an email to spark-users...@googlegroups.com.
>> >>>>>
>> >>>>> For more options, visit https://groups.google.com/groups/opt_out.
>> >>>>>
>> >>>>
>> >>>>
>> >>
>> >
>> > --
>> > You received this message because you are subscribed to the Google
>> Groups
>> > "Spark Users" group.
>> > To unsubscribe from this group and stop receiving emails from it, send
>> an
>> > email to spark-users+unsubscribe@googlegroups.com.
>> >
>> > For more options, visit https://groups.google.com/groups/opt_out.
>> >
>> >
>> >  --
>> > You received this message because you are subscribed to the Google
>> Groups
>> > "Spark Users" group.
>> > To unsubscribe from this group and stop receiving emails from it, send
>> an
>> > email to spark-users+unsubscribe@googlegroups.com.
>> >
>> > For more options, visit https://groups.google.com/groups/opt_out.
>> >
>>
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/> <http://www.facebook.com/ooyala><http://www.link=
edin.com/company/ooyala><http://www.twitter.com/ooyala>
>
>  --
> You received this message because you are subscribed to the Google Groups
> "Spark Users" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to spark-users+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/groups/opt_out.
>

--f46d0444eb2975fd0104ee4d35c8--

From dev-return-995-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 20:35:01 2013
Return-Path: <dev-return-995-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1E0DF10A45
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 20:35:01 +0000 (UTC)
Received: (qmail 78323 invoked by uid 500); 24 Dec 2013 20:35:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78290 invoked by uid 500); 24 Dec 2013 20:35:00 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 78282 invoked by uid 99); 24 Dec 2013 20:35:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 20:35:00 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hdc1112@gmail.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Dec 2013 20:34:56 +0000
Received: by mail-vc0-f181.google.com with SMTP id ks9so3502188vcb.26
        for <dev@spark.incubator.apache.org>; Tue, 24 Dec 2013 12:34:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:content-type;
        bh=69o9HK0xT3VNB9Zf2bnVPD3vU7eK8xzgyQdvj6UNSVs=;
        b=VCfNghaFKzI7Js3STG5pk3BIG8tyJfQo+zQY2tumdJu+IKXixzoct/8B2x2R3Ohtd0
         v0NBnacxeHmGQUxm2N3jCBNLrVYF4sn6vQHOsi6FYju8pdji6yGSWlBdA7jIYyS+oLAY
         6LXPsoJwO0wpZmIkcbNBHH1dAPAv51/KsJvh2279vDOiuXUlNXbROYg2V+CpmdZ8mVUl
         xJRK5Cl9Hbnfz0VIc4CJtzy6Ndg+ei7qNYuWwWEftc6UjFt5dBovJdUn107mwIeV1JCq
         f9J60UjlfouzYx6ADqHTv7YUIjmb3lEhOBxFTkD+QARkoiTWj3o9RzkVymew5PxSy6Y3
         3yNA==
MIME-Version: 1.0
X-Received: by 10.58.46.171 with SMTP id w11mr17140241vem.5.1387917275511;
 Tue, 24 Dec 2013 12:34:35 -0800 (PST)
Sender: hdc1112@gmail.com
Received: by 10.58.32.199 with HTTP; Tue, 24 Dec 2013 12:34:35 -0800 (PST)
In-Reply-To: <CAMwrk0=ECphTo5oSbGO9DZD7Q7us_49nq1VpoVvX37rS8n4E-w@mail.gmail.com>
References: <CAAzo=r92Fy4N6TWYya_EuhwZgBK4trZ28cY_eg_g1Nz9QO=raQ@mail.gmail.com>
	<CAMwrk0=ECphTo5oSbGO9DZD7Q7us_49nq1VpoVvX37rS8n4E-w@mail.gmail.com>
Date: Tue, 24 Dec 2013 15:34:35 -0500
X-Google-Sender-Auth: PMmcN5DUx8-etgFOQx5RKTBpsoQ
Message-ID: <CAAzo=r_i+gwY_=9vbPs52g+eNzg6pV5cv-bCbWtL1D4if9AyZw@mail.gmail.com>
Subject: Re: Stackoverflow after a small change by me
From: Dachuan Huang <huangda@cse.ohio-state.edu>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013cbdf22f42b204ee4dacc3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013cbdf22f42b204ee4dacc3
Content-Type: text/plain; charset=ISO-8859-1

Yes, your explanation makes sense.

I try to disable the checkpoint and use that as a control group to measure
the overhead of checkpoint. Now I guess I can create a dummy CheckpointRDD
to do this task (a better way?).

Besides, I am curious about where exactly the StackOverflowError happens,
because serialization usually happens under the hood, it's hard to find it.
I have tried this line of code, but it seems this is not the root cause.

serializedTask = Task.serializeWithDependencies(task, sched.sc.addedFiles,
sched.sc.addedJars, ser)

On Tue, Dec 24, 2013 at 2:33 PM, Tathagata Das
<tathagata.das1565@gmail.com>wrote:

> Hello Dachuan,
>
> RDDs generated by StateDStream are checkpointed because the tree of RDD
> dependencies (i.e. the RDD lineage) can grow indefinitely as each state RDD
> depends on the state RDD from the previous batch of data. Checkpointing
> save an RDD to HDFS to cuts of all ties to its parent RDDs (i.e. truncates
> the lineage). If you do not periodically checkpoint of the state RDDs,
> these really large lineages can lead to all sorts of problems. The
> "mustCheckpoint" field ensures that state RDDs are automatically
> checkpointed with some periodicity even if the user does not explicitly
> specify one. Setting mustCheckpoint to false disables this automatic
> checkpointing. I think that is leading to really large lineages, and
> serializing the RDD with its lineage is causing the stack to overflow.
>
> On that note, what are you trying to achieve by setting mustCheckpoint =
> false? Maybe there is another way of achieving what you are trying to
> achieve.
>
> TD
>
>
> On Tue, Dec 24, 2013 at 9:05 AM, Dachuan Huang
> <huangda@cse.ohio-state.edu>wrote:
>
> > Hello, developers,
> >
> > Just out of curiosity, I have changed the "mustCheckpoint" in
> > StateDStream.scala to "false" by default. And run the
> > StatefulNetworkWordCount.scala example.
> >
> > My input is a 3MB/s speed Serversocket.
> >
> > It reports the following error after some time, the exception trace
> didn't
> > say anything about the spark code, so I don't know how to nail down the
> > root cause, can anybody help me with this? thanks.
> >
> > Exception in thread "DAGScheduler" java.lang.StackOverflowError
> > at
> > java.io.ObjectStreamClass.getPrimFieldValues(ObjectStreamClass.java:1233)
> > at
> >
> java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1532)
> > at
> java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
> > at
> >
> >
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> > at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> > at
> >
> java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
> > at
> java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
> > at
> >
> >
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> > at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> > at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
> > at scala.collection.immutable.$colon$colon.writeObject(List.scala:430)
> > at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
> > at
> >
> >
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
> > at java.lang.reflect.Method.invoke(Method.java:606)
> > at
> java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
> > at
> java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
> > at
> >
> >
> java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
> > at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
> > at
> >
>

--089e013cbdf22f42b204ee4dacc3--

From dev-return-996-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 24 20:51:04 2013
Return-Path: <dev-return-996-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A39DE10AC9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Dec 2013 20:51:04 +0000 (UTC)
Received: (qmail 90638 invoked by uid 500); 24 Dec 2013 20:51:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90602 invoked by uid 500); 24 Dec 2013 20:51:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 89802 invoked by uid 99); 24 Dec 2013 20:50:12 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=9kzmy6Lyvt6bshQgVMQe1tN2uqPhk7IqeI9zD5nEFnQ=;
        b=Xe8H0Oba/9nu3CqCmLiDCDM7h0wUmL3P8FxPx68H+SFQG1iQawB0eHY8Iu5u2cTjh0
         FGEGRfpbY5Kh+ci0eXnXuHoB3tKik9v6qkspBUV4TXYgR3LOxxVxCGEparfCUgYEcPDw
         FqSEGbApGJI5Kifxp8nx1yGCdfa547oqItheZyUUmqeSZyYFECxUJrwuLqR17hFDXT49
         HW/1FVVPJjBpUqrOnSjubzIy2JIzQ37gqZdZU4DO25qImnzIhg0y1cYYVsOyuoibYjky
         hbVein+5ml/HBcYCgyDu8MQbKXlecn0TM0XaBPTRKcVn/DL2FUoZrHA0k4EVLobYWwWs
         Dtyg==
X-Gm-Message-State: ALoCoQnSMDprZxwOVLZ+EpLHC2S593z934lCK72zNi3lPStu9jlDlC+jtMqZN95uJAqZ6UJ/Wd1h
MIME-Version: 1.0
X-Received: by 10.182.199.70 with SMTP id ji6mr23576379obc.36.1387918187422;
 Tue, 24 Dec 2013 12:49:47 -0800 (PST)
In-Reply-To: <CADWPM3hLv_76=K=nJFmLnDLv9UCUZpYpf+6f6WLd=5dru5ssNQ@mail.gmail.com>
References: <CAPh_B=ass2NcrN41t7KTSoF1SFGce=N57YMVyukX4hPcO5YN2Q@mail.gmail.com>
	<CADWPM3hLv_76=K=nJFmLnDLv9UCUZpYpf+6f6WLd=5dru5ssNQ@mail.gmail.com>
Date: Tue, 24 Dec 2013 12:49:47 -0800
Message-ID: <CAM6vJxHaVocAZ4oceOtHg5k35CoOHpkbsyGj_zz=NH7daMgUKA@mail.gmail.com>
Subject: Re: Akka problem when using scala command to launch Spark
 applications in the current 0.9.0-SNAPSHOT
From: Patrick Wendell <patrick@databricks.com>
To: Evan Chan <ev@ooyala.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>, Tathagata Das <tdas@eecs.berkeley.edu>
Content-Type: multipart/alternative; boundary=e89a8ff1cbda89f8f304ee4de26b
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8ff1cbda89f8f304ee4de26b
Content-Type: text/plain; charset=ISO-8859-1

Even,

This problem also exists for people who write their own applications that
depend on/include Spark. E.g. they bundle up their app and then launch the
driver with "scala -cp my-budle.jar"... I've seen this cause an issue in
that setting.

- Patrick


On Tue, Dec 24, 2013 at 10:50 AM, Evan Chan <ev@ooyala.com> wrote:

> Hi Reynold,
>
> The default, documented methods of starting Spark all use the assembly
> jar, and thus java, right?
>
> -Evan
>
>
>
> On Fri, Dec 20, 2013 at 11:36 PM, Reynold Xin <rxin@databricks.com> wrote:
>
>> It took me hours to debug a problem yesterday on the latest master branch
>> (0.9.0-SNAPSHOT), and I would like to share with the dev list in case
>> anybody runs into this Akka problem.
>>
>> A little background for those of you who haven't followed closely the
>> development of Spark and YARN 2.2: YARN 2.2 uses protobuf 2.5, and Akka
>> uses an older version of protobuf that is not binary compatible. In order
>> to have a single build that is compatible for both YARN 2.2 and pre-2.2
>> YARN/Hadoop, we published a special version of Akka that builds with
>> protobuf shaded (i.e. using a different package name for the protobuf
>> stuff).
>>
>> However, it turned out Scala 2.10 includes a version of Akka jar in its
>> default classpath (look at the lib folder in Scala 2.10 binary
>> distribution). If you use the scala command to launch any Spark
>> application
>> on the current master branch, there is a pretty high chance that you
>> wouldn't be able to create the SparkContext (stack trace at the end of the
>> email). The problem is that the Akka packaged with Scala 2.10 takes
>> precedence in the classloader over the special Akka version Spark
>> includes.
>>
>> Before we have a good solution for this, the workaround is to use java to
>> launch the application instead of scala. All you need to do is to include
>> the right Scala jars (scala-library and scala-compiler) in the classpath.
>> Note that the scala command is really just a simple script that calls java
>> with the right classpath.
>>
>>
>> Stack trace:
>>
>> java.lang.NoSuchMethodException:
>> akka.remote.RemoteActorRefProvider.<init>(java.lang.String,
>> akka.actor.ActorSystem$Settings, akka.event.EventStream,
>> akka.actor.Scheduler, akka.actor.DynamicAccess)
>> at java.lang.Class.getConstructor0(Class.java:2763)
>> at java.lang.Class.getDeclaredConstructor(Class.java:2021)
>> at
>>
>> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$2.apply(DynamicAccess.scala:77)
>> at scala.util.Try$.apply(Try.scala:161)
>> at
>>
>> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:74)
>> at
>>
>> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
>> at
>>
>> akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$3.apply(DynamicAccess.scala:85)
>> at scala.util.Success.flatMap(Try.scala:200)
>> at
>>
>> akka.actor.ReflectiveDynamicAccess.createInstanceFor(DynamicAccess.scala:85)
>> at akka.actor.ActorSystemImpl.<init>(ActorSystem.scala:546)
>> at akka.actor.ActorSystem$.apply(ActorSystem.scala:111)
>> at akka.actor.ActorSystem$.apply(ActorSystem.scala:104)
>> at org.apache.spark.util.AkkaUtils$.createActorSystem(AkkaUtils.scala:79)
>> at
>> org.apache.spark.SparkEnv$.createFromSystemProperties(SparkEnv.scala:120)
>> at org.apache.spark.SparkContext.<init>(SparkContext.scala:106)
>>
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><http://www.twitter.com/ooyala>
>
>

--e89a8ff1cbda89f8f304ee4de26b--

From dev-return-997-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 25 17:42:38 2013
Return-Path: <dev-return-997-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D5B081097B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Dec 2013 17:42:38 +0000 (UTC)
Received: (qmail 19154 invoked by uid 500); 25 Dec 2013 17:42:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19040 invoked by uid 500); 25 Dec 2013 17:42:13 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 79669 invoked by uid 99); 25 Dec 2013 13:22:16 -0000
X-ASF-Spam-Status: No, hits=1.3 required=5.0
	tests=FSL_HELO_BARE_IP_2,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of prime@yandex-team.ru designates 95.108.253.251 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yandex-team.ru;
	s=default; t=1387977709;
	bh=CkaHo9as0Sfh32s5kA9w4VfWeQD6CebyUWkq+GLFaXY=;
	h=From:To:Cc:Subject:Date;
	b=LGZWwg9JA04IxPyz6pcdS8l71OZL62jSAiIF1bKb0Zx/KrAePbwI30MgTgPED9z69
	 hgRXhnN0sbY96sObtJJ4jLJw2iuBflOkxgmPsP7lhUpfQqSmB1Rydb8t92hlgTFNLy
	 nVT/XfHrGOFY4yJvTAYmGo4t4WiEJzwd6whioZr0=
From: =?koi8-r?B?5qPEz9Ig68/Sz9TLyco=?= <prime@yandex-team.ru>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Cc: Philipp Sinitsyn <phill@yandex-team.ru>,
	Ivan Puzyrevskiy <sandello@yandex-team.ru>
Subject: Spark graduate project ideas
MIME-Version: 1.0
Message-Id: <37941387977708@webcorp1h.yandex-team.ru>
X-Mailer: Yamail [ http://yandex.ru ] 5.0
Date: Wed, 25 Dec 2013 17:21:48 +0400
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset=utf-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

Currently I’m pursuing a masters degree in CS and I’m in search of my year project theme (in distributed systems field), and Spark seems very interesting to me. 

Can you suggest some problems or ideas to work on? 

By the way, what is the status of external sorting(https://spark-project.atlassian.net/browse/SPARK-983)?

From dev-return-998-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Wed Dec 25 17:51:30 2013
Return-Path: <dev-return-998-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E66D61098E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Dec 2013 17:51:30 +0000 (UTC)
Received: (qmail 21443 invoked by uid 500); 25 Dec 2013 17:51:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21406 invoked by uid 500); 25 Dec 2013 17:51:28 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 15332 invoked by uid 99); 25 Dec 2013 14:15:27 -0000
X-ASF-Spam-Status: No, hits=-2000.0 required=5.0
	tests=ALL_TRUSTED
X-Spam-Check-By: apache.org
To: dev@spark.incubator.apache.org
From: Marvin <no-reply@apache.org>
Subject: Incubator PMC/Board report for Jan 2014 ([ppmc])
Message-Id: <20131225141502.7CFCF2388D44@eris.apache.org>
Date: Wed, 25 Dec 2013 14:15:02 +0000 (UTC)
X-Virus-Checked: Checked by ClamAV on apache.org



Dear podling,

This email was sent by an automated system on behalf of the Apache Incubator PMC.
It is an initial reminder to give you plenty of time to prepare your quarterly
board report.

The board meeting is scheduled for Wed, 15 January 2014, 10:30:30:00 PST. The report 
for your podling will form a part of the Incubator PMC report. The Incubator PMC 
requires your report to be submitted 2 weeks before the board meeting, to allow 
sufficient time for review and submission (Wed, Jan 1st).

Please submit your report with sufficient time to allow the incubator PMC, and 
subsequently board members to review and digest. Again, the very latest you 
should submit your report is 2 weeks prior to the board meeting.

Thanks,

The Apache Incubator PMC

Submitting your Report
----------------------

Your report should contain the following:

 * Your project name
 * A brief description of your project, which assumes no knowledge of the project
   or necessarily of its field
 * A list of the three most important issues to address in the move towards 
   graduation.
 * Any issues that the Incubator PMC or ASF Board might wish/need to be aware of
 * How has the community developed since the last report
 * How has the project developed since the last report.
 
This should be appended to the Incubator Wiki page at:

  http://wiki.apache.org/incubator/January2014

Note: This manually populated. You may need to wait a little before this page is
      created from a template.

Mentors
-------
Mentors should review reports for their project(s) and sign them off on the 
Incubator wiki page. Signing off reports shows that you are following the 
project - projects that are not signed may raise alarms for the Incubator PMC.

Incubator PMC


From dev-return-999-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 03:33:51 2013
Return-Path: <dev-return-999-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4222810F18
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 03:33:51 +0000 (UTC)
Received: (qmail 9507 invoked by uid 500); 26 Dec 2013 03:33:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9125 invoked by uid 500); 26 Dec 2013 03:33:46 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 9116 invoked by uid 99); 26 Dec 2013 03:33:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 03:33:45 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of puravaggarwal123@gmail.com designates 209.85.212.51 as permitted sender)
Received: from [209.85.212.51] (HELO mail-vb0-f51.google.com) (209.85.212.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 03:33:37 +0000
Received: by mail-vb0-f51.google.com with SMTP id 11so3879372vbe.24
        for <dev@spark.incubator.apache.org>; Wed, 25 Dec 2013 19:33:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=C28oU6xqTLb5hDCb6rQw2b+MPUrNeR37lEsFU45BdhE=;
        b=Am3upoVgxmLeEHr0Fpqlb1hrDVWOLWF+RdK2th9rDXWpWdQu1W2uERTR72rV/GNXTV
         AxTKnRBfR3O2QPUbEIvI79r6DwOncsj/Bi5haqKCyhs9c36ND+tKgDV8kFFBbgSEFF/q
         G1pQHpGasCbzKnFyOY0/wEhNxO3jfyEupliwzO7wj7YeJJOjQm4Qs8CSXBkQd2qEcfPb
         vTjGMpYpHRZTKR7bPfs91jLwqp+PYRt8uGYzsgQMjHSp9nBe+D2Usb4mnhNN/l5JXWOc
         QjURSDmeqzm+KZGiIXxTdAohSE2F+Avw2yJwytRqN3wxb3sKIp/gxSISS+ekqsEwJniG
         xpsg==
X-Received: by 10.53.9.201 with SMTP id du9mr1687695vdd.36.1388028796160; Wed,
 25 Dec 2013 19:33:16 -0800 (PST)
MIME-Version: 1.0
Received: by 10.58.207.163 with HTTP; Wed, 25 Dec 2013 19:32:56 -0800 (PST)
From: purav aggarwal <puravaggarwal123@gmail.com>
Date: Thu, 26 Dec 2013 09:02:56 +0530
Message-ID: <CAPNhUcdNpoXN89aGgA4pK-Gb3yU_JAdGBvsUFjVQ=dXPjsW37Q@mail.gmail.com>
Subject: Large DataStructure to Broadcast
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1133b1ac5551cc04ee67a327
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133b1ac5551cc04ee67a327
Content-Type: text/plain; charset=ISO-8859-1

Hi all,

I have a large file ( > 5 gigs) which I need to lookup. Since each slave
need to perform the search operation on the hashmap (built out of the file)
in parallel I need to broadcast the file. I was wondering if broadcasting
such a huge file is really a good idea. Do we have any benchmarks for the
broadcast variables. I am on a Standalone cluster and machine configuration
is not a problem at the moment.
Has anyone exploited broadcast to such an extent ?

Thanks,
Purav

--001a1133b1ac5551cc04ee67a327--

From dev-return-1000-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 03:55:50 2013
Return-Path: <dev-return-1000-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A9A0A10F52
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 03:55:50 +0000 (UTC)
Received: (qmail 25609 invoked by uid 500); 26 Dec 2013 03:55:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25222 invoked by uid 500); 26 Dec 2013 03:55:47 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 25213 invoked by uid 99); 26 Dec 2013 03:55:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 03:55:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mosharafkabir@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 03:55:40 +0000
Received: by mail-ie0-f175.google.com with SMTP id x13so7998936ief.6
        for <dev@spark.incubator.apache.org>; Wed, 25 Dec 2013 19:55:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=I9uamml521uk02+woY1f+vq84x5TzAvwpsmcPtO15ac=;
        b=gMEJne4ZvYyLJBQiIJ633TXlLAxOPiSVRBRgDHM9zrawnCLeJPRMA7hEjLgUZX5HQZ
         Q6+51KlHbCYFYllokjGtKy3HpzvDur9O1hkXhcCiwHtNUTdwdqGx9y9De3dqgnYC+nkJ
         aXsCHsmi0jr411oOPHhU4JVQH16XFZ/XJ5QCYT8rewI+C+oPJbf/MpR7eOhQzA5VcQnx
         zDfodEW/UQOCvUKXe5ZA/qVFLvRapAtBIkBTPsS+nDLG0RnurFBXxoj9epeZkDP4GV32
         LjppJ1SUDZOa/MPLTibIjGXRdtjx8h5zUDTuADHgmlcrwiOzdOeSmS8Q1H8tG5Nu1AOQ
         MFDA==
X-Received: by 10.50.66.212 with SMTP id h20mr32337564igt.48.1388030119631;
 Wed, 25 Dec 2013 19:55:19 -0800 (PST)
MIME-Version: 1.0
Received: by 10.50.234.226 with HTTP; Wed, 25 Dec 2013 19:54:49 -0800 (PST)
In-Reply-To: <CAPNhUcdNpoXN89aGgA4pK-Gb3yU_JAdGBvsUFjVQ=dXPjsW37Q@mail.gmail.com>
References: <CAPNhUcdNpoXN89aGgA4pK-Gb3yU_JAdGBvsUFjVQ=dXPjsW37Q@mail.gmail.com>
From: Mosharaf Chowdhury <mosharafkabir@gmail.com>
Date: Wed, 25 Dec 2013 19:54:49 -0800
Message-ID: <CAK=PQ7AMCMGs8AvtVLaaCEukQ1-9PpvFYzdFeFE0kvdQ_yAXWQ@mail.gmail.com>
Subject: Re: Large DataStructure to Broadcast
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bdc1b7237e6e104ee67f263
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc1b7237e6e104ee67f263
Content-Type: text/plain; charset=ISO-8859-1

You should try out TorrentBroadcast (NOT BitTorrentBroadcast) from the
0.8.1 branch.
In your config file, set spark.broadcast.factory=
org.apache.spark.broadcast.TorrentBroadcastFactory
It should perform significantly better than HttpBroadcast (some benchmarks
here: https://github.com/apache/incubator-spark/pull/68). I expect a 10X
improvement over the default.
Make sure you have enough memory in slaves.

--
Mosharaf Chowdhury
http://www.mosharaf.com/


On Wed, Dec 25, 2013 at 7:32 PM, purav aggarwal
<puravaggarwal123@gmail.com>wrote:

> Hi all,
>
> I have a large file ( > 5 gigs) which I need to lookup. Since each slave
> need to perform the search operation on the hashmap (built out of the file)
> in parallel I need to broadcast the file. I was wondering if broadcasting
> such a huge file is really a good idea. Do we have any benchmarks for the
> broadcast variables. I am on a Standalone cluster and machine configuration
> is not a problem at the moment.
> Has anyone exploited broadcast to such an extent ?
>
> Thanks,
> Purav
>

--047d7bdc1b7237e6e104ee67f263--

From dev-return-1001-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 05:12:08 2013
Return-Path: <dev-return-1001-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2EA51100DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 05:12:08 +0000 (UTC)
Received: (qmail 74649 invoked by uid 500); 26 Dec 2013 05:12:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74592 invoked by uid 500); 26 Dec 2013 05:12:03 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 74580 invoked by uid 99); 26 Dec 2013 05:12:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 05:12:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ctn@adatao.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 05:11:56 +0000
Received: by mail-ie0-f178.google.com with SMTP id lx4so8452206iec.9
        for <dev@spark.incubator.apache.org>; Wed, 25 Dec 2013 21:11:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=ACuzsdPaRkyUF5NlD8e58xeTUy/zJmszs0e46kFrqDM=;
        b=T8ITxQHUBFQdnHu5nXvn60T+NohFR9kMEg4Fm14QYBgEqXlmu+GgegkUjESuedQnbt
         GtMA1eeIJXcN14RBtGT2aSfDTNVGIv92F48eDWVCWl5OC//uXlrtSE9nv9qQm9neh6QX
         cR0gS4PlQ8uJmlOpzeA646ZSZ+X70R3k0mfaQ=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=ACuzsdPaRkyUF5NlD8e58xeTUy/zJmszs0e46kFrqDM=;
        b=gWRT+XvtRXvYx8w2ZobdGBnkAyVI8DBFc5EBf9oQJYkNdZ0x0TwgAyUDxcp/CKp5OL
         acDjWhLsgl7vsBaFDA6BA8oRzoZQ9xSTgNyq8l4JXT4j3HQCkErUIKu6oV03IxpoxzDw
         oOSIhSfcGRU8IwQlCki4SjlCnFOO0HKSuk6OLG4MNwJ3aHx2ws2Pyn/8ZtyL6ASstrnH
         91HvJ03TUi5tfhnEiXIVe63Il+7Kxu2Zw7wQEdPJ8fIV9aO5RGH1tVzoDSnFfw9eWdSc
         xbfgzYu5c3fhBKzwFlVSfzzum0mDq9SzRCVDCrx8LJe/qE1e2zq3O/6TrF+Z+D0UGZ6C
         xxkQ==
X-Gm-Message-State: ALoCoQkrnPPmiZYmVfziDeXAzPfzAqqFIc3muOykogNpYvWSEIfX6vmGyd1ufvkq3GwMk3vvg4Qv
X-Received: by 10.42.48.202 with SMTP id t10mr26768210icf.9.1388034695492;
 Wed, 25 Dec 2013 21:11:35 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.20.78 with HTTP; Wed, 25 Dec 2013 21:11:15 -0800 (PST)
X-Originating-IP: [67.188.95.187]
In-Reply-To: <CAPNhUcdNpoXN89aGgA4pK-Gb3yU_JAdGBvsUFjVQ=dXPjsW37Q@mail.gmail.com>
References: <CAPNhUcdNpoXN89aGgA4pK-Gb3yU_JAdGBvsUFjVQ=dXPjsW37Q@mail.gmail.com>
From: Christopher Nguyen <ctn@adatao.com>
Date: Wed, 25 Dec 2013 21:11:15 -0800
Message-ID: <CAGh_TuMBy5hBc=n-K7=xrgSgdP0rXw+_Lb-TXUV+R8b70v-yww@mail.gmail.com>
Subject: Re: Large DataStructure to Broadcast
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=90e6ba6e8e88f60a5604ee69025e
X-Virus-Checked: Checked by ClamAV on apache.org

--90e6ba6e8e88f60a5604ee69025e
Content-Type: text/plain; charset=ISO-8859-1

Purav, depending on the access pattern you should also consider the
trade-offs of setting up a lookup service (using, e.g., memcached, egad!)
which may end up being more efficient overall.

The general point is not to restrict yourself to only Spark APIs when
considering the overall architecture.
--
Christopher T. Nguyen
Co-founder & CEO, Adatao <http://adatao.com>
linkedin.com/in/ctnguyen



On Wed, Dec 25, 2013 at 7:32 PM, purav aggarwal
<puravaggarwal123@gmail.com>wrote:

> Hi all,
>
> I have a large file ( > 5 gigs) which I need to lookup. Since each slave
> need to perform the search operation on the hashmap (built out of the file)
> in parallel I need to broadcast the file. I was wondering if broadcasting
> such a huge file is really a good idea. Do we have any benchmarks for the
> broadcast variables. I am on a Standalone cluster and machine configuration
> is not a problem at the moment.
> Has anyone exploited broadcast to such an extent ?
>
> Thanks,
> Purav
>

--90e6ba6e8e88f60a5604ee69025e--

From dev-return-1002-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 20:33:31 2013
Return-Path: <dev-return-1002-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F28B10F71
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 20:33:31 +0000 (UTC)
Received: (qmail 92801 invoked by uid 500); 26 Dec 2013 20:33:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92730 invoked by uid 500); 26 Dec 2013 20:33:30 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 92721 invoked by uid 99); 26 Dec 2013 20:33:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 20:33:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mark@clearstorydata.com designates 209.85.214.47 as permitted sender)
Received: from [209.85.214.47] (HELO mail-bk0-f47.google.com) (209.85.214.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 20:33:23 +0000
Received: by mail-bk0-f47.google.com with SMTP id mx12so2933990bkb.34
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 12:33:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=O7hm3oWseEG3iMwVyZq58w1SiuUK9a5W2L53Znh4jM8=;
        b=jWJtjvRhjTWGkJvh+WQbqjB6n1R3qy/wqB8GUHsvqfweiCz9pHBs3OntCaf+keAU+1
         GwkW+7ZBGzg6xDtc/ipbb11/Pit2QvYQvKbJQq2QHB26B7SuHk/Y3szfk98NeiNKSLoZ
         tOzJqo5Ur7shwZoqoa9nMGV0bLEUfDbt+gdVciyd1dfifiMvjgkWDEJJoRAJXiQoA2rt
         q+N7YbNV4wyxf30Cbili6FWlge18GyO8x9lVaAfYPsfglnJza9A4RsuR6wR9GFlWZJU3
         +lPZjV3AZKMWL//BAloE0yT29H/UhKeuBJNFU4MBEwo3tzPMnZ0ArcD6JX08c7sdGvDS
         RCmQ==
X-Gm-Message-State: ALoCoQm6GebI7jMB8KTcOLiFCtDI7F7PF834GubvVxL00rn7Vn6eu7YVucHR9LyItWuf5mGXXNUL
MIME-Version: 1.0
X-Received: by 10.205.92.196 with SMTP id br4mr33816bkc.138.1388089982772;
 Thu, 26 Dec 2013 12:33:02 -0800 (PST)
Received: by 10.205.6.199 with HTTP; Thu, 26 Dec 2013 12:33:02 -0800 (PST)
Date: Thu, 26 Dec 2013 12:33:02 -0800
Message-ID: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
Subject: Option folding idiom
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b66f5db5749f104ee75e2b9
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b66f5db5749f104ee75e2b9
Content-Type: text/plain; charset=ISO-8859-1

In code added to Spark over the past several months, I'm glad to see more
use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
pattern matching boilerplate.  There are opportunities to push `Option`
idioms even further now that we are using Scala 2.10 in master, but I want
to discuss the issue here a little bit before committing code whose form
may be a little unfamiliar to some Spark developers.

In particular, I really like the use of `fold` with `Option` to cleanly an
concisely express the "do something if the Option is None; do something
else with the thing contained in the Option if it is Some" code fragment.

An example:

Instead of...

val driver = drivers.find(_.id == driverId)
driver match {
  case Some(d) =>
    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
    else {
      d.worker.foreach { w =>
        w.actor ! KillDriver(driverId)
      }
    }
    val msg = s"Kill request for $driverId submitted"
    logInfo(msg)
    sender ! KillDriverResponse(true, msg)
  case None =>
    val msg = s"Could not find running driver $driverId"
    logWarning(msg)
    sender ! KillDriverResponse(false, msg)
}

...using fold we end up with...

driver.fold
  {
    val msg = s"Could not find running driver $driverId"
    logWarning(msg)
    sender ! KillDriverResponse(false, msg)
  }
  { d =>
    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
    else {
      d.worker.foreach { w =>
        w.actor ! KillDriver(driverId)
      }
    }
    val msg = s"Kill request for $driverId submitted"
    logInfo(msg)
    sender ! KillDriverResponse(true, msg)
  }


So the basic pattern (and my proposed formatting standard) for folding over
an `Option[A]` from which you need to produce a B (which may be Unit if
you're only interested in side effects) is:

anOption.fold
  {
    // something that evaluates to a B if anOption = None
  }
  { a =>
    // something that transforms `a` into a B if anOption = Some(a)
  }


Any thoughts?  Does anyone really, really hate this style of coding and
oppose its use in Spark?

--047d7b66f5db5749f104ee75e2b9--

From dev-return-1003-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 20:55:13 2013
Return-Path: <dev-return-1003-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 10ECB10FC0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 20:55:13 +0000 (UTC)
Received: (qmail 18489 invoked by uid 500); 26 Dec 2013 20:55:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18389 invoked by uid 500); 26 Dec 2013 20:55:12 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 18381 invoked by uid 99); 26 Dec 2013 20:55:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 20:55:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of freeman@adatao.com designates 209.85.213.169 as permitted sender)
Received: from [209.85.213.169] (HELO mail-ig0-f169.google.com) (209.85.213.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 20:55:06 +0000
Received: by mail-ig0-f169.google.com with SMTP id hk11so28169674igb.0
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 12:54:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=from:content-type:message-id:mime-version:subject:date:references
         :to:in-reply-to;
        bh=fD3TXfFJw+Q797o6RUbZzjASWs2lJz6J+czDzc1oBR8=;
        b=QlnMv9Me6VOyImXDlAQOo6gBgu9HNP+IrsFA/XkUzNoJDHUKb0aH59XRGcuJlLtkns
         PCqM7P76SSFo8GpS5WRkYOvuqOL1iZXGvXsLzRqmjEg0Hcck+FIGtBkc5V+vcfyaxvOy
         rNGnYjdtS0ObI9+clwqCF2kVG9vKb9rBJ8QpM=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:from:content-type:message-id:mime-version
         :subject:date:references:to:in-reply-to;
        bh=fD3TXfFJw+Q797o6RUbZzjASWs2lJz6J+czDzc1oBR8=;
        b=G4ndw1BMlL4+foHjS2TzAdkiBHrvIkTwvmjzefkHNG/jfZu7B0t+aw23SVgtn45bca
         N7CLFGLJ0LeIa9qSmTby3s0B+qpzYbf2S7CL49tGsfWp3ZPgh3deOlS2KCnWMFf4q/i9
         yZH1+1szUifB2P6KkXDjHNro2CRMoRxL5hAMIrKHnIJur0FDBqKlpTcV25LHCpekYeI9
         yGMWWiXgD1WIYRYAd+B9CqEop2Vq0rYGi3WSr+Tkauvv7KTxHRcTD0ifjL2VP4OAlWDe
         avQiMBECKCIneu5DNgZNYf9iYzjXcC88rh2B6544iutoVye56vrrzrkQSTElWsiV9vDx
         lAAQ==
X-Gm-Message-State: ALoCoQkfNH5S8olnrwt9YCnSugwIrAHXNtPJ7uo5ij/3R8YqEizfsX443NRo0loJl6byye123r4d
X-Received: by 10.50.4.9 with SMTP id g9mr36826220igg.22.1388091283231;
        Thu, 26 Dec 2013 12:54:43 -0800 (PST)
Received: from [192.168.0.6] (c-98-212-149-78.hsd1.il.comcast.net. [98.212.149.78])
        by mx.google.com with ESMTPSA id t4sm41358395igm.10.2013.12.26.12.54.42
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 26 Dec 2013 12:54:42 -0800 (PST)
From: "Michael (Bach) Bui" <freeman@adatao.com>
Content-Type: multipart/alternative; boundary="Apple-Mail=_FB6BB54B-3D30-432E-BB82-054CAF2A9D67"
Message-Id: <00854A60-9FCE-4EB8-B214-04C7956AA90F@adatao.com>
Mime-Version: 1.0 (Mac OS X Mail 7.0 \(1822\))
Subject: Re: Option folding idiom
Date: Thu, 26 Dec 2013 14:54:40 -0600
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
To: dev@spark.incubator.apache.org
In-Reply-To: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
X-Mailer: Apple Mail (2.1822)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_FB6BB54B-3D30-432E-BB82-054CAF2A9D67
Content-Transfer-Encoding: 7bit
Content-Type: text/plain;
	charset=iso-8859-1

+1.

It is a little bit harder to read for new comers but not really a big deal.




On Dec 26, 2013, at 2:33 PM, Mark Hamstra <mark@clearstorydata.com> wrote:

> In code added to Spark over the past several months, I'm glad to see more
> use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> pattern matching boilerplate.  There are opportunities to push `Option`
> idioms even further now that we are using Scala 2.10 in master, but I want
> to discuss the issue here a little bit before committing code whose form
> may be a little unfamiliar to some Spark developers.
> 
> In particular, I really like the use of `fold` with `Option` to cleanly an
> concisely express the "do something if the Option is None; do something
> else with the thing contained in the Option if it is Some" code fragment.
> 
> An example:
> 
> Instead of...
> 
> val driver = drivers.find(_.id == driverId)
> driver match {
>  case Some(d) =>
>    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
>    else {
>      d.worker.foreach { w =>
>        w.actor ! KillDriver(driverId)
>      }
>    }
>    val msg = s"Kill request for $driverId submitted"
>    logInfo(msg)
>    sender ! KillDriverResponse(true, msg)
>  case None =>
>    val msg = s"Could not find running driver $driverId"
>    logWarning(msg)
>    sender ! KillDriverResponse(false, msg)
> }
> 
> ...using fold we end up with...
> 
> driver.fold
>  {
>    val msg = s"Could not find running driver $driverId"
>    logWarning(msg)
>    sender ! KillDriverResponse(false, msg)
>  }
>  { d =>
>    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
>    else {
>      d.worker.foreach { w =>
>        w.actor ! KillDriver(driverId)
>      }
>    }
>    val msg = s"Kill request for $driverId submitted"
>    logInfo(msg)
>    sender ! KillDriverResponse(true, msg)
>  }
> 
> 
> So the basic pattern (and my proposed formatting standard) for folding over
> an `Option[A]` from which you need to produce a B (which may be Unit if
> you're only interested in side effects) is:
> 
> anOption.fold
>  {
>    // something that evaluates to a B if anOption = None
>  }
>  { a =>
>    // something that transforms `a` into a B if anOption = Some(a)
>  }
> 
> 
> Any thoughts?  Does anyone really, really hate this style of coding and
> oppose its use in Spark?


--Apple-Mail=_FB6BB54B-3D30-432E-BB82-054CAF2A9D67--

From dev-return-1004-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Thu Dec 26 21:20:00 2013
Return-Path: <dev-return-1004-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 18B611007C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Dec 2013 21:20:00 +0000 (UTC)
Received: (qmail 34131 invoked by uid 500); 26 Dec 2013 21:19:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34098 invoked by uid 500); 26 Dec 2013 21:19:59 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 34090 invoked by uid 99); 26 Dec 2013 21:19:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 21:19:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ctn@adatao.com designates 209.85.223.172 as permitted sender)
Received: from [209.85.223.172] (HELO mail-ie0-f172.google.com) (209.85.223.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Dec 2013 21:19:55 +0000
Received: by mail-ie0-f172.google.com with SMTP id qd12so9106706ieb.17
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 13:19:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=K66lF5luowMZOTfN3II+1TIFFWZoeS7bJN69fWZ3liE=;
        b=BfbZSPONntUzGHBYxyMIqhw/IbF1x1wkyVw+HL56n3XX6CYli2vMDerjNySgamnMiE
         6QEUCq3VKru3B+FK895ZXvi8PjCow4DjXZmOLGvClRfBLfOSS6ipqImwdBhobQOVd18C
         AQDJZEmoyMhVVY3xzDdHjl3Wmc45UKjtiEzpk=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=K66lF5luowMZOTfN3II+1TIFFWZoeS7bJN69fWZ3liE=;
        b=kEZ3zzE2vgQ9ZRWUlBcUrX/kSUu7V/2KbvxjywkOVFQYTvALomjnWibPZAPORrlxrT
         OK2ZggcsG3k7db9UgU5AcygNj62z2VfyEvPiTuc1ByvTNoY5fuiy+QMGNjVACyHDYIbU
         1o2clwgGR6WLvvzKISd18rLX0LGMvGz95nXWixiB8YSJCNEhuJu74/D7LZORvJWFFIFo
         T/kBp/MWRXJDQquHLaLQapUiviqaj8a7c7i2NF2Am7+aZZa08E1R3MCW00bWzIzT/s0e
         zMDF1qkDmjslQ/2NDTBrPIHFjwBbPx03VFmS3g86FPjkxJqOPJoQhlefGqW1nARgs9ic
         TwXA==
X-Gm-Message-State: ALoCoQlVLsHvOS6TI/q5T29y7sy7CfWtcycXzS1RUpzLQ9VJAVW2TM0/9nMI9lOoNXFB4n4thTbk
X-Received: by 10.42.214.202 with SMTP id hb10mr2919653icb.76.1388092774856;
 Thu, 26 Dec 2013 13:19:34 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.20.78 with HTTP; Thu, 26 Dec 2013 13:19:14 -0800 (PST)
X-Originating-IP: [67.188.95.187]
In-Reply-To: <00854A60-9FCE-4EB8-B214-04C7956AA90F@adatao.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
 <00854A60-9FCE-4EB8-B214-04C7956AA90F@adatao.com>
From: Christopher Nguyen <ctn@adatao.com>
Date: Thu, 26 Dec 2013 13:19:14 -0800
Message-ID: <CAGh_TuPSw2S9zPLOa57GgNVqKxq3MTdeyqAUcmgB+dj7rmYEkA@mail.gmail.com>
Subject: Re: Option folding idiom
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=20cf301cc3b2c2d97a04ee768818
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf301cc3b2c2d97a04ee768818
Content-Type: text/plain; charset=ISO-8859-1

+1 as you can't fight the future, but clear warning signs ahead would be
helpful :)

Just be careful that it's not an exact equivalent to *match*, else we can
get confused by behavior like this:


*scala> class parentdefined class parent*


*scala> class child1 extends parentdefined class child1*


*scala> class child2 extends parentdefined class child2*


*scala> Option("abc") match { case None => new child1 ; case _ => new
child2 } res16: parent = child2@9d9347d*





*scala> Option("abc").fold { new child1 } { _ => new child2 }<console>:11:
error: type mismatch;  found   : child2 required: child1
 Option("abc").fold { new child1 } { _ => new child2 }*


*scala> Option("abc").fold { new child1 : parent } { _ => new child2 }
res14: parent = child2@58a470a8*

--
Christopher T. Nguyen
Co-founder & CEO, Adatao <http://adatao.com>
linkedin.com/in/ctnguyen



On Thu, Dec 26, 2013 at 12:54 PM, Michael (Bach) Bui <freeman@adatao.com>wrote:

> +1.
>
> It is a little bit harder to read for new comers but not really a big deal.
>
>
>
>
> On Dec 26, 2013, at 2:33 PM, Mark Hamstra <mark@clearstorydata.com> wrote:
>
> > In code added to Spark over the past several months, I'm glad to see more
> > use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> > pattern matching boilerplate.  There are opportunities to push `Option`
> > idioms even further now that we are using Scala 2.10 in master, but I
> want
> > to discuss the issue here a little bit before committing code whose form
> > may be a little unfamiliar to some Spark developers.
> >
> > In particular, I really like the use of `fold` with `Option` to cleanly
> an
> > concisely express the "do something if the Option is None; do something
> > else with the thing contained in the Option if it is Some" code fragment.
> >
> > An example:
> >
> > Instead of...
> >
> > val driver = drivers.find(_.id == driverId)
> > driver match {
> >  case Some(d) =>
> >    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> >    else {
> >      d.worker.foreach { w =>
> >        w.actor ! KillDriver(driverId)
> >      }
> >    }
> >    val msg = s"Kill request for $driverId submitted"
> >    logInfo(msg)
> >    sender ! KillDriverResponse(true, msg)
> >  case None =>
> >    val msg = s"Could not find running driver $driverId"
> >    logWarning(msg)
> >    sender ! KillDriverResponse(false, msg)
> > }
> >
> > ...using fold we end up with...
> >
> > driver.fold
> >  {
> >    val msg = s"Could not find running driver $driverId"
> >    logWarning(msg)
> >    sender ! KillDriverResponse(false, msg)
> >  }
> >  { d =>
> >    if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> >    else {
> >      d.worker.foreach { w =>
> >        w.actor ! KillDriver(driverId)
> >      }
> >    }
> >    val msg = s"Kill request for $driverId submitted"
> >    logInfo(msg)
> >    sender ! KillDriverResponse(true, msg)
> >  }
> >
> >
> > So the basic pattern (and my proposed formatting standard) for folding
> over
> > an `Option[A]` from which you need to produce a B (which may be Unit if
> > you're only interested in side effects) is:
> >
> > anOption.fold
> >  {
> >    // something that evaluates to a B if anOption = None
> >  }
> >  { a =>
> >    // something that transforms `a` into a B if anOption = Some(a)
> >  }
> >
> >
> > Any thoughts?  Does anyone really, really hate this style of coding and
> > oppose its use in Spark?
>
>

--20cf301cc3b2c2d97a04ee768818--

From dev-return-1005-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 01:51:34 2013
Return-Path: <dev-return-1005-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 703101078F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 01:51:34 +0000 (UTC)
Received: (qmail 22496 invoked by uid 500); 27 Dec 2013 01:51:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22430 invoked by uid 500); 27 Dec 2013 01:51:33 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 22421 invoked by uid 99); 27 Dec 2013 01:51:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 01:51:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 01:51:28 +0000
Received: by mail-lb0-f172.google.com with SMTP id x18so4071816lbi.31
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 17:51:07 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=rvH0i3xlyLj2co4LbLrJ3xLFIi1F6PwUZSmMxHLcMKw=;
        b=q6QKhkQnyuOUsQhcQiGuQezFHELvNmOdHL2DIav3rAyISnkomAYWUZz5+pr5I+0wd5
         1uWRwOi11hYRSaUGy3G0Fxgl4xLuJZDt+H8F4heMOyZwnRL80tCoXmheSi1/1jf8r7xo
         0IGbqMHVENURn9eRp7CP/DlK20laLbvcb3GvE=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=rvH0i3xlyLj2co4LbLrJ3xLFIi1F6PwUZSmMxHLcMKw=;
        b=TohyIvRD2DqvmiUpLv5WKQ/Lkcm6DS3Qf/aaXjvLxGYFtFuATrzF43jo0tD90x1JWt
         73nF/tPqTmjQo2g3DFmAkQogRJXjSIeztrQZEzWseuP1IXpIQEWzwC6rtaKzOg01+B7e
         L5LwqiE772jOJQtRkScQt0cJ+B9tp+Q5x5HF0qIlvdwucfZS1g+hW/J2a4P75okLGDps
         p8kvofBukvCC8TS9NR21mFrL0PtXkjkpmm12p0uuPH/UHUs9Ju5lIdHZH3/29zhSnXAv
         cI+rCU7394RnVAjoKGBguYV53q1xIxL9gzaQwW+vKRXO65ovnvmuSFfBoioAHoR/oanc
         Q9Fg==
X-Gm-Message-State: ALoCoQkoiakjpnim5S+aJk23P/YalgPyTOzzuk+AGbMerA0opHFsBHwCgVdsTXnMwQpeCqXZ2CyF
MIME-Version: 1.0
X-Received: by 10.152.26.72 with SMTP id j8mr89226lag.85.1388109067544; Thu,
 26 Dec 2013 17:51:07 -0800 (PST)
Received: by 10.112.20.10 with HTTP; Thu, 26 Dec 2013 17:51:07 -0800 (PST)
In-Reply-To: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
Date: Thu, 26 Dec 2013 17:51:07 -0800
Message-ID: <CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
Subject: Re: Option folding idiom
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e0160c36ee17b4b04ee7a5360
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160c36ee17b4b04ee7a5360
Content-Type: text/plain; charset=ISO-8859-1

+1 for using more functional idioms in general.

That's a pretty clever use of `fold`, but putting the default condition
first there makes it not as intuitive.   What about the following, which
are more readable?

    option.map { a => someFuncMakesB() }
              .getOrElse(b)

    option.map { a => someFuncMakesB() }
              .orElse { a => otherDefaultB() }.get


On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> In code added to Spark over the past several months, I'm glad to see more
> use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> pattern matching boilerplate.  There are opportunities to push `Option`
> idioms even further now that we are using Scala 2.10 in master, but I want
> to discuss the issue here a little bit before committing code whose form
> may be a little unfamiliar to some Spark developers.
>
> In particular, I really like the use of `fold` with `Option` to cleanly an
> concisely express the "do something if the Option is None; do something
> else with the thing contained in the Option if it is Some" code fragment.
>
> An example:
>
> Instead of...
>
> val driver = drivers.find(_.id == driverId)
> driver match {
>   case Some(d) =>
>     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
>     else {
>       d.worker.foreach { w =>
>         w.actor ! KillDriver(driverId)
>       }
>     }
>     val msg = s"Kill request for $driverId submitted"
>     logInfo(msg)
>     sender ! KillDriverResponse(true, msg)
>   case None =>
>     val msg = s"Could not find running driver $driverId"
>     logWarning(msg)
>     sender ! KillDriverResponse(false, msg)
> }
>
> ...using fold we end up with...
>
> driver.fold
>   {
>     val msg = s"Could not find running driver $driverId"
>     logWarning(msg)
>     sender ! KillDriverResponse(false, msg)
>   }
>   { d =>
>     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
>     else {
>       d.worker.foreach { w =>
>         w.actor ! KillDriver(driverId)
>       }
>     }
>     val msg = s"Kill request for $driverId submitted"
>     logInfo(msg)
>     sender ! KillDriverResponse(true, msg)
>   }
>
>
> So the basic pattern (and my proposed formatting standard) for folding over
> an `Option[A]` from which you need to produce a B (which may be Unit if
> you're only interested in side effects) is:
>
> anOption.fold
>   {
>     // something that evaluates to a B if anOption = None
>   }
>   { a =>
>     // something that transforms `a` into a B if anOption = Some(a)
>   }
>
>
> Any thoughts?  Does anyone really, really hate this style of coding and
> oppose its use in Spark?
>



-- 
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

<http://www.ooyala.com/>
<http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><http://www.twitter.com/ooyala>

--089e0160c36ee17b4b04ee7a5360--

From dev-return-1006-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 02:24:14 2013
Return-Path: <dev-return-1006-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9F01E1081B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 02:24:14 +0000 (UTC)
Received: (qmail 48326 invoked by uid 500); 27 Dec 2013 02:24:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48291 invoked by uid 500); 27 Dec 2013 02:24:14 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 48283 invoked by uid 99); 27 Dec 2013 02:24:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 02:24:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 209.85.214.50 as permitted sender)
Received: from [209.85.214.50] (HELO mail-bk0-f50.google.com) (209.85.214.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 02:24:10 +0000
Received: by mail-bk0-f50.google.com with SMTP id e11so3009273bkh.9
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 18:23:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=I0aWbZ9KOrcd3kSXxPCH+C2s2+uH/Yqvnnro9zBoYK8=;
        b=WF0xSARSaaUoF436fUZHfgKHVEHEJ8V+bAOWLT58jh7BGcRY3QxDQ2vVHDdnlObG/4
         D2GJ/aX4oy06vOjrsf+5dvORzfT1J03Z6O0YHJHPbXSTN4auuXziRZn7wTyjFcU1ZhH8
         0cz+UR3qdidrbwEspC75x3BlBvzO9lITL1H6K6vSf3LWaBBXafr9JWmd8UaVq4g8STQV
         4t48DQC6JdxVWLDxlItCV5Z9VmpfwEgabiohCsyF4GBgABbDH0HMoywn2/Sjd2zOqWSv
         b2H4UNia+n2CzmjgyJxKVc3w7DqkZGMdYea9xBJiHPkpZunLsTY8V2z5Okol5Ug/1V+e
         EpWQ==
X-Gm-Message-State: ALoCoQlXALdronV4ajYrNkLg6Lq0a5UPQf/OwupFLVcGDEyHWOF9Q0XWvV5k0qyYUqtPMvd/aLFI
MIME-Version: 1.0
X-Received: by 10.204.224.207 with SMTP id ip15mr485373bkb.71.1388111028764;
 Thu, 26 Dec 2013 18:23:48 -0800 (PST)
Received: by 10.205.6.199 with HTTP; Thu, 26 Dec 2013 18:23:48 -0800 (PST)
In-Reply-To: <CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
	<CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
Date: Thu, 26 Dec 2013 18:23:48 -0800
Message-ID: <CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
Subject: Re: Option folding idiom
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=485b3970cec2c7bf1804ee7ac866
X-Virus-Checked: Checked by ClamAV on apache.org

--485b3970cec2c7bf1804ee7ac866
Content-Type: text/plain; charset=ISO-8859-1

On the contrary, it is the completely natural place for the initial value
of the accumulator, and provides the expected result of folding over an
empty collection.

scala> val l: List[Int] = List()

l: List[Int] = List()


scala> l.fold(42)(_ + _)

res0: Int = 42


scala> val o: Option[Int] = None

o: Option[Int] = None


scala> o.fold(42)(_ + 1)

res1: Int = 42


On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:

> +1 for using more functional idioms in general.
>
> That's a pretty clever use of `fold`, but putting the default condition
> first there makes it not as intuitive.   What about the following, which
> are more readable?
>
>     option.map { a => someFuncMakesB() }
>               .getOrElse(b)
>
>     option.map { a => someFuncMakesB() }
>               .orElse { a => otherDefaultB() }.get
>
>
> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
>
> > In code added to Spark over the past several months, I'm glad to see more
> > use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> > pattern matching boilerplate.  There are opportunities to push `Option`
> > idioms even further now that we are using Scala 2.10 in master, but I
> want
> > to discuss the issue here a little bit before committing code whose form
> > may be a little unfamiliar to some Spark developers.
> >
> > In particular, I really like the use of `fold` with `Option` to cleanly
> an
> > concisely express the "do something if the Option is None; do something
> > else with the thing contained in the Option if it is Some" code fragment.
> >
> > An example:
> >
> > Instead of...
> >
> > val driver = drivers.find(_.id == driverId)
> > driver match {
> >   case Some(d) =>
> >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> >     else {
> >       d.worker.foreach { w =>
> >         w.actor ! KillDriver(driverId)
> >       }
> >     }
> >     val msg = s"Kill request for $driverId submitted"
> >     logInfo(msg)
> >     sender ! KillDriverResponse(true, msg)
> >   case None =>
> >     val msg = s"Could not find running driver $driverId"
> >     logWarning(msg)
> >     sender ! KillDriverResponse(false, msg)
> > }
> >
> > ...using fold we end up with...
> >
> > driver.fold
> >   {
> >     val msg = s"Could not find running driver $driverId"
> >     logWarning(msg)
> >     sender ! KillDriverResponse(false, msg)
> >   }
> >   { d =>
> >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> >     else {
> >       d.worker.foreach { w =>
> >         w.actor ! KillDriver(driverId)
> >       }
> >     }
> >     val msg = s"Kill request for $driverId submitted"
> >     logInfo(msg)
> >     sender ! KillDriverResponse(true, msg)
> >   }
> >
> >
> > So the basic pattern (and my proposed formatting standard) for folding
> over
> > an `Option[A]` from which you need to produce a B (which may be Unit if
> > you're only interested in side effects) is:
> >
> > anOption.fold
> >   {
> >     // something that evaluates to a B if anOption = None
> >   }
> >   { a =>
> >     // something that transforms `a` into a B if anOption = Some(a)
> >   }
> >
> >
> > Any thoughts?  Does anyone really, really hate this style of coding and
> > oppose its use in Spark?
> >
>
>
>
> --
> --
> Evan Chan
> Staff Engineer
> ev@ooyala.com  |
>
> <http://www.ooyala.com/>
> <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala><
> http://www.twitter.com/ooyala>
>

--485b3970cec2c7bf1804ee7ac866--

From dev-return-1007-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 03:58:58 2013
Return-Path: <dev-return-1007-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6973F10958
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 03:58:58 +0000 (UTC)
Received: (qmail 135 invoked by uid 500); 27 Dec 2013 03:58:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99997 invoked by uid 500); 27 Dec 2013 03:58:51 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 99987 invoked by uid 99); 27 Dec 2013 03:58:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 03:58:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.128.45] (HELO mail-qe0-f45.google.com) (209.85.128.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 03:58:45 +0000
Received: by mail-qe0-f45.google.com with SMTP id 6so8572214qea.4
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 19:58:24 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=sXxQoyRnvBE00pY6u2K5cH/S0U5pl8kA9GQ4znMmo1s=;
        b=X+DwYdzH1pg4EHGhz2tiJSY1jY7nd6dlmFPqPYm9n59nD7VBOUXjeEq7xui62YIs2A
         u0Xa9t1Vn/kb1aQF0CqQW0jRUm0kFqNDVRP3Nfh2RFrV1N9rE1gZzIikNsN0ab4WAhJn
         S6Oy/4F+ykEojiwii7ANMrHQmEjT6K2R4BYyJ2KpItqLuNmrg0zHo4dK0X088wZAWgBy
         qQISazRVCtqqC6tNRe8cSqVZhSuuncrccUs23tuoe9lrrbke2q/3P5KdEG6okEhZmCBF
         fxOGcV7ffTJ0m/OgerW7MqMUXVyLBXCsDigZYoAAHGM4kvu7gVLgSJQgr1Ol5hijmEtP
         c59g==
X-Gm-Message-State: ALoCoQkJp6yndMlfK5YzxS2NdLlR4tPNrU0yzzvmhi4fWS22UW+9TU+dPph1l8O6o8gGgVS//43i
MIME-Version: 1.0
X-Received: by 10.49.109.97 with SMTP id hr1mr79042880qeb.59.1388116704606;
 Thu, 26 Dec 2013 19:58:24 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Thu, 26 Dec 2013 19:58:24 -0800 (PST)
In-Reply-To: <CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
	<CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
	<CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
Date: Thu, 26 Dec 2013 17:58:24 -1000
Message-ID: <CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com>
Subject: Re: Option folding idiom
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7bea31a615d68404ee7c1b41
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bea31a615d68404ee7c1b41
Content-Type: text/plain; charset=ISO-8859-1

I'm not strongly against Option.fold, but I find the readability getting
worse for the use case you brought up.  For the use case of if/else, I find
Option.fold pretty confusing because it reverses the order of Some vs None.
Also, when code gets long, the lack of an obvious boundary (the only
boundary is "} {") with two closures is pretty confusing.


On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <mark@clearstorydata.com>wrote:

> On the contrary, it is the completely natural place for the initial value
> of the accumulator, and provides the expected result of folding over an
> empty collection.
>
> scala> val l: List[Int] = List()
>
> l: List[Int] = List()
>
>
> scala> l.fold(42)(_ + _)
>
> res0: Int = 42
>
>
> scala> val o: Option[Int] = None
>
> o: Option[Int] = None
>
>
> scala> o.fold(42)(_ + 1)
>
> res1: Int = 42
>
>
> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
>
> > +1 for using more functional idioms in general.
> >
> > That's a pretty clever use of `fold`, but putting the default condition
> > first there makes it not as intuitive.   What about the following, which
> > are more readable?
> >
> >     option.map { a => someFuncMakesB() }
> >               .getOrElse(b)
> >
> >     option.map { a => someFuncMakesB() }
> >               .orElse { a => otherDefaultB() }.get
> >
> >
> > On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <mark@clearstorydata.com
> > >wrote:
> >
> > > In code added to Spark over the past several months, I'm glad to see
> more
> > > use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> > > pattern matching boilerplate.  There are opportunities to push `Option`
> > > idioms even further now that we are using Scala 2.10 in master, but I
> > want
> > > to discuss the issue here a little bit before committing code whose
> form
> > > may be a little unfamiliar to some Spark developers.
> > >
> > > In particular, I really like the use of `fold` with `Option` to cleanly
> > an
> > > concisely express the "do something if the Option is None; do something
> > > else with the thing contained in the Option if it is Some" code
> fragment.
> > >
> > > An example:
> > >
> > > Instead of...
> > >
> > > val driver = drivers.find(_.id == driverId)
> > > driver match {
> > >   case Some(d) =>
> > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > >     else {
> > >       d.worker.foreach { w =>
> > >         w.actor ! KillDriver(driverId)
> > >       }
> > >     }
> > >     val msg = s"Kill request for $driverId submitted"
> > >     logInfo(msg)
> > >     sender ! KillDriverResponse(true, msg)
> > >   case None =>
> > >     val msg = s"Could not find running driver $driverId"
> > >     logWarning(msg)
> > >     sender ! KillDriverResponse(false, msg)
> > > }
> > >
> > > ...using fold we end up with...
> > >
> > > driver.fold
> > >   {
> > >     val msg = s"Could not find running driver $driverId"
> > >     logWarning(msg)
> > >     sender ! KillDriverResponse(false, msg)
> > >   }
> > >   { d =>
> > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > >     else {
> > >       d.worker.foreach { w =>
> > >         w.actor ! KillDriver(driverId)
> > >       }
> > >     }
> > >     val msg = s"Kill request for $driverId submitted"
> > >     logInfo(msg)
> > >     sender ! KillDriverResponse(true, msg)
> > >   }
> > >
> > >
> > > So the basic pattern (and my proposed formatting standard) for folding
> > over
> > > an `Option[A]` from which you need to produce a B (which may be Unit if
> > > you're only interested in side effects) is:
> > >
> > > anOption.fold
> > >   {
> > >     // something that evaluates to a B if anOption = None
> > >   }
> > >   { a =>
> > >     // something that transforms `a` into a B if anOption = Some(a)
> > >   }
> > >
> > >
> > > Any thoughts?  Does anyone really, really hate this style of coding and
> > > oppose its use in Spark?
> > >
> >
> >
> >
> > --
> > --
> > Evan Chan
> > Staff Engineer
> > ev@ooyala.com  |
> >
> > <http://www.ooyala.com/>
> > <http://www.facebook.com/ooyala><http://www.linkedin.com/company/ooyala
> ><
> > http://www.twitter.com/ooyala>
> >
>

--047d7bea31a615d68404ee7c1b41--

From dev-return-1008-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 04:11:42 2013
Return-Path: <dev-return-1008-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25706109A9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 04:11:42 +0000 (UTC)
Received: (qmail 8564 invoked by uid 500); 27 Dec 2013 04:11:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8518 invoked by uid 500); 27 Dec 2013 04:11:38 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 8510 invoked by uid 99); 27 Dec 2013 04:11:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 04:11:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of holden.karau@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 04:11:33 +0000
Received: by mail-pa0-f44.google.com with SMTP id fa1so8935109pad.3
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 20:11:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:content-type;
        bh=9FLBtT2kcV4S4RXqZa9qGaCoLA+ESPcSXcSICPaIJ54=;
        b=SQZCAz5uTNGplOLrjG4ti0SGWmQ1cuCzmxIHbHPYMa5JYE+3omQERqoco5oVYm0hwh
         XThWfbyHmDZrn7it+38r+cWV0Rtzhz3PxTGnvXxYYrDwNpRJ4ihEC44gLai+bGhVf6Ln
         eFzOKVA/QGRztyQsVaxz5dGVB5McLwaZ4wIit2XX7+4oRiy3+2HsgbBjEoR4ZD2CllMG
         bCpGKDLXHG4aS42kavL1V01xd36i3ngdL0LXDfDDTnxw/tFAcPibrfceiZOI9ig1riVg
         7eRhYjlqu5/uE0fWa3SFMJRzk7SM2csdf7b3xWNtCa36U5TOXpm6EuFmVSTEKtjB4wJN
         +tGg==
MIME-Version: 1.0
X-Received: by 10.66.162.136 with SMTP id ya8mr47635860pab.110.1388117472967;
 Thu, 26 Dec 2013 20:11:12 -0800 (PST)
Sender: holden.karau@gmail.com
Received: by 10.68.242.1 with HTTP; Thu, 26 Dec 2013 20:11:12 -0800 (PST)
In-Reply-To: <CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
	<CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
	<CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
	<CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com>
Date: Thu, 26 Dec 2013 20:11:12 -0800
X-Google-Sender-Auth: zhQbH_q6tpYclsZMjIssit9A7Ww
Message-ID: <CAJLcJd9PD=vuKTedGgw5EqTov8AgzRcrVVXFDPsdL+-KdZRRDQ@mail.gmail.com>
Subject: Re: Option folding idiom
From: Holden Karau <holden@pigscanfly.ca>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b86e424e2031e04ee7c48c4
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b86e424e2031e04ee7c48c4
Content-Type: text/plain; charset=ISO-8859-1

I personally with Evan in that I prefer map with getOrElse over fold with
options (but that just my personal preference) :)


On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com> wrote:

> I'm not strongly against Option.fold, but I find the readability getting
> worse for the use case you brought up.  For the use case of if/else, I find
> Option.fold pretty confusing because it reverses the order of Some vs None.
> Also, when code gets long, the lack of an obvious boundary (the only
> boundary is "} {") with two closures is pretty confusing.
>
>
> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <mark@clearstorydata.com
> >wrote:
>
> > On the contrary, it is the completely natural place for the initial value
> > of the accumulator, and provides the expected result of folding over an
> > empty collection.
> >
> > scala> val l: List[Int] = List()
> >
> > l: List[Int] = List()
> >
> >
> > scala> l.fold(42)(_ + _)
> >
> > res0: Int = 42
> >
> >
> > scala> val o: Option[Int] = None
> >
> > o: Option[Int] = None
> >
> >
> > scala> o.fold(42)(_ + 1)
> >
> > res1: Int = 42
> >
> >
> > On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
> >
> > > +1 for using more functional idioms in general.
> > >
> > > That's a pretty clever use of `fold`, but putting the default condition
> > > first there makes it not as intuitive.   What about the following,
> which
> > > are more readable?
> > >
> > >     option.map { a => someFuncMakesB() }
> > >               .getOrElse(b)
> > >
> > >     option.map { a => someFuncMakesB() }
> > >               .orElse { a => otherDefaultB() }.get
> > >
> > >
> > > On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
> mark@clearstorydata.com
> > > >wrote:
> > >
> > > > In code added to Spark over the past several months, I'm glad to see
> > more
> > > > use of `foreach`, `for`, `map` and `flatMap` over `Option` instead of
> > > > pattern matching boilerplate.  There are opportunities to push
> `Option`
> > > > idioms even further now that we are using Scala 2.10 in master, but I
> > > want
> > > > to discuss the issue here a little bit before committing code whose
> > form
> > > > may be a little unfamiliar to some Spark developers.
> > > >
> > > > In particular, I really like the use of `fold` with `Option` to
> cleanly
> > > an
> > > > concisely express the "do something if the Option is None; do
> something
> > > > else with the thing contained in the Option if it is Some" code
> > fragment.
> > > >
> > > > An example:
> > > >
> > > > Instead of...
> > > >
> > > > val driver = drivers.find(_.id == driverId)
> > > > driver match {
> > > >   case Some(d) =>
> > > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > > >     else {
> > > >       d.worker.foreach { w =>
> > > >         w.actor ! KillDriver(driverId)
> > > >       }
> > > >     }
> > > >     val msg = s"Kill request for $driverId submitted"
> > > >     logInfo(msg)
> > > >     sender ! KillDriverResponse(true, msg)
> > > >   case None =>
> > > >     val msg = s"Could not find running driver $driverId"
> > > >     logWarning(msg)
> > > >     sender ! KillDriverResponse(false, msg)
> > > > }
> > > >
> > > > ...using fold we end up with...
> > > >
> > > > driver.fold
> > > >   {
> > > >     val msg = s"Could not find running driver $driverId"
> > > >     logWarning(msg)
> > > >     sender ! KillDriverResponse(false, msg)
> > > >   }
> > > >   { d =>
> > > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > > >     else {
> > > >       d.worker.foreach { w =>
> > > >         w.actor ! KillDriver(driverId)
> > > >       }
> > > >     }
> > > >     val msg = s"Kill request for $driverId submitted"
> > > >     logInfo(msg)
> > > >     sender ! KillDriverResponse(true, msg)
> > > >   }
> > > >
> > > >
> > > > So the basic pattern (and my proposed formatting standard) for
> folding
> > > over
> > > > an `Option[A]` from which you need to produce a B (which may be Unit
> if
> > > > you're only interested in side effects) is:
> > > >
> > > > anOption.fold
> > > >   {
> > > >     // something that evaluates to a B if anOption = None
> > > >   }
> > > >   { a =>
> > > >     // something that transforms `a` into a B if anOption = Some(a)
> > > >   }
> > > >
> > > >
> > > > Any thoughts?  Does anyone really, really hate this style of coding
> and
> > > > oppose its use in Spark?
> > > >
> > >
> > >
> > >
> > > --
> > > --
> > > Evan Chan
> > > Staff Engineer
> > > ev@ooyala.com  |
> > >
> > > <http://www.ooyala.com/>
> > > <http://www.facebook.com/ooyala><
> http://www.linkedin.com/company/ooyala
> > ><
> > > http://www.twitter.com/ooyala>
> > >
> >
>



-- 
Cell : 425-233-8271

--047d7b86e424e2031e04ee7c48c4--

From dev-return-1009-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 05:13:07 2013
Return-Path: <dev-return-1009-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1DE4310A64
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 05:13:07 +0000 (UTC)
Received: (qmail 51154 invoked by uid 500); 27 Dec 2013 05:13:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51092 invoked by uid 500); 27 Dec 2013 05:12:58 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 51084 invoked by uid 99); 27 Dec 2013 05:12:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 05:12:56 +0000
X-ASF-Spam-Status: No, hits=0.9 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.142 as permitted sender)
Received: from [169.229.218.142] (HELO cm01fe.IST.Berkeley.EDU) (169.229.218.142)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 05:12:52 +0000
Received: from mail-ie0-f178.google.com ([209.85.223.178])
	by cm01fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1VwPin-0007h7-6D
	for dev@spark.incubator.apache.org; Thu, 26 Dec 2013 21:12:31 -0800
Received: by mail-ie0-f178.google.com with SMTP id lx4so9484092iec.9
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 21:12:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=MB5oG4wSEWgB11BwkCorPbIcRWXSrpQlaxiXeePABqI=;
        b=LQpJxc7khCdSsGwnRsLrMYayUCBowOm9ozeOEV9uDZScHedlZty8XMY1tJc67HRqVo
         p2WfyYPFJwIZLOxuRV4gU+yesTW1llSb9gY/MEl9M08IZo5RpvdDNpfKJVKKSkWHlDEV
         R2IQwY2CwDMk2SwHp5KfqrjM0uSnHMgRQ6oJMndNhpzQLlDw1QobwmHgFObpo72NKbI2
         cSpwovMuoE0sE7iLE68VvtUfRPOrDyMLSmLdr/zc4494cXKBBd4M7uatDc2coJmpp15b
         PtFVCMnkFztUQY4jy38alAEORnmKKGC8bGyo/M5/pgMCnzVQL+nElyhgxr6fJUyBYt9o
         2r4A==
MIME-Version: 1.0
X-Received: by 10.50.138.72 with SMTP id qo8mr39079633igb.4.1388121149238;
 Thu, 26 Dec 2013 21:12:29 -0800 (PST)
Received: by 10.64.149.4 with HTTP; Thu, 26 Dec 2013 21:12:29 -0800 (PST)
In-Reply-To: <CAJLcJd9PD=vuKTedGgw5EqTov8AgzRcrVVXFDPsdL+-KdZRRDQ@mail.gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
	<CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
	<CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
	<CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com>
	<CAJLcJd9PD=vuKTedGgw5EqTov8AgzRcrVVXFDPsdL+-KdZRRDQ@mail.gmail.com>
Date: Thu, 26 Dec 2013 21:12:29 -0800
Message-ID: <CAKJXNjFXPq00toCOYCHvozSnqptC1-CcPH=AbasybmNRHhwc4A@mail.gmail.com>
Subject: Re: Option folding idiom
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a1134c79201795a04ee7d2478
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134c79201795a04ee7d2478
Content-Type: text/plain; charset=ISO-8859-1

I agree with what Reynold said -- there's not a big benefit in terms of
lines of code (esp. compared to using getOrElse) and I think it hurts code
readability.  One of the great things about the current Spark codebase is
that it's very accessible for newcomers -- something that would be less
true with this use of "fold".


On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca> wrote:

> I personally with Evan in that I prefer map with getOrElse over fold with
> options (but that just my personal preference) :)
>
>
> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > I'm not strongly against Option.fold, but I find the readability getting
> > worse for the use case you brought up.  For the use case of if/else, I
> find
> > Option.fold pretty confusing because it reverses the order of Some vs
> None.
> > Also, when code gets long, the lack of an obvious boundary (the only
> > boundary is "} {") with two closures is pretty confusing.
> >
> >
> > On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <mark@clearstorydata.com
> > >wrote:
> >
> > > On the contrary, it is the completely natural place for the initial
> value
> > > of the accumulator, and provides the expected result of folding over an
> > > empty collection.
> > >
> > > scala> val l: List[Int] = List()
> > >
> > > l: List[Int] = List()
> > >
> > >
> > > scala> l.fold(42)(_ + _)
> > >
> > > res0: Int = 42
> > >
> > >
> > > scala> val o: Option[Int] = None
> > >
> > > o: Option[Int] = None
> > >
> > >
> > > scala> o.fold(42)(_ + 1)
> > >
> > > res1: Int = 42
> > >
> > >
> > > On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
> > >
> > > > +1 for using more functional idioms in general.
> > > >
> > > > That's a pretty clever use of `fold`, but putting the default
> condition
> > > > first there makes it not as intuitive.   What about the following,
> > which
> > > > are more readable?
> > > >
> > > >     option.map { a => someFuncMakesB() }
> > > >               .getOrElse(b)
> > > >
> > > >     option.map { a => someFuncMakesB() }
> > > >               .orElse { a => otherDefaultB() }.get
> > > >
> > > >
> > > > On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
> > mark@clearstorydata.com
> > > > >wrote:
> > > >
> > > > > In code added to Spark over the past several months, I'm glad to
> see
> > > more
> > > > > use of `foreach`, `for`, `map` and `flatMap` over `Option` instead
> of
> > > > > pattern matching boilerplate.  There are opportunities to push
> > `Option`
> > > > > idioms even further now that we are using Scala 2.10 in master,
> but I
> > > > want
> > > > > to discuss the issue here a little bit before committing code whose
> > > form
> > > > > may be a little unfamiliar to some Spark developers.
> > > > >
> > > > > In particular, I really like the use of `fold` with `Option` to
> > cleanly
> > > > an
> > > > > concisely express the "do something if the Option is None; do
> > something
> > > > > else with the thing contained in the Option if it is Some" code
> > > fragment.
> > > > >
> > > > > An example:
> > > > >
> > > > > Instead of...
> > > > >
> > > > > val driver = drivers.find(_.id == driverId)
> > > > > driver match {
> > > > >   case Some(d) =>
> > > > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > > > >     else {
> > > > >       d.worker.foreach { w =>
> > > > >         w.actor ! KillDriver(driverId)
> > > > >       }
> > > > >     }
> > > > >     val msg = s"Kill request for $driverId submitted"
> > > > >     logInfo(msg)
> > > > >     sender ! KillDriverResponse(true, msg)
> > > > >   case None =>
> > > > >     val msg = s"Could not find running driver $driverId"
> > > > >     logWarning(msg)
> > > > >     sender ! KillDriverResponse(false, msg)
> > > > > }
> > > > >
> > > > > ...using fold we end up with...
> > > > >
> > > > > driver.fold
> > > > >   {
> > > > >     val msg = s"Could not find running driver $driverId"
> > > > >     logWarning(msg)
> > > > >     sender ! KillDriverResponse(false, msg)
> > > > >   }
> > > > >   { d =>
> > > > >     if (waitingDrivers.contains(d)) { waitingDrivers -= d }
> > > > >     else {
> > > > >       d.worker.foreach { w =>
> > > > >         w.actor ! KillDriver(driverId)
> > > > >       }
> > > > >     }
> > > > >     val msg = s"Kill request for $driverId submitted"
> > > > >     logInfo(msg)
> > > > >     sender ! KillDriverResponse(true, msg)
> > > > >   }
> > > > >
> > > > >
> > > > > So the basic pattern (and my proposed formatting standard) for
> > folding
> > > > over
> > > > > an `Option[A]` from which you need to produce a B (which may be
> Unit
> > if
> > > > > you're only interested in side effects) is:
> > > > >
> > > > > anOption.fold
> > > > >   {
> > > > >     // something that evaluates to a B if anOption = None
> > > > >   }
> > > > >   { a =>
> > > > >     // something that transforms `a` into a B if anOption = Some(a)
> > > > >   }
> > > > >
> > > > >
> > > > > Any thoughts?  Does anyone really, really hate this style of coding
> > and
> > > > > oppose its use in Spark?
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > --
> > > > Evan Chan
> > > > Staff Engineer
> > > > ev@ooyala.com  |
> > > >
> > > > <http://www.ooyala.com/>
> > > > <http://www.facebook.com/ooyala><
> > http://www.linkedin.com/company/ooyala
> > > ><
> > > > http://www.twitter.com/ooyala>
> > > >
> > >
> >
>
>
>
> --
> Cell : 425-233-8271
>

--001a1134c79201795a04ee7d2478--

From dev-return-1010-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 07:06:50 2013
Return-Path: <dev-return-1010-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B7D1E10C17
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 07:06:50 +0000 (UTC)
Received: (qmail 39728 invoked by uid 500); 27 Dec 2013 07:06:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39696 invoked by uid 500); 27 Dec 2013 07:06:47 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 39685 invoked by uid 99); 27 Dec 2013 07:06:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 07:06:46 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 07:06:40 +0000
Received: by mail-ig0-f177.google.com with SMTP id uy17so21302912igb.4
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 23:06:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=JIqx3+5CD8vWgJshDbuAJM+fbCpiZ5ruyEhrqOJDDRk=;
        b=tcL0SlDG92d25TOpSBs8UvZQ60se5brIreglcbFatUX3TEF1luVlqbgZgFDHomeB0a
         VkxOxuCcvT/aOKW/9fcx0jeWw5I4G9TJd4YAnQsF+RFEQZrmVH1udpd6W0lz1STCAn8V
         SNYLEvfRzDppT5Ns9FQsP0UEsNxLohM0koPWtt7IN/ztD2MsbbmDN39osQLPJjrJkbXW
         B3uLlo/SUbJrkBPO5wassAlLHaS5Mws7pq2zzLW98P+7LxoPQFIZuHVt8vG9OcY2zbaV
         VP4nmW3s4IOIoWY9yRFqmwMFIDFAMEaiypW6lYOzc9kJIycylKRs2Fe43r9zt77vs7cO
         f+ow==
X-Received: by 10.42.148.200 with SMTP id s8mr1197511icv.67.1388127979658;
        Thu, 26 Dec 2013 23:06:19 -0800 (PST)
Received: from [192.168.1.144] (CPE68b6fc3fbad3-CM68b6fc3fbad0.cpe.net.cable.rogers.com. [99.226.46.122])
        by mx.google.com with ESMTPSA id j16sm43626306igf.6.2013.12.26.23.06.16
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 26 Dec 2013 23:06:17 -0800 (PST)
Content-Type: text/plain; charset=windows-1252
Mime-Version: 1.0 (Mac OS X Mail 7.1 \(1827\))
Subject: Re: Option folding idiom
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAKJXNjFXPq00toCOYCHvozSnqptC1-CcPH=AbasybmNRHhwc4A@mail.gmail.com>
Date: Fri, 27 Dec 2013 02:06:15 -0500
Content-Transfer-Encoding: quoted-printable
Message-Id: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com> <CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com> <CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com> <CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com> <CAJLcJd9PD=vuKTedGgw5EqTov8AgzRcrVVXFDPsdL+-KdZRRDQ@mail.gmail.com> <CAKJXNjFXPq00toCOYCHvozSnqptC1-CcPH=AbasybmNRHhwc4A@mail.gmail.com>
To: dev@spark.incubator.apache.org
X-Mailer: Apple Mail (2.1827)
X-Virus-Checked: Checked by ClamAV on apache.org

I agree about using getOrElse instead. In choosing which code style and =
idioms to use, my goal has always been to maximize the ease of *other =
developers* understanding the code, and most developers today still =
don=92t know Scala. It=92s fine to use a maps or matches, because their =
meaning is obvious, but fold on Option is not obvious (even foreach is =
kind of weird for new people). In this case the benefit is so small that =
it doesn=92t seem worth it.

Note that if you use getOrElse, you can even throw exceptions in the =
=93else=94 part if you=92d like. (This is because Nothing is a subtype =
of every type in Scala.) So for example you can do val stuff =3D =
option.getOrElse(throw new Exception(=93It wasn=92t set=94)). It looks a =
little weird, but note how the meaning is obvious even if you don=92t =
know anything about the type system.

Matei

On Dec 27, 2013, at 12:12 AM, Kay Ousterhout <keo@eecs.berkeley.edu> =
wrote:

> I agree with what Reynold said -- there's not a big benefit in terms =
of
> lines of code (esp. compared to using getOrElse) and I think it hurts =
code
> readability.  One of the great things about the current Spark codebase =
is
> that it's very accessible for newcomers -- something that would be =
less
> true with this use of "fold".
>=20
>=20
> On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca> =
wrote:
>=20
>> I personally with Evan in that I prefer map with getOrElse over fold =
with
>> options (but that just my personal preference) :)
>>=20
>>=20
>> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>>=20
>>> I'm not strongly against Option.fold, but I find the readability =
getting
>>> worse for the use case you brought up.  For the use case of if/else, =
I
>> find
>>> Option.fold pretty confusing because it reverses the order of Some =
vs
>> None.
>>> Also, when code gets long, the lack of an obvious boundary (the only
>>> boundary is "} {") with two closures is pretty confusing.
>>>=20
>>>=20
>>> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra =
<mark@clearstorydata.com
>>>> wrote:
>>>=20
>>>> On the contrary, it is the completely natural place for the initial
>> value
>>>> of the accumulator, and provides the expected result of folding =
over an
>>>> empty collection.
>>>>=20
>>>> scala> val l: List[Int] =3D List()
>>>>=20
>>>> l: List[Int] =3D List()
>>>>=20
>>>>=20
>>>> scala> l.fold(42)(_ + _)
>>>>=20
>>>> res0: Int =3D 42
>>>>=20
>>>>=20
>>>> scala> val o: Option[Int] =3D None
>>>>=20
>>>> o: Option[Int] =3D None
>>>>=20
>>>>=20
>>>> scala> o.fold(42)(_ + 1)
>>>>=20
>>>> res1: Int =3D 42
>>>>=20
>>>>=20
>>>> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
>>>>=20
>>>>> +1 for using more functional idioms in general.
>>>>>=20
>>>>> That's a pretty clever use of `fold`, but putting the default
>> condition
>>>>> first there makes it not as intuitive.   What about the following,
>>> which
>>>>> are more readable?
>>>>>=20
>>>>>    option.map { a =3D> someFuncMakesB() }
>>>>>              .getOrElse(b)
>>>>>=20
>>>>>    option.map { a =3D> someFuncMakesB() }
>>>>>              .orElse { a =3D> otherDefaultB() }.get
>>>>>=20
>>>>>=20
>>>>> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
>>> mark@clearstorydata.com
>>>>>> wrote:
>>>>>=20
>>>>>> In code added to Spark over the past several months, I'm glad to
>> see
>>>> more
>>>>>> use of `foreach`, `for`, `map` and `flatMap` over `Option` =
instead
>> of
>>>>>> pattern matching boilerplate.  There are opportunities to push
>>> `Option`
>>>>>> idioms even further now that we are using Scala 2.10 in master,
>> but I
>>>>> want
>>>>>> to discuss the issue here a little bit before committing code =
whose
>>>> form
>>>>>> may be a little unfamiliar to some Spark developers.
>>>>>>=20
>>>>>> In particular, I really like the use of `fold` with `Option` to
>>> cleanly
>>>>> an
>>>>>> concisely express the "do something if the Option is None; do
>>> something
>>>>>> else with the thing contained in the Option if it is Some" code
>>>> fragment.
>>>>>>=20
>>>>>> An example:
>>>>>>=20
>>>>>> Instead of...
>>>>>>=20
>>>>>> val driver =3D drivers.find(_.id =3D=3D driverId)
>>>>>> driver match {
>>>>>>  case Some(d) =3D>
>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
>>>>>>    else {
>>>>>>      d.worker.foreach { w =3D>
>>>>>>        w.actor ! KillDriver(driverId)
>>>>>>      }
>>>>>>    }
>>>>>>    val msg =3D s"Kill request for $driverId submitted"
>>>>>>    logInfo(msg)
>>>>>>    sender ! KillDriverResponse(true, msg)
>>>>>>  case None =3D>
>>>>>>    val msg =3D s"Could not find running driver $driverId"
>>>>>>    logWarning(msg)
>>>>>>    sender ! KillDriverResponse(false, msg)
>>>>>> }
>>>>>>=20
>>>>>> ...using fold we end up with...
>>>>>>=20
>>>>>> driver.fold
>>>>>>  {
>>>>>>    val msg =3D s"Could not find running driver $driverId"
>>>>>>    logWarning(msg)
>>>>>>    sender ! KillDriverResponse(false, msg)
>>>>>>  }
>>>>>>  { d =3D>
>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
>>>>>>    else {
>>>>>>      d.worker.foreach { w =3D>
>>>>>>        w.actor ! KillDriver(driverId)
>>>>>>      }
>>>>>>    }
>>>>>>    val msg =3D s"Kill request for $driverId submitted"
>>>>>>    logInfo(msg)
>>>>>>    sender ! KillDriverResponse(true, msg)
>>>>>>  }
>>>>>>=20
>>>>>>=20
>>>>>> So the basic pattern (and my proposed formatting standard) for
>>> folding
>>>>> over
>>>>>> an `Option[A]` from which you need to produce a B (which may be
>> Unit
>>> if
>>>>>> you're only interested in side effects) is:
>>>>>>=20
>>>>>> anOption.fold
>>>>>>  {
>>>>>>    // something that evaluates to a B if anOption =3D None
>>>>>>  }
>>>>>>  { a =3D>
>>>>>>    // something that transforms `a` into a B if anOption =3D =
Some(a)
>>>>>>  }
>>>>>>=20
>>>>>>=20
>>>>>> Any thoughts?  Does anyone really, really hate this style of =
coding
>>> and
>>>>>> oppose its use in Spark?
>>>>>>=20
>>>>>=20
>>>>>=20
>>>>>=20
>>>>> --
>>>>> --
>>>>> Evan Chan
>>>>> Staff Engineer
>>>>> ev@ooyala.com  |
>>>>>=20
>>>>> <http://www.ooyala.com/>
>>>>> <http://www.facebook.com/ooyala><
>>> http://www.linkedin.com/company/ooyala
>>>>> <
>>>>> http://www.twitter.com/ooyala>
>>>>>=20
>>>>=20
>>>=20
>>=20
>>=20
>>=20
>> --
>> Cell : 425-233-8271
>>=20


From dev-return-1011-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 07:40:51 2013
Return-Path: <dev-return-1011-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 44AE810C99
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 07:40:51 +0000 (UTC)
Received: (qmail 82953 invoked by uid 500); 27 Dec 2013 07:40:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82916 invoked by uid 500); 27 Dec 2013 07:40:45 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 82898 invoked by uid 99); 27 Dec 2013 07:40:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 07:40:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.170 as permitted sender)
Received: from [209.85.216.170] (HELO mail-qc0-f170.google.com) (209.85.216.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 07:40:38 +0000
Received: by mail-qc0-f170.google.com with SMTP id x13so8491292qcv.29
        for <dev@spark.incubator.apache.org>; Thu, 26 Dec 2013 23:40:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:in-reply-to:references:from:to:subject
         :content-type;
        bh=B1F34OjUIaNAe4+/wFvaPWamDfOIzjjlpcLKsthzjYQ=;
        b=x3M+WXqzNOck6cwdA13iL1YRoD3wc0yMVssTVewZL0/0QrQ1xqGO2YWWMJ233o+Fc5
         dFsTmtuZkrBLvQV23U8vAenMXbbNbYJKE/0WtE2RqAalrff5EAWQlG1XeOv9S2EamDgT
         GePqE0BshBhZv0LXFbKI5b7TBAeRitgyJ7u799dyJr99rhsZHfr2TKzm3KDAHzvXAQJ+
         laR1ogxwEc/6J0hcB0VcldgnyZn2biNgR4jcAgLN4FLUTBtKmo5C/Ga3TD+6RdTBJ2DY
         MTjqw8o8HX/kO3AydLaMjPqUn1NXC7gAFVfZ8HzGSlyDSJVbLqqEddHlK8LocqOL0VQo
         12Zg==
X-Received: by 10.224.171.196 with SMTP id i4mr78901766qaz.38.1388130017851;
        Thu, 26 Dec 2013 23:40:17 -0800 (PST)
Received: from [127.0.0.1] (ec2-54-235-159-161.compute-1.amazonaws.com. [54.235.159.161])
        by mx.google.com with ESMTPSA id z4sm42293985qeq.11.2013.12.26.23.40.17
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 26 Dec 2013 23:40:17 -0800 (PST)
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Date: Thu, 26 Dec 2013 23:40:17 -0800 (PST)
Message-Id: <1388130017101.e357ebea@Nodemailer>
In-Reply-To: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
References: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
X-Orchestra-Oid: 0299C021-8131-4502-8302-F63C1DC94FF1
X-Orchestra-Sig: a21ad5fe163bd245c7e861a870b3991ac9093c3a
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1455517872375333676
X-Orchestra-Thrid-Sig: 3ac37eade8824e39aa871467909d569a62316813
X-Orchestra-Account: 976e66768d247067bd5688ad72008d7dfa2de608
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: dev@spark.incubator.apache.org
Subject: Re: Option folding idiom
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1388130017389"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1388130017389
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

+1 for getOrElse


When I was new to Scala I tended to use match almost like if/else =
statements with Option. These days I try to use map/flatMap instead and use=
 getOrElse extensively and I for one find it very intuitive.




I also agree that the fold syntax seems way less intuitive and I certainly =
prefer readable Scala code to that which might be more =22idiomatic=22 but =
which I honestly tend to find very inscrutable and hard to grok quickly.
=E2=80=94
Sent from Mailbox for iPhone

On Fri, Dec 27, 2013 at 9:06 AM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> I agree about using getOrElse instead. In choosing which code style and =
idioms to use, my goal has always been to maximize the ease of *other =
developers* understanding the code, and most developers today still =
don=E2=80=99t know Scala. It=E2=80=99s fine to use a maps or matches, =
because their meaning is obvious, but fold on Option is not obvious (even =
foreach is kind of weird for new people). In this case the benefit is so =
small that it doesn=E2=80=99t seem worth it.
> Note that if you use getOrElse, you can even throw exceptions in the =
=E2=80=9Celse=E2=80=9D part if you=E2=80=99d like. (This is because Nothing=
 is a subtype of every type in Scala.) So for example you can do val stuff =
=3D option.getOrElse(throw new Exception(=E2=80=9CIt wasn=E2=80=99t =
set=E2=80=9D)). It looks a little weird, but note how the meaning is =
obvious even if you don=E2=80=99t know anything about the type system.
> Matei
> On Dec 27, 2013, at 12:12 AM, Kay Ousterhout <keo@eecs.berkeley.edu> =
wrote:
>> I agree with what Reynold said -- there's not a big benefit in terms of
>> lines of code (esp. compared to using getOrElse) and I think it hurts =
code
>> readability.  One of the great things about the current Spark codebase =
is
>> that it's very accessible for newcomers -- something that would be less
>> true with this use of =22fold=22.
>>=20
>>=20
>> On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca> =
wrote:
>>=20
>>> I personally with Evan in that I prefer map with getOrElse over fold =
with
>>> options (but that just my personal preference) :)
>>>=20
>>>=20
>>> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>>>=20
>>>> I'm not strongly against Option.fold, but I find the readability =
getting
>>>> worse for the use case you brought up.  For the use case of if/else, =
I
>>> find
>>>> Option.fold pretty confusing because it reverses the order of Some vs
>>> None.
>>>> Also, when code gets long, the lack of an obvious boundary (the only
>>>> boundary is =22} {=22) with two closures is pretty confusing.
>>>>=20
>>>>=20
>>>> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <mark@clearstorydata.=
com
>>>>> wrote:
>>>>=20
>>>>> On the contrary, it is the completely natural place for the initial
>>> value
>>>>> of the accumulator, and provides the expected result of folding over =
an
>>>>> empty collection.
>>>>>=20
>>>>> scala> val l: List[Int] =3D List()
>>>>>=20
>>>>> l: List[Int] =3D List()
>>>>>=20
>>>>>=20
>>>>> scala> l.fold(42)(=5F + =5F)
>>>>>=20
>>>>> res0: Int =3D 42
>>>>>=20
>>>>>=20
>>>>> scala> val o: Option[Int] =3D None
>>>>>=20
>>>>> o: Option[Int] =3D None
>>>>>=20
>>>>>=20
>>>>> scala> o.fold(42)(=5F + 1)
>>>>>=20
>>>>> res1: Int =3D 42
>>>>>=20
>>>>>=20
>>>>> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
>>>>>=20
>>>>>> +1 for using more functional idioms in general.
>>>>>>=20
>>>>>> That's a pretty clever use of `fold`, but putting the default
>>> condition
>>>>>> first there makes it not as intuitive.   What about the following,
>>>> which
>>>>>> are more readable=3F
>>>>>>=20
>>>>>>    option.map { a =3D> someFuncMakesB() }
>>>>>>              .getOrElse(b)
>>>>>>=20
>>>>>>    option.map { a =3D> someFuncMakesB() }
>>>>>>              .orElse { a =3D> otherDefaultB() }.get
>>>>>>=20
>>>>>>=20
>>>>>> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
>>>> mark@clearstorydata.com
>>>>>>> wrote:
>>>>>>=20
>>>>>>> In code added to Spark over the past several months, I'm glad to
>>> see
>>>>> more
>>>>>>> use of `foreach`, `for`, `map` and `flatMap` over `Option` instead
>>> of
>>>>>>> pattern matching boilerplate.  There are opportunities to push
>>>> `Option`
>>>>>>> idioms even further now that we are using Scala 2.10 in master,
>>> but I
>>>>>> want
>>>>>>> to discuss the issue here a little bit before committing code =
whose
>>>>> form
>>>>>>> may be a little unfamiliar to some Spark developers.
>>>>>>>=20
>>>>>>> In particular, I really like the use of `fold` with `Option` to
>>>> cleanly
>>>>>> an
>>>>>>> concisely express the =22do something if the Option is None; do
>>>> something
>>>>>>> else with the thing contained in the Option if it is Some=22 code
>>>>> fragment.
>>>>>>>=20
>>>>>>> An example:
>>>>>>>=20
>>>>>>> Instead of...
>>>>>>>=20
>>>>>>> val driver =3D drivers.find(=5F.id =3D=3D driverId)
>>>>>>> driver match {
>>>>>>>  case Some(d) =3D>
>>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
>>>>>>>    else {
>>>>>>>      d.worker.foreach { w =3D>
>>>>>>>        w.actor ! KillDriver(driverId)
>>>>>>>      }
>>>>>>>    }
>>>>>>>    val msg =3D s=22Kill request for $driverId submitted=22
>>>>>>>    logInfo(msg)
>>>>>>>    sender ! KillDriverResponse(true, msg)
>>>>>>>  case None =3D>
>>>>>>>    val msg =3D s=22Could not find running driver $driverId=22
>>>>>>>    logWarning(msg)
>>>>>>>    sender ! KillDriverResponse(false, msg)
>>>>>>> }
>>>>>>>=20
>>>>>>> ...using fold we end up with...
>>>>>>>=20
>>>>>>> driver.fold
>>>>>>>  {
>>>>>>>    val msg =3D s=22Could not find running driver $driverId=22
>>>>>>>    logWarning(msg)
>>>>>>>    sender ! KillDriverResponse(false, msg)
>>>>>>>  }
>>>>>>>  { d =3D>
>>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
>>>>>>>    else {
>>>>>>>      d.worker.foreach { w =3D>
>>>>>>>        w.actor ! KillDriver(driverId)
>>>>>>>      }
>>>>>>>    }
>>>>>>>    val msg =3D s=22Kill request for $driverId submitted=22
>>>>>>>    logInfo(msg)
>>>>>>>    sender ! KillDriverResponse(true, msg)
>>>>>>>  }
>>>>>>>=20
>>>>>>>=20
>>>>>>> So the basic pattern (and my proposed formatting standard) for
>>>> folding
>>>>>> over
>>>>>>> an `Option[A]` from which you need to produce a B (which may be
>>> Unit
>>>> if
>>>>>>> you're only interested in side effects) is:
>>>>>>>=20
>>>>>>> anOption.fold
>>>>>>>  {
>>>>>>>    // something that evaluates to a B if anOption =3D None
>>>>>>>  }
>>>>>>>  { a =3D>
>>>>>>>    // something that transforms `a` into a B if anOption =3D =
Some(a)
>>>>>>>  }
>>>>>>>=20
>>>>>>>=20
>>>>>>> Any thoughts=3F  Does anyone really, really hate this style of =
coding
>>>> and
>>>>>>> oppose its use in Spark=3F
>>>>>>>=20
>>>>>>=20
>>>>>>=20
>>>>>>=20
>>>>>> --
>>>>>> --
>>>>>> Evan Chan
>>>>>> Staff Engineer
>>>>>> ev@ooyala.com  |
>>>>>>=20
>>>>>> <http://www.ooyala.com/>
>>>>>> <http://www.facebook.com/ooyala><
>>>> http://www.linkedin.com/company/ooyala
>>>>>> <
>>>>>> http://www.twitter.com/ooyala>
>>>>>>=20
>>>>>=20
>>>>=20
>>>=20
>>>=20
>>>=20
>>> --
>>> Cell : 425-233-8271
>>>=20
------Nodemailer-0.5.0-?=_1-1388130017389--

From dev-return-1012-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 08:30:26 2013
Return-Path: <dev-return-1012-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD0E110D3B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 08:30:26 +0000 (UTC)
Received: (qmail 18082 invoked by uid 500); 27 Dec 2013 08:30:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17840 invoked by uid 500); 27 Dec 2013 08:30:17 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 17832 invoked by uid 99); 27 Dec 2013 08:30:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 08:30:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 209.85.214.48 as permitted sender)
Received: from [209.85.214.48] (HELO mail-bk0-f48.google.com) (209.85.214.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 08:30:10 +0000
Received: by mail-bk0-f48.google.com with SMTP id r7so2966142bkg.7
        for <dev@spark.incubator.apache.org>; Fri, 27 Dec 2013 00:29:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=MdB0fmtS2a8E/FbTD4OWdqcP+1hm44WGxYFwmMHEyL0=;
        b=mShI4kSZM2RxRpHEBTyfPncL551/bHji8xgTXGZDMh+BLMyV1w8/IUmlFuLUFRyRRO
         SrcPV9aFJQEgSmWr+QTiCm7ZZbZr2FJuFX04KY2ZoFlz0oXj1MprD+tYRk1MJbGzhIgD
         OBwtWc1jGswBVj+UIoLzza8GOR50y3JA5ZpD+rv1OaCgVxwtTGrCc1P7MlxDKTVDoLus
         hDBgz0NKWBxQw27y4DvZhKYuOEx+n5+jKyKghd8jopyjoRA/3DFT8q3fwQBzfuIEJO8s
         YtDUHmnNwWM8A5EsrEW5OciI6b/kcEM+0Omck/+ILLaaLz4WSk8ZW/Tmp8eIsO3p8uOP
         d4xw==
X-Gm-Message-State: ALoCoQmVznvld2RlRNkYD42xo8zhmYJIOPMrYCFoqX2qvEA2XAbPH/tNQ513u22kx0NJFwrepOh2
MIME-Version: 1.0
X-Received: by 10.204.53.75 with SMTP id l11mr3469880bkg.35.1388132988379;
 Fri, 27 Dec 2013 00:29:48 -0800 (PST)
Received: by 10.205.6.199 with HTTP; Fri, 27 Dec 2013 00:29:48 -0800 (PST)
In-Reply-To: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
References: <CAAsvFP=8ZV4kn6JYBLFnjY5eL3uBpdLKXTU=KpAt3sJwMQWm8Q@mail.gmail.com>
	<CADWPM3hZEmbRnvxrj8gLRb_eL_u0W819QqrJ1X0NmdtJ7H+9MA@mail.gmail.com>
	<CAAsvFP=JC1N8+tAkMa+1oQ2OkJzV0yi_Vedv1Zcdf1MMb=4WgQ@mail.gmail.com>
	<CAPh_B=bY0v-Vd2AC1V7YqKA7h4z9uNrhH8YA+0veNbhQrWMYjA@mail.gmail.com>
	<CAJLcJd9PD=vuKTedGgw5EqTov8AgzRcrVVXFDPsdL+-KdZRRDQ@mail.gmail.com>
	<CAKJXNjFXPq00toCOYCHvozSnqptC1-CcPH=AbasybmNRHhwc4A@mail.gmail.com>
	<EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
Date: Fri, 27 Dec 2013 00:29:48 -0800
Message-ID: <CAAsvFPnyYbqc1NRoBfWyz6sm85SK0=noCRxAyEA-+H3iEkyJfA@mail.gmail.com>
Subject: Re: Option folding idiom
From: Mark Hamstra <mark@clearstorydata.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c3692aacd8ee04ee7fe5f6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3692aacd8ee04ee7fe5f6
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

Well, you can throw exceptions from within a fold as well:

scala> val o: Option[Int] =3D None
o: Option[Int] =3D None

scala> o.fold { throw new Exception("It wasn't set") } { _.toString }
java.lang.Exception: It wasn't set
  at $anonfun$1.apply(<console>:9)
  at $anonfun$1.apply(<console>:9)
  at scala.Option.fold(Option.scala:157)
  ... 32 elided

But it looks to me like there's an emerging majority, if not a consensus,
who find clearly expressing the catamorphism not to be very useful or
helpful on its own, so I can certainly make do with other syntactic
constructs that others appreciate more.  That was worth clarifying for me,
so thank you all.



On Thu, Dec 26, 2013 at 11:06 PM, Matei Zaharia <matei.zaharia@gmail.com>wr=
ote:

> I agree about using getOrElse instead. In choosing which code style and
> idioms to use, my goal has always been to maximize the ease of *other
> developers* understanding the code, and most developers today still don=
=92t
> know Scala. It=92s fine to use a maps or matches, because their meaning i=
s
> obvious, but fold on Option is not obvious (even foreach is kind of weird
> for new people). In this case the benefit is so small that it doesn=92t s=
eem
> worth it.
>
> Note that if you use getOrElse, you can even throw exceptions in the
> =93else=94 part if you=92d like. (This is because Nothing is a subtype of=
 every
> type in Scala.) So for example you can do val stuff =3D
> option.getOrElse(throw new Exception(=93It wasn=92t set=94)). It looks a =
little
> weird, but note how the meaning is obvious even if you don=92t know anyth=
ing
> about the type system.
>
> Matei
>
> On Dec 27, 2013, at 12:12 AM, Kay Ousterhout <keo@eecs.berkeley.edu>
> wrote:
>
> > I agree with what Reynold said -- there's not a big benefit in terms of
> > lines of code (esp. compared to using getOrElse) and I think it hurts
> code
> > readability.  One of the great things about the current Spark codebase =
is
> > that it's very accessible for newcomers -- something that would be less
> > true with this use of "fold".
> >
> >
> > On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca>
> wrote:
> >
> >> I personally with Evan in that I prefer map with getOrElse over fold
> with
> >> options (but that just my personal preference) :)
> >>
> >>
> >> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >>
> >>> I'm not strongly against Option.fold, but I find the readability
> getting
> >>> worse for the use case you brought up.  For the use case of if/else, =
I
> >> find
> >>> Option.fold pretty confusing because it reverses the order of Some vs
> >> None.
> >>> Also, when code gets long, the lack of an obvious boundary (the only
> >>> boundary is "} {") with two closures is pretty confusing.
> >>>
> >>>
> >>> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <mark@clearstorydata.co=
m
> >>>> wrote:
> >>>
> >>>> On the contrary, it is the completely natural place for the initial
> >> value
> >>>> of the accumulator, and provides the expected result of folding over
> an
> >>>> empty collection.
> >>>>
> >>>> scala> val l: List[Int] =3D List()
> >>>>
> >>>> l: List[Int] =3D List()
> >>>>
> >>>>
> >>>> scala> l.fold(42)(_ + _)
> >>>>
> >>>> res0: Int =3D 42
> >>>>
> >>>>
> >>>> scala> val o: Option[Int] =3D None
> >>>>
> >>>> o: Option[Int] =3D None
> >>>>
> >>>>
> >>>> scala> o.fold(42)(_ + 1)
> >>>>
> >>>> res1: Int =3D 42
> >>>>
> >>>>
> >>>> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
> >>>>
> >>>>> +1 for using more functional idioms in general.
> >>>>>
> >>>>> That's a pretty clever use of `fold`, but putting the default
> >> condition
> >>>>> first there makes it not as intuitive.   What about the following,
> >>> which
> >>>>> are more readable?
> >>>>>
> >>>>>    option.map { a =3D> someFuncMakesB() }
> >>>>>              .getOrElse(b)
> >>>>>
> >>>>>    option.map { a =3D> someFuncMakesB() }
> >>>>>              .orElse { a =3D> otherDefaultB() }.get
> >>>>>
> >>>>>
> >>>>> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
> >>> mark@clearstorydata.com
> >>>>>> wrote:
> >>>>>
> >>>>>> In code added to Spark over the past several months, I'm glad to
> >> see
> >>>> more
> >>>>>> use of `foreach`, `for`, `map` and `flatMap` over `Option` instead
> >> of
> >>>>>> pattern matching boilerplate.  There are opportunities to push
> >>> `Option`
> >>>>>> idioms even further now that we are using Scala 2.10 in master,
> >> but I
> >>>>> want
> >>>>>> to discuss the issue here a little bit before committing code whos=
e
> >>>> form
> >>>>>> may be a little unfamiliar to some Spark developers.
> >>>>>>
> >>>>>> In particular, I really like the use of `fold` with `Option` to
> >>> cleanly
> >>>>> an
> >>>>>> concisely express the "do something if the Option is None; do
> >>> something
> >>>>>> else with the thing contained in the Option if it is Some" code
> >>>> fragment.
> >>>>>>
> >>>>>> An example:
> >>>>>>
> >>>>>> Instead of...
> >>>>>>
> >>>>>> val driver =3D drivers.find(_.id =3D=3D driverId)
> >>>>>> driver match {
> >>>>>>  case Some(d) =3D>
> >>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> >>>>>>    else {
> >>>>>>      d.worker.foreach { w =3D>
> >>>>>>        w.actor ! KillDriver(driverId)
> >>>>>>      }
> >>>>>>    }
> >>>>>>    val msg =3D s"Kill request for $driverId submitted"
> >>>>>>    logInfo(msg)
> >>>>>>    sender ! KillDriverResponse(true, msg)
> >>>>>>  case None =3D>
> >>>>>>    val msg =3D s"Could not find running driver $driverId"
> >>>>>>    logWarning(msg)
> >>>>>>    sender ! KillDriverResponse(false, msg)
> >>>>>> }
> >>>>>>
> >>>>>> ...using fold we end up with...
> >>>>>>
> >>>>>> driver.fold
> >>>>>>  {
> >>>>>>    val msg =3D s"Could not find running driver $driverId"
> >>>>>>    logWarning(msg)
> >>>>>>    sender ! KillDriverResponse(false, msg)
> >>>>>>  }
> >>>>>>  { d =3D>
> >>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> >>>>>>    else {
> >>>>>>      d.worker.foreach { w =3D>
> >>>>>>        w.actor ! KillDriver(driverId)
> >>>>>>      }
> >>>>>>    }
> >>>>>>    val msg =3D s"Kill request for $driverId submitted"
> >>>>>>    logInfo(msg)
> >>>>>>    sender ! KillDriverResponse(true, msg)
> >>>>>>  }
> >>>>>>
> >>>>>>
> >>>>>> So the basic pattern (and my proposed formatting standard) for
> >>> folding
> >>>>> over
> >>>>>> an `Option[A]` from which you need to produce a B (which may be
> >> Unit
> >>> if
> >>>>>> you're only interested in side effects) is:
> >>>>>>
> >>>>>> anOption.fold
> >>>>>>  {
> >>>>>>    // something that evaluates to a B if anOption =3D None
> >>>>>>  }
> >>>>>>  { a =3D>
> >>>>>>    // something that transforms `a` into a B if anOption =3D Some(=
a)
> >>>>>>  }
> >>>>>>
> >>>>>>
> >>>>>> Any thoughts?  Does anyone really, really hate this style of codin=
g
> >>> and
> >>>>>> oppose its use in Spark?
> >>>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> --
> >>>>> Evan Chan
> >>>>> Staff Engineer
> >>>>> ev@ooyala.com  |
> >>>>>
> >>>>> <http://www.ooyala.com/>
> >>>>> <http://www.facebook.com/ooyala><
> >>> http://www.linkedin.com/company/ooyala
> >>>>> <
> >>>>> http://www.twitter.com/ooyala>
> >>>>>
> >>>>
> >>>
> >>
> >>
> >>
> >> --
> >> Cell : 425-233-8271
> >>
>
>

--001a11c3692aacd8ee04ee7fe5f6--

From dev-return-1013-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 08:58:11 2013
Return-Path: <dev-return-1013-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C5FEA10E5A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 08:58:11 +0000 (UTC)
Received: (qmail 47615 invoked by uid 500); 27 Dec 2013 08:58:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47567 invoked by uid 500); 27 Dec 2013 08:58:07 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 47559 invoked by uid 99); 27 Dec 2013 08:58:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 08:58:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ctn@adatao.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 08:58:03 +0000
Received: by mail-ie0-f176.google.com with SMTP id at1so9452163iec.21
        for <dev@spark.incubator.apache.org>; Fri, 27 Dec 2013 00:57:40 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=adatao.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=r2lir/YK7dz/z3YbusuF+e8jCotWj0V3/5r9w3UeRl0=;
        b=AlhKffaToW9YeCre09lUlMg71uv6d91a6PLW0D2z6vDTGTP8tP5qawYbaGyyS8R6K1
         xVTiipZv7nGRD23hEyd0bYdBNwgoAyjW00Jtlm/il9SkbgPssqwYrJSjq77WUNT1u7xO
         VFx2Ba42Jh7SmhulU0K0QrUh6jux2QEWoldoU=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=r2lir/YK7dz/z3YbusuF+e8jCotWj0V3/5r9w3UeRl0=;
        b=YHk3yyXw0ZTRaaaKkS0fW1tCp5p8BfWSSF2QUCVgCGaeYp6U8lMiAEPG+YxwfUJ6wg
         rMTzEo+YwnuSUdkc+6ivNiKtrVSPXhsDskIbeTNWDtfB6dtPRlSLzKEiRFS4nbMMAdCt
         b8MsUgxZim0961xBZ9uGT7FPRg5Gtu6b/aKYCBBFqFxTZArCRrT71CxxE+aHSD8kKn67
         aaI/OjXVhchJKvxGUYkyYteVzu3iRlO4qMWQxkv7uGwDeyOmXe+Hq/PjVSKNUg6cMGuj
         en4UUeZO2FsSo3bQTl+kepsKsKjWR57S02lNlEYbOwLDWx4/dMgu8z2FScIaJfu9C4m5
         NWZA==
X-Gm-Message-State: ALoCoQmKmcsFV9Fx/Y4fviJwVm61lNR8LNGHzLihImuaUhM/K6SbWBd3aOWrFNfGLSoWYGD3xqD9
X-Received: by 10.50.78.199 with SMTP id d7mr38831039igx.8.1388134660692; Fri,
 27 Dec 2013 00:57:40 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.20.78 with HTTP; Fri, 27 Dec 2013 00:57:20 -0800 (PST)
X-Originating-IP: [128.177.190.114]
In-Reply-To: <1388130017101.e357ebea@Nodemailer>
References: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com> <1388130017101.e357ebea@Nodemailer>
From: Christopher Nguyen <ctn@adatao.com>
Date: Fri, 27 Dec 2013 00:57:20 -0800
Message-ID: <CAGh_TuMLPEnXVuZPi5Pwv_5xCQLdkR8fUnCOsKD24AgaTzxC9g@mail.gmail.com>
Subject: Re: Option folding idiom
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e013c6ee459fe6904ee8049e0
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6ee459fe6904ee8049e0
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

I've learned and unlearned enough things to be careful when claiming
something is "more intuitive" than another, since it's subject to prior
knowledge. When I first encountered map().getOrElse() it wasn't any more
intuitive than this fold()() syntax. Maybe the "OrElse" helps a bit, but
the "get" in front of it confuses matters again (it sets one up to expect
two things following, not one). Meanwhile, people coming from
data-structure-folding background would argue that fold()() is more
"intuitive".

If the choice is among three alternatives (match, map().getOrElse(), and
fold()()), and the goal is intuitively obvious syntax to the broadest
audience, then "match" wins by a reasonably good distance, with the latter
two about equal. This tie could be broken by the fact that more people by
now know about getOrElse than fold, crossed with the fact that it probably
isn't on the top of the Spark community's agenda to be avant garde on new
Scala syntax.



--
Christopher T. Nguyen
Co-founder & CEO, Adatao <http://adatao.com>
linkedin.com/in/ctnguyen



On Thu, Dec 26, 2013 at 11:40 PM, Nick Pentreath
<nick.pentreath@gmail.com>wrote:

> +1 for getOrElse
>
>
> When I was new to Scala I tended to use match almost like if/else
> statements with Option. These days I try to use map/flatMap instead and u=
se
> getOrElse extensively and I for one find it very intuitive.
>
>
>
>
> I also agree that the fold syntax seems way less intuitive and I certainl=
y
> prefer readable Scala code to that which might be more "idiomatic" but
> which I honestly tend to find very inscrutable and hard to grok quickly.
> =97
> Sent from Mailbox for iPhone
>
> On Fri, Dec 27, 2013 at 9:06 AM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>
> > I agree about using getOrElse instead. In choosing which code style and
> idioms to use, my goal has always been to maximize the ease of *other
> developers* understanding the code, and most developers today still don=
=92t
> know Scala. It=92s fine to use a maps or matches, because their meaning i=
s
> obvious, but fold on Option is not obvious (even foreach is kind of weird
> for new people). In this case the benefit is so small that it doesn=92t s=
eem
> worth it.
> > Note that if you use getOrElse, you can even throw exceptions in the
> =93else=94 part if you=92d like. (This is because Nothing is a subtype of=
 every
> type in Scala.) So for example you can do val stuff =3D
> option.getOrElse(throw new Exception(=93It wasn=92t set=94)). It looks a =
little
> weird, but note how the meaning is obvious even if you don=92t know anyth=
ing
> about the type system.
> > Matei
> > On Dec 27, 2013, at 12:12 AM, Kay Ousterhout <keo@eecs.berkeley.edu>
> wrote:
> >> I agree with what Reynold said -- there's not a big benefit in terms o=
f
> >> lines of code (esp. compared to using getOrElse) and I think it hurts
> code
> >> readability.  One of the great things about the current Spark codebase
> is
> >> that it's very accessible for newcomers -- something that would be les=
s
> >> true with this use of "fold".
> >>
> >>
> >> On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca>
> wrote:
> >>
> >>> I personally with Evan in that I prefer map with getOrElse over fold
> with
> >>> options (but that just my personal preference) :)
> >>>
> >>>
> >>> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >>>
> >>>> I'm not strongly against Option.fold, but I find the readability
> getting
> >>>> worse for the use case you brought up.  For the use case of if/else,=
 I
> >>> find
> >>>> Option.fold pretty confusing because it reverses the order of Some v=
s
> >>> None.
> >>>> Also, when code gets long, the lack of an obvious boundary (the only
> >>>> boundary is "} {") with two closures is pretty confusing.
> >>>>
> >>>>
> >>>> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <
> mark@clearstorydata.com
> >>>>> wrote:
> >>>>
> >>>>> On the contrary, it is the completely natural place for the initial
> >>> value
> >>>>> of the accumulator, and provides the expected result of folding ove=
r
> an
> >>>>> empty collection.
> >>>>>
> >>>>> scala> val l: List[Int] =3D List()
> >>>>>
> >>>>> l: List[Int] =3D List()
> >>>>>
> >>>>>
> >>>>> scala> l.fold(42)(_ + _)
> >>>>>
> >>>>> res0: Int =3D 42
> >>>>>
> >>>>>
> >>>>> scala> val o: Option[Int] =3D None
> >>>>>
> >>>>> o: Option[Int] =3D None
> >>>>>
> >>>>>
> >>>>> scala> o.fold(42)(_ + 1)
> >>>>>
> >>>>> res1: Int =3D 42
> >>>>>
> >>>>>
> >>>>> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
> >>>>>
> >>>>>> +1 for using more functional idioms in general.
> >>>>>>
> >>>>>> That's a pretty clever use of `fold`, but putting the default
> >>> condition
> >>>>>> first there makes it not as intuitive.   What about the following,
> >>>> which
> >>>>>> are more readable?
> >>>>>>
> >>>>>>    option.map { a =3D> someFuncMakesB() }
> >>>>>>              .getOrElse(b)
> >>>>>>
> >>>>>>    option.map { a =3D> someFuncMakesB() }
> >>>>>>              .orElse { a =3D> otherDefaultB() }.get
> >>>>>>
> >>>>>>
> >>>>>> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
> >>>> mark@clearstorydata.com
> >>>>>>> wrote:
> >>>>>>
> >>>>>>> In code added to Spark over the past several months, I'm glad to
> >>> see
> >>>>> more
> >>>>>>> use of `foreach`, `for`, `map` and `flatMap` over `Option` instea=
d
> >>> of
> >>>>>>> pattern matching boilerplate.  There are opportunities to push
> >>>> `Option`
> >>>>>>> idioms even further now that we are using Scala 2.10 in master,
> >>> but I
> >>>>>> want
> >>>>>>> to discuss the issue here a little bit before committing code who=
se
> >>>>> form
> >>>>>>> may be a little unfamiliar to some Spark developers.
> >>>>>>>
> >>>>>>> In particular, I really like the use of `fold` with `Option` to
> >>>> cleanly
> >>>>>> an
> >>>>>>> concisely express the "do something if the Option is None; do
> >>>> something
> >>>>>>> else with the thing contained in the Option if it is Some" code
> >>>>> fragment.
> >>>>>>>
> >>>>>>> An example:
> >>>>>>>
> >>>>>>> Instead of...
> >>>>>>>
> >>>>>>> val driver =3D drivers.find(_.id =3D=3D driverId)
> >>>>>>> driver match {
> >>>>>>>  case Some(d) =3D>
> >>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> >>>>>>>    else {
> >>>>>>>      d.worker.foreach { w =3D>
> >>>>>>>        w.actor ! KillDriver(driverId)
> >>>>>>>      }
> >>>>>>>    }
> >>>>>>>    val msg =3D s"Kill request for $driverId submitted"
> >>>>>>>    logInfo(msg)
> >>>>>>>    sender ! KillDriverResponse(true, msg)
> >>>>>>>  case None =3D>
> >>>>>>>    val msg =3D s"Could not find running driver $driverId"
> >>>>>>>    logWarning(msg)
> >>>>>>>    sender ! KillDriverResponse(false, msg)
> >>>>>>> }
> >>>>>>>
> >>>>>>> ...using fold we end up with...
> >>>>>>>
> >>>>>>> driver.fold
> >>>>>>>  {
> >>>>>>>    val msg =3D s"Could not find running driver $driverId"
> >>>>>>>    logWarning(msg)
> >>>>>>>    sender ! KillDriverResponse(false, msg)
> >>>>>>>  }
> >>>>>>>  { d =3D>
> >>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> >>>>>>>    else {
> >>>>>>>      d.worker.foreach { w =3D>
> >>>>>>>        w.actor ! KillDriver(driverId)
> >>>>>>>      }
> >>>>>>>    }
> >>>>>>>    val msg =3D s"Kill request for $driverId submitted"
> >>>>>>>    logInfo(msg)
> >>>>>>>    sender ! KillDriverResponse(true, msg)
> >>>>>>>  }
> >>>>>>>
> >>>>>>>
> >>>>>>> So the basic pattern (and my proposed formatting standard) for
> >>>> folding
> >>>>>> over
> >>>>>>> an `Option[A]` from which you need to produce a B (which may be
> >>> Unit
> >>>> if
> >>>>>>> you're only interested in side effects) is:
> >>>>>>>
> >>>>>>> anOption.fold
> >>>>>>>  {
> >>>>>>>    // something that evaluates to a B if anOption =3D None
> >>>>>>>  }
> >>>>>>>  { a =3D>
> >>>>>>>    // something that transforms `a` into a B if anOption =3D Some=
(a)
> >>>>>>>  }
> >>>>>>>
> >>>>>>>
> >>>>>>> Any thoughts?  Does anyone really, really hate this style of codi=
ng
> >>>> and
> >>>>>>> oppose its use in Spark?
> >>>>>>>
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> --
> >>>>>> Evan Chan
> >>>>>> Staff Engineer
> >>>>>> ev@ooyala.com  |
> >>>>>>
> >>>>>> <http://www.ooyala.com/>
> >>>>>> <http://www.facebook.com/ooyala><
> >>>> http://www.linkedin.com/company/ooyala
> >>>>>> <
> >>>>>> http://www.twitter.com/ooyala>
> >>>>>>
> >>>>>
> >>>>
> >>>
> >>>
> >>>
> >>> --
> >>> Cell : 425-233-8271
> >>>
>

--089e013c6ee459fe6904ee8049e0--

From dev-return-1014-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 15:03:13 2013
Return-Path: <dev-return-1014-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A47A2104EE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 15:03:13 +0000 (UTC)
Received: (qmail 88028 invoked by uid 500); 27 Dec 2013 15:03:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86803 invoked by uid 500); 27 Dec 2013 15:03:08 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 86688 invoked by uid 99); 27 Dec 2013 15:03:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 15:03:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of imran@quantifind.com designates 209.85.215.43 as permitted sender)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 15:02:59 +0000
Received: by mail-la0-f43.google.com with SMTP id n7so4407977lam.30
        for <dev@spark.incubator.apache.org>; Fri, 27 Dec 2013 07:02:37 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=75j/WmNdyY6B0Xi5hV0ulcoxM0xfk2WHdWkby+6JgGQ=;
        b=McQjNv9HeYPUf7DTpeL1K+xETiA7M7zneeqR4xQM9Pf9TmeuXfZOwbhNpupY0tkZ9d
         O5ta2XiiysQ89KBkSzmQq2naog5Q/lPka/yYBVs1TBdK8MHsZ0HW4QPyw5lKvq5Fguk8
         zqF0uuifCbCRLpijHCrbHT5SBIhOlB0ADxyMF989jugknCxExnx6tCjU96Vsg06barNL
         WbmtfjBryMaoROtDmQgNe8dAsaD7Ivt7UJScP516bZSNaBKuNAW4wQnyNHJnKTNC6e9u
         iiltGWtQ6zTJCDYP2RGuUl/93M2Q+1MymSEhrOZf5l202AvLjgtl7YqzDGq0rqFzGfp+
         RXxQ==
X-Gm-Message-State: ALoCoQnERYnVkXjiX/7hDuTIPzIsAQuTQg/8RJGSyzzodKtxXcm3GQPiE0ernXN5xNJNPcHBlQUy
MIME-Version: 1.0
X-Received: by 10.152.1.197 with SMTP id 5mr21185913lao.0.1388156557194; Fri,
 27 Dec 2013 07:02:37 -0800 (PST)
Received: by 10.112.74.226 with HTTP; Fri, 27 Dec 2013 07:02:37 -0800 (PST)
X-Originating-IP: [98.193.39.168]
In-Reply-To: <CAGh_TuMLPEnXVuZPi5Pwv_5xCQLdkR8fUnCOsKD24AgaTzxC9g@mail.gmail.com>
References: <EB3B9CED-E6EB-4864-B766-92B86C793A51@gmail.com>
	<1388130017101.e357ebea@Nodemailer>
	<CAGh_TuMLPEnXVuZPi5Pwv_5xCQLdkR8fUnCOsKD24AgaTzxC9g@mail.gmail.com>
Date: Fri, 27 Dec 2013 09:02:37 -0600
Message-ID: <CAO24D=QauW5vPm8XuQ=JZ=PoVEpGZKJXbUm-HX8d_SCSmTYDVA@mail.gmail.com>
Subject: Re: Option folding idiom
From: Imran Rashid <imran@quantifind.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=089e0112bfce7c038104ee856235
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0112bfce7c038104ee856235
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable

I'm also against option.fold (though I wouldn't say I "really, really hate
this style of coding"), for the readability reasons already mentioned.

I actually find myself pulling back from some scala-isms after having spent
some time with them, for readability / maintainability.




On Fri, Dec 27, 2013 at 2:57 AM, Christopher Nguyen <ctn@adatao.com> wrote:

> I've learned and unlearned enough things to be careful when claiming
> something is "more intuitive" than another, since it's subject to prior
> knowledge. When I first encountered map().getOrElse() it wasn't any more
> intuitive than this fold()() syntax. Maybe the "OrElse" helps a bit, but
> the "get" in front of it confuses matters again (it sets one up to expect
> two things following, not one). Meanwhile, people coming from
> data-structure-folding background would argue that fold()() is more
> "intuitive".
>
> If the choice is among three alternatives (match, map().getOrElse(), and
> fold()()), and the goal is intuitively obvious syntax to the broadest
> audience, then "match" wins by a reasonably good distance, with the latte=
r
> two about equal. This tie could be broken by the fact that more people by
> now know about getOrElse than fold, crossed with the fact that it probabl=
y
> isn't on the top of the Spark community's agenda to be avant garde on new
> Scala syntax.
>
>
>
> --
> Christopher T. Nguyen
> Co-founder & CEO, Adatao <http://adatao.com>
> linkedin.com/in/ctnguyen
>
>
>
> On Thu, Dec 26, 2013 at 11:40 PM, Nick Pentreath
> <nick.pentreath@gmail.com>wrote:
>
> > +1 for getOrElse
> >
> >
> > When I was new to Scala I tended to use match almost like if/else
> > statements with Option. These days I try to use map/flatMap instead and
> use
> > getOrElse extensively and I for one find it very intuitive.
> >
> >
> >
> >
> > I also agree that the fold syntax seems way less intuitive and I
> certainly
> > prefer readable Scala code to that which might be more "idiomatic" but
> > which I honestly tend to find very inscrutable and hard to grok quickly=
.
> > =97
> > Sent from Mailbox for iPhone
> >
> > On Fri, Dec 27, 2013 at 9:06 AM, Matei Zaharia <matei.zaharia@gmail.com=
>
> > wrote:
> >
> > > I agree about using getOrElse instead. In choosing which code style a=
nd
> > idioms to use, my goal has always been to maximize the ease of *other
> > developers* understanding the code, and most developers today still don=
=92t
> > know Scala. It=92s fine to use a maps or matches, because their meaning=
 is
> > obvious, but fold on Option is not obvious (even foreach is kind of wei=
rd
> > for new people). In this case the benefit is so small that it doesn=92t
> seem
> > worth it.
> > > Note that if you use getOrElse, you can even throw exceptions in the
> > =93else=94 part if you=92d like. (This is because Nothing is a subtype =
of every
> > type in Scala.) So for example you can do val stuff =3D
> > option.getOrElse(throw new Exception(=93It wasn=92t set=94)). It looks =
a little
> > weird, but note how the meaning is obvious even if you don=92t know
> anything
> > about the type system.
> > > Matei
> > > On Dec 27, 2013, at 12:12 AM, Kay Ousterhout <keo@eecs.berkeley.edu>
> > wrote:
> > >> I agree with what Reynold said -- there's not a big benefit in terms
> of
> > >> lines of code (esp. compared to using getOrElse) and I think it hurt=
s
> > code
> > >> readability.  One of the great things about the current Spark codeba=
se
> > is
> > >> that it's very accessible for newcomers -- something that would be
> less
> > >> true with this use of "fold".
> > >>
> > >>
> > >> On Thu, Dec 26, 2013 at 8:11 PM, Holden Karau <holden@pigscanfly.ca>
> > wrote:
> > >>
> > >>> I personally with Evan in that I prefer map with getOrElse over fol=
d
> > with
> > >>> options (but that just my personal preference) :)
> > >>>
> > >>>
> > >>> On Thu, Dec 26, 2013 at 7:58 PM, Reynold Xin <rxin@databricks.com>
> > wrote:
> > >>>
> > >>>> I'm not strongly against Option.fold, but I find the readability
> > getting
> > >>>> worse for the use case you brought up.  For the use case of
> if/else, I
> > >>> find
> > >>>> Option.fold pretty confusing because it reverses the order of Some
> vs
> > >>> None.
> > >>>> Also, when code gets long, the lack of an obvious boundary (the on=
ly
> > >>>> boundary is "} {") with two closures is pretty confusing.
> > >>>>
> > >>>>
> > >>>> On Thu, Dec 26, 2013 at 4:23 PM, Mark Hamstra <
> > mark@clearstorydata.com
> > >>>>> wrote:
> > >>>>
> > >>>>> On the contrary, it is the completely natural place for the initi=
al
> > >>> value
> > >>>>> of the accumulator, and provides the expected result of folding
> over
> > an
> > >>>>> empty collection.
> > >>>>>
> > >>>>> scala> val l: List[Int] =3D List()
> > >>>>>
> > >>>>> l: List[Int] =3D List()
> > >>>>>
> > >>>>>
> > >>>>> scala> l.fold(42)(_ + _)
> > >>>>>
> > >>>>> res0: Int =3D 42
> > >>>>>
> > >>>>>
> > >>>>> scala> val o: Option[Int] =3D None
> > >>>>>
> > >>>>> o: Option[Int] =3D None
> > >>>>>
> > >>>>>
> > >>>>> scala> o.fold(42)(_ + 1)
> > >>>>>
> > >>>>> res1: Int =3D 42
> > >>>>>
> > >>>>>
> > >>>>> On Thu, Dec 26, 2013 at 5:51 PM, Evan Chan <ev@ooyala.com> wrote:
> > >>>>>
> > >>>>>> +1 for using more functional idioms in general.
> > >>>>>>
> > >>>>>> That's a pretty clever use of `fold`, but putting the default
> > >>> condition
> > >>>>>> first there makes it not as intuitive.   What about the followin=
g,
> > >>>> which
> > >>>>>> are more readable?
> > >>>>>>
> > >>>>>>    option.map { a =3D> someFuncMakesB() }
> > >>>>>>              .getOrElse(b)
> > >>>>>>
> > >>>>>>    option.map { a =3D> someFuncMakesB() }
> > >>>>>>              .orElse { a =3D> otherDefaultB() }.get
> > >>>>>>
> > >>>>>>
> > >>>>>> On Thu, Dec 26, 2013 at 12:33 PM, Mark Hamstra <
> > >>>> mark@clearstorydata.com
> > >>>>>>> wrote:
> > >>>>>>
> > >>>>>>> In code added to Spark over the past several months, I'm glad t=
o
> > >>> see
> > >>>>> more
> > >>>>>>> use of `foreach`, `for`, `map` and `flatMap` over `Option`
> instead
> > >>> of
> > >>>>>>> pattern matching boilerplate.  There are opportunities to push
> > >>>> `Option`
> > >>>>>>> idioms even further now that we are using Scala 2.10 in master,
> > >>> but I
> > >>>>>> want
> > >>>>>>> to discuss the issue here a little bit before committing code
> whose
> > >>>>> form
> > >>>>>>> may be a little unfamiliar to some Spark developers.
> > >>>>>>>
> > >>>>>>> In particular, I really like the use of `fold` with `Option` to
> > >>>> cleanly
> > >>>>>> an
> > >>>>>>> concisely express the "do something if the Option is None; do
> > >>>> something
> > >>>>>>> else with the thing contained in the Option if it is Some" code
> > >>>>> fragment.
> > >>>>>>>
> > >>>>>>> An example:
> > >>>>>>>
> > >>>>>>> Instead of...
> > >>>>>>>
> > >>>>>>> val driver =3D drivers.find(_.id =3D=3D driverId)
> > >>>>>>> driver match {
> > >>>>>>>  case Some(d) =3D>
> > >>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> > >>>>>>>    else {
> > >>>>>>>      d.worker.foreach { w =3D>
> > >>>>>>>        w.actor ! KillDriver(driverId)
> > >>>>>>>      }
> > >>>>>>>    }
> > >>>>>>>    val msg =3D s"Kill request for $driverId submitted"
> > >>>>>>>    logInfo(msg)
> > >>>>>>>    sender ! KillDriverResponse(true, msg)
> > >>>>>>>  case None =3D>
> > >>>>>>>    val msg =3D s"Could not find running driver $driverId"
> > >>>>>>>    logWarning(msg)
> > >>>>>>>    sender ! KillDriverResponse(false, msg)
> > >>>>>>> }
> > >>>>>>>
> > >>>>>>> ...using fold we end up with...
> > >>>>>>>
> > >>>>>>> driver.fold
> > >>>>>>>  {
> > >>>>>>>    val msg =3D s"Could not find running driver $driverId"
> > >>>>>>>    logWarning(msg)
> > >>>>>>>    sender ! KillDriverResponse(false, msg)
> > >>>>>>>  }
> > >>>>>>>  { d =3D>
> > >>>>>>>    if (waitingDrivers.contains(d)) { waitingDrivers -=3D d }
> > >>>>>>>    else {
> > >>>>>>>      d.worker.foreach { w =3D>
> > >>>>>>>        w.actor ! KillDriver(driverId)
> > >>>>>>>      }
> > >>>>>>>    }
> > >>>>>>>    val msg =3D s"Kill request for $driverId submitted"
> > >>>>>>>    logInfo(msg)
> > >>>>>>>    sender ! KillDriverResponse(true, msg)
> > >>>>>>>  }
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> So the basic pattern (and my proposed formatting standard) for
> > >>>> folding
> > >>>>>> over
> > >>>>>>> an `Option[A]` from which you need to produce a B (which may be
> > >>> Unit
> > >>>> if
> > >>>>>>> you're only interested in side effects) is:
> > >>>>>>>
> > >>>>>>> anOption.fold
> > >>>>>>>  {
> > >>>>>>>    // something that evaluates to a B if anOption =3D None
> > >>>>>>>  }
> > >>>>>>>  { a =3D>
> > >>>>>>>    // something that transforms `a` into a B if anOption =3D
> Some(a)
> > >>>>>>>  }
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> Any thoughts?  Does anyone really, really hate this style of
> coding
> > >>>> and
> > >>>>>>> oppose its use in Spark?
> > >>>>>>>
> > >>>>>>
> > >>>>>>
> > >>>>>>
> > >>>>>> --
> > >>>>>> --
> > >>>>>> Evan Chan
> > >>>>>> Staff Engineer
> > >>>>>> ev@ooyala.com  |
> > >>>>>>
> > >>>>>> <http://www.ooyala.com/>
> > >>>>>> <http://www.facebook.com/ooyala><
> > >>>> http://www.linkedin.com/company/ooyala
> > >>>>>> <
> > >>>>>> http://www.twitter.com/ooyala>
> > >>>>>>
> > >>>>>
> > >>>>
> > >>>
> > >>>
> > >>>
> > >>> --
> > >>> Cell : 425-233-8271
> > >>>
> >
>

--089e0112bfce7c038104ee856235--

From dev-return-1015-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Fri Dec 27 15:23:44 2013
Return-Path: <dev-return-1015-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 706A310528
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Dec 2013 15:23:44 +0000 (UTC)
Received: (qmail 1086 invoked by uid 500); 27 Dec 2013 15:23:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1044 invoked by uid 500); 27 Dec 2013 15:23:42 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 1036 invoked by uid 99); 27 Dec 2013 15:23:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 15:23:40 +0000
X-ASF-Spam-Status: No, hits=1.6 required=5.0
	tests=FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of andy.petrella@gmail.com designates 209.85.212.170 as permitted sender)
Received: from [209.85.212.170] (HELO mail-wi0-f170.google.com) (209.85.212.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Dec 2013 15:23:34 +0000
Received: by mail-wi0-f170.google.com with SMTP id hq4so13794984wib.3
        for <dev@spark.incubator.apache.org>; Fri, 27 Dec 2013 07:23:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:to:from:subject:date:mime-version:content-type;
        bh=3Fvy0L1zaHwQspfFtlUSjCW1PFn613OZo/1MGrwUFb8=;
        b=Olz2u+kDX4OVIqYnjWO79xUyjWCPnimsnRvHATjRQNl/HkW7ou84sNYjK7pdewvq0+
         MWPYvZaqW67KcIiuGGVkz+1ejIhdnZxsWttwC+Iv9kaIjH2GWsixyuth8Xl+4pzDJZxr
         YI/JrfqPyIcjguIOEV5JVro/lJDCpAbfheGwuLaNNCu6X5VXiqH0y5L1WSMDG9aV8ScI
         eMfLgU6FGRGG0BGcG/pn6wpW7NRbwID/bsvpt3ODreyHbywwfB69stged8xMgx/vgQwp
         MYcql6pI/gE2NzXIppl3hePapiSs9jbiTP7yxR84IRPTtaPWwII8sTWu5l79f1UpS7QW
         QKgg==
X-Received: by 10.180.20.33 with SMTP id k1mr33476722wie.34.1388157793509;
        Fri, 27 Dec 2013 07:23:13 -0800 (PST)
Received: from [109.143.111.196] ([109.143.111.196])
        by mx.google.com with ESMTPSA id m1sm82667250eeg.0.2013.12.27.07.23.11
        for <dev@spark.incubator.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 27 Dec 2013 07:23:12 -0800 (PST)
Message-ID: <52bd9b60.816a0e0a.0cc0.ffff9033@mx.google.com>
To: "=?utf-8?B?ZGV2QHNwYXJrLmluY3ViYXRvci5hcGFjaGUub3Jn?=" <dev@spark.incubator.apache.org>,"=?utf-8?B?ZGV2QHNwYXJrLmluY3ViYXRvci5hcGFjaGUub3Jn?=" <dev@spark.incubator.apache.org>
From: "=?utf-8?B?YW5keS5wZXRyZWxsYUBnbWFpbC5jb20=?=" <andy.petrella@gmail.com>
Subject: =?utf-8?B?UmUgOiBPcHRpb24gZm9sZGluZyBpZGlvbQ==?=
Date: Fri, 27 Dec 2013 16:23:09 +0100
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_Part_1_1388157789059"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_1_1388157789059
Content-Type: text/plain;
	charset=utf-8
Content-Transfer-Encoding: base64
Content-Disposition: inline
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------=_Part_1_1388157789059--


From dev-return-1016-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 28 07:12:01 2013
Return-Path: <dev-return-1016-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A55510F89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Dec 2013 07:12:01 +0000 (UTC)
Received: (qmail 50671 invoked by uid 500); 28 Dec 2013 07:12:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50482 invoked by uid 500); 28 Dec 2013 07:11:55 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50472 invoked by uid 99); 28 Dec 2013 07:11:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 07:11:53 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ev@ooyala.com designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 07:11:48 +0000
Received: by mail-lb0-f180.google.com with SMTP id x18so4680081lbi.11
        for <dev@spark.incubator.apache.org>; Fri, 27 Dec 2013 23:11:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=ooyala.com; s=google;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=jcigpSnBxDNKx61bi+Kx1AfNzyWEanghkOPsz69nB84=;
        b=UVN6goMHsYIXdN4HU4OUcnpIY0Dm9sXgFLpTEvJWVaDUufFykyNli16oJbpQKHmtxw
         XTy4gaPq2osFue4jHdMfYDmLcWK9bbX9LTrlz+IOqOltlqUIIeDEoupJgzNAIyOnh6OT
         0dEqdDDkc2QgRn0e3nwChUq9clpmzJ4WP/rvg=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=jcigpSnBxDNKx61bi+Kx1AfNzyWEanghkOPsz69nB84=;
        b=P+ME8pAUYJZHDti+LyPXAj0fMOOqd7nGM8kkqF1ckK19JOnjrBfKUk3F3z3/v7xdJE
         HOZu00j/0qQgxRCvb2hCDjebsk6Gii1FXF14WnuCagBVFVkoDJYdSbIIs/xP1a5KS7qp
         6ttq2l356TkE441npOsXMO/Hw/h0C5aQEkwOmxoeosr2OUpB55/lzuUQr6avVVAiBjGa
         sZmeA473vAR7UshJTUNzdpG4OOzC/cZCe+90Wh1m0Pr2TJgrlLpiEeGEGfa5RHm5EUWO
         8a+dLswApPzkDz2F3dLDj/LmjkZqidanF5ZiPAhqKpAQSruyrtUHySGYWPpx49VxghgD
         ywHA==
X-Gm-Message-State: ALoCoQlxWhuFAOgIN+R7l/vUSGlG09byEjAM2GhoWdIuLLXz7kyjMfDKV8H8H7k+5cWBxkZSkWSi
MIME-Version: 1.0
X-Received: by 10.112.88.226 with SMTP id bj2mr4746126lbb.66.1388214677090;
 Fri, 27 Dec 2013 23:11:17 -0800 (PST)
Received: by 10.112.30.37 with HTTP; Fri, 27 Dec 2013 23:11:17 -0800 (PST)
Date: Fri, 27 Dec 2013 23:11:17 -0800
Message-ID: <CADWPM3jzuYciQgiPNTViHQF+EGLa-xGdjnEsUbKD807kCMwwag@mail.gmail.com>
Subject: scala-graph
From: Evan Chan <ev@ooyala.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

http://www.scala-graph.org/

Have you guys seen the above site?  I wonder if this will ever be
merged into the Scala standard library, but might be interesting to
see if this fits into GraphX at all, or to add a Spark backend to it.

-- 
--
Evan Chan
Staff Engineer
ev@ooyala.com  |

From dev-return-1017-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 28 17:01:29 2013
Return-Path: <dev-return-1017-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DFA011074E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Dec 2013 17:01:28 +0000 (UTC)
Received: (qmail 31536 invoked by uid 500); 28 Dec 2013 17:01:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31144 invoked by uid 500); 28 Dec 2013 17:01:24 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 31135 invoked by uid 99); 28 Dec 2013 17:01:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 17:01:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 17:01:17 +0000
Received: by mail-la0-f51.google.com with SMTP id ec20so4863985lab.10
        for <dev@spark.incubator.apache.org>; Sat, 28 Dec 2013 09:00:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=Reg/48/nvxWoUo0tJv21cxY84Ar5KvFRe/3jsE8cwyw=;
        b=nSA2SSpOUjglJerdyDNhYUTjyVgLSX6DSxVnjsva5Y2EwVeBZx0BSKel6QWlwmKI2m
         q+U/mq6W5evq1HIFqmW9cBSAPpmgd4PbSHtxYvEWg0nKnn/0BVJxQrTCOmr3gmWiMXaz
         Rj38hp34jWFzVShaPvl61RjKszVdL1qXfi9+hi6XvNdHfq2qshMqgQpITEUvbF3MAlGh
         3hhS5F01wyn0wvQORFroSqJveXzHXl/3hcpQBadWOH+iAZNxED/6kDIPVhjY91E7Bgvq
         k6iktMzzi0Aopxt9e5Q6uZdtHf0MBCextPrkEPLHAHVqOQ+BkKfDImwJfVSbzMYQHkSQ
         6K+g==
MIME-Version: 1.0
X-Received: by 10.112.189.134 with SMTP id gi6mr22134604lbc.6.1388250055708;
 Sat, 28 Dec 2013 09:00:55 -0800 (PST)
Received: by 10.112.138.234 with HTTP; Sat, 28 Dec 2013 09:00:55 -0800 (PST)
Date: Sat, 28 Dec 2013 09:00:55 -0800
Message-ID: <CALte62y-5bXFQtSNTs+n0VA3Bcj8YGE10977=eaTgrU2aqoHJw@mail.gmail.com>
Subject: test suite results in OOME
From: Ted Yu <yuzhihong@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c36ad26e187a04ee9b272e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c36ad26e187a04ee9b272e
Content-Type: text/plain; charset=ISO-8859-1

Hi,
I used the following setting to run test suite:
export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=812M
-XX:ReservedCodeCacheSize=512m"

I got:

[ERROR] [12/28/2013 08:34:03.747]
[sparkWorker1-akka.actor.default-dispatcher-14] [ActorSystem(sparkWorker1)]
Uncaught fatal error from thread
[sparkWorker1-akka.actor.default-dispatcher-14] shutting down ActorSystem
[sparkWorker1]
java.lang.OutOfMemoryError: PermGen space

How do I run test suite on Mac ?

Thanks

--001a11c36ad26e187a04ee9b272e--

From dev-return-1018-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sat Dec 28 23:13:56 2013
Return-Path: <dev-return-1018-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7209C10E2E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Dec 2013 23:13:56 +0000 (UTC)
Received: (qmail 95351 invoked by uid 500); 28 Dec 2013 23:13:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95313 invoked by uid 500); 28 Dec 2013 23:13:55 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 95305 invoked by uid 99); 28 Dec 2013 23:13:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 23:13:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.216.181] (HELO mail-qc0-f181.google.com) (209.85.216.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Dec 2013 23:13:50 +0000
Received: by mail-qc0-f181.google.com with SMTP id e9so9582158qcy.40
        for <dev@spark.incubator.apache.org>; Sat, 28 Dec 2013 15:13:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=UTC73VaiiKjzmYPJA/4DrhA8Ic1LZs3LvAUTjHCCaHo=;
        b=H0mW9bQ1WGdcMt+dmPv5VW7Iqh05mFl+PytHSb9RkekiKKJ3NFF2XZ/w2CsdG4MM83
         3u/g0V5+g8pF9SanaXWo4fRgwU7jTZ7CLHngPeBhNMaVcTfZCqNLRi38V7dYOxSZWP1d
         q7jts9pAEDyrGWdEqwj7Ez7tWO7RXVERSezgwjosU+M7mbCqKg2D0DqLC0fFygk1O/ps
         hrsZPHojLXfSA0dAHJB/9bJ1Jsmz0Dnv1XkON228sGDRyzLeeNGgrmMxJw6SOhiVh8q7
         fi9gqol0VkueLI4L5VxHvbzakWqIC9wE89//9O0BZWVs0dA8VksD5RfETNkWOlK3qzLJ
         0/7g==
X-Gm-Message-State: ALoCoQlzvO5UJdWBMe6Acm6cnM7gzcmm7heG7z9xma8AkIxfuCBSfl8mxqDXnjC+/QNCHEN5Y+kX
MIME-Version: 1.0
X-Received: by 10.49.2.170 with SMTP id 10mr95794389qev.24.1388272409048; Sat,
 28 Dec 2013 15:13:29 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Sat, 28 Dec 2013 15:13:28 -0800 (PST)
In-Reply-To: <CALte62y-5bXFQtSNTs+n0VA3Bcj8YGE10977=eaTgrU2aqoHJw@mail.gmail.com>
References: <CALte62y-5bXFQtSNTs+n0VA3Bcj8YGE10977=eaTgrU2aqoHJw@mail.gmail.com>
Date: Sat, 28 Dec 2013 13:13:28 -1000
Message-ID: <CAPh_B=bj+14fr7kURHB9GPWT1-k+5pfTyK50jiXyLgWFWOReGg@mail.gmail.com>
Subject: Re: test suite results in OOME
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b6da3d4cb283b04eea05bee
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6da3d4cb283b04eea05bee
Content-Type: text/plain; charset=ISO-8859-1

I usually use sbt. i.e. sbt/sbt test




On Sat, Dec 28, 2013 at 7:00 AM, Ted Yu <yuzhihong@gmail.com> wrote:

> Hi,
> I used the following setting to run test suite:
> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=812M
> -XX:ReservedCodeCacheSize=512m"
>
> I got:
>
> [ERROR] [12/28/2013 08:34:03.747]
> [sparkWorker1-akka.actor.default-dispatcher-14] [ActorSystem(sparkWorker1)]
> Uncaught fatal error from thread
> [sparkWorker1-akka.actor.default-dispatcher-14] shutting down ActorSystem
> [sparkWorker1]
> java.lang.OutOfMemoryError: PermGen space
>
> How do I run test suite on Mac ?
>
> Thanks
>

--047d7b6da3d4cb283b04eea05bee--

From dev-return-1019-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 29 00:04:35 2013
Return-Path: <dev-return-1019-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 09AD310F6C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 29 Dec 2013 00:04:35 +0000 (UTC)
Received: (qmail 50974 invoked by uid 500); 29 Dec 2013 00:04:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50942 invoked by uid 500); 29 Dec 2013 00:04:34 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 50934 invoked by uid 99); 29 Dec 2013 00:04:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 29 Dec 2013 00:04:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 29 Dec 2013 00:04:30 +0000
Received: by mail-lb0-f180.google.com with SMTP id x18so4776119lbi.25
        for <dev@spark.incubator.apache.org>; Sat, 28 Dec 2013 16:04:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=ZASTs94Nbks/p8asgKiU9O2zBrHToFY38LQRbo+pu5g=;
        b=QekRIHyqIJJ6VnGO6IFv2j0hGWNU6CVosFc23asPHFuAqr/Ljw6OZHWiFkUgJW0Inh
         DtAqiZk0VTRFJhht2Z6pK68QBHVsygO5ka4Zvu12zbcAihSKXrcZx909NHuJZPxN/v0F
         9X675tOVk2LeCQ0l9O6c5suEgz6I49t+CiXVZkvNJoCuxTD77v5M4eQw0oG2vqVyAi8T
         vbyo/MU0gkcCnTG+5WXdgvMU+XpV4mN5pudUK18nRYE0DBpLOltUdAqOw26ZE0B1dCDz
         mkCtt58ceZnua62XLN6uglgKHRkHgQt5G3xG3VVJ6HE/YpnGlnuOO/+Yfqyd6/t98ICy
         HnlQ==
MIME-Version: 1.0
X-Received: by 10.112.167.228 with SMTP id zr4mr6557088lbb.56.1388275448842;
 Sat, 28 Dec 2013 16:04:08 -0800 (PST)
Received: by 10.112.138.234 with HTTP; Sat, 28 Dec 2013 16:04:08 -0800 (PST)
In-Reply-To: <CAPh_B=bj+14fr7kURHB9GPWT1-k+5pfTyK50jiXyLgWFWOReGg@mail.gmail.com>
References: <CALte62y-5bXFQtSNTs+n0VA3Bcj8YGE10977=eaTgrU2aqoHJw@mail.gmail.com>
	<CAPh_B=bj+14fr7kURHB9GPWT1-k+5pfTyK50jiXyLgWFWOReGg@mail.gmail.com>
Date: Sat, 28 Dec 2013 16:04:08 -0800
Message-ID: <CALte62y1KF2yZpM=rr+Sut7rqUsVj-LQvsgX0TAa5C+CuxoWSw@mail.gmail.com>
Subject: Re: test suite results in OOME
From: Ted Yu <yuzhihong@gmail.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2432afa90b404eea110aa
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2432afa90b404eea110aa
Content-Type: text/plain; charset=ISO-8859-1

Build Tools slide from Matei's slides, transition toward maven only is
happening.

That was why I used mvn.

BTW I specified the following on the commandline:
-Dtest=TaskResultGetterSuite

Many other test suites were run.

How can I run one suite ?

Thanks


On Sat, Dec 28, 2013 at 3:13 PM, Reynold Xin <rxin@databricks.com> wrote:

> I usually use sbt. i.e. sbt/sbt test
>
>
>
>
> On Sat, Dec 28, 2013 at 7:00 AM, Ted Yu <yuzhihong@gmail.com> wrote:
>
> > Hi,
> > I used the following setting to run test suite:
> > export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=812M
> > -XX:ReservedCodeCacheSize=512m"
> >
> > I got:
> >
> > [ERROR] [12/28/2013 08:34:03.747]
> > [sparkWorker1-akka.actor.default-dispatcher-14]
> [ActorSystem(sparkWorker1)]
> > Uncaught fatal error from thread
> > [sparkWorker1-akka.actor.default-dispatcher-14] shutting down ActorSystem
> > [sparkWorker1]
> > java.lang.OutOfMemoryError: PermGen space
> >
> > How do I run test suite on Mac ?
> >
> > Thanks
> >
>

--001a11c2432afa90b404eea110aa--

From dev-return-1020-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Sun Dec 29 07:18:31 2013
Return-Path: <dev-return-1020-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 82D55100B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 29 Dec 2013 07:18:31 +0000 (UTC)
Received: (qmail 9386 invoked by uid 500); 29 Dec 2013 06:14:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9351 invoked by uid 500); 29 Dec 2013 06:14:11 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Delivered-To: moderator for dev@spark.incubator.apache.org
Received: (qmail 9139 invoked by uid 99); 29 Dec 2013 06:12:41 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hlin05tu@gmail.com designates 209.85.215.49 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:date:message-id:subject:from:to:content-type;
        bh=nZaVHhwaQ6bXXX/mIRI6onuWbPnAicYkMxNZzLd/ias=;
        b=qfFqPVij3s7QwWcHU7AkNQoaloC6GVT7rZQPps9URmklpxBtLMixlIRtyJTtqv2Ip0
         e9gJF2mg/L916f3yAyg+y+Pebmlq3BfUbVTig2XnCXjtwkpq2crfChjP9E9jljbEepWa
         rtAy2v0oinSs4F3M1a1YHNBJ1t/5CJ020p24b/naUJh3whOXT26S+77sHPLfpCm7ucUL
         tqAgzdov0GuytBcWbNstHROAs/9ZBxUWGshJMadmJNF0TXkaX9rktqjRD105BL6q6+ii
         zVQeJxxVubHVXDh2gakoxsBB47lWPaJ03SPFRHYrz7eLFYlSpP1VULfCX5Are4emNxF8
         CBNQ==
MIME-Version: 1.0
X-Received: by 10.112.53.201 with SMTP id d9mr21108023lbp.26.1388297533132;
 Sat, 28 Dec 2013 22:12:13 -0800 (PST)
Sender: hlin05tu@gmail.com
Date: Sun, 29 Dec 2013 01:12:13 -0500
X-Google-Sender-Auth: 0A1tX6g3SbVI6SMhU80I_Q8C03o
Message-ID: <CAKOYTn8YGw0AaSOjH1dr3nbQSamdUqdNBk6Fc2yFwhR50adobA@mail.gmail.com>
Subject: Systematically performance diagnose
From: Hao Lin <hlin09pu@gmail.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a11c3f1724e140604eea635af
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f1724e140604eea635af
Content-Type: text/plain; charset=ISO-8859-1

Hi folks,

I am trying to test the performance on a couple of my Spark applications.
For benchmarking purpose, I am wondering if there is a good performance
analysis practice. The best way I can think of is to instrument log prints
and analyze the timestamps in logs on each node.

The major metrics I am interested in are computation ratios (computation
time, data transferring time, basically a timeline of detailed events),
memory usage, disk throughput. Could I have some suggestions on how Spark
is benchmarked.

Thanks,

Max

--001a11c3f1724e140604eea635af--

From dev-return-1021-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 31 05:38:40 2013
Return-Path: <dev-return-1021-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB5651022D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 31 Dec 2013 05:38:40 +0000 (UTC)
Received: (qmail 3591 invoked by uid 500); 31 Dec 2013 05:38:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3203 invoked by uid 500); 31 Dec 2013 05:38:31 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 3190 invoked by uid 99); 31 Dec 2013 05:38:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 05:38:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.128.50] (HELO mail-qe0-f50.google.com) (209.85.128.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 05:38:23 +0000
Received: by mail-qe0-f50.google.com with SMTP id 1so12100563qec.37
        for <dev@spark.incubator.apache.org>; Mon, 30 Dec 2013 21:38:02 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=nmzyaIU2mzjWCeiGcQKGr8Ih2MyWNROev3Oyz3BW3RM=;
        b=Vp/BQRWE/91xh4jEcSQQDjJQdoo64Xc6DBEIi/aF5SVcofm0eU9ZI1AYzbn4RYqipN
         MP0Yxmnq/nclt33TKdVkZBre97XEq7z4zn7Moj75MwQK6eW8p6+mRzWJ6IH6jpxGKRlr
         RcpZZPBQkCPADKFcjlaMSQiYUox8KmANd0cibNfNhixJm6ujkjybnFhM+cDB1XaJJSQI
         kKa7vwtXEqg70IV8VRiiPGhvkOPHwNxzi5h4N0xIh5NSa6uX2Swuc9IDAgy+CH6cnIiO
         FEPbqoT7K75ae/lS8vxegUCsqKctyvylld1dFWz7eJwzATR2uhgW6EONdBkOkPv6JtG5
         HyqQ==
X-Gm-Message-State: ALoCoQmSmQb5zDtc5LnCBzci+dNoI8rqoQibWGcQZJ/7aRjRmz0D0NfQY060eRu2jF/GcIyz2DAb
MIME-Version: 1.0
X-Received: by 10.49.24.140 with SMTP id u12mr66370729qef.78.1388468282164;
 Mon, 30 Dec 2013 21:38:02 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Mon, 30 Dec 2013 21:38:02 -0800 (PST)
In-Reply-To: <CALte62y1KF2yZpM=rr+Sut7rqUsVj-LQvsgX0TAa5C+CuxoWSw@mail.gmail.com>
References: <CALte62y-5bXFQtSNTs+n0VA3Bcj8YGE10977=eaTgrU2aqoHJw@mail.gmail.com>
	<CAPh_B=bj+14fr7kURHB9GPWT1-k+5pfTyK50jiXyLgWFWOReGg@mail.gmail.com>
	<CALte62y1KF2yZpM=rr+Sut7rqUsVj-LQvsgX0TAa5C+CuxoWSw@mail.gmail.com>
Date: Mon, 30 Dec 2013 19:38:02 -1000
Message-ID: <CAPh_B=YALtz++r_-P4AqgRo+MKBxxhqup47kEftTFRqwOefiKw@mail.gmail.com>
Subject: Re: test suite results in OOME
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=047d7b6d87cebdb5ec04eecdf6ca
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6d87cebdb5ec04eecdf6ca
Content-Type: text/plain; charset=ISO-8859-1

Again, I usually use sbt ...

sbt/sbt "test-only *TaskResultGetterSuite*"


On Sat, Dec 28, 2013 at 2:04 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Build Tools slide from Matei's slides, transition toward maven only is
> happening.
>
> That was why I used mvn.
>
> BTW I specified the following on the commandline:
> -Dtest=TaskResultGetterSuite
>
> Many other test suites were run.
>
> How can I run one suite ?
>
> Thanks
>
>
> On Sat, Dec 28, 2013 at 3:13 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > I usually use sbt. i.e. sbt/sbt test
> >
> >
> >
> >
> > On Sat, Dec 28, 2013 at 7:00 AM, Ted Yu <yuzhihong@gmail.com> wrote:
> >
> > > Hi,
> > > I used the following setting to run test suite:
> > > export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=812M
> > > -XX:ReservedCodeCacheSize=512m"
> > >
> > > I got:
> > >
> > > [ERROR] [12/28/2013 08:34:03.747]
> > > [sparkWorker1-akka.actor.default-dispatcher-14]
> > [ActorSystem(sparkWorker1)]
> > > Uncaught fatal error from thread
> > > [sparkWorker1-akka.actor.default-dispatcher-14] shutting down
> ActorSystem
> > > [sparkWorker1]
> > > java.lang.OutOfMemoryError: PermGen space
> > >
> > > How do I run test suite on Mac ?
> > >
> > > Thanks
> > >
> >
>

--047d7b6d87cebdb5ec04eecdf6ca--

From dev-return-1022-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 31 05:40:56 2013
Return-Path: <dev-return-1022-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A15F1023C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 31 Dec 2013 05:40:56 +0000 (UTC)
Received: (qmail 5435 invoked by uid 500); 31 Dec 2013 05:40:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5400 invoked by uid 500); 31 Dec 2013 05:40:45 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 5380 invoked by uid 99); 31 Dec 2013 05:40:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 05:40:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.216.50] (HELO mail-qa0-f50.google.com) (209.85.216.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 05:40:39 +0000
Received: by mail-qa0-f50.google.com with SMTP id i13so11488567qae.9
        for <dev@spark.incubator.apache.org>; Mon, 30 Dec 2013 21:40:18 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=Df44o/RsBqLLyGRIidPueUSvMM9+3wepHtmxBfhWPOo=;
        b=cIdYcc7zgXHHeGJsU7kXFToMPTZ9aULBebVu+smOlNxbwYxtpu5vkSj+P1238i5y31
         qRdVIyqlXdVmkcYsNWiiYBdmwk4LNB0HdWBsKnoIqW2el6PXHKQfvggykfPGqXryABp9
         QhvZRmLpU2+N00z7yMPjQC3V1BGuY7yo/xGOH0DGokWw9cGSb2bBxSapW38m/5tQ24UM
         fJ81PWoBqf9bKZ53Mfq726PLNhjdwMFVzlbIcwz67626peu9Zrri1A6AZIS5dFjmXZ5E
         9UcBEfRGq8STgusJp018LlI4RUj3WMXnRq5EqcfzSvvrZpiwmaI3pt8kn//yf3a+3uQD
         aWbQ==
X-Gm-Message-State: ALoCoQmxcBSb4sYhrWTHRHBszlwP0kYihy3lwNTBJ1vL6qiwLJmF1wtkIW2eaxGfZjnBFwcs5ZxW
MIME-Version: 1.0
X-Received: by 10.229.105.9 with SMTP id r9mr114062480qco.12.1388468418377;
 Mon, 30 Dec 2013 21:40:18 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Mon, 30 Dec 2013 21:40:18 -0800 (PST)
In-Reply-To: <CAKOYTn8YGw0AaSOjH1dr3nbQSamdUqdNBk6Fc2yFwhR50adobA@mail.gmail.com>
References: <CAKOYTn8YGw0AaSOjH1dr3nbQSamdUqdNBk6Fc2yFwhR50adobA@mail.gmail.com>
Date: Mon, 30 Dec 2013 19:40:18 -1000
Message-ID: <CAPh_B=Y8PrbBYqSWtJ-Q67v9jEGFuCGzwMmW4JvW-A6GuRxg3Q@mail.gmail.com>
Subject: Re: Systematically performance diagnose
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=001a113382b4dbfda404eecdfedf
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113382b4dbfda404eecdfedf
Content-Type: text/plain; charset=ISO-8859-1

The application web ui is pretty useful. We have been adding more and more
information to the web ui for easier performance analysis.

Look at Patrick Wendell's two talks at the Spark Summit for more
information: http://spark-summit.org/summit-2013/


On Sat, Dec 28, 2013 at 8:12 PM, Hao Lin <hlin09pu@gmail.com> wrote:

> Hi folks,
>
> I am trying to test the performance on a couple of my Spark applications.
> For benchmarking purpose, I am wondering if there is a good performance
> analysis practice. The best way I can think of is to instrument log prints
> and analyze the timestamps in logs on each node.
>
> The major metrics I am interested in are computation ratios (computation
> time, data transferring time, basically a timeline of detailed events),
> memory usage, disk throughput. Could I have some suggestions on how Spark
> is benchmarked.
>
> Thanks,
>
> Max
>

--001a113382b4dbfda404eecdfedf--

From dev-return-1023-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org  Tue Dec 31 22:32:23 2013
Return-Path: <dev-return-1023-apmail-spark-dev-archive=spark.apache.org@spark.incubator.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 094C710641
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 31 Dec 2013 22:32:23 +0000 (UTC)
Received: (qmail 19865 invoked by uid 500); 31 Dec 2013 22:32:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19830 invoked by uid 500); 31 Dec 2013 22:32:22 -0000
Mailing-List: contact dev-help@spark.incubator.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.incubator.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.incubator.apache.org>
List-Post: <mailto:dev@spark.incubator.apache.org>
List-Id: <dev.spark.incubator.apache.org>
Reply-To: dev@spark.incubator.apache.org
Delivered-To: mailing list dev@spark.incubator.apache.org
Received: (qmail 19819 invoked by uid 99); 31 Dec 2013 22:32:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 22:32:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy includes SPF record at spf.trusted-forwarder.org)
Received: from [209.85.216.50] (HELO mail-qa0-f50.google.com) (209.85.216.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 31 Dec 2013 22:32:16 +0000
Received: by mail-qa0-f50.google.com with SMTP id i13so12152502qae.9
        for <dev@spark.incubator.apache.org>; Tue, 31 Dec 2013 14:31:55 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=AI0tdfIxZiSdEFFTZqHyE4rdEpxlaV6W3x+IpL01Rmk=;
        b=ZZJK1mG11Sat4FVpysW8vvhm27OLAm7HJWk+DvK8OrWYtC1BnN0BiCDUuIoHFV6pns
         AEVx4OMs2azsKV8R95TkGB63R4bwD8l99vKTjQmuTroUEzEDwS8BgWybovzwiRZWmSXr
         ap21PnWvYpuBktAThBQdtuOFouOtIBVhO3KyKwwWeX1w5OjlZ42owqA0jUPWV5ZJKCxH
         PcdkApbIdeuSYDBf/XAroD57WaZMBJ4i7DkrSGl4NKGIoaBFw3DeBus4OXWUKpAV3Yue
         6ZLoz5aRUXKWR8r06Yap7ZsZ1jbq0WqdyIgpixO50Noa/ZR+P2kMn65UbuxxXtJQEXxV
         FBKw==
X-Gm-Message-State: ALoCoQm3wOYJ/k3iAkKeEegdbkLIyBh17/4d0Vb51p9ItXlIsp9I+nCWj0bqCzn2+Tiq96Dj2Quv
MIME-Version: 1.0
X-Received: by 10.224.79.206 with SMTP id q14mr23451405qak.86.1388529114999;
 Tue, 31 Dec 2013 14:31:54 -0800 (PST)
Received: by 10.96.180.130 with HTTP; Tue, 31 Dec 2013 14:31:54 -0800 (PST)
In-Reply-To: <37941387977708@webcorp1h.yandex-team.ru>
References: <37941387977708@webcorp1h.yandex-team.ru>
Date: Tue, 31 Dec 2013 14:31:54 -0800
Message-ID: <CAPh_B=ZqRGwpqFc1cN2Vc1gkiC8xxOSjEyTWLbWmrW66Y--n+A@mail.gmail.com>
Subject: Re: Spark graduate project ideas
From: Reynold Xin <rxin@databricks.com>
To: dev@spark.incubator.apache.org
Cc: Philipp Sinitsyn <phill@yandex-team.ru>, Ivan Puzyrevskiy <sandello@yandex-team.ru>
Content-Type: multipart/alternative; boundary=047d7bf166daa9019004eedc2043
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf166daa9019004eedc2043
Content-Type: text/plain; charset=KOI8-R
Content-Transfer-Encoding: quoted-printable

There is a recent discussion on academic projects on Spark.

Take a look at the replies to that email (unfortunately you have to dig
through the archive to find the replies):
http://mail-archives.apache.org/mod_mbox/spark-dev/201312.mbox/%3CCAHH8_ON-=
2y69fBfVtt6pngWtEPOZdsmvt4hZ=3DdOE-DZSK6k3sA@mail.gmail.com%3E



On Wed, Dec 25, 2013 at 5:21 AM, =E6=A3=C4=CF=D2 =EB=CF=D2=CF=D4=CB=C9=CA <=
prime@yandex-team.ru>wrote:

> Hi,
>
> Currently I'm pursuing a masters degree in CS and I'm in search of my yea=
r
> project theme (in distributed systems field), and Spark seems very
> interesting to me.
>
> Can you suggest some problems or ideas to work on?
>
> By the way, what is the status of external sorting(
> https://spark-project.atlassian.net/browse/SPARK-983)?
>

--047d7bf166daa9019004eedc2043--


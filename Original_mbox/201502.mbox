From dev-return-11374-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 03:37:37 2015
Return-Path: <dev-return-11374-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6024317DF0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 03:37:37 +0000 (UTC)
Received: (qmail 25403 invoked by uid 500); 1 Feb 2015 03:37:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25328 invoked by uid 500); 1 Feb 2015 03:37:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25315 invoked by uid 99); 1 Feb 2015 03:37:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 03:37:36 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.216.41 as permitted sender)
Received: from [209.85.216.41] (HELO mail-qa0-f41.google.com) (209.85.216.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 03:37:31 +0000
Received: by mail-qa0-f41.google.com with SMTP id bm13so25189923qab.0
        for <dev@spark.apache.org>; Sat, 31 Jan 2015 19:36:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=6p72bKl3DS2Afl+2PgKP9M2ySsHBgCJh3sk0LEbGdBI=;
        b=PaoW0N1LCOJDrkNBWsnCYMj1kft15EUCD72ZEbqf0yZ1rjzSoHfip5AiU/eEX/8MyC
         UTHYxsaQalqDXXAf/ITJhDxPRyTUSOnnuK/pwEAaC37XT3aZCsC8mOKetmZl9CaD5uAj
         tmvqL7ufmF2sPpeVZQWs6Htdq1mofP7/WlBKWrHXWG9pfzUx9wov9GA+wqW/WXxUt7xb
         dU9NR++nteUMx7T7TZ42sS6b7hBmaDR+tsI8iFohfaSDuOQxDuk6qLNQPD0qecOmnspN
         iINfz2I3QV4N7+1JgHPPS4IBJMskO9etNdIK1Rt5WYYXheqaoVbp8gZQkp8Xn9I4kcCG
         3OtA==
X-Received: by 10.140.97.7 with SMTP id l7mr23998884qge.66.1422761786137;
        Sat, 31 Jan 2015 19:36:26 -0800 (PST)
Received: from [192.168.6.40] (ip-64-134-100-247.public.wayport.net. [64.134.100.247])
        by mx.google.com with ESMTPSA id a6sm14528189qgf.13.2015.01.31.19.36.25
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 31 Jan 2015 19:36:25 -0800 (PST)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC2)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <1422734234030-10370.post@n3.nabble.com>
Date: Sat, 31 Jan 2015 19:36:25 -0800
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <8B1DF58E-2FCA-425E-A8D9-9318BD6F5D66@gmail.com>
References: <CABPQxsuvbeCK53qqggYfK0PsuhnmNgprHKf3v7ZT85eKOcKVBg@mail.gmail.com> <1422734234030-10370.post@n3.nabble.com>
To: MartinWeindel <martin.weindel@gmail.com>
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

This looks like a pretty serious problem, thanks! Glad people are =
testing on Windows.

Matei

> On Jan 31, 2015, at 11:57 AM, MartinWeindel <martin.weindel@gmail.com> =
wrote:
>=20
> FYI: Spark 1.2.1rc2 does not work on Windows!
>=20
> On creating a Spark context you get following log output on my Windows
> machine:
> INFO  org.apache.spark.SparkEnv:59 - Registering BlockManagerMaster
> ERROR org.apache.spark.util.Utils:75 - Failed to create local root dir =
in
> C:\Users\mweindel\AppData\Local\Temp\. Ignoring this directory.
> ERROR org.apache.spark.storage.DiskBlockManager:75 - Failed to create =
any
> local dir.
>=20
> I have already located the cause. A newly added function chmod700() in
> org.apache.util.Utils uses functionality which only works on a Unix =
file
> system.
>=20
> See also pull request [https://github.com/apache/spark/pull/4299] for =
my
> suggestion how to resolve the issue.
>=20
> Best regards,
>=20
> Martin Weindel
>=20
>=20
>=20
> --
> View this message in context: =
http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apa=
che-Spark-1-2-1-RC2-tp10317p10370.html
> Sent from the Apache Spark Developers List mailing list archive at =
Nabble.com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11375-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 04:03:05 2015
Return-Path: <dev-return-11375-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 507B617E21
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 04:03:05 +0000 (UTC)
Received: (qmail 33777 invoked by uid 500); 1 Feb 2015 04:03:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33685 invoked by uid 500); 1 Feb 2015 04:03:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33673 invoked by uid 99); 1 Feb 2015 04:03:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:03:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of daniel.yafeng.guo@gmail.com designates 209.85.192.67 as permitted sender)
Received: from [209.85.192.67] (HELO mail-qg0-f67.google.com) (209.85.192.67)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:02:57 +0000
Received: by mail-qg0-f67.google.com with SMTP id i50so15001255qgf.2
        for <dev@spark.apache.org>; Sat, 31 Jan 2015 20:01:06 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=auz4BIDzx2klmlymL+mCudS4pCusdKYy0Nn0KriJgsI=;
        b=xpEVcg6aeMlH5sP1rHMRTiofXchW3bm8dbc23cL5/69VuH3DjgXoPR37xyiCiooYP2
         esucCWVwhe7/0AqKidtoz4t9hWfWdqssjOi1TYNg3RJHE9fshxohPUoAr7Iv8QqaiHIf
         GSXtNKDuW16gORZn9DNRIO2pJ+w3GO1q6Pz9m/GoL8JjK7OQrfk0FhYr5cpIvCsP9J5T
         xg+GMDUX0Atvyto78+9DLzRM00U5ypvLrnTWm+xLkX25g49D2Ui3QIXLI/DLyXlTPpcq
         p2Rgj5damjzU9048kL1WizUvZh/wDaybBtM2RmqK7erG07nezgo5YyRrQ/xp318IrAF7
         RaIA==
MIME-Version: 1.0
X-Received: by 10.140.16.50 with SMTP id 47mr27504279qga.105.1422763266677;
 Sat, 31 Jan 2015 20:01:06 -0800 (PST)
Received: by 10.140.222.210 with HTTP; Sat, 31 Jan 2015 20:01:06 -0800 (PST)
Date: Sat, 31 Jan 2015 23:01:06 -0500
Message-ID: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
Subject: Intellij IDEA 14 env setup; NoClassDefFoundError when run examples
From: Yafeng Guo <daniel.yafeng.guo@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c1005a1c2176050dfee3a9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1005a1c2176050dfee3a9
Content-Type: text/plain; charset=UTF-8

Hi,

I'm setting up a dev environment with Intellij IDEA 14. I selected profile
scala-2.10, maven-3, hadoop 2.4, hive, hive 0.13.1. The compilation passed.
But when I try to run LogQuery in examples, I met below issue:

Connected to the target VM, address: '127.0.0.1:37182', transport: 'socket'
Exception in thread "main" java.lang.NoClassDefFoundError:
org/apache/spark/SparkConf
at org.apache.spark.examples.LogQuery$.main(LogQuery.scala:46)
at org.apache.spark.examples.LogQuery.main(LogQuery.scala)
Caused by: java.lang.ClassNotFoundException: org.apache.spark.SparkConf
at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
... 2 more
Disconnected from the target VM, address: '127.0.0.1:37182', transport:
'socket'

anyone met similar issue before? Thanks a lot

Regards,
Ya-Feng

--001a11c1005a1c2176050dfee3a9--

From dev-return-11376-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 04:20:46 2015
Return-Path: <dev-return-11376-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B53E317E45
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 04:20:46 +0000 (UTC)
Received: (qmail 44390 invoked by uid 500); 1 Feb 2015 04:20:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44317 invoked by uid 500); 1 Feb 2015 04:20:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44305 invoked by uid 99); 1 Feb 2015 04:20:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:20:45 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.173 as permitted sender)
Received: from [209.85.213.173] (HELO mail-ig0-f173.google.com) (209.85.213.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:20:41 +0000
Received: by mail-ig0-f173.google.com with SMTP id a13so11568606igq.0
        for <dev@spark.apache.org>; Sat, 31 Jan 2015 20:19:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=waXn7oWbBFKgQhhRhjE+QgF/qD72+5Hhsqf3Vt9qMZ0=;
        b=OtI/7YRrZexRP0D2IDlEx0yGWg/EQkSHO2cKb7HrYaMa7DVcoVsFMzMCFDXFECNY5m
         PwY7bFKt7FIgCmY9S2p1S6pYgGCkpVp7ipRncaa1g6xSGddJBWJF3ma7O9t5z3VlY39U
         yhg/S9riPUopnWUX6QV0+XHsi0g+1mkaMTYVQj5tp2maFimFFvtFZ7gh+vhDH8wRIjTl
         nuzQEwQF4V8ZURfwxiY797LkXePKIfoPXtMizdnKQlc2/Y1rQYv4dULKcKuMPJLzx6Pz
         fvu5ULYYhXo86St95xq7SunLkcXbhuGN8fceA3pUn2Eg7J45tPMnCtbCPVmY7B+3Pj5C
         r7Qw==
X-Received: by 10.43.14.197 with SMTP id pr5mr13702768icb.0.1422764376301;
 Sat, 31 Jan 2015 20:19:36 -0800 (PST)
MIME-Version: 1.0
References: <CABPQxsuvbeCK53qqggYfK0PsuhnmNgprHKf3v7ZT85eKOcKVBg@mail.gmail.com>
 <1422734234030-10370.post@n3.nabble.com> <8B1DF58E-2FCA-425E-A8D9-9318BD6F5D66@gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 01 Feb 2015 04:19:35 +0000
Message-ID: <CAOhmDzf_7=MgzdYaWjNfun=0_B0gzp9oz9pe5bSxWFJAqbNKtg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC2)
To: Matei Zaharia <matei.zaharia@gmail.com>, MartinWeindel <martin.weindel@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=bcaec50e61b13fa565050dff25af
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec50e61b13fa565050dff25af
Content-Type: text/plain; charset=UTF-8

Do we have any open JIRA issues to add automated testing on Windows to
Jenkins? I assume that's something we want to do.

On Sat Jan 31 2015 at 10:37:42 PM Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> This looks like a pretty serious problem, thanks! Glad people are testing
> on Windows.
>
> Matei
>
> > On Jan 31, 2015, at 11:57 AM, MartinWeindel <martin.weindel@gmail.com>
> wrote:
> >
> > FYI: Spark 1.2.1rc2 does not work on Windows!
> >
> > On creating a Spark context you get following log output on my Windows
> > machine:
> > INFO  org.apache.spark.SparkEnv:59 - Registering BlockManagerMaster
> > ERROR org.apache.spark.util.Utils:75 - Failed to create local root dir in
> > C:\Users\mweindel\AppData\Local\Temp\. Ignoring this directory.
> > ERROR org.apache.spark.storage.DiskBlockManager:75 - Failed to create
> any
> > local dir.
> >
> > I have already located the cause. A newly added function chmod700() in
> > org.apache.util.Utils uses functionality which only works on a Unix file
> > system.
> >
> > See also pull request [https://github.com/apache/spark/pull/4299] for my
> > suggestion how to resolve the issue.
> >
> > Best regards,
> >
> > Martin Weindel
> >
> >
> >
> > --
> > View this message in context: http://apache-spark-
> developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-2-1-RC2-
> tp10317p10370.html
> > Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--bcaec50e61b13fa565050dff25af--

From dev-return-11377-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 04:43:35 2015
Return-Path: <dev-return-11377-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 321C217E72
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 04:43:35 +0000 (UTC)
Received: (qmail 57486 invoked by uid 500); 1 Feb 2015 04:43:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57245 invoked by uid 500); 1 Feb 2015 04:43:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57209 invoked by uid 99); 1 Feb 2015 04:43:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:43:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.160.178 as permitted sender)
Received: from [209.85.160.178] (HELO mail-yk0-f178.google.com) (209.85.160.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 04:43:28 +0000
Received: by mail-yk0-f178.google.com with SMTP id q200so19788028ykb.9
        for <dev@spark.apache.org>; Sat, 31 Jan 2015 20:43:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ggwQVJkj/Txg1TKg6dVnjU/FcFrlAWry0abICquAuxM=;
        b=KwjA/A8ywsTeshYG2A3QaZpK5BIoV0SEbFDvQgZdLKM6L3r3El97aeIq3MzBUAxn/p
         Bz2eu26xDdfNf8lLzkRlAAp6dl5INAvV9YBJyqy9Ec6yrpqd0uJaIv7AEudvsEnYNbLo
         pdpkEC+VH/CyWRhhW+ktI97E7LXIXKBfRz6DtqKISYox/G2UNDb7bpeWZITwISvVzLEF
         Od1yWAE0K2OAsYiagEXARJMBrHIhZseROnGp0IaezRSvH9HedzAWIxbRc3LfiSeqT28A
         RNQOwhfWFgWcbosEbIKIhrh0Uu4/6Zn411fw4D0vSzdif5TdYHBaupapOSI5V0xAMmHg
         G4iQ==
MIME-Version: 1.0
X-Received: by 10.236.206.8 with SMTP id k8mr5959486yho.23.1422765788066; Sat,
 31 Jan 2015 20:43:08 -0800 (PST)
Received: by 10.170.139.9 with HTTP; Sat, 31 Jan 2015 20:43:07 -0800 (PST)
In-Reply-To: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
References: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
Date: Sat, 31 Jan 2015 20:43:07 -0800
Message-ID: <CALte62znMnex93UOTVZ8z_Osk-w3nLrETaw_dCUZPGoHuD3U8A@mail.gmail.com>
Subject: Re: Intellij IDEA 14 env setup; NoClassDefFoundError when run examples
From: Ted Yu <yuzhihong@gmail.com>
To: Yafeng Guo <daniel.yafeng.guo@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011616a865957d050dff7979
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011616a865957d050dff7979
Content-Type: text/plain; charset=UTF-8

Have you read / followed this ?

https://cwiki.apache.org/confluence/display/SPARK
/Useful+Developer+Tools#UsefulDeveloperTools-BuildingSparkinIntelliJIDEA

Cheers

On Sat, Jan 31, 2015 at 8:01 PM, Yafeng Guo <daniel.yafeng.guo@gmail.com>
wrote:

> Hi,
>
> I'm setting up a dev environment with Intellij IDEA 14. I selected profile
> scala-2.10, maven-3, hadoop 2.4, hive, hive 0.13.1. The compilation passed.
> But when I try to run LogQuery in examples, I met below issue:
>
> Connected to the target VM, address: '127.0.0.1:37182', transport:
> 'socket'
> Exception in thread "main" java.lang.NoClassDefFoundError:
> org/apache/spark/SparkConf
> at org.apache.spark.examples.LogQuery$.main(LogQuery.scala:46)
> at org.apache.spark.examples.LogQuery.main(LogQuery.scala)
> Caused by: java.lang.ClassNotFoundException: org.apache.spark.SparkConf
> at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
> at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
> ... 2 more
> Disconnected from the target VM, address: '127.0.0.1:37182', transport:
> 'socket'
>
> anyone met similar issue before? Thanks a lot
>
> Regards,
> Ya-Feng
>

--089e011616a865957d050dff7979--

From dev-return-11378-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 08:31:43 2015
Return-Path: <dev-return-11378-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35C6710122
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 08:31:43 +0000 (UTC)
Received: (qmail 89614 invoked by uid 500); 1 Feb 2015 08:31:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89540 invoked by uid 500); 1 Feb 2015 08:31:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89528 invoked by uid 99); 1 Feb 2015 08:31:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 08:31:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of velvia.github@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 08:31:38 +0000
Received: by mail-wg0-f44.google.com with SMTP id z12so33707298wgg.3
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 00:31:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=g0HqViQcXPwarS2JmgVFbat4VxQv5C3bL0xZQkfTTPE=;
        b=GJlWAfVccqCntJgzbJSFxkViFA6cK1hWXD5IV8KcnGfViXAFluinMSPQxOmKufyEBf
         QzAobVveUjjGW+c8XGatUPC0mFbCSLb3jV6/vXuLw35gmsjbsoFGLjbDYDvewkEbujw9
         IEtLMRPH+YOfYU40Ty1UrjRxFjmmGuq4rq2ntCyhIas2Ngj8cfbDNUa2QnP4fYQXu1bk
         ElQ7NP/txxOIers5ooTe51hJM7r+lJUbPVvGGaDzf0qW+Q8zbGmPMXjDYDi/N4AApJg+
         9QbIplXAy09g4Oex+WgqgSp3ShHIZHtNS5GuNwlAcnXKkBfIIrIVCPWgdqZwV1nsm+60
         McHQ==
MIME-Version: 1.0
X-Received: by 10.180.160.166 with SMTP id xl6mr12486804wib.16.1422779477548;
 Sun, 01 Feb 2015 00:31:17 -0800 (PST)
Received: by 10.217.38.20 with HTTP; Sun, 1 Feb 2015 00:31:17 -0800 (PST)
In-Reply-To: <54CAAD2D.8030407@gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
	<CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
	<CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
	<CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
	<CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
	<D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com>
	<CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
	<CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
	<CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
	<CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
	<CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
	<CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
	<CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
	<CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
	<54CAAD2D.8030407@gmail.com>
Date: Sun, 1 Feb 2015 00:31:17 -0800
Message-ID: <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
From: Evan Chan <velvia.github@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Koert Kuipers <koert@tresata.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

It is true that you can persist SchemaRdds / DataFrames to disk via
Parquet, but a lot of time and inefficiencies is lost.   The in-memory
columnar cached representation is completely different from the
Parquet file format, and I believe there has to be a translation into
a Row (because ultimately Spark SQL traverses Row's -- even the
InMemoryColumnarTableScan has to then convert the columns into Rows
for row-based processing).   On the other hand, traditional data
frames process in a columnar fashion.   Columnar storage is good, but
nowhere near as good as columnar processing.

Another issue, which I don't know if it is solved yet, but it is
difficult for Tachyon to efficiently cache Parquet files without
understanding the file format itself.

I gave a talk at last year's Spark Summit on this topic.

I'm working on efforts to change this, however.  Shoot me an email at
velvia at gmail if you're interested in joining forces.

On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> Yes, when a DataFrame is cached in memory, it's stored in an efficient
> columnar format. And you can also easily persist it on disk using Parquet,
> which is also columnar.
>
> Cheng
>
>
> On 1/29/15 1:24 PM, Koert Kuipers wrote:
>>
>> to me the word DataFrame does come with certain expectations. one of them
>> is that the data is stored columnar. in R data.frame internally uses a
>> list
>> of sequences i think, but since lists can have labels its more like a
>> SortedMap[String, Array[_]]. this makes certain operations very cheap
>> (such
>> as adding a column).
>>
>> in Spark the closest thing would be a data structure where per Partition
>> the data is also stored columnar. does spark SQL already use something
>> like
>> that? Evan mentioned "Spark SQL columnar compression", which sounds like
>> it. where can i find that?
>>
>> thanks
>>
>> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan <velvia.github@gmail.com>
>> wrote:
>>
>>> +1.... having proper NA support is much cleaner than using null, at
>>> least the Java null.
>>>
>>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks <evan.sparks@gmail.com>
>>> wrote:
>>>>
>>>> You've got to be a little bit careful here. "NA" in systems like R or
>>>
>>> pandas
>>>>
>>>> may have special meaning that is distinct from "null".
>>>>
>>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
>>>>
>>>>
>>>>
>>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin <rxin@databricks.com>
>>>
>>> wrote:
>>>>>
>>>>> Isn't that just "null" in SQL?
>>>>>
>>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan <velvia.github@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> I believe that most DataFrame implementations out there, like Pandas,
>>>>>> supports the idea of missing values / NA, and some support the idea of
>>>>>> Not Meaningful as well.
>>>>>>
>>>>>> Does Row support anything like that?  That is important for certain
>>>>>> applications.  I thought that Row worked by being a mutable object,
>>>>>> but haven't looked into the details in a while.
>>>>>>
>>>>>> -Evan
>>>>>>
>>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin <rxin@databricks.com>
>>>>>> wrote:
>>>>>>>
>>>>>>> It shouldn't change the data source api at all because data sources
>>>>>>
>>>>>> create
>>>>>>>
>>>>>>> RDD[Row], and that gets converted into a DataFrame automatically
>>>>>>
>>>>>> (previously
>>>>>>>
>>>>>>> to SchemaRDD).
>>>>>>>
>>>>>>>
>>>>>>
>>>
>>> https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala
>>>>>>>
>>>>>>> One thing that will break the data source API in 1.3 is the location
>>>>>>> of
>>>>>>> types. Types were previously defined in sql.catalyst.types, and now
>>>>>>
>>>>>> moved to
>>>>>>>
>>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and all
>>>>>>> public
>>>>>>
>>>>>> APIs
>>>>>>>
>>>>>>> have first class classes/objects defined in sql directly.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <velvia.github@gmail.com
>>>>>>
>>>>>> wrote:
>>>>>>>>
>>>>>>>> Hey guys,
>>>>>>>>
>>>>>>>> How does this impact the data sources API?  I was planning on using
>>>>>>>> this for a project.
>>>>>>>>
>>>>>>>> +1 that many things from spark-sql / DataFrame is universally
>>>>>>>> desirable and useful.
>>>>>>>>
>>>>>>>> By the way, one thing that prevents the columnar compression stuff
>>>
>>> in
>>>>>>>>
>>>>>>>> Spark SQL from being more useful is, at least from previous talks
>>>>>>>> with
>>>>>>>> Reynold and Michael et al., that the format was not designed for
>>>>>>>> persistence.
>>>>>>>>
>>>>>>>> I have a new project that aims to change that.  It is a
>>>>>>>> zero-serialisation, high performance binary vector library,
>>>
>>> designed
>>>>>>>>
>>>>>>>> from the outset to be a persistent storage friendly.  May be one
>>>
>>> day
>>>>>>>>
>>>>>>>> it can replace the Spark SQL columnar compression.
>>>>>>>>
>>>>>>>> Michael told me this would be a lot of work, and recreates parts of
>>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
>>>
>>> details.
>>>>>>>>
>>>>>>>> -Evan
>>>>>>>>
>>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin <rxin@databricks.com>
>>>>>>
>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> Alright I have merged the patch (
>>>>>>>>> https://github.com/apache/spark/pull/4173
>>>>>>>>> ) since I don't see any strong opinions against it (as a matter
>>>
>>> of
>>>>>>
>>>>>> fact
>>>>>>>>>
>>>>>>>>> most were for it). We can still change it if somebody lays out a
>>>>>>
>>>>>> strong
>>>>>>>>>
>>>>>>>>> argument.
>>>>>>>>>
>>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
>>>>>>>>> <matei.zaharia@gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>>> The type alias means your methods can specify either type and
>>>
>>> they
>>>>>>
>>>>>> will
>>>>>>>>>>
>>>>>>>>>> work. It's just another name for the same type. But Scaladocs
>>>
>>> and
>>>>>>
>>>>>> such
>>>>>>>>>>
>>>>>>>>>> will
>>>>>>>>>> show DataFrame as the type.
>>>>>>>>>>
>>>>>>>>>> Matei
>>>>>>>>>>
>>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
>>>>>>>>>>
>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>>>>>>>>>>>
>>>>>>>>>>> Reynold,
>>>>>>>>>>> But with type alias we will have the same problem, right?
>>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will have
>>>>>>>>>>> to
>>>>>>>>>>> change
>>>>>>>>>>> our code to migrade from schema to dataframe. Unless we have
>>>
>>> an
>>>>>>>>>>>
>>>>>>>>>>> implicit
>>>>>>>>>>> conversion between DataFrame and SchemaRDD
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin <rxin@databricks.com>:
>>>>>>>>>>>
>>>>>>>>>>>> Dirceu,
>>>>>>>>>>>>
>>>>>>>>>>>> That is not possible because one cannot overload return
>>>
>>> types.
>>>>>>>>>>>>
>>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
>>>
>>> return
>>>>>>
>>>>>> some
>>>>>>>>>>
>>>>>>>>>> type,
>>>>>>>>>>>>
>>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
>>>>>>>>>>>>
>>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
>>>>>>>>>>>> SchemaRDD
>>>>>>>>>>>> to
>>>>>>>>>>
>>>>>>>>>> not
>>>>>>>>>>>>
>>>>>>>>>>>> break source compatibility for Scala.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
>>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and be
>>>>>>
>>>>>> removed
>>>>>>>>>>>>>
>>>>>>>>>>>>> in
>>>>>>>>>>
>>>>>>>>>> the
>>>>>>>>>>>>>
>>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been added
>>>>>>>>>>>>> to
>>>>>>>>>>
>>>>>>>>>> DataFrame?
>>>>>>>>>>>>>
>>>>>>>>>>>>> With this, we don't impact in existing code for the next few
>>>>>>>>>>>>> releases.
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
>>>>>>>>>>>>> <kushal.datta@gmail.com>:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> I want to address the issue that Matei raised about the
>>>
>>> heavy
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> lifting
>>>>>>>>>>>>>> required for a full SQL support. It is amazing that even
>>>>>>>>>>>>>> after
>>>>>>
>>>>>> 30
>>>>>>>>>>
>>>>>>>>>> years
>>>>>>>>>>>>>
>>>>>>>>>>>>> of
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> research there is not a single good open source columnar
>>>>>>
>>>>>> database
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> like
>>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but it is
>>>>>>>>>>>>>> not
>>>>>>>>>>>>>> nearly
>>>>>>>>>>>>>
>>>>>>>>>>>>> as
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
>>>
>>> need
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> for
>>>>>>>>>>>>>> such
>>>>>>>>>>
>>>>>>>>>> a
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> system. I wonder why so and it's high time to change that.
>>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
>>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
>>>>>>>>>>
>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though I
>>>
>>> like
>>>>>>
>>>>>> the
>>>>>>>>>>>>>
>>>>>>>>>>>>> former
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> slightly better because it's more descriptive.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under the
>>>>>>
>>>>>> covers,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> it
>>>>>>>>>>>>>
>>>>>>>>>>>>> would
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> be more clear from a user-facing perspective to at least
>>>>>>
>>>>>> choose a
>>>>>>>>>>>>>
>>>>>>>>>>>>> package
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> name for it that omits "sql".
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark Schema
>>>>>>
>>>>>> module
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Spark
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large a
>>>>>>>>>>>>>>> change
>>>>>>
>>>>>> at
>>>>>>>>>>
>>>>>>>>>> this
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> point?
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> -Sandy
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
>>>>>>>>>>>>>
>>>>>>>>>>>>> matei.zaharia@gmail.com>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of giving
>>>>>>>>>>>>>>>> it
>>>>>>>>>>>>>>>> another
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> name,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL since
>>>>>>>>>>>>>>>> that
>>>>>>>>>>>>>>>> was
>>>>>>>>>>>>>
>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> most
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> obvious use case to many users.)
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Matei
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
>>>>>>>>>>>>>
>>>>>>>>>>>>> matei.zaharia@gmail.com>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> While it might be possible to move this concept to Spark
>>>>>>>>>>>>>>>>> Core
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> long-term,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> supporting structured data efficiently does require
>>>
>>> quite a
>>>>>>
>>>>>> bit
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> of
>>>>>>>>>>>>>
>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning and
>>>>>>
>>>>>> columnar
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> storage.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a SQL
>>>>>>>>>>>>>>>> server
>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>
>>>>>>>>>>>>> it's
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> meant to be a library for manipulating structured data.
>>>>>>>>>>>>>>>> Since
>>>>>>>>>>>>>>>> this
>>>>>>>>>>>>>
>>>>>>>>>>>>> is
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> possible to build over the core API, it's pretty natural
>>>
>>> to
>>>>>>>>>>>>>
>>>>>>>>>>>>> organize it
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Matei
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
>>>>>>
>>>>>> koert@tresata.com>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
>>>
>>> data
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> format
>>>>>>>>>>>>>
>>>>>>>>>>>>> used
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
>>>
>>> used
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>
>>>>>>>>>>>>> various
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API."
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in spark
>>>>>>>>>>>>>>>>>> core,
>>>>>>
>>>>>> not
>>>>>>>>>>>>>
>>>>>>>>>>>>> sql
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
>>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it yet,
>>>>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>> Jan.
>>>>>>>>>>>>>
>>>>>>>>>>>>> 13
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Bay
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Area
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of background
>>>>>>>>>>>>>
>>>>>>>>>>>>> information
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> on
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> this
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=YWppYPWznSQ
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> ________________________________
>>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
>>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
>>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
>>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
>>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
>>>
>>> there
>>>>>>
>>>>>> will
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> be
>>>>>>>>>>>>>
>>>>>>>>>>>>> a
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> 1:1
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
>>>>>>
>>>>>> DataFrame.
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
>>>>>>>>>>>>>
>>>>>>>>>>>>> rxin@databricks.com>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Hi,
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD -> DataFrame in
>>>>>>>>>>>>>>>>>>>> 1.3,
>>>>>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> wanted
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> to
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> get the community's opinion.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a common
>>>
>>> data
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> format
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> used
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
>>>>>>>>>>>>>>>>>>>> used
>>>>>>
>>>>>> for
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> various
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API.
>>>
>>> We
>>>>>>
>>>>>> also
>>>>>>>>>>>>>
>>>>>>>>>>>>> expect
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> more
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> more users to be programming directly against
>>>
>>> SchemaRDD
>>>>>>
>>>>>> API
>>>>>>>>>>>>>
>>>>>>>>>>>>> rather
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> than
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less commonly
>>>
>>> used
>>>>>>
>>>>>> DSL
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> originally
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
>>>>>>>>>>>>>>>>>>>> data-frame
>>>>>>>>>>>>>>>>>>>> like
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> API.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> In
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
>>>
>>> usable
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>> end
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> users.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
>>>
>>> than
>>>>>>>>>>>>>
>>>>>>>>>>>>> SchemaRDD.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to be an
>>>>>>>>>>>>>>>>>>>> RDD
>>>>>>>>>>>>>
>>>>>>>>>>>>> anymore
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> (even
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like map,
>>>>>>>>>>>>>>>>>>>> flatMap,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> etc),
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
>>>
>>> highly
>>>>>>>>>>>>>
>>>>>>>>>>>>> confusing.
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Instead.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for all
>>>>>>>>>>>>>>>>>>>> RDD
>>>>>>>>>>>>>
>>>>>>>>>>>>> methods.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
>>>>>>>>>>>>>>>>>>>> directly
>>>>>>>>>>>>>
>>>>>>>>>>>>> against
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
>>>
>>> well
>>>>>>>>>>>>>
>>>>>>>>>>>>> documented.
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> However,
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can create a
>>>>>>>>>>>>>>>>>>>> type
>>>>>>>>>>>>>>>>>>>> alias
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> DataFrame
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
>>>>>>>>>>>>>>>>>>>> source
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> compatibility
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all existing
>>>>>>>>>>>>>
>>>>>>>>>>>>> materials to
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> use
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>>>
>>> dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>>>
>>> dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>
>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>> ---------------------------------------------------------------------
>>>>>>>>>>
>>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>
>>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11379-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 10:47:03 2015
Return-Path: <dev-return-11379-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 237C9102D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 10:47:03 +0000 (UTC)
Received: (qmail 73619 invoked by uid 500); 1 Feb 2015 10:47:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73543 invoked by uid 500); 1 Feb 2015 10:47:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73532 invoked by uid 99); 1 Feb 2015 10:47:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 10:47:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 10:46:36 +0000
Received: by mail-wg0-f52.google.com with SMTP id y19so33907329wgg.11
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 02:45:05 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ulujC+HHHmh1MuUbjCgokycXeGemuMsvFeTEJxCkEPI=;
        b=HNEupIJuU1nv4VytSxQVkFbPbJYFM0prOqGJkAiKgxCMhyjx6SYtG1khoyxSJ3wFAJ
         j7K5DMnN4qRG/QmLxv6omHkgWsyx4aqLcYNvZDiQOZ7FOZu3h0UBxeMgmLTIwu3/2mdj
         soCsjUUWmMZ4upXO8OZh2saZP2aryXfv7hMiq53WYGn+DxVg9tm5SDygnXuapeQNE+uP
         MFG8iB9J1/M8eZFpT6yW7NcKY9k2SggDTGF4bVnYKCiDWp92+WV1H/Bg7hDQQ6Y+T2pD
         yu9YJfHeOnWaCGx/3SJhOKPC11r3EMP3yDGqD4cpaghLGmjPfzbpzKNprJ+9z34ttHfQ
         +iig==
X-Gm-Message-State: ALoCoQk9ZEsOlxyLYcRYaS4NJbbHMxUjXXiuZmd/kyEt5L9lpbbZMmrpruLqkIfKvroI2njdniiM
X-Received: by 10.194.6.228 with SMTP id e4mr32251502wja.63.1422787504846;
 Sun, 01 Feb 2015 02:45:04 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Sun, 1 Feb 2015 02:44:44 -0800 (PST)
In-Reply-To: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
References: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Sun, 1 Feb 2015 10:44:44 +0000
Message-ID: <CAMAsSdLFUw=AHxPpteqxgyELD+8HrPunz_9v+JqjH3BBJcmYpA@mail.gmail.com>
Subject: Re: Intellij IDEA 14 env setup; NoClassDefFoundError when run examples
To: Yafeng Guo <daniel.yafeng.guo@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

How do you mean you run LogQuery? you would run these using the
run-example script rather than in IntelliJ.

On Sun, Feb 1, 2015 at 4:01 AM, Yafeng Guo <daniel.yafeng.guo@gmail.com> wrote:
> Hi,
>
> I'm setting up a dev environment with Intellij IDEA 14. I selected profile
> scala-2.10, maven-3, hadoop 2.4, hive, hive 0.13.1. The compilation passed.
> But when I try to run LogQuery in examples, I met below issue:
>
> Connected to the target VM, address: '127.0.0.1:37182', transport: 'socket'
> Exception in thread "main" java.lang.NoClassDefFoundError:
> org/apache/spark/SparkConf
> at org.apache.spark.examples.LogQuery$.main(LogQuery.scala:46)
> at org.apache.spark.examples.LogQuery.main(LogQuery.scala)
> Caused by: java.lang.ClassNotFoundException: org.apache.spark.SparkConf
> at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
> at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
> at java.security.AccessController.doPrivileged(Native Method)
> at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
> at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
> at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
> ... 2 more
> Disconnected from the target VM, address: '127.0.0.1:37182', transport:
> 'socket'
>
> anyone met similar issue before? Thanks a lot
>
> Regards,
> Ya-Feng

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11380-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 11:04:30 2015
Return-Path: <dev-return-11380-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 65BCA10308
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 11:04:30 +0000 (UTC)
Received: (qmail 80500 invoked by uid 500); 1 Feb 2015 11:04:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80423 invoked by uid 500); 1 Feb 2015 11:04:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80412 invoked by uid 99); 1 Feb 2015 11:04:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 11:04:29 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of michael.belldavies@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 11:04:03 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 171061276462
	for <dev@spark.apache.org>; Sun,  1 Feb 2015 03:03:34 -0800 (PST)
Date: Sun, 1 Feb 2015 04:03:31 -0700 (MST)
From: Mick Davies <michael.belldavies@gmail.com>
To: dev@spark.apache.org
Message-ID: <1422788611928-10377.post@n3.nabble.com>
Subject: Caching tables at column level
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I have been working a lot recently with denormalised tables with lots of
columns, nearly 600. We are using this form to avoid joins. 

I have tried to use cache table with this data, but it proves too expensive
as it seems to try to cache all the data in the table.

For data sets such as the one I am using you find that certain columns will
be hot, referenced frequently in queries, others will be used very
infrequently.

Therefore it would be great if caches could be column based. I realise that
this may not be optimal for all use cases, but I think it could be quite a
common need.  Has something like this been considered?

Thanks Mick



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Caching-tables-at-column-level-tp10377.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11381-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 11:53:26 2015
Return-Path: <dev-return-11381-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6178010469
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 11:53:26 +0000 (UTC)
Received: (qmail 11751 invoked by uid 500); 1 Feb 2015 11:53:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11677 invoked by uid 500); 1 Feb 2015 11:53:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11666 invoked by uid 99); 1 Feb 2015 11:53:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 11:53:25 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of ogeagla@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 11:53:20 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 90EE61276D61
	for <dev@spark.apache.org>; Sun,  1 Feb 2015 03:53:02 -0800 (PST)
Date: Sun, 1 Feb 2015 04:53:00 -0700 (MST)
From: Octavian Geagla <ogeagla@gmail.com>
To: dev@spark.apache.org
Message-ID: <1422791580417-10378.post@n3.nabble.com>
In-Reply-To: <1422564038193-10355.post@n3.nabble.com>
References: <1422116785722-10265.post@n3.nabble.com> <CAJgQjQ_zr+xqKCmM0kySqaRnGU18DhUvz-Raqc99919-7Mqn5A@mail.gmail.com> <CABjXkq6GOQKq9e4-XELKM0VZbJEAfrFFqqFSZUevyaHGvfz17A@mail.gmail.com> <1422564038193-10355.post@n3.nabble.com>
Subject: Re: Any interest in 'weighting' VectorTransformer which does
 component-wise scaling?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I've added support for sparse vectors and created HadamardTF for the
pipeline, please take a look  on my branch
<https://github.com/ogeagla/spark/compare/spark-mllib-weighting>  .

Thanks!



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Any-interest-in-weighting-VectorTransformer-which-does-component-wise-scaling-tp10265p10378.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11382-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 13:31:22 2015
Return-Path: <dev-return-11382-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 866BB10594
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 13:31:22 +0000 (UTC)
Received: (qmail 76945 invoked by uid 500); 1 Feb 2015 13:31:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76868 invoked by uid 500); 1 Feb 2015 13:31:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76856 invoked by uid 99); 1 Feb 2015 13:31:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 13:31:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of daniel.yafeng.guo@gmail.com designates 209.85.192.46 as permitted sender)
Received: from [209.85.192.46] (HELO mail-qg0-f46.google.com) (209.85.192.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 13:31:17 +0000
Received: by mail-qg0-f46.google.com with SMTP id i50so44076991qgf.5
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 05:29:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ifNv69OI2M134nKbMUf1wiuf05m1wQIfVDvOGK5crMg=;
        b=EAv+8j5sl9mrwlLTT2hxNUu1n+qTgTUK4RjdzVpDmzD/r0xkrp2tPhhGLgPH70ijEi
         txw8kk2iDrMw8DEQOGvRYZJZPg/6KTb7ZiTrYVm57sq+kBkTNRaV2dlcqOHl3xKZ3hhg
         C1a68xKagmOofvyU9EtcG/CBUkFl2PXW652dtJs8c1ZTvUPmr9e+WN5CK4B37Bef7aN5
         sLKg8ovWTI2WqBZ1dUsFaoD1Na1YdplJyBmJqQdMBuFNiVmIF0lebfvQiEUnd6nVFH/p
         MIWVwdogQvMYv17dDLDw/5s8OVksXg86rKOcRpdfXhYqoJW/zHJx7lwBdit7Svazoaby
         MkpQ==
MIME-Version: 1.0
X-Received: by 10.224.98.143 with SMTP id q15mr31008985qan.29.1422797366506;
 Sun, 01 Feb 2015 05:29:26 -0800 (PST)
Received: by 10.140.222.210 with HTTP; Sun, 1 Feb 2015 05:29:26 -0800 (PST)
In-Reply-To: <CAMAsSdLFUw=AHxPpteqxgyELD+8HrPunz_9v+JqjH3BBJcmYpA@mail.gmail.com>
References: <CAMYLQvg50BkXX7=v_EjX2QFcbT6tZAjuLrcJM=1GqUXvC4UWTA@mail.gmail.com>
	<CAMAsSdLFUw=AHxPpteqxgyELD+8HrPunz_9v+JqjH3BBJcmYpA@mail.gmail.com>
Date: Sun, 1 Feb 2015 21:29:26 +0800
Message-ID: <CAMYLQvg_Md3DjRMfS7vTH2=ER60O8jXm080U=YhQPXR8M3zGeg@mail.gmail.com>
Subject: Re: Intellij IDEA 14 env setup; NoClassDefFoundError when run examples
From: Yafeng Guo <daniel.yafeng.guo@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0153727a9e3908050e06d3f3
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0153727a9e3908050e06d3f3
Content-Type: text/plain; charset=UTF-8

Finally it works.

@Sean, I'm trying to setup env in IDE so I can track into to Spark -- that
will help me understand Spark internal mechanism.

@Ted, thanks. I'm using Maven, not SBT, but thanks for the suggestion
anyway.

For others who might interested in:

I choose "bigtop-dist" profile so under "Spark-Assembly" maven will build a
fat jar file, which include all artifacts built. Then I added such fat jar
as a dependency of examples module, set it as "runtime".

Then I find I can debug and track code step by step.

This is maybe not a formal way but at least works for me.

Regards,
Ya-Feng

On Sun, Feb 1, 2015 at 6:44 PM, Sean Owen <sowen@cloudera.com> wrote:

> How do you mean you run LogQuery? you would run these using the
> run-example script rather than in IntelliJ.
>
> On Sun, Feb 1, 2015 at 4:01 AM, Yafeng Guo <daniel.yafeng.guo@gmail.com>
> wrote:
> > Hi,
> >
> > I'm setting up a dev environment with Intellij IDEA 14. I selected
> profile
> > scala-2.10, maven-3, hadoop 2.4, hive, hive 0.13.1. The compilation
> passed.
> > But when I try to run LogQuery in examples, I met below issue:
> >
> > Connected to the target VM, address: '127.0.0.1:37182', transport:
> 'socket'
> > Exception in thread "main" java.lang.NoClassDefFoundError:
> > org/apache/spark/SparkConf
> > at org.apache.spark.examples.LogQuery$.main(LogQuery.scala:46)
> > at org.apache.spark.examples.LogQuery.main(LogQuery.scala)
> > Caused by: java.lang.ClassNotFoundException: org.apache.spark.SparkConf
> > at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
> > at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
> > at java.security.AccessController.doPrivileged(Native Method)
> > at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
> > at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
> > at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
> > at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
> > ... 2 more
> > Disconnected from the target VM, address: '127.0.0.1:37182', transport:
> > 'socket'
> >
> > anyone met similar issue before? Thanks a lot
> >
> > Regards,
> > Ya-Feng
>

--089e0153727a9e3908050e06d3f3--

From dev-return-11383-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 15:32:49 2015
Return-Path: <dev-return-11383-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 337B610788
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 15:32:49 +0000 (UTC)
Received: (qmail 68126 invoked by uid 500); 1 Feb 2015 15:32:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68059 invoked by uid 500); 1 Feb 2015 15:32:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68043 invoked by uid 99); 1 Feb 2015 15:32:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 15:32:42 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [157.193.49.126] (HELO smtp2.ugent.be) (157.193.49.126)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 15:32:17 +0000
Received: from localhost (mcheck2.ugent.be [157.193.49.249])
	by smtp2.ugent.be (Postfix) with ESMTP id 7D29D12C34C;
	Sun,  1 Feb 2015 16:31:35 +0100 (CET)
X-Virus-Scanned: by UGent DICT
Received: from smtp2.ugent.be ([IPv6:::ffff:157.193.49.126])
	by localhost (mcheck2.UGent.be [::ffff:157.193.43.11]) (amavisd-new, port 10024)
	with ESMTP id HeFKYXEzRNvj; Sun,  1 Feb 2015 16:31:35 +0100 (CET)
Received: from [172.34.36.239] (wifi-nat232.ulb.ac.be [164.15.117.232])
	(Authenticated sender: ehiggs)
	by smtp2.ugent.be (Postfix) with ESMTPSA id DCCCA12C33F;
	Sun,  1 Feb 2015 16:31:34 +0100 (CET)
Message-ID: <54CE46D6.3080401@ugent.be>
Date: Sun, 01 Feb 2015 16:31:34 +0100
From: Ewan Higgs <ewan.higgs@ugent.be>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.3.0
MIME-Version: 1.0
To: Anjana Fernando <lafernando@gmail.com>, dev@spark.apache.org
Subject: Re: Custom Cluster Managers / Standalone Recovery Mode in Spark
References: <CACpu_pP5i7v8wQjrD4iknektzKbSdVHShAWrOeRewYy4_boS9g@mail.gmail.com>
In-Reply-To: <CACpu_pP5i7v8wQjrD4iknektzKbSdVHShAWrOeRewYy4_boS9g@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Miltered: at jchkm3 with ID 54CE46D6.000 by Joe's j-chkmail (http://helpdesk.ugent.be/email/)!
X-j-chkmail-Enveloppe: 54CE46D6.000 from wifi-nat232.ulb.ac.be/wifi-nat232.ulb.ac.be/164.15.117.232/[172.34.36.239]/<ewan.higgs@ugent.be>
X-j-chkmail-Score: MSGID : 54CE46D6.000 on smtp2.ugent.be : j-chkmail score : . : R=. U=. O=# B=0.000 -> S=0.083
X-j-chkmail-Status: Ham
X-Virus-Checked: Checked by ClamAV on apache.org

+1
On a related note, there is a lot of interest in Hadoop and Spark from 
the HPC community who often run slurm, pbs, and sge to control jobs (as 
opposed to Yarn and Mesos). Currently, there are several projects that 
launch Yarn clusters (or MR1 clusters) inside PBS Jobs [1] but this is 
not the ideal situation. It would be much better to spark-submit 
pbs://master.whatever.org ... and run the job directly.

I would also appreciate help on how to move forward on such a project 
for Spark since it has the performance benefits over Hadoop and I don't 
think Hadoop can currently be disentangled from Yarn at the moment.

I think I need to define a new PbsExecutorBackend and 
PbsSchedulerBackend. IPython approaches this by writing a job script to 
shell out to command line tools like qsub, qdel, qstat because most of 
the job schedulers use these command line tools as a front end [2]. Then 
we should be able to get slurm, pbs, and sge in one shot rather than 
implementing some wire formats for RPC.

Thanks,
Ewan Higgs

[1] https://hadoop.apache.org/docs/r1.2.1/hod_scheduler.html
https://github.com/glennklockwood/hpchadoop
http://jaliyacgl.blogspot.be/2008/08/hadoop-as-batch-job-using-pbs.html
https://github.com/hpcugent/hanythingondemand

[2] http://ipython.org/ipython-doc/stable/parallel/parallel_process.html
https://github.com/ipython/ipython/blob/master/IPython/parallel/apps/launcher.py#L1150

On 31/01/15 09:55, Anjana Fernando wrote:
> Hi everyone,
>
> I've been experimenting, and somewhat of a newbie for Spark. I was
> wondering, if there is any way, that I can use a custom cluster manager
> implementation with Spark. Basically, as I understood, at the moment, the
> inbuilt modes supported are with standalone, Mesos and  Yarn. My
> requirement is basically a simple clustering solution with high
> availability of the master. I don't want to use a separate Zookeeper
> cluster, since this would complicate my deployment, but rather, I would
> like to use something like Hazelcast, which has a peer-to-peer cluster
> coordination implementation.
>
> I found that, there is already this JIRA [1], which requests for a custom
> persistence engine, I guess for storing state information. So basically,
> what I would want to do is, use Hazelcast to use for leader election, to
> make an existing node the master, and to lookup the state information from
> the distributed memory. Appreciate any help on how to archive this. And if
> it useful for a wider audience, hopefully I can contribute this back to the
> project.
>
> [1] https://issues.apache.org/jira/browse/SPARK-1180
>
> Cheers,
> Anjana.
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11384-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 21:29:11 2015
Return-Path: <dev-return-11384-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2358310C76
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 21:29:11 +0000 (UTC)
Received: (qmail 41898 invoked by uid 500); 1 Feb 2015 21:29:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41822 invoked by uid 500); 1 Feb 2015 21:29:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41811 invoked by uid 99); 1 Feb 2015 21:29:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 21:29:09 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 21:29:04 +0000
Received: by mail-la0-f44.google.com with SMTP id s18so35392261lam.3
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 13:27:41 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Lkt3Gwha/uIsJ6JWs9/qbuJQjGetciye6ZBdfDbFdZU=;
        b=YDLPAQZ968UHsd2PskfWSQAUSLt1cRzyWqjX79OyTqi9sjlhdTcOmbZcZKiSed2g7x
         RWLtrqH7HoNUqNND3HfETRuUCW7kY+Al9P3msqRfn2X7CLXELZR6PGuS4dcd617vqkP8
         ++0eiBldO+gvKNxhIXo+ms5TgFhXIS7j4/LFnRCDknr3ChwdJ3CxKfQA1MffGD+ZFBV5
         rEzOnhSID7n+PgzkZnpPgoFLJDhLNv3ZndHcMrKT/zduR6oB/oPkA3thkDTQpjmU5QOW
         DBKM1XdW5JLvJIEarpTuyPugB2ONsTV9HS8EbXtjSL19my/RKhgtSQIi508VJkLmVUg5
         sTLg==
X-Gm-Message-State: ALoCoQmLHhZgwCoC0PjVMv0gk8KfeaNR7x9X3CJsq7+jW98r9KwzOtyIVMbggoae3bdOUGIxkqid
X-Received: by 10.112.61.228 with SMTP id t4mr16749514lbr.0.1422826061687;
 Sun, 01 Feb 2015 13:27:41 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.149.78 with HTTP; Sun, 1 Feb 2015 13:27:20 -0800 (PST)
In-Reply-To: <1422788611928-10377.post@n3.nabble.com>
References: <1422788611928-10377.post@n3.nabble.com>
From: Michael Armbrust <michael@databricks.com>
Date: Sun, 1 Feb 2015 13:27:20 -0800
Message-ID: <CAAswR-6MUKL1u5LwdQmuGkMN+PsiuODveQkfcpCbc5S_04gBvQ@mail.gmail.com>
Subject: Re: Caching tables at column level
To: Mick Davies <michael.belldavies@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3e9c8fbffa1050e0d81fe
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3e9c8fbffa1050e0d81fe
Content-Type: text/plain; charset=UTF-8

Its not completely transparent, but you can do something like the following
today:

CACHE TABLE hotData AS SELECT columns, I, care, about FROM fullTable

On Sun, Feb 1, 2015 at 3:03 AM, Mick Davies <michael.belldavies@gmail.com>
wrote:

> I have been working a lot recently with denormalised tables with lots of
> columns, nearly 600. We are using this form to avoid joins.
>
> I have tried to use cache table with this data, but it proves too expensive
> as it seems to try to cache all the data in the table.
>
> For data sets such as the one I am using you find that certain columns will
> be hot, referenced frequently in queries, others will be used very
> infrequently.
>
> Therefore it would be great if caches could be column based. I realise that
> this may not be optimal for all use cases, but I think it could be quite a
> common need.  Has something like this been considered?
>
> Thanks Mick
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Caching-tables-at-column-level-tp10377.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c3e9c8fbffa1050e0d81fe--

From dev-return-11385-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  1 21:39:35 2015
Return-Path: <dev-return-11385-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3C17210C9D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  1 Feb 2015 21:39:35 +0000 (UTC)
Received: (qmail 56994 invoked by uid 500); 1 Feb 2015 21:39:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56923 invoked by uid 500); 1 Feb 2015 21:39:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56911 invoked by uid 99); 1 Feb 2015 21:39:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 21:39:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ilikerps@gmail.com designates 209.85.216.176 as permitted sender)
Received: from [209.85.216.176] (HELO mail-qc0-f176.google.com) (209.85.216.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 01 Feb 2015 21:39:04 +0000
Received: by mail-qc0-f176.google.com with SMTP id c9so27788314qcz.7
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 13:38:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=I6zg5HN1xYc4dcV4uPUj+Au87Ouz5SSbPElhOREiUPQ=;
        b=UCEMJ5t/jS8RrlCOKyYQ+T1/ZXZnwmXdIXzZvazvzmDF8UeXAAsvHga6W13BU06Ef3
         RKYZzUdbwRPfogw0fIw+0CSzcLwLzg0nd440Fca5uJIjwegaH9LGcEUZAhdqbNz+lv7K
         bdSIYkwilKjPSnT+Q3iFVvVk3lfJz0GmKLWnOMHYR9Ch6so1W8glZ53fbDVwDVTRkzJo
         CfYlOahnsDbX2RUdTFj//2qrdip4vu0nzL2rmFxgzR5B09aiF93jG6a4NOmEb16zry05
         huzPS0BHOHUmsS2CWipgguEPPe84RT6u/v2vMj3dSpwSCX/+HWxoX2SWk8gxji7S1/pc
         vJgQ==
X-Received: by 10.224.36.197 with SMTP id u5mr29816100qad.69.1422826697613;
 Sun, 01 Feb 2015 13:38:17 -0800 (PST)
MIME-Version: 1.0
Received: by 10.140.102.166 with HTTP; Sun, 1 Feb 2015 13:37:57 -0800 (PST)
In-Reply-To: <CACpu_pP5i7v8wQjrD4iknektzKbSdVHShAWrOeRewYy4_boS9g@mail.gmail.com>
References: <CACpu_pP5i7v8wQjrD4iknektzKbSdVHShAWrOeRewYy4_boS9g@mail.gmail.com>
From: Aaron Davidson <ilikerps@gmail.com>
Date: Sun, 1 Feb 2015 13:37:57 -0800
Message-ID: <CANGvG8pofdZKrS8Exku6uBbk8bxUDM_bcY+BrpydusL3LmaHNA@mail.gmail.com>
Subject: Re: Custom Cluster Managers / Standalone Recovery Mode in Spark
To: Anjana Fernando <lafernando@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1c6eae368b7050e0da7e4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1c6eae368b7050e0da7e4
Content-Type: text/plain; charset=UTF-8

For the specific question of supplementing Standalone Mode with a custom
leader election protocol, this was actually already committed in master and
will be available in Spark 1.3:

https://github.com/apache/spark/pull/771/files

You can specify spark.deploy.recoveryMode = "CUSTOM"
and spark.deploy.recoveryMode.factory to a class which
implements StandaloneRecoveryModeFactory. See the current implementations
of FileSystemRecoveryModeFactory and ZooKeeperRecoveryModeFactory.

I will update the JIRA you linked to be more current.

On Sat, Jan 31, 2015 at 12:55 AM, Anjana Fernando <lafernando@gmail.com>
wrote:

> Hi everyone,
>
> I've been experimenting, and somewhat of a newbie for Spark. I was
> wondering, if there is any way, that I can use a custom cluster manager
> implementation with Spark. Basically, as I understood, at the moment, the
> inbuilt modes supported are with standalone, Mesos and  Yarn. My
> requirement is basically a simple clustering solution with high
> availability of the master. I don't want to use a separate Zookeeper
> cluster, since this would complicate my deployment, but rather, I would
> like to use something like Hazelcast, which has a peer-to-peer cluster
> coordination implementation.
>
> I found that, there is already this JIRA [1], which requests for a custom
> persistence engine, I guess for storing state information. So basically,
> what I would want to do is, use Hazelcast to use for leader election, to
> make an existing node the master, and to lookup the state information from
> the distributed memory. Appreciate any help on how to archive this. And if
> it useful for a wider audience, hopefully I can contribute this back to the
> project.
>
> [1] https://issues.apache.org/jira/browse/SPARK-1180
>
> Cheers,
> Anjana.
>

--001a11c1c6eae368b7050e0da7e4--

From dev-return-11386-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 02:05:42 2015
Return-Path: <dev-return-11386-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3A86617318
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 02:05:42 +0000 (UTC)
Received: (qmail 42822 invoked by uid 500); 2 Feb 2015 02:05:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42745 invoked by uid 500); 2 Feb 2015 02:05:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42733 invoked by uid 99); 2 Feb 2015 02:05:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 02:05:41 +0000
X-ASF-Spam-Status: No, hits=1.0 required=10.0
	tests=FORGED_YAHOO_RCVD,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of michaelmalak@yahoo.com designates 72.30.239.143 as permitted sender)
Received: from [72.30.239.143] (HELO nm32-vm7.bullet.mail.bf1.yahoo.com) (72.30.239.143)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 02:05:15 +0000
Received: from [66.196.81.173] by nm32.bullet.mail.bf1.yahoo.com with NNFMP; 02 Feb 2015 02:04:10 -0000
Received: from [98.139.212.222] by tm19.bullet.mail.bf1.yahoo.com with NNFMP; 02 Feb 2015 02:04:10 -0000
Received: from [127.0.0.1] by omp1031.mail.bf1.yahoo.com with NNFMP; 02 Feb 2015 02:04:10 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 222239.61835.bm@omp1031.mail.bf1.yahoo.com
X-YMail-OSG: sBP44GIVM1lnz5V4oeC_zCtCf8XPV0XqtF7oUIcjjQnTvZmF8JTQbld4rAqrham
 37qrUpxkQ6tJgw_lRe.1ICNvk2CRq4lRy3Cqj46zIrGLmAqjbUQLoyl_5C2Oj8IRNKftIqS_P9cz
 tirshthlTqKdIH3sEs7jPC3c6.QeTT9aPhvY1iJKslanIg4WXLdLl0Owz.DAN_npbgkrkVn0SIxV
 g2fOPdWUcrWpWLBNPfbpyxCayx2RLjKL.2bVCsDzoPhm2xFT5NosMGs9uX9Lthc7zYpw6_9RNCHO
 IS3SkCCGLHkQOslVYVBezdYoie5_YBmeJOZkkV0Pun5EVDCtRbs5eBw5Aug.rHlkXYx4VCO1S.nd
 3ReEy5avTSqgqi8P7KaWvq5Mbuh5Jp1aYHDr_CX84PnHY2tKWGYDQdO0LQBJuhCODhL9ovb.6OYF
 xgRaqTIwySEz3isUY3G4eG5b8zdUglx51P5DpadxgvC3UQO2gIf_yI6KA2EUo86aV632FBoAHHSb
 TqDfwIo10LMkmLzCmJTwfCHfAxAkneZsZ1NHj4wwi.d5U_7oRl_W9D0COp_daLKBKRWcphNg2G6U
 .8D0GxW4Kq9PDpypAhK0gvXrEGJCPbgLasPX0POLLGVMPI1f.hn2bI.hUH72gzlG1AaXJsJFP42U
 LRqosudHP7RPHBBn1chwtdsPfeoy.eElMIMlcHJYlPv.5Zv2P9U9HJI359foMwM5GGtHQjwgk5dy
 qyxpO8Afk4d55kzHVtsSqOTM4gKYFCOPysp4BAbSg
Received: by 66.196.81.119; Mon, 02 Feb 2015 02:04:09 +0000 
Date: Mon, 2 Feb 2015 02:04:09 +0000 (UTC)
From: Michael Malak <michaelmalak@yahoo.com.INVALID>
Reply-To: Michael Malak <michaelmalak@yahoo.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Message-ID: <124374463.673510.1422842649351.JavaMail.yahoo@mail.yahoo.com>
Subject: Word2Vec IndexedRDD
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

1. Is IndexedRDD planned for 1.3? https://issues.apache.org/jira/browse/SPARK-2365

2. Once IndexedRDD is in, is it planned to convert Word2VecModel to it from its current Map[String,Array[Float]]? 
https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/feature/Word2Vec.scala#L425

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11387-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 02:11:57 2015
Return-Path: <dev-return-11387-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D00A41733D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 02:11:57 +0000 (UTC)
Received: (qmail 55330 invoked by uid 500); 2 Feb 2015 02:11:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55257 invoked by uid 500); 2 Feb 2015 02:11:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55244 invoked by uid 99); 2 Feb 2015 02:11:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 02:11:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lafernando@gmail.com designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 02:11:32 +0000
Received: by mail-la0-f42.google.com with SMTP id ms9so36285990lab.1
        for <dev@spark.apache.org>; Sun, 01 Feb 2015 18:09:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=S3QGMSDMX8ZP8hcdF2UbULrhsciCvk9tyQAMfh2HKpc=;
        b=ptnMZ1wShabzyDjwDLDqDkdf84f5x5oRTWjSJCr/sMhNisz3hCAhOJPkNjKT10o/b9
         L9fl1GXTRIx3iq+lI036yZ3pm178cZfv83qRX05yk9epVNwTNOEpHNaJmg6EEy7+RejY
         vG4W8IWb6SjaoiiQF/uemyte0loV5j1p0PSBKg4935It1asifl/09n3jmDvrHie9mKcg
         admvFptMVu+GlVXkCrmIUxIExELgA6O8J9FmrIw2oOB7MleZzwkTnP85/+s9TpzFhYQt
         O0YSgRwL5E4+CMbqM7fu1EDUVfxWyRExOxA2AVaVsxhjQq8HQ8abv9UT9rYkUcqUyFq+
         9psw==
MIME-Version: 1.0
X-Received: by 10.152.44.193 with SMTP id g1mr17111465lam.15.1422842999331;
 Sun, 01 Feb 2015 18:09:59 -0800 (PST)
Received: by 10.114.3.177 with HTTP; Sun, 1 Feb 2015 18:09:59 -0800 (PST)
In-Reply-To: <CANGvG8pofdZKrS8Exku6uBbk8bxUDM_bcY+BrpydusL3LmaHNA@mail.gmail.com>
References: <CACpu_pP5i7v8wQjrD4iknektzKbSdVHShAWrOeRewYy4_boS9g@mail.gmail.com>
	<CANGvG8pofdZKrS8Exku6uBbk8bxUDM_bcY+BrpydusL3LmaHNA@mail.gmail.com>
Date: Mon, 2 Feb 2015 07:39:59 +0530
Message-ID: <CACpu_pNfPc1YiwMSbq5iQCzeHPsz1Gc9Zc1E-6iaYRMfCxni3Q@mail.gmail.com>
Subject: Re: Custom Cluster Managers / Standalone Recovery Mode in Spark
From: Anjana Fernando <lafernando@gmail.com>
To: Aaron Davidson <ilikerps@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160bda48bdf3f050e1173b2
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160bda48bdf3f050e1173b2
Content-Type: text/plain; charset=UTF-8

Hi guys,

That's great to hear that this is available in Spark 1.3! .. I will play
around with this feature and let you know the results for integrating
Hazelcast. Also, may I know the tentative release date for Spark 1.3? ..

Cheers,
Anjana.

On Mon, Feb 2, 2015 at 3:07 AM, Aaron Davidson <ilikerps@gmail.com> wrote:

> For the specific question of supplementing Standalone Mode with a custom
> leader election protocol, this was actually already committed in master and
> will be available in Spark 1.3:
>
> https://github.com/apache/spark/pull/771/files
>
> You can specify spark.deploy.recoveryMode = "CUSTOM"
> and spark.deploy.recoveryMode.factory to a class which
> implements StandaloneRecoveryModeFactory. See the current implementations
> of FileSystemRecoveryModeFactory and ZooKeeperRecoveryModeFactory.
>
> I will update the JIRA you linked to be more current.
>
> On Sat, Jan 31, 2015 at 12:55 AM, Anjana Fernando <lafernando@gmail.com>
> wrote:
>
>> Hi everyone,
>>
>> I've been experimenting, and somewhat of a newbie for Spark. I was
>> wondering, if there is any way, that I can use a custom cluster manager
>> implementation with Spark. Basically, as I understood, at the moment, the
>> inbuilt modes supported are with standalone, Mesos and  Yarn. My
>> requirement is basically a simple clustering solution with high
>> availability of the master. I don't want to use a separate Zookeeper
>> cluster, since this would complicate my deployment, but rather, I would
>> like to use something like Hazelcast, which has a peer-to-peer cluster
>> coordination implementation.
>>
>> I found that, there is already this JIRA [1], which requests for a custom
>> persistence engine, I guess for storing state information. So basically,
>> what I would want to do is, use Hazelcast to use for leader election, to
>> make an existing node the master, and to lookup the state information from
>> the distributed memory. Appreciate any help on how to archive this. And if
>> it useful for a wider audience, hopefully I can contribute this back to
>> the
>> project.
>>
>> [1] https://issues.apache.org/jira/browse/SPARK-1180
>>
>> Cheers,
>> Anjana.
>>
>
>

--089e0160bda48bdf3f050e1173b2--

From dev-return-11388-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 08:26:19 2015
Return-Path: <dev-return-11388-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7837617939
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 08:26:19 +0000 (UTC)
Received: (qmail 59069 invoked by uid 500); 2 Feb 2015 08:26:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59001 invoked by uid 500); 2 Feb 2015 08:26:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56187 invoked by uid 99); 2 Feb 2015 08:26:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 08:26:06 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saisai.shao@intel.com designates 134.134.136.65 as permitted sender)
Received: from [134.134.136.65] (HELO mga03.intel.com) (134.134.136.65)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 08:25:39 +0000
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by orsmga103.jf.intel.com with ESMTP; 02 Feb 2015 00:19:57 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.09,505,1418112000"; 
   d="scan'208,217";a="646035998"
Received: from pgsmsx102.gar.corp.intel.com ([10.221.44.80])
  by orsmga001.jf.intel.com with ESMTP; 02 Feb 2015 00:24:30 -0800
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 PGSMSX102.gar.corp.intel.com (10.221.44.80) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Mon, 2 Feb 2015 16:24:18 +0800
Received: from shsmsx103.ccr.corp.intel.com ([169.254.4.91]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.168]) with mapi id 14.03.0195.001;
 Mon, 2 Feb 2015 16:24:19 +0800
From: "Shao, Saisai" <saisai.shao@intel.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org"
	<user@spark.apache.org>
Subject: Questions about Spark standalone resource scheduler
Thread-Topic: Questions about Spark standalone resource scheduler
Thread-Index: AdA+vXndPGtTo0peRy+GBnELvMdDbw==
Date: Mon, 2 Feb 2015 08:24:18 +0000
Message-ID: <64474308D680D540A4D8151B0F7C03F70278AF28@SHSMSX103.ccr.corp.intel.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: multipart/alternative;
	boundary="_000_64474308D680D540A4D8151B0F7C03F70278AF28SHSMSX103ccrcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_64474308D680D540A4D8151B0F7C03F70278AF28SHSMSX103ccrcor_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi all,

I have some questions about the future development of Spark's standalone re=
source scheduler. We've heard some users have the requirements to have mult=
i-tenant support in standalone mode, like multi-user management, resource m=
anagement and isolation, whitelist of users. Seems current Spark standalone=
 do not support such kind of functionalities, while resource schedulers lik=
e Yarn offers such kind of advanced managements, I'm not sure what's the fu=
ture target of standalone resource scheduler, will it only target on simple=
 implementation, and for advanced usage shift to YARN? Or will it plan to a=
dd some simple multi-tenant related functionalities?

Thanks a lot for your comments.

BR
Jerry

--_000_64474308D680D540A4D8151B0F7C03F70278AF28SHSMSX103ccrcor_--

From dev-return-11389-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 08:49:01 2015
Return-Path: <dev-return-11389-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 62D68179D0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 08:49:01 +0000 (UTC)
Received: (qmail 10099 invoked by uid 500); 2 Feb 2015 08:48:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10016 invoked by uid 500); 2 Feb 2015 08:48:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8887 invoked by uid 99); 2 Feb 2015 08:48:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 08:48:58 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 08:48:52 +0000
Received: by mail-oi0-f44.google.com with SMTP id a3so43117893oib.3;
        Mon, 02 Feb 2015 00:48:32 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=CYJud2/901+OLR25SOd7CzB6tgLUBYB0VE8MJajVVN8=;
        b=wS/KDtqrCQEQAeVy2IqL+HYPC6d+o82jWHKl9k0tAs+KpBuf++KO11L0Yx4JSPzPLC
         xXdr41EAvRCqScDSXwhQc5liPD0f03Jq2mdk5n6FXE9uMWcqMwjEturNs7FoKyWF+vRZ
         fIKQ94BUajwEmBLkv64OfacgZG7WRz9Bvwb6uwlBEg9twiAAUa5kYjdMNS6BfnUPrkEP
         nLD4VQVVZ9FQ1+WCpbcAgH0tdbA95NoYy0NdaPRrEP1Sk38HPNg2ssmFbcP0jJMltPae
         6Ycy44W90KnUM/7jTgX9t79TloV2GKIJ1veFRjdKjHgrHQ4ezNe7kjKYcT5FE9sb+v3e
         k40A==
MIME-Version: 1.0
X-Received: by 10.202.1.200 with SMTP id 191mr10488470oib.82.1422866912233;
 Mon, 02 Feb 2015 00:48:32 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 00:48:32 -0800 (PST)
In-Reply-To: <64474308D680D540A4D8151B0F7C03F70278AF28@SHSMSX103.ccr.corp.intel.com>
References: <64474308D680D540A4D8151B0F7C03F70278AF28@SHSMSX103.ccr.corp.intel.com>
Date: Mon, 2 Feb 2015 00:48:32 -0800
Message-ID: <CABPQxstr8yx_6bX2WvF=jc_++hX=whgW63bLjRCv8qbv6ZyT_Q@mail.gmail.com>
Subject: Re: Questions about Spark standalone resource scheduler
From: Patrick Wendell <pwendell@gmail.com>
To: "Shao, Saisai" <saisai.shao@intel.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Jerry,

I think standalone mode will still add more features over time, but
the goal isn't really for it to become equivalent to what Mesos/YARN
are today. Or at least, I doubt Spark Standalone will ever attempt to
manage _other_ frameworks outside of Spark and become a general
purpose resource manager.

In terms of having better support for multi tenancy, meaning multiple
*Spark* instances, this is something I think could be in scope in the
future. For instance, we added H/A to the standalone scheduler a while
back, because it let us support H/A streaming apps in a totally native
way. It's a trade off of adding new features and keeping the scheduler
very simple and easy to use. We've tended to bias towards simplicity
as the main goal, since this is something we want to be really easy
"out of the box".

One thing to point out, a lot of people use the standalone mode with
some coarser grained scheduler, such as running in a cloud service. In
this case they really just want a simple "inner" cluster manager. This
may even be the majority of all Spark installations. This is slightly
different than Hadoop environments, where they might just want nice
integration into the existing Hadoop stack via something like YARN.

- Patrick

On Mon, Feb 2, 2015 at 12:24 AM, Shao, Saisai <saisai.shao@intel.com> wrote:
> Hi all,
>
>
>
> I have some questions about the future development of Spark's standalone
> resource scheduler. We've heard some users have the requirements to have
> multi-tenant support in standalone mode, like multi-user management,
> resource management and isolation, whitelist of users. Seems current Spark
> standalone do not support such kind of functionalities, while resource
> schedulers like Yarn offers such kind of advanced managements, I'm not sure
> what's the future target of standalone resource scheduler, will it only
> target on simple implementation, and for advanced usage shift to YARN? Or
> will it plan to add some simple multi-tenant related functionalities?
>
>
>
> Thanks a lot for your comments.
>
>
>
> BR
>
> Jerry

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11390-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 09:30:45 2015
Return-Path: <dev-return-11390-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 77D8617B33
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 09:30:45 +0000 (UTC)
Received: (qmail 83035 invoked by uid 500); 2 Feb 2015 09:22:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82967 invoked by uid 500); 2 Feb 2015 09:22:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81899 invoked by uid 99); 2 Feb 2015 09:22:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 09:22:39 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=5.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saisai.shao@intel.com designates 134.134.136.20 as permitted sender)
Received: from [134.134.136.20] (HELO mga02.intel.com) (134.134.136.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 09:22:14 +0000
Received: from orsmga002.jf.intel.com ([10.7.209.21])
  by orsmga101.jf.intel.com with ESMTP; 02 Feb 2015 01:20:10 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.09,505,1418112000"; 
   d="scan'208";a="679585214"
Received: from pgsmsx103.gar.corp.intel.com ([10.221.44.82])
  by orsmga002.jf.intel.com with ESMTP; 02 Feb 2015 01:20:09 -0800
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 PGSMSX103.gar.corp.intel.com (10.221.44.82) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Mon, 2 Feb 2015 17:20:07 +0800
Received: from shsmsx103.ccr.corp.intel.com ([169.254.4.91]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.168]) with mapi id 14.03.0195.001;
 Mon, 2 Feb 2015 17:20:07 +0800
From: "Shao, Saisai" <saisai.shao@intel.com>
To: Patrick Wendell <pwendell@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org"
	<user@spark.apache.org>
Subject: RE: Questions about Spark standalone resource scheduler
Thread-Topic: Questions about Spark standalone resource scheduler
Thread-Index: AdA+vXndPGtTo0peRy+GBnELvMdDb///iPsA//91rPA=
Date: Mon, 2 Feb 2015 09:20:07 +0000
Message-ID: <64474308D680D540A4D8151B0F7C03F70278CF5C@SHSMSX103.ccr.corp.intel.com>
References: <64474308D680D540A4D8151B0F7C03F70278AF28@SHSMSX103.ccr.corp.intel.com>
 <CABPQxstr8yx_6bX2WvF=jc_++hX=whgW63bLjRCv8qbv6ZyT_Q@mail.gmail.com>
In-Reply-To: <CABPQxstr8yx_6bX2WvF=jc_++hX=whgW63bLjRCv8qbv6ZyT_Q@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Patrick,

Thanks a lot for your detailed explanation. For now we have such requiremen=
ts: whitelist the application submitter, user resources (CPU, MEMORY) quota=
s, resources allocations in Spark Standalone mode. These are quite specific=
 requirements for production-use, generally these problem will become wheth=
er we need to offer a more advanced resource scheduler compared to current =
simple FIFO one. I think our aim is to not provide a general resource sched=
uler like Mesos/Yarn, we only support Spark, but we hope to add some Mesos/=
Yarn functionalities to better use of Spark standalone mode.

I admitted that resource scheduler may have some overlaps with cloud manage=
r, whether to offer a powerful scheduler or use cloud manager is really a d=
ilemma.

I think we can break down to some small features to improve the standalone =
mode. What's your opinion?

Thanks
Jerry

-----Original Message-----
From: Patrick Wendell [mailto:pwendell@gmail.com]=20
Sent: Monday, February 2, 2015 4:49 PM
To: Shao, Saisai
Cc: dev@spark.apache.org; user@spark.apache.org
Subject: Re: Questions about Spark standalone resource scheduler

Hey Jerry,

I think standalone mode will still add more features over time, but the goa=
l isn't really for it to become equivalent to what Mesos/YARN are today. Or=
 at least, I doubt Spark Standalone will ever attempt to manage _other_ fra=
meworks outside of Spark and become a general purpose resource manager.

In terms of having better support for multi tenancy, meaning multiple
*Spark* instances, this is something I think could be in scope in the futur=
e. For instance, we added H/A to the standalone scheduler a while back, bec=
ause it let us support H/A streaming apps in a totally native way. It's a t=
rade off of adding new features and keeping the scheduler very simple and e=
asy to use. We've tended to bias towards simplicity as the main goal, since=
 this is something we want to be really easy "out of the box".

One thing to point out, a lot of people use the standalone mode with some c=
oarser grained scheduler, such as running in a cloud service. In this case =
they really just want a simple "inner" cluster manager. This may even be th=
e majority of all Spark installations. This is slightly different than Hado=
op environments, where they might just want nice integration into the exist=
ing Hadoop stack via something like YARN.

- Patrick

On Mon, Feb 2, 2015 at 12:24 AM, Shao, Saisai <saisai.shao@intel.com> wrote=
:
> Hi all,
>
>
>
> I have some questions about the future development of Spark's=20
> standalone resource scheduler. We've heard some users have the=20
> requirements to have multi-tenant support in standalone mode, like=20
> multi-user management, resource management and isolation, whitelist of=20
> users. Seems current Spark standalone do not support such kind of=20
> functionalities, while resource schedulers like Yarn offers such kind=20
> of advanced managements, I'm not sure what's the future target of=20
> standalone resource scheduler, will it only target on simple=20
> implementation, and for advanced usage shift to YARN? Or will it plan to =
add some simple multi-tenant related functionalities?
>
>
>
> Thanks a lot for your comments.
>
>
>
> BR
>
> Jerry

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11391-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 20:24:21 2015
Return-Path: <dev-return-11391-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF0451783F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 20:24:21 +0000 (UTC)
Received: (qmail 46307 invoked by uid 500); 2 Feb 2015 20:24:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46225 invoked by uid 500); 2 Feb 2015 20:24:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46002 invoked by uid 99); 2 Feb 2015 20:24:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 20:24:11 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of ankitsoni9@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 20:24:06 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 818961299845
	for <dev@spark.apache.org>; Mon,  2 Feb 2015 12:23:46 -0800 (PST)
Date: Mon, 2 Feb 2015 13:23:45 -0700 (MST)
From: ankits <ankitsoni9@gmail.com>
To: dev@spark.apache.org
Message-ID: <1422908625927-10388.post@n3.nabble.com>
In-Reply-To: <54CC51F1.3030604@gmail.com>
References: <1422670555626-10366.post@n3.nabble.com> <54CC51F1.3030604@gmail.com>
Subject: Re: Get size of rdd in memory
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for your response. So AFAICT 

calling parallelize(1  to1024).map(i =>KV(i,
i.toString)).toSchemaRDD.cache().count(), will allow me to see the size of
the schemardd in memory

and parallelize(1  to1024).map(i =>KV(i, i.toString)).cache().count()  will
show me the size of a regular rdd.

But this will not show us the size when using cacheTable() right? Like if i
call

parallelize(1  to1024).map(i =>KV(i,
i.toString)).toSchemaRDD.registerTempTable("test")
sqc.cacheTable("test")
sqc.sql("SELECT COUNT(*) FROM test")

the web UI does not show us the size of the cached table. 





--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Get-size-of-rdd-in-memory-tp10366p10388.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11392-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 21:20:00 2015
Return-Path: <dev-return-11392-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 28A9517A5F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 21:20:00 +0000 (UTC)
Received: (qmail 19628 invoked by uid 500); 2 Feb 2015 21:19:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19560 invoked by uid 500); 2 Feb 2015 21:19:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19490 invoked by uid 99); 2 Feb 2015 21:19:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 21:19:59 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 21:19:53 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so87226664pad.7
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 13:18:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        bh=SO9iYyginVVtUbuC3l+Sqb2bAi45odkIZAt77KtELdk=;
        b=y6M+1p4dmDVisidDny8hEViPt8VDR99SeAE07z3X1Vbl83AYTFs1db/L2TprR7Zenm
         0us0ns8v7jthv6VUXe5CCWE14PB48JBtA4yCSIwnlgO7WGykKmrX4a9NftYnfCMITslc
         2MujprsD74LS5PdBy1/btjMHKym9fmX311n8rLGXAw3UPxe/xt1qqgChwEaMLd0t5MXj
         YNW7LS1Tt3rcIBYHwK75Oh6GQWrAxKxkqe/aq2iYuQ2+eDuKTzBaPO1ZgFaYGJewoOgW
         cNcga2D+NK9AwqZXWMc3E/64HzM2EZX67kz3iWg/lFtauZu+qu2g5zsiiPTbJh2zjo5T
         ncjA==
X-Received: by 10.67.6.225 with SMTP id cx1mr32396342pad.1.1422911883442;
        Mon, 02 Feb 2015 13:18:03 -0800 (PST)
Received: from [192.168.1.168] (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id rf9sm18379555pab.0.2015.02.02.13.18.02
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 02 Feb 2015 13:18:02 -0800 (PST)
Message-ID: <54CFE988.2070705@gmail.com>
Date: Mon, 02 Feb 2015 13:18:00 -0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: ankits <ankitsoni9@gmail.com>, dev@spark.apache.org
Subject: Re: Get size of rdd in memory
References: <1422670555626-10366.post@n3.nabble.com> <54CC51F1.3030604@gmail.com> <1422908625927-10388.post@n3.nabble.com>
In-Reply-To: <1422908625927-10388.post@n3.nabble.com>
Content-Type: multipart/alternative;
 boundary="------------030004080501010505070204"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------030004080501010505070204
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit

Actually |SchemaRDD.cache()| behaves exactly the same as |cacheTable| 
since Spark 1.2.0. The reason why your web UI didn’t show you the cached 
table is that both |cacheTable| and |sql("SELECT ...")| are lazy :-) 
Simply add a |.collect()| after the |sql(...)| call.

Cheng

On 2/2/15 12:23 PM, ankits wrote:

> Thanks for your response. So AFAICT
>
> calling parallelize(1  to1024).map(i =>KV(i,
> i.toString)).toSchemaRDD.cache().count(), will allow me to see the size of
> the schemardd in memory
>
> and parallelize(1  to1024).map(i =>KV(i, i.toString)).cache().count()  will
> show me the size of a regular rdd.
>
> But this will not show us the size when using cacheTable() right? Like if i
> call
>
> parallelize(1  to1024).map(i =>KV(i,
> i.toString)).toSchemaRDD.registerTempTable("test")
> sqc.cacheTable("test")
> sqc.sql("SELECT COUNT(*) FROM test")
>
> the web UI does not show us the size of the cached table.
>
>
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Get-size-of-rdd-in-memory-tp10366p10388.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>
​

--------------030004080501010505070204--

From dev-return-11393-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 21:44:42 2015
Return-Path: <dev-return-11393-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 364E617BE5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 21:44:42 +0000 (UTC)
Received: (qmail 16953 invoked by uid 500); 2 Feb 2015 21:44:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16880 invoked by uid 500); 2 Feb 2015 21:44:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16866 invoked by uid 99); 2 Feb 2015 21:44:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 21:44:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.176 as permitted sender)
Received: from [209.85.213.176] (HELO mail-ig0-f176.google.com) (209.85.213.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 21:44:16 +0000
Received: by mail-ig0-f176.google.com with SMTP id hl2so21845544igb.3
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 13:44:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=0CFfV75aGFSIn45BRF00UzQbSNHlP+oTTGbpDes8BSM=;
        b=hxzSO1ue9s4rXqc2mdaTogOMHFxTyNKJeBPNHAl7snh7JPnvLEdQ4RO54BHRMm1QI/
         fczxOAVkWvb2ZYID5ePLlgasBrTcbpFOe+Bf7FH8mALMoFRdI0U0NGIzQCvcZRi3xFVP
         w70fZqHwPl3ywzF8tY7H0f695t6Dt9y6bf7qEt9X8ty6p/q8nE3dsUjpdK+pmDAXwKFU
         LGAfODEzN7JVyy3+zCmFsjtj0RLu7rBcff+ejXB2J24FPmq13/YYoKDqEYxR+mBsghDF
         AOi8gkBxGvWL+jOOJW9amtBtzPRHSt+sSQzMmVQMOvqGqWuV6rQDKjOeCc6uCjrn9J3c
         zz8Q==
X-Received: by 10.107.161.75 with SMTP id k72mr20654141ioe.46.1422913455011;
 Mon, 02 Feb 2015 13:44:15 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 02 Feb 2015 21:44:14 +0000
Message-ID: <CAOhmDzdpY-LeGvr03QUtf16XgfRs2HmJ-9Rtvaer3R_L5ez6KA@mail.gmail.com>
Subject: Spark Master Maven with YARN build is broken
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114100b00864c2050e21db49
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114100b00864c2050e21db49
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

https://amplab.cs.berkeley.edu/jenkins/view/Spark/job/Spark-Master-Maven-wi=
th-YARN/HADOOP_PROFILE=3Dhadoop-2.4,label=3Dcentos/

Is this is a known issue? It seems to have been broken since last night.

Here=E2=80=99s a snippet from the build output of one of the builds
<https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-with-YARN/HA=
DOOP_PROFILE=3Dhadoop-2.4,label=3Dcentos/1308/console>
:

[error] bad symbolic reference. A signature in WebUI.class refers to
term eclipse
[error] in package org which is not available.
[error] It may be completely missing from the current classpath, or
the version on
[error] the classpath might be incompatible with the version used when
compiling WebUI.class.
[error] bad symbolic reference. A signature in WebUI.class refers to term j=
etty
[error] in value org.eclipse which is not available.
[error] It may be completely missing from the current classpath, or
the version on
[error] the classpath might be incompatible with the version used when
compiling WebUI.class.
[error]
[error]      while compiling:
/home/jenkins/workspace/Spark-Master-Maven-with-YARN/HADOOP_PROFILE/hadoop-=
2.4/label/centos/yarn/src/main/scala/org/apache/spark/deploy/yarn/Applicati=
onMaster.scala
[error]         during phase: erasure
[error]      library version: version 2.10.4
[error]     compiler version: version 2.10.4

Nick
=E2=80=8B

--001a114100b00864c2050e21db49--

From dev-return-11394-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 22:01:13 2015
Return-Path: <dev-return-11394-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7EED117CB6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 22:01:13 +0000 (UTC)
Received: (qmail 66971 invoked by uid 500); 2 Feb 2015 22:01:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66897 invoked by uid 500); 2 Feb 2015 22:01:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66880 invoked by uid 99); 2 Feb 2015 22:01:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:01:12 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:01:08 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so15510958obc.5
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 14:00:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=xtV5j9xfdUffSzA0AqKXjxqp0E1XLE2FmsOqbBuLrwM=;
        b=ZblVUXfKpuIqOli6ppAvNx8pIhlLFvsAQZthaWSFMjDodVI12o142WolKefzGimeQW
         EL533J5aTvhzrJwBsBm/82/2ah5eBLJjbCEKoCajxyrfl/IaD1V/LR2s/p2uf9VChrKT
         +gxfz7T8OSm3hLP4ioBw8lB4OnOvJiKGK2WG8EU+03bKfYKzBTIcdcA3SwRXMQsO5srr
         KGzfC2k9JeS+oQEnFOxa837eA2zi95h89ayeplc/WY7NMPAx2mJul0OXtMCIVKDTftAB
         3fVm0tZfeliFHHgF5XGXM7Ibhmz1ihdXHPiyGyORAmZDcButRpvaaffOtAgXvwJfpxxk
         hA2A==
MIME-Version: 1.0
X-Received: by 10.202.45.9 with SMTP id t9mr12728531oit.100.1422914403166;
 Mon, 02 Feb 2015 14:00:03 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 14:00:03 -0800 (PST)
In-Reply-To: <CAOhmDzdpY-LeGvr03QUtf16XgfRs2HmJ-9Rtvaer3R_L5ez6KA@mail.gmail.com>
References: <CAOhmDzdpY-LeGvr03QUtf16XgfRs2HmJ-9Rtvaer3R_L5ez6KA@mail.gmail.com>
Date: Mon, 2 Feb 2015 14:00:03 -0800
Message-ID: <CABPQxssPhN0t6ZafjC_9sUoDqKogPe-PwM-koeLhPomXO+AWuw@mail.gmail.com>
Subject: Re: Spark Master Maven with YARN build is broken
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

It's my fault, I'm sending a hot fix now.

On Mon, Feb 2, 2015 at 1:44 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> https://amplab.cs.berkeley.edu/jenkins/view/Spark/job/Spark-Master-Maven-with-YARN/HADOOP_PROFILE=hadoop-2.4,label=centos/
>
> Is this is a known issue? It seems to have been broken since last night.
>
> Here's a snippet from the build output of one of the builds
> <https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-with-YARN/HADOOP_PROFILE=hadoop-2.4,label=centos/1308/console>
> :
>
> [error] bad symbolic reference. A signature in WebUI.class refers to
> term eclipse
> [error] in package org which is not available.
> [error] It may be completely missing from the current classpath, or
> the version on
> [error] the classpath might be incompatible with the version used when
> compiling WebUI.class.
> [error] bad symbolic reference. A signature in WebUI.class refers to term jetty
> [error] in value org.eclipse which is not available.
> [error] It may be completely missing from the current classpath, or
> the version on
> [error] the classpath might be incompatible with the version used when
> compiling WebUI.class.
> [error]
> [error]      while compiling:
> /home/jenkins/workspace/Spark-Master-Maven-with-YARN/HADOOP_PROFILE/hadoop-2.4/label/centos/yarn/src/main/scala/org/apache/spark/deploy/yarn/ApplicationMaster.scala
> [error]         during phase: erasure
> [error]      library version: version 2.10.4
> [error]     compiler version: version 2.10.4
>
> Nick
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11395-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 22:05:33 2015
Return-Path: <dev-return-11395-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8558E17CFD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 22:05:33 +0000 (UTC)
Received: (qmail 86583 invoked by uid 500); 2 Feb 2015 22:05:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86373 invoked by uid 500); 2 Feb 2015 22:05:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85596 invoked by uid 99); 2 Feb 2015 22:05:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:05:25 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of ankitsoni9@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:05:21 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id D3FB5129B9E7
	for <dev@spark.apache.org>; Mon,  2 Feb 2015 14:03:30 -0800 (PST)
Date: Mon, 2 Feb 2015 15:03:30 -0700 (MST)
From: ankits <ankitsoni9@gmail.com>
To: dev@spark.apache.org
Message-ID: <1422914610217-10392.post@n3.nabble.com>
In-Reply-To: <54CFE988.2070705@gmail.com>
References: <1422670555626-10366.post@n3.nabble.com> <54CC51F1.3030604@gmail.com> <1422908625927-10388.post@n3.nabble.com> <54CFE988.2070705@gmail.com>
Subject: Re: Get size of rdd in memory
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Great, thank you very much. I was confused because this is in the docs:

https://spark.apache.org/docs/1.2.0/sql-programming-guide.html, and on the
"branch-1.2" branch,
https://github.com/apache/spark/blob/branch-1.2/docs/sql-programming-guide.md

"Note that if you call schemaRDD.cache() rather than
sqlContext.cacheTable(...), tables will not be cached using the in-memory
columnar format, and therefore sqlContext.cacheTable(...) is strongly
recommended for this use case.".

If this is no longer accurate, i could make a PR to remove it.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Get-size-of-rdd-in-memory-tp10366p10392.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11396-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 22:17:54 2015
Return-Path: <dev-return-11396-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 81CE917D8B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 22:17:54 +0000 (UTC)
Received: (qmail 26332 invoked by uid 500); 2 Feb 2015 22:17:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26260 invoked by uid 500); 2 Feb 2015 22:17:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26227 invoked by uid 99); 2 Feb 2015 22:17:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:17:47 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:17:42 +0000
Received: by mail-pa0-f54.google.com with SMTP id eu11so87717277pac.13
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 14:16:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=D0ckknUJvumDyyZz4IfZ+91PF1QCy+lb/Y2key3m6rM=;
        b=Y/bqx8Sti8qtgLILRTCp9aw9+ofWegG0eJZiF1J/Rxpl9EsGA9FdBN6E5yNW2+kBQo
         YrQh6pRR0t5+P7IlFLf2RHOVfq7+TAMW4pA+wEsMVOAnYBF7YeZlSslDCiciDxhbRcz4
         23GYZ7lRaI0AwcmOlJ1nG4Dc1588xGgVSbDqWohSpgZyjPklX7TL7u2jz+dLmOtT13LR
         u84IheIFYgK3uprpIvY8HuSq+dZlkIMbZOYvDsvgH+/0IiVZXn5Acbu9pBSzIIA3wwNi
         HKCZ0bzCoHaUUlsUZGuHFhv0Mk1Vz1caLflfr1ER3EnyL0yLeoKA1RW3bLcR+0iVPAq4
         IRvw==
X-Received: by 10.70.27.33 with SMTP id q1mr33109602pdg.84.1422915397636;
        Mon, 02 Feb 2015 14:16:37 -0800 (PST)
Received: from [192.168.1.168] (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id k5sm68093pdb.14.2015.02.02.14.16.36
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 02 Feb 2015 14:16:37 -0800 (PST)
Message-ID: <54CFF742.2090708@gmail.com>
Date: Mon, 02 Feb 2015 14:16:34 -0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: ankits <ankitsoni9@gmail.com>, dev@spark.apache.org
Subject: Re: Get size of rdd in memory
References: <1422670555626-10366.post@n3.nabble.com> <54CC51F1.3030604@gmail.com> <1422908625927-10388.post@n3.nabble.com> <54CFE988.2070705@gmail.com> <1422914610217-10392.post@n3.nabble.com>
In-Reply-To: <1422914610217-10392.post@n3.nabble.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

It's already fixed in the master branch. Sorry that we forgot to update 
this before releasing 1.2.0 and caused you trouble...

Cheng

On 2/2/15 2:03 PM, ankits wrote:
> Great, thank you very much. I was confused because this is in the docs:
>
> https://spark.apache.org/docs/1.2.0/sql-programming-guide.html, and on the
> "branch-1.2" branch,
> https://github.com/apache/spark/blob/branch-1.2/docs/sql-programming-guide.md
>
> "Note that if you call schemaRDD.cache() rather than
> sqlContext.cacheTable(...), tables will not be cached using the in-memory
> columnar format, and therefore sqlContext.cacheTable(...) is strongly
> recommended for this use case.".
>
> If this is no longer accurate, i could make a PR to remove it.
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Get-size-of-rdd-in-memory-tp10366p10392.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11397-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 22:18:36 2015
Return-Path: <dev-return-11397-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D95B917D8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 22:18:36 +0000 (UTC)
Received: (qmail 30605 invoked by uid 500); 2 Feb 2015 22:18:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30533 invoked by uid 500); 2 Feb 2015 22:18:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30511 invoked by uid 99); 2 Feb 2015 22:18:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:18:35 +0000
X-ASF-Spam-Status: No, hits=1.3 required=10.0
	tests=FORGED_YAHOO_RCVD,FREEMAIL_ENVFROM_END_DIGIT,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of medale94@yahoo.com designates 98.138.91.138 as permitted sender)
Received: from [98.138.91.138] (HELO nm8-vm3.bullet.mail.ne1.yahoo.com) (98.138.91.138)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:18:30 +0000
Received: from [98.138.100.116] by nm8.bullet.mail.ne1.yahoo.com with NNFMP; 02 Feb 2015 22:18:09 -0000
Received: from [98.138.226.130] by tm107.bullet.mail.ne1.yahoo.com with NNFMP; 02 Feb 2015 22:18:09 -0000
Received: from [127.0.0.1] by smtp217.mail.ne1.yahoo.com with NNFMP; 02 Feb 2015 22:18:09 -0000
X-Yahoo-Newman-Id: 263731.8459.bm@smtp217.mail.ne1.yahoo.com
X-Yahoo-Newman-Property: ymail-3
X-YMail-OSG: fgx.UF0VM1kBiz7932fQRO4UbGjOgO0aOFd78L4i0UEr3oy
 bbRPQhWOC_AuvpP0D1GrHUrhpWcqYS5oS4EeMJsY7JD_9BeonxREIA.UQrPU
 zTT9J07dYgLttBxvqE9BEZHgs57_95Ba5clBIZxETZiyiej2eX.VHM2EShYJ
 oAkfLfSklTcvle.3r3OAAkFKnjjq74MlCjx.YCDTS7sO6vOOf_m4hds.gkPn
 a92TVeNHL7btOCoYih4iKSER8LSbzta86t10pajgC0Fp715NCeS_R_3D4ysg
 ra88QFQyKWLr6JWz428OLllkpTOv7Ya0wsO48d.O7WDFuBy_sgCAKHOIASsz
 _UgOIIs5Pdz4u6xfrG4L4hVcKTKvhtPs_6E5j6TtU_hQjSFak6XbCDxDzDit
 SHaDdCuNVQpLCjgo12u2_VBSf7fen0wCVvTr1v5YT5kIapfJNprAd7pHJDe4
 KusJig2.R2PwaT2geBh3CflRNCwVCFaTRYMEcI7q4rsImVwHhaWtk031WkmN
 B0wLK4T5BJ5U3vDa53auBSJyXSxZ8xsCcs2x0WQZHJQsoSFnbPjjLPKiRBvJ
 QOmhrKzMB3mN4Jbz6LGO2iWcdusmFxPzzyFNl5rPBptGid62Fk61V4A--
X-Yahoo-SMTP: 3cEdYaqswBCV.ogjqp0uR59JyCnf
Message-ID: <54CFF7A0.4010106@yahoo.com>
Date: Mon, 02 Feb 2015 17:18:08 -0500
From: "M. Dale" <medale94@yahoo.com.INVALID>
Reply-To: medale@acm.org
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Additional fix for Avro IncompatibleClassChangeError (SPARK-3039)
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

SPARK-3039 "Spark assembly for new hadoop API (hadoop 2) contains 
avro-mapred for hadoop 1 API"
was marked resolved with Spark 1.2.0 release. However, when I download the
pre-built Spark distro for Hadoop 2.4 and later 
(spark-1.2.0-bin-hadoop2.4.tgz) and run it
against Avro code compiled against Hadoop 2.4/new Hadoop API I still get:

java.lang.IncompatibleClassChangeError: Found interface 
org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
     at 
org.apache.avro.mapreduce.AvroRecordReaderBase.initialize(AvroRecordReaderBase.java:87)
     at 
org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:135)

TaskAttemptContext was a class in the Hadoop 1.x series but became an 
interface
in Hadoop 2.x. Therefore there is a avro-mapred-1.7.6.jar and
avro-mapred-1.7.6-hadoop2.jar. For Hadoop 2.x the 
avro-mapred-1.7.6-hadoop2.jar
is needed.

So it seemed that spark-assembly-1.2.0-hadoop2.4.0.jar still did not contain
the org.apache.avro.mapreduce.AvroRecordReaderBase from 
avro-mapred-1.7.6-hadoop2.jar.

I then downloaded the source code and compiled with:
mvn -Pyarn -Phadoop-2.4 -Phive-0.13.1 -DskipTests clean package

The hadoop-2.4 profile sets:
<avro.mapred.classifier>hadoop2</avro.mapred.classifier> which through
dependency management should pull in the right hadoop2 version:

<dependency>
         <groupId>org.apache.avro</groupId>
         <artifactId>avro-mapred</artifactId>
         <version>${avro.version}</version>
<classifier>${avro.mapred.classifier}</classifier>
         <exclusions>

However, same IncompatibleClassChangeError after replacing the assembly jar.

I had cleaned my local ~/.m2/repository before the build and found that for
avro-mapred both 1.7.5 (no extension, i.e. hadoop1) and 1.7.6 (hadoop2) had
been downloaded. That seemed a likely culprit.

After installing the created jar files into my local repo (had to handcopy
poms/jars for repl/yarn subprojects) and then running:

mvn -Pyarn -Phadoop-2.4 -Phive-0.13.1 -DskipTests dependency:tree 
-Dincludes=org.apache.avro:avro-mapred

Building Spark Project Hive 1.2.0
[INFO] 
------------------------------------------------------------------------
[INFO]
[INFO] --- maven-dependency-plugin:2.4:tree (default-cli) @ 
spark-hive_2.10 ---
[INFO] org.apache.spark:spark-hive_2.10:jar:1.2.0
[INFO] +- org.spark-project.hive:hive-exec:jar:0.13.1a:compile
[INFO] |  \- org.apache.avro:avro-mapred:jar:1.7.5:compile
[INFO] \- org.apache.avro:avro-mapred:jar:hadoop2:1.7.6:compile
[INFO]

Showed that hive-exec brought in the avro-mapred-1.7.5.jar (hadoop1). 
Fix for
spark 1.2.x:

spark-1.2.0/sql/hive/pom.xml

     <dependency>
       <groupId>org.spark-project.hive</groupId>
       <artifactId>hive-exec</artifactId>
       <version>${hive.version}</version>
       <exclusions>
         <exclusion>
           <groupId>commons-logging</groupId>
           <artifactId>commons-logging</artifactId>
         </exclusion>
         <exclusion>
           <groupId>com.esotericsoftware.kryo</groupId>
           <artifactId>kryo</artifactId>
         </exclusion>
         <exclusion>
           <groupId>org.apache.avro</groupId>
           <artifactId>avro-mapred</artifactId>
         </exclusion>
       </exclusions>
     </dependency>

  Just add the last exclusion for avro-mapred (comparison at 
https://github.com/medale/spark/compare/apache:v1.2.1-rc2...medale:avro-hadoop2-v1.2.1-rc2).
  I was able to build and run against that fix with Avro code.

  Fix for current master: https://github.com/apache/spark/pull/4315

  Any feedback much appreciated,
  Markus

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11398-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  2 22:27:15 2015
Return-Path: <dev-return-11398-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7DA9E17DFB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  2 Feb 2015 22:27:15 +0000 (UTC)
Received: (qmail 63165 invoked by uid 500); 2 Feb 2015 22:27:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63091 invoked by uid 500); 2 Feb 2015 22:27:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63080 invoked by uid 99); 2 Feb 2015 22:27:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:27:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of krajah@maprtech.com designates 209.85.192.45 as permitted sender)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 02 Feb 2015 22:27:04 +0000
Received: by mail-qg0-f45.google.com with SMTP id q107so49750423qgd.4
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 14:26:43 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=+XGIXkBGZf0QgV5p67a/VTaMVh6xgjHF5vnlsPzIm0I=;
        b=DXSmatDlYBiej9Dic2X6s06b1bBNm4YR+6iYVx+URNr7d7+G6X1RkUoFi5HqhydZwW
         XyQWiecI2+/bUyNW/Tsk4DUZ8ueMg2eSuEAS9BjUMFS5mPO2zE7cVbNv9MOBdqwDoqmd
         sxTOk4CUoiwOGtklqhvR6w1+cu6WBFAqgFNo4dpdXrToaTU1EIZwFPlSI+oPOnkS6mKr
         X6uGNUaRg0h9PjNgF1xGmTWCz/8jjsXNfA80xant2QffZG8YE90QNPHJdDBQPTtr2ZNa
         bpSv7GXVdViSUPn2pM56LyPle8uiyRRNpQOiKCJ7bgcY/fUXNoAsoBxZXlMHwD0X9w27
         LwpQ==
X-Gm-Message-State: ALoCoQmendVG2CYrBgzHDxgL4V62UUKYjkgabqqtpyvTsbTehvLZ+PtewXdhWGcr9b4u0sYq0sl1
MIME-Version: 1.0
X-Received: by 10.140.104.1 with SMTP id z1mr43914971qge.76.1422916003274;
 Mon, 02 Feb 2015 14:26:43 -0800 (PST)
Received: by 10.140.105.11 with HTTP; Mon, 2 Feb 2015 14:26:43 -0800 (PST)
Date: Mon, 2 Feb 2015 14:26:43 -0800
Message-ID: <CALH4WSMhkLyE98NCRK-6Y39SXi8r8qyumaf+s4i4J34_9UGh7A@mail.gmail.com>
Subject: Performance test for sort shuffle
From: Kannan Rajah <krajah@maprtech.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1135366cebb7af050e22720a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135366cebb7af050e22720a
Content-Type: text/plain; charset=UTF-8

Is there a recommended performance test for sort based shuffle? Something
similar to terasort on Hadoop. I couldn't find one on the spark-perf code
base.

https://github.com/databricks/spark-perf

--
Kannan

--001a1135366cebb7af050e22720a--

From dev-return-11399-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:17:25 2015
Return-Path: <dev-return-11399-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D9C11046E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:17:25 +0000 (UTC)
Received: (qmail 46013 invoked by uid 500); 3 Feb 2015 00:17:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45936 invoked by uid 500); 3 Feb 2015 00:17:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45923 invoked by uid 99); 3 Feb 2015 00:17:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:17:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of daniil.osipov@shazam.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:16:49 +0000
Received: by mail-ie0-f180.google.com with SMTP id rl12so21520956iec.11
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:16:47 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=YjPdPnhmMzjWDKWGAACSYv1LlJDztaXgkBO5R+6X1Zc=;
        b=dXKWZMFzhzaUBgwd6+ebpXnta/Z+DfrcdqGKZLLGdVvg68RUsIC1sJq7jzFj9Dp+98
         8DmXM/gjQt5zvpws4/jHgfRrSCX9OMnCfpZ/APbNyQHvzYL5A5euakwdr02V3kK+yLTm
         B4zCUywAQDnnd06WC2abes8s1oj1zGmIVjz64GHYWViS1ZdGkgdJFerZPJdLEQCMRR1m
         l5Zd6hlVooFaXN2ArsXgjmaghlMgOakn+XxtoJaG35eynPamvfaMwLeFWLtLG9rIEukH
         D1JCbru3MyGkv6pfghTN3h5a4GY01Ru8/5nAhM9WAG9jqsf5QD93Raw21h+dvuj1tBan
         H48w==
X-Gm-Message-State: ALoCoQlQg/5wFlQMZhT4+zelE2cPrcV9mESzk3oowUJHOxOLOZ9tzgQDshl7MZrjGQ25wyUem1NV
MIME-Version: 1.0
X-Received: by 10.42.84.138 with SMTP id m10mr16446890icl.21.1422922607093;
 Mon, 02 Feb 2015 16:16:47 -0800 (PST)
Received: by 10.50.207.67 with HTTP; Mon, 2 Feb 2015 16:16:47 -0800 (PST)
Date: Mon, 2 Feb 2015 16:16:47 -0800
Message-ID: <CA+HOc9Mu0_z6FFRnvnuQmJcWFvKC1cQ2LduenpB_wHZSVAhsgQ@mail.gmail.com>
Subject: [spark-sql] JsonRDD
From: Daniil Osipov <daniil.osipov@shazam.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf3030bcf38a0297050e23fc76
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3030bcf38a0297050e23fc76
Content-Type: text/plain; charset=UTF-8

Hey Spark developers,

Is there a good reason for JsonRDD being a Scala object as opposed to
class? Seems most other RDDs are classes, and can be extended.

The reason I'm asking is that there is a problem with Hive interoperability
with JSON DataFrames where jsonFile generates case sensitive schema, while
Hive expects case insensitive and fails with an exception during
saveAsTable if there are two columns with the same name in different case.

I'm trying to resolve the problem, but that requires me to extend JsonRDD,
which I can't do. Other RDDs are subclass friendly, why is JsonRDD
different?

Dan

--20cf3030bcf38a0297050e23fc76--

From dev-return-11400-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:27:01 2015
Return-Path: <dev-return-11400-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1E8CA104F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:27:01 +0000 (UTC)
Received: (qmail 65643 invoked by uid 500); 3 Feb 2015 00:27:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65574 invoked by uid 500); 3 Feb 2015 00:27:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65552 invoked by uid 99); 3 Feb 2015 00:27:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:27:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:26:35 +0000
Received: by mail-ig0-f177.google.com with SMTP id z20so20808101igj.4
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:25:48 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=16RnoHiZzb9uVYZzktYRcHUU1p38A1CYf4fArXKbvso=;
        b=DyxJJwBHiNNS0iMhzBL/UDBD7b3vAfgcHqvetMBK5f/WdfI3MJ1qpudLYrOYefHZ5l
         wRhm3NTaRdcO3gEXi6sMgLBAYENdhNqrKG1H+wWKU2E9jA28DgjgTfXt+vGrJMC5oFxM
         dhjPE8ek3C/kistcb29lpnuV3xhdId4903e0umh6oa9hCHauh67u6N2h3//ePWWD2RUc
         gMPycJWEBm1f9UVCjfpnprgjqf3HZeGTCMP1aEPqk+h5zEKiizjODVsQRjCnraI8kjyb
         b13Re1Y4NT7wchsoj4RsdD1oxEeKO2qlwa69B/5GqFRCI1s8JTOgq8cD/5F/csMu9Tuk
         Z36Q==
X-Received: by 10.107.167.135 with SMTP id q129mr25633806ioe.23.1422923148735;
 Mon, 02 Feb 2015 16:25:48 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 03 Feb 2015 00:25:47 +0000
Message-ID: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
Subject: Building Spark with Pants
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1142a444d2b9ff050e241c96
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1142a444d2b9ff050e241c96
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Does anyone here have experience with Pants
<http://pantsbuild.github.io/index.html> or interest in trying to build
Spark with it?

Pants has an interesting story. It was born at Twitter to help them build
their Scala, Java, and Python projects as several independent components in
one monolithic repo. (It was inspired by a similar build tool at Google
called blaze.) The mix of languages and sub-projects at Twitter seems
similar to the breakdown we have in Spark.

Pants has an interesting take on how a build system should work, and
Twitter and Foursquare (who use Pants as their primary build tool) claim it
helps enforce better build hygiene and maintainability.

Some relevant talks:

   - Building Scala Hygienically with Pants
   <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
   - The Pants Build Tool at Twitter
   <https://engineering.twitter.com/university/videos/the-pants-build-tool-=
at-twitter>
   - Getting Started with the Pants Build System: Why Pants?
   <https://engineering.twitter.com/university/videos/getting-started-with-=
the-pants-build-system-why-pants>

At some point I may take a shot at converting Spark to use Pants as an
experiment and just see what it=E2=80=99s like.

Nick
=E2=80=8B

--001a1142a444d2b9ff050e241c96--

From dev-return-11401-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:33:41 2015
Return-Path: <dev-return-11401-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EC3B510546
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:33:40 +0000 (UTC)
Received: (qmail 82221 invoked by uid 500); 3 Feb 2015 00:33:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82148 invoked by uid 500); 3 Feb 2015 00:33:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81140 invoked by uid 99); 3 Feb 2015 00:33:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:33:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:32:50 +0000
Received: by mail-qc0-f173.google.com with SMTP id m20so32887245qcx.4
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:30:57 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=tthKyuLKz5Nzd8+FU52EHIHj6CGucM74YCIwOTXdOPU=;
        b=HiLyAp6ZwHwla9/cwbJ8NIWt0k8xM9xW8ZvkVlqA5KXY0Xcsxswg1YB9j+RuSRcaFc
         dZpixaizXwmLnL8V4JuX3rk4nh9NO8B7vi4aJQCh9TBYSWbqX0L2VMheqm5JK+tu6OCf
         PNPbadMZY+6aqJYOiwXCPVWChN8ClWZVysCaUk2cottJ5ztekCIWeELGeTsMP1VbN7Ae
         wIFTNG2u9EtpK/K3dLX1ySWCHjF105fke52aYYzaqGV7bwOFBmwSZLLhh8AQYMIeNnjw
         b47tA5jwfaAD8zL5dtlqcfObEHEMQDYR3BgAdyrOUPADXJQR7pfWFI1WWf2QLryxBQyN
         Hksg==
X-Gm-Message-State: ALoCoQn2jmIG7hmDfubIdon2BCk5I9yfCkQ+Z34MZiZuhjbK4F/ZJSIhDVCAoBTQa3NYmIF3RRB5
X-Received: by 10.140.30.197 with SMTP id d63mr40981259qgd.13.1422923457571;
 Mon, 02 Feb 2015 16:30:57 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Mon, 2 Feb 2015 16:30:37 -0800 (PST)
In-Reply-To: <CA+HOc9Mu0_z6FFRnvnuQmJcWFvKC1cQ2LduenpB_wHZSVAhsgQ@mail.gmail.com>
References: <CA+HOc9Mu0_z6FFRnvnuQmJcWFvKC1cQ2LduenpB_wHZSVAhsgQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 2 Feb 2015 16:30:37 -0800
Message-ID: <CAPh_B=baG9z0i7h9+cW5yuDHiS+ZnOkqkU6cbYS9CGFXTOtSag@mail.gmail.com>
Subject: Re: [spark-sql] JsonRDD
To: Daniil Osipov <daniil.osipov@shazam.com>
Cc: dev <dev@spark.apache.org>, Yin Huai <yhuai@databricks.com>
Content-Type: multipart/alternative; boundary=001a113a80a43b423c050e242f43
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a80a43b423c050e242f43
Content-Type: text/plain; charset=UTF-8

It's bad naming - JsonRDD is actually not an RDD. It is just a set of util
methods.

The case sensitivity issues seem orthogonal, and would be great to be able
to control that with a flag.


On Mon, Feb 2, 2015 at 4:16 PM, Daniil Osipov <daniil.osipov@shazam.com>
wrote:

> Hey Spark developers,
>
> Is there a good reason for JsonRDD being a Scala object as opposed to
> class? Seems most other RDDs are classes, and can be extended.
>
> The reason I'm asking is that there is a problem with Hive interoperability
> with JSON DataFrames where jsonFile generates case sensitive schema, while
> Hive expects case insensitive and fails with an exception during
> saveAsTable if there are two columns with the same name in different case.
>
> I'm trying to resolve the problem, but that requires me to extend JsonRDD,
> which I can't do. Other RDDs are subclass friendly, why is JsonRDD
> different?
>
> Dan
>

--001a113a80a43b423c050e242f43--

From dev-return-11402-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:34:22 2015
Return-Path: <dev-return-11402-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A64BE1054B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:34:22 +0000 (UTC)
Received: (qmail 85239 invoked by uid 500); 3 Feb 2015 00:34:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85171 invoked by uid 500); 3 Feb 2015 00:34:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85159 invoked by uid 99); 3 Feb 2015 00:34:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:34:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.192.44 as permitted sender)
Received: from [209.85.192.44] (HELO mail-qg0-f44.google.com) (209.85.192.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:34:17 +0000
Received: by mail-qg0-f44.google.com with SMTP id l89so50193650qgf.3
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:33:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8REIHL87VcRiMVFtUsxBfSzZEValsQ5d2+YBva9KvS0=;
        b=eGUUpyIokHhwxQwRretf8pzQK8hahLmP8XlgJ0YzJdzxigNbdwbv8hxXdT/0xft3tB
         3q+6y94bfS2rlB7lFxZ1e5UEFxe1cS81NgBiKdzyErXiA7M9r8YgiLqEwY5k08VW6Pxt
         rDOOnjlWC/DU6rLzHznCpsANzE+wm21RCLF33An/Trge6Bw4mWvAwOPkqTABQ47Fn2fw
         VH4mWGFUznvB/f//GMKRxEypxghxvdQw6dCK5xU7Qwn1ZJVja2e7zlNVxhqHeQy5hPex
         knIzcqhMcRdth1qsY7WdiAK3mEM2irsEiMiB7xrUT0SNodRfQ7GCK3SgM0epAZk9t8M8
         dJSQ==
MIME-Version: 1.0
X-Received: by 10.224.2.9 with SMTP id 9mr46961866qah.66.1422923591149; Mon,
 02 Feb 2015 16:33:11 -0800 (PST)
Received: by 10.140.89.133 with HTTP; Mon, 2 Feb 2015 16:33:11 -0800 (PST)
In-Reply-To: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
References: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
Date: Mon, 2 Feb 2015 16:33:11 -0800
Message-ID: <CACkSZy3MAt22t1XQrkfax8g3At6Uea9S7uJMB0ViCy5-pDMu=w@mail.gmail.com>
Subject: Re: Building Spark with Pants
From: Stephen Boesch <javadba@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c22ccc317008050e24370a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c22ccc317008050e24370a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

There is a significant investment in sbt and maven - and they are not at
all likely to be going away. A third build tool?  Note that there is also
the perspective of building within an IDE - which actually works presently
for sbt and with a little bit of tweaking with maven as well.

2015-02-02 16:25 GMT-08:00 Nicholas Chammas <nicholas.chammas@gmail.com>:

> Does anyone here have experience with Pants
> <http://pantsbuild.github.io/index.html> or interest in trying to build
> Spark with it?
>
> Pants has an interesting story. It was born at Twitter to help them build
> their Scala, Java, and Python projects as several independent components =
in
> one monolithic repo. (It was inspired by a similar build tool at Google
> called blaze.) The mix of languages and sub-projects at Twitter seems
> similar to the breakdown we have in Spark.
>
> Pants has an interesting take on how a build system should work, and
> Twitter and Foursquare (who use Pants as their primary build tool) claim =
it
> helps enforce better build hygiene and maintainability.
>
> Some relevant talks:
>
>    - Building Scala Hygienically with Pants
>    <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
>    - The Pants Build Tool at Twitter
>    <
> https://engineering.twitter.com/university/videos/the-pants-build-tool-at=
-twitter
> >
>    - Getting Started with the Pants Build System: Why Pants?
>    <
> https://engineering.twitter.com/university/videos/getting-started-with-th=
e-pants-build-system-why-pants
> >
>
> At some point I may take a shot at converting Spark to use Pants as an
> experiment and just see what it=E2=80=99s like.
>
> Nick
> =E2=80=8B
>

--001a11c22ccc317008050e24370a--

From dev-return-11403-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:42:05 2015
Return-Path: <dev-return-11403-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6B87D105BA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:42:05 +0000 (UTC)
Received: (qmail 6247 invoked by uid 500); 3 Feb 2015 00:41:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6128 invoked by uid 500); 3 Feb 2015 00:41:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6075 invoked by uid 99); 3 Feb 2015 00:41:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:41:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:41:33 +0000
Received: by mail-ig0-f170.google.com with SMTP id l13so21115904iga.1
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:40:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=LVap74Xie+2/7xna+eJ2ga8/coVmbYU5sl0ZPoEmdfI=;
        b=RPo6HCofsWy2nj0i1cdudQ/ToVAv0aneUBC2sUd6fsQOfuMd9Tp8zXWkNfuC1j5bxI
         F/+gEmWsCtiCCn1kiFXOalDjwHjqRKfxBQy439SsAEpPdAoW4LC7ekoO6GbkAHeK1ksz
         FAsQk2TX37xgCkFMUE1exBDaw/mO53u/hrCAeyPc71W0YUfiQo4QQL+0e26MMU0jL2QU
         TC96V2pkEeNkT6zAmQlruERoJLicdK7kS6pQVbK2Net6dYdXZHWp1EsyuJjHt6sGYm+Z
         WaQeAGifSGImj6ziE96c3AlnyEnliWU1P67io/WFXjt7wZDZ0ArD5as8hIpQ+NGJ82a9
         NsKw==
X-Received: by 10.50.32.33 with SMTP id f1mr15111858igi.9.1422924046640; Mon,
 02 Feb 2015 16:40:46 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
 <CACkSZy3MAt22t1XQrkfax8g3At6Uea9S7uJMB0ViCy5-pDMu=w@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 03 Feb 2015 00:40:46 +0000
Message-ID: <CAOhmDzebSdPA_WOzq=QaehUn2iUAnbC0nGfQ0Np5C79PTUNxPg@mail.gmail.com>
Subject: Re: Building Spark with Pants
To: Stephen Boesch <javadba@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b10ce3d57b02d050e2452c8
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10ce3d57b02d050e2452c8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I'm asking from an experimental standpoint; this is not happening anytime
soon.

Of course, if the experiment turns out very well, Pants would replace both
sbt and Maven (like it has at Twitter, for example). Pants also works with
IDEs <http://pantsbuild.github.io/index.html#using-pants-with>.

On Mon Feb 02 2015 at 4:33:11 PM Stephen Boesch <javadba@gmail.com> wrote:

> There is a significant investment in sbt and maven - and they are not at
> all likely to be going away. A third build tool?  Note that there is also
> the perspective of building within an IDE - which actually works presentl=
y
> for sbt and with a little bit of tweaking with maven as well.
>
> 2015-02-02 16:25 GMT-08:00 Nicholas Chammas <nicholas.chammas@gmail.com>:
>
>> Does anyone here have experience with Pants
>>
> <http://pantsbuild.github.io/index.html> or interest in trying to build
>
>
>> Spark with it?
>>
>> Pants has an interesting story. It was born at Twitter to help them buil=
d
>> their Scala, Java, and Python projects as several independent components
>> in
>> one monolithic repo. (It was inspired by a similar build tool at Google
>> called blaze.) The mix of languages and sub-projects at Twitter seems
>> similar to the breakdown we have in Spark.
>>
>> Pants has an interesting take on how a build system should work, and
>> Twitter and Foursquare (who use Pants as their primary build tool) claim
>> it
>> helps enforce better build hygiene and maintainability.
>>
>> Some relevant talks:
>>
>>    - Building Scala Hygienically with Pants
>>    <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
>>    - The Pants Build Tool at Twitter
>>    <
>> https://engineering.twitter.com/university/videos/the-pants-build-tool-a=
t-twitter
>> >
>>    - Getting Started with the Pants Build System: Why Pants?
>>    <
>> https://engineering.twitter.com/university/videos/getting-started-with-t=
he-pants-build-system-why-pants
>> >
>
>
>>
>> At some point I may take a shot at converting Spark to use Pants as an
>> experiment and just see what it=E2=80=99s like.
>>
>> Nick
>> =E2=80=8B
>>
>

--047d7b10ce3d57b02d050e2452c8--

From dev-return-11404-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 00:51:45 2015
Return-Path: <dev-return-11404-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 020481063A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 00:51:45 +0000 (UTC)
Received: (qmail 25838 invoked by uid 500); 3 Feb 2015 00:51:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25761 invoked by uid 500); 3 Feb 2015 00:51:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25710 invoked by uid 99); 3 Feb 2015 00:51:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:51:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.181 as permitted sender)
Received: from [209.85.223.181] (HELO mail-ie0-f181.google.com) (209.85.223.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 00:51:40 +0000
Received: by mail-ie0-f181.google.com with SMTP id rd18so12461264iec.12
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 16:50:34 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=3sf9AAm6Sw7XjATQU/ehYjgfgVHIkVhI48fMXF+ToAc=;
        b=LoCk4cxrUkhMoC9uRxpHCv722z27j+9fQHmQ2X+zhSrQGTkok0Dil6cyZg4AG9disR
         1OzZNmOb+bYtQ/i9KSzyKV20pmu3MFkbOExmEB9qJtnhLRKinjANCuf9kJ1CoXf6QJy8
         9oSN32vJQSqAQOeq4OKEevjqsx3ZlQZpHBEZg8N02Zvr16URnWnfphpJFUEK/xREGNqb
         ST4EYyn8L9uN/0q8FD1n/GL5h0nALOn4MorZQr7hUxCPm5HMFH4gTGZGp+blt4hHD0HX
         aJ/h6lw4VykNl1YHLgYR/x8CkhYDxaNY7UUSqQ/GSe9JARF8/dUoGL6Oekc2Sh+Rqiot
         oonQ==
X-Received: by 10.42.88.9 with SMTP id a9mr21544765icm.34.1422924634857; Mon,
 02 Feb 2015 16:50:34 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
 <CACkSZy3MAt22t1XQrkfax8g3At6Uea9S7uJMB0ViCy5-pDMu=w@mail.gmail.com> <CAOhmDzebSdPA_WOzq=QaehUn2iUAnbC0nGfQ0Np5C79PTUNxPg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 03 Feb 2015 00:50:34 +0000
Message-ID: <CAOhmDzfG7GABey-tJG-AgOQuWWXbECdk1j-ZQakvYO=x2gPg=Q@mail.gmail.com>
Subject: Re: Building Spark with Pants
To: Stephen Boesch <javadba@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=90e6ba61486e6729d8050e2475c8
X-Virus-Checked: Checked by ClamAV on apache.org

--90e6ba61486e6729d8050e2475c8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

To reiterate, I'm asking from an experimental perspective. I'm not
proposing we change Spark to build with Pants or anything like that.

I'm interested in trying Pants out and I'm wondering if anyone else shares
my interest or already has experience with Pants that they can share.

On Mon Feb 02 2015 at 4:40:45 PM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I'm asking from an experimental standpoint; this is not happening anytime
> soon.
>
> Of course, if the experiment turns out very well, Pants would replace bot=
h
> sbt and Maven (like it has at Twitter, for example). Pants also works
> with IDEs <http://pantsbuild.github.io/index.html#using-pants-with>.
>
> On Mon Feb 02 2015 at 4:33:11 PM Stephen Boesch <javadba@gmail.com> wrote=
:
>
>> There is a significant investment in sbt and maven - and they are not at
>> all likely to be going away. A third build tool?  Note that there is als=
o
>> the perspective of building within an IDE - which actually works present=
ly
>> for sbt and with a little bit of tweaking with maven as well.
>>
>> 2015-02-02 16:25 GMT-08:00 Nicholas Chammas <nicholas.chammas@gmail.com>=
:
>>
>>> Does anyone here have experience with Pants
>>>
>> <http://pantsbuild.github.io/index.html> or interest in trying to build
>>
>>
>>> Spark with it?
>>>
>>> Pants has an interesting story. It was born at Twitter to help them bui=
ld
>>> their Scala, Java, and Python projects as several independent component=
s
>>> in
>>> one monolithic repo. (It was inspired by a similar build tool at Google
>>> called blaze.) The mix of languages and sub-projects at Twitter seems
>>> similar to the breakdown we have in Spark.
>>>
>>> Pants has an interesting take on how a build system should work, and
>>> Twitter and Foursquare (who use Pants as their primary build tool) clai=
m
>>> it
>>> helps enforce better build hygiene and maintainability.
>>>
>>> Some relevant talks:
>>>
>>>    - Building Scala Hygienically with Pants
>>>    <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
>>>    - The Pants Build Tool at Twitter
>>>    <https://engineering.twitter.com/university/videos/the-
>>> pants-build-tool-at-twitter>
>>>    - Getting Started with the Pants Build System: Why Pants?
>>>    <https://engineering.twitter.com/university/videos/getting-
>>> started-with-the-pants-build-system-why-pants>
>>
>>
>>>
>>> At some point I may take a shot at converting Spark to use Pants as an
>>> experiment and just see what it=E2=80=99s like.
>>>
>>> Nick
>>> =E2=80=8B
>>>
>>

--90e6ba61486e6729d8050e2475c8--

From dev-return-11405-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 03:38:19 2015
Return-Path: <dev-return-11405-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5BE7D10B78
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 03:38:19 +0000 (UTC)
Received: (qmail 66027 invoked by uid 500); 3 Feb 2015 03:38:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65913 invoked by uid 500); 3 Feb 2015 03:38:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65890 invoked by uid 99); 3 Feb 2015 03:38:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 03:38:18 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.54 as permitted sender)
Received: from [209.85.218.54] (HELO mail-oi0-f54.google.com) (209.85.218.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 03:37:52 +0000
Received: by mail-oi0-f54.google.com with SMTP id v63so47300732oia.13
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 19:37:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=9eydhHu8EkLQSZsqHCLrmRwFjD3/HZCsFG9Jy1ueJjU=;
        b=eapeY6gY5QqxllDHQx30NwnhX8aBXlRGgfhraMXj9FS8EsE3ouSdTnsmtJiu8Fceob
         3Sg30jkH7H88Cv5ed2YPKhmCFjvbSBdrayq1WkS3yg4VASrd+rt863gfNnXHTLD3sCEH
         cDCmInFW83U61nlagLDFrCBBcLUGf+HpNdwj1SzAjrjepMHiFKQJWnsk+ZrAvj6hZAN1
         +njq+4VOcrjoT4v/0Z28gMVnDZ+00vwXkHNFPdVN1CtcqVc19fuFpnWQ2JS9u994KBik
         AxsEGdL6PLQYQqp51SUl+usFqBCTHJ9yOIF/pPvUtMvkbYRqlV9sJkhKT4wfmiQ3rNIw
         xwUQ==
MIME-Version: 1.0
X-Received: by 10.182.33.138 with SMTP id r10mr14072848obi.67.1422934670688;
 Mon, 02 Feb 2015 19:37:50 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 19:37:50 -0800 (PST)
Date: Mon, 2 Feb 2015 19:37:50 -0800
Message-ID: <CABPQxsuBD5rVsQPT4NiQQG3LDkqRf5-6yv_YnmwsO5_RZJvTRw@mail.gmail.com>
Subject: Temporary jenkins issue
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

I made a change to the Jenkins configuration that caused most builds
to fail (attempting to enable a new plugin), I've reverted the change
effective about 10 minutes ago.

If you've seen recent build failures like below, this was caused by
that change. Sorry about that.

====
ERROR: Publisher
com.google.jenkins.flakyTestHandler.plugin.JUnitFlakyResultArchiver
aborted due to exception
java.lang.NoSuchMethodError:
hudson.model.AbstractBuild.getTestResultAction()Lhudson/tasks/test/AbstractTestResultAction;
at com.google.jenkins.flakyTestHandler.plugin.FlakyTestResultAction.<init>(FlakyTestResultAction.java:78)
at com.google.jenkins.flakyTestHandler.plugin.JUnitFlakyResultArchiver.perform(JUnitFlakyResultArchiver.java:89)
at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:20)
at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:770)
at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:734)
at hudson.model.Build$BuildExecution.post2(Build.java:183)
at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:683)
at hudson.model.Run.execute(Run.java:1784)
at hudson.matrix.MatrixRun.run(MatrixRun.java:146)
at hudson.model.ResourceController.execute(ResourceController.java:89)
at hudson.model.Executor.run(Executor.java:240)
====

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11406-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 04:52:03 2015
Return-Path: <dev-return-11406-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 989F310DA5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 04:52:03 +0000 (UTC)
Received: (qmail 44076 invoked by uid 500); 3 Feb 2015 04:52:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43996 invoked by uid 500); 3 Feb 2015 04:52:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43982 invoked by uid 99); 3 Feb 2015 04:52:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:52:02 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.51 as permitted sender)
Received: from [209.85.218.51] (HELO mail-oi0-f51.google.com) (209.85.218.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:51:58 +0000
Received: by mail-oi0-f51.google.com with SMTP id x69so47525486oia.10
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 20:50:53 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Ti740YTcD0+0aYGF4BUd1VFrNjzDCqn0HhlgX6QhpbM=;
        b=UVCc4KXoRWxPQI0Ug3U39vkAIC7avMvEvtnMaVZYZNGQzIVd5Um8LkgtIOti72LLuR
         2lABYgms7uPlWJy3Cd9LDAn5mKcqKVnbuQ7H5ax7Upw1yRDgpY+Kh7QSmOI3iMSlrOhf
         0H4fS/N6JdVn9KQbRkt6GnqpXCVAOQYgd+v4hkWiB6gm0KuhQgEGqRUD6OyKPN+O6B8O
         9jS1aQ8M9W+IkjE5CgFV4RpkDvv82brfTUGhLWVv1YSJxJ1IrAM/j13hhQTdEhQXo2LW
         TNEEIeh7DnYFDvkmjm05lvawMRl72u5oBIdV5AdEAZCu8BpdWpQES7+YLib/dbmOuyvH
         fDsA==
MIME-Version: 1.0
X-Received: by 10.182.27.241 with SMTP id w17mr13922647obg.14.1422939052918;
 Mon, 02 Feb 2015 20:50:52 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 20:50:52 -0800 (PST)
In-Reply-To: <8B1DF58E-2FCA-425E-A8D9-9318BD6F5D66@gmail.com>
References: <CABPQxsuvbeCK53qqggYfK0PsuhnmNgprHKf3v7ZT85eKOcKVBg@mail.gmail.com>
	<1422734234030-10370.post@n3.nabble.com>
	<8B1DF58E-2FCA-425E-A8D9-9318BD6F5D66@gmail.com>
Date: Mon, 2 Feb 2015 20:50:52 -0800
Message-ID: <CABPQxssXRcCMH01Wej8OgjX4Ou-xqdqDgU9OrPKqygLi4WfB6A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC2)
From: Patrick Wendell <pwendell@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: MartinWeindel <martin.weindel@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

The windows issue reported only affects actually running Spark on
Windows (not job submission). However, I agree it's worth cutting a
new RC. I'm going to cancel this vote and propose RC3 with a single
additional patch. Let's try to vote that through so we can ship Spark
1.2.1.

- Patrick

On Sat, Jan 31, 2015 at 7:36 PM, Matei Zaharia <matei.zaharia@gmail.com> wrote:
> This looks like a pretty serious problem, thanks! Glad people are testing on Windows.
>
> Matei
>
>> On Jan 31, 2015, at 11:57 AM, MartinWeindel <martin.weindel@gmail.com> wrote:
>>
>> FYI: Spark 1.2.1rc2 does not work on Windows!
>>
>> On creating a Spark context you get following log output on my Windows
>> machine:
>> INFO  org.apache.spark.SparkEnv:59 - Registering BlockManagerMaster
>> ERROR org.apache.spark.util.Utils:75 - Failed to create local root dir in
>> C:\Users\mweindel\AppData\Local\Temp\. Ignoring this directory.
>> ERROR org.apache.spark.storage.DiskBlockManager:75 - Failed to create any
>> local dir.
>>
>> I have already located the cause. A newly added function chmod700() in
>> org.apache.util.Utils uses functionality which only works on a Unix file
>> system.
>>
>> See also pull request [https://github.com/apache/spark/pull/4299] for my
>> suggestion how to resolve the issue.
>>
>> Best regards,
>>
>> Martin Weindel
>>
>>
>>
>> --
>> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-2-1-RC2-tp10317p10370.html
>> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11407-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 04:53:39 2015
Return-Path: <dev-return-11407-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EA23510DC1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 04:53:39 +0000 (UTC)
Received: (qmail 48265 invoked by uid 500); 3 Feb 2015 04:53:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48187 invoked by uid 500); 3 Feb 2015 04:53:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47523 invoked by uid 99); 3 Feb 2015 04:53:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:53:26 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:53:22 +0000
Received: by mail-ob0-f171.google.com with SMTP id gq1so11701189obb.2
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 20:51:32 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=4elgFNth55VVTx3E29cuyMaHZHQ1K2/oAsPHK30rRKU=;
        b=QWm4V4gqwQtOxuk2+IQ6ql2vLNhApjgX2Ql47uq7ygRxq8uInl52H+tP9XO83YilYv
         2N0CHWD+x6sqqxdjZOtvkSQNubKKObr1K/QaRD6AZGzoYScve5NK2gZKqDuw1LbYEzD0
         HQs6xWk7iYC7k6nuFHhAK6OR6PI2vSr14cp7lIlKM5lehDnuF/MPgd7S2P0G6YPB+m36
         voe8uv3dDKSE4mQ3b2LYZ5gp6nO06wR5lt6yW87SZO0TMSB613CWGdmUVImQeUF41VEY
         mlWgX+YmMwg33nlt3aVhOpr7vCRTfwrD34OoxzU4M7eGbycOZlulL49Fbn8dzgAV+MhK
         T0tw==
MIME-Version: 1.0
X-Received: by 10.60.176.34 with SMTP id cf2mr14034926oec.52.1422939092259;
 Mon, 02 Feb 2015 20:51:32 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 20:51:32 -0800 (PST)
Date: Mon, 2 Feb 2015 20:51:32 -0800
Message-ID: <CABPQxsu3wnMiUrDSMkLm5GDN=GdZiGFWT5wV18-MpU7Z72FT-Q@mail.gmail.com>
Subject: [RESULT] [VOTE] Release Apache Spark 1.2.1 (RC2)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

This is cancelled in favor of RC2.

On Mon, Feb 2, 2015 at 8:50 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> The windows issue reported only affects actually running Spark on
> Windows (not job submission). However, I agree it's worth cutting a
> new RC. I'm going to cancel this vote and propose RC3 with a single
> additional patch. Let's try to vote that through so we can ship Spark
> 1.2.1.
>
> - Patrick
>
> On Sat, Jan 31, 2015 at 7:36 PM, Matei Zaharia <matei.zaharia@gmail.com> wrote:
>> This looks like a pretty serious problem, thanks! Glad people are testing on Windows.
>>
>> Matei
>>
>>> On Jan 31, 2015, at 11:57 AM, MartinWeindel <martin.weindel@gmail.com> wrote:
>>>
>>> FYI: Spark 1.2.1rc2 does not work on Windows!
>>>
>>> On creating a Spark context you get following log output on my Windows
>>> machine:
>>> INFO  org.apache.spark.SparkEnv:59 - Registering BlockManagerMaster
>>> ERROR org.apache.spark.util.Utils:75 - Failed to create local root dir in
>>> C:\Users\mweindel\AppData\Local\Temp\. Ignoring this directory.
>>> ERROR org.apache.spark.storage.DiskBlockManager:75 - Failed to create any
>>> local dir.
>>>
>>> I have already located the cause. A newly added function chmod700() in
>>> org.apache.util.Utils uses functionality which only works on a Unix file
>>> system.
>>>
>>> See also pull request [https://github.com/apache/spark/pull/4299] for my
>>> suggestion how to resolve the issue.
>>>
>>> Best regards,
>>>
>>> Martin Weindel
>>>
>>>
>>>
>>> --
>>> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-2-1-RC2-tp10317p10370.html
>>> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11408-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 04:57:56 2015
Return-Path: <dev-return-11408-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5907110DED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 04:57:56 +0000 (UTC)
Received: (qmail 52893 invoked by uid 500); 3 Feb 2015 04:57:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52818 invoked by uid 500); 3 Feb 2015 04:57:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52805 invoked by uid 99); 3 Feb 2015 04:57:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:57:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:57:30 +0000
Received: by mail-oi0-f47.google.com with SMTP id a141so47620662oig.6
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 20:57:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=viuFVK3supwqBUszE0nPrKLqFJwFk26QJ298nhNEsSc=;
        b=bUX0i2f48nvN3h6bFN0nsF79mrHIS3CIa4fB8EFmlawDg71ikXlFkny6MXAUhtC3K9
         +naahVzcKy4P8mcV3Mce6DONqDy/zgzOb0afIaOkOMBjACtvxWtmm3lcp9harDpRfV1r
         e6qcHtCdnsqohOzLgs78NmBEjIJguUcvRWbcs9OwjiLnUvkG2tVpjYCL352jFJZFTraG
         V+DMBBKqKBeAAcTKi0SZdG+fbIrV8prDWRzae9DA3yd3GYoZXC4+LSXlXwaBYW/yO09K
         qbMF8kO+yLeyliY9TPv023/L02tX7zm2M6XxePoxIeZdPTYfk9pXdwNqxt8R6megS50m
         ZDCg==
MIME-Version: 1.0
X-Received: by 10.182.215.163 with SMTP id oj3mr14275853obc.49.1422939448471;
 Mon, 02 Feb 2015 20:57:28 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Mon, 2 Feb 2015 20:57:28 -0800 (PST)
Date: Mon, 2 Feb 2015 20:57:28 -0800
Message-ID: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 1.2.1 (RC3)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Please vote on releasing the following candidate as Apache Spark version 1.2.1!

The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.2.1-rc3/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1065/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/

Changes from rc2:
A single patch fixing a windows issue.

Please vote on releasing this package as Apache Spark 1.2.1!

The vote is open until Friday, February 06, at 05:00 UTC and passes
if a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.2.1
[ ] -1 Do not release this package because ...

For a list of fixes in this release, see http://s.apache.org/Mpn.

To learn more about Apache Spark, please see
http://spark.apache.org/

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11409-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 04:59:12 2015
Return-Path: <dev-return-11409-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6DB8610DFD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 04:59:12 +0000 (UTC)
Received: (qmail 54884 invoked by uid 500); 3 Feb 2015 04:59:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54801 invoked by uid 500); 3 Feb 2015 04:59:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54786 invoked by uid 99); 3 Feb 2015 04:59:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:59:09 +0000
X-ASF-Spam-Status: No, hits=-0.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rikima3132@gmail.com designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 04:59:03 +0000
Received: by mail-la0-f49.google.com with SMTP id gf13so47808071lab.8
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 20:56:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=PWmqbKgET8CZ+cCe30/HTcL4+0a+p4YOzqcGRLJkmOM=;
        b=cE8MUEemdMkG3Dnv58UMLDydEzmQULHhEc87Mx5oAqmwtLgO6YpkZNZ+uJ2I8OGAab
         IbLfNULR44Uj/EurnRuG60Eimg5BSr0LJ7kSGasM8yseCzAynYE+MNcgCq5qFzfwqKlP
         qRHaP5d1EFc4/uMt2LS4ns8/FUG/N5RfenPGRGuXTLbMBPFuz4I2LtMFx2oi1FWcrvtM
         aqLQPID+NLGwEET5rOMfA1V15jiTprtn7DI15aXSQg1+aZ9yWke+mkgi0IGv7KnpvSJl
         YJhRMIfGZiZ6BoqGfNahNFcizMsr78rjMc83K1Huq4ZJf63YtNK8i3/zLEMUeVXs02w8
         VdTg==
MIME-Version: 1.0
X-Received: by 10.112.235.194 with SMTP id uo2mr22323312lbc.57.1422939387671;
 Mon, 02 Feb 2015 20:56:27 -0800 (PST)
Received: by 10.114.24.234 with HTTP; Mon, 2 Feb 2015 20:56:27 -0800 (PST)
Date: Tue, 3 Feb 2015 13:56:27 +0900
Message-ID: <CAPa0eF7F_Ru6Wough8Rs-Ns7ocbwnVoFeQd=X6O4CaYL66o72w@mail.gmail.com>
Subject: IDF for ml pipeline
From: masaki rikitoku <rikima3132@gmail.com>
To: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all

I am trying the ml pipeline for text classfication now.

recently, i succeed to execute the pipeline processing in ml packages,
which consist of the original Japanese tokenizer, hashingTF,
logisticRegression.

then,  i failed to  executed the pipeline with idf in mllib package directly.

To use the idf feature in ml package,
do i have to implement the wrapper for idf in ml package like the hashingTF?

best

Masaki Rikitoku

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11410-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 05:49:23 2015
Return-Path: <dev-return-11410-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47CEF10F69
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 05:49:23 +0000 (UTC)
Received: (qmail 34869 invoked by uid 500); 3 Feb 2015 05:49:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34792 invoked by uid 500); 3 Feb 2015 05:49:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34778 invoked by uid 99); 3 Feb 2015 05:49:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 05:49:19 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of xuelincao2014@gmail.com designates 209.85.216.54 as permitted sender)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 05:49:13 +0000
Received: by mail-qa0-f54.google.com with SMTP id w8so32512087qac.13
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 21:48:53 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=blPVYSaZLoNc29jTUgEmWlJSvxwHgKE0DmJp8VwQn6U=;
        b=fEC/zjlFheWaOL8b1QUC+V/GEsN1vR2+Ye57JNYwwYE8YGE7hCbtTjzdBLSdfZqiyI
         FGQBATsw+orOyS+WjOWOyV2X0L8xbPHmSTLO0JDcHqmYBP0ihyqq0Aqc6ulb52i6i6oe
         JKU9PBiJImY179UbmpFKjGgKN4/ByegdZRHwFHWaPRtGJ/pGaINSgQhn134AvQYtP0SC
         dfdWgDUDkHufYNStvPzyud/6RTNUFtExXgujJ5ohg12InCsIWoGtp8nlA/SLOJKtnAie
         0MnIKxqb4p2+hRy9Bd8WBFJNh9HTAtCwtkreM0nfkn3R2IBu/PvXLEHVIH2+vnieLZcX
         WsaQ==
MIME-Version: 1.0
X-Received: by 10.224.79.82 with SMTP id o18mr49256419qak.3.1422942533496;
 Mon, 02 Feb 2015 21:48:53 -0800 (PST)
Received: by 10.140.81.42 with HTTP; Mon, 2 Feb 2015 21:48:53 -0800 (PST)
Date: Tue, 3 Feb 2015 13:48:53 +0800
Message-ID: <CABjPPTQB1NRu5Xhk6rLC4e=FoS=i_Y+P70=4TiGf2g7c+TSzpA@mail.gmail.com>
Subject: Can spark provide an option to start reduce stage early?
From: Xuelin Cao <xuelincao2014@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdcad5e3eb391050e28a080
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdcad5e3eb391050e28a080
Content-Type: text/plain; charset=UTF-8

In hadoop MR, there is an option *mapred.reduce.slowstart.completed.maps*

which can be used to start reducer stage when X% mappers are completed. By
doing this, the data shuffling process is able to parallel with the map
process.

In a large multi-tenancy cluster, this option is usually tuned off. But, in
some cases, turn on the option could accelerate some high priority jobs.

Will spark provide similar option?

--047d7bdcad5e3eb391050e28a080--

From dev-return-11411-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 06:36:56 2015
Return-Path: <dev-return-11411-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8EC031730D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 06:36:56 +0000 (UTC)
Received: (qmail 18592 invoked by uid 500); 3 Feb 2015 06:36:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18520 invoked by uid 500); 3 Feb 2015 06:36:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18229 invoked by uid 99); 3 Feb 2015 06:36:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 06:36:53 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ksankar42@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 06:36:23 +0000
Received: by mail-pa0-f54.google.com with SMTP id eu11so92332936pac.13
        for <dev@spark.apache.org>; Mon, 02 Feb 2015 22:34:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Rx4flxQo2N2IKs4C6wvT8i+gREee6LIWf1NvLW0IwM0=;
        b=SsTAggGSWKrBQ5Dq/l5EtlqRexJEelGpu6jqqeMRr+u4rBkySn+1xvX315pCnFtZ7V
         hJ+d9WFcLdta/w4DkG6CYAzs/Oe1+4Yfb0OgOqw/L5a5rHHE2h0gbgTq+jwRh4ybmwT7
         GAhdmC/huVWBlK3n+cZ8ESKAgbio9GhIht8umrbI+TdScSJyTJ1WxizOvACMcFzF5USK
         euz2W1Jf5KlsbjFQ7Zl1TGKrvNqAvlLvHBLJzQpiakPKC0A+lsne5Z2QjnMkxQeGpFf1
         H9SSjovu7V/u19WWtu/nVQJ/dWz3zThrOH+cqHqCYhLunjoEHHq0b0k9qKIgxj5cwhj9
         QYWA==
MIME-Version: 1.0
X-Received: by 10.66.63.106 with SMTP id f10mr35574259pas.0.1422945245849;
 Mon, 02 Feb 2015 22:34:05 -0800 (PST)
Received: by 10.70.48.203 with HTTP; Mon, 2 Feb 2015 22:34:05 -0800 (PST)
In-Reply-To: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
Date: Mon, 2 Feb 2015 22:34:05 -0800
Message-ID: <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
From: Krishna Sankar <ksankar42@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136b100e9edbe050e29411b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136b100e9edbe050e29411b
Content-Type: text/plain; charset=UTF-8

+1 (non-binding, of course)

1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min
     mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
-Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
2. Tested pyspark, mlib - running as well as compare results with 1.1.x &
1.2.0
2.1. statistics (min,max,mean,Pearson,Spearman) OK
2.2. Linear/Ridge/Laso Regression OK
2.3. Decision Tree, Naive Bayes OK
2.4. KMeans OK
       Center And Scale OK
       Fixed : org.apache.spark.SparkException in zip !
2.5. rdd operations OK
      State of the Union Texts - MapReduce, Filter,sortByKey (word count)
2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
       Model evaluation/optimization (rank, numIter, lmbda) with itertools
OK
3. Scala - MLLib
3.1. statistics (min,max,mean,Pearson,Spearman) OK
3.2. LinearRegressionWIthSGD OK
3.3. Decision Tree OK
3.4. KMeans OK
3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK

Cheers
<k/>


On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Please vote on releasing the following candidate as Apache Spark version
> 1.2.1!
>
> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
>
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1065/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
>
> Changes from rc2:
> A single patch fixing a windows issue.
>
> Please vote on releasing this package as Apache Spark 1.2.1!
>
> The vote is open until Friday, February 06, at 05:00 UTC and passes
> if a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.2.1
> [ ] -1 Do not release this package because ...
>
> For a list of fixes in this release, see http://s.apache.org/Mpn.
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1136b100e9edbe050e29411b--

From dev-return-11412-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 07:53:50 2015
Return-Path: <dev-return-11412-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6670D17540
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 07:53:50 +0000 (UTC)
Received: (qmail 36063 invoked by uid 500); 3 Feb 2015 07:53:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35995 invoked by uid 500); 3 Feb 2015 07:53:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35973 invoked by uid 99); 3 Feb 2015 07:53:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 07:53:46 +0000
X-ASF-Spam-Status: No, hits=-1.0 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [157.193.49.126] (HELO smtp2.ugent.be) (157.193.49.126)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 07:53:21 +0000
Received: from localhost (mcheck3.ugent.be [157.193.71.89])
	by smtp2.ugent.be (Postfix) with ESMTP id DEB5D12C2AA;
	Tue,  3 Feb 2015 08:52:59 +0100 (CET)
X-Virus-Scanned: by UGent DICT
Received: from smtp2.ugent.be ([IPv6:::ffff:157.193.49.126])
	by localhost (mcheck3.UGent.be [::ffff:157.193.43.11]) (amavisd-new, port 10024)
	with ESMTP id MC-TuiQQq6N3; Tue,  3 Feb 2015 08:52:59 +0100 (CET)
Received: from [157.193.44.242] (gast044b.ugent.be [157.193.44.242])
	(Authenticated sender: ehiggs)
	by smtp2.ugent.be (Postfix) with ESMTPSA id 51AE912C27F;
	Tue,  3 Feb 2015 08:52:59 +0100 (CET)
Message-ID: <54D07E5B.1080200@ugent.be>
Date: Tue, 03 Feb 2015 08:52:59 +0100
From: Ewan Higgs <ewan.higgs@ugent.be>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.3.0
MIME-Version: 1.0
To: Kannan Rajah <krajah@maprtech.com>, dev@spark.apache.org
Subject: Re: Performance test for sort shuffle
References: <CALH4WSMhkLyE98NCRK-6Y39SXi8r8qyumaf+s4i4J34_9UGh7A@mail.gmail.com>
In-Reply-To: <CALH4WSMhkLyE98NCRK-6Y39SXi8r8qyumaf+s4i4J34_9UGh7A@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Miltered: at jchkm3 with ID 54D07E5B.000 by Joe's j-chkmail (http://helpdesk.ugent.be/email/)!
X-j-chkmail-Enveloppe: 54D07E5B.000 from gast044b.ugent.be/gast044b.ugent.be/157.193.44.242/[157.193.44.242]/<ewan.higgs@ugent.be>
X-j-chkmail-Score: MSGID : 54D07E5B.000 on smtp2.ugent.be : j-chkmail score : . : R=. U=. O=. B=0.000 -> S=0.000
X-j-chkmail-Status: Ham
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Kannan,
I have a branch here:

https://github.com/ehiggs/spark/tree/terasort

The code is in the examples. I don't do any fancy partitioning so it 
could be made quicker, I'm sure. But it should be a good baseline.

I have a WIP PR for spark-perf but I'm having trouble building it 
there[1]. I put it on the back burner until someone can get back to me 
on it.

Yours,
Ewan Higgs

[1] 
http://apache-spark-developers-list.1001551.n3.nabble.com/SparkSpark-perf-terasort-WIP-branch-tt10105.html

On 02/02/15 23:26, Kannan Rajah wrote:
> Is there a recommended performance test for sort based shuffle? Something
> similar to terasort on Hadoop. I couldn't find one on the spark-perf code
> base.
>
> https://github.com/databricks/spark-perf
>
> --
> Kannan
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11413-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 08:00:59 2015
Return-Path: <dev-return-11413-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9B10317582
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 08:00:59 +0000 (UTC)
Received: (qmail 45428 invoked by uid 500); 3 Feb 2015 08:00:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45358 invoked by uid 500); 3 Feb 2015 08:00:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44174 invoked by uid 99); 3 Feb 2015 07:59:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 07:59:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wangfei1@huawei.com designates 119.145.14.64 as permitted sender)
Received: from [119.145.14.64] (HELO szxga01-in.huawei.com) (119.145.14.64)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 07:59:34 +0000
Received: from 172.24.2.119 (EHLO szxeml428-hub.china.huawei.com) ([172.24.2.119])
	by szxrg01-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id CJA03328;
	Tue, 03 Feb 2015 15:53:13 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml428-hub.china.huawei.com
 (10.82.67.183) with Microsoft SMTP Server id 14.3.158.1; Tue, 3 Feb 2015
 15:53:06 +0800
Message-ID: <54D07E61.7060801@huawei.com>
Date: Tue, 3 Feb 2015 15:53:05 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Jenkins install reference
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, all
   we want to set up a CI env for spark in our team, is there any reference of how to install jenkins over spark?
   Thanks

Fei


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11414-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 09:13:13 2015
Return-Path: <dev-return-11414-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB69217763
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 09:13:13 +0000 (UTC)
Received: (qmail 58128 invoked by uid 500); 3 Feb 2015 09:13:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58055 invoked by uid 500); 3 Feb 2015 09:13:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58041 invoked by uid 99); 3 Feb 2015 09:13:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 09:13:13 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 09:13:08 +0000
Received: by mail-we0-f172.google.com with SMTP id q59so43635958wes.3
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 01:12:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=7fi5S2Nn/t3aXxED/Kcw1PRIGP4DGN2C70oUzt27Fro=;
        b=Y+wfPLP1Jt1Fex53I91KKjdH2xxP/tuAOJ8wXUYnNubxElzydHh6UAscTohD9lxTN1
         Vk3Daf9k9uBAlRmZgB5sJ9Mrq1V/7/OTRVPs9wlXlSUleLIgHWZDHEu7HjDjAyn5VbVb
         z3dIniZ4wXoZ5yhFOPlL0Aw8UJu3RJVwvwGioL2GXTp2m4sApsiPwyBShW7q5o78N3lU
         +ioBo9j3PrGA+IQtggWDytcqVt7H6LbgI1YIMK9nvQLL8Li7FGGLb7bfY6IP9uL/XWvP
         BebsT2RgsdRQOZQTAjF3R4nepzcvf6tcISOeOIsnbqOjh+e9LPuXUuTqC1IBf9EB23UG
         N2bA==
MIME-Version: 1.0
X-Received: by 10.194.200.1 with SMTP id jo1mr53730032wjc.64.1422954767604;
 Tue, 03 Feb 2015 01:12:47 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Tue, 3 Feb 2015 01:12:47 -0800 (PST)
In-Reply-To: <CAPa0eF7F_Ru6Wough8Rs-Ns7ocbwnVoFeQd=X6O4CaYL66o72w@mail.gmail.com>
References: <CAPa0eF7F_Ru6Wough8Rs-Ns7ocbwnVoFeQd=X6O4CaYL66o72w@mail.gmail.com>
Date: Tue, 3 Feb 2015 01:12:47 -0800
Message-ID: <CAJgQjQ-bQNhSUdFALjQARcsd7=Q5qEP9HR_NT+udpxRHxQc5GQ@mail.gmail.com>
Subject: Re: IDF for ml pipeline
From: Xiangrui Meng <mengxr@gmail.com>
To: masaki rikitoku <rikima3132@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, we need a wrapper under spark.ml. Feel free to create a JIRA for
it. -Xiangrui

On Mon, Feb 2, 2015 at 8:56 PM, masaki rikitoku <rikima3132@gmail.com> wrote:
> Hi all
>
> I am trying the ml pipeline for text classfication now.
>
> recently, i succeed to execute the pipeline processing in ml packages,
> which consist of the original Japanese tokenizer, hashingTF,
> logisticRegression.
>
> then,  i failed to  executed the pipeline with idf in mllib package directly.
>
> To use the idf feature in ml package,
> do i have to implement the wrapper for idf in ml package like the hashingTF?
>
> best
>
> Masaki Rikitoku
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11415-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 12:18:38 2015
Return-Path: <dev-return-11415-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DE07217D3C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 12:18:37 +0000 (UTC)
Received: (qmail 51323 invoked by uid 500); 3 Feb 2015 12:18:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51251 invoked by uid 500); 3 Feb 2015 12:18:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50642 invoked by uid 99); 3 Feb 2015 12:18:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:18:34 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:18:09 +0000
Received: by mail-oi0-f47.google.com with SMTP id a141so48899511oig.6
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 04:17:23 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=A+fmCzHSjrAMsNWPRdrLf2+7BfXsN7YNMEIxCGE7rKI=;
        b=P2F9g9B3qRs2Ol0EH5jBO/0g2vZwbuUydyvO6up4e/kagAA05gzmXHhENcRuStZzg+
         DxImMyBu+KI+gObbSGZo9Ym+X4GR1lyQZfOFbDTwENvwwoeXYDhmGQA9fD0EujhYu7cQ
         mqZ00RAXzhZfKHGymhNENByhmPBlKCQa+/QqFbiKFu75na45Wf1n3mx8uihq9M/URgCc
         jFQqannB7fREdyQCukP0Hfucd/yWT6z6qCF3ibeHZ50FW5t4BDQe144oaHqFSv/SgRq+
         22fWtV20hDQhf80veTayZhzdICaWW166LpWGPK4vkx+MNrgMWe9dr8T0EBUqZUYF3Wjp
         nfJw==
MIME-Version: 1.0
X-Received: by 10.60.178.105 with SMTP id cx9mr15293629oec.16.1422965842948;
 Tue, 03 Feb 2015 04:17:22 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Tue, 3 Feb 2015 04:17:22 -0800 (PST)
Date: Tue, 3 Feb 2015 17:47:22 +0530
Message-ID: <CAFQAd-=3mQ=crU+gsAiwMx4u7cKyxdiT=AZrHM0sU8HOp_ZeuA@mail.gmail.com>
Subject: Accessing indices and values in SparseVector
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e0118481298b77a050e2e0d1d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0118481298b77a050e2e0d1d
Content-Type: text/plain; charset=UTF-8

Hello,

This is related to one of the issues that I'm working on. I am not sure if
this is expected behavior or not.

This works fine.
val sv2 = new SparseVector(3, Array(0, 2), Array(1.1, 3.0))
sv2.indices

But when I do this
val sv2: Vector = Vectors.sparse(3, Array(0, 2), Array(1.1, 3.0))
sv2.indices

It raises an error.

If agreed that this is not expected, I can send a Pull Request.
Thanks.



-- 
Godspeed,
Manoj Kumar,
http://manojbits.wordpress.com
<http://goog_1017110195>
http://github.com/MechCoder

--089e0118481298b77a050e2e0d1d--

From dev-return-11416-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 12:21:05 2015
Return-Path: <dev-return-11416-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 43FAA17D48
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 12:21:05 +0000 (UTC)
Received: (qmail 57471 invoked by uid 500); 3 Feb 2015 12:21:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57401 invoked by uid 500); 3 Feb 2015 12:21:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57389 invoked by uid 99); 3 Feb 2015 12:21:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:21:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.170 as permitted sender)
Received: from [74.125.82.170] (HELO mail-we0-f170.google.com) (74.125.82.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:20:38 +0000
Received: by mail-we0-f170.google.com with SMTP id w55so39166822wes.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 04:18:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=zudQrPyfIXTbEKXrVsnaopHECEUBeYRwxnMk2fxOCcE=;
        b=UqCBapqLKhBYy88sa5sBIpa5ip/fNI4VdkZrfd4ttuj1xpeuhhHS8YInRQ1iIaY3vD
         0fAY5uhoK6fnmSihHGGGDti2gDIunlYtZK7JAWPItfCwIjxymlvu7W20yFGS64ML/TVt
         FWK4er011OEe3LpDCf0yPV8aHWUD+tzdhdD/vqewc8kMqND0aos2qVlCDcu6i3msHM3X
         g9xX9h5ZGlmQ1F15tBkITlgVuSjs2I6ueA4KkrC4Vw06doFQddErqbOD/ZzuGfkq6A5S
         TgC60WlpxxkZN+hvlWicS5b9KUAvw5U/Bfdm+T+bA44YfCpSJ6px+VVwCVR1hvPCoEj5
         CvcQ==
X-Gm-Message-State: ALoCoQloL37ysoozJ51ihld+D+xKlr51vD4avQb23EOpDwbHeMDJLbn+WyECuh68Evmrg6vPBBA7
X-Received: by 10.180.21.162 with SMTP id w2mr33474697wie.42.1422965901687;
 Tue, 03 Feb 2015 04:18:21 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Tue, 3 Feb 2015 04:18:01 -0800 (PST)
In-Reply-To: <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
 <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 3 Feb 2015 06:18:01 -0600
Message-ID: <CAMAsSdL-GnpTbcbd5SOi8r=tDz+i5X9eLPtcXhab6Vba3TsgCA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1

The signatures are still fine.
Building for Hadoop 2.6 with YARN works; tests pass, except that
MQTTStreamSuite, which we established is a test problem and already
fixed in master.

On Tue, Feb 3, 2015 at 12:34 AM, Krishna Sankar <ksankar42@gmail.com> wrote:
> +1 (non-binding, of course)
>
> 1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min
>      mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
> -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
> 2. Tested pyspark, mlib - running as well as compare results with 1.1.x &
> 1.2.0
> 2.1. statistics (min,max,mean,Pearson,Spearman) OK
> 2.2. Linear/Ridge/Laso Regression OK
> 2.3. Decision Tree, Naive Bayes OK
> 2.4. KMeans OK
>        Center And Scale OK
>        Fixed : org.apache.spark.SparkException in zip !
> 2.5. rdd operations OK
>       State of the Union Texts - MapReduce, Filter,sortByKey (word count)
> 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
>        Model evaluation/optimization (rank, numIter, lmbda) with itertools
> OK
> 3. Scala - MLLib
> 3.1. statistics (min,max,mean,Pearson,Spearman) OK
> 3.2. LinearRegressionWIthSGD OK
> 3.3. Decision Tree OK
> 3.4. KMeans OK
> 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK
>
> Cheers
> <k/>
>
>
> On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> Please vote on releasing the following candidate as Apache Spark version
>> 1.2.1!
>>
>> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
>>
>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97
>>
>> The release files, including signatures, digests, etc. can be found at:
>> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
>>
>> Release artifacts are signed with the following key:
>> https://people.apache.org/keys/committer/pwendell.asc
>>
>> The staging repository for this release can be found at:
>> https://repository.apache.org/content/repositories/orgapachespark-1065/
>>
>> The documentation corresponding to this release can be found at:
>> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
>>
>> Changes from rc2:
>> A single patch fixing a windows issue.
>>
>> Please vote on releasing this package as Apache Spark 1.2.1!
>>
>> The vote is open until Friday, February 06, at 05:00 UTC and passes
>> if a majority of at least 3 +1 PMC votes are cast.
>>
>> [ ] +1 Release this package as Apache Spark 1.2.1
>> [ ] -1 Do not release this package because ...
>>
>> For a list of fixes in this release, see http://s.apache.org/Mpn.
>>
>> To learn more about Apache Spark, please see
>> http://spark.apache.org/
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11417-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 12:23:23 2015
Return-Path: <dev-return-11417-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C96B17D60
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 12:23:23 +0000 (UTC)
Received: (qmail 69160 invoked by uid 500); 3 Feb 2015 12:23:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69095 invoked by uid 500); 3 Feb 2015 12:23:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68336 invoked by uid 99); 3 Feb 2015 12:23:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:23:18 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.212.174 as permitted sender)
Received: from [209.85.212.174] (HELO mail-wi0-f174.google.com) (209.85.212.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:23:14 +0000
Received: by mail-wi0-f174.google.com with SMTP id n3so23888727wiv.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 04:22:54 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=rfsX4TQarhjlb8tGxycnC82qnMyETxi8HxzOy7ryBPM=;
        b=L7BLvizWGjm59Nslb98LtJS1ZPPEZt9wKdatBlipw5R+Y9kl2By7+b6vNtzzIxODhz
         R3gBN7xb1ffDORczCx0nIsdEYBxyJWXAwQTsQ5fu6p+8pbmY1JVY9eUAjao/4vciedwt
         4MfmJednn5p1c7NbLUzyEwjH5GjqEKBXFIsfOpQTeAuECNa1ADZSuFbd2LqEa0wolc+Q
         8RvCNtKrDHFhrw49/53HpoJenwl94qEnP3djQ0rPkYvFZsltKNZPd2OOeEki83tWAArg
         9d91Fc4VOeFhvR1y2eooK7FYGFxWFmrDFHAs6WKpu+IwnMhihuKokcMwRI1wLL1jIOSc
         vgyg==
X-Gm-Message-State: ALoCoQmdI51W4iCSrUMnH8yuMBzf4lNyiPwxtlpStb984c7gsElov+F0fOqbteeiaSnlv1+WcUNp
X-Received: by 10.180.21.162 with SMTP id w2mr33512505wie.42.1422966173878;
 Tue, 03 Feb 2015 04:22:53 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Tue, 3 Feb 2015 04:22:33 -0800 (PST)
In-Reply-To: <CAFQAd-=3mQ=crU+gsAiwMx4u7cKyxdiT=AZrHM0sU8HOp_ZeuA@mail.gmail.com>
References: <CAFQAd-=3mQ=crU+gsAiwMx4u7cKyxdiT=AZrHM0sU8HOp_ZeuA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 3 Feb 2015 06:22:33 -0600
Message-ID: <CAMAsSdL2L1wXwx2bi_mgj_vN=zJCFU=n8Zjb+-XahyC3u8DnNA@mail.gmail.com>
Subject: Re: Accessing indices and values in SparseVector
To: Manoj Kumar <manojkumarsivaraj334@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

When you are describing an error, you should say what the error is.
Here I'm pretty sure it says there is no such member of Vector, right?
You explicitly made the type of sv2 Vector and not SparseVector, and
the trait does not have any indices member. No it's not a problem, and
I think the compiler tells you what's happening in this case.

On Tue, Feb 3, 2015 at 6:17 AM, Manoj Kumar
<manojkumarsivaraj334@gmail.com> wrote:
> Hello,
>
> This is related to one of the issues that I'm working on. I am not sure if
> this is expected behavior or not.
>
> This works fine.
> val sv2 = new SparseVector(3, Array(0, 2), Array(1.1, 3.0))
> sv2.indices
>
> But when I do this
> val sv2: Vector = Vectors.sparse(3, Array(0, 2), Array(1.1, 3.0))
> sv2.indices
>
> It raises an error.
>
> If agreed that this is not expected, I can send a Pull Request.
> Thanks.
>
>
>
> --
> Godspeed,
> Manoj Kumar,
> http://manojbits.wordpress.com
> <http://goog_1017110195>
> http://github.com/MechCoder

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11418-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 12:36:08 2015
Return-Path: <dev-return-11418-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8EE4617E43
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 12:36:08 +0000 (UTC)
Received: (qmail 7606 invoked by uid 500); 3 Feb 2015 12:36:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7521 invoked by uid 500); 3 Feb 2015 12:36:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7504 invoked by uid 99); 3 Feb 2015 12:36:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:36:08 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wangfei1@huawei.com designates 119.145.14.64 as permitted sender)
Received: from [119.145.14.64] (HELO szxga01-in.huawei.com) (119.145.14.64)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 12:36:02 +0000
Received: from 172.24.2.119 (EHLO szxeml428-hub.china.huawei.com) ([172.24.2.119])
	by szxrg01-dlp.huawei.com (MOS 4.3.7-GA FastPath queued)
	with ESMTP id CJA39536;
	Tue, 03 Feb 2015 20:35:40 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml428-hub.china.huawei.com
 (10.82.67.183) with Microsoft SMTP Server id 14.3.158.1; Tue, 3 Feb 2015
 20:35:36 +0800
Message-ID: <54D0C0C2.4000600@huawei.com>
Date: Tue, 3 Feb 2015 20:36:18 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: <dev@spark.apache.org>
Subject: Re: Jenkins install reference
References: <54D07E61.7060801@huawei.com>
In-Reply-To: <54D07E61.7060801@huawei.com>
Content-Type: text/plain; charset="ISO-8859-1"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Virus-Checked: Checked by ClamAV on apache.org

Here my question is:
     1 How to set jenkins to make it build for multi PR parallel?. or one machine only support one PR building?
     2 do we need install sbt on the CI machine since the script dev/run-tests will auto fetch the sbt jar ?

- Fei


On 2015/2/3 15:53, scwf wrote:
> Hi, all
>    we want to set up a CI env for spark in our team, is there any reference of how to install jenkins over spark?
>    Thanks
>
> Fei
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>
>



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11419-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 13:02:31 2015
Return-Path: <dev-return-11419-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F27F417F29
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 13:02:31 +0000 (UTC)
Received: (qmail 57661 invoked by uid 500); 3 Feb 2015 13:02:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57586 invoked by uid 500); 3 Feb 2015 13:02:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57501 invoked by uid 99); 3 Feb 2015 13:02:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 13:02:28 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.218.41 as permitted sender)
Received: from [209.85.218.41] (HELO mail-oi0-f41.google.com) (209.85.218.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 13:02:01 +0000
Received: by mail-oi0-f41.google.com with SMTP id z81so49004481oif.0
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 05:01:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=A5t4ozfly2J1v1OohVFXxLvtjnFAtczTfqokFF3ADnU=;
        b=c2EGMH6fQuWp6Lf9pJKljt6CJNPty0FhR0qYJwbKn6G2g6mllGkgJqhZBCyEsRWUJR
         XDcpDWk6qluyftxtKMBLGsaDEKcrFtTMamYKd8BVkhTP01nbVJzxgCV2M3XV9l//GQGy
         xX+DFG/hm++pcwzxsDJAop78pEjAUPZsZ63hW4e1yqoeGP1zu8mRqmU8S8tNU+XVzUdt
         Ov9IKCHPcW/ZySSl7Y4hd6TlGRZf4WMhm4gbwL7je+I2uULnnaX1fpaqBtielNRnOUGF
         9jGcK7FvU67RXafrwk7awVF8t992E3cvyG4URbHmnwkWd/1XIVoG8lfqDjM+kf54Dybw
         K79g==
MIME-Version: 1.0
X-Received: by 10.202.102.21 with SMTP id a21mr14637008oic.118.1422968519570;
 Tue, 03 Feb 2015 05:01:59 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Tue, 3 Feb 2015 05:01:59 -0800 (PST)
In-Reply-To: <CAMAsSdL2L1wXwx2bi_mgj_vN=zJCFU=n8Zjb+-XahyC3u8DnNA@mail.gmail.com>
References: <CAFQAd-=3mQ=crU+gsAiwMx4u7cKyxdiT=AZrHM0sU8HOp_ZeuA@mail.gmail.com>
	<CAMAsSdL2L1wXwx2bi_mgj_vN=zJCFU=n8Zjb+-XahyC3u8DnNA@mail.gmail.com>
Date: Tue, 3 Feb 2015 18:31:59 +0530
Message-ID: <CAFQAd-kS6nvO+eEh=t5pbSejm7A4CxzWUbq7rGOdq6eyHsiLQQ@mail.gmail.com>
Subject: Re: Accessing indices and values in SparseVector
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1140e85e22b956050e2eadcd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1140e85e22b956050e2eadcd
Content-Type: text/plain; charset=UTF-8

Alright, thanks for the quick clarification.

--001a1140e85e22b956050e2eadcd--

From dev-return-11420-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 17:15:55 2015
Return-Path: <dev-return-11420-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EBDB17C5F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 17:15:55 +0000 (UTC)
Received: (qmail 83190 invoked by uid 500); 3 Feb 2015 17:15:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83118 invoked by uid 500); 3 Feb 2015 17:15:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83023 invoked by uid 99); 3 Feb 2015 17:15:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 17:15:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 17:15:37 +0000
Received: by mail-la0-f47.google.com with SMTP id hz20so53472151lab.6
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 09:15:15 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=/lE9RytXh9X+Bt5jkvkq0gwfqFzrxbjF/TkuZ+ITzfo=;
        b=AAmxm63x87OpiCnvE4b+7worLZVOGWcpIe5rRiwHKiqtvDMIyhLg/Efv1w6NAwEqHB
         AYBzumbZGIaLyiV2pz3gJDtislWVEgNJRADuy3nTnbgdnb+qxYYX2FpzmjX1BF9m0pCd
         4iDdAG4FO1w3M/c07NNboSeCt736RZjLmLF/RatQly6nVpRDq2gUaoQhTnnLvXNoBFqM
         XV0X5/2LaOOKdNX3eTf8oXDVAkd8f/nVZeY1Dylo1TwSKPurzdGCpHZEp1MveUpaCUO7
         0HhDzTxYnUDX0KC1CYnRjhntNau24XgKvo3+6BA+pNvR+7w1NN9/sUOULr5a8DKlkPkC
         mnvw==
X-Gm-Message-State: ALoCoQmHKb4KLrtkriK6xprzTbZTi+tmulMva7AZCbBEFdWrQ0gt1mEbEyvMss27d1e/2q2u7jiD
X-Received: by 10.112.211.168 with SMTP id nd8mr26107167lbc.18.1422983715733;
 Tue, 03 Feb 2015 09:15:15 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.185.97 with HTTP; Tue, 3 Feb 2015 09:14:55 -0800 (PST)
In-Reply-To: <54D0C0C2.4000600@huawei.com>
References: <54D07E61.7060801@huawei.com> <54D0C0C2.4000600@huawei.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 3 Feb 2015 09:14:55 -0800
Message-ID: <CACdU-dRKu-hRRX-O+mr7pU13vrwRFv2mEYJRRwRS0pb444dLvw@mail.gmail.com>
Subject: Re: Jenkins install reference
To: scwf <wangfei1@huawei.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3bc4ee5dd00050e323681
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3bc4ee5dd00050e323681
Content-Type: text/plain; charset=UTF-8

here's the wiki describing the system setup:
https://cwiki.apache.org/confluence/display/SPARK/Spark+QA+Infrastructure

we have 1 master and 8 worker nodes, 12 executors per worker (we'd be
better off w/more and smaller worker nodes however).

you don't need to install sbt -- it's in the build/ directory.

the pull request builder builds in parallel, but the master builds require
specific ports to be reserved and each build effectively locks down a
worker until it's done.  since we have 8 worker nodes, it's not *that* big
of a deal...

shane

On Tue, Feb 3, 2015 at 4:36 AM, scwf <wangfei1@huawei.com> wrote:

> Here my question is:
>     1 How to set jenkins to make it build for multi PR parallel?. or one
> machine only support one PR building?
>     2 do we need install sbt on the CI machine since the script
> dev/run-tests will auto fetch the sbt jar ?
>
> - Fei
>
>
>
> On 2015/2/3 15:53, scwf wrote:
>
>> Hi, all
>>    we want to set up a CI env for spark in our team, is there any
>> reference of how to install jenkins over spark?
>>    Thanks
>>
>> Fei
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>>
>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c3bc4ee5dd00050e323681--

From dev-return-11421-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 17:17:35 2015
Return-Path: <dev-return-11421-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7039417C6F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 17:17:35 +0000 (UTC)
Received: (qmail 88054 invoked by uid 500); 3 Feb 2015 17:17:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88003 invoked by uid 500); 3 Feb 2015 17:17:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87840 invoked by uid 99); 3 Feb 2015 17:17:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 17:17:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of daniil.osipov@shazam.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 17:16:36 +0000
Received: by mail-ig0-f170.google.com with SMTP id l13so25883184iga.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 09:15:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=nJDmXBSbPrf5PTt6KIR6e+N2AD/PWRgIiBm+16S2oPA=;
        b=FSY+2GZ2tP4uxv0Y/cHi+8DE3av7BDFXVZ48EBSTZTQ+uXEG0PY6eICzy4sphFytiC
         H2u5hpHRh7Q4UW64KaIB/JK9PZA93qMmvFjF/Hgv9aGcUsJWNPfAoMde1EUgFAFFJmmI
         MIO9X4kggBsMuIY2ukzavPpSXF2N6Rhyh3bm//S6pR/8brwFyD4g9HA7ZdHMjdQ7sdQH
         bGbVuMlHuGs6xwGffB3XktAc3rlKvrxjt2v1wjf0uf8Zqli0lbZlOrqFHBwz4iHTvYSE
         mQCtssdJQ05xUxWktMNt9fEJhA1AW+TVu/JDyRBNKm9VpvxJcxZf2d7YoBh+sQOymSb5
         Epww==
X-Gm-Message-State: ALoCoQmNMFtp0eTFtaqZF2poypOwmCkjkFwj0Hhwdt0fg0pttZTzsFPWUHcgA22sWh8Qgw6z3uGZ
MIME-Version: 1.0
X-Received: by 10.42.84.138 with SMTP id m10mr20101150icl.21.1422983746979;
 Tue, 03 Feb 2015 09:15:46 -0800 (PST)
Received: by 10.50.207.67 with HTTP; Tue, 3 Feb 2015 09:15:46 -0800 (PST)
In-Reply-To: <CAPh_B=baG9z0i7h9+cW5yuDHiS+ZnOkqkU6cbYS9CGFXTOtSag@mail.gmail.com>
References: <CA+HOc9Mu0_z6FFRnvnuQmJcWFvKC1cQ2LduenpB_wHZSVAhsgQ@mail.gmail.com>
	<CAPh_B=baG9z0i7h9+cW5yuDHiS+ZnOkqkU6cbYS9CGFXTOtSag@mail.gmail.com>
Date: Tue, 3 Feb 2015 09:15:46 -0800
Message-ID: <CA+HOc9M0mvgqBVBJqL6zNDHRMNkTp6BdefE_osaxELtxGCrKWA@mail.gmail.com>
Subject: Re: [spark-sql] JsonRDD
From: Daniil Osipov <daniil.osipov@shazam.com>
To: Reynold Xin <rxin@databricks.com>
Cc: dev <dev@spark.apache.org>, Yin Huai <yhuai@databricks.com>
Content-Type: multipart/alternative; boundary=20cf3030bcf3c2a12a050e3238bb
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3030bcf3c2a12a050e3238bb
Content-Type: text/plain; charset=UTF-8

Thanks Reynold,

Case sensitivity issues are definitely orthogonal. I'll submit a bug or PR.

Is there a way to rename the object to eliminate the confusion? Not sure
how locked down the API is at this time, but it seems like a potential
confusion point for developers.

On Mon, Feb 2, 2015 at 4:30 PM, Reynold Xin <rxin@databricks.com> wrote:

> It's bad naming - JsonRDD is actually not an RDD. It is just a set of util
> methods.
>
> The case sensitivity issues seem orthogonal, and would be great to be able
> to control that with a flag.
>
>
> On Mon, Feb 2, 2015 at 4:16 PM, Daniil Osipov <daniil.osipov@shazam.com>
> wrote:
>
>> Hey Spark developers,
>>
>> Is there a good reason for JsonRDD being a Scala object as opposed to
>> class? Seems most other RDDs are classes, and can be extended.
>>
>> The reason I'm asking is that there is a problem with Hive
>> interoperability
>> with JSON DataFrames where jsonFile generates case sensitive schema, while
>> Hive expects case insensitive and fails with an exception during
>> saveAsTable if there are two columns with the same name in different case.
>>
>> I'm trying to resolve the problem, but that requires me to extend JsonRDD,
>> which I can't do. Other RDDs are subclass friendly, why is JsonRDD
>> different?
>>
>> Dan
>>
>
>

--20cf3030bcf3c2a12a050e3238bb--

From dev-return-11422-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 18:34:04 2015
Return-Path: <dev-return-11422-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A73D81745B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 18:34:04 +0000 (UTC)
Received: (qmail 24884 invoked by uid 500); 3 Feb 2015 18:34:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24800 invoked by uid 500); 3 Feb 2015 18:34:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24785 invoked by uid 99); 3 Feb 2015 18:34:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:34:04 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.142 as permitted sender)
Received: from [169.229.218.142] (HELO cm01fe.IST.Berkeley.EDU) (169.229.218.142)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:33:57 +0000
Received: from mail-yh0-f43.google.com ([209.85.213.43])
	by cm01fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1YIiHz-0004oC-4f
	for dev@spark.apache.org; Tue, 03 Feb 2015 10:33:37 -0800
Received: by mail-yh0-f43.google.com with SMTP id 29so19294172yhl.2
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 10:33:30 -0800 (PST)
MIME-Version: 1.0
X-Received: by 10.236.207.10 with SMTP id m10mr11115304yho.0.1422988410671;
 Tue, 03 Feb 2015 10:33:30 -0800 (PST)
Received: by 10.170.210.133 with HTTP; Tue, 3 Feb 2015 10:33:30 -0800 (PST)
In-Reply-To: <CABjPPTQB1NRu5Xhk6rLC4e=FoS=i_Y+P70=4TiGf2g7c+TSzpA@mail.gmail.com>
References: <CABjPPTQB1NRu5Xhk6rLC4e=FoS=i_Y+P70=4TiGf2g7c+TSzpA@mail.gmail.com>
Date: Tue, 3 Feb 2015 10:33:30 -0800
Message-ID: <CAKJXNjHrxHZBLArjfvC9U9ivODdV6L1BLn-FYBU42xSTONgKkg@mail.gmail.com>
Subject: Re: Can spark provide an option to start reduce stage early?
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: Xuelin Cao <xuelincao2014@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1de2cbcdb61050e334ed4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1de2cbcdb61050e334ed4
Content-Type: text/plain; charset=UTF-8

There's a JIRA tracking this here:
https://issues.apache.org/jira/browse/SPARK-2387

On Mon, Feb 2, 2015 at 9:48 PM, Xuelin Cao <xuelincao2014@gmail.com> wrote:

> In hadoop MR, there is an option *mapred.reduce.slowstart.completed.maps*
>
> which can be used to start reducer stage when X% mappers are completed. By
> doing this, the data shuffling process is able to parallel with the map
> process.
>
> In a large multi-tenancy cluster, this option is usually tuned off. But, in
> some cases, turn on the option could accelerate some high priority jobs.
>
> Will spark provide similar option?
>

--001a11c1de2cbcdb61050e334ed4--

From dev-return-11423-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 18:44:00 2015
Return-Path: <dev-return-11423-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E72CB174BD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 18:43:59 +0000 (UTC)
Received: (qmail 51837 invoked by uid 500); 3 Feb 2015 18:43:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51765 invoked by uid 500); 3 Feb 2015 18:43:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48838 invoked by uid 99); 3 Feb 2015 18:43:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:43:36 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=HTML_MESSAGE,MISSING_HEADERS,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of dirceu.semighini@gmail.com designates 209.85.218.50 as permitted sender)
Received: from [209.85.218.50] (HELO mail-oi0-f50.google.com) (209.85.218.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:43:10 +0000
Received: by mail-oi0-f50.google.com with SMTP id h136so50825421oig.9
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 10:43:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:cc
         :content-type;
        bh=g7L260meqFx9vDoojLgkGHO0vreBFuVU1c4EmxtdA+w=;
        b=Qdy9TCtWR1mta/tFBGL4DfzDXzEcXbtoRrrxQECcYLsvwGOFDF4YH+P1oLElUGw+cb
         vpGThX3pDXm+hhVZdufYm68+N3i2xkMuQClmQ59DBh2PZBT3eECUM5AL8tuFlpmTaEuG
         ZXp8wVza64ZtwftVCnnNlpnrdCHAill0ICw311QxAkQqbwbC7YMfqojrH9kUQRBH4YjM
         DqMKsIhK4KCc6G3i4DaFhSWkS3r4mQG85zchZmIJMR+XikNFmkIBZf3kj24fg3fn3P2P
         HbLh0Qmh4AJdr9K8WZRw9LAvY2TZ1G3ifuE3oEfbOw5RXGr+8ABBIHWabpAVGqWbb8X3
         rNSA==
X-Received: by 10.202.55.137 with SMTP id e131mt12595051oia.52.1422988988748;
 Tue, 03 Feb 2015 10:43:08 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.77.131 with HTTP; Tue, 3 Feb 2015 10:42:25 -0800 (PST)
In-Reply-To: <CAMAsSdL-GnpTbcbd5SOi8r=tDz+i5X9eLPtcXhab6Vba3TsgCA@mail.gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
 <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com> <CAMAsSdL-GnpTbcbd5SOi8r=tDz+i5X9eLPtcXhab6Vba3TsgCA@mail.gmail.com>
From: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Date: Tue, 3 Feb 2015 16:42:25 -0200
Message-ID: <CAO4-Pq8OS8SQzrPXxfzZ+uOtdPjrp=5XrB5B-tMh51m1jty5kA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113cef2e31eec0050e33717f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cef2e31eec0050e33717f
Content-Type: text/plain; charset=UTF-8

Hi Patrick,
I work in an Startup and we want make one of our projects as open source.
This project is based on Spark, and it will help users to instantiate spark
clusters in a cloud environment.
But for that project we need to use the repl, hive and thrift-server.
Can the decision of not publishing this libraries be changed in this
release?

Kind Regards,
Dirceu

2015-02-03 10:18 GMT-02:00 Sean Owen <sowen@cloudera.com>:

> +1
>
> The signatures are still fine.
> Building for Hadoop 2.6 with YARN works; tests pass, except that
> MQTTStreamSuite, which we established is a test problem and already
> fixed in master.
>
> On Tue, Feb 3, 2015 at 12:34 AM, Krishna Sankar <ksankar42@gmail.com>
> wrote:
> > +1 (non-binding, of course)
> >
> > 1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min
> >      mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
> > -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
> > 2. Tested pyspark, mlib - running as well as compare results with 1.1.x &
> > 1.2.0
> > 2.1. statistics (min,max,mean,Pearson,Spearman) OK
> > 2.2. Linear/Ridge/Laso Regression OK
> > 2.3. Decision Tree, Naive Bayes OK
> > 2.4. KMeans OK
> >        Center And Scale OK
> >        Fixed : org.apache.spark.SparkException in zip !
> > 2.5. rdd operations OK
> >       State of the Union Texts - MapReduce, Filter,sortByKey (word count)
> > 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
> >        Model evaluation/optimization (rank, numIter, lmbda) with
> itertools
> > OK
> > 3. Scala - MLLib
> > 3.1. statistics (min,max,mean,Pearson,Spearman) OK
> > 3.2. LinearRegressionWIthSGD OK
> > 3.3. Decision Tree OK
> > 3.4. KMeans OK
> > 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK
> >
> > Cheers
> > <k/>
> >
> >
> > On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >
> >> Please vote on releasing the following candidate as Apache Spark version
> >> 1.2.1!
> >>
> >> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
> >>
> >>
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97
> >>
> >> The release files, including signatures, digests, etc. can be found at:
> >> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
> >>
> >> Release artifacts are signed with the following key:
> >> https://people.apache.org/keys/committer/pwendell.asc
> >>
> >> The staging repository for this release can be found at:
> >> https://repository.apache.org/content/repositories/orgapachespark-1065/
> >>
> >> The documentation corresponding to this release can be found at:
> >> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
> >>
> >> Changes from rc2:
> >> A single patch fixing a windows issue.
> >>
> >> Please vote on releasing this package as Apache Spark 1.2.1!
> >>
> >> The vote is open until Friday, February 06, at 05:00 UTC and passes
> >> if a majority of at least 3 +1 PMC votes are cast.
> >>
> >> [ ] +1 Release this package as Apache Spark 1.2.1
> >> [ ] -1 Do not release this package because ...
> >>
> >> For a list of fixes in this release, see http://s.apache.org/Mpn.
> >>
> >> To learn more about Apache Spark, please see
> >> http://spark.apache.org/
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113cef2e31eec0050e33717f--

From dev-return-11424-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 18:45:03 2015
Return-Path: <dev-return-11424-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2DDD9174C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 18:45:03 +0000 (UTC)
Received: (qmail 55080 invoked by uid 500); 3 Feb 2015 18:45:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55008 invoked by uid 500); 3 Feb 2015 18:45:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 55000 invoked by uid 99); 3 Feb 2015 14:29:46 -0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of jayhutfles@gmail.com does not designate 162.253.133.43 as permitted sender)
Date: Tue, 3 Feb 2015 07:28:47 -0700 (MST)
From: jayhutfles <jayhutfles@gmail.com>
To: dev@spark.apache.org
Message-ID: <1422973727233-10417.post@n3.nabble.com>
Subject: SparkSubmit.scala and stderr
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I just saw that the SparkSubmit.scala class has the following lines:

  object SparkSubmit {
    ...
    // Exposed for testing
    private[spark] var printStream: PrintStream = System.err
    ...
  }

This causes all verbose logging messages elsewhere in SparkSubmit to go to
stderr, not stdout.  Is this by design?  Verbose messages don't necessarily
reflect errors.  But as the comment states that it's for testing, maybe I'm
misunderstanding its intent...

Thanks in advance
  -Jay



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/SparkSubmit-scala-and-stderr-tp10417.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11425-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 18:50:12 2015
Return-Path: <dev-return-11425-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D647174F1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 18:50:12 +0000 (UTC)
Received: (qmail 71724 invoked by uid 500); 3 Feb 2015 18:50:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71647 invoked by uid 500); 3 Feb 2015 18:50:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71633 invoked by uid 99); 3 Feb 2015 18:50:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:50:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 18:50:07 +0000
Received: by mail-ie0-f176.google.com with SMTP id at20so27401797iec.7
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 10:48:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=1OgXyI0qpNjsIOApe5yoQRLS83obkCYLaWPZU8cP1nY=;
        b=M3mwR4ixY0qTiWkqkFReb20Rzp7eNqhQMQA9l5AB4bxGJsRUlD20NNmprzmoR2xRn0
         e+T9ApdF2ORuAuiexvMGRrZ5q/ekvfqOE7AED4s1vhiuc9vAGHU3mSyY/Zf1NnRZnM0X
         SFNTthfJde0HjufHaRx6lq/xMnIgJjPbzXUisMbH7RQ+WYcQLfoYfJuUCI8eM66pK8kM
         UiLJ3wlM11i7THT8LKqp8XgYD3MfkAx0TBAqWAT/AT1piXJlmXmenW3Ot181HT7r7V4/
         z54QbMk7WVcaExrdqN3M4j9RFczbHebPQw80DCNyw3n4dc7Pl/uxFIDG89HoJYtY3xOT
         MMAg==
X-Received: by 10.50.137.99 with SMTP id qh3mr19833384igb.9.1422989296535;
 Tue, 03 Feb 2015 10:48:16 -0800 (PST)
MIME-Version: 1.0
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
 <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com>
 <CAMAsSdL-GnpTbcbd5SOi8r=tDz+i5X9eLPtcXhab6Vba3TsgCA@mail.gmail.com> <CAO4-Pq8OS8SQzrPXxfzZ+uOtdPjrp=5XrB5B-tMh51m1jty5kA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 03 Feb 2015 18:48:15 +0000
Message-ID: <CAOhmDzcYnFsM4T9KHK76oXRUj2mWBP8y_3RnP0vGwemq0QOicg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
To: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3bcbc8a0e4a050e338360
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3bcbc8a0e4a050e338360
Content-Type: text/plain; charset=UTF-8

I believe this was changed for 1.2.1. Here are the relevant JIRA issues
<https://issues.apache.org/jira/browse/SPARK-5289?jql=project%20%3D%20SPARK%20AND%20fixVersion%20%3D%201.2.1%20AND%20text%20~%20%22publish%22%20order%20by%20priority>
.

On Tue Feb 03 2015 at 10:43:59 AM Dirceu Semighini Filho <
dirceu.semighini@gmail.com> wrote:

> Hi Patrick,
> I work in an Startup and we want make one of our projects as open source.
> This project is based on Spark, and it will help users to instantiate spark
> clusters in a cloud environment.
> But for that project we need to use the repl, hive and thrift-server.
> Can the decision of not publishing this libraries be changed in this
> release?
>
> Kind Regards,
> Dirceu
>
> 2015-02-03 10:18 GMT-02:00 Sean Owen <sowen@cloudera.com>:
>
> > +1
> >
> > The signatures are still fine.
> > Building for Hadoop 2.6 with YARN works; tests pass, except that
> > MQTTStreamSuite, which we established is a test problem and already
> > fixed in master.
> >
> > On Tue, Feb 3, 2015 at 12:34 AM, Krishna Sankar <ksankar42@gmail.com>
> > wrote:
> > > +1 (non-binding, of course)
> > >
> > > 1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min
> > >      mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
> > > -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
> > > 2. Tested pyspark, mlib - running as well as compare results with
> 1.1.x &
> > > 1.2.0
> > > 2.1. statistics (min,max,mean,Pearson,Spearman) OK
> > > 2.2. Linear/Ridge/Laso Regression OK
> > > 2.3. Decision Tree, Naive Bayes OK
> > > 2.4. KMeans OK
> > >        Center And Scale OK
> > >        Fixed : org.apache.spark.SparkException in zip !
> > > 2.5. rdd operations OK
> > >       State of the Union Texts - MapReduce, Filter,sortByKey (word
> count)
> > > 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
> > >        Model evaluation/optimization (rank, numIter, lmbda) with
> > itertools
> > > OK
> > > 3. Scala - MLLib
> > > 3.1. statistics (min,max,mean,Pearson,Spearman) OK
> > > 3.2. LinearRegressionWIthSGD OK
> > > 3.3. Decision Tree OK
> > > 3.4. KMeans OK
> > > 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK
> > >
> > > Cheers
> > > <k/>
> > >
> > >
> > > On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> > >
> > >> Please vote on releasing the following candidate as Apache Spark
> version
> > >> 1.2.1!
> > >>
> > >> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
> > >>
> > >>
> > https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=
> b6eaf77d4332bfb0a698849b1f5f917d20d70e97
> > >>
> > >> The release files, including signatures, digests, etc. can be found
> at:
> > >> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
> > >>
> > >> Release artifacts are signed with the following key:
> > >> https://people.apache.org/keys/committer/pwendell.asc
> > >>
> > >> The staging repository for this release can be found at:
> > >> https://repository.apache.org/content/repositories/
> orgapachespark-1065/
> > >>
> > >> The documentation corresponding to this release can be found at:
> > >> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
> > >>
> > >> Changes from rc2:
> > >> A single patch fixing a windows issue.
> > >>
> > >> Please vote on releasing this package as Apache Spark 1.2.1!
> > >>
> > >> The vote is open until Friday, February 06, at 05:00 UTC and passes
> > >> if a majority of at least 3 +1 PMC votes are cast.
> > >>
> > >> [ ] +1 Release this package as Apache Spark 1.2.1
> > >> [ ] -1 Do not release this package because ...
> > >>
> > >> For a list of fixes in this release, see http://s.apache.org/Mpn.
> > >>
> > >> To learn more about Apache Spark, please see
> > >> http://spark.apache.org/
> > >>
> > >> ---------------------------------------------------------------------
> > >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >> For additional commands, e-mail: dev-help@spark.apache.org
> > >>
> > >>
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a11c3bcbc8a0e4a050e338360--

From dev-return-11426-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 19:48:48 2015
Return-Path: <dev-return-11426-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C456D17790
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 19:48:48 +0000 (UTC)
Received: (qmail 40547 invoked by uid 500); 3 Feb 2015 19:48:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40480 invoked by uid 500); 3 Feb 2015 19:48:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40463 invoked by uid 99); 3 Feb 2015 19:48:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 19:48:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chip.senkbeil@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 19:48:43 +0000
Received: by mail-ob0-f171.google.com with SMTP id gq1so15481148obb.2
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 11:47:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=ULTZupCZrqIW1iIdTHFIiwp/zuFF7d3eS2f//SIlTFQ=;
        b=Umm9jAydCTxWgAFeAthzglNdVA7V+rDM2rqaUGZAwzh1UaQd4LP4SoFLsf7EYRgVGS
         83njEFa6gs0OfdTmbPgos51fMMinueQSpTkuhPeFZNrPxNNDnCtmt+SLGXC+4fEOibPC
         3iCYg6lHJ8PsT8zJBM1vv0dvU+ZFCc7HJe5skgmjdfIpUddsUfbDBRqwxPELMTwJYZwq
         mC2Z19BEB5SVZC3k1L3I/TsEvcd994YUzjZKSaK+/WJHGonT9JOcLKH7I9jT/mY2HuRU
         yeWW/9vQ1XwXEUUzsKjwWWcdI3mPluUu0q0VpCdYaOrCInqEBdFTHjm/Yn0PUm2mIB7A
         bbkw==
X-Received: by 10.202.53.84 with SMTP id c81mr13329133oia.120.1422992858097;
 Tue, 03 Feb 2015 11:47:38 -0800 (PST)
MIME-Version: 1.0
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
 <CAOTBr2m0k4-bWDB5N5aVmsOXOQ39dqoaTqyn9taMUHL9GUP0BQ@mail.gmail.com>
 <CAMAsSdL-GnpTbcbd5SOi8r=tDz+i5X9eLPtcXhab6Vba3TsgCA@mail.gmail.com>
 <CAO4-Pq8OS8SQzrPXxfzZ+uOtdPjrp=5XrB5B-tMh51m1jty5kA@mail.gmail.com> <CAOhmDzcYnFsM4T9KHK76oXRUj2mWBP8y_3RnP0vGwemq0QOicg@mail.gmail.com>
From: Chip Senkbeil <chip.senkbeil@gmail.com>
Date: Tue, 03 Feb 2015 19:47:37 +0000
Message-ID: <CAEYw2Z7vKZ9bDbC4Gk3cn4zw3NWsf+Yk5meQpW26aTsyq6Rapw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
To: Nicholas Chammas <nicholas.chammas@gmail.com>, 
	Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d6084d3307b050e345717
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d6084d3307b050e345717
Content-Type: text/plain; charset=UTF-8

+1 Tested the REPL release against the Spark Kernel project
(compilation/testing/manual execution). Everything still checks out fine.

Signed,
Chip Senkbeil
IBM Emerging Technologies Software Engineer

On Tue Feb 03 2015 at 12:50:12 PM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I believe this was changed for 1.2.1. Here are the relevant JIRA issues
> <https://issues.apache.org/jira/browse/SPARK-5289?jql=
> project%20%3D%20SPARK%20AND%20fixVersion%20%3D%201.2.1%
> 20AND%20text%20~%20%22publish%22%20order%20by%20priority>
> .
>
> On Tue Feb 03 2015 at 10:43:59 AM Dirceu Semighini Filho <
> dirceu.semighini@gmail.com> wrote:
>
> > Hi Patrick,
> > I work in an Startup and we want make one of our projects as open source.
> > This project is based on Spark, and it will help users to instantiate
> spark
> > clusters in a cloud environment.
> > But for that project we need to use the repl, hive and thrift-server.
> > Can the decision of not publishing this libraries be changed in this
> > release?
> >
> > Kind Regards,
> > Dirceu
> >
> > 2015-02-03 10:18 GMT-02:00 Sean Owen <sowen@cloudera.com>:
> >
> > > +1
> > >
> > > The signatures are still fine.
> > > Building for Hadoop 2.6 with YARN works; tests pass, except that
> > > MQTTStreamSuite, which we established is a test problem and already
> > > fixed in master.
> > >
> > > On Tue, Feb 3, 2015 at 12:34 AM, Krishna Sankar <ksankar42@gmail.com>
> > > wrote:
> > > > +1 (non-binding, of course)
> > > >
> > > > 1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min
> > > >      mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
> > > > -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
> > > > 2. Tested pyspark, mlib - running as well as compare results with
> > 1.1.x &
> > > > 1.2.0
> > > > 2.1. statistics (min,max,mean,Pearson,Spearman) OK
> > > > 2.2. Linear/Ridge/Laso Regression OK
> > > > 2.3. Decision Tree, Naive Bayes OK
> > > > 2.4. KMeans OK
> > > >        Center And Scale OK
> > > >        Fixed : org.apache.spark.SparkException in zip !
> > > > 2.5. rdd operations OK
> > > >       State of the Union Texts - MapReduce, Filter,sortByKey (word
> > count)
> > > > 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
> > > >        Model evaluation/optimization (rank, numIter, lmbda) with
> > > itertools
> > > > OK
> > > > 3. Scala - MLLib
> > > > 3.1. statistics (min,max,mean,Pearson,Spearman) OK
> > > > 3.2. LinearRegressionWIthSGD OK
> > > > 3.3. Decision Tree OK
> > > > 3.4. KMeans OK
> > > > 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK
> > > >
> > > > Cheers
> > > > <k/>
> > > >
> > > >
> > > > On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell <pwendell@gmail.com>
> > > wrote:
> > > >
> > > >> Please vote on releasing the following candidate as Apache Spark
> > version
> > > >> 1.2.1!
> > > >>
> > > >> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
> > > >>
> > > >>
> > > https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=
> > b6eaf77d4332bfb0a698849b1f5f917d20d70e97
> > > >>
> > > >> The release files, including signatures, digests, etc. can be found
> > at:
> > > >> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
> > > >>
> > > >> Release artifacts are signed with the following key:
> > > >> https://people.apache.org/keys/committer/pwendell.asc
> > > >>
> > > >> The staging repository for this release can be found at:
> > > >> https://repository.apache.org/content/repositories/
> > orgapachespark-1065/
> > > >>
> > > >> The documentation corresponding to this release can be found at:
> > > >> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
> > > >>
> > > >> Changes from rc2:
> > > >> A single patch fixing a windows issue.
> > > >>
> > > >> Please vote on releasing this package as Apache Spark 1.2.1!
> > > >>
> > > >> The vote is open until Friday, February 06, at 05:00 UTC and passes
> > > >> if a majority of at least 3 +1 PMC votes are cast.
> > > >>
> > > >> [ ] +1 Release this package as Apache Spark 1.2.1
> > > >> [ ] -1 Do not release this package because ...
> > > >>
> > > >> For a list of fixes in this release, see http://s.apache.org/Mpn.
> > > >>
> > > >> To learn more about Apache Spark, please see
> > > >> http://spark.apache.org/
> > > >>
> > > >> ------------------------------------------------------------
> ---------
> > > >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > >> For additional commands, e-mail: dev-help@spark.apache.org
> > > >>
> > > >>
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--001a113d6084d3307b050e345717--

From dev-return-11427-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 19:59:40 2015
Return-Path: <dev-return-11427-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 567FC177E5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 19:59:40 +0000 (UTC)
Received: (qmail 67093 invoked by uid 500); 3 Feb 2015 19:59:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67009 invoked by uid 500); 3 Feb 2015 19:59:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66994 invoked by uid 99); 3 Feb 2015 19:59:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 19:59:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 19:59:11 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so12598651obc.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 11:59:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=/aCUXwRmEhEf1/lSr8G8Ewonhf98UWIq6j1JIIsLCRQ=;
        b=AAGMl/DZVgobSD2xVi9VqSdRunjefeuOuln4cV9hInNim4qv7EpHiFZq12MhDXmfRz
         oe6G8PannTlyZotQNiZ4ASfOCO14NImrnieIZ/VaIrdBdNm5wkHxJwueAXmGEKEizjni
         v86TGTFBz8xO/Gp0ZRqxL/OP93V+RaPT4NXrEKEhmDBOiESXocEmhUo5aRyLnHGK8tPE
         8BVVLM2uR+m+wPBbO/MLSkBa2E+cnPtx3O394+hikKlwt9LCc/F/aULw8VNhmFbFrFbQ
         sN+BBNuzb5ONLepkOi9kVEYSZrRph7H+scKKJJRSTkBXnYlQyJObyYxb1J2uuKk5hHDe
         enWw==
MIME-Version: 1.0
X-Received: by 10.202.80.199 with SMTP id e190mr15798988oib.75.1422993549546;
 Tue, 03 Feb 2015 11:59:09 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Tue, 3 Feb 2015 11:59:09 -0800 (PST)
Date: Tue, 3 Feb 2015 11:59:09 -0800
Message-ID: <CABPQxsvyXmrZFGtr_a=qjkbkjdEHt7B-CJ-fDUfgXCNaWdKbGg@mail.gmail.com>
Subject: [ANNOUNCE] branch-1.3 has been cut
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

Just wanted to announce that we've cut the 1.3 branch which will
become the 1.3 release after community testing.

There are still some features that will go in (in higher level
libraries, and some stragglers in spark core), but overall this
indicates the end of major feature development for Spark 1.3 and a
transition into testing.

Within a few days I'll cut a snapshot package release for this so that
people can begin testing.

https://git-wip-us.apache.org/repos/asf?p=spark.git;a=shortlog;h=refs/heads/branch-1.3

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11428-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 20:31:08 2015
Return-Path: <dev-return-11428-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4729C17933
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 20:31:08 +0000 (UTC)
Received: (qmail 61846 invoked by uid 500); 3 Feb 2015 20:31:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61776 invoked by uid 500); 3 Feb 2015 20:31:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61765 invoked by uid 99); 3 Feb 2015 20:31:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 20:31:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 20:31:03 +0000
Received: by mail-lb0-f170.google.com with SMTP id w7so40796137lbi.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 12:29:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=V7avcmnRFYEqLh1cgsL2eZPW1/EyasApfbCiuLglAJo=;
        b=dRbyKZSyXr9gGPUJXgHZt4iJuMkbwnMLuOZEgH4KK4sbRSgeEitpJUUXgczi/VUE4g
         geN0oB9kO9lCPCk44vc0fvjLGVIjcBi1nrY1xRdCfoBl9EKudhdMbVcxuvFef8o+W3II
         KGCqJCZLJNNp06TlN0fEpe1qr0aUeUn2Ir9OTu4mWJCrGCVi8ZBm72yaW9MDvXvcWtQr
         5dbvpHSMx5RvA84DmQaqd96ZWZz4DpzvStkU1d2xcvC0A9tGPjb4akFvA52fh3dPBPkI
         JVOEGtJnmwJk/k9QkMMcN1aQrS5Yu7IRZzTQ47mBJYGX4ItaVVLJBRB4GIVXxAnLHci+
         Jwxg==
X-Gm-Message-State: ALoCoQkazip1+2RQzvqSfrtLjV9ShBxAq5hU0H3jVHx8XA4yEiLTPPdgef530G5Uh1qsPTY9aLJY
MIME-Version: 1.0
X-Received: by 10.152.8.1 with SMTP id n1mr26070382laa.47.1422995376488; Tue,
 03 Feb 2015 12:29:36 -0800 (PST)
Received: by 10.25.86.129 with HTTP; Tue, 3 Feb 2015 12:29:36 -0800 (PST)
In-Reply-To: <CA+HOc9M0mvgqBVBJqL6zNDHRMNkTp6BdefE_osaxELtxGCrKWA@mail.gmail.com>
References: <CA+HOc9Mu0_z6FFRnvnuQmJcWFvKC1cQ2LduenpB_wHZSVAhsgQ@mail.gmail.com>
	<CAPh_B=baG9z0i7h9+cW5yuDHiS+ZnOkqkU6cbYS9CGFXTOtSag@mail.gmail.com>
	<CA+HOc9M0mvgqBVBJqL6zNDHRMNkTp6BdefE_osaxELtxGCrKWA@mail.gmail.com>
Date: Tue, 3 Feb 2015 12:29:36 -0800
Message-ID: <CAHP0wa+f_pUP=n9j5e9T7Vyk3KJidsyCcayRTps5P18fg+3o8Q@mail.gmail.com>
Subject: Re: [spark-sql] JsonRDD
From: Yin Huai <yhuai@databricks.com>
To: Daniil Osipov <daniil.osipov@shazam.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2618ceed8d7050e34ed81
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2618ceed8d7050e34ed81
Content-Type: text/plain; charset=UTF-8

We probably will extract general purpose functions from JsonRDD and also do
the renaming through https://issues.apache.org/jira/browse/SPARK-5260.

On Tue, Feb 3, 2015 at 9:15 AM, Daniil Osipov <daniil.osipov@shazam.com>
wrote:

> Thanks Reynold,
>
> Case sensitivity issues are definitely orthogonal. I'll submit a bug or PR.
>
> Is there a way to rename the object to eliminate the confusion? Not sure
> how locked down the API is at this time, but it seems like a potential
> confusion point for developers.
>
> On Mon, Feb 2, 2015 at 4:30 PM, Reynold Xin <rxin@databricks.com> wrote:
>
>> It's bad naming - JsonRDD is actually not an RDD. It is just a set of
>> util methods.
>>
>> The case sensitivity issues seem orthogonal, and would be great to be
>> able to control that with a flag.
>>
>>
>> On Mon, Feb 2, 2015 at 4:16 PM, Daniil Osipov <daniil.osipov@shazam.com>
>> wrote:
>>
>>> Hey Spark developers,
>>>
>>> Is there a good reason for JsonRDD being a Scala object as opposed to
>>> class? Seems most other RDDs are classes, and can be extended.
>>>
>>> The reason I'm asking is that there is a problem with Hive
>>> interoperability
>>> with JSON DataFrames where jsonFile generates case sensitive schema,
>>> while
>>> Hive expects case insensitive and fails with an exception during
>>> saveAsTable if there are two columns with the same name in different
>>> case.
>>>
>>> I'm trying to resolve the problem, but that requires me to extend
>>> JsonRDD,
>>> which I can't do. Other RDDs are subclass friendly, why is JsonRDD
>>> different?
>>>
>>> Dan
>>>
>>
>>
>

--001a11c2618ceed8d7050e34ed81--

From dev-return-11429-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 21:58:22 2015
Return-Path: <dev-return-11429-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 20A8717D63
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 21:58:22 +0000 (UTC)
Received: (qmail 14164 invoked by uid 500); 3 Feb 2015 21:58:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14098 invoked by uid 500); 3 Feb 2015 21:58:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14080 invoked by uid 99); 3 Feb 2015 21:58:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 21:58:21 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.182 as permitted sender)
Received: from [74.125.82.182] (HELO mail-we0-f182.google.com) (74.125.82.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 21:58:16 +0000
Received: by mail-we0-f182.google.com with SMTP id l61so47451170wev.13
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 13:56:26 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=+nL6lLFU8k9ERH3Y+gEAtMlzIeC8328BCfYnQ1wnR+g=;
        b=ZSsFoLCl3o2jf8IKHagw0Ox0yQuVzxjFcDopZ+Ttm5//f+CNF3BhjcjvVmSHpqHedU
         bClY0qSFFaz6jmvF/nETrIyTDAeKYhd95VQ0z16msit45bzYZOpa+FGFfojMESNSAvxj
         AhqMRDy1MgNVS/8DnxDSoBcG1MV6tnkDE6NZ8//roy+Qg/EgjPcI6EWbZVyctQHlJVBb
         2YJ7xls5mXHsWL0JaRz5w77AQpedvFD4M3rkIKg3dwl3YsXetbDHRCZ5pI5RRrHueQDB
         QP5bGpyGThPTysTSBVHcgxGl2gG8QXQOgd4zT3yw+azo7SypQXIDgr+BiASl+yMGVKoT
         uc7w==
X-Gm-Message-State: ALoCoQmFVHip9zrieYCfoyRJ4bOkw59fWOQ06e92qLsAZBdUG7T/YFSgqPbFOgGL2EOkSWOwoaTH
X-Received: by 10.194.173.138 with SMTP id bk10mr26275913wjc.112.1423000585910;
 Tue, 03 Feb 2015 13:56:25 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Tue, 3 Feb 2015 13:56:05 -0800 (PST)
In-Reply-To: <1422973727233-10417.post@n3.nabble.com>
References: <1422973727233-10417.post@n3.nabble.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 3 Feb 2015 15:56:05 -0600
Message-ID: <CAMAsSdK-J+50R2DBrNyNBVEy7L4RHJxhk4a0-c2Ddw6rYOzj2g@mail.gmail.com>
Subject: Re: SparkSubmit.scala and stderr
To: jayhutfles <jayhutfles@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Despite its name, stderr is frequently used as the destination for
anything that's not the output of the program, which includes log
messages. That way, for example, you can redirect the output of such a
program to capture its result without also capturing log or error
messages, which will still just print to the console.

On Tue, Feb 3, 2015 at 8:28 AM, jayhutfles <jayhutfles@gmail.com> wrote:
> Hi all,
>
> I just saw that the SparkSubmit.scala class has the following lines:
>
>   object SparkSubmit {
>     ...
>     // Exposed for testing
>     private[spark] var printStream: PrintStream = System.err
>     ...
>   }
>
> This causes all verbose logging messages elsewhere in SparkSubmit to go to
> stderr, not stdout.  Is this by design?  Verbose messages don't necessarily
> reflect errors.  But as the comment states that it's for testing, maybe I'm
> misunderstanding its intent...
>
> Thanks in advance
>   -Jay
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/SparkSubmit-scala-and-stderr-tp10417.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11430-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 22:21:18 2015
Return-Path: <dev-return-11430-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B18EB17E8B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 22:21:18 +0000 (UTC)
Received: (qmail 82264 invoked by uid 500); 3 Feb 2015 22:21:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82211 invoked by uid 500); 3 Feb 2015 22:21:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81700 invoked by uid 99); 3 Feb 2015 22:20:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:20:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.213.179 as permitted sender)
Received: from [209.85.213.179] (HELO mail-ig0-f179.google.com) (209.85.213.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:20:28 +0000
Received: by mail-ig0-f179.google.com with SMTP id l13so27992233iga.0
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 14:18:11 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=hBOd7pytpYN2pynSj9q6bM8el/DROsuJvB2kCqgXCEU=;
        b=DL6cWDrD8tj2GbkxArcNvP8KTXRPRz6T95QGe89ub9GQV6ciG6ZXOzJmVE5zSJc2K1
         HmLSMDJ7rcyNiIY5o/CliCSd3/m+Gx9HXBIc022GgbtaIJr/oikxKsdT1asV7OaEdL3D
         x25LFmynbSFjDfuT5XrQrUGipt3WHu4pVvVWyS4HPtLXXzwyH3FrWdTmzSkukU2GcOKF
         AoEZlvVHyK8ffKR5NFDtkGXUFMh+5hSF2i3XwX8o2OGWi5I0HF8ze1u2+obRkEQfWnZS
         Nmv/rG4t65yxHY5JfypvVQKK/4Q6MaXrhPYmQZ9mZs+sDDgxQcEYIx0PR3wdEbzBnqK+
         bufw==
X-Gm-Message-State: ALoCoQmIKYT9O41zS3al4nJhjqBvPO0fZJjcHbGQyUrwF2+TDiadHnUgPDhy6ug7Fghq1I0Jmb+3
MIME-Version: 1.0
X-Received: by 10.42.98.139 with SMTP id s11mr12379718icn.3.1423001890982;
 Tue, 03 Feb 2015 14:18:10 -0800 (PST)
Received: by 10.36.118.135 with HTTP; Tue, 3 Feb 2015 14:18:10 -0800 (PST)
In-Reply-To: <1422973727233-10417.post@n3.nabble.com>
References: <1422973727233-10417.post@n3.nabble.com>
Date: Tue, 3 Feb 2015 14:18:10 -0800
Message-ID: <CAAOnQ7sa2fetGBp2n5msysYuYRghvYBnGpohnJNhr_JpDLgCRA@mail.gmail.com>
Subject: Re: SparkSubmit.scala and stderr
From: Marcelo Vanzin <vanzin@cloudera.com>
To: jayhutfles <jayhutfles@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Jay,

On Tue, Feb 3, 2015 at 6:28 AM, jayhutfles <jayhutfles@gmail.com> wrote:
>     // Exposed for testing
>     private[spark] var printStream: PrintStream = System.err

> But as the comment states that it's for testing, maybe I'm
> misunderstanding its intent...

The comment is there to tell someone reading the code that this field
is a `var` and not private just because test code (SparkSubmitSuite in
this case) needs to modify it, otherwise it wouldn't exist or would be
private. Similar in spirit to this annotation:

http://guava-libraries.googlecode.com/svn/tags/release09/javadoc/com/google/common/annotations/VisibleForTesting.html

(Which I'd probably have used in this case, but is not really common
in Spark code.)

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11431-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 22:23:35 2015
Return-Path: <dev-return-11431-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8BF8E17EA8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 22:23:35 +0000 (UTC)
Received: (qmail 90352 invoked by uid 500); 3 Feb 2015 22:23:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90286 invoked by uid 500); 3 Feb 2015 22:23:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90244 invoked by uid 99); 3 Feb 2015 22:23:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:23:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.44] (HELO mail-qa0-f44.google.com) (209.85.216.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:23:09 +0000
Received: by mail-qa0-f44.google.com with SMTP id w8so36034299qac.3
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 14:22:47 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=HK/dOVOly0KeJwPbUzD5pcwbIIzrD8aveJQlWeguUCU=;
        b=WfrBINwRdaMRb7a15wJK6e/29FqWlraoMXUaxwBtwiNp0Ot1CTeI/+oH/I+eml22Ct
         7dFRPWLCqJzkFX6sEEJGdSVGx0zXfAEnMexXxtRyDHifJmeRD3JapYs6x7GNR+UfrEtw
         K4zxz/L2hR8Z/07dQ45g0EUNALbI9wiVwBUX1e3qC125lVkVV2UdPdld3dN3l+0t/Wyi
         QWhsi7dm5pStyB5duRq1yCTFe/zp4FgDGfJSnQT5D5ol34DalJEbQNIpiyrlYJBqxO9j
         JVSzRq4apTVnK1KrDpcD50bM1rA0vt349ecAVlrZmUTXz9INXR9JRaE0sX4Ch/320pI0
         9U1Q==
X-Gm-Message-State: ALoCoQmsu9FWQAwvlAaiYnV7JDGEz6blWvQoe0KqOTfGWIkJLHBF7Z2/4SocPAuPHmm/fMp2tWgY
X-Received: by 10.140.89.177 with SMTP id v46mr53702087qgd.58.1423002166900;
 Tue, 03 Feb 2015 14:22:46 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Tue, 3 Feb 2015 14:22:26 -0800 (PST)
In-Reply-To: <CAAOnQ7sa2fetGBp2n5msysYuYRghvYBnGpohnJNhr_JpDLgCRA@mail.gmail.com>
References: <1422973727233-10417.post@n3.nabble.com> <CAAOnQ7sa2fetGBp2n5msysYuYRghvYBnGpohnJNhr_JpDLgCRA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 3 Feb 2015 14:22:26 -0800
Message-ID: <CAPh_B=Zfvn-w5P0nBN7+b2qqvyZJSkya=nuxR8fK2H_8x9k-zw@mail.gmail.com>
Subject: Re: SparkSubmit.scala and stderr
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: jayhutfles <jayhutfles@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c11c60ac4cab050e368288
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c11c60ac4cab050e368288
Content-Type: text/plain; charset=UTF-8

We can use ScalaTest's privateMethodTester also instead of exposing that.

On Tue, Feb 3, 2015 at 2:18 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Hi Jay,
>
> On Tue, Feb 3, 2015 at 6:28 AM, jayhutfles <jayhutfles@gmail.com> wrote:
> >     // Exposed for testing
> >     private[spark] var printStream: PrintStream = System.err
>
> > But as the comment states that it's for testing, maybe I'm
> > misunderstanding its intent...
>
> The comment is there to tell someone reading the code that this field
> is a `var` and not private just because test code (SparkSubmitSuite in
> this case) needs to modify it, otherwise it wouldn't exist or would be
> private. Similar in spirit to this annotation:
>
>
> http://guava-libraries.googlecode.com/svn/tags/release09/javadoc/com/google/common/annotations/VisibleForTesting.html
>
> (Which I'd probably have used in this case, but is not really common
> in Spark code.)
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c11c60ac4cab050e368288--

From dev-return-11432-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 22:36:11 2015
Return-Path: <dev-return-11432-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A19DC17F1C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 22:36:11 +0000 (UTC)
Received: (qmail 27855 invoked by uid 500); 3 Feb 2015 22:36:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27783 invoked by uid 500); 3 Feb 2015 22:36:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27771 invoked by uid 99); 3 Feb 2015 22:36:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:36:11 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.43 as permitted sender)
Received: from [209.85.220.43] (HELO mail-pa0-f43.google.com) (209.85.220.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:35:44 +0000
Received: by mail-pa0-f43.google.com with SMTP id eu11so101753227pac.2
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 14:34:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-type:content-transfer-encoding:subject:date:message-id
         :cc:to:mime-version;
        bh=p5+nu001ciJocC7i4XMlfgHZnEkb+qCkMGvgeQpqg5k=;
        b=aYAfrOP57lS48OSXSU5MUq2UCfT45C5QWwJwo9ZksmJap+xstFeL05RG6s9qmhySSt
         Dze7FCmxcprcGo5ZTA7oW8shDd+kQjCgJNBVov1BqX4sDGd9+nWmjtIrDsX5k1ahMCf5
         2KShbSh+FsanCTCq2wn+ORe1KsYs3BNcV9NUcvd4UuBc+DPHLhc485WUT2sCd4aagpqT
         nXDOppGv1T9o3OrDiXoLdwuQclmGRLTC7cEhBI2tYWe1rr229tihKe9ufsaYpEHordo2
         X0MfFSB+vpXwIT1UNzSzkn4qfRBj0pUx7AI7Q7TOluTQPNf9oB4rxLcFZYNEF3oRtunk
         qQVQ==
X-Received: by 10.68.189.105 with SMTP id gh9mr9796449pbc.142.1423002852302;
        Tue, 03 Feb 2015 14:34:12 -0800 (PST)
Received: from [192.168.1.100] (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id d11sm3161515pdk.26.2015.02.03.14.34.11
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 14:34:11 -0800 (PST)
From: Matei Zaharia <matei.zaharia@gmail.com>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Subject: Welcoming three new committers
Date: Tue, 3 Feb 2015 14:34:10 -0800
Message-Id: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>,
 Joseph Bradley <joseph@databricks.com>,
 Cheng Lian <lian@databricks.com>
To: dev <dev@spark.apache.org>
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

The PMC recently voted to add three new committers: Cheng Lian, Joseph =
Bradley and Sean Owen. All three have been major contributors to Spark =
in the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML =
and many pieces throughout Spark Core. Join me in welcoming them as =
committers!

Matei=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11433-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 22:54:14 2015
Return-Path: <dev-return-11433-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 14FA617FEC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 22:54:14 +0000 (UTC)
Received: (qmail 75413 invoked by uid 500); 3 Feb 2015 22:54:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75336 invoked by uid 500); 3 Feb 2015 22:54:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75324 invoked by uid 99); 3 Feb 2015 22:54:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:54:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:54:08 +0000
Received: by mail-ig0-f180.google.com with SMTP id b16so28095092igk.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 14:53:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=KLxS2wMOou+n3594+x+jzToAb7XVm1V5XczubC+AG7U=;
        b=U1wF12JehR/jUA1s6+SqE851MzlcrB+lOrryUPsyT4mXF8m/3ZFbvsjCtWknH9cdZY
         OiKmfWMeBXDDnCHeVeyK52XVrb7d5s7h5VFuzVe8PPoBnXo5HaA5uYeZU5472LYzMdpi
         CbMMpFl3SOut4xp/V4lgWcjoxg/rsxuNjpb6IdNkfR5RS9loFmJADJ91mp2OuSvHPcoL
         bHQqTfZUxo1RrCwTFJwZZ5aTFBEmsBBUb/oIiUiLQX9zLWARor0TdO1BBlLtZO4bytyw
         q9aNOtPzhxhd12ct4dmEqVaw7MvrFTtgmtpP/OfKkhqCKwDSB+NbzaicC/Z9oa0WgBuq
         HDNQ==
X-Received: by 10.107.167.135 with SMTP id q129mr31664766ioe.23.1423004027555;
 Tue, 03 Feb 2015 14:53:47 -0800 (PST)
MIME-Version: 1.0
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 03 Feb 2015 22:53:46 +0000
Message-ID: <CAOhmDzeJxRiywZOmpU8Ov8NbdBVv55OBemZ62ZvzhNJdkPPnSQ@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: Matei Zaharia <matei.zaharia@gmail.com>, dev <dev@spark.apache.org>
Cc: Sean Owen <sowen@cloudera.com>, Joseph Bradley <joseph@databricks.com>, 
	Cheng Lian <lian@databricks.com>
Content-Type: multipart/alternative; boundary=001a1142a44493971b050e36f15c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1142a44493971b050e36f15c
Content-Type: text/plain; charset=UTF-8

Congratulations guys!

On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Hi all,
>
> The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1142a44493971b050e36f15c--

From dev-return-11434-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 22:56:08 2015
Return-Path: <dev-return-11434-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3F9E917FF9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 22:56:08 +0000 (UTC)
Received: (qmail 79100 invoked by uid 500); 3 Feb 2015 22:55:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79023 invoked by uid 500); 3 Feb 2015 22:55:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79003 invoked by uid 99); 3 Feb 2015 22:55:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:55:58 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.160.178 as permitted sender)
Received: from [209.85.160.178] (HELO mail-yk0-f178.google.com) (209.85.160.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 22:55:52 +0000
Received: by mail-yk0-f178.google.com with SMTP id q200so25693969ykb.9
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 14:55:32 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5yhKBKdLyGR0VbqWP8AaAa7Q1tiU4MuElzsR+kr432A=;
        b=dk0mmbf5gyHzqKmkNRbwWG5FXYwms9ZvbEoNtbLk2OzZany87PbqSpmK2lgAWiosCo
         b7DooU1C4MXdc0JfOCecBt2rWlpKMy4SxVGkp7qrUgEauStUIpxFOx1wba/n//X4OSvC
         Beb1O5N1LY39oWvwz3nczwk90XDJgQsdYqUinx0YDooatCzkcr/HXtFo1H0Iy6vV8siZ
         Uh0rTvAWtPNfWVXCPUHNBo1d0vk8JoOuqHPV4LFtv5jfFoq5PZb6QRo6Tnr3v5WZurmI
         r2BXc9/a5sUTgnvJeYNtCENg4yqloD9fH8f98n4GlfUy5mtlom+pz/7efv56EDmuzdoc
         yymQ==
MIME-Version: 1.0
X-Received: by 10.236.66.8 with SMTP id g8mr3738765yhd.188.1423004132237; Tue,
 03 Feb 2015 14:55:32 -0800 (PST)
Received: by 10.170.157.3 with HTTP; Tue, 3 Feb 2015 14:55:32 -0800 (PST)
In-Reply-To: <CAOhmDzeJxRiywZOmpU8Ov8NbdBVv55OBemZ62ZvzhNJdkPPnSQ@mail.gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
	<CAOhmDzeJxRiywZOmpU8Ov8NbdBVv55OBemZ62ZvzhNJdkPPnSQ@mail.gmail.com>
Date: Tue, 3 Feb 2015 14:55:32 -0800
Message-ID: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Ted Yu <yuzhihong@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, dev <dev@spark.apache.org>, 
	Sean Owen <sowen@cloudera.com>, Joseph Bradley <joseph@databricks.com>, 
	Cheng Lian <lian@databricks.com>
Content-Type: multipart/alternative; boundary=089e0139fdb0d0e806050e36f7e9
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0139fdb0d0e806050e36f7e9
Content-Type: text/plain; charset=UTF-8

Congratulations, Cheng, Joseph and Sean.

On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Congratulations guys!
>
> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>
> > Hi all,
> >
> > The PMC recently voted to add three new committers: Cheng Lian, Joseph
> > Bradley and Sean Owen. All three have been major contributors to Spark in
> > the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and
> many
> > pieces throughout Spark Core. Join me in welcoming them as committers!
> >
> > Matei
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--089e0139fdb0d0e806050e36f7e9--

From dev-return-11435-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 23:02:49 2015
Return-Path: <dev-return-11435-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B10EB17239
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 23:02:49 +0000 (UTC)
Received: (qmail 3734 invoked by uid 500); 3 Feb 2015 23:02:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3661 invoked by uid 500); 3 Feb 2015 23:02:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3650 invoked by uid 99); 3 Feb 2015 23:02:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:02:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hshreedharan@cloudera.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:02:41 +0000
Received: by mail-qg0-f53.google.com with SMTP id f51so4957287qge.12
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 15:02:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:in-reply-to
         :references:from:to:cc:subject:content-type;
        bh=by8j8Dx02cvFotaokTBh4lcq/WhEFlbhazDp/rrq+No=;
        b=JXl6u1w4+aFosLZmGSgHtODPHqUR8ftxHvjMh62piW73q3twBY+bBU9jzvdjp27B4o
         O+W57ckB7yQiAbNMnKoC4ivuiEhRefN6PgbykDxezHNHMawxM6a6U9cFGA+DFDQxxRYK
         rR8CLkWoKpp11gn3Y65MOtkNsO2826hvj/GmcTcOYdDtwAzNtd5bdulHUZhV0GbQBD8B
         K7Efcvu6k8efdeae3WfjgOYKH9jvquGh0syJer3iVVX5IbUcFrJWsK5xxRMRMJMf7/v4
         R1l+DRG/gxyjumqdeqxEvrEFOiDzHrlJTKzCQiy7g6tPOPrLXE4/50ash8yN513cpeNZ
         QMeA==
X-Gm-Message-State: ALoCoQmYefYeeLrKFFvDHuOnyHIHacQiX0Se8zEb59FNN1ohteOBKGfOGgjiwAuEzVD1lXNvSQrJ
X-Received: by 10.140.22.234 with SMTP id 97mr9230449qgn.21.1423004541037;
        Tue, 03 Feb 2015 15:02:21 -0800 (PST)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id o10sm22034488qah.35.2015.02.03.15.02.20
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 15:02:20 -0800 (PST)
Date: Tue, 03 Feb 2015 15:02:20 -0800 (PST)
X-Google-Original-Date: Tue, 03 Feb 2015 23:02:20 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1423004540014.c43aa522@Nodemailer>
In-Reply-To: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com>
References: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com>
X-Orchestra-Oid: 18EC79C0-B21A-43E2-8B79-44F11A7BF306
X-Orchestra-Sig: 33913327ce79a5d4877ad0f44e3dea6254e3379c
X-Orchestra-Thrid: TEB56D109-7104-46FE-9747-57A7D6EE5D69_1492126764801086621
X-Orchestra-Thrid-Sig: a8d64283fc424d671cb602a60aaa86b0635fc581
X-Orchestra-Account: 5d5f1e9b4ebb2d4b67bf640c2b5287124427b945
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: "Ted Yu" <yuzhihong@gmail.com>
Cc: "Nicholas Chammas" <nicholas.chammas@gmail.com>, "dev"
 <dev@spark.apache.org>, "Joseph Bradley" <joseph@databricks.com>, "Cheng
 Lian" <lian@databricks.com>, "Matei Zaharia" <matei.zaharia@gmail.com>,
 "Sean Owen" <sowen@cloudera.com>
Subject: Re: Welcoming three new committers
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1423004540419"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1423004540419
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Congrats Cheng, Joseph and Owen! Well done!




Thanks,=C2=A0Hari

On Tue, Feb 3, 2015 at 2:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Congratulations, Cheng, Joseph and Sean.
> On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas <nicholas.chammas@gmail.=
com
>> wrote:
>> Congratulations guys!
>>
>> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia <matei.zaharia@gmail.=
com>
>> wrote:
>>
>> > Hi all,
>> >
>> > The PMC recently voted to add three new committers: Cheng Lian, =
Joseph
>> > Bradley and Sean Owen. All three have been major contributors to Spark=
 in
>> > the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML =
and
>> many
>> > pieces throughout Spark Core. Join me in welcoming them as committers!=

>> >
>> > Matei
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>
------Nodemailer-0.5.0-?=_1-1423004540419--

From dev-return-11436-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 23:11:51 2015
Return-Path: <dev-return-11436-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A74F172DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 23:11:51 +0000 (UTC)
Received: (qmail 30334 invoked by uid 500); 3 Feb 2015 23:11:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30275 invoked by uid 500); 3 Feb 2015 23:11:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30263 invoked by uid 99); 3 Feb 2015 23:11:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:11:50 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of SRS0=Q_II_p=CV=nirvana-international.com=pritish@eigbox.net designates 66.96.185.6 as permitted sender)
Received: from [66.96.185.6] (HELO bosmailout06.eigbox.net) (66.96.185.6)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:11:45 +0000
Received: from bosmailscan02.eigbox.net ([10.20.15.2])
	by bosmailout06.eigbox.net with esmtp (Exim)
	id 1YImbt-0007iZ-2m
	for dev@spark.apache.org; Tue, 03 Feb 2015 18:10:21 -0500
Received: from [10.115.3.31] (helo=bosimpout11)
	by bosmailscan02.eigbox.net with esmtp (Exim)
	id 1YImbs-0005GV-T0
	for dev@spark.apache.org; Tue, 03 Feb 2015 18:10:20 -0500
Received: from bosauthsmtp11.yourhostingaccount.com ([10.20.18.11])
	by bosimpout11 with 
	id nzAG1p00j0EKspE01zAK4n; Tue, 03 Feb 2015 18:10:20 -0500
X-Authority-Analysis: v=2.1 cv=b5M8472x c=1 sm=1 tr=0
 a=anyYG9rjTBM1sAjEBQ8Cew==:117 a=5m8bdR5WECWHrEi29Stmew==:17 a=pq4jwCggAAAA:8
 a=QPcu4mC3AAAA:8 a=V0h-Sl8yMhwA:10 a=IkcTkHD0fZMA:10 a=RYXLKYPDAAAA:8
 a=kviXuzpPAAAA:8 a=0HtSIViG9nkA:10 a=IFTmCX7IAAAA:8 a=pGLkceISAAAA:8
 a=mV9VRH-2AAAA:8 a=WQwCSqVSgO7R8DKKxSQA:9 a=QEXdDO2ut3YA:10
Received: from ip98-169-85-109.dc.dc.cox.net ([98.169.85.109]:55951 helo=Nirvana)
	by bosauthsmtp11.eigbox.net with esmtpa (Exim)
	id 1YImbo-0003hP-Mt; Tue, 03 Feb 2015 18:10:16 -0500
From: "Pritish Nawlakhe" <pritish@nirvana-international.com>
To: "'Hari Shreedharan'" <hshreedharan@cloudera.com>,
	"'Ted Yu'" <yuzhihong@gmail.com>
Cc: "'Nicholas Chammas'" <nicholas.chammas@gmail.com>,
	"'dev'" <dev@spark.apache.org>,
	"'Joseph Bradley'" <joseph@databricks.com>,
	"'Cheng Lian'" <lian@databricks.com>,
	"'Matei Zaharia'" <matei.zaharia@gmail.com>,
	"'Sean Owen'" <sowen@cloudera.com>
References: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com> <1423004540014.c43aa522@Nodemailer>
In-Reply-To: <1423004540014.c43aa522@Nodemailer>
Subject: RE: Welcoming three new committers
Date: Tue, 3 Feb 2015 18:10:03 -0500
Message-ID: <001501d04006$925638d0$b702aa70$@nirvana-international.com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Outlook 14.0
Thread-Index: AQI0c0dbwhsottKYKulX8NXWtluYcALEWUVsnAEDsBA=
Content-Language: en-us
X-EN-UserInfo: b278a81a0ffe224bbf52888facaa1d72:931c98230c6409dcc37fa7e93b490c27
X-EN-AuthUser: pritish@nirvana-international.com
Sender:  "Pritish Nawlakhe" <pritish@nirvana-international.com>
X-EN-OrigIP: 98.169.85.109
X-EN-OrigHost: ip98-169-85-109.dc.dc.cox.net
X-Virus-Checked: Checked by ClamAV on apache.org

Congrats and welcome back!!



Thank you!!

Regards
Pritish
Nirvana International Inc.

Big Data, Hadoop, Oracle EBS and IT Solutions
VA - SWaM, MD - MBE Certified Company
pritish@nirvana-international.com=20
http://www.nirvana-international.com=20
Twitter: @nirvanainternat=20

-----Original Message-----
From: Hari Shreedharan [mailto:hshreedharan@cloudera.com]=20
Sent: Tuesday, February 3, 2015 6:02 PM
To: Ted Yu
Cc: Nicholas Chammas; dev; Joseph Bradley; Cheng Lian; Matei Zaharia; =
Sean Owen
Subject: Re: Welcoming three new committers

Congrats Cheng, Joseph and Owen! Well done!




Thanks, Hari

On Tue, Feb 3, 2015 at 2:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Congratulations, Cheng, Joseph and Sean.
> On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas=20
> <nicholas.chammas@gmail.com
>> wrote:
>> Congratulations guys!
>>
>> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia=20
>> <matei.zaharia@gmail.com>
>> wrote:
>>
>> > Hi all,
>> >
>> > The PMC recently voted to add three new committers: Cheng Lian,=20
>> > Joseph Bradley and Sean Owen. All three have been major=20
>> > contributors to Spark in the past year: Cheng on Spark SQL, Joseph=20
>> > on MLlib, and Sean on ML and
>> many
>> > pieces throughout Spark Core. Join me in welcoming them as =
committers!
>> >
>> > Matei
>> > -------------------------------------------------------------------
>> > -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For=20
>> > additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11437-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 23:18:26 2015
Return-Path: <dev-return-11437-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A88C417323
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 23:18:26 +0000 (UTC)
Received: (qmail 52745 invoked by uid 500); 3 Feb 2015 23:18:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52680 invoked by uid 500); 3 Feb 2015 23:18:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52660 invoked by uid 99); 3 Feb 2015 23:18:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:18:12 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tnachen@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:18:07 +0000
Received: by mail-pa0-f54.google.com with SMTP id eu11so102197557pac.13
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 15:17:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=LkGS/XMlMDbxghF31K57kmAZPiPPzovC1qip0Vb8O7c=;
        b=C3UEJNBVt08/7ZjPDfWWLKcOSXTbLr2SH8kPoXWmRzz6FwLs/3hJ84B7E5pd7kCAEs
         dUow3CCGRGqypVN4lxIrvCca9liFp9kSEx7yFWc4fgF0wHLSx8ht+gjUtmpM8lWhAN2e
         wE1w19TTKcuUtcjDld5QlIPeK6mLgGH1aGXVNBEl/4oHlOp+iSW4HHOCJIGYOa6/gPw2
         VMzqeaBlFczt1jVwHjPxVvTNxJpCNZj9j2bVAeUcSe/+x0aQX/ub++9bjM9ZeZa+MZEH
         zctFOHq8lCpQ/vFTc3fP0xMQagOeFsol04Ex3kfIHXIwi5sOBtWu0XhasEcwl93fv9dA
         FF3A==
X-Received: by 10.70.27.33 with SMTP id q1mr42209978pdg.84.1423005466852;
        Tue, 03 Feb 2015 15:17:46 -0800 (PST)
Received: from [192.168.1.113] (61-223-196-221.dynamic.hinet.net. [61.223.196.221])
        by mx.google.com with ESMTPSA id jz5sm11083pbc.0.2015.02.03.15.17.45
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 15:17:46 -0800 (PST)
Content-Type: text/plain;
	charset=us-ascii
Mime-Version: 1.0 (1.0)
Subject: Re: Welcoming three new committers
From: Timothy Chen <tnachen@gmail.com>
X-Mailer: iPhone Mail (12B440)
In-Reply-To: <001501d04006$925638d0$b702aa70$@nirvana-international.com>
Date: Wed, 4 Feb 2015 07:17:46 +0800
Cc: Hari Shreedharan <hshreedharan@cloudera.com>,
 Ted Yu <yuzhihong@gmail.com>,
 Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>,
 Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>,
 Matei Zaharia <matei.zaharia@gmail.com>, Sean Owen <sowen@cloudera.com>
Content-Transfer-Encoding: quoted-printable
Message-Id: <A0318687-F7C7-4994-AE30-569CF0B4A116@gmail.com>
References: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com> <1423004540014.c43aa522@Nodemailer> <001501d04006$925638d0$b702aa70$@nirvana-international.com>
To: Pritish Nawlakhe <pritish@nirvana-international.com>
X-Virus-Checked: Checked by ClamAV on apache.org

Congrats all!

Tim


> On Feb 4, 2015, at 7:10 AM, Pritish Nawlakhe <pritish@nirvana-internationa=
l.com> wrote:
>=20
> Congrats and welcome back!!
>=20
>=20
>=20
> Thank you!!
>=20
> Regards
> Pritish
> Nirvana International Inc.
>=20
> Big Data, Hadoop, Oracle EBS and IT Solutions
> VA - SWaM, MD - MBE Certified Company
> pritish@nirvana-international.com=20
> http://www.nirvana-international.com=20
> Twitter: @nirvanainternat=20
>=20
> -----Original Message-----
> From: Hari Shreedharan [mailto:hshreedharan@cloudera.com]=20
> Sent: Tuesday, February 3, 2015 6:02 PM
> To: Ted Yu
> Cc: Nicholas Chammas; dev; Joseph Bradley; Cheng Lian; Matei Zaharia; Sean=
 Owen
> Subject: Re: Welcoming three new committers
>=20
> Congrats Cheng, Joseph and Owen! Well done!
>=20
>=20
>=20
>=20
> Thanks, Hari
>=20
>> On Tue, Feb 3, 2015 at 2:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>=20
>> Congratulations, Cheng, Joseph and Sean.
>> On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas=20
>> <nicholas.chammas@gmail.com
>>> wrote:
>>> Congratulations guys!
>>>=20
>>> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia=20
>>> <matei.zaharia@gmail.com>
>>> wrote:
>>>=20
>>>> Hi all,
>>>>=20
>>>> The PMC recently voted to add three new committers: Cheng Lian,=20
>>>> Joseph Bradley and Sean Owen. All three have been major=20
>>>> contributors to Spark in the past year: Cheng on Spark SQL, Joseph=20
>>>> on MLlib, and Sean on ML and
>>> many
>>>> pieces throughout Spark Core. Join me in welcoming them as committers!
>>>>=20
>>>> Matei
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For=20
>>>> additional commands, e-mail: dev-help@spark.apache.org
>=20
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11438-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 23:21:58 2015
Return-Path: <dev-return-11438-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BFCB417356
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 23:21:58 +0000 (UTC)
Received: (qmail 68195 invoked by uid 500); 3 Feb 2015 23:21:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68112 invoked by uid 500); 3 Feb 2015 23:21:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66144 invoked by uid 99); 3 Feb 2015 23:21:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:21:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:21:44 +0000
Received: by mail-ob0-f172.google.com with SMTP id nt9so21752719obb.3
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 15:21:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=F8Kg1q/+ZuR+dse8AofaN9+ZHWt27bI7OY8nMP1zHcE=;
        b=LgAQuAnsPqW2WoIaxfJvAqy7bnzVlrbajEEBPr8+n++kOq21peDsr5nrqCldw9jrHk
         bK8+mwaGpHGn/bA7D4F2Nc2nUVvt0sSSIzVzVyHkkRpQ/wZ2e7ZX4CHrQ422piJfDLHA
         TjEv/59Zt/DONfviX5RMStvgvO0Am/jK+MRu14uYqiagP0BnGOkT6mq8+i9lN07CWWCh
         UcgLjryqgY4qdSqGVfzGnSjK7/JP1ObNQGfIpINWIH8ZeQx7/ilmgnZ7HYkctaXrthUL
         OLwVM2GgGVZDJA81KAwpCketzKC8R5iTgA0IsbDmUuUZXsfxV7CTJ9Q3VsP1dn0aXI6O
         ndjg==
X-Gm-Message-State: ALoCoQlHr3cmKYZS0JoLj/ZeOqmN/a0cUVRyK6DrYejROOawD513KyZ9Dbig0L5ckIRQ9wCVRvuR
X-Received: by 10.182.19.167 with SMTP id g7mr17093573obe.75.1423005663259;
 Tue, 03 Feb 2015 15:21:03 -0800 (PST)
MIME-Version: 1.0
Received: by 10.76.56.166 with HTTP; Tue, 3 Feb 2015 15:20:43 -0800 (PST)
In-Reply-To: <CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com>
References: <CAMAsSd++EeLWFNq3BF_jr_6DTti5T41pP9kVtiHcKZc40og9GA@mail.gmail.com>
 <2035367225.1416359.1422961091409.JavaMail.yahoo@mail.yahoo.com> <CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 3 Feb 2015 15:20:43 -0800
Message-ID: <CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
Subject: Re: 2GB limit for partitions?
To: Michael Albert <m_albert137@yahoo.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2ea20128ba6050e3753d5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2ea20128ba6050e3753d5
Content-Type: text/plain; charset=UTF-8

cc dev list


How are you saving the data? There are two relevant 2GB limits:

1. Caching

2. Shuffle


For caching, a partition is turned into a single block.

For shuffle, each map partition is partitioned into R blocks, where R =
number of reduce tasks. It is unlikely a shuffle block > 2G, although it
can still happen.

I think the 2nd problem is easier to fix than the 1st, because we can
handle that in the network transport layer. It'd require us to divide the
transfer of a very large block into multiple smaller blocks.



On Tue, Feb 3, 2015 at 3:00 PM, Imran Rashid <irashid@cloudera.com> wrote:

> Michael,
>
> you are right, there is definitely some limit at 2GB.  Here is a trivial
> example to demonstrate it:
>
> import org.apache.spark.storage.StorageLevel
> val d = sc.parallelize(1 to 1e6.toInt, 1).map{i => new
> Array[Byte](5e3.toInt)}.persist(StorageLevel.DISK_ONLY)
> d.count()
>
> It gives the same error you are observing.  I was under the same
> impression as Sean about the limits only being on blocks, not partitions --
> but clearly that isn't the case here.
>
> I don't know the whole story yet, but I just wanted to at least let you
> know you aren't crazy :)
> At the very least this suggests that you might need to make smaller
> partitions for now.
>
> Imran
>
>
> On Tue, Feb 3, 2015 at 4:58 AM, Michael Albert <
> m_albert137@yahoo.com.invalid> wrote:
>
>> Greetings!
>>
>> Thanks for the response.
>>
>> Below is an example of the exception I saw.
>> I'd rather not post code at the moment, so I realize it is completely
>> unreasonable to ask for a diagnosis.
>> However, I will say that adding a "partitionBy()" was the last change
>> before this error was created.
>>
>>
>> Thanks for your time and any thoughts you might have.
>>
>> Sincerely,
>>  Mike
>>
>>
>>
>> Exception in thread "main" org.apache.spark.SparkException: Job aborted
>> due to stage failure: Task 4 in stage 5.0 failed 4 times, most recent
>> failure: Lost task 4.3 in stage 5.0 (TID 6012,
>> ip-10-171-0-31.ec2.internal): java.lang.RuntimeException:
>> java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
>>     at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828)
>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:123)
>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:132)
>>     at
>> org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:517)
>>     at
>> org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:307)
>>     at
>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>     at
>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>     at
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>     at
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>     at
>> scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
>>   at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
>>     at
>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>     at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:108)
>>     at
>> org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:57)
>>
>>
>>   ------------------------------
>>  *From:* Sean Owen <sowen@cloudera.com>
>> *To:* Michael Albert <m_albert137@yahoo.com>
>> *Cc:* "user@spark.apache.org" <user@spark.apache.org>
>> *Sent:* Monday, February 2, 2015 10:13 PM
>> *Subject:* Re: 2GB limit for partitions?
>>
>> The limit is on blocks, not partitions. Partitions have many blocks.
>>
>> It sounds like you are creating very large values in memory, but I'm
>> not sure given your description. You will run into problems if a
>> single object is more than 2GB, of course. More of the stack trace
>> might show what is mapping that much memory.
>>
>> If you simply want data into 1000 files it's a lot simpler. Just
>> repartition into 1000 partitions and save the data. If you need more
>> control over what goes into which partition, use a Partitioner, yes.
>>
>>
>>
>> On Mon, Feb 2, 2015 at 8:40 PM, Michael Albert
>> <m_albert137@yahoo.com.invalid> wrote:
>> > Greetings!
>> >
>> > SPARK-1476 says that there is a 2G limit for "blocks".
>> > Is this the same as a 2G limit for partitions (or approximately so?)?
>> >
>> >
>> > What I had been attempting to do is the following.
>> > 1) Start with a moderately large data set (currently about 100GB, but
>> > growing).
>> > 2) Create about 1,000 files (yes, files) each representing a subset of
>> the
>> > data.
>> >
>> > The current attempt I am working on is something like this.
>> > 1) Do a "map" whose output key indicates which of the 1,000 files it
>> will go
>> > into and whose value is what I will want to stick into the file.
>> > 2) Partition the data and use the body of mapPartition to open a file
>> and
>> > save the data.
>> >
>> > My apologies, this is actually embedded in a bigger mess, so I won't
>> post
>> > it.
>> >
>> > However, I get errors telling me that there is an
>> "IllegalArgumentException:
>> > Size exceeds Inter.MAX_VALUE", with sun.nio.ch.FileChannelImpl.map at
>> the
>> > top of the stack.  This leads me to think that I have hit the limit or
>> > partition and/or block size.
>> >
>> > Perhaps this is not a good way to do it?
>> >
>> > I suppose I could run 1,000 passes over the data, each time collecting
>> the
>> > output for one of my 1,000 final files, but that seems likely to be
>> > painfully slow to run.
>> >
>> > Am I missing something?
>> >
>> > Admittedly, this is an odd use case....
>> >
>> > Thanks!
>> >
>> > Sincerely,
>> >  Mike Albert
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>> For additional commands, e-mail: user-help@spark.apache.org
>>
>>
>>
>>
>>
>

--001a11c2ea20128ba6050e3753d5--

From dev-return-11439-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb  3 23:46:26 2015
Return-Path: <dev-return-11439-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 476171740E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  3 Feb 2015 23:46:26 +0000 (UTC)
Received: (qmail 35869 invoked by uid 500); 3 Feb 2015 23:46:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35788 invoked by uid 500); 3 Feb 2015 23:46:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35774 invoked by uid 99); 3 Feb 2015 23:46:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:46:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of irashid@cloudera.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 03 Feb 2015 23:46:00 +0000
Received: by mail-wg0-f52.google.com with SMTP id y19so47423973wgg.11
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 15:45:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=jo4cCAaWpyTw3IPsGAM8P0V/FnjgKve4zbFBSn3RP1I=;
        b=CHGgqX4AFqAmEXmxaQAfz5TuGT/rQyv7amnVypusB8ozpVS++W0VFylC1vq6VqDSqq
         OqvQZVgwTfrCN+MXfDrVvRUeVb/GdOuLAx20FG6UX1ZEIzrA6O16ETvPSnRWAfPSr4A2
         YPhA1SVu2kXMKdg0iijSdUXQB+XcsSs6z98FXRZ2bYYTEsopxmr9xjqsZau40Aw72SjH
         Y8KjLwltBW1bySu3Xkb6uJ85Fo1qgicyOJKavFCsNCVOOh9oJqUwT8zA8hVCXJPdOj5L
         y+icEg9g3VHbBklgDtVDbqMa9ZUO9OvrZ8jqtIiWJvM3eGlDWankXCYPqKnXU7S2Q03R
         zY9g==
X-Gm-Message-State: ALoCoQmLyc+xSRD/JUd1zFqveX/NBervXmEtWi4kpIfLkCeZePDfkbYL+5cJLOCmYL/UORt3uMh/
X-Received: by 10.180.198.74 with SMTP id ja10mr39236861wic.52.1423007114127;
 Tue, 03 Feb 2015 15:45:14 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.144.194 with HTTP; Tue, 3 Feb 2015 15:44:53 -0800 (PST)
In-Reply-To: <CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
References: <CAMAsSd++EeLWFNq3BF_jr_6DTti5T41pP9kVtiHcKZc40og9GA@mail.gmail.com>
 <2035367225.1416359.1422961091409.JavaMail.yahoo@mail.yahoo.com>
 <CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com> <CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
From: Imran Rashid <irashid@cloudera.com>
Date: Tue, 3 Feb 2015 17:44:53 -0600
Message-ID: <CA+3qhFThsvx8xAzYKbzOE1LnNEKnwdXgAeTYZ32YngYMwgVnmQ@mail.gmail.com>
Subject: Re: 2GB limit for partitions?
To: Reynold Xin <rxin@databricks.com>
Cc: Michael Albert <m_albert137@yahoo.com>, "user@spark.apache.org" <user@spark.apache.org>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b62498c8d01cc050e37a9aa
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b62498c8d01cc050e37a9aa
Content-Type: text/plain; charset=UTF-8

Thanks for the explanations, makes sense.  For the record looks like this
was worked on a while back (and maybe the work is even close to a solution?)

https://issues.apache.org/jira/browse/SPARK-1476

and perhaps an independent solution was worked on here?

https://issues.apache.org/jira/browse/SPARK-1391


On Tue, Feb 3, 2015 at 5:20 PM, Reynold Xin <rxin@databricks.com> wrote:

> cc dev list
>
>
> How are you saving the data? There are two relevant 2GB limits:
>
> 1. Caching
>
> 2. Shuffle
>
>
> For caching, a partition is turned into a single block.
>
> For shuffle, each map partition is partitioned into R blocks, where R =
> number of reduce tasks. It is unlikely a shuffle block > 2G, although it
> can still happen.
>
> I think the 2nd problem is easier to fix than the 1st, because we can
> handle that in the network transport layer. It'd require us to divide the
> transfer of a very large block into multiple smaller blocks.
>
>
>
> On Tue, Feb 3, 2015 at 3:00 PM, Imran Rashid <irashid@cloudera.com> wrote:
>
>> Michael,
>>
>> you are right, there is definitely some limit at 2GB.  Here is a trivial
>> example to demonstrate it:
>>
>> import org.apache.spark.storage.StorageLevel
>> val d = sc.parallelize(1 to 1e6.toInt, 1).map{i => new
>> Array[Byte](5e3.toInt)}.persist(StorageLevel.DISK_ONLY)
>> d.count()
>>
>> It gives the same error you are observing.  I was under the same
>> impression as Sean about the limits only being on blocks, not partitions --
>> but clearly that isn't the case here.
>>
>> I don't know the whole story yet, but I just wanted to at least let you
>> know you aren't crazy :)
>> At the very least this suggests that you might need to make smaller
>> partitions for now.
>>
>> Imran
>>
>>
>> On Tue, Feb 3, 2015 at 4:58 AM, Michael Albert <
>> m_albert137@yahoo.com.invalid> wrote:
>>
>>> Greetings!
>>>
>>> Thanks for the response.
>>>
>>> Below is an example of the exception I saw.
>>> I'd rather not post code at the moment, so I realize it is completely
>>> unreasonable to ask for a diagnosis.
>>> However, I will say that adding a "partitionBy()" was the last change
>>> before this error was created.
>>>
>>>
>>> Thanks for your time and any thoughts you might have.
>>>
>>> Sincerely,
>>>  Mike
>>>
>>>
>>>
>>> Exception in thread "main" org.apache.spark.SparkException: Job aborted
>>> due to stage failure: Task 4 in stage 5.0 failed 4 times, most recent
>>> failure: Lost task 4.3 in stage 5.0 (TID 6012,
>>> ip-10-171-0-31.ec2.internal): java.lang.RuntimeException:
>>> java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
>>>     at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828)
>>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:123)
>>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:132)
>>>     at
>>> org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:517)
>>>     at
>>> org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:307)
>>>     at
>>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>>     at
>>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>>     at
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>     at
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>     at
>>> scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
>>>   at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
>>>     at
>>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>>     at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:108)
>>>     at
>>> org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:57)
>>>
>>>
>>>   ------------------------------
>>>  *From:* Sean Owen <sowen@cloudera.com>
>>> *To:* Michael Albert <m_albert137@yahoo.com>
>>> *Cc:* "user@spark.apache.org" <user@spark.apache.org>
>>> *Sent:* Monday, February 2, 2015 10:13 PM
>>> *Subject:* Re: 2GB limit for partitions?
>>>
>>> The limit is on blocks, not partitions. Partitions have many blocks.
>>>
>>> It sounds like you are creating very large values in memory, but I'm
>>> not sure given your description. You will run into problems if a
>>> single object is more than 2GB, of course. More of the stack trace
>>> might show what is mapping that much memory.
>>>
>>> If you simply want data into 1000 files it's a lot simpler. Just
>>> repartition into 1000 partitions and save the data. If you need more
>>> control over what goes into which partition, use a Partitioner, yes.
>>>
>>>
>>>
>>> On Mon, Feb 2, 2015 at 8:40 PM, Michael Albert
>>> <m_albert137@yahoo.com.invalid> wrote:
>>> > Greetings!
>>> >
>>> > SPARK-1476 says that there is a 2G limit for "blocks".
>>> > Is this the same as a 2G limit for partitions (or approximately so?)?
>>> >
>>> >
>>> > What I had been attempting to do is the following.
>>> > 1) Start with a moderately large data set (currently about 100GB, but
>>> > growing).
>>> > 2) Create about 1,000 files (yes, files) each representing a subset of
>>> the
>>> > data.
>>> >
>>> > The current attempt I am working on is something like this.
>>> > 1) Do a "map" whose output key indicates which of the 1,000 files it
>>> will go
>>> > into and whose value is what I will want to stick into the file.
>>> > 2) Partition the data and use the body of mapPartition to open a file
>>> and
>>> > save the data.
>>> >
>>> > My apologies, this is actually embedded in a bigger mess, so I won't
>>> post
>>> > it.
>>> >
>>> > However, I get errors telling me that there is an
>>> "IllegalArgumentException:
>>> > Size exceeds Inter.MAX_VALUE", with sun.nio.ch.FileChannelImpl.map at
>>> the
>>> > top of the stack.  This leads me to think that I have hit the limit or
>>> > partition and/or block size.
>>> >
>>> > Perhaps this is not a good way to do it?
>>> >
>>> > I suppose I could run 1,000 passes over the data, each time collecting
>>> the
>>> > output for one of my 1,000 final files, but that seems likely to be
>>> > painfully slow to run.
>>> >
>>> > Am I missing something?
>>> >
>>> > Admittedly, this is an odd use case....
>>> >
>>> > Thanks!
>>> >
>>> > Sincerely,
>>> >  Mike Albert
>>>
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: user-help@spark.apache.org
>>>
>>>
>>>
>>>
>>>
>>
>

--047d7b62498c8d01cc050e37a9aa--

From dev-return-11440-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 00:02:22 2015
Return-Path: <dev-return-11440-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A4C4174A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 00:02:22 +0000 (UTC)
Received: (qmail 77113 invoked by uid 500); 4 Feb 2015 00:02:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77043 invoked by uid 500); 4 Feb 2015 00:02:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77031 invoked by uid 99); 4 Feb 2015 00:02:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:02:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of velvia.github@gmail.com designates 209.85.212.172 as permitted sender)
Received: from [209.85.212.172] (HELO mail-wi0-f172.google.com) (209.85.212.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:01:56 +0000
Received: by mail-wi0-f172.google.com with SMTP id h11so28266009wiw.5
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 16:01:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SFd5C1kncldxU8rHKWCfISL2b8akSwoQkrRAMz1SNIo=;
        b=oVwLEI/OtpOqletoDbtKSeWWTP+lVGibxOAkQtUmf9DfKz2JqbkMXDGwvevY2m5Blp
         5bOWrJuUsP8PSRRWE+LN0cR4Ior6UKu0lQnfK9CtVaRSFcVJfdX4erZd4iAUDbacnsNO
         Dc0pyw6e/O+otHrSEr4DaP0mnEdONg7R84YOiO3C/YJXwxsY3OSgWM9eUXFzQZMa1U0k
         9l7wqrtLNm73GMKVfCntl00bTINp1oKV1h59/0Br0v10QGB2bnGjbqHrM0nMkK22ngl+
         GreJfGlEdsnfYmbAJJ/95c4Lq+QzQpkK5YtE/ymKt8YEgXt5+ESaEf2E73pDnskcdAJa
         +saA==
MIME-Version: 1.0
X-Received: by 10.180.160.166 with SMTP id xl6mr40100620wib.16.1423008115253;
 Tue, 03 Feb 2015 16:01:55 -0800 (PST)
Received: by 10.216.241.130 with HTTP; Tue, 3 Feb 2015 16:01:55 -0800 (PST)
In-Reply-To: <A0318687-F7C7-4994-AE30-569CF0B4A116@gmail.com>
References: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com>
	<1423004540014.c43aa522@Nodemailer>
	<001501d04006$925638d0$b702aa70$@nirvana-international.com>
	<A0318687-F7C7-4994-AE30-569CF0B4A116@gmail.com>
Date: Tue, 3 Feb 2015 16:01:55 -0800
Message-ID: <CAN6Vra2U_-VSamz2T4bY2yELb_hKEHAZMeJhHtLQPZOnpOqUpQ@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Evan Chan <velvia.github@gmail.com>
To: Timothy Chen <tnachen@gmail.com>
Cc: Pritish Nawlakhe <pritish@nirvana-international.com>, 
	Hari Shreedharan <hshreedharan@cloudera.com>, Ted Yu <yuzhihong@gmail.com>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>, 
	Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, Sean Owen <sowen@cloudera.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Congrats everyone!!!

On Tue, Feb 3, 2015 at 3:17 PM, Timothy Chen <tnachen@gmail.com> wrote:
> Congrats all!
>
> Tim
>
>
>> On Feb 4, 2015, at 7:10 AM, Pritish Nawlakhe <pritish@nirvana-international.com> wrote:
>>
>> Congrats and welcome back!!
>>
>>
>>
>> Thank you!!
>>
>> Regards
>> Pritish
>> Nirvana International Inc.
>>
>> Big Data, Hadoop, Oracle EBS and IT Solutions
>> VA - SWaM, MD - MBE Certified Company
>> pritish@nirvana-international.com
>> http://www.nirvana-international.com
>> Twitter: @nirvanainternat
>>
>> -----Original Message-----
>> From: Hari Shreedharan [mailto:hshreedharan@cloudera.com]
>> Sent: Tuesday, February 3, 2015 6:02 PM
>> To: Ted Yu
>> Cc: Nicholas Chammas; dev; Joseph Bradley; Cheng Lian; Matei Zaharia; Sean Owen
>> Subject: Re: Welcoming three new committers
>>
>> Congrats Cheng, Joseph and Owen! Well done!
>>
>>
>>
>>
>> Thanks, Hari
>>
>>> On Tue, Feb 3, 2015 at 2:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>> Congratulations, Cheng, Joseph and Sean.
>>> On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas
>>> <nicholas.chammas@gmail.com
>>>> wrote:
>>>> Congratulations guys!
>>>>
>>>> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia
>>>> <matei.zaharia@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> The PMC recently voted to add three new committers: Cheng Lian,
>>>>> Joseph Bradley and Sean Owen. All three have been major
>>>>> contributors to Spark in the past year: Cheng on Spark SQL, Joseph
>>>>> on MLlib, and Sean on ML and
>>>> many
>>>>> pieces throughout Spark Core. Join me in welcoming them as committers!
>>>>>
>>>>> Matei
>>>>> -------------------------------------------------------------------
>>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
>>>>> additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11441-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 00:04:58 2015
Return-Path: <dev-return-11441-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25A31174C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 00:04:58 +0000 (UTC)
Received: (qmail 86365 invoked by uid 500); 4 Feb 2015 00:04:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86298 invoked by uid 500); 4 Feb 2015 00:04:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86274 invoked by uid 99); 4 Feb 2015 00:04:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:04:54 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of velvia.github@gmail.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:04:29 +0000
Received: by mail-wi0-f179.google.com with SMTP id l15so221436wiw.0
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 16:02:58 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=J7ba5jmRaI+x5fjfO+sg4Du3lasEAEVJbjDSFSrzFjE=;
        b=Ig/M2VzrEAkMROUeHkc9XjEisf/9DSW700J0sPbS83q1BOOKxJ0zmJSCrSS+lCjL41
         rl0hGzvefUIJogEZ3OGdEHDg5HM5wwFS99fJCikPzOvLpGzx7mTRiw9VWyy4vp3cvGZY
         bdrJSwaL6It99pX70dCU+Sj7tclpN2NinRFNZTF3xN+QU/+bbmJEbf1SU+vJZ2X1kXca
         INJqVelyLpm9fFKSrtoZSVV+IkgoiF6aNyvIIVmENq1ZAFFbiztMb3Hc4YecUSM7tRgs
         6DAdJaBulNExOpxhvNUzMCCbVxS4dI4101+U11u7Z/B7W52fvnmFTQgU91DbHgksjG0i
         UWxA==
MIME-Version: 1.0
X-Received: by 10.194.236.200 with SMTP id uw8mr60792575wjc.10.1423008178620;
 Tue, 03 Feb 2015 16:02:58 -0800 (PST)
Received: by 10.216.241.130 with HTTP; Tue, 3 Feb 2015 16:02:58 -0800 (PST)
In-Reply-To: <CAPh_B=Zfvn-w5P0nBN7+b2qqvyZJSkya=nuxR8fK2H_8x9k-zw@mail.gmail.com>
References: <1422973727233-10417.post@n3.nabble.com>
	<CAAOnQ7sa2fetGBp2n5msysYuYRghvYBnGpohnJNhr_JpDLgCRA@mail.gmail.com>
	<CAPh_B=Zfvn-w5P0nBN7+b2qqvyZJSkya=nuxR8fK2H_8x9k-zw@mail.gmail.com>
Date: Tue, 3 Feb 2015 16:02:58 -0800
Message-ID: <CAN6Vra1V+jKBXAjq-EWGTijxsQD52EG8WF6C9oBdRoLntCyB4w@mail.gmail.com>
Subject: Re: SparkSubmit.scala and stderr
From: Evan Chan <velvia.github@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Marcelo Vanzin <vanzin@cloudera.com>, jayhutfles <jayhutfles@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Why not just use SLF4J?

On Tue, Feb 3, 2015 at 2:22 PM, Reynold Xin <rxin@databricks.com> wrote:
> We can use ScalaTest's privateMethodTester also instead of exposing that.
>
> On Tue, Feb 3, 2015 at 2:18 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
>
>> Hi Jay,
>>
>> On Tue, Feb 3, 2015 at 6:28 AM, jayhutfles <jayhutfles@gmail.com> wrote:
>> >     // Exposed for testing
>> >     private[spark] var printStream: PrintStream = System.err
>>
>> > But as the comment states that it's for testing, maybe I'm
>> > misunderstanding its intent...
>>
>> The comment is there to tell someone reading the code that this field
>> is a `var` and not private just because test code (SparkSubmitSuite in
>> this case) needs to modify it, otherwise it wouldn't exist or would be
>> private. Similar in spirit to this annotation:
>>
>>
>> http://guava-libraries.googlecode.com/svn/tags/release09/javadoc/com/google/common/annotations/VisibleForTesting.html
>>
>> (Which I'd probably have used in this case, but is not really common
>> in Spark code.)
>>
>> --
>> Marcelo
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11442-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 00:41:33 2015
Return-Path: <dev-return-11442-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 328741763A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 00:41:33 +0000 (UTC)
Received: (qmail 71084 invoked by uid 500); 4 Feb 2015 00:41:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71011 invoked by uid 500); 4 Feb 2015 00:41:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70999 invoked by uid 99); 4 Feb 2015 00:41:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:41:32 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rikima3132@gmail.com designates 209.85.192.51 as permitted sender)
Received: from [209.85.192.51] (HELO mail-qg0-f51.google.com) (209.85.192.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 00:41:27 +0000
Received: by mail-qg0-f51.google.com with SMTP id z107so55100172qgd.10
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 16:40:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:mime-version:message-id:in-reply-to:references:from:to:cc
         :subject:content-type;
        bh=3olzeMKuVLPqt0WAI1fvOJLQ9uA4gsnTSjQ50vv8a4Y=;
        b=u4dPZPGat1G4fr4fD6Jv31y+YB+vlVqYYvnPVJtO1Fca1BWaGcpKWlH02GSKi4Z1DB
         S9TYjzEmYDLZG3EK/cgaJbJov8KROUjvc7to9k62BhgysBVNyGbRcJpfbsRlVajnHWfp
         Cz9TAiQ9+M3qB4jRNFk3MqOTc+ICOVAXl4xFg8UBRco67BNT7fXi6TWSeArBCfLPb3W9
         8VcJmdh7/NOPP4ClUBosiCiH1oV2typW0lUBCjt7sAQ4h95NASBMYoEniX07MuXE93gx
         L0vbL+5ykck4pR/YBCqCf93YzTCdkGA1B+Y/8PGNFNfJxrk+i/1zmObvOkK75t8nhxwc
         0Wcw==
X-Received: by 10.140.37.39 with SMTP id q36mr53715127qgq.89.1423010421836;
        Tue, 03 Feb 2015 16:40:21 -0800 (PST)
Received: from hedwig-32.prd.orcali.com (ec2-54-85-253-254.compute-1.amazonaws.com. [54.85.253.254])
        by mx.google.com with ESMTPSA id o105sm161777qge.39.2015.02.03.16.40.20
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 16:40:20 -0800 (PST)
Date: Tue, 03 Feb 2015 16:40:20 -0800 (PST)
X-Google-Original-Date: Wed, 04 Feb 2015 00:40:19 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1423010419583.5905f88b@Nodemailer>
In-Reply-To: <CAJgQjQ-bQNhSUdFALjQARcsd7=Q5qEP9HR_NT+udpxRHxQc5GQ@mail.gmail.com>
References: <CAJgQjQ-bQNhSUdFALjQARcsd7=Q5qEP9HR_NT+udpxRHxQc5GQ@mail.gmail.com>
X-Orchestra-Oid: 74B3A96C-E68C-456D-BA55-7EF26217756F
X-Orchestra-Sig: 90a9930ee432f96022d0637b4060b1fc2ba6ca29
X-Orchestra-Thrid: T6FB7293C-9FCD-4FB8-BBA2-693EE8DD50EC_1492060091345796891
X-Orchestra-Thrid-Sig: d47986e3bbd957573cea3702015e304f17c200f6
X-Orchestra-Account: 9f82b2d17608c9f593801d4f03cec402614df483
From: "masaki rikitoku" <rikima3132@gmail.com>
To: "Xiangrui Meng" <mengxr@gmail.com>
Cc: "dev" <dev@spark.apache.org>
Subject: Re: IDF for ml pipeline
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1423010420732"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1423010420732
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Thank you for your reply. I will do it.



=E2=80=94
Mailbox =E3=81=8B=E3=82=89=E9=80=81=E4=BF=A1

On Tue, Feb 3, 2015 at 6:12 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Yes, we need a wrapper under spark.ml. Feel free to create a JIRA for
> it. -Xiangrui
> On Mon, Feb 2, 2015 at 8:56 PM, masaki rikitoku <rikima3132@gmail.com> =
wrote:
>> Hi all
>>
>> I am trying the ml pipeline for text classfication now.
>>
>> recently, i succeed to execute the pipeline processing in ml packages,
>> which consist of the original Japanese tokenizer, hashingTF,
>> logisticRegression.
>>
>> then,  i failed to  executed the pipeline with idf in mllib package =
directly.
>>
>> To use the idf feature in ml package,
>> do i have to implement the wrapper for idf in ml package like the =
hashingTF=3F
>>
>> best
>>
>> Masaki Rikitoku
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
------Nodemailer-0.5.0-?=_1-1423010420732--

From dev-return-11443-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:03:55 2015
Return-Path: <dev-return-11443-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DCA6F17733
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:03:55 +0000 (UTC)
Received: (qmail 20297 invoked by uid 500); 4 Feb 2015 01:03:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20223 invoked by uid 500); 4 Feb 2015 01:03:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20211 invoked by uid 99); 4 Feb 2015 01:03:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:03:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cjnolet@gmail.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:03:50 +0000
Received: by mail-ig0-f174.google.com with SMTP id b16so31299441igk.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:01:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=jF2/+QRWoO6+eVELO1RrZCdZqN3OSpLlAOf6NstGFAo=;
        b=HAeuoaIZ+bMxZbDrcTURprRmmIMsec8XsnnINoST5J87yylGy+emF7UY5DzQDB9m1m
         kKysvX6Ka5AD4Zblq4XRKgC4mkVWIi9xr4ZVnP+nQqh3oLyAapOikVKSaA0PDul40/Rz
         dgYf+Rs4ua7kV+TRtEZUyWKBRUKnvSTvQyjXDGS+Gg1t+gN33WGjmUbG+bVrE494UaGu
         hrmkGtJetqJkVHqdOxhR59GbuZ2Y1zCIaDJgyjv8+qZf+8OJcJ1REEMOOcP1LoIPNocX
         EplSoQWnViQk4qUHA5CUxSyhgN62JIdCSG+TAI6l+HfyvOQjUySW36pxXuk/aJiiPzC/
         GZ0w==
X-Received: by 10.107.26.136 with SMTP id a130mr8389977ioa.2.1423011719479;
 Tue, 03 Feb 2015 17:01:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.232.146 with HTTP; Tue, 3 Feb 2015 17:01:39 -0800 (PST)
In-Reply-To: <CAN6Vra2U_-VSamz2T4bY2yELb_hKEHAZMeJhHtLQPZOnpOqUpQ@mail.gmail.com>
References: <CALte62yxgFr01FgMegxsvYpizGFSCfyOCw65TZLTu01kXx2shg@mail.gmail.com>
 <1423004540014.c43aa522@Nodemailer> <001501d04006$925638d0$b702aa70$@nirvana-international.com>
 <A0318687-F7C7-4994-AE30-569CF0B4A116@gmail.com> <CAN6Vra2U_-VSamz2T4bY2yELb_hKEHAZMeJhHtLQPZOnpOqUpQ@mail.gmail.com>
From: Corey Nolet <cjnolet@gmail.com>
Date: Tue, 3 Feb 2015 20:01:39 -0500
Message-ID: <CAOHP_tFBpiD3eZ0wVwtk7f=h37DhaSaL=HLu=xXSAyfD7N97TA@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: Evan Chan <velvia.github@gmail.com>
Cc: Timothy Chen <tnachen@gmail.com>, Pritish Nawlakhe <pritish@nirvana-international.com>, 
	Hari Shreedharan <hshreedharan@cloudera.com>, Ted Yu <yuzhihong@gmail.com>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>, 
	Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, Sean Owen <sowen@cloudera.com>
Content-Type: multipart/alternative; boundary=001a113ff0a40d33bb050e38bc2b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ff0a40d33bb050e38bc2b
Content-Type: text/plain; charset=UTF-8

Congrats guys!

On Tue, Feb 3, 2015 at 7:01 PM, Evan Chan <velvia.github@gmail.com> wrote:

> Congrats everyone!!!
>
> On Tue, Feb 3, 2015 at 3:17 PM, Timothy Chen <tnachen@gmail.com> wrote:
> > Congrats all!
> >
> > Tim
> >
> >
> >> On Feb 4, 2015, at 7:10 AM, Pritish Nawlakhe <
> pritish@nirvana-international.com> wrote:
> >>
> >> Congrats and welcome back!!
> >>
> >>
> >>
> >> Thank you!!
> >>
> >> Regards
> >> Pritish
> >> Nirvana International Inc.
> >>
> >> Big Data, Hadoop, Oracle EBS and IT Solutions
> >> VA - SWaM, MD - MBE Certified Company
> >> pritish@nirvana-international.com
> >> http://www.nirvana-international.com
> >> Twitter: @nirvanainternat
> >>
> >> -----Original Message-----
> >> From: Hari Shreedharan [mailto:hshreedharan@cloudera.com]
> >> Sent: Tuesday, February 3, 2015 6:02 PM
> >> To: Ted Yu
> >> Cc: Nicholas Chammas; dev; Joseph Bradley; Cheng Lian; Matei Zaharia;
> Sean Owen
> >> Subject: Re: Welcoming three new committers
> >>
> >> Congrats Cheng, Joseph and Owen! Well done!
> >>
> >>
> >>
> >>
> >> Thanks, Hari
> >>
> >>> On Tue, Feb 3, 2015 at 2:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> >>>
> >>> Congratulations, Cheng, Joseph and Sean.
> >>> On Tue, Feb 3, 2015 at 2:53 PM, Nicholas Chammas
> >>> <nicholas.chammas@gmail.com
> >>>> wrote:
> >>>> Congratulations guys!
> >>>>
> >>>> On Tue Feb 03 2015 at 2:36:12 PM Matei Zaharia
> >>>> <matei.zaharia@gmail.com>
> >>>> wrote:
> >>>>
> >>>>> Hi all,
> >>>>>
> >>>>> The PMC recently voted to add three new committers: Cheng Lian,
> >>>>> Joseph Bradley and Sean Owen. All three have been major
> >>>>> contributors to Spark in the past year: Cheng on Spark SQL, Joseph
> >>>>> on MLlib, and Sean on ML and
> >>>> many
> >>>>> pieces throughout Spark Core. Join me in welcoming them as
> committers!
> >>>>>
> >>>>> Matei
> >>>>> -------------------------------------------------------------------
> >>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
> >>>>> additional commands, e-mail: dev-help@spark.apache.org
> >>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113ff0a40d33bb050e38bc2b--

From dev-return-11444-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:09:46 2015
Return-Path: <dev-return-11444-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F2631776A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:09:46 +0000 (UTC)
Received: (qmail 43263 invoked by uid 500); 4 Feb 2015 01:09:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43195 invoked by uid 500); 4 Feb 2015 01:09:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43183 invoked by uid 99); 4 Feb 2015 01:09:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:09:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of benewu@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:09:15 +0000
Received: by mail-pa0-f50.google.com with SMTP id rd3so103146289pab.9
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:08:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=LQ0yFBPSM9W9uwVKoqSVzWyd1UryyPK5H6+1GoO2QDM=;
        b=GzuKnfmiBXSKGO3Pojjt/jBGutTvjI9mmHwydE+l02x4385F23e7iGe7K92h22Ztq7
         cqrCfouWHk0HWuyaBpWnk3atKvLb3n2LCxuaGptsJGDN/Y+s7tiAO3/gXeQ0vxqyU6YS
         pitSzXXEHgjkt4TSAz8h/1Ww83nuRK/NIhCHb8+fiyBE6nDF0Dl0zyLAfbGjwHYDo4J+
         RTfNHQLvrHQfeI/4Tztp0nRyWkfMYu2Yg6B9YonwF2lK8D8UwKF03y/1frMERpjPYh85
         2ckUig6Fvx4kosIAiSG/6KAyxBv7CA5DNzwotdMygmKiI3PoHj7h9BS2+obEaTeSJJd9
         xA2g==
X-Received: by 10.66.141.176 with SMTP id rp16mr42986100pab.11.1423012108013;
        Tue, 03 Feb 2015 17:08:28 -0800 (PST)
Received: from [192.168.0.234] (li637-157.members.linode.com. [106.186.117.157])
        by mx.google.com with ESMTPSA id cb2sm127863pbd.37.2015.02.03.17.08.25
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 17:08:26 -0800 (PST)
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Content-Type: text/plain;
	charset=gb2312
Content-Transfer-Encoding: quoted-printable
Message-Id: <F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com>
Cc: dev <dev@spark.apache.org>, Sean Owen <sowen@cloudera.com>,
 Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>
X-Mailer: iPhone Mail (12B466)
From: Xuefeng Wu <benewu@gmail.com>
Subject: Re: Welcoming three new committers
Date: Wed, 4 Feb 2015 09:08:20 +0800
To: Matei Zaharia <matei.zaharia@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

Congratulations=A3=A1well done.=20

Yours, Xuefeng Wu =CE=E2=D1=A9=B7=E5 =BE=B4=C9=CF

> On 2015=C4=EA2=D4=C24=C8=D5, at =C9=CF=CE=E76:34, Matei Zaharia <matei.zah=
aria@gmail.com> wrote:
>=20
> Hi all,
>=20
> The PMC recently voted to add three new committers: Cheng Lian, Joseph Bra=
dley and Sean Owen. All three have been major contributors to Spark in the p=
ast year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many piece=
s throughout Spark Core. Join me in welcoming them as committers!
>=20
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11445-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:27:25 2015
Return-Path: <dev-return-11445-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0D3BF177D3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:27:25 +0000 (UTC)
Received: (qmail 70192 invoked by uid 500); 4 Feb 2015 01:27:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70117 invoked by uid 500); 4 Feb 2015 01:27:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70105 invoked by uid 99); 4 Feb 2015 01:27:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:27:24 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.192.42 as permitted sender)
Received: from [209.85.192.42] (HELO mail-qg0-f42.google.com) (209.85.192.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:27:18 +0000
Received: by mail-qg0-f42.google.com with SMTP id q107so55340504qgd.1
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:26:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=Kofj9tHF73TsYtIpBkYYmQgxSNx8a9jm0hfAjdI1hPc=;
        b=FgcbSLiCOT0j0cClktFZgoAGVttCryR90jIkqveOV7unl6EvSu0oAGnbUHOyYgyQoU
         kxJufjYbV6kKfMTWOfMOWsB2ZQWpWk/CH7+sHcSVKg/t+kqt2CJhryLLoHTRSpaBYfKC
         z4hrpo5CM1wzrbEajcl6kBsnwiixx1tL1LlysmTX9pY9wiMHeymxyKNu+CRRgY5sw32j
         RZ/uLBqYshsmy/j58TEzBBVNz73UH2+OcK44+LD98w96Jgb9mUwsm3RNENFm/tB/+34d
         eEPu/YitracPaju7YslK5N8bLsdiGuZn9/uOEJ+X5Lf8R1Urw8AwhPGGfcC1UuYqmtIW
         2ENQ==
X-Received: by 10.224.160.81 with SMTP id m17mr50214453qax.63.1423013173023;
        Tue, 03 Feb 2015 17:26:13 -0800 (PST)
Received: from [192.168.2.16] (bas3-montreal42-1242353428.dsl.bell.ca. [74.12.207.20])
        by mx.google.com with ESMTPSA id a1sm271700qab.28.2015.02.03.17.26.12
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 17:26:12 -0800 (PST)
Date: Tue, 3 Feb 2015 20:26:11 -0500
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Xuefeng Wu <benewu@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, dev <dev@spark.apache.org>, 
 Sean Owen <sowen@cloudera.com>, Joseph Bradley <joseph@databricks.com>, 
 Cheng Lian <lian@databricks.com>
Message-ID: <F61982DA568A4F8F9E9446D0D135F06B@gmail.com>
In-Reply-To: <F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
 <F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com>
Subject: Re: Welcoming three new committers
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54d17533_643c9869_1d5"
X-Virus-Checked: Checked by ClamAV on apache.org

--54d17533_643c9869_1d5
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Congratulations=21

-- =20
Nan Zhu
http://codingcat.me


On Tuesday, =46ebruary 3, 2015 at 8:08 PM, Xuefeng Wu wrote:

> Congratulations=EF=BC=81well done. =20
> =20
> Yours, Xuefeng Wu =E5=90=B4=E9=9B=AA=E5=B3=B0 =E6=95=AC=E4=B8=8A
> =20
> > On 2015=E5=B9=B42=E6=9C=884=E6=97=A5, at =E4=B8=8A=E5=8D=886:34, Mate=
i Zaharia <matei.zaharia=40gmail.com (mailto:matei.zaharia=40gmail.com)> =
wrote:
> > =20
> > Hi all,
> > =20
> > The PMC recently voted to add three new committers: Cheng Lian, Josep=
h Bradley and Sean Owen. All three have been major contributors to Spark =
in the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and=
 many pieces throughout Spark Core. Join me in welcoming them as committe=
rs=21
> > =20
> > Matei
> > ---------------------------------------------------------------------=

> > To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org (mailto:de=
v-unsubscribe=40spark.apache.org)
> > =46or additional commands, e-mail: dev-help=40spark.apache.org (mailt=
o:dev-help=40spark.apache.org)
> > =20
> =20
> =20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org (mailto:dev-=
unsubscribe=40spark.apache.org)
> =46or additional commands, e-mail: dev-help=40spark.apache.org (mailto:=
dev-help=40spark.apache.org)
> =20
> =20



--54d17533_643c9869_1d5--


From dev-return-11446-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:30:10 2015
Return-Path: <dev-return-11446-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BAEAF177E6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:30:10 +0000 (UTC)
Received: (qmail 76228 invoked by uid 500); 4 Feb 2015 01:29:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76147 invoked by uid 500); 4 Feb 2015 01:29:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76129 invoked by uid 99); 4 Feb 2015 01:29:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:29:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mridul@gmail.com designates 209.85.192.45 as permitted sender)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:29:49 +0000
Received: by mail-qg0-f45.google.com with SMTP id q107so55346484qgd.4
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:29:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Ljk80yATyQCwFf8LaZRK7rBiefg1nwoEa2oRp1+A2Y8=;
        b=kluYYbCTNjNPcOVQPinyJP7Bje8tFwtCeZ9RudmeNidFE6lkbqBeSl4uMyEU3Rjnok
         f4IWYLKv4IuxqhL+5SnOuSS4OJcKlLsnOa3E6x8w87m935ucAs069hl+BWqKgh9Tr0+d
         C4nqJzwYQQ3PZkXknS8Ra46yAClFQ9Th4wahwDDFEVlJtSg45eRH3MzNSTM8DMkHe4JU
         RmhkwAW6fGsWRlYEua8BJm/Q4MyiCkuoTAY3o3PILcnhfwTaWLclGCMlo2M9klrM7dFl
         +NRVuOXRx/YbMt5vfkc9fxAgD5CggkaTc8jBdE7Z0o9HMUMrkl1VAECSVY2CBrqaL1Uq
         GVlw==
MIME-Version: 1.0
X-Received: by 10.224.80.202 with SMTP id u10mr4629546qak.57.1423013368507;
 Tue, 03 Feb 2015 17:29:28 -0800 (PST)
Received: by 10.140.33.230 with HTTP; Tue, 3 Feb 2015 17:29:28 -0800 (PST)
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Date: Tue, 3 Feb 2015 17:29:28 -0800
Message-ID: <CAJiQeY+W0miJ8Tq2xpMEGHXWNdAxCAfutCmegrCWjhrp=YPdKQ@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Mridul Muralidharan <mridul@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: dev <dev@spark.apache.org>, Sean Owen <sowen@cloudera.com>, 
	Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>
Content-Type: multipart/alternative; boundary=001a11c3cf1a5733a2050e391e41
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3cf1a5733a2050e391e41
Content-Type: text/plain; charset=UTF-8

Congratulations !
Keep up the good work :-)

Regards
Mridul


On Tuesday, February 3, 2015, Matei Zaharia <matei.zaharia@gmail.com> wrote:

> Hi all,
>
> The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: dev-help@spark.apache.org <javascript:;>
>
>

--001a11c3cf1a5733a2050e391e41--

From dev-return-11447-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:34:01 2015
Return-Path: <dev-return-11447-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3A23F177F8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:34:01 +0000 (UTC)
Received: (qmail 83802 invoked by uid 500); 4 Feb 2015 01:34:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83729 invoked by uid 500); 4 Feb 2015 01:34:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83717 invoked by uid 99); 4 Feb 2015 01:34:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:34:00 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of crazyjvm@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:33:34 +0000
Received: by mail-pa0-f50.google.com with SMTP id rd3so103392685pab.9
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:32:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=Tdk8mhYq2+ieyBcQhr+fQ9DGy+fMfD89I3uE1R0MpuU=;
        b=NWEUNA2yTLuoQ5OM4XYQCgPA19MOkszv+mrUMAo24X/4eyPVe7flC9Q9iIBmfBjch1
         TpzxqLcOzjBkBCVDYsyO68PAIDG1MofXnbWfTj5MUV9WpNpxcYa4bxqn563IWwK1ucv4
         v6cwsTSPWg9YRZ7uSWX+49R3ZZg1s3kvuHWpJV1xJ323r1BZMd/EM/3d2k6bg/mNs1P/
         IsqIc44dbgjrsm/syBo5ZGF6kQxML/85HjGLC08n4uHPmJCAEgBavWJVEQeqxY3eOarh
         84BiX2D/A9PSESnlWxwp9n5OsCmDhPiytNYc9TmLfrovn/eMstL9zuu/pDTgWxNCSAwd
         SI7Q==
X-Received: by 10.68.203.136 with SMTP id kq8mr10988084pbc.103.1423013567455;
        Tue, 03 Feb 2015 17:32:47 -0800 (PST)
Received: from CC.local ([23.234.19.123])
        by mx.google.com with ESMTPSA id ns6sm135751pbb.77.2015.02.03.17.32.45
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 03 Feb 2015 17:32:46 -0800 (PST)
Message-ID: <54D176B9.9070900@gmail.com>
Date: Wed, 04 Feb 2015 09:32:41 +0800
From: Chao Chen <crazyjvm@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: Welcoming three new committers
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com> <F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com> <F61982DA568A4F8F9E9446D0D135F06B@gmail.com>
In-Reply-To: <F61982DA568A4F8F9E9446D0D135F06B@gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Congratulations guys, well done!

在 15-2-4 上午9:26, Nan Zhu 写道:
> Congratulations!
>
> --
> Nan Zhu
> http://codingcat.me
>
>
> On Tuesday, February 3, 2015 at 8:08 PM, Xuefeng Wu wrote:
>
>> Congratulations！well done.
>>   
>> Yours, Xuefeng Wu 吴雪峰 敬上
>>   
>>> On 2015年2月4日, at 上午6:34, Matei Zaharia <matei.zaharia@gmail.com (mailto:matei.zaharia@gmail.com)> wrote:
>>>   
>>> Hi all,
>>>   
>>> The PMC recently voted to add three new committers: Cheng Lian, Joseph Bradley and Sean Owen. All three have been major contributors to Spark in the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many pieces throughout Spark Core. Join me in welcoming them as committers!
>>>   
>>> Matei
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
>>> For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
>>>   
>>   
>>   
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
>> For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
>>   
>>   
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11448-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:34:09 2015
Return-Path: <dev-return-11448-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E2402177FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:34:08 +0000 (UTC)
Received: (qmail 85674 invoked by uid 500); 4 Feb 2015 01:34:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85535 invoked by uid 500); 4 Feb 2015 01:34:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85431 invoked by uid 99); 4 Feb 2015 01:34:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:34:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mridul@gmail.com designates 209.85.192.45 as permitted sender)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:34:00 +0000
Received: by mail-qg0-f45.google.com with SMTP id q107so55356334qgd.4;
        Tue, 03 Feb 2015 17:32:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SpAWL63UvetwjNzqDK2fqHb1+x0wjL/qhvC5NTTEd4c=;
        b=Z2cZD8FWrpup45OPUV1rrOWaV6Dbz4r6W6q0upWWALFcWirihFoZD/mHFS7tGBVoBu
         sNVw616XNIZTxivwMs9CeztsH0NIkGfCUF9xKqYNkLDZmojlkCtsjTTYD7Szy3tk3/GH
         Tj/XHA5PlIewBRGDsBXdEyYlNeHPWpWqcDZm/Trxhgp9nLtyLr0wK/m9yEsvdKIOrmDU
         5hWcD7MB4Z2DVa9np0uA6Hb1KtvqDfFr+J1XMBWbgvYj/JthcR7K7aPggOPScXHFuyD6
         YOuDiR66gaLDoCF9u0HhuDEysBP0pZZ9rb84QdVu0mcJNM1NUb20L8ikib+8wRzRx5zp
         OL8w==
MIME-Version: 1.0
X-Received: by 10.224.61.2 with SMTP id r2mr58100599qah.92.1423013575236; Tue,
 03 Feb 2015 17:32:55 -0800 (PST)
Received: by 10.140.33.230 with HTTP; Tue, 3 Feb 2015 17:32:55 -0800 (PST)
In-Reply-To: <CA+3qhFThsvx8xAzYKbzOE1LnNEKnwdXgAeTYZ32YngYMwgVnmQ@mail.gmail.com>
References: <CAMAsSd++EeLWFNq3BF_jr_6DTti5T41pP9kVtiHcKZc40og9GA@mail.gmail.com>
	<2035367225.1416359.1422961091409.JavaMail.yahoo@mail.yahoo.com>
	<CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com>
	<CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
	<CA+3qhFThsvx8xAzYKbzOE1LnNEKnwdXgAeTYZ32YngYMwgVnmQ@mail.gmail.com>
Date: Tue, 3 Feb 2015 17:32:55 -0800
Message-ID: <CAJiQeYKMi76qPivAx4xCFoah7UBDJGGBfAH0AR4hF9kanx_7yQ@mail.gmail.com>
Subject: Re: 2GB limit for partitions?
From: Mridul Muralidharan <mridul@gmail.com>
To: Imran Rashid <irashid@cloudera.com>
Cc: Reynold Xin <rxin@databricks.com>, Michael Albert <m_albert137@yahoo.com>, 
	"user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3ddf8a9a409050e392a57
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3ddf8a9a409050e392a57
Content-Type: text/plain; charset=UTF-8

That is fairly out of date (we used to run some of our jobs on it ... But
that is forked off 1.1 actually).

Regards
Mridul

On Tuesday, February 3, 2015, Imran Rashid <irashid@cloudera.com> wrote:

> Thanks for the explanations, makes sense.  For the record looks like this
> was worked on a while back (and maybe the work is even close to a
> solution?)
>
> https://issues.apache.org/jira/browse/SPARK-1476
>
> and perhaps an independent solution was worked on here?
>
> https://issues.apache.org/jira/browse/SPARK-1391
>
>
> On Tue, Feb 3, 2015 at 5:20 PM, Reynold Xin <rxin@databricks.com
> <javascript:;>> wrote:
>
> > cc dev list
> >
> >
> > How are you saving the data? There are two relevant 2GB limits:
> >
> > 1. Caching
> >
> > 2. Shuffle
> >
> >
> > For caching, a partition is turned into a single block.
> >
> > For shuffle, each map partition is partitioned into R blocks, where R =
> > number of reduce tasks. It is unlikely a shuffle block > 2G, although it
> > can still happen.
> >
> > I think the 2nd problem is easier to fix than the 1st, because we can
> > handle that in the network transport layer. It'd require us to divide the
> > transfer of a very large block into multiple smaller blocks.
> >
> >
> >
> > On Tue, Feb 3, 2015 at 3:00 PM, Imran Rashid <irashid@cloudera.com
> <javascript:;>> wrote:
> >
> >> Michael,
> >>
> >> you are right, there is definitely some limit at 2GB.  Here is a trivial
> >> example to demonstrate it:
> >>
> >> import org.apache.spark.storage.StorageLevel
> >> val d = sc.parallelize(1 to 1e6.toInt, 1).map{i => new
> >> Array[Byte](5e3.toInt)}.persist(StorageLevel.DISK_ONLY)
> >> d.count()
> >>
> >> It gives the same error you are observing.  I was under the same
> >> impression as Sean about the limits only being on blocks, not
> partitions --
> >> but clearly that isn't the case here.
> >>
> >> I don't know the whole story yet, but I just wanted to at least let you
> >> know you aren't crazy :)
> >> At the very least this suggests that you might need to make smaller
> >> partitions for now.
> >>
> >> Imran
> >>
> >>
> >> On Tue, Feb 3, 2015 at 4:58 AM, Michael Albert <
> >> m_albert137@yahoo.com.invalid> wrote:
> >>
> >>> Greetings!
> >>>
> >>> Thanks for the response.
> >>>
> >>> Below is an example of the exception I saw.
> >>> I'd rather not post code at the moment, so I realize it is completely
> >>> unreasonable to ask for a diagnosis.
> >>> However, I will say that adding a "partitionBy()" was the last change
> >>> before this error was created.
> >>>
> >>>
> >>> Thanks for your time and any thoughts you might have.
> >>>
> >>> Sincerely,
> >>>  Mike
> >>>
> >>>
> >>>
> >>> Exception in thread "main" org.apache.spark.SparkException: Job aborted
> >>> due to stage failure: Task 4 in stage 5.0 failed 4 times, most recent
> >>> failure: Lost task 4.3 in stage 5.0 (TID 6012,
> >>> ip-10-171-0-31.ec2.internal): java.lang.RuntimeException:
> >>> java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
> >>>     at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828)
> >>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:123)
> >>>     at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:132)
> >>>     at
> >>>
> org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:517)
> >>>     at
> >>>
> org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:307)
> >>>     at
> >>>
> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
> >>>     at
> >>>
> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
> >>>     at
> >>>
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
> >>>     at
> >>>
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
> >>>     at
> >>>
> scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
> >>>   at
> scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
> >>>     at
> >>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
> >>>     at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:108)
> >>>     at
> >>>
> org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:57)
> >>>
> >>>
> >>>   ------------------------------
> >>>  *From:* Sean Owen <sowen@cloudera.com <javascript:;>>
> >>> *To:* Michael Albert <m_albert137@yahoo.com <javascript:;>>
> >>> *Cc:* "user@spark.apache.org <javascript:;>" <user@spark.apache.org
> <javascript:;>>
> >>> *Sent:* Monday, February 2, 2015 10:13 PM
> >>> *Subject:* Re: 2GB limit for partitions?
> >>>
> >>> The limit is on blocks, not partitions. Partitions have many blocks.
> >>>
> >>> It sounds like you are creating very large values in memory, but I'm
> >>> not sure given your description. You will run into problems if a
> >>> single object is more than 2GB, of course. More of the stack trace
> >>> might show what is mapping that much memory.
> >>>
> >>> If you simply want data into 1000 files it's a lot simpler. Just
> >>> repartition into 1000 partitions and save the data. If you need more
> >>> control over what goes into which partition, use a Partitioner, yes.
> >>>
> >>>
> >>>
> >>> On Mon, Feb 2, 2015 at 8:40 PM, Michael Albert
> >>> <m_albert137@yahoo.com.invalid> wrote:
> >>> > Greetings!
> >>> >
> >>> > SPARK-1476 says that there is a 2G limit for "blocks".
> >>> > Is this the same as a 2G limit for partitions (or approximately so?)?
> >>> >
> >>> >
> >>> > What I had been attempting to do is the following.
> >>> > 1) Start with a moderately large data set (currently about 100GB, but
> >>> > growing).
> >>> > 2) Create about 1,000 files (yes, files) each representing a subset
> of
> >>> the
> >>> > data.
> >>> >
> >>> > The current attempt I am working on is something like this.
> >>> > 1) Do a "map" whose output key indicates which of the 1,000 files it
> >>> will go
> >>> > into and whose value is what I will want to stick into the file.
> >>> > 2) Partition the data and use the body of mapPartition to open a file
> >>> and
> >>> > save the data.
> >>> >
> >>> > My apologies, this is actually embedded in a bigger mess, so I won't
> >>> post
> >>> > it.
> >>> >
> >>> > However, I get errors telling me that there is an
> >>> "IllegalArgumentException:
> >>> > Size exceeds Inter.MAX_VALUE", with sun.nio.ch.FileChannelImpl.map at
> >>> the
> >>> > top of the stack.  This leads me to think that I have hit the limit
> or
> >>> > partition and/or block size.
> >>> >
> >>> > Perhaps this is not a good way to do it?
> >>> >
> >>> > I suppose I could run 1,000 passes over the data, each time
> collecting
> >>> the
> >>> > output for one of my 1,000 final files, but that seems likely to be
> >>> > painfully slow to run.
> >>> >
> >>> > Am I missing something?
> >>> >
> >>> > Admittedly, this is an odd use case....
> >>> >
> >>> > Thanks!
> >>> >
> >>> > Sincerely,
> >>> >  Mike Albert
> >>>
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> <javascript:;>
> >>> For additional commands, e-mail: user-help@spark.apache.org
> <javascript:;>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>
> >
>

--001a11c3ddf8a9a409050e392a57--

From dev-return-11449-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:35:51 2015
Return-Path: <dev-return-11449-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 05E3C1780F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:35:51 +0000 (UTC)
Received: (qmail 94891 invoked by uid 500); 4 Feb 2015 01:35:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94814 invoked by uid 500); 4 Feb 2015 01:35:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94688 invoked by uid 99); 4 Feb 2015 01:35:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:35:25 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.46 as permitted sender)
Received: from [209.85.220.46] (HELO mail-pa0-f46.google.com) (209.85.220.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:35:00 +0000
Received: by mail-pa0-f46.google.com with SMTP id lj1so103460643pab.5
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:34:58 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=B27OhM30MOkBKKuqHBh/yEzQCMZiOEB8Bv3Nr8kmbY8=;
        b=ERT7CyYtxPWhVvlrAnUo/atGkShQZq/DGdgOqN+GcbkUAF3lkiJoR3UMFA4Tjs+0IT
         tNUm4pK/kDUIspcCLVmgwLZkS38gM60jm0p2oirLwrAUWs/pUrgbvaI3Pff8iG2nRFoc
         FXZ2NsaNRpA8BdPH83+19/gbV7LCzMPI8T02ODq+r/s/sg9ZE/9upPS4pDJHyuVX2EER
         krDIOt+ql1WReeTWA6v3ElaOMFzwPToWWere5N/5kbgCSXcIvBD3LekVowGXo0vv0ovY
         Tsyk4d55Fl7TPTI6FisKbMyu8lQ31YpqUlnHWs4Y/I1Y5TsKYrlYSbmSDLVSH0MBsoCL
         hUMQ==
X-Received: by 10.70.95.35 with SMTP id dh3mr41850971pdb.91.1423013698569;
 Tue, 03 Feb 2015 17:34:58 -0800 (PST)
MIME-Version: 1.0
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
 <F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com> <F61982DA568A4F8F9E9446D0D135F06B@gmail.com>
 <54D176B9.9070900@gmail.com>
From: Denny Lee <denny.g.lee@gmail.com>
Date: Wed, 04 Feb 2015 01:34:57 +0000
Message-ID: <CABjYQ3_Atuu+HGCYHqHUO9hhPe5djE6OL1Fq0pBVZRy0_Ax94A@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: Chao Chen <crazyjvm@gmail.com>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2d268038d51050e3932a5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2d268038d51050e3932a5
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Awesome stuff - congratulations! :)

On Tue Feb 03 2015 at 5:34:06 PM Chao Chen <crazyjvm@gmail.com> wrote:

> Congratulations guys, well done!
>
> =E5=9C=A8 15-2-4 =E4=B8=8A=E5=8D=889:26, Nan Zhu =E5=86=99=E9=81=93:
> > Congratulations!
> >
> > --
> > Nan Zhu
> > http://codingcat.me
> >
> >
> > On Tuesday, February 3, 2015 at 8:08 PM, Xuefeng Wu wrote:
> >
> >> Congratulations=EF=BC=81well done.
> >>
> >> Yours, Xuefeng Wu =E5=90=B4=E9=9B=AA=E5=B3=B0 =E6=95=AC=E4=B8=8A
> >>
> >>> On 2015=E5=B9=B42=E6=9C=884=E6=97=A5, at =E4=B8=8A=E5=8D=886:34, Mate=
i Zaharia <matei.zaharia@gmail.com
> (mailto:matei.zaharia@gmail.com)> wrote:
> >>>
> >>> Hi all,
> >>>
> >>> The PMC recently voted to add three new committers: Cheng Lian, Josep=
h
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and ma=
ny
> pieces throughout Spark Core. Join me in welcoming them as committers!
> >>>
> >>> Matei
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:
> dev-unsubscribe@spark.apache.org)
> >>> For additional commands, e-mail: dev-help@spark.apache.org (mailto:
> dev-help@spark.apache.org)
> >>>
> >>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:
> dev-unsubscribe@spark.apache.org)
> >> For additional commands, e-mail: dev-help@spark.apache.org (mailto:
> dev-help@spark.apache.org)
> >>
> >>
> >
> >
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c2d268038d51050e3932a5--

From dev-return-11450-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 01:40:15 2015
Return-Path: <dev-return-11450-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C09B717839
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 01:40:15 +0000 (UTC)
Received: (qmail 11076 invoked by uid 500); 4 Feb 2015 01:40:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11006 invoked by uid 500); 4 Feb 2015 01:40:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10863 invoked by uid 99); 4 Feb 2015 01:40:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:40:14 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.48 as permitted sender)
Received: from [209.85.215.48] (HELO mail-la0-f48.google.com) (209.85.215.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 01:39:49 +0000
Received: by mail-la0-f48.google.com with SMTP id pv20so55425079lab.7
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 17:38:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=PfVg5WALPjl5jz7XsV3sFSjoXb8rT3GbwTjvRgPF8b0=;
        b=eh/INHuBf5LgVeaYNeQpIqNH3hWf6tymqAWV743w6ougJtGoQouyTmVhn+ns9fhFIc
         X87962+PtSJgMZdXlUTIh1A4KOOzOhOwEjD2TtOorkoiMXgoQcDTIkMI5DR2xlr9C6//
         MEtyY5QBV+tUzLmU5B9Noj2sA7fm2GSHY5SMjvIu/wVT1ZHGAGlXXcoQ1+Th7cQdVUNi
         et3Wq7RNN4PXhyMp7/+RD84pv2WmqmPust35IQpPUh8xt1moK8JiZO0AOftYC8m2gg1N
         YYV8AKbGJrDOO3BsyJ+T+LziZ7+d2nyXWr8BrBs+xVWQDXYg2bKOtiKfUGmDyYIylc5s
         q5tQ==
MIME-Version: 1.0
X-Received: by 10.152.183.196 with SMTP id eo4mr28158657lac.0.1423013897775;
 Tue, 03 Feb 2015 17:38:17 -0800 (PST)
Received: by 10.25.212.9 with HTTP; Tue, 3 Feb 2015 17:38:17 -0800 (PST)
In-Reply-To: <CABjYQ3_Atuu+HGCYHqHUO9hhPe5djE6OL1Fq0pBVZRy0_Ax94A@mail.gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
	<F5D04DA0-5D12-409B-958D-0B0A5E7D3831@gmail.com>
	<F61982DA568A4F8F9E9446D0D135F06B@gmail.com>
	<54D176B9.9070900@gmail.com>
	<CABjYQ3_Atuu+HGCYHqHUO9hhPe5djE6OL1Fq0pBVZRy0_Ax94A@mail.gmail.com>
Date: Tue, 3 Feb 2015 17:38:17 -0800
Message-ID: <CA+B-+fxwzma1xgETKb7S468=RdPEpS8qG8YixHwTKFmWfg68yA@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Debasish Das <debasish.das83@gmail.com>
To: Denny Lee <denny.g.lee@gmail.com>
Cc: Chao Chen <crazyjvm@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113456d4e32ed6050e393d6c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113456d4e32ed6050e393d6c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Congratulations !

Keep helping the community :-)

On Tue, Feb 3, 2015 at 5:34 PM, Denny Lee <denny.g.lee@gmail.com> wrote:

> Awesome stuff - congratulations! :)
>
> On Tue Feb 03 2015 at 5:34:06 PM Chao Chen <crazyjvm@gmail.com> wrote:
>
> > Congratulations guys, well done!
> >
> > =E5=9C=A8 15-2-4 =E4=B8=8A=E5=8D=889:26, Nan Zhu =E5=86=99=E9=81=93:
> > > Congratulations!
> > >
> > > --
> > > Nan Zhu
> > > http://codingcat.me
> > >
> > >
> > > On Tuesday, February 3, 2015 at 8:08 PM, Xuefeng Wu wrote:
> > >
> > >> Congratulations=EF=BC=81well done.
> > >>
> > >> Yours, Xuefeng Wu =E5=90=B4=E9=9B=AA=E5=B3=B0 =E6=95=AC=E4=B8=8A
> > >>
> > >>> On 2015=E5=B9=B42=E6=9C=884=E6=97=A5, at =E4=B8=8A=E5=8D=886:34, Ma=
tei Zaharia <matei.zaharia@gmail.com
> > (mailto:matei.zaharia@gmail.com)> wrote:
> > >>>
> > >>> Hi all,
> > >>>
> > >>> The PMC recently voted to add three new committers: Cheng Lian,
> Joseph
> > Bradley and Sean Owen. All three have been major contributors to Spark =
in
> > the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and
> many
> > pieces throughout Spark Core. Join me in welcoming them as committers!
> > >>>
> > >>> Matei
> > >>> -------------------------------------------------------------------=
--
> > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:
> > dev-unsubscribe@spark.apache.org)
> > >>> For additional commands, e-mail: dev-help@spark.apache.org (mailto:
> > dev-help@spark.apache.org)
> > >>>
> > >>
> > >>
> > >> --------------------------------------------------------------------=
-
> > >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:
> > dev-unsubscribe@spark.apache.org)
> > >> For additional commands, e-mail: dev-help@spark.apache.org (mailto:
> > dev-help@spark.apache.org)
> > >>
> > >>
> > >
> > >
> >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a113456d4e32ed6050e393d6c--

From dev-return-11451-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 02:24:07 2015
Return-Path: <dev-return-11451-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B43621794D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 02:24:07 +0000 (UTC)
Received: (qmail 87982 invoked by uid 500); 4 Feb 2015 02:24:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87915 invoked by uid 500); 4 Feb 2015 02:24:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87887 invoked by uid 99); 4 Feb 2015 02:24:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:24:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zsxwing@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:23:38 +0000
Received: by mail-ob0-f172.google.com with SMTP id nt9so22344891obb.3
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 18:23:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=s5YX1mQk+W94pMylJLS/Twz4Ecrx2nYhUT0AL9jZy08=;
        b=Ep49LDxPyUbLW+Q6yzf7ToQqSj7UC1iksOF8AjuzP+Spy3J6Sr25VVW20Cmxmi8olw
         nwdGRxBiaaHs2KyATG2ki09EmQ52+ugp80X/p11K90AyMjngJLdOKc9HQ2FvWoWu8Ms6
         MlJOjogjhdPDcJ+UWaCcVEqCmYgD7/5Dq5VyO+8AQwN8kbkVABBs+IflyKFGqSGU5KFC
         2FfTRZ4P6en8uNjWVIdffK7DMMr7nN8SQOn55gI0/4ETrV2PtEUIpqQ/hrd8vnjQr+VF
         IfT2M3ZBz4HJgD6LelGqw7qwwbvJl6Jo/dSWK4CphJItz6EpVjp3Sczx95hHHUyT6KEZ
         N4Jg==
MIME-Version: 1.0
X-Received: by 10.202.178.131 with SMTP id b125mr16494227oif.80.1423016616248;
 Tue, 03 Feb 2015 18:23:36 -0800 (PST)
Received: by 10.182.139.39 with HTTP; Tue, 3 Feb 2015 18:23:36 -0800 (PST)
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Date: Wed, 4 Feb 2015 10:23:36 +0800
Message-ID: <CAPn6-YQfoYOCOT6Bmtzu0iQZKSyfjURCJ8f0hNupEBdk4h4f_g@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Shixiong Zhu <zsxwing@gmail.com>
To: Cheng Lian <lian@databricks.com>, Joseph Bradley <joseph@databricks.com>, 
	Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>, Matei Zaharia <matei.zaharia@gmail.com>
Content-Type: multipart/alternative; boundary=001a113b7e9cebcc55050e39df2d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113b7e9cebcc55050e39df2d
Content-Type: text/plain; charset=UTF-8

Congrats guys!

Best Regards,
Shixiong Zhu

2015-02-04 6:34 GMT+08:00 Matei Zaharia <matei.zaharia@gmail.com>:

> Hi all,
>
> The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113b7e9cebcc55050e39df2d--

From dev-return-11452-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 02:34:07 2015
Return-Path: <dev-return-11452-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 33A4A179B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 02:34:07 +0000 (UTC)
Received: (qmail 5647 invoked by uid 500); 4 Feb 2015 02:34:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5576 invoked by uid 500); 4 Feb 2015 02:34:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5559 invoked by uid 99); 4 Feb 2015 02:34:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:34:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of advancedxy@gmail.com designates 209.85.220.45 as permitted sender)
Received: from [209.85.220.45] (HELO mail-pa0-f45.google.com) (209.85.220.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:34:00 +0000
Received: by mail-pa0-f45.google.com with SMTP id et14so104130322pad.4
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 18:32:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=I5YUJHUS9zGVQSHYd1KnsYDUYnEql4FWEKaj6KvyBUU=;
        b=Ek8fzoQLgGFMpQwd1fdr4+2H1Db4gN4EAFjJBq4C+yu5znFx49Z2mYZTcAyri22QbT
         VM92bs9YN3MxSY5JQeGj4Nmy803RC45UswCM8dHMGZ0lFmfjKQdNuHv2emlnQFqIC5hf
         br+RRGaBed6F21tvHJYB8MD/U9C2gLFRgVMEXGvr/88m+Q4ZJSDq17q3qu8eyX0VshKL
         jFhE6GPo1LFRJxVcTxmdDm5IQlWNkWjQ906M+5lu3rDPZ6DmjC6/FQM/dMOR4Av6Bnk8
         augen13EhorC28utWGcQCGxMctNx1QEISUX5+iZFhXmMs7jiJVkTf7l0Okza07QdH6GF
         3wXg==
X-Received: by 10.68.133.198 with SMTP id pe6mr41983053pbb.119.1423017175339;
        Tue, 03 Feb 2015 18:32:55 -0800 (PST)
Received: from [172.16.100.171] (li580-54.members.linode.com. [106.186.22.54])
        by mx.google.com with ESMTPSA id rk9sm242001pab.40.2015.02.03.18.32.52
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 03 Feb 2015 18:32:54 -0800 (PST)
Date: Wed, 4 Feb 2015 10:32:47 +0800
From: Ye Xianjin <advancedxy@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: dev <dev@spark.apache.org>, Sean Owen <sowen@cloudera.com>, Joseph
 Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>
Message-ID: <48CDFF89C7D2428A9C0278055D6990B9@gmail.com>
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Subject: Re: Welcoming three new committers
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54d184cf_238e1f29_591d"
X-Virus-Checked: Checked by ClamAV on apache.org

--54d184cf_238e1f29_591d
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Congratulations!

-- 
Ye Xianjin
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)


On Wednesday, February 4, 2015 at 6:34 AM, Matei Zaharia wrote:

> Hi all,
> 
> The PMC recently voted to add three new committers: Cheng Lian, Joseph Bradley and Sean Owen. All three have been major contributors to Spark in the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many pieces throughout Spark Core. Join me in welcoming them as committers!
> 
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
> For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
> 
> 



--54d184cf_238e1f29_591d--


From dev-return-11453-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 02:35:35 2015
Return-Path: <dev-return-11453-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 804F9179CA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 02:35:35 +0000 (UTC)
Received: (qmail 9108 invoked by uid 500); 4 Feb 2015 02:35:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9037 invoked by uid 500); 4 Feb 2015 02:35:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8782 invoked by uid 99); 4 Feb 2015 02:35:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:35:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 02:34:59 +0000
Received: by mail-ig0-f175.google.com with SMTP id hn18so31681086igb.2
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 18:33:52 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=Juy5bT9jl6ql2ucUG0eWGNmsAm3pFCauKkEvuvLJ5N4=;
        b=MIXvpPpsM6f+XGzg/NufenWn3njOEim1n+1w7yIYuDUduFUjfeKgtaTgGIAoPUsSRk
         1a7j+lmiSRJgfBzttaRZfgmzS8T4EtzxPfUGGN8xq6QZAJmKj6YXEbtAKdW7CPTQfsI4
         pkdh3Bp7/g1tF/VTJEaRw4/+95hOYJPnTjZi9EglaFYbMZ024Y0XTY2QYYrDdJFzJ+pg
         v+kqE7jvyf0mMwXpx/pI6/Xe56Cr87Bi72NWucjPIw+Bivwb1TcfNLq/S/zWSVkQiIWO
         dmvdqq1VGevy86VBJ2uaGygZumczZ4ZqE7yGkHId8JyCKLb3NZKHev05eNiXj5QJeOmQ
         S+Jw==
X-Gm-Message-State: ALoCoQkqo4LAYOT9pLZwIFK8jd420U0iJO9unPcDA1VLnTiRflJZZEY8uELfzaRAgBzC30GgxBtv
MIME-Version: 1.0
X-Received: by 10.50.60.72 with SMTP id f8mr21992710igr.31.1423017232235; Tue,
 03 Feb 2015 18:33:52 -0800 (PST)
Received: by 10.36.66.15 with HTTP; Tue, 3 Feb 2015 18:33:52 -0800 (PST)
In-Reply-To: <CAPn6-YQfoYOCOT6Bmtzu0iQZKSyfjURCJ8f0hNupEBdk4h4f_g@mail.gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
	<CAPn6-YQfoYOCOT6Bmtzu0iQZKSyfjURCJ8f0hNupEBdk4h4f_g@mail.gmail.com>
Date: Tue, 3 Feb 2015 18:33:52 -0800
Message-ID: <CAF7ADNqgMaVn=7t9bqbhRBKxwR6hycCUAVo3Pq=T_qx5gssgQA@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Joseph Bradley <joseph@databricks.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b10d0e3a31674050e3a0462
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10d0e3a31674050e3a0462
Content-Type: text/plain; charset=UTF-8

Thanks to everyone in the community for past collaborations, and I look
forward to continuing in the future!
Joseph

On Tue, Feb 3, 2015 at 6:23 PM, Shixiong Zhu <zsxwing@gmail.com> wrote:

> Congrats guys!
>
> Best Regards,
> Shixiong Zhu
>
> 2015-02-04 6:34 GMT+08:00 Matei Zaharia <matei.zaharia@gmail.com>:
>
>> Hi all,
>>
>> The PMC recently voted to add three new committers: Cheng Lian, Joseph
>> Bradley and Sean Owen. All three have been major contributors to Spark in
>> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
>> pieces throughout Spark Core. Join me in welcoming them as committers!
>>
>> Matei
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--047d7b10d0e3a31674050e3a0462--

From dev-return-11454-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 04:24:00 2015
Return-Path: <dev-return-11454-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 661D317CEB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 04:24:00 +0000 (UTC)
Received: (qmail 78370 invoked by uid 500); 4 Feb 2015 04:24:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78306 invoked by uid 500); 4 Feb 2015 04:24:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78294 invoked by uid 99); 4 Feb 2015 04:23:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 04:23:59 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=FSL_HELO_BARE_IP_2,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zzhang@hortonworks.com designates 64.78.52.184 as permitted sender)
Received: from [64.78.52.184] (HELO relayvx11b.securemail.intermedia.net) (64.78.52.184)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 04:23:53 +0000
Received: from emg-ca-1-1 (localhost [127.0.0.1])
	by emg-ca-1-1.localdomain (Postfix) with ESMTP id F1D7853E98;
	Tue,  3 Feb 2015 20:22:50 -0800 (PST)
Subject: Re: Welcoming three new committers
MIME-Version: 1.0
x-echoworx-emg-received: Tue, 3 Feb 2015 20:22:50.975 -0800
x-echoworx-msg-id: b7a2e7fa-ab42-4565-88ca-e86dbe7b7ddc
x-echoworx-action: delivered
Received: from 10.254.155.14 ([10.254.155.14])
          by emg-ca-1-1 (JAMES SMTP Server 2.3.2) with SMTP ID 602;
          Tue, 3 Feb 2015 20:22:50 -0800 (PST)
Received: from MBX080-W4-CO-2.exch080.serverpod.net (unknown [10.224.117.102])
	by emg-ca-1-1.localdomain (Postfix) with ESMTP id C6A5E53E98;
	Tue,  3 Feb 2015 20:22:50 -0800 (PST)
Received: from MBX080-W4-CO-1.exch080.serverpod.net (10.224.117.101) by
 MBX080-W4-CO-2.exch080.serverpod.net (10.224.117.102) with Microsoft SMTP
 Server (TLS) id 15.0.1044.25; Tue, 3 Feb 2015 20:22:50 -0800
Received: from MBX080-W4-CO-1.exch080.serverpod.net ([10.224.117.101]) by
 mbx080-w4-co-1.exch080.serverpod.net ([10.224.117.101]) with mapi id
 15.00.1044.021; Tue, 3 Feb 2015 20:22:50 -0800
From: Zhan Zhang <zzhang@hortonworks.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
CC: dev <dev@spark.apache.org>, Sean Owen <sowen@cloudera.com>, Joseph Bradley
	<joseph@databricks.com>, Cheng Lian <lian@databricks.com>
Thread-Topic: Welcoming three new committers
Thread-Index: AQHQQDI8wQEhhrx/kU+cG4M56Tx0zg==
Date: Wed, 4 Feb 2015 04:22:49 +0000
Message-ID: <FB43FA69-1F27-4D3F-B524-F3236E9066AB@hortonworks.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [67.161.7.189]
x-source-routing-agent: Processed
Content-Type: text/plain; charset="us-ascii"
Content-ID: <0BC482267D714244A0BD9ECAC0D57CBA@exch080.serverpod.net>
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Congratulations!

On Feb 3, 2015, at 2:34 PM, Matei Zaharia <matei.zaharia@gmail.com> wrote:

> Hi all,
>=20
> The PMC recently voted to add three new committers: Cheng Lian, Joseph Br=
adley and Sean Owen. All three have been major contributors to Spark in the=
 past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many pi=
eces throughout Spark Core. Join me in welcoming them as committers!
>=20
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11455-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 05:10:31 2015
Return-Path: <dev-return-11455-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 854B817E88
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 05:10:31 +0000 (UTC)
Received: (qmail 59407 invoked by uid 500); 4 Feb 2015 05:10:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59350 invoked by uid 500); 4 Feb 2015 05:10:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59315 invoked by uid 99); 4 Feb 2015 05:10:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:10:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:09:50 +0000
Received: by mail-qc0-f177.google.com with SMTP id p6so39046048qcv.8
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 21:09:28 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=hGYbwsKbtwp+BThxx9y1lBt2ANhX2MFSwdNxxoL0vOM=;
        b=A00mxAwkmiiGBczHgk2OIBMAKkH0IwXYuCYhwFUvwBNwYQ/LK6N275JzM6K7YV760e
         9/4NH6fm1Ecs39y2Ws99ejjxgEnohpXxnrL0rZpr6irnpK5D8Yuxdb/kyV5FVvx4Vpuy
         jQhH2Jm1aPUnjFnwzAEYuk5vzZxhuOXGlzCXgZH4DRxGjAK92deBSufcDsDJOgWfxzt1
         zeAR0lGIOLOH3dySCPbYouOU+3v5QYtPqcOPn8apVp+tJAGKl0+xKG+FPXnE3EwoZBzg
         sa0i+m1mcjHvCUTSSKemalGGCm3GqJJnXeCvWE/rMlDxfmm1AYZSMGn0GZtp9D1D/gFT
         ghbQ==
X-Gm-Message-State: ALoCoQnKpsoFx0eslDAF7jLI2yczZN9DPAw2IeO9MeCDgslQ0f2pbFKyHr8kq41YURQV+ZYQTmbI
X-Received: by 10.224.151.69 with SMTP id b5mr5154930qaw.10.1423026568411;
 Tue, 03 Feb 2015 21:09:28 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Tue, 3 Feb 2015 21:09:08 -0800 (PST)
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 3 Feb 2015 21:09:08 -0800
Message-ID: <CAPh_B=Z655Ja2iKhH88M3kUEjw3jM5idPd+VRQ6LzYgNua0sVg@mail.gmail.com>
Subject: ASF Git / GitHub sync is down
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0149ca441dd469050e3c317f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149ca441dd469050e3c317f
Content-Type: text/plain; charset=UTF-8

Haven't sync-ed anything for the last 4 hours. Seems like this little piece
of infrastructure always stops working around our own code freeze time ...

--089e0149ca441dd469050e3c317f--

From dev-return-11456-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 05:16:17 2015
Return-Path: <dev-return-11456-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B28B317EAF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 05:16:17 +0000 (UTC)
Received: (qmail 72594 invoked by uid 500); 4 Feb 2015 05:16:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72526 invoked by uid 500); 4 Feb 2015 05:16:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72509 invoked by uid 99); 4 Feb 2015 05:16:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:16:17 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of manish9ue@gmail.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:16:12 +0000
Received: by mail-qc0-f178.google.com with SMTP id b13so39146877qcw.9
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 21:15:06 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=1oCiI3JupIi0JpWxbr/iv6h2hzC7j/MV5Y88oDzxoYs=;
        b=rJLPOpz+ilx9AmPvL8zLxUdzLPmvuDzcl23Bt4+LrO1dlfNX4tfMNFjtBBQg0imoyy
         mMOJffWgmqe5rqivL+CZvfqeka/yxuQz+RkFhKw9bgOGEWn3cYvQSyb2RdCmJtGVFYwX
         C2vlKp++xwmp9w2kgezUEu59kya4slrJfqifdCO+c/T1rvFazyMuhK8eqpcrFTBHJFAr
         wRS6UFo+GgY6LUEtLH3tpcMyEM3SR63X2dRMRvWkQolTtMWHIVuhEz5ck42sF2/OvGpQ
         0Niej18YGKj3PiPqOT7a+88P3Ex9SBU4HaO4uq+W0/l9cvNnuefvIdA3b4X7oHzvMdv7
         5LAA==
MIME-Version: 1.0
X-Received: by 10.224.69.67 with SMTP id y3mr61076699qai.59.1423026906873;
 Tue, 03 Feb 2015 21:15:06 -0800 (PST)
Received: by 10.140.196.65 with HTTP; Tue, 3 Feb 2015 21:15:06 -0800 (PST)
In-Reply-To: <FB43FA69-1F27-4D3F-B524-F3236E9066AB@hortonworks.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
	<FB43FA69-1F27-4D3F-B524-F3236E9066AB@hortonworks.com>
Date: Tue, 3 Feb 2015 21:15:06 -0800
Message-ID: <CAF4jm1DAYdFQSB7RNhgo4qJXwNkUyOg0aaqD0PZ2sT792JpnqQ@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Manish Amde <manish9ue@gmail.com>
To: Zhan Zhang <zzhang@hortonworks.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, dev <dev@spark.apache.org>, 
	Sean Owen <sowen@cloudera.com>, Joseph Bradley <joseph@databricks.com>, 
	Cheng Lian <lian@databricks.com>
Content-Type: multipart/alternative; boundary=001a11c2d8f64a563e050e3c45c1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2d8f64a563e050e3c45c1
Content-Type: text/plain; charset=UTF-8

Congratulations Cheng, Joseph and Sean.

On Tuesday, February 3, 2015, Zhan Zhang <zzhang@hortonworks.com> wrote:

> Congratulations!
>
> On Feb 3, 2015, at 2:34 PM, Matei Zaharia <matei.zaharia@gmail.com
> <javascript:;>> wrote:
>
> > Hi all,
> >
> > The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
> >
> > Matei
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> > For additional commands, e-mail: dev-help@spark.apache.org
> <javascript:;>
> >
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: dev-help@spark.apache.org <javascript:;>
>
>

--001a11c2d8f64a563e050e3c45c1--

From dev-return-11457-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 05:26:44 2015
Return-Path: <dev-return-11457-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4CB8217EED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 05:26:44 +0000 (UTC)
Received: (qmail 87785 invoked by uid 500); 4 Feb 2015 05:26:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87709 invoked by uid 500); 4 Feb 2015 05:26:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87693 invoked by uid 99); 4 Feb 2015 05:26:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:26:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.216.43] (HELO mail-qa0-f43.google.com) (209.85.216.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 05:26:38 +0000
Received: by mail-qa0-f43.google.com with SMTP id v10so37183458qac.2
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 21:25:57 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=RuqqFz7iI0t46C5R/wseoLBJWsDG/kAA8j9PNTNClN0=;
        b=kUB+6wervvfpYoKl/NoqL0gKoq+tQYaAn8ssLwmZ2MUGZgqxGF2nCISurSP6Kc+Blo
         HFkCp/VFQj4fwEWgAVdpTGpHliR58/gg5R1DOv/1Q3vUuiwMk9CX71bz34mfk7lYsPiF
         zMNgUbUTseeY5xAtEeux26mN6iVc7XIV/3Jq+uyCqDW1ydEtm7CWQQzCnaA+ukVd5g1e
         uJLVs0WMvHpRe0JSI8sMV/O7dwxUe5Dc4WR7PIFA2mUnjVBkCHLJ/VMmlTUCE31EiRF/
         1ntdOaPqykEXICKG+LtkfcSZD9KGVgxbjZXaw49h7bp6mF+b/Wwt+AWbwoOSJtP+kPnL
         lzmg==
X-Gm-Message-State: ALoCoQnF6Ob4iioSh3VT/RAga989KTBEluaPmE579FvsJPQWGw1faXMBGc8wtSafwB2LPAHcp/AT
X-Received: by 10.224.96.130 with SMTP id h2mr60495742qan.85.1423027557481;
 Tue, 03 Feb 2015 21:25:57 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Tue, 3 Feb 2015 21:25:37 -0800 (PST)
In-Reply-To: <CAPh_B=Z655Ja2iKhH88M3kUEjw3jM5idPd+VRQ6LzYgNua0sVg@mail.gmail.com>
References: <CAPh_B=Z655Ja2iKhH88M3kUEjw3jM5idPd+VRQ6LzYgNua0sVg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 3 Feb 2015 21:25:37 -0800
Message-ID: <CAPh_B=ZZoPVV7HYa0nZWfPzQgzYF1PN077rq+s9HzS1jEUDryA@mail.gmail.com>
Subject: Re: ASF Git / GitHub sync is down
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c34fa611d5c6050e3c6c6e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34fa611d5c6050e3c6c6e
Content-Type: text/plain; charset=UTF-8

I filed an INFRA ticket: https://issues.apache.org/jira/browse/INFRA-9115



I wish ASF can reconsider requests like this in order to handle downtime
gracefully https://issues.apache.org/jira/browse/INFRA-8738

On Tue, Feb 3, 2015 at 9:09 PM, Reynold Xin <rxin@databricks.com> wrote:

> Haven't sync-ed anything for the last 4 hours. Seems like this little
> piece of infrastructure always stops working around our own code freeze
> time ...
>
>

--001a11c34fa611d5c6050e3c6c6e--

From dev-return-11458-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 07:45:00 2015
Return-Path: <dev-return-11458-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 348E410367
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 07:45:00 +0000 (UTC)
Received: (qmail 95916 invoked by uid 500); 4 Feb 2015 07:45:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95852 invoked by uid 500); 4 Feb 2015 07:45:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95838 invoked by uid 99); 4 Feb 2015 07:44:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 07:44:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of prabsmails@gmail.com designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 07:44:33 +0000
Received: by mail-la0-f49.google.com with SMTP id gf13so69964lab.8
        for <dev@spark.apache.org>; Tue, 03 Feb 2015 23:43:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=vZQKEZgSEPkbAZL1YGSpAOTxVX8sRHnAHaKytpltXcY=;
        b=dJ9hd/PwXYZQcqyoJmtxiqcIacuAkOK2LQpCa8VP683IK0bNYaGENjYLaXCvL9O+gj
         RhWh39UOwYR0VQsu641DId2NrGTyDCM4ddmmvqxVf5Aj6hI6t5N01kyPj/EFQnTdmHAS
         QXpPm3zpnQJMdtyuAXy7KOINAO5EDLoSbObDQSihNV5b8HsdTbnJYhsICceJVVjUHMYA
         NxusDVeHO5+T6riZ0Ma/mcWfXmF8RxJv1XNJ5JeCb/Z2svKg6x7v1fH4Jl8St6KpiTW9
         6g2RlSovatpT/6aPLBZDzJzW324+r+gfpSe4h+YFfMJ6t5PdNVPFjOpwi+1MVjv7xhrT
         m42w==
X-Received: by 10.112.199.162 with SMTP id jl2mr1330040lbc.48.1423035826593;
 Tue, 03 Feb 2015 23:43:46 -0800 (PST)
MIME-Version: 1.0
Received: by 10.152.115.3 with HTTP; Tue, 3 Feb 2015 23:43:06 -0800 (PST)
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
From: prabeesh k <prabsmails@gmail.com>
Date: Wed, 4 Feb 2015 11:43:06 +0400
Message-ID: <CAPdPcW3ss=fOtkq4x959-mQ8gqYwDmd9iOrPwcrZrs4w--F+-A@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: dev <dev@spark.apache.org>, Sean Owen <sowen@cloudera.com>, 
	Joseph Bradley <joseph@databricks.com>, Cheng Lian <lian@databricks.com>
Content-Type: multipart/alternative; boundary=001a11c38254f26398050e3e5885
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c38254f26398050e3e5885
Content-Type: text/plain; charset=UTF-8

Congratulations!

On 4 February 2015 at 02:34, Matei Zaharia <matei.zaharia@gmail.com> wrote:

> Hi all,
>
> The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c38254f26398050e3e5885--

From dev-return-11459-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 12:11:22 2015
Return-Path: <dev-return-11459-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D11A10D65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 12:11:22 +0000 (UTC)
Received: (qmail 13908 invoked by uid 500); 4 Feb 2015 12:11:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13813 invoked by uid 500); 4 Feb 2015 12:11:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13688 invoked by uid 99); 4 Feb 2015 12:11:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 12:11:05 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 12:11:00 +0000
Received: by mail-wi0-f179.google.com with SMTP id l15so3164414wiw.0
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 04:10:39 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type:content-transfer-encoding;
        bh=JykPi7aq1os/lL6zHNeA0F2O/1cueARURpdPQhETOB0=;
        b=RI5ZhTPrd5o0OT+JTsKxNSluauK3rMWlP6tKU+/J/gN2YMVBXD53SiPS6fiMbtC8ca
         fgOco6SYsy93MSxCvxnJ1Cw0rbj9wi4MCKSPttE8uVAd0KBhYjAkg/j4C+pFcleF5Ucu
         gquloPoaAxHLStFEdyu8kd5kYtw2hu533TEavDeNYwI4QTGB6SlnV/lADb7yvpf74buB
         CjLWKItZYGhRInVcw3ORYV/0NiL2LEQxijR5EKxm2/gAU/iGC8YNTBWtawU3weuFwTA/
         dhj4glSe+xik8jFaOKdUlY+5VYNC9X2QPQIVROipH4wOoE/yNMB7RNcwDEG2Bf2w4ged
         pwiA==
X-Gm-Message-State: ALoCoQmUzI47u8/jgVasyi/Tov+Mwac8f65PmmrYk/dTBAnpDeW7wJVC08kqRs+PIaiMChlgQHMF
X-Received: by 10.180.103.102 with SMTP id fv6mr3806037wib.80.1423051839784;
 Wed, 04 Feb 2015 04:10:39 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Wed, 4 Feb 2015 04:10:19 -0800 (PST)
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 4 Feb 2015 06:10:19 -0600
Message-ID: <CAMAsSdJoF31L4Kr6pvnxm8SZUns_gPpZV6LJgACqJm=ue95A9w@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks all, I appreciate the vote of trust. I'll do my best to help
keep JIRA and commits moving along, and am ramping up carefully this
week. Now get back to work reviewing things!

On Tue, Feb 3, 2015 at 4:34 PM, Matei Zaharia <matei.zaharia@gmail.com> wro=
te:
> Hi all,
>
> The PMC recently voted to add three new committers: Cheng Lian, Joseph Br=
adley and Sean Owen. All three have been major contributors to Spark in the=
 past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many pi=
eces throughout Spark Core. Join me in welcoming them as committers!
>
> Matei

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11460-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 12:25:58 2015
Return-Path: <dev-return-11460-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 18D3510E20
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 12:25:58 +0000 (UTC)
Received: (qmail 43192 invoked by uid 500); 4 Feb 2015 12:25:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43113 invoked by uid 500); 4 Feb 2015 12:25:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43095 invoked by uid 99); 4 Feb 2015 12:25:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 12:25:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 74.125.82.53 as permitted sender)
Received: from [74.125.82.53] (HELO mail-wg0-f53.google.com) (74.125.82.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 12:25:49 +0000
Received: by mail-wg0-f53.google.com with SMTP id a1so1367871wgh.12
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 04:25:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=aA1IdUdJKPmgStW4ZunZs8uITGLpk2tJIG9OCvNiJHQ=;
        b=h3IOYpmwNTqWsGuZoeotLlsUy+bGcrpE6Kyevzf6Ad1/uPgMCFsN/9g0ZEjjsk6YT4
         YVXpA5QIWX8unaf/zIYs2AqYJRSGx7NrHn2/XnFWjEQBELErkQXGAoLmn8mCDa3TqRPh
         OAnObg1Yw9Cg4Er34SGoq9UtESaTdx2IqpUt4NRakVnA8gZhM1xGBGkGJP3gXuSbdFBQ
         XPCaQwGpvb8X06ydW0mzu2W1tASYv3HSWQkC2Wm+2Le0vqxFSygtF11plnkyPBIAJq1u
         k9RynVuN19S6kF/t3XepK4SS+e7X6TRNhPw9a5F6BP5SSU0AJqlGy1YVMwzMDliZ1Q4u
         b+mQ==
MIME-Version: 1.0
X-Received: by 10.180.103.33 with SMTP id ft1mr4018687wib.19.1423052729103;
 Wed, 04 Feb 2015 04:25:29 -0800 (PST)
Received: by 10.27.215.213 with HTTP; Wed, 4 Feb 2015 04:25:28 -0800 (PST)
In-Reply-To: <CAMAsSdJoF31L4Kr6pvnxm8SZUns_gPpZV6LJgACqJm=ue95A9w@mail.gmail.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
	<CAMAsSdJoF31L4Kr6pvnxm8SZUns_gPpZV6LJgACqJm=ue95A9w@mail.gmail.com>
Date: Wed, 4 Feb 2015 14:25:28 +0200
Message-ID: <CALD+6GMOJnQ=FvsMNznymPjkEvdrjQUkq6ukE7AxCgAWC12gJA@mail.gmail.com>
Subject: Re: Welcoming three new committers
From: Nick Pentreath <nick.pentreath@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0442715c6a38ee050e4248fc
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0442715c6a38ee050e4248fc
Content-Type: text/plain; charset=UTF-8

Congrats and welcome Sean, Joseph and Cheng!


On Wed, Feb 4, 2015 at 2:10 PM, Sean Owen <sowen@cloudera.com> wrote:

> Thanks all, I appreciate the vote of trust. I'll do my best to help
> keep JIRA and commits moving along, and am ramping up carefully this
> week. Now get back to work reviewing things!
>
> On Tue, Feb 3, 2015 at 4:34 PM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Hi all,
> >
> > The PMC recently voted to add three new committers: Cheng Lian, Joseph
> Bradley and Sean Owen. All three have been major contributors to Spark in
> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
> pieces throughout Spark Core. Join me in welcoming them as committers!
> >
> > Matei
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--f46d0442715c6a38ee050e4248fc--

From dev-return-11461-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 13:35:04 2015
Return-Path: <dev-return-11461-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ED7BB17314
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 13:35:03 +0000 (UTC)
Received: (qmail 85959 invoked by uid 500); 4 Feb 2015 13:34:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85881 invoked by uid 500); 4 Feb 2015 13:34:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85869 invoked by uid 99); 4 Feb 2015 13:34:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 13:34:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of irashid@cloudera.com designates 74.125.82.181 as permitted sender)
Received: from [74.125.82.181] (HELO mail-we0-f181.google.com) (74.125.82.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 13:34:28 +0000
Received: by mail-we0-f181.google.com with SMTP id k48so1734280wev.12
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 05:33:42 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ZtkYU1d+fUhF4JWN17jCFtdCunsEPgQQajT9PAuypIc=;
        b=cZXcA1iC7K2yw7NNswEac03odM//P6rmx/66JoTMOHLVq9PlSA5wXB11NJNyb9MJpK
         8/JX2+xlmgxEh0VmACxTRXvTVyTdmx8HFt1F1waavj51jeajloO/5yCym9wmI2dv980B
         BnmFVCuSMAQA1zBrp++t4vuAfziatcXl0VA074Ps/Iw1dX31iwAqDnULXW35fUhPbwRL
         f/+hyyTMvp0Dmc8nTHy0E6wQI199/KVDaaQsKSSC5qOak1iBGziKi/j7tSnMF0dvQcKb
         oiQmyhTe7ROZD6w06/5fd7WuARisYLFu4DYTNHpCKHUEr6UFhwW95Gb8dOE4R+eHIw+C
         0qUA==
X-Gm-Message-State: ALoCoQmvBCvc+6YFYDhHOReyGWexydazQBtMVaFCQQc3IxJREzOesFllpDmYEcPw5emcb2Bfac0I
X-Received: by 10.194.133.101 with SMTP id pb5mr12558427wjb.40.1423056822254;
 Wed, 04 Feb 2015 05:33:42 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.144.194 with HTTP; Wed, 4 Feb 2015 05:33:22 -0800 (PST)
In-Reply-To: <CAJiQeYKMi76qPivAx4xCFoah7UBDJGGBfAH0AR4hF9kanx_7yQ@mail.gmail.com>
References: <CAMAsSd++EeLWFNq3BF_jr_6DTti5T41pP9kVtiHcKZc40og9GA@mail.gmail.com>
 <2035367225.1416359.1422961091409.JavaMail.yahoo@mail.yahoo.com>
 <CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com>
 <CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
 <CA+3qhFThsvx8xAzYKbzOE1LnNEKnwdXgAeTYZ32YngYMwgVnmQ@mail.gmail.com> <CAJiQeYKMi76qPivAx4xCFoah7UBDJGGBfAH0AR4hF9kanx_7yQ@mail.gmail.com>
From: Imran Rashid <irashid@cloudera.com>
Date: Wed, 4 Feb 2015 07:33:22 -0600
Message-ID: <CA+3qhFT0JZc=9_XVTDWczaqzjv=GQxr6ywAnjxd4qYeVb_vKVA@mail.gmail.com>
Subject: Re: 2GB limit for partitions?
To: Mridul Muralidharan <mridul@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, Michael Albert <m_albert137@yahoo.com>, 
	"user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011771f362d7f5050e433ca0
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011771f362d7f5050e433ca0
Content-Type: text/plain; charset=UTF-8

Hi Mridul,


do you think you'll keep working on this, or should this get picked up by
others?  Looks like there was a lot of work put into LargeByteBuffer, seems
promising.

thanks,
Imran

On Tue, Feb 3, 2015 at 7:32 PM, Mridul Muralidharan <mridul@gmail.com>
wrote:

> That is fairly out of date (we used to run some of our jobs on it ... But
> that is forked off 1.1 actually).
>
> Regards
> Mridul
>
>
> On Tuesday, February 3, 2015, Imran Rashid <irashid@cloudera.com> wrote:
>
>> Thanks for the explanations, makes sense.  For the record looks like this
>> was worked on a while back (and maybe the work is even close to a
>> solution?)
>>
>> https://issues.apache.org/jira/browse/SPARK-1476
>>
>> and perhaps an independent solution was worked on here?
>>
>> https://issues.apache.org/jira/browse/SPARK-1391
>>
>>
>> On Tue, Feb 3, 2015 at 5:20 PM, Reynold Xin <rxin@databricks.com> wrote:
>>
>> > cc dev list
>> >
>> >
>> > How are you saving the data? There are two relevant 2GB limits:
>> >
>> > 1. Caching
>> >
>> > 2. Shuffle
>> >
>> >
>> > For caching, a partition is turned into a single block.
>> >
>> > For shuffle, each map partition is partitioned into R blocks, where R =
>> > number of reduce tasks. It is unlikely a shuffle block > 2G, although it
>> > can still happen.
>> >
>> > I think the 2nd problem is easier to fix than the 1st, because we can
>> > handle that in the network transport layer. It'd require us to divide
>> the
>> > transfer of a very large block into multiple smaller blocks.
>> >
>> >
>> >
>> > On Tue, Feb 3, 2015 at 3:00 PM, Imran Rashid <irashid@cloudera.com>
>> wrote:
>> >
>> >> Michael,
>> >>
>> >> you are right, there is definitely some limit at 2GB.  Here is a
>> trivial
>> >> example to demonstrate it:
>> >>
>> >> import org.apache.spark.storage.StorageLevel
>> >> val d = sc.parallelize(1 to 1e6.toInt, 1).map{i => new
>> >> Array[Byte](5e3.toInt)}.persist(StorageLevel.DISK_ONLY)
>> >> d.count()
>> >>
>> >> It gives the same error you are observing.  I was under the same
>> >> impression as Sean about the limits only being on blocks, not
>> partitions --
>> >> but clearly that isn't the case here.
>> >>
>> >> I don't know the whole story yet, but I just wanted to at least let you
>> >> know you aren't crazy :)
>> >> At the very least this suggests that you might need to make smaller
>> >> partitions for now.
>> >>
>> >> Imran
>> >>
>> >>
>> >> On Tue, Feb 3, 2015 at 4:58 AM, Michael Albert <
>> >> m_albert137@yahoo.com.invalid> wrote:
>> >>
>> >>> Greetings!
>> >>>
>> >>> Thanks for the response.
>> >>>
>> >>> Below is an example of the exception I saw.
>> >>> I'd rather not post code at the moment, so I realize it is completely
>> >>> unreasonable to ask for a diagnosis.
>> >>> However, I will say that adding a "partitionBy()" was the last change
>> >>> before this error was created.
>> >>>
>> >>>
>> >>> Thanks for your time and any thoughts you might have.
>> >>>
>> >>> Sincerely,
>> >>>  Mike
>> >>>
>> >>>
>> >>>
>> >>> Exception in thread "main" org.apache.spark.SparkException: Job
>> aborted
>> >>> due to stage failure: Task 4 in stage 5.0 failed 4 times, most recent
>> >>> failure: Lost task 4.3 in stage 5.0 (TID 6012,
>> >>> ip-10-171-0-31.ec2.internal): java.lang.RuntimeException:
>> >>> java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
>> >>>     at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828)
>> >>>     at
>> org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:123)
>> >>>     at
>> org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:132)
>> >>>     at
>> >>>
>> org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:517)
>> >>>     at
>> >>>
>> org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:307)
>> >>>     at
>> >>>
>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>> >>>     at
>> >>>
>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>> >>>     at
>> >>>
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>> >>>     at
>> >>>
>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>> >>>     at
>> >>>
>> scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
>> >>>   at
>> scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
>> >>>     at
>> >>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>> >>>     at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:108)
>> >>>     at
>> >>>
>> org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:57)
>> >>>
>> >>>
>> >>>   ------------------------------
>> >>>  *From:* Sean Owen <sowen@cloudera.com>
>> >>> *To:* Michael Albert <m_albert137@yahoo.com>
>> >>> *Cc:* "user@spark.apache.org" <user@spark.apache.org>
>> >>> *Sent:* Monday, February 2, 2015 10:13 PM
>> >>> *Subject:* Re: 2GB limit for partitions?
>>
>> >>>
>> >>> The limit is on blocks, not partitions. Partitions have many blocks.
>> >>>
>> >>> It sounds like you are creating very large values in memory, but I'm
>> >>> not sure given your description. You will run into problems if a
>> >>> single object is more than 2GB, of course. More of the stack trace
>> >>> might show what is mapping that much memory.
>> >>>
>> >>> If you simply want data into 1000 files it's a lot simpler. Just
>> >>> repartition into 1000 partitions and save the data. If you need more
>> >>> control over what goes into which partition, use a Partitioner, yes.
>> >>>
>> >>>
>> >>>
>> >>> On Mon, Feb 2, 2015 at 8:40 PM, Michael Albert
>> >>> <m_albert137@yahoo.com.invalid> wrote:
>> >>> > Greetings!
>> >>> >
>> >>> > SPARK-1476 says that there is a 2G limit for "blocks".
>> >>> > Is this the same as a 2G limit for partitions (or approximately
>> so?)?
>> >>> >
>> >>> >
>> >>> > What I had been attempting to do is the following.
>> >>> > 1) Start with a moderately large data set (currently about 100GB,
>> but
>> >>> > growing).
>> >>> > 2) Create about 1,000 files (yes, files) each representing a subset
>> of
>> >>> the
>> >>> > data.
>> >>> >
>> >>> > The current attempt I am working on is something like this.
>> >>> > 1) Do a "map" whose output key indicates which of the 1,000 files it
>> >>> will go
>> >>> > into and whose value is what I will want to stick into the file.
>> >>> > 2) Partition the data and use the body of mapPartition to open a
>> file
>> >>> and
>> >>> > save the data.
>> >>> >
>> >>> > My apologies, this is actually embedded in a bigger mess, so I won't
>> >>> post
>> >>> > it.
>> >>> >
>> >>> > However, I get errors telling me that there is an
>> >>> "IllegalArgumentException:
>> >>> > Size exceeds Inter.MAX_VALUE", with sun.nio.ch.FileChannelImpl.map
>> at
>> >>> the
>> >>> > top of the stack.  This leads me to think that I have hit the limit
>> or
>> >>> > partition and/or block size.
>> >>> >
>> >>> > Perhaps this is not a good way to do it?
>> >>> >
>> >>> > I suppose I could run 1,000 passes over the data, each time
>> collecting
>> >>> the
>> >>> > output for one of my 1,000 final files, but that seems likely to be
>> >>> > painfully slow to run.
>> >>> >
>> >>> > Am I missing something?
>> >>> >
>> >>> > Admittedly, this is an odd use case....
>> >>> >
>> >>> > Thanks!
>> >>> >
>> >>> > Sincerely,
>> >>> >  Mike Albert
>> >>>
>> >>>
>> >>> ---------------------------------------------------------------------
>> >>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>> >>> For additional commands, e-mail: user-help@spark.apache.org
>> >>>
>> >>>
>> >>>
>> >>>
>> >>>
>> >>
>> >
>>
>

--089e011771f362d7f5050e433ca0--

From dev-return-11462-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 13:53:20 2015
Return-Path: <dev-return-11462-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 980EB173AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 13:53:20 +0000 (UTC)
Received: (qmail 34650 invoked by uid 500); 4 Feb 2015 13:53:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34571 invoked by uid 500); 4 Feb 2015 13:53:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31643 invoked by uid 99); 4 Feb 2015 13:53:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 13:53:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of athompson.opr@gmail.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 13:52:48 +0000
Received: by mail-qa0-f51.google.com with SMTP id f12so1126862qad.10;
        Wed, 04 Feb 2015 05:52:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:cc:content-type;
        bh=jXB6IOmOe2DQ8QcGFowZlZUcnjLkKqnmrH6MQ0FWgzQ=;
        b=jHv9U80YSYnyeKOXOBleXydZ2CiiulhubHVWzlmiCkS4EL4jYTc5+fSo8catp7S0jR
         0TNdEBddTFKTGhhhComEsjbOCb0Kto/glmoDlAnnPGeZpHG6+2h6CqriHIZQ6VmTtNwf
         8Q38YcclCy3gFl0w2p6Fsd7L02kyd/BdEQ6N2BuFrrgL2YCm22KfNly47KELAL91wJl2
         N/zRPhHq0YiCaOWtlahqvcgO3jh1h+K6t290EkEWUQep5RqKo7iRlLrdnGx4cOTM/x8a
         lScFORDc8Du4VZUenBQPg+UewRUQhvf917wSg/9T+gfw8MdU+pELczd2Nsf6ldx0pT45
         dJiw==
MIME-Version: 1.0
X-Received: by 10.224.46.132 with SMTP id j4mr63543731qaf.16.1423057966380;
 Wed, 04 Feb 2015 05:52:46 -0800 (PST)
Received: by 10.140.140.81 with HTTP; Wed, 4 Feb 2015 05:52:46 -0800 (PST)
Date: Wed, 4 Feb 2015 05:52:46 -0800
Message-ID: <CACMaG+4ekfEm6K3DXaQa4r8O6Q5hELTNsbKmDNX+T-4k2AH9yw@mail.gmail.com>
Subject: Hive window functions in 1.2+
From: Al Thompson <athompson.opr@gmail.com>
To: user@spark.apache.org
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2505894b996050e43807e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2505894b996050e43807e
Content-Type: text/plain; charset=UTF-8

Hi All:

We want to use Hive window functions on Spark on time series data.
I take it from viewing issues SPARK-1442 and SPARK-4226 that work on window
function support is ongoing and remains unresolved.

Are there good workarounds to working with windows on time series stored on
Spark?
Does Streaming have a role in windowed analysis of time series?

Cheers,
Al

--001a11c2505894b996050e43807e--

From dev-return-11463-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 15:31:13 2015
Return-Path: <dev-return-11463-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1058817860
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 15:31:13 +0000 (UTC)
Received: (qmail 21423 invoked by uid 500); 4 Feb 2015 15:31:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21346 invoked by uid 500); 4 Feb 2015 15:31:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21334 invoked by uid 99); 4 Feb 2015 15:31:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 15:31:12 +0000
X-ASF-Spam-Status: No, hits=1.3 required=10.0
	tests=FORGED_YAHOO_RCVD,FREEMAIL_ENVFROM_END_DIGIT,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of medale94@yahoo.com designates 98.138.91.100 as permitted sender)
Received: from [98.138.91.100] (HELO nm7-vm6.bullet.mail.ne1.yahoo.com) (98.138.91.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 15:31:06 +0000
Received: from [98.138.226.178] by nm7.bullet.mail.ne1.yahoo.com with NNFMP; 04 Feb 2015 15:30:46 -0000
Received: from [98.138.226.30] by tm13.bullet.mail.ne1.yahoo.com with NNFMP; 04 Feb 2015 15:30:46 -0000
Received: from [127.0.0.1] by smtp201.mail.ne1.yahoo.com with NNFMP; 04 Feb 2015 15:30:46 -0000
X-Yahoo-Newman-Id: 63525.71019.bm@smtp201.mail.ne1.yahoo.com
X-Yahoo-Newman-Property: ymail-3
X-YMail-OSG: KkolBl0VM1mVut6AKnPxg8F9VlxiOBL_9oT.iOjA7D6.9O3
 bF9cINCFqe8uM7LEt17FwBEAYiCIMJ7houingoZ3_TRmKr7ztoSYbL.teCNm
 vPDC_G312yAiN70D8hwXnUP2rjC6mFxWJzWma8JZqxlDWnxuz2AreRvNpwmi
 .6UTk3CgpAjJqj.GvgI5RITJgf_b2L.aGNgGR17U0QkPbGDjykRVl1fieLPy
 wxfe.vfylUWWcpo7Nn1xY8zE.AZ1qa5uL8jQv4nauvTlp6SSwug4m0QvGy82
 bLxzxvNX1j83PyNm_ArO3AZKkHc2nftyH9Di7wYLkcCdceKw3CaVCO6VV3pA
 .zZLul98mSXFFXdgWv8pg0HYcQJsSSNrVpmhbz9xT5xxuGpifI8Bgd6CkNVL
 1mGhs7aDe6c9vPkRn6OHLw1k8qrwz6O1KngMk9p0UE6unQYvJ5RDFBZ02hLF
 aaEiaXitMxktu3B02A47PXDaHCa9e4sni.VLB2qTTF7ajlSOLwPJZlF4kfgC
 2cOcvo_1a4y0_EdoVA_DK_4ll7A4TTEDtE3N57ciXV0LoUQB__yjVxrMhqX7
 YyF6UDjC5wJ7mjSKMV19pVpPilRWpDFhaDeRtO34SiO_.WrVdfcM-
X-Yahoo-SMTP: 3cEdYaqswBCV.ogjqp0uR59JyCnf
Message-ID: <54D23B24.2010606@yahoo.com>
Date: Wed, 04 Feb 2015 10:30:44 -0500
From: "M. Dale" <medale94@yahoo.com.INVALID>
Reply-To: medale@acm.org
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: 1.2.1-rc3 - Avro input format for Hadoop 2 broken/fix?
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

SPARK-3039 "Spark assembly for new hadoop API (hadoop 2) contains 
avro-mapred for hadoop 1 API" was reopened
and prevents v.1.2.1-rc3 from using Avro Input format for Hadoop 2 
API/instances (it includes the hadoop1 avro-mapred library files).

What are the chances of getting the fix outlined here 
(https://github.com/medale/spark/compare/apache:v1.2.1-rc3...avro-hadoop2-v1.2.1-rc2) 
included in 1.2.1? My apologies, I do not know how to generate a pull 
request against a tag version.

I did add pull request https://github.com/apache/spark/pull/4315 for the 
current 1.3.0-SNAPSHOT master on this issue. Even though 1.3.0 build 
already does not include avro-mapred in the spark assembly jar this 
minor change improves dependence convergence.

Thanks,
Markus

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11464-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 15:55:22 2015
Return-Path: <dev-return-11464-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B73E21798D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 15:55:22 +0000 (UTC)
Received: (qmail 25793 invoked by uid 500); 4 Feb 2015 15:55:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25711 invoked by uid 500); 4 Feb 2015 15:55:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25665 invoked by uid 99); 4 Feb 2015 15:55:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 15:55:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jzhou.research@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 15:55:11 +0000
Received: by mail-oi0-f52.google.com with SMTP id h136so1845086oig.11
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 07:52:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=3kvCxSSlUjeigCmLw5baoRMCDEqy1yFdecDl1uH1UG8=;
        b=C1/1t3dL+hSz00Jisn1Q2qZBbYjHOe8s3H5xNuEGmL50bqkDj3QP1S/5aeg96+9pKr
         /P40Y+Fv8l9usKgA19RNTjF5oiBVsWpM4Tms8zm0u7drx3a3pksfl805PW9JevB7NU8J
         BPGpM+F+v9epO9vHQ8tmi8wL+ay5JX+kmHtBjbyNtRQkOUyZFHtSDSM1tmo8e2uYu3XZ
         9ps1NVEY8yQ3KzPVzNF28e81NPUfLiR1CQMrsVDD3NOoaKjDWEwHj6ahy5Zlo0sef1Kz
         Ihfgs4TJSe9vJ9zaM8K+RCLUU+s8P9e+xrEsBoj1q5qgnYW2SFYdtGJtvlie7Sefq7q+
         yUZQ==
X-Received: by 10.182.71.39 with SMTP id r7mr19354840obu.42.1423065155512;
 Wed, 04 Feb 2015 07:52:35 -0800 (PST)
MIME-Version: 1.0
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
 <CAMAsSdJoF31L4Kr6pvnxm8SZUns_gPpZV6LJgACqJm=ue95A9w@mail.gmail.com> <CALD+6GMOJnQ=FvsMNznymPjkEvdrjQUkq6ukE7AxCgAWC12gJA@mail.gmail.com>
From: Jian Zhou <jzhou.research@gmail.com>
Date: Wed, 04 Feb 2015 15:52:35 +0000
Message-ID: <CAEjhy9WvNfKe=3+6UYgRsG9HtDN_EpS_A-igi04S3y26CFP02w@mail.gmail.com>
Subject: Re: Welcoming three new committers
To: Nick Pentreath <nick.pentreath@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8fb202ac1630c7050e452def
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8fb202ac1630c7050e452def
Content-Type: text/plain; charset=UTF-8

Congratulations!

On Wed Feb 04 2015 at 7:26:00 AM Nick Pentreath <nick.pentreath@gmail.com>
wrote:

> Congrats and welcome Sean, Joseph and Cheng!
>
>
> On Wed, Feb 4, 2015 at 2:10 PM, Sean Owen <sowen@cloudera.com> wrote:
>
> > Thanks all, I appreciate the vote of trust. I'll do my best to help
> > keep JIRA and commits moving along, and am ramping up carefully this
> > week. Now get back to work reviewing things!
> >
> > On Tue, Feb 3, 2015 at 4:34 PM, Matei Zaharia <matei.zaharia@gmail.com>
> > wrote:
> > > Hi all,
> > >
> > > The PMC recently voted to add three new committers: Cheng Lian, Joseph
> > Bradley and Sean Owen. All three have been major contributors to Spark in
> > the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and
> many
> > pieces throughout Spark Core. Join me in welcoming them as committers!
> > >
> > > Matei
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--e89a8fb202ac1630c7050e452def--

From dev-return-11465-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 16:41:37 2015
Return-Path: <dev-return-11465-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 77FC317C38
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 16:41:37 +0000 (UTC)
Received: (qmail 10838 invoked by uid 500); 4 Feb 2015 16:41:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10650 invoked by uid 500); 4 Feb 2015 16:41:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10525 invoked by uid 99); 4 Feb 2015 16:41:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 16:41:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mridul@gmail.com designates 209.85.216.41 as permitted sender)
Received: from [209.85.216.41] (HELO mail-qa0-f41.google.com) (209.85.216.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 16:41:25 +0000
Received: by mail-qa0-f41.google.com with SMTP id bm13so1934826qab.0;
        Wed, 04 Feb 2015 08:41:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=sh0wgT2jPi0UZ/BjhlT3n/mriEvPDhOFQ4fVTJs/XXQ=;
        b=XZjjjS4Hl2RuBOaMp/Kf0S3cbj/cKP3DdeBU9BVc9JVNQqw3/SrYFWgFEHb7xCPyQD
         Huecnas7S9EiURwTKpZN/FvTfvQn/kpmZY5Sfv8Z2rqB+GgZSq/bO3S+UBOW5wQw3RuG
         1LMleAC6/CId3UrgjxngGbzmsdgZ8uef8XNFFNU7H7lRd1G3vmcPjg0FxpvuWy5PpXze
         8e8ORHlZi1HTXnoXCo2m/hCmHRjse/kQy4EDCCrE0rukcRySReyOHsTL03QG8UMpmcqY
         yySIm2tMMYwRWcLTs18+6ky/AyxNoYs48kcwf8EWA40To3ZhPowWnQCdcGHNBlZJfSkG
         TgZw==
MIME-Version: 1.0
X-Received: by 10.140.22.234 with SMTP id 97mr16946311qgn.21.1423068065031;
 Wed, 04 Feb 2015 08:41:05 -0800 (PST)
Received: by 10.140.33.230 with HTTP; Wed, 4 Feb 2015 08:41:04 -0800 (PST)
In-Reply-To: <CA+3qhFT0JZc=9_XVTDWczaqzjv=GQxr6ywAnjxd4qYeVb_vKVA@mail.gmail.com>
References: <CAMAsSd++EeLWFNq3BF_jr_6DTti5T41pP9kVtiHcKZc40og9GA@mail.gmail.com>
	<2035367225.1416359.1422961091409.JavaMail.yahoo@mail.yahoo.com>
	<CA+3qhFT+ByyyhCYJSM4pr1xYH_om47kirYsY-SJEOtX8rAB8_A@mail.gmail.com>
	<CAPh_B=YiL_Jd_kaqNtH+FJA7y8JmF1pNfsPgLEf-XYpv71S_AQ@mail.gmail.com>
	<CA+3qhFThsvx8xAzYKbzOE1LnNEKnwdXgAeTYZ32YngYMwgVnmQ@mail.gmail.com>
	<CAJiQeYKMi76qPivAx4xCFoah7UBDJGGBfAH0AR4hF9kanx_7yQ@mail.gmail.com>
	<CA+3qhFT0JZc=9_XVTDWczaqzjv=GQxr6ywAnjxd4qYeVb_vKVA@mail.gmail.com>
Date: Wed, 4 Feb 2015 08:41:04 -0800
Message-ID: <CAJiQeYKy6c3gdwcTOCWhGN+QKVgX8Yk2XOoNq=E1mD-aRoMM=Q@mail.gmail.com>
Subject: Re: 2GB limit for partitions?
From: Mridul Muralidharan <mridul@gmail.com>
To: Imran Rashid <irashid@cloudera.com>
Cc: Reynold Xin <rxin@databricks.com>, Michael Albert <m_albert137@yahoo.com>, 
	"user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c14f2681ebb6050e45da18
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c14f2681ebb6050e45da18
Content-Type: text/plain; charset=UTF-8

That work is from more than an year back and is not maintained anymore
since we do not use it inhouse now.
Also note that there have been quite a lot of changes in spark ...
Including some which break assumptions made in the patch, so it's value is
very low - having said that, do feel free to work on the jira and/or use
the patch if it helps !

Regards
Mridul

On Wednesday, February 4, 2015, Imran Rashid <irashid@cloudera.com> wrote:

> Hi Mridul,
>
>
> do you think you'll keep working on this, or should this get picked up by
> others?  Looks like there was a lot of work put into LargeByteBuffer, seems
> promising.
>
> thanks,
> Imran
>
> On Tue, Feb 3, 2015 at 7:32 PM, Mridul Muralidharan <mridul@gmail.com
> <javascript:_e(%7B%7D,'cvml','mridul@gmail.com');>> wrote:
>
>> That is fairly out of date (we used to run some of our jobs on it ... But
>> that is forked off 1.1 actually).
>>
>> Regards
>> Mridul
>>
>>
>> On Tuesday, February 3, 2015, Imran Rashid <irashid@cloudera.com
>> <javascript:_e(%7B%7D,'cvml','irashid@cloudera.com');>> wrote:
>>
>>> Thanks for the explanations, makes sense.  For the record looks like this
>>> was worked on a while back (and maybe the work is even close to a
>>> solution?)
>>>
>>> https://issues.apache.org/jira/browse/SPARK-1476
>>>
>>> and perhaps an independent solution was worked on here?
>>>
>>> https://issues.apache.org/jira/browse/SPARK-1391
>>>
>>>
>>> On Tue, Feb 3, 2015 at 5:20 PM, Reynold Xin <rxin@databricks.com> wrote:
>>>
>>> > cc dev list
>>> >
>>> >
>>> > How are you saving the data? There are two relevant 2GB limits:
>>> >
>>> > 1. Caching
>>> >
>>> > 2. Shuffle
>>> >
>>> >
>>> > For caching, a partition is turned into a single block.
>>> >
>>> > For shuffle, each map partition is partitioned into R blocks, where R =
>>> > number of reduce tasks. It is unlikely a shuffle block > 2G, although
>>> it
>>> > can still happen.
>>> >
>>> > I think the 2nd problem is easier to fix than the 1st, because we can
>>> > handle that in the network transport layer. It'd require us to divide
>>> the
>>> > transfer of a very large block into multiple smaller blocks.
>>> >
>>> >
>>> >
>>> > On Tue, Feb 3, 2015 at 3:00 PM, Imran Rashid <irashid@cloudera.com>
>>> wrote:
>>> >
>>> >> Michael,
>>> >>
>>> >> you are right, there is definitely some limit at 2GB.  Here is a
>>> trivial
>>> >> example to demonstrate it:
>>> >>
>>> >> import org.apache.spark.storage.StorageLevel
>>> >> val d = sc.parallelize(1 to 1e6.toInt, 1).map{i => new
>>> >> Array[Byte](5e3.toInt)}.persist(StorageLevel.DISK_ONLY)
>>> >> d.count()
>>> >>
>>> >> It gives the same error you are observing.  I was under the same
>>> >> impression as Sean about the limits only being on blocks, not
>>> partitions --
>>> >> but clearly that isn't the case here.
>>> >>
>>> >> I don't know the whole story yet, but I just wanted to at least let
>>> you
>>> >> know you aren't crazy :)
>>> >> At the very least this suggests that you might need to make smaller
>>> >> partitions for now.
>>> >>
>>> >> Imran
>>> >>
>>> >>
>>> >> On Tue, Feb 3, 2015 at 4:58 AM, Michael Albert <
>>> >> m_albert137@yahoo.com.invalid> wrote:
>>> >>
>>> >>> Greetings!
>>> >>>
>>> >>> Thanks for the response.
>>> >>>
>>> >>> Below is an example of the exception I saw.
>>> >>> I'd rather not post code at the moment, so I realize it is completely
>>> >>> unreasonable to ask for a diagnosis.
>>> >>> However, I will say that adding a "partitionBy()" was the last change
>>> >>> before this error was created.
>>> >>>
>>> >>>
>>> >>> Thanks for your time and any thoughts you might have.
>>> >>>
>>> >>> Sincerely,
>>> >>>  Mike
>>> >>>
>>> >>>
>>> >>>
>>> >>> Exception in thread "main" org.apache.spark.SparkException: Job
>>> aborted
>>> >>> due to stage failure: Task 4 in stage 5.0 failed 4 times, most recent
>>> >>> failure: Lost task 4.3 in stage 5.0 (TID 6012,
>>> >>> ip-10-171-0-31.ec2.internal): java.lang.RuntimeException:
>>> >>> java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
>>> >>>     at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828)
>>> >>>     at
>>> org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:123)
>>> >>>     at
>>> org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:132)
>>> >>>     at
>>> >>>
>>> org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:517)
>>> >>>     at
>>> >>>
>>> org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:307)
>>> >>>     at
>>> >>>
>>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>> >>>     at
>>> >>>
>>> org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$2.apply(NettyBlockRpcServer.scala:57)
>>> >>>     at
>>> >>>
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>> >>>     at
>>> >>>
>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>> >>>     at
>>> >>>
>>> scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
>>> >>>   at
>>> scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
>>> >>>     at
>>> >>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>> >>>     at
>>> scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:108)
>>> >>>     at
>>> >>>
>>> org.apache.spark.network.netty.NettyBlockRpcServer.receive(NettyBlockRpcServer.scala:57)
>>> >>>
>>> >>>
>>> >>>   ------------------------------
>>> >>>  *From:* Sean Owen <sowen@cloudera.com>
>>> >>> *To:* Michael Albert <m_albert137@yahoo.com>
>>> >>> *Cc:* "user@spark.apache.org" <user@spark.apache.org>
>>> >>> *Sent:* Monday, February 2, 2015 10:13 PM
>>> >>> *Subject:* Re: 2GB limit for partitions?
>>>
>>> >>>
>>> >>> The limit is on blocks, not partitions. Partitions have many blocks.
>>> >>>
>>> >>> It sounds like you are creating very large values in memory, but I'm
>>> >>> not sure given your description. You will run into problems if a
>>> >>> single object is more than 2GB, of course. More of the stack trace
>>> >>> might show what is mapping that much memory.
>>> >>>
>>> >>> If you simply want data into 1000 files it's a lot simpler. Just
>>> >>> repartition into 1000 partitions and save the data. If you need more
>>> >>> control over what goes into which partition, use a Partitioner, yes.
>>> >>>
>>> >>>
>>> >>>
>>> >>> On Mon, Feb 2, 2015 at 8:40 PM, Michael Albert
>>> >>> <m_albert137@yahoo.com.invalid> wrote:
>>> >>> > Greetings!
>>> >>> >
>>> >>> > SPARK-1476 says that there is a 2G limit for "blocks".
>>> >>> > Is this the same as a 2G limit for partitions (or approximately
>>> so?)?
>>> >>> >
>>> >>> >
>>> >>> > What I had been attempting to do is the following.
>>> >>> > 1) Start with a moderately large data set (currently about 100GB,
>>> but
>>> >>> > growing).
>>> >>> > 2) Create about 1,000 files (yes, files) each representing a
>>> subset of
>>> >>> the
>>> >>> > data.
>>> >>> >
>>> >>> > The current attempt I am working on is something like this.
>>> >>> > 1) Do a "map" whose output key indicates which of the 1,000 files
>>> it
>>> >>> will go
>>> >>> > into and whose value is what I will want to stick into the file.
>>> >>> > 2) Partition the data and use the body of mapPartition to open a
>>> file
>>> >>> and
>>> >>> > save the data.
>>> >>> >
>>> >>> > My apologies, this is actually embedded in a bigger mess, so I
>>> won't
>>> >>> post
>>> >>> > it.
>>> >>> >
>>> >>> > However, I get errors telling me that there is an
>>> >>> "IllegalArgumentException:
>>> >>> > Size exceeds Inter.MAX_VALUE", with sun.nio.ch.FileChannelImpl.map
>>> at
>>> >>> the
>>> >>> > top of the stack.  This leads me to think that I have hit the
>>> limit or
>>> >>> > partition and/or block size.
>>> >>> >
>>> >>> > Perhaps this is not a good way to do it?
>>> >>> >
>>> >>> > I suppose I could run 1,000 passes over the data, each time
>>> collecting
>>> >>> the
>>> >>> > output for one of my 1,000 final files, but that seems likely to be
>>> >>> > painfully slow to run.
>>> >>> >
>>> >>> > Am I missing something?
>>> >>> >
>>> >>> > Admittedly, this is an odd use case....
>>> >>> >
>>> >>> > Thanks!
>>> >>> >
>>> >>> > Sincerely,
>>> >>> >  Mike Albert
>>> >>>
>>> >>>
>>> >>> ---------------------------------------------------------------------
>>> >>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>>> >>> For additional commands, e-mail: user-help@spark.apache.org
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>
>>> >
>>>
>>
>

--001a11c14f2681ebb6050e45da18--

From dev-return-11466-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 18:11:39 2015
Return-Path: <dev-return-11466-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2B1CA17275
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 18:11:39 +0000 (UTC)
Received: (qmail 41100 invoked by uid 500); 4 Feb 2015 18:11:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41018 invoked by uid 500); 4 Feb 2015 18:11:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40577 invoked by uid 99); 4 Feb 2015 18:11:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 18:11:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 18:11:30 +0000
Received: by mail-ob0-f181.google.com with SMTP id vb8so2779934obc.12
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 10:11:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=bNiIOpjyuuA6mpA5Lt5mG/AKFbquvz15TIwamC25S8Q=;
        b=LJO5WICCZW/pKNpp5/aJlVKFyiT+MjhX/fp4s70vRwI169WAHqj8Y53qKV7S5W52nS
         zB4ACIairgyyn/ZHC7VT3R2j6GprSaEx3dd4yvXQw2b4vHcCdv9ixZ4UAFCAy528HPqz
         KckCu942mloZmaUcA5+/b1Xr4AHc+0QWFsz3Gbm42GYFHXRVW1ob3fJf2GV/5iuyBy3k
         rFNNAAVO5yfeIHC0y0bnHUtpfHbC9pjaqgDiw139nCWdgMfTbrA7jhj7LJHx+QTCpYcx
         W4kgkdlC3qKJlXoHGzB3jmj9GVEtvunN3tLspmt0RgkOwJuOaZERYV0i64oG+CYMudND
         dlvw==
MIME-Version: 1.0
X-Received: by 10.202.1.200 with SMTP id 191mr18515894oib.82.1423073470075;
 Wed, 04 Feb 2015 10:11:10 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Wed, 4 Feb 2015 10:11:09 -0800 (PST)
In-Reply-To: <54D23B24.2010606@yahoo.com>
References: <54D23B24.2010606@yahoo.com>
Date: Wed, 4 Feb 2015 10:11:09 -0800
Message-ID: <CABPQxstQC+am_Xwp263o7SY4w+C=hasPTtxBwGWE6Be8YkP1xg@mail.gmail.com>
Subject: Re: 1.2.1-rc3 - Avro input format for Hadoop 2 broken/fix?
From: Patrick Wendell <pwendell@gmail.com>
To: medale@acm.org
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Markus,

That won't be included in 1.2.1 most likely because the release votes
have already started, and at that point we don't hold the release
except for major regression issues from 1.2.0. However, if this goes
through we can backport it into the 1.2 branch and it will end up in a
future maintenance release, or you can just build spark from that
branch as soon as it's in there.

- Patric

On Wed, Feb 4, 2015 at 7:30 AM, M. Dale <medale94@yahoo.com.invalid> wrote:
> SPARK-3039 "Spark assembly for new hadoop API (hadoop 2) contains
> avro-mapred for hadoop 1 API" was reopened
> and prevents v.1.2.1-rc3 from using Avro Input format for Hadoop 2
> API/instances (it includes the hadoop1 avro-mapred library files).
>
> What are the chances of getting the fix outlined here
> (https://github.com/medale/spark/compare/apache:v1.2.1-rc3...avro-hadoop2-v1.2.1-rc2)
> included in 1.2.1? My apologies, I do not know how to generate a pull
> request against a tag version.
>
> I did add pull request https://github.com/apache/spark/pull/4315 for the
> current 1.3.0-SNAPSHOT master on this issue. Even though 1.3.0 build already
> does not include avro-mapred in the spark assembly jar this minor change
> improves dependence convergence.
>
> Thanks,
> Markus
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11467-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 21:08:59 2015
Return-Path: <dev-return-11467-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4522F179BA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 21:08:59 +0000 (UTC)
Received: (qmail 44834 invoked by uid 500); 4 Feb 2015 21:08:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44769 invoked by uid 500); 4 Feb 2015 21:08:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44752 invoked by uid 99); 4 Feb 2015 21:08:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:08:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sergey.belousov@gmail.com designates 209.85.220.169 as permitted sender)
Received: from [209.85.220.169] (HELO mail-vc0-f169.google.com) (209.85.220.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:08:32 +0000
Received: by mail-vc0-f169.google.com with SMTP id hq12so1447352vcb.0
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 13:08:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=u41f6JM/xzLsPMZWILqzXVkXTLlJudLudSgm6m99cDY=;
        b=NjZxCxW8XLUMUOvFxXjgmBg9CIlYdRHs18meXXX3b846JTgiE3k4PQirxu0DOLZHhw
         gL6AtPeY/vNOj5f2Qs4jwse3bmOGZ1AuwtjJ9VV4radROKa7ap9ebG3nsEMi4ST4RlqH
         Ad933kUW9Ad4RMXnLn33BYtq6WWG5DRPlSFNnvG4cfFSPJO66am94CcCNaZS9qVAFZ87
         awBilx+YpOX5wp1Zi8iQfpAvPVAzory6aD5DzLZs9vsJeGPVBCQLX1IVSB1Z2qfXopyL
         Mt/59uUKlIKTO+a20GELlRxin8pDkcudVLHAC4gKhMTvVWRSrZjVoz1obEMthYEKHV7C
         5QGg==
MIME-Version: 1.0
X-Received: by 10.220.167.3 with SMTP id o3mr299659vcy.9.1423084110648; Wed,
 04 Feb 2015 13:08:30 -0800 (PST)
Received: by 10.52.56.67 with HTTP; Wed, 4 Feb 2015 13:08:30 -0800 (PST)
Date: Wed, 4 Feb 2015 16:08:30 -0500
Message-ID: <CAFmqivqs+vn_RNcwvmZ6Wu+=unv1k5TZjfJgo-2ZpFo+yRZR+A@mail.gmail.com>
Subject: Spark Cluster vs Spark on YARN jar loading
From: Sergey Belousov <sergey.belousov@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e011619d6e69b97050e499699
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011619d6e69b97050e499699
Content-Type: text/plain; charset=UTF-8

Hi All

We have our farjar that using asynchbase throwing following exception.

ERROR [Executor task launch worker-2-EventThread:ClientCnxn$EventThread@610]
- Caught unexpected throwable
java.lang.IllegalAccessError: class
com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass
com.google.protobuf.LiteralByteString
at java.lang.ClassLoader.defineClass1(Native Method)
at java.lang.ClassLoader.defineClass(Unknown Source)
at java.security.SecureClassLoader.defineClass(Unknown Source)
at java.net.URLClassLoader.defineClass(Unknown Source)
at java.net.URLClassLoader.access$100(Unknown Source)
at java.net.URLClassLoader$1.run(Unknown Source)
at java.net.URLClassLoader$1.run(Unknown Source)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(Unknown Source)
at java.lang.ClassLoader.loadClass(Unknown Source)
at java.lang.ClassLoader.loadClass(Unknown Source)
at org.hbase.async.Bytes.wrap(Bytes.java:287)
at org.hbase.async.RegionClient.<clinit>(RegionClient.java:580)
at
org.hbase.async.HBaseClient$RegionClientPipeline.init(HBaseClient.java:2655)
at org.hbase.async.HBaseClient.newClient(HBaseClient.java:2604)
at org.hbase.async.HBaseClient.access$2700(HBaseClient.java:179)
at
org.hbase.async.HBaseClient$ZKClient$ZKCallback.handleMetaZnode(HBaseClient.java:3301)
at
org.hbase.async.HBaseClient$ZKClient$ZKCallback.processResult(HBaseClient.java:3157)
at
org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:558)
at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:495)


*But when we try it with Spark on Yarn we do not have that problem. *
Can someone provide details as of what are differences that made that
particular problem go away when we use Spark on YARN?

I have some guess but I would really appreciate some infor from people who
has more than just guess.

Thank you
S

--089e011619d6e69b97050e499699--

From dev-return-11468-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 21:13:47 2015
Return-Path: <dev-return-11468-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ADE0217A1F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 21:13:47 +0000 (UTC)
Received: (qmail 71116 invoked by uid 500); 4 Feb 2015 21:13:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71045 invoked by uid 500); 4 Feb 2015 21:13:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71033 invoked by uid 99); 4 Feb 2015 21:13:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:13:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of skacanski@gmail.com designates 209.85.216.174 as permitted sender)
Received: from [209.85.216.174] (HELO mail-qc0-f174.google.com) (209.85.216.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:13:42 +0000
Received: by mail-qc0-f174.google.com with SMTP id s11so3487305qcv.5
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 13:13:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=oqFulZpJLqlIgXGEbiTxQksVRWsRQrV5hd2nOUlaXhI=;
        b=gKVkzC1L/9HAj3I365vtrxdb0UG79EXvN6kpKzaT7jHTQHgdPkkC5yjN1BUPeti6kV
         24uK9ITu8x261vyvIIazN+9nxK3TqALfdd8eMuTQqaD14+ofvpYzlsVo/X4ut52c+paB
         cZnz4DuU8SFXB/2mNabqEarn2P7pbQ6gM3wUy1t569phSjocfEKVMNxoSNFYRbJMC6ak
         Nuu/S6d36wG3R2k8jkQfziWwKxHlMhZnn+XDuG17cjxKyJI980zBV1b68DSl1dBdKHXT
         Tc3OtmuR4dTysM2Zr0SnBXksiiVRKAyIroMzXwk0E4ehRdzI0tUKiaWMuLIluJ0i8tJK
         RMGA==
MIME-Version: 1.0
X-Received: by 10.224.37.138 with SMTP id x10mr912212qad.4.1423084401391; Wed,
 04 Feb 2015 13:13:21 -0800 (PST)
Received: by 10.96.35.225 with HTTP; Wed, 4 Feb 2015 13:13:21 -0800 (PST)
Date: Wed, 4 Feb 2015 16:13:21 -0500
Message-ID: <CAFWiikp_+a+LBuzw5Q1uuBXyUvzxZsx3zXt+rknWqK+97yoVqQ@mail.gmail.com>
Subject: ZMQ and python streaming
From: Sasha Kacanski <skacanski@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1ef623b0122050e49a89d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1ef623b0122050e49a89d
Content-Type: text/plain; charset=UTF-8

Hi,

is it possible to integrate zmq with pyspark.streaming to receive messages
over TCP socket.

I seem to not be able to find working example for ZeroMQ implementation.

Regards,

-- 
Aleksandar Kacanski

--001a11c1ef623b0122050e49a89d--

From dev-return-11469-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 21:53:49 2015
Return-Path: <dev-return-11469-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6DC8817BEC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 21:53:49 +0000 (UTC)
Received: (qmail 84753 invoked by uid 500); 4 Feb 2015 21:53:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84681 invoked by uid 500); 4 Feb 2015 21:53:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84664 invoked by uid 99); 4 Feb 2015 21:53:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:53:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kayousterhout@gmail.com designates 209.85.213.52 as permitted sender)
Received: from [209.85.213.52] (HELO mail-yh0-f52.google.com) (209.85.213.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:53:24 +0000
Received: by mail-yh0-f52.google.com with SMTP id f10so1845932yha.11
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 13:53:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=yS1bI2T0Om2QK7X4xItRrJbnW+F9fOHPskT+IDlLraY=;
        b=Y1D4luWBWB505rKxkMPeNUHh52MTs1+UX+q1B6F/rYFIds/GHbEQO0INGcs4THVS0o
         pjlAphNlwpjyjjVAUzhvR3AYolRhFwZv5LdCSD7upURkTCOQshxODK2ZdXw59TE/wqGI
         tkHdnVmhTygmcieISrk+YtGTG7x3opb702zQvmy47OnI85Fg4UvnuDDXt6x9ayhoJdeO
         +Ax8R0Nj8JI2Y//4kpCzFzFBbQcLDEH6b4q3LYWibP0PRXVi9KB+6DduLM95+QH/4b6/
         Y2zTTtjfL0VC/XMPV9Zdc0e4ijNV4fcKGKZKDleWb5E6K01tUSmok9Mb4GZqdpxNbMqe
         uDDw==
MIME-Version: 1.0
X-Received: by 10.236.229.225 with SMTP id h91mr193753yhq.20.1423086802306;
 Wed, 04 Feb 2015 13:53:22 -0800 (PST)
Received: by 10.170.210.133 with HTTP; Wed, 4 Feb 2015 13:53:22 -0800 (PST)
Date: Wed, 4 Feb 2015 13:53:22 -0800
Message-ID: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
Subject: multi-line comment style
From: Kay Ousterhout <kayousterhout@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bf18428560e9b050e4a37c3
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf18428560e9b050e4a37c3
Content-Type: text/plain; charset=UTF-8

Hi all,

The Spark Style Guide
<https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide>
says multi-line comments should formatted as:

/*
 * This is a
 * very
 * long comment.
 */

But in my experience, we almost always use "//" for multi-line comments:

// This is a
// very
// long comment.

Here are some examples:

   - Recent commit by Reynold, king of style:
   https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
   - RDD.scala:
   https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
   - DAGScheduler.scala:
   https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281


Any objections to me updating the style guide to reflect this?  As with
other style issues, I think consistency here is helpful (and formatting
multi-line comments as "//" does nicely visually distinguish code comments
from doc comments).

-Kay

--047d7bf18428560e9b050e4a37c3--

From dev-return-11470-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 22:00:13 2015
Return-Path: <dev-return-11470-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4518817C46
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 22:00:13 +0000 (UTC)
Received: (qmail 16172 invoked by uid 500); 4 Feb 2015 22:00:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16097 invoked by uid 500); 4 Feb 2015 22:00:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16086 invoked by uid 99); 4 Feb 2015 22:00:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:00:11 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 21:59:47 +0000
Received: by mail-wi0-f182.google.com with SMTP id n3so6731460wiv.3
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 13:59:01 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=znDgWokPMwC+3daqRvJec8dFgA7hKNs6zk6g2DCL4uw=;
        b=OUabqTJR7H4W4QKR2UaN5K2nnwAoxIQCHtJGdvyJMwSYJLWwAebg+uoyuL0bRafaFX
         0LW3RLg5mzxVtdArapS7Z3JMKMdWl/9st09+IGQ8qoswbo7gdBKTmUnoEQIwW34tnHnZ
         0UgTZeTHWpq5r+LdevMGEdNYSBygYcX4erGyQl5L6MKgd66p8aTZP8Rl3TLvxsgGHmh/
         YuKp/QFT/lJw/CyZkK1gQ0HeRtpHnS07Hd4ZnqqMMNtVkFasTHgL5gqc2bALeTOTg9zf
         GrLHh1OAiJXxaZCankavj2ZXDFpWbdY3taHvVmtDF5ex6JjuXpoGQs9xmdCHcSkpWFnL
         EJ1Q==
X-Gm-Message-State: ALoCoQm+Ljcz2Yz0rAKZ2V80rSOK1ZAWorL9IT/+hxhKYps/huM1X97QHbyeJD4XR+isqTDqsbOy
X-Received: by 10.194.201.137 with SMTP id ka9mr1080814wjc.66.1423087141586;
 Wed, 04 Feb 2015 13:59:01 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Wed, 4 Feb 2015 13:58:41 -0800 (PST)
In-Reply-To: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 4 Feb 2015 15:58:41 -0600
Message-ID: <CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
Subject: Re: multi-line comment style
To: Kay Ousterhout <kayousterhout@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

One thing Marcelo pointed out to me is that the // style does not
interfere with commenting out blocks of code with /* */, which is a
small good thing. I am also accustomed to // style for multiline, and
reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
inline always looks a little funny to me.

On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <kayousterhout@gmail.com> wrote:
> Hi all,
>
> The Spark Style Guide
> <https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide>
> says multi-line comments should formatted as:
>
> /*
>  * This is a
>  * very
>  * long comment.
>  */
>
> But in my experience, we almost always use "//" for multi-line comments:
>
> // This is a
> // very
> // long comment.
>
> Here are some examples:
>
>    - Recent commit by Reynold, king of style:
>    https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
>    - RDD.scala:
>    https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
>    - DAGScheduler.scala:
>    https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
>
>
> Any objections to me updating the style guide to reflect this?  As with
> other style issues, I think consistency here is helpful (and formatting
> multi-line comments as "//" does nicely visually distinguish code comments
> from doc comments).
>
> -Kay

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11471-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 22:06:05 2015
Return-Path: <dev-return-11471-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D3C7417C7A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 22:06:05 +0000 (UTC)
Received: (qmail 34098 invoked by uid 500); 4 Feb 2015 22:06:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34027 invoked by uid 500); 4 Feb 2015 22:06:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34014 invoked by uid 99); 4 Feb 2015 22:06:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:06:05 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.46 as permitted sender)
Received: from [209.85.218.46] (HELO mail-oi0-f46.google.com) (209.85.218.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:05:40 +0000
Received: by mail-oi0-f46.google.com with SMTP id a141so3612847oig.5
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 14:05:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=4cHvOLccZiUBvuRmwEPWWoyTpoFIfk2C5uc9ZBUvJWA=;
        b=oJwn/vp08AbpqYjvBSjJM+C6wzEJ8vp+wu6p7n6RrHwSp0G0wVViQZU47HNb8Tg/zJ
         oSz4XS4SuKFu/rD62+Ri1HB/2ZaycWUhzZpIkmRm0+V6eopoa/fY8jP4Bigy19wySNzf
         Q2NXZRr2lJLW7zZ/XZXHJWd3NMOzL6HD8TuuZ2+ybbhgU30DctnDkXx6tgHDZR2nSDjq
         +djryXtuxrrqKqPpdwirI6tH+Rauow06k0Osr2JhsDXYCMY32alPrXPX0jhFMCheDu5y
         35rARODakJknZRgMpnStDIlAdhJQ9/j7Bfl8vZ//XHMuWqYktC7wWC8C3+tT+CsTmPCu
         q2bA==
MIME-Version: 1.0
X-Received: by 10.60.46.136 with SMTP id v8mr403549oem.18.1423087539030; Wed,
 04 Feb 2015 14:05:39 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Wed, 4 Feb 2015 14:05:38 -0800 (PST)
In-Reply-To: <CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
Date: Wed, 4 Feb 2015 14:05:38 -0800
Message-ID: <CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
Subject: Re: multi-line comment style
From: Patrick Wendell <pwendell@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Kay Ousterhout <kayousterhout@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Personally I have no opinion, but agree it would be nice to standardize.

- Patrick

On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
> One thing Marcelo pointed out to me is that the // style does not
> interfere with commenting out blocks of code with /* */, which is a
> small good thing. I am also accustomed to // style for multiline, and
> reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
> inline always looks a little funny to me.
>
> On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <kayousterhout@gmail.com> wrote:
>> Hi all,
>>
>> The Spark Style Guide
>> <https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide>
>> says multi-line comments should formatted as:
>>
>> /*
>>  * This is a
>>  * very
>>  * long comment.
>>  */
>>
>> But in my experience, we almost always use "//" for multi-line comments:
>>
>> // This is a
>> // very
>> // long comment.
>>
>> Here are some examples:
>>
>>    - Recent commit by Reynold, king of style:
>>    https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
>>    - RDD.scala:
>>    https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
>>    - DAGScheduler.scala:
>>    https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
>>
>>
>> Any objections to me updating the style guide to reflect this?  As with
>> other style issues, I think consistency here is helpful (and formatting
>> multi-line comments as "//" does nicely visually distinguish code comments
>> from doc comments).
>>
>> -Kay
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11472-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 22:10:20 2015
Return-Path: <dev-return-11472-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3926F17C9E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 22:10:20 +0000 (UTC)
Received: (qmail 53360 invoked by uid 500); 4 Feb 2015 22:10:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53281 invoked by uid 500); 4 Feb 2015 22:10:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53268 invoked by uid 99); 4 Feb 2015 22:10:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:10:19 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of shivaram@berkeley.edu designates 209.85.212.174 as permitted sender)
Received: from [209.85.212.174] (HELO mail-wi0-f174.google.com) (209.85.212.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:10:15 +0000
Received: by mail-wi0-f174.google.com with SMTP id n3so35106084wiv.1
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 14:09:54 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=Y2ZvdqL1oh/k15ZCUTJECS4HDhrb2igb5hsCdPLQUpc=;
        b=RBHIKandTunx4weSIJdoS34237BgVdJihj2IoMr+j8FNYu/tavzk1PtWZevhgjwLOL
         OR5Ah5dv+9M6dRnFpSttzwv+BhB0R2E/m/SPmH1fgMRse7yDwbsRqtmQhe2at6mXPMs9
         j1/LD0C/rJOl8bDphz5CmC8huFz14TaBPIfJtHODhCw260dA206wyJhXJC4pkU14ibbp
         2RyJ85l67ibjgRNejqnbpWIiP/GZBO2ANHM5z3olggZsySQewUH46LBJvaZOmhU3Ua3q
         TEeMOiHVRKqXQzGzRD9JhFOKqTu5YFwD27di7ke+25CcZiVldueBL/NHT+YzyILV+2nE
         allQ==
X-Gm-Message-State: ALoCoQlvsSNWlaAQkRuVmHqkC1sZ0dSooCL4Wzb7Enk0w0WpCdqBQEmF2W5yGmGdxSott9Ykyyf9
MIME-Version: 1.0
X-Received: by 10.194.63.16 with SMTP id c16mr707163wjs.117.1423087794484;
 Wed, 04 Feb 2015 14:09:54 -0800 (PST)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.216.163.6 with HTTP; Wed, 4 Feb 2015 14:09:54 -0800 (PST)
In-Reply-To: <CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
Date: Wed, 4 Feb 2015 14:09:54 -0800
Message-ID: <CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
Subject: Re: multi-line comment style
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b86da3a798672050e4a724c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b86da3a798672050e4a724c
Content-Type: text/plain; charset=UTF-8

FWIW I like the multi-line // over /* */ from a purely style standpoint.
The Google Java style guide[1] has some comment about code formatting tools
working better with /* */ but there doesn't seem to be any strong arguments
for one over the other I can find

Thanks
Shivaram

[1]
https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style

On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Personally I have no opinion, but agree it would be nice to standardize.
>
> - Patrick
>
> On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
> > One thing Marcelo pointed out to me is that the // style does not
> > interfere with commenting out blocks of code with /* */, which is a
> > small good thing. I am also accustomed to // style for multiline, and
> > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
> > inline always looks a little funny to me.
> >
> > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <kayousterhout@gmail.com>
> wrote:
> >> Hi all,
> >>
> >> The Spark Style Guide
> >> <
> https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide>
> >> says multi-line comments should formatted as:
> >>
> >> /*
> >>  * This is a
> >>  * very
> >>  * long comment.
> >>  */
> >>
> >> But in my experience, we almost always use "//" for multi-line comments:
> >>
> >> // This is a
> >> // very
> >> // long comment.
> >>
> >> Here are some examples:
> >>
> >>    - Recent commit by Reynold, king of style:
> >>
> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
> >>    - RDD.scala:
> >>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
> >>    - DAGScheduler.scala:
> >>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
> >>
> >>
> >> Any objections to me updating the style guide to reflect this?  As with
> >> other style issues, I think consistency here is helpful (and formatting
> >> multi-line comments as "//" does nicely visually distinguish code
> comments
> >> from doc comments).
> >>
> >> -Kay
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b86da3a798672050e4a724c--

From dev-return-11473-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb  4 22:18:34 2015
Return-Path: <dev-return-11473-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9F1C317D02
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  4 Feb 2015 22:18:34 +0000 (UTC)
Received: (qmail 89193 invoked by uid 500); 4 Feb 2015 22:18:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89116 invoked by uid 500); 4 Feb 2015 22:18:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89102 invoked by uid 99); 4 Feb 2015 22:18:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:18:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.53] (HELO mail-qa0-f53.google.com) (209.85.216.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 04 Feb 2015 22:18:09 +0000
Received: by mail-qa0-f53.google.com with SMTP id n4so3326644qaq.12
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 14:16:16 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=SD8mlHaiLuRge6otqRXI3Med4NVkWQqoZmb3QvMi4JA=;
        b=mk1YO1faVVgnXCSziCI5Kkz5sBjxQ3De6nHqrEN32qnDPeuxwKGOn2FTNTKVahGwBV
         03VDQ6MqgAD/VEGmrHamhNVSXtIPZ7iXazfiaRab1ysR2Ww/cgzpzf3/UpxJffiOBsO+
         G37hOJ+Vh6iUHxqTsPc0BZ5uciBTjER9w2i5E6yiTQ/CUJyD2UnGL35y2rCPlMls5ZzE
         mrwnYUgIT2hfBy3xpk+YhcCtdcXVMKHsN/keQMqXqU/t1sky8vO29TjznE3wto+SalBt
         nTfAC1Jr4tW0hsnKH1pkrcbWW6fCrtdtpXsCWzbY/hp8wd71y89CqMDH//9BSQeQJda+
         bOmQ==
X-Gm-Message-State: ALoCoQltM4+MqKfMMI2kx3S+0oslb7OFxDeVFPzY7r0cTocHPt+bxWpQjcVAb3E7Y7madh7K1Ttb
X-Received: by 10.140.19.175 with SMTP id 44mr1017677qgh.79.1423088176485;
 Wed, 04 Feb 2015 14:16:16 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Wed, 4 Feb 2015 14:15:56 -0800 (PST)
In-Reply-To: <CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
 <CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
 <CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com> <CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 4 Feb 2015 14:15:56 -0800
Message-ID: <CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
Subject: Re: multi-line comment style
To: shivaram@eecs.berkeley.edu
Cc: Patrick Wendell <pwendell@gmail.com>, Sean Owen <sowen@cloudera.com>, 
	Kay Ousterhout <kayousterhout@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134f65e3e721f050e4a8939
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134f65e3e721f050e4a8939
Content-Type: text/plain; charset=UTF-8

We should update the style doc to reflect what we have in most places
(which I think is //).



On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
shivaram@eecs.berkeley.edu> wrote:

> FWIW I like the multi-line // over /* */ from a purely style standpoint.
> The Google Java style guide[1] has some comment about code formatting tools
> working better with /* */ but there doesn't seem to be any strong arguments
> for one over the other I can find
>
> Thanks
> Shivaram
>
> [1]
>
> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
>
> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Personally I have no opinion, but agree it would be nice to standardize.
> >
> > - Patrick
> >
> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
> > > One thing Marcelo pointed out to me is that the // style does not
> > > interfere with commenting out blocks of code with /* */, which is a
> > > small good thing. I am also accustomed to // style for multiline, and
> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
> > > inline always looks a little funny to me.
> > >
> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
> kayousterhout@gmail.com>
> > wrote:
> > >> Hi all,
> > >>
> > >> The Spark Style Guide
> > >> <
> > https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
> >
> > >> says multi-line comments should formatted as:
> > >>
> > >> /*
> > >>  * This is a
> > >>  * very
> > >>  * long comment.
> > >>  */
> > >>
> > >> But in my experience, we almost always use "//" for multi-line
> comments:
> > >>
> > >> // This is a
> > >> // very
> > >> // long comment.
> > >>
> > >> Here are some examples:
> > >>
> > >>    - Recent commit by Reynold, king of style:
> > >>
> >
> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
> > >>    - RDD.scala:
> > >>
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
> > >>    - DAGScheduler.scala:
> > >>
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
> > >>
> > >>
> > >> Any objections to me updating the style guide to reflect this?  As
> with
> > >> other style issues, I think consistency here is helpful (and
> formatting
> > >> multi-line comments as "//" does nicely visually distinguish code
> > comments
> > >> from doc comments).
> > >>
> > >> -Kay
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a1134f65e3e721f050e4a8939--

From dev-return-11474-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:22:19 2015
Return-Path: <dev-return-11474-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 813EF101F0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:22:19 +0000 (UTC)
Received: (qmail 64647 invoked by uid 500); 5 Feb 2015 01:32:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64569 invoked by uid 500); 5 Feb 2015 01:32:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64546 invoked by uid 99); 5 Feb 2015 01:32:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:32:57 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of wangfei1@huawei.com designates 119.145.14.66 as permitted sender)
Received: from [119.145.14.66] (HELO szxga03-in.huawei.com) (119.145.14.66)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:32:53 +0000
Received: from 172.24.2.119 (EHLO szxeml428-hub.china.huawei.com) ([172.24.2.119])
	by szxrg03-dlp.huawei.com (MOS 4.4.3-GA FastPath queued)
	with ESMTP id BBK41126;
	Thu, 05 Feb 2015 09:32:31 +0800 (CST)
Received: from [127.0.0.1] (10.177.17.18) by szxeml428-hub.china.huawei.com
 (10.82.67.183) with Microsoft SMTP Server id 14.3.158.1; Thu, 5 Feb 2015
 09:32:30 +0800
Message-ID: <54D2C82D.9090505@huawei.com>
Date: Thu, 5 Feb 2015 09:32:29 +0800
From: scwf <wangfei1@huawei.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20130509 Thunderbird/17.0.6
MIME-Version: 1.0
To: <dev@spark.apache.org>
Subject: Re: Welcoming three new committers
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com> <CAMAsSdJoF31L4Kr6pvnxm8SZUns_gPpZV6LJgACqJm=ue95A9w@mail.gmail.com> <CALD+6GMOJnQ=FvsMNznymPjkEvdrjQUkq6ukE7AxCgAWC12gJA@mail.gmail.com>
In-Reply-To: <CALD+6GMOJnQ=FvsMNznymPjkEvdrjQUkq6ukE7AxCgAWC12gJA@mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"; format=flowed
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.177.17.18]
X-CFilter-Loop: Reflected
X-Mirapoint-Virus-RAPID-Raw: score=unknown(0),
	refid=str=0001.0A020205.54D2C82F.0132,ss=1,re=0.001,recu=0.000,reip=0.000,cl=1,cld=1,fgs=0,
	ip=0.0.0.0,
	so=2013-05-26 15:14:31,
	dmn=2013-03-21 17:37:32
X-Mirapoint-Loop-Id: a41f300619cce5651c7ab6b3a9733c2c
X-Virus-Checked: Checked by ClamAV on apache.org

Congratulations!

On 2015/2/4 20:25, Nick Pentreath wrote:
> Congrats and welcome Sean, Joseph and Cheng!
>
>
> On Wed, Feb 4, 2015 at 2:10 PM, Sean Owen <sowen@cloudera.com> wrote:
>
>> Thanks all, I appreciate the vote of trust. I'll do my best to help
>> keep JIRA and commits moving along, and am ramping up carefully this
>> week. Now get back to work reviewing things!
>>
>> On Tue, Feb 3, 2015 at 4:34 PM, Matei Zaharia <matei.zaharia@gmail.com>
>> wrote:
>>> Hi all,
>>>
>>> The PMC recently voted to add three new committers: Cheng Lian, Joseph
>> Bradley and Sean Owen. All three have been major contributors to Spark in
>> the past year: Cheng on Spark SQL, Joseph on MLlib, and Sean on ML and many
>> pieces throughout Spark Core. Join me in welcoming them as committers!
>>>
>>> Matei
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11478-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:26:27 2015
Return-Path: <dev-return-11478-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D19A1026C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:26:27 +0000 (UTC)
Received: (qmail 82675 invoked by uid 500); 5 Feb 2015 03:26:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82600 invoked by uid 500); 5 Feb 2015 03:26:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82586 invoked by uid 99); 5 Feb 2015 03:26:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 03:26:25 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.192.44 as permitted sender)
Received: from [209.85.192.44] (HELO mail-qg0-f44.google.com) (209.85.192.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 03:26:00 +0000
Received: by mail-qg0-f44.google.com with SMTP id l89so4527916qgf.3
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 19:25:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=RqCEmMFe/9/ZwLtiNEyGfIx3eVj9HSwRGz3mwUIjJ6I=;
        b=jR3WTpxPJJJti6kLNJNG5ZuSH08tWim3pPJ5Cn4oM02xdm/E+X6zS1TxOuVFMWocIM
         C0edQowN+1L7B4q7dNRCJEHCtju7MXFNGbTXYlmQokIkPBhz1sl/xVxeXVECZ5W2ARys
         jwFs0WOqECJsEpv+Y4CQMkTGMbmTxfCcuat7BDt8TkMCjurWMw7jmaxFFLtf6RXKrQKs
         A00sbfS/xBnGnm52DHoKpsZEfwgJvB58VAoouIDfyCbET1c2dj4jI/9MYoEtE9gRn0oh
         IosXKkxitGxnhnutCY0s7rhXzNY5CpsU64tky2jxk8JVlI0F/ryQ4oBuIZrfw80vs7Vk
         XqSQ==
MIME-Version: 1.0
X-Received: by 10.229.236.129 with SMTP id kk1mr3985001qcb.20.1423106713165;
 Wed, 04 Feb 2015 19:25:13 -0800 (PST)
Received: by 10.140.89.133 with HTTP; Wed, 4 Feb 2015 19:25:13 -0800 (PST)
Date: Wed, 4 Feb 2015 19:25:13 -0800
Message-ID: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
Subject: Broken record a bit here: building spark on intellij with sbt
From: Stephen Boesch <javadba@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134a43e1da6dc050e4eda1b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134a43e1da6dc050e4eda1b
Content-Type: text/plain; charset=UTF-8

For building in intellij with sbt my mileage has varied widely: it had
built as late as Monday (after the 1.3.0 release)  - and with zero
'special' steps: just "import" as sbt project.

 However I can not presently repeat the process.  The wiki page has the
latest instructions on how to build with maven - but not with sbt.  Is
there a resource for that?

https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-IntelliJ

The error I see is same as from a post in July

http://apache-spark-user-list.1001560.n3.nabble.com/Build-spark-with-Intellij-IDEA-13-td9904.html

Here is an excerpt:

uncaught exception during compilation: java.lang.AssertionError
Error:scalac: Error: assertion failed:
com.google.protobuf.InvalidProtocolBufferException
java.lang.AssertionError: assertion failed:
com.google.protobuf.InvalidProtocolBufferException
        at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)

The answer in the mailing list to that thread was about using maven .. so
that is not useful here.

--001a1134a43e1da6dc050e4eda1b--

From dev-return-11475-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:37:00 2015
Return-Path: <dev-return-11475-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0011F10446
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:36:59 +0000 (UTC)
Received: (qmail 726 invoked by uid 500); 5 Feb 2015 01:47:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 658 invoked by uid 500); 5 Feb 2015 01:47:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 646 invoked by uid 99); 5 Feb 2015 01:47:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:47:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of velvia.github@gmail.com designates 74.125.82.174 as permitted sender)
Received: from [74.125.82.174] (HELO mail-we0-f174.google.com) (74.125.82.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:47:32 +0000
Received: by mail-we0-f174.google.com with SMTP id w55so5053486wes.5
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 17:46:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=aiTa1guLYQEY9g4Q29r3aN3genYSSwDm16jGXbhLTfc=;
        b=JMPHJuJQ8GbLgIlXLdt5KtwyZS3hPPEFoGA1R911dGlV9yzXhzLMWPNPW2xtytgqTB
         5I99swErd4N3p/NMFqNLo5dFUPzDnKGTFuTwZBXn7IDkHQA7UpHfF0kC/EOW78OW7aDo
         ZaEOgB9P6eavd1CmkWLASOXWTced7lMC8Gmj3EAGEIQv9tdY65s7kplxQLFRXcmj6bFb
         VDpgSyn89Z+7N71514x+dqyPOPlWoYbnHkb6juScEMCSfXpeXGs+ThM9q4mwoyl89VtS
         l7nC7kaN5sreZAnBlNdc+trm3bZX5iKJvl1gUFTBW3pDBLHynEV/r4H9tqGuApg0nKTB
         Wj+Q==
MIME-Version: 1.0
X-Received: by 10.194.158.39 with SMTP id wr7mr2506947wjb.118.1423100787025;
 Wed, 04 Feb 2015 17:46:27 -0800 (PST)
Received: by 10.216.241.130 with HTTP; Wed, 4 Feb 2015 17:46:26 -0800 (PST)
Date: Wed, 4 Feb 2015 17:46:26 -0800
Message-ID: <CAN6Vra1-HpQK1N8nPUo0nQKg54QCdLAoDC5Zu8tAqO5dsvhNrQ@mail.gmail.com>
Subject: Spark Summit CFP - Tracks guidelines
From: Evan Chan <velvia.github@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hey guys,

Is there any guidance on what the different tracks for Spark Summit
West mean?  There are some new ones, like "Third Party Apps", which
seems like it would be similar to the "Use Cases".   Any further
guidance would be great.

thanks,
Evan

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11476-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:45:01 2015
Return-Path: <dev-return-11476-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1316610528
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:45:01 +0000 (UTC)
Received: (qmail 17369 invoked by uid 500); 5 Feb 2015 01:55:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17297 invoked by uid 500); 5 Feb 2015 01:55:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17286 invoked by uid 99); 5 Feb 2015 01:55:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:55:38 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.144 as permitted sender)
Received: from [169.229.218.144] (HELO cm03fe.IST.Berkeley.EDU) (169.229.218.144)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 01:55:11 +0000
Received: from mail-yk0-f176.google.com ([209.85.160.176])
	by cm03fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1YJBet-0003qM-Bu
	for dev@spark.apache.org; Wed, 04 Feb 2015 17:55:08 -0800
Received: by mail-yk0-f176.google.com with SMTP id q200so2148413ykb.7
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 17:55:06 -0800 (PST)
MIME-Version: 1.0
X-Received: by 10.236.3.73 with SMTP id 49mr218351yhg.57.1423101306898; Wed,
 04 Feb 2015 17:55:06 -0800 (PST)
Received: by 10.170.210.133 with HTTP; Wed, 4 Feb 2015 17:55:06 -0800 (PST)
In-Reply-To: <CAN6Vra1-HpQK1N8nPUo0nQKg54QCdLAoDC5Zu8tAqO5dsvhNrQ@mail.gmail.com>
References: <CAN6Vra1-HpQK1N8nPUo0nQKg54QCdLAoDC5Zu8tAqO5dsvhNrQ@mail.gmail.com>
Date: Wed, 4 Feb 2015 17:55:06 -0800
Message-ID: <CAKJXNjH5uVCbZ+Rr+cHU-aaejS0XACtZ1Z2P+PRbbcc2Y60MDw@mail.gmail.com>
Subject: Re: Spark Summit CFP - Tracks guidelines
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: Evan Chan <velvia.github@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11367d66e0fc4d050e4d9755
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11367d66e0fc4d050e4d9755
Content-Type: text/plain; charset=UTF-8

Did you see the longer descriptions under the "Learn More" link?

Developer
This track will present technical deep dive content across a wide range of
advanced/basic topics.

Data Science
This track will focus on the practice of data science using Spark. Sessions
should cover innovative techniques, algorithms and systems that refine raw
data into actionable insight using visualization, statistics and machine
learning.

Use Cases
This track is about use cases of Spark in the enterprise and lessons
learned.

Third-Party Apps
This track will focus on the applications that run on Spark. Talks will
offer more of the vendor perspective for end-to-end apps: integrations,
benefits of leveraging Spark, trade-offs, etc.

Research
This track will focus on academic research. Talks range from systems
research involving Spark to research use cases (e.g. genomics).

Business
This track will focus on how businesses utilize Spark. Talks will offer
exploration into ROI, best practices, Compliance requirements for specific
industries, customer testimonials.

On Wed, Feb 4, 2015 at 5:46 PM, Evan Chan <velvia.github@gmail.com> wrote:

> Hey guys,
>
> Is there any guidance on what the different tracks for Spark Summit
> West mean?  There are some new ones, like "Third Party Apps", which
> seems like it would be similar to the "Use Cases".   Any further
> guidance would be great.
>
> thanks,
> Evan
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11367d66e0fc4d050e4d9755--

From dev-return-11479-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:46:09 2015
Return-Path: <dev-return-11479-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEC2B10579
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:46:08 +0000 (UTC)
Received: (qmail 10828 invoked by uid 500); 5 Feb 2015 03:46:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10755 invoked by uid 500); 5 Feb 2015 03:46:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10743 invoked by uid 99); 5 Feb 2015 03:46:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 03:46:07 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of xuelincao2014@gmail.com designates 209.85.192.52 as permitted sender)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 03:45:42 +0000
Received: by mail-qg0-f52.google.com with SMTP id h3so604225qgf.11
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 19:44:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=DQeD55WHYlBhHuJcpq0UaVr4/pdghPtDdVc1yMUNnKY=;
        b=NJvDZIR8NDB0jgDu06fZUlaCr7yq9y3Of2GVU0HYIoxmNaZVMjCBmqxtnk37hUj8NN
         QT9wiJHxjQbFNVinSfeptnSswW1xlRkP4g/gWv1gpYWsEm2ot3ONTnvgAYqLvbTDyIn9
         mPpGO1xWZ3mjQVz1wqBBlJZeBcOzI3DDn9r7DcUFT7rVqCY95/d5ZIVV0B/KSX9QpYhy
         dmaekn4LVS++kXyaGEoRIjXNBLRAHaoRC+sfB90ggGHBMhckwD+ENwiOyt75DedmETs7
         dBWLqmBO8EyWYn9xM4OJWwqx9u4fV29fh15Ze1g3r8Uoo0PMnDWqFoZDTzG2/UtE9lD3
         cL+Q==
MIME-Version: 1.0
X-Received: by 10.224.46.132 with SMTP id j4mr4066698qaf.16.1423107850156;
 Wed, 04 Feb 2015 19:44:10 -0800 (PST)
Received: by 10.140.81.42 with HTTP; Wed, 4 Feb 2015 19:44:10 -0800 (PST)
Date: Thu, 5 Feb 2015 11:44:10 +0800
Message-ID: <CABjPPTQMJyuOjZMaOOyD5UkeY=gHw31BHrH0m66Uor+VGYgpTw@mail.gmail.com>
Subject: When will Spark Streaming supports Kafka-simple consumer API?
From: Xuelin Cao <xuelincao2014@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c25058e2c02b050e4f1d59
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25058e2c02b050e4f1d59
Content-Type: text/plain; charset=UTF-8

Hi,

     In our environment, Kafka can only be used with simple consumer API,
like storm spout does.

     And, also, I found there are suggestions that " Kafka connector of
Spark should not be used in production
<http://markmail.org/message/2lb776ta5sq6lgtw> because it is based on the
high-level consumer API of Kafka."

    So, my question is, when will spark streaming supports Kafka simple
consumer API?

--001a11c25058e2c02b050e4f1d59--

From dev-return-11477-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 03:57:12 2015
Return-Path: <dev-return-11477-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90CC010609
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 03:57:12 +0000 (UTC)
Received: (qmail 47454 invoked by uid 500); 5 Feb 2015 02:07:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47384 invoked by uid 500); 5 Feb 2015 02:07:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47372 invoked by uid 99); 5 Feb 2015 02:07:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 02:07:49 +0000
X-ASF-Spam-Status: No, hits=3.5 required=10.0
	tests=FORGED_YAHOO_RCVD,FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of medale94@yahoo.com designates 98.138.91.139 as permitted sender)
Received: from [98.138.91.139] (HELO nm9-vm3.bullet.mail.ne1.yahoo.com) (98.138.91.139)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 02:07:43 +0000
Received: from [98.138.100.118] by nm9.bullet.mail.ne1.yahoo.com with NNFMP; 05 Feb 2015 02:06:19 -0000
Received: from [98.138.104.115] by tm109.bullet.mail.ne1.yahoo.com with NNFMP; 05 Feb 2015 02:06:19 -0000
Received: from [127.0.0.1] by smtp224.mail.ne1.yahoo.com with NNFMP; 05 Feb 2015 02:06:19 -0000
X-Yahoo-Newman-Id: 535563.21914.bm@smtp224.mail.ne1.yahoo.com
X-Yahoo-Newman-Property: ymail-3
X-YMail-OSG: J.gvyJsVM1mF8hiaOzWgEMAQVoPF3jajokHbEMG1DRAvWxn
 XEd3x.1Z5TS2ErOiDDfhXIJ_iDZiQIxNoSxk4kub.LtowXnIQsSf5HuMmTk3
 06DvwAsNxeEmvPNHuGdyCuEadErm6sTtKEivmSWqD_IPyP281OZs9TBY8gq2
 deChs4xBa1aKfPKy5QPh9kTEsbCGTA.CLS9uAAXqHpXfbeJ2qA7bGxSO4stQ
 ii32fZ.Yc6jo0nB7dPrgn84PhXeMh6dERbTa8caJ9bCfigcS1Km0X2LMI7Ne
 NgVceQ4z90tFYU_flLfE3VnTkZh0TcK8L5v6_T5U21xj0D71lsUrUIYlK4he
 zoE7epgZWcBZTVd4VOPZJC4nlXM.ILQZLD7O4Wu4ImgAGBtjdURfwZMngYJD
 fuzQuOSBTtk3xfs6RE5Xxcmspwp16mS1JF8D9EWk8osRud5QxN1ipu0ogq2y
 G18YSfQIywVmQEyhDDBqZU0P8jIECLWz2OKHGanAvnQ5S3K4v4qXabOtxvLl
 lnXAA4zif0cEObR20trWOBtLOX2pZM8N9VQq3hlmQOuvGDaLQWJaUuiYhZ1C
 iAmGsixzlkAu6WjuRueuKVWaeHepds2W8UDLvEG2I1qLLwVmnStJm_g--
X-Yahoo-SMTP: 3cEdYaqswBCV.ogjqp0uR59JyCnf
Message-ID: <54D2D01A.2080300@yahoo.com>
Date: Wed, 04 Feb 2015 21:06:18 -0500
From: "M. Dale" <medale94@yahoo.com.INVALID>
Reply-To: medale@acm.org
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: Josh Rosen <rosenville@gmail.com>
CC: dev@spark.apache.org
Subject: Re: 1.2.1-rc3 - Avro input format for Hadoop 2 broken/fix?
References: <476F0CA8-B91B-4C2C-9523-FE93B2ED4BF3@gmail.com> <1294213902.1412359.1423076552677.JavaMail.yahoo@mail.yahoo.com> <etPan.54d26d30.74b0dc51.113@Joshs-MacBook-Pro.local>
In-Reply-To: <etPan.54d26d30.74b0dc51.113@Joshs-MacBook-Pro.local>
Content-Type: multipart/alternative;
 boundary="------------030506050209040603070109"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------030506050209040603070109
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

    On 02/04/2015 02:04 PM, Josh Rosen wrote:
> It looks like you replied just to me; mind CC’ing the mailing list, too?
>
>
> On February 4, 2015 at 11:02:34 AM, M. Dale (medale94@yahoo.com 
> <mailto:medale94@yahoo.com>) wrote:
>
>> Josh,
>> That was a bug that was present earlier. It was marked as fixed in 
>> 1.2.0 but it had not been fixed.
>>
>> Thanks,
>> Markus
>>
>>
>> On Wednesday, February 4, 2015 1:04 PM, Josh Rosen 
>> <rosenville@gmail.com> wrote:
>>
>>
>> Just to clarify, is this a regression from Spark 1.2.0 or is it a bug 
>> that was present in older versions?  Unless this is a 1.2.0->1.2.1 
>> regression, I don't think this can make it into 1.2.1 and will have 
>> to wait for 1.2.2.
>>
>> - Josh
>>
>> Sent from my phone
>>
>> > On Feb 4, 2015, at 7:30 AM, "M. Dale" <medale94@yahoo.com.INVALID 
>> <mailto:medale94@yahoo.com.INVALID>> wrote:
>> >
>> > SPARK-3039 "Spark assembly for new hadoop API (hadoop 2) contains 
>> avro-mapred for hadoop 1 API" was reopened
>> > and prevents v.1.2.1-rc3 from using Avro Input format for Hadoop 2 
>> API/instances (it includes the hadoop1 avro-mapred library files).
>> >
>> > What are the chances of getting the fix outlined here 
>> (https://github.com/medale/spark/compare/apache:v1.2.1-rc3...avro-hadoop2-v1.2.1-rc2) 
>> included in 1.2.1? My apologies, I do not know how to generate a pull 
>> request against a tag version.
>> >
>> > I did add pull request https://github.com/apache/spark/pull/4315 
>> for the current 1.3.0-SNAPSHOT master on this issue. Even though 
>> 1.3.0 build already does not include avro-mapred in the spark 
>> assembly jar this minor change improves dependence convergence.
>> >
>> > Thanks,
>> > Markus
>>
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org 
>> <mailto:dev-unsubscribe@spark.apache.org>
>> > For additional commands, e-mail: dev-help@spark.apache.org 
>> <mailto:dev-help@spark.apache.org>
>>
>> >
>>
>>


--------------030506050209040603070109--

From dev-return-11480-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 04:28:24 2015
Return-Path: <dev-return-11480-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B2778106E1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 04:28:24 +0000 (UTC)
Received: (qmail 54863 invoked by uid 500); 5 Feb 2015 04:28:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54782 invoked by uid 500); 5 Feb 2015 04:28:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54770 invoked by uid 99); 5 Feb 2015 04:28:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 04:28:22 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.192.45 as permitted sender)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 04:27:58 +0000
Received: by mail-qg0-f45.google.com with SMTP id q107so4656535qgd.4
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 20:27:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=dTg9r4aQl4ztM31SIJPTtzVLY7rmm8IucQ/1NaHmYg0=;
        b=cZ49h/rrlTQztGw358oxTSRH2UaItxO0zUf51hgJVl6m1dWSTVnYq7ECgOZszwlYgh
         cb2FwbJ6teMb5s7tlAnbJl/DSz2UT7c3++9IE8bRTWPWYEAKtMm2QWGrJvd2qBrp+yGm
         VrYP/rp0o5uOPjkZaUrVP80pNeSmkSl4RLE5Z866X5dQValfWTQLDlMMW6RDRZ80nuf0
         OqKN+Pdc/MD/+ksqt6TGBLvm9GxgZ1v/VkuQ9H0Jtrotg048nk1f1dewnO42mOFiqc27
         l/FIRA7fnnRlesNagvLj9O55kV4RQMaVh8MzEuOuNlcieXluMke4NCzuIhLCqu8qFuqy
         WBqw==
X-Received: by 10.140.38.136 with SMTP id t8mr3875638qgt.61.1423110430936;
 Wed, 04 Feb 2015 20:27:10 -0800 (PST)
MIME-Version: 1.0
Received: by 10.140.134.5 with HTTP; Wed, 4 Feb 2015 20:26:40 -0800 (PST)
In-Reply-To: <CABjPPTQMJyuOjZMaOOyD5UkeY=gHw31BHrH0m66Uor+VGYgpTw@mail.gmail.com>
References: <CABjPPTQMJyuOjZMaOOyD5UkeY=gHw31BHrH0m66Uor+VGYgpTw@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Wed, 4 Feb 2015 20:26:40 -0800
Message-ID: <CAMwrk0=rb-oK5fVXfgeU8rzRQT9KXqaFwXNTqF8+=C0jFZ5yvA@mail.gmail.com>
Subject: Re: When will Spark Streaming supports Kafka-simple consumer API?
To: Xuelin Cao <xuelincao2014@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c12db2b66422050e4fb7a5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c12db2b66422050e4fb7a5
Content-Type: text/plain; charset=UTF-8

1. There is already a third-party low-level kafka receiver -
http://spark-packages.org/package/5
2. There is a new experimental Kafka stream that will be available in Spark
1.3 release. This is based on the low level API, and might suffice your
purpose. JIRA - https://issues.apache.org/jira/browse/SPARK-4964

Can you elaborate on why you have to use SimpleConsumer in your environment?

TD


On Wed, Feb 4, 2015 at 7:44 PM, Xuelin Cao <xuelincao2014@gmail.com> wrote:

> Hi,
>
>      In our environment, Kafka can only be used with simple consumer API,
> like storm spout does.
>
>      And, also, I found there are suggestions that " Kafka connector of
> Spark should not be used in production
> <http://markmail.org/message/2lb776ta5sq6lgtw> because it is based on the
> high-level consumer API of Kafka."
>
>     So, my question is, when will spark streaming supports Kafka simple
> consumer API?
>

--001a11c12db2b66422050e4fb7a5--

From dev-return-11481-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 05:48:02 2015
Return-Path: <dev-return-11481-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 388DB108E3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 05:48:02 +0000 (UTC)
Received: (qmail 63965 invoked by uid 500); 5 Feb 2015 05:48:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63888 invoked by uid 500); 5 Feb 2015 05:48:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63877 invoked by uid 99); 5 Feb 2015 05:48:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 05:48:00 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 05:47:35 +0000
Received: by mail-lb0-f172.google.com with SMTP id l4so5268472lbv.3
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 21:46:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=5CMuD7rhFeWabpyyB7GI0KjAufN3qprtqxHgA2ksSPc=;
        b=LTjdtIx81vR+xAuwgWvKQFkZ0lgVrBvHOgNtilh8Y2K2q/7nt4Brqid48wQ6Y9lh/r
         NNUvwhEASG6LuP74FGkQOVIOL1Ki9QQYIfOEbR/hRyIyvDNqYUorfZufKrnUrCdomKvS
         AhvRHxeXvYm+M4/FB4X8mPzihA4G9xnA0moNueFxqAV1PujxyfXQ2t5QnU+mVie4zQvd
         JOPhPvFMK0QYpPq4kd0Bzm4OIAA7p/KYji7q1seETTgJsRXe2R6O1Jfye5ynRcgVNg6e
         nAur7BnwRhPeuKKJpxgCuxRI3SzonauObrlMhwWmVaLN6mNUZ9xk/iOBnpK4Y8jXn9RG
         AE+w==
X-Gm-Message-State: ALoCoQnuxlnwGk+TGpptSbuor1qIv6dGo3PIo3bo2PTQ0pfNEDZ5qyfIQCLVu3PJgA4krbd2eGxx
MIME-Version: 1.0
X-Received: by 10.112.235.194 with SMTP id uo2mr1564660lbc.57.1423115189370;
 Wed, 04 Feb 2015 21:46:29 -0800 (PST)
Received: by 10.152.124.38 with HTTP; Wed, 4 Feb 2015 21:46:29 -0800 (PST)
In-Reply-To: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
References: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
Date: Thu, 5 Feb 2015 11:16:29 +0530
Message-ID: <CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
Subject: Re: Broken record a bit here: building spark on intellij with sbt
From: Akhil Das <akhil@sigmoidanalytics.com>
To: Stephen Boesch <javadba@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c315e8565e8c050e50d31d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c315e8565e8c050e50d31d
Content-Type: text/plain; charset=UTF-8

Here's the sbt version
https://docs.sigmoidanalytics.com/index.php/Step_by_Step_instructions_on_how_to_build_Spark_App_with_IntelliJ_IDEA


Thanks
Best Regards

On Thu, Feb 5, 2015 at 8:55 AM, Stephen Boesch <javadba@gmail.com> wrote:

> For building in intellij with sbt my mileage has varied widely: it had
> built as late as Monday (after the 1.3.0 release)  - and with zero
> 'special' steps: just "import" as sbt project.
>
>  However I can not presently repeat the process.  The wiki page has the
> latest instructions on how to build with maven - but not with sbt.  Is
> there a resource for that?
>
>
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-IntelliJ
>
> The error I see is same as from a post in July
>
>
> http://apache-spark-user-list.1001560.n3.nabble.com/Build-spark-with-Intellij-IDEA-13-td9904.html
>
> Here is an excerpt:
>
> uncaught exception during compilation: java.lang.AssertionError
> Error:scalac: Error: assertion failed:
> com.google.protobuf.InvalidProtocolBufferException
> java.lang.AssertionError: assertion failed:
> com.google.protobuf.InvalidProtocolBufferException
>         at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)
>
> The answer in the mailing list to that thread was about using maven .. so
> that is not useful here.
>

--001a11c315e8565e8c050e50d31d--

From dev-return-11482-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 06:09:06 2015
Return-Path: <dev-return-11482-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 26DE7109A1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 06:09:06 +0000 (UTC)
Received: (qmail 97997 invoked by uid 500); 5 Feb 2015 06:09:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97945 invoked by uid 500); 5 Feb 2015 06:09:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97931 invoked by uid 99); 5 Feb 2015 06:09:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 06:09:04 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pradhandeep1991@gmail.com designates 209.85.216.179 as permitted sender)
Received: from [209.85.216.179] (HELO mail-qc0-f179.google.com) (209.85.216.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 06:08:39 +0000
Received: by mail-qc0-f179.google.com with SMTP id w7so5039308qcr.10
        for <dev@spark.apache.org>; Wed, 04 Feb 2015 22:07:07 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eHeuytcy6hAxQL1TU61Zpac8o+4AofIw/bH3JiZxQHY=;
        b=a8gYpkYGtuTugbuRQZOnq/jrd2bwz8Ja1hT7j85R37sdCwvy/ijdHAoLIm21yKuAVr
         lHTrtSLkE541uaPh8IDWQNTR169Bt+Vuzwzg9GcYpQGWo26SKp7GR2SkgNfIADe9i4PM
         tlTINybppeHEIXSZ4tm+tjdC8oHaWIwwLBJgKQjCjl1urPXeVUcdYNktYi/KadIXXMQd
         5uiycLrjKP4TenzIGb+aFfFs9XREKI3ZLGuG6anb0E2hsUA2arnkmKnNFRwKL8GvcEg1
         +9ANB525HEMCl1mJe/quy2DZn0B09WGuyvuNLMcSdik+RyF1imHbPAfKFeZ7CPGILByd
         ooOw==
MIME-Version: 1.0
X-Received: by 10.224.119.143 with SMTP id z15mr4857159qaq.11.1423116427758;
 Wed, 04 Feb 2015 22:07:07 -0800 (PST)
Received: by 10.229.84.130 with HTTP; Wed, 4 Feb 2015 22:07:07 -0800 (PST)
In-Reply-To: <CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
References: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
	<CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
Date: Thu, 5 Feb 2015 11:37:07 +0530
Message-ID: <CAO4MWgKNUQDE+fU6qH7XitxNQ=AmztP_S7f1jseRvCKB_63j5A@mail.gmail.com>
Subject: Re: Broken record a bit here: building spark on intellij with sbt
From: Deep Pradhan <pradhandeep1991@gmail.com>
To: Akhil Das <akhil@sigmoidanalytics.com>
Cc: Stephen Boesch <javadba@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bacc08026915e050e511d6b
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bacc08026915e050e511d6b
Content-Type: text/plain; charset=UTF-8

Akhil, it is not able to find the SBT package when I tried the steps given
in the site.

On Thu, Feb 5, 2015 at 11:16 AM, Akhil Das <akhil@sigmoidanalytics.com>
wrote:

> Here's the sbt version
>
> https://docs.sigmoidanalytics.com/index.php/Step_by_Step_instructions_on_how_to_build_Spark_App_with_IntelliJ_IDEA
>
>
> Thanks
> Best Regards
>
> On Thu, Feb 5, 2015 at 8:55 AM, Stephen Boesch <javadba@gmail.com> wrote:
>
> > For building in intellij with sbt my mileage has varied widely: it had
> > built as late as Monday (after the 1.3.0 release)  - and with zero
> > 'special' steps: just "import" as sbt project.
> >
> >  However I can not presently repeat the process.  The wiki page has the
> > latest instructions on how to build with maven - but not with sbt.  Is
> > there a resource for that?
> >
> >
> >
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-IntelliJ
> >
> > The error I see is same as from a post in July
> >
> >
> >
> http://apache-spark-user-list.1001560.n3.nabble.com/Build-spark-with-Intellij-IDEA-13-td9904.html
> >
> > Here is an excerpt:
> >
> > uncaught exception during compilation: java.lang.AssertionError
> > Error:scalac: Error: assertion failed:
> > com.google.protobuf.InvalidProtocolBufferException
> > java.lang.AssertionError: assertion failed:
> > com.google.protobuf.InvalidProtocolBufferException
> >         at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)
> >
> > The answer in the mailing list to that thread was about using maven .. so
> > that is not useful here.
> >
>

--047d7bacc08026915e050e511d6b--

From dev-return-11483-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 10:32:35 2015
Return-Path: <dev-return-11483-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0978A174F4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 10:32:35 +0000 (UTC)
Received: (qmail 62138 invoked by uid 500); 5 Feb 2015 10:32:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62068 invoked by uid 500); 5 Feb 2015 10:32:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62045 invoked by uid 99); 5 Feb 2015 10:32:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 10:32:33 +0000
X-ASF-Spam-Status: No, hits=4.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of xuelincao2014@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 10:32:29 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id CDEAD12E4D00
	for <dev@spark.apache.org>; Thu,  5 Feb 2015 02:31:10 -0800 (PST)
Date: Thu, 5 Feb 2015 03:31:08 -0700 (MST)
From: "Xuelin Cao.2015" <xuelincao2014@gmail.com>
To: dev@spark.apache.org
Message-ID: <CABjPPTSt-B80wvm81z6cL8WBQDCEkHsSGsW-tSRXrgf-_1hNSQ@mail.gmail.com>
In-Reply-To: <CAMwrk0=rb-oK5fVXfgeU8rzRQT9KXqaFwXNTqF8+=C0jFZ5yvA@mail.gmail.com>
References: <CABjPPTQMJyuOjZMaOOyD5UkeY=gHw31BHrH0m66Uor+VGYgpTw@mail.gmail.com> <CAMwrk0=rb-oK5fVXfgeU8rzRQT9KXqaFwXNTqF8+=C0jFZ5yvA@mail.gmail.com>
Subject: Re: When will Spark Streaming supports Kafka-simple consumer API?
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_186312_732458495.1423132268432"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_186312_732458495.1423132268432
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Hi, Tathagata

     Thanks for the information, I'm trying to build 1.3 snapshot and make
another try.

     There are 2 reasons for why we use Kafka SimpleConsumer API
     1. Previously, in our company, all of the real time processing system
were build on Apache Storm. So, the kafka environment is set to only
support SimpleConsumer API. The kafka environment is controlled by another
group of engineers in our company, and for some reasons I don't know, they
only support SimpleConsumer API.

     2. There is a document advises do not use kafka + spark streaming in
the production environment, due to spark streaming only supports high level
API. see
*http://www.michael-noll.com/blog/2014/10/01/kafka-spark-streaming-integration-example-tutorial/#known-issues-in-spark-streaming
<http://www.michael-noll.com/blog/2014/10/01/kafka-spark-streaming-integration-example-tutorial/#known-issues-in-spark-streaming>*

         I'm not quite sure whether the advise is with bias to spark
streaming. But, since we don't have any successful project as our
reference, we need to be careful about it.



On Thu, Feb 5, 2015 at 12:28 PM, Tathagata Das [via Apache Spark Developers
List] <ml-node+s1001551n10477h96@n3.nabble.com> wrote:

> 1. There is already a third-party low-level kafka receiver -
> http://spark-packages.org/package/5
> 2. There is a new experimental Kafka stream that will be available in
> Spark
> 1.3 release. This is based on the low level API, and might suffice your
> purpose. JIRA - https://issues.apache.org/jira/browse/SPARK-4964
>
> Can you elaborate on why you have to use SimpleConsumer in your
> environment?
>
> TD
>
>
> On Wed, Feb 4, 2015 at 7:44 PM, Xuelin Cao <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=10477&i=0>> wrote:
>
> > Hi,
> >
> >      In our environment, Kafka can only be used with simple consumer
> API,
> > like storm spout does.
> >
> >      And, also, I found there are suggestions that " Kafka connector of
> > Spark should not be used in production
> > <http://markmail.org/message/2lb776ta5sq6lgtw> because it is based on
> the
> > high-level consumer API of Kafka."
> >
> >     So, my question is, when will spark streaming supports Kafka simple
> > consumer API?
> >
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://apache-spark-developers-list.1001551.n3.nabble.com/When-will-Spark-Streaming-supports-Kafka-simple-consumer-API-tp10476p10477.html
>  To start a new topic under Apache Spark Developers List, email
> ml-node+s1001551n1h40@n3.nabble.com
> To unsubscribe from Apache Spark Developers List, click here
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=1&code=eHVlbGluY2FvMjAxNEBnbWFpbC5jb218MXwtOTc3NDY2MzAy>
> .
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/When-will-Spark-Streaming-supports-Kafka-simple-consumer-API-tp10476p10480.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_186312_732458495.1423132268432--

From dev-return-11484-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 19:56:55 2015
Return-Path: <dev-return-11484-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9EB6517DF3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 19:56:55 +0000 (UTC)
Received: (qmail 3650 invoked by uid 500); 5 Feb 2015 19:56:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3578 invoked by uid 500); 5 Feb 2015 19:56:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3567 invoked by uid 99); 5 Feb 2015 19:56:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 19:56:53 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.54] (HELO g4t3426.houston.hp.com) (15.201.208.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 19:56:47 +0000
Received: from G4W6310.americas.hpqcorp.net (g4w6310.houston.hp.com [16.210.26.217])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3426.houston.hp.com (Postfix) with ESMTPS id 3CB9FEA
	for <dev@spark.apache.org>; Thu,  5 Feb 2015 19:56:27 +0000 (UTC)
Received: from G9W3615.americas.hpqcorp.net (16.216.186.50) by
 G4W6310.americas.hpqcorp.net (16.210.26.217) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Thu, 5 Feb 2015 19:55:21 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G9W3615.americas.hpqcorp.net ([16.216.186.50]) with mapi id 14.03.0169.001;
 Thu, 5 Feb 2015 19:55:21 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQ==
Date: Thu, 5 Feb 2015 19:55:21 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Dear Spark developers,

I am exploring how to make linear algebra operations faster within Spark. O=
ne way of doing this is to use Scala Breeze library that is bundled with Sp=
ark. For matrix operations, it employs Netlib-java that has a Java wrapper =
for BLAS (basic linear algebra subprograms) and LAPACK native binaries if t=
hey are available on the worker node. It also has its own optimized Java im=
plementation of BLAS. It is worth mentioning, that native binaries provide =
better performance only for BLAS level 3, i.e. matrix-matrix operations or =
general matrix multiplication (GEMM). This is confirmed by GEMM test on Net=
lib-java page https://github.com/fommil/netlib-java. I also confirmed it wi=
th my experiments with training of artificial neural network https://github=
.com/apache/spark/pull/1290#issuecomment-70313952. However, I would like to=
 boost performance more.

GPU is supposed to work fast with linear algebra and there is Nvidia CUDA i=
mplementation of BLAS, called cublas. I have one Linux server with Nvidia G=
PU and I was able to do the following. I linked cublas (instead of cpu-base=
d blas) with Netlib-java wrapper and put it into Spark, so Breeze/Netlib is=
 using it. Then I did some performance measurements with regards to artific=
ial neural network batch learning in Spark MLlib that involves matrix-matri=
x multiplications. It turns out that for matrices of size less than ~1000x7=
80 GPU cublas has the same speed as CPU blas. Cublas becomes slower for big=
ger matrices. It worth mentioning that it is was not a test for ONLY multip=
lication since there are other operations involved. One of the reasons for =
slowdown might be the overhead of copying the matrices from computer memory=
 to graphic card memory and back.=20

So, few questions:
1) Do these results with CUDA make sense?=20
2) If the problem is with copy overhead, are there any libraries that allow=
 to force intermediate results to stay in graphic card memory thus removing=
 the overhead?
3) Any other options to speed-up linear algebra in Spark?

Thank you, Alexander

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11485-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 20:10:06 2015
Return-Path: <dev-return-11485-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0FC9C17EA5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 20:10:06 +0000 (UTC)
Received: (qmail 42364 invoked by uid 500); 5 Feb 2015 20:10:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42279 invoked by uid 500); 5 Feb 2015 20:10:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42267 invoked by uid 99); 5 Feb 2015 20:10:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:10:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.171 as permitted sender)
Received: from [209.85.220.171] (HELO mail-vc0-f171.google.com) (209.85.220.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:09:39 +0000
Received: by mail-vc0-f171.google.com with SMTP id hq12so1282263vcb.2
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 12:08:52 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=1m5aUmWOh1416rJEAalp2+562url2Czo58a4Z3tgYcg=;
        b=GiJPMO+1K+haYfmyNujaxmQlqA4YBsIRyYN3DReiC9ktI0uucJj+ZniN7DrcY2MxqI
         4m0qRfQNspPI3kGjoSVNTR94kOzWsW9PiN8OyK2gBwSxK6RPmPAfE0CNgD8DeLcOQjQ1
         Rz0FX8o4qV7MWNODdw+O+SHWWeBcr3hiB1LFlYhG7Oog747TW0Cs7TB2jER26clAR7Ih
         dhikcmbXH45htg9HaJE6prKufDCvMIgWBJFi1T/5TYiJR+um2SzDXQi8OqdLchWOBekR
         SyrnzLAndAVo4vZ4zUHG8RgsyPjR8lXjVXDIBbiYvfRE5ixBQAsCstMsbgcXARbzUG1m
         jzhQ==
X-Received: by 10.52.250.6 with SMTP id yy6mr3265772vdc.45.1423166932362; Thu,
 05 Feb 2015 12:08:52 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Thu, 5 Feb 2015 12:08:32 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Thu, 5 Feb 2015 12:08:32 -0800
Message-ID: <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136744e75ae16050e5cdf09
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136744e75ae16050e5cdf09
Content-Type: text/plain; charset=UTF-8

I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
many cases.

You might consider taking a look at the codepaths that BIDMat (
https://github.com/BIDData/BIDMat) takes and comparing them to
netlib-java/breeze. John Canny et. al. have done a bunch of work optimizing
to make this work really fast from Scala. I've run it on my laptop and
compared to MKL and in certain cases it's 10x faster at matrix multiply.
There are a lot of layers of indirection here and you really want to avoid
data copying as much as possible.

We could also consider swapping out BIDMat for Breeze, but that would be a
big project and if we can figure out how to get breeze+cublas to comparable
performance that would be a big win.

On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that native
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidia
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cublas
> becomes slower for bigger matrices. It worth mentioning that it is was not
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1136744e75ae16050e5cdf09--

From dev-return-11486-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 20:12:44 2015
Return-Path: <dev-return-11486-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 767DE17EE1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 20:12:44 +0000 (UTC)
Received: (qmail 53797 invoked by uid 500); 5 Feb 2015 20:12:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53711 invoked by uid 500); 5 Feb 2015 20:12:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53688 invoked by uid 99); 5 Feb 2015 20:12:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:12:42 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.216.44 as permitted sender)
Received: from [209.85.216.44] (HELO mail-qa0-f44.google.com) (209.85.216.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:12:38 +0000
Received: by mail-qa0-f44.google.com with SMTP id w8so7558236qac.3
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 12:11:32 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=qDR9AUQ1PxBsGZmuW40wbIqkJgX/LSwoCeV+U0Q6Z64=;
        b=fK7RmyBZkbsm7VbI2qty3JG6WXoI/0SwYy0Ug2zqQHzS2Jb76vbeDx/vkWBer2KpSa
         y9YW23a5hUVkUjGzzy6PpTgBZz/YyDAJALX0l+Lf0P4+ZImhjSLRKlSnlExEwaNw0aDO
         DIjrpmFHeACJfwGUvDqz1LQrmNlCzVJ9yG2EgKoOI8v7bF/B3Mkzl35mANu/ADWpVm8/
         E+oeaz7vpIRMZtzwggtzhLk26ZitDFNTZMeWfQtLrJfTb3AZIlDwqaWb2Si8JrNx4GwT
         D1TpZj2+slsV/BBeLpUeKp4k/4nKcJKWis4ZjHsLaYQdX+C9kA/pq76M9N5aEpsAY9/W
         xPjg==
MIME-Version: 1.0
X-Received: by 10.224.89.65 with SMTP id d1mr2050585qam.40.1423167092511; Thu,
 05 Feb 2015 12:11:32 -0800 (PST)
Received: by 10.140.89.133 with HTTP; Thu, 5 Feb 2015 12:11:32 -0800 (PST)
In-Reply-To: <CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
References: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
	<CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
Date: Thu, 5 Feb 2015 12:11:32 -0800
Message-ID: <CACkSZy2qUDZiLabDuTPkCk5wJG7pUdouMOnQ9KC8m_Q5sN07TA@mail.gmail.com>
Subject: Re: Broken record a bit here: building spark on intellij with sbt
From: Stephen Boesch <javadba@gmail.com>
To: Akhil Das <akhil@sigmoidanalytics.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3bb8e015c64050e5ce928
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3bb8e015c64050e5ce928
Content-Type: text/plain; charset=UTF-8

Hi Akhil
  Those instructions you provided are showing how to manually build an sbt
project that may include adding spark dependencies.  Whereas my OP was
about how to open the existing spark sbt project .  These two are not
similar tasks.

2015-02-04 21:46 GMT-08:00 Akhil Das <akhil@sigmoidanalytics.com>:

> Here's the sbt version
> https://docs.sigmoidanalytics.com/index.php/Step_by_Step_instructions_on_how_to_build_Spark_App_with_IntelliJ_IDEA
>
>
> Thanks
> Best Regards
>
> On Thu, Feb 5, 2015 at 8:55 AM, Stephen Boesch <javadba@gmail.com> wrote:
>
>> For building in intellij with sbt my mileage has varied widely: it had
>> built as late as Monday (after the 1.3.0 release)  - and with zero
>> 'special' steps: just "import" as sbt project.
>>
>>  However I can not presently repeat the process.  The wiki page has the
>> latest instructions on how to build with maven - but not with sbt.  Is
>> there a resource for that?
>>
>>
>> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-IntelliJ
>>
>> The error I see is same as from a post in July
>>
>>
>> http://apache-spark-user-list.1001560.n3.nabble.com/Build-spark-with-Intellij-IDEA-13-td9904.html
>>
>> Here is an excerpt:
>>
>> uncaught exception during compilation: java.lang.AssertionError
>> Error:scalac: Error: assertion failed:
>> com.google.protobuf.InvalidProtocolBufferException
>> java.lang.AssertionError: assertion failed:
>> com.google.protobuf.InvalidProtocolBufferException
>>         at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)
>>
>> The answer in the mailing list to that thread was about using maven .. so
>> that is not useful here.
>>
>
>

--001a11c3bb8e015c64050e5ce928--

From dev-return-11487-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 20:32:20 2015
Return-Path: <dev-return-11487-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B67E117F97
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 20:32:20 +0000 (UTC)
Received: (qmail 9952 invoked by uid 500); 5 Feb 2015 20:32:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9886 invoked by uid 500); 5 Feb 2015 20:32:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9867 invoked by uid 99); 5 Feb 2015 20:32:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:32:19 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,T_REMOTE_IMAGE,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 20:31:54 +0000
Received: by mail-ig0-f180.google.com with SMTP id b16so887284igk.1
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 12:30:02 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=lsKzXYqAl7EfofEEemzipzb4NVDVhVplQQGQLke7gcA=;
        b=LF28+jajx+gOMIVgHA1O0f0WYnruz8PeNwlXJKUxt8S7YVttkUDOTo0AbIFNzHsWan
         PnJ1l+WXDcIbKh92/n1Ssj4eCkotVlPh+1qhTc86M6E3vVxusFDSR4/th0hUDl5Aaz2n
         I71pVIu1aS//x2yq4UM+JQUiMsbZHRUsZF0KvmSfFDzISLapA6RVbk4+eVa8h11S6Zm+
         l791d9Tfm9N0OWUFpcb9NKF7TQ18gnzd6HL2p7arRDmO3mZBb//5S1bH3gUMXoLOhvcv
         o4SWbYtqxJREdg8WxOQhPJt8zJ7s2emfAmOp/aqXuYZ4U690TIsIQCDOEqhZgn/oUEo0
         CSjQ==
X-Gm-Message-State: ALoCoQmL//K9Gtsr/5Y2i9WknbZg1/dxbA5og/o46sXvv8YVMPlMX53G7eLaVX2Hm7lV/nVO9oQN
MIME-Version: 1.0
X-Received: by 10.50.39.112 with SMTP id o16mr411828igk.0.1423168202219; Thu,
 05 Feb 2015 12:30:02 -0800 (PST)
Received: by 10.107.11.137 with HTTP; Thu, 5 Feb 2015 12:30:02 -0800 (PST)
In-Reply-To: <CACkSZy2qUDZiLabDuTPkCk5wJG7pUdouMOnQ9KC8m_Q5sN07TA@mail.gmail.com>
References: <CACkSZy31kxXf7fhzgN0h+=A_L7UCR=w6NdmOyuOW0j3BUnQO7g@mail.gmail.com>
	<CAHUQ+_bhdh=Gqg=_p7S8UPGC5S=NJHrT85HnrzEXpPAVmNtdrA@mail.gmail.com>
	<CACkSZy2qUDZiLabDuTPkCk5wJG7pUdouMOnQ9KC8m_Q5sN07TA@mail.gmail.com>
Date: Fri, 6 Feb 2015 02:00:02 +0530
Message-ID: <CABD4CGKZqac2fhiCEg6k4+90emyY2-APiuK8wZOEGE99Sv9kZA@mail.gmail.com>
Subject: Re: Broken record a bit here: building spark on intellij with sbt
From: Arush Kharbanda <arush@sigmoidanalytics.com>
To: Stephen Boesch <javadba@gmail.com>
Cc: Akhil Das <akhil@sigmoidanalytics.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdca2f4263c36050e5d2b12
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdca2f4263c36050e5d2b12
Content-Type: text/plain; charset=UTF-8

I follow these ones to import sbt projects.

1. Install sbt plugins: Goto File -> Settings -> Plugins -> Install
IntelliJ Plugins -> Search for sbt and install it
2. File ->Import->browse the root of spark source code

I hope this helps




On Fri, Feb 6, 2015 at 1:41 AM, Stephen Boesch <javadba@gmail.com> wrote:

> Hi Akhil
>   Those instructions you provided are showing how to manually build an sbt
> project that may include adding spark dependencies.  Whereas my OP was
> about how to open the existing spark sbt project .  These two are not
> similar tasks.
>
> 2015-02-04 21:46 GMT-08:00 Akhil Das <akhil@sigmoidanalytics.com>:
>
> > Here's the sbt version
> >
> https://docs.sigmoidanalytics.com/index.php/Step_by_Step_instructions_on_how_to_build_Spark_App_with_IntelliJ_IDEA
> >
> >
> > Thanks
> > Best Regards
> >
> > On Thu, Feb 5, 2015 at 8:55 AM, Stephen Boesch <javadba@gmail.com>
> wrote:
> >
> >> For building in intellij with sbt my mileage has varied widely: it had
> >> built as late as Monday (after the 1.3.0 release)  - and with zero
> >> 'special' steps: just "import" as sbt project.
> >>
> >>  However I can not presently repeat the process.  The wiki page has the
> >> latest instructions on how to build with maven - but not with sbt.  Is
> >> there a resource for that?
> >>
> >>
> >>
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-IntelliJ
> >>
> >> The error I see is same as from a post in July
> >>
> >>
> >>
> http://apache-spark-user-list.1001560.n3.nabble.com/Build-spark-with-Intellij-IDEA-13-td9904.html
> >>
> >> Here is an excerpt:
> >>
> >> uncaught exception during compilation: java.lang.AssertionError
> >> Error:scalac: Error: assertion failed:
> >> com.google.protobuf.InvalidProtocolBufferException
> >> java.lang.AssertionError: assertion failed:
> >> com.google.protobuf.InvalidProtocolBufferException
> >>         at
> scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)
> >>
> >> The answer in the mailing list to that thread was about using maven ..
> so
> >> that is not useful here.
> >>
> >
> >
>



-- 

[image: Sigmoid Analytics] <http://htmlsig.com/www.sigmoidanalytics.com>

Arush Kharbanda || Technical Teamlead

arush@sigmoidanalytics.com || www.sigmoidanalytics.com

--047d7bdca2f4263c36050e5d2b12--

From dev-return-11488-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 21:03:03 2015
Return-Path: <dev-return-11488-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D43EF172F0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 21:03:03 +0000 (UTC)
Received: (qmail 97663 invoked by uid 500); 5 Feb 2015 21:03:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97586 invoked by uid 500); 5 Feb 2015 21:03:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97569 invoked by uid 99); 5 Feb 2015 21:03:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 21:03:01 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 21:02:34 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id 207EF2F8;
	Thu,  5 Feb 2015 21:02:01 +0000 (UTC)
Received: from G9W3614.americas.hpqcorp.net (16.216.186.49) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Thu, 5 Feb 2015 21:00:51 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G9W3614.americas.hpqcorp.net ([16.216.186.49]) with mapi id 14.03.0169.001;
 Thu, 5 Feb 2015 21:00:51 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLA=
Date: Thu, 5 Feb 2015 21:00:51 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
In-Reply-To: <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2DG4W3292americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2DG4W3292americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2DG4W3292americas_--

From dev-return-11489-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb  5 21:29:25 2015
Return-Path: <dev-return-11489-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AFE9C1741B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  5 Feb 2015 21:29:25 +0000 (UTC)
Received: (qmail 68618 invoked by uid 500); 5 Feb 2015 21:29:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68540 invoked by uid 500); 5 Feb 2015 21:29:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68528 invoked by uid 99); 5 Feb 2015 21:29:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 21:29:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.179 as permitted sender)
Received: from [209.85.220.179] (HELO mail-vc0-f179.google.com) (209.85.220.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 05 Feb 2015 21:29:20 +0000
Received: by mail-vc0-f179.google.com with SMTP id la4so3686152vcb.10
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 13:28:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=Fi2XmuFHiGIVO2+ucUgreB91RZ6JPaVWyDBeScFVkVU=;
        b=rkDJSucVTuSDBKiI707/04RVqb0RtA3WSoD9/D5K2a8oITDdFIftBKnn3stcyMgV4r
         weYizHAsJ0Acic0Gxq7Ddu11ep3dV7Y57MMDPjHCBdOBW60xZ67OyiwVv7jhQJ4wfz+E
         UAizNK8vId2t1QJ9DmRoiQ7vUj1qt9or5CzXRA9CVo9HHkRc3iF5MJ6F6jDiLzyMmV2E
         nIh7kHMoP7nqj417TU2WHpem7U4rNaCKYqLJDmAG3OGPQkMc0HcHI+zaN9T6V88ET+3k
         J9GpnTdvHGrGR5+LhLymKBjqx/+IRw9UCfLfj4GU4zvPaGLhQ1dFgM/qzChig6Bepa2N
         xtww==
X-Received: by 10.52.73.166 with SMTP id m6mr171880vdv.13.1423171739318; Thu,
 05 Feb 2015 13:28:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Thu, 5 Feb 2015 13:28:39 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Thu, 5 Feb 2015 13:28:39 -0800
Message-ID: <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec5015fa5f9ffee050e5dfd0d
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec5015fa5f9ffee050e5dfd0d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I'd be surprised of BIDMat+OpenBLAS was significantly faster than
netlib-java+OpenBLAS, but if it is much faster it's probably due to data
layout and fewer levels of indirection - it's definitely a worthwhile
experiment to run. The main speedups I've seen from using it come from
highly optimized GPU code for linear algebra. I know that in the past Canny
has gone as far as to write custom GPU kernels for performance-critical
regions of code.[1]

BIDMach is highly optimized for single node performance or performance on
small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
batched in that way) the performance tends to fall off. Canny argues for
hardware/software codesign and as such prefers machine configurations that
are quite different than what we find in most commodity cluster nodes -
e.g. 10 disk cahnnels and 4 GPUs.

In contrast, MLlib was designed for horizontal scalability on commodity
clusters and works best on very big datasets - order of terabytes.

For the most part, these projects developed concurrently to address
slightly different use cases. That said, there may be bits of BIDMach we
could repurpose for MLlib - keep in mind we need to be careful about
maintaining cross-language compatibility for our Java and Python-users,
though.

- Evan

[1] - http://arxiv.org/abs/1409.5402
[2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf

On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

>  Hi Evan,
>
>
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
>
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
>
>
> Best regards, Alexander
>
>
>
> *From:* Evan R. Sparks [mailto:evan.sparks@gmail.com]
> *Sent:* Thursday, February 05, 2015 12:09 PM
> *To:* Ulanov, Alexander
> *Cc:* dev@spark.apache.org
> *Subject:* Re: Using CUDA within Spark / boosting linear algebra
>
>
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
>
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
>
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
>
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com> wrote:
>
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>
>

--bcaec5015fa5f9ffee050e5dfd0d--

From dev-return-11490-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 00:16:43 2015
Return-Path: <dev-return-11490-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F0E7C17ABF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 00:16:42 +0000 (UTC)
Received: (qmail 11649 invoked by uid 500); 6 Feb 2015 00:16:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11578 invoked by uid 500); 6 Feb 2015 00:16:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11565 invoked by uid 99); 6 Feb 2015 00:16:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 00:16:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 00:16:14 +0000
Received: by mail-ig0-f177.google.com with SMTP id z20so3293182igj.4
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 16:16:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=jDeeD8+68TkSO6tNgPruYynotcpOD8vX0Mkcb89AbLw=;
        b=mbNb5GGrhsMn34OmnU+0Ld67+n7yDGItGGmz6SyIgxFqkSFQ9J+fqDz3K3OEpcWc8W
         HK4VJpsenn7wnmP3dK0gnivVXs15szk93hzzDgo2SUtoVvzptAkCl1m9lWJOAHRsT6Ne
         Ix9YiApSO/ejXFD5pu1diIBc02A3uzpZEbN5ggVTaDIk5T9ofvAutIKcrqaIes8KYli2
         1g/BvM1m8+4DvTJRwNcmcZS92BusBeQZpB5i6Z6hzR6NyKLtpapdYOKAbEcH3nbbBhtd
         wXrB3bb5shYwIVI7/TbFmdTW2Mq3YCjtjeKFu1VDZbGkcxA708wEJU7rOGRXDPCC0E+z
         uswQ==
X-Received: by 10.107.157.67 with SMTP id g64mr8082395ioe.72.1423181772948;
 Thu, 05 Feb 2015 16:16:12 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 06 Feb 2015 00:16:12 +0000
Message-ID: <CAOhmDzcCob-Rn61mm-vzCJky-gH9JhyUpOmdWCL8yWN-yHFf6w@mail.gmail.com>
Subject: PSA: Maven supports parallel builds
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1140cd1e070f36050e605470
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1140cd1e070f36050e605470
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Y=E2=80=99all may already know this, but I haven=E2=80=99t seen it mentione=
d anywhere in
our docs on here and it=E2=80=99s a pretty easy win.

Maven supports parallel builds
<https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven=
+3>
with the -T command line option.

For example:

./build/mvn -T 1C -Dhadoop.version=3D1.2.1 -DskipTests clean package

This will have Maven use 1 thread per core on your machine to build Spark.

On my little MacBook air, this cuts the build time from 14 minutes to 10.5
minutes. A machine with more cores should see a bigger improvement.

Note though that the docs mark this as experimental, so I wouldn=E2=80=99t =
change
our reference build to use this. But it should be useful, for example, in
Jenkins or when working locally.

Nick
=E2=80=8B

--001a1140cd1e070f36050e605470--

From dev-return-11491-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 00:54:26 2015
Return-Path: <dev-return-11491-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1253117BDB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 00:54:26 +0000 (UTC)
Received: (qmail 8447 invoked by uid 500); 6 Feb 2015 00:54:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8373 invoked by uid 500); 6 Feb 2015 00:54:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8361 invoked by uid 99); 6 Feb 2015 00:54:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 00:54:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of dirceu.semighini@gmail.com designates 209.85.214.178 as permitted sender)
Received: from [209.85.214.178] (HELO mail-ob0-f178.google.com) (209.85.214.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 00:53:57 +0000
Received: by mail-ob0-f178.google.com with SMTP id uz6so10401762obc.9
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 16:53:11 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=weXrIvd7LrhhRbYew3nRAIfiktxTg21A60REoyiwo+U=;
        b=bes5xniK9jFJ1cJ8toVsKiEn1RvAkWh0oMK3uRQkcK/ls7kepBlIhhlSWHkO9t3Qzz
         YCYB3+tdRtZoEQQvGqLt0mQRA2CFS0hrQxPPOz6rWqNSPCqo50C9dICs58fVasEe8ldf
         zaIM665R02PbW+zD9shxzWUhFJkm6RIVDJ/rlLAwV2KYFhTc9nqGOG2x78Ly12GU0BoT
         LcMlw5QJZe8uxGZcj/ZCTMCJt4dAQ9zRImKdeMRKg57h95UQsV/uzhd/+Ys8W3okyLSo
         117X2tuTaoTrQiJSMEgxzuY5CUXAuuBSw0SgjBQ4bEaTCwuUTILlXb2BDIwdUHAegfwE
         CwTw==
X-Received: by 10.182.213.102 with SMTP id nr6mr659794obc.5.1423183991095;
 Thu, 05 Feb 2015 16:53:11 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.108.87 with HTTP; Thu, 5 Feb 2015 16:52:30 -0800 (PST)
In-Reply-To: <CAOhmDzcCob-Rn61mm-vzCJky-gH9JhyUpOmdWCL8yWN-yHFf6w@mail.gmail.com>
References: <CAOhmDzcCob-Rn61mm-vzCJky-gH9JhyUpOmdWCL8yWN-yHFf6w@mail.gmail.com>
From: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Date: Thu, 5 Feb 2015 22:52:30 -0200
Message-ID: <CAO4-Pq-JnNkWnLGzStEZAohh6B8AAJ4DPHs1wiHHgf=qMCYu=w@mail.gmail.com>
Subject: Re: PSA: Maven supports parallel builds
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3234c3d476d050e60d8e5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3234c3d476d050e60d8e5
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks Nicholas, I didn't knew this.

2015-02-05 22:16 GMT-02:00 Nicholas Chammas <nicholas.chammas@gmail.com>:

> Y=E2=80=99all may already know this, but I haven=E2=80=99t seen it mentio=
ned anywhere in
> our docs on here and it=E2=80=99s a pretty easy win.
>
> Maven supports parallel builds
> <
> https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Mave=
n+3
> >
> with the -T command line option.
>
> For example:
>
> ./build/mvn -T 1C -Dhadoop.version=3D1.2.1 -DskipTests clean package
>
> This will have Maven use 1 thread per core on your machine to build Spark=
.
>
> On my little MacBook air, this cuts the build time from 14 minutes to 10.=
5
> minutes. A machine with more cores should see a bigger improvement.
>
> Note though that the docs mark this as experimental, so I wouldn=E2=80=99=
t change
> our reference build to use this. But it should be useful, for example, in
> Jenkins or when working locally.
>
> Nick
> =E2=80=8B
>

--001a11c3234c3d476d050e60d8e5--

From dev-return-11492-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 01:01:01 2015
Return-Path: <dev-return-11492-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0875117C2C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 01:01:01 +0000 (UTC)
Received: (qmail 26987 invoked by uid 500); 6 Feb 2015 01:01:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26909 invoked by uid 500); 6 Feb 2015 01:00:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26897 invoked by uid 99); 6 Feb 2015 01:00:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:00:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:00:33 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so10326611obc.5
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 16:59:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Wt3GR7e2xIy9dGV+MX3W+qeLz9CA3NpEg73oyNigS2o=;
        b=nEXJhSUQT5xv0qbV7zi+gEVX/J1hh2B1b7CCftsNH9xt816iKy0kmvm3KvSREtyYQ7
         1yeRjYmiY+EMGYA7WDRLV5gmweHI5j6MoME1EiL61IS2hpxSEN2sCIJ4ht78UaQG9IY/
         2/fxBjMUysvJ/qwMDL8LG/g+YfDLS5rii5QYEinI/+8IIi6YkEUlp0x3kJC4g0Zca/Lr
         FxvjUPEre+CSj3YlJ4DcPRfmL0WCIgYAI3vKYEeAh93hn4wPQIscNBXRdKG9dB0GYHQA
         psQHJxUpgS3auwIAZvilSSSLhoBBqfImddlCACGQ5wMHYEXqESiGejba/anavkbr4OLv
         34Tg==
MIME-Version: 1.0
X-Received: by 10.202.196.137 with SMTP id u131mr653426oif.78.1423184387066;
 Thu, 05 Feb 2015 16:59:47 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Thu, 5 Feb 2015 16:59:46 -0800 (PST)
In-Reply-To: <CAO4-Pq-JnNkWnLGzStEZAohh6B8AAJ4DPHs1wiHHgf=qMCYu=w@mail.gmail.com>
References: <CAOhmDzcCob-Rn61mm-vzCJky-gH9JhyUpOmdWCL8yWN-yHFf6w@mail.gmail.com>
	<CAO4-Pq-JnNkWnLGzStEZAohh6B8AAJ4DPHs1wiHHgf=qMCYu=w@mail.gmail.com>
Date: Thu, 5 Feb 2015 16:59:46 -0800
Message-ID: <CABPQxsufWqw_X=-+ox14J=1=h0Q3JUb08XP1B015v0MfZpZ6eg@mail.gmail.com>
Subject: Re: PSA: Maven supports parallel builds
From: Patrick Wendell <pwendell@gmail.com>
To: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, Spark dev list <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I've done this in the past, but back when I wasn't using Zinc it
didn't make a big difference. It's worth doing this in our jenkins
environment though.

- Patrick

On Thu, Feb 5, 2015 at 4:52 PM, Dirceu Semighini Filho
<dirceu.semighini@gmail.com> wrote:
> Thanks Nicholas, I didn't knew this.
>
> 2015-02-05 22:16 GMT-02:00 Nicholas Chammas <nicholas.chammas@gmail.com>:
>
>> Y'all may already know this, but I haven't seen it mentioned anywhere in
>> our docs on here and it's a pretty easy win.
>>
>> Maven supports parallel builds
>> <
>> https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3
>> >
>> with the -T command line option.
>>
>> For example:
>>
>> ./build/mvn -T 1C -Dhadoop.version=1.2.1 -DskipTests clean package
>>
>> This will have Maven use 1 thread per core on your machine to build Spark.
>>
>> On my little MacBook air, this cuts the build time from 14 minutes to 10.5
>> minutes. A machine with more cores should see a bigger improvement.
>>
>> Note though that the docs mark this as experimental, so I wouldn't change
>> our reference build to use this. But it should be useful, for example, in
>> Jenkins or when working locally.
>>
>> Nick
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11493-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 01:01:30 2015
Return-Path: <dev-return-11493-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 85EC617C30
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 01:01:30 +0000 (UTC)
Received: (qmail 29015 invoked by uid 500); 6 Feb 2015 01:01:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28941 invoked by uid 500); 6 Feb 2015 01:01:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28930 invoked by uid 99); 6 Feb 2015 01:01:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:01:29 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:01:24 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id 31EBF337;
	Fri,  6 Feb 2015 01:00:33 +0000 (UTC)
Received: from G9W3612.americas.hpqcorp.net (16.216.186.47) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Fri, 6 Feb 2015 00:59:30 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G9W3612.americas.hpqcorp.net ([16.216.186.47]) with mapi id 14.03.0169.001;
 Fri, 6 Feb 2015 00:59:29 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZA
Date: Fri, 6 Feb 2015 00:59:29 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
In-Reply-To: <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2G4W3292americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2G4W3292americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2G4W3292americas_--

From dev-return-11494-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 01:04:04 2015
Return-Path: <dev-return-11494-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8E3BC17C3B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 01:04:04 +0000 (UTC)
Received: (qmail 34689 invoked by uid 500); 6 Feb 2015 01:04:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34615 invoked by uid 500); 6 Feb 2015 01:04:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34604 invoked by uid 99); 6 Feb 2015 01:04:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:04:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.174 as permitted sender)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:03:58 +0000
Received: by mail-lb0-f174.google.com with SMTP id f15so13462954lbj.5
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 17:02:07 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=oAPwIeZoiCZkcckJTZ0Mm3zQdAiX/Rt8ctK8e5pfi3k=;
        b=iW5UhJ5lT0whbA39d+yvGRaDOvomVze0+QsaEB73ne4eS+b9wYq6iPWOxYtk50DzY6
         UtvRPy9QPR1GnIdXJtcwsx+sGWjOMohQjVqeTpdMspX6/HDLs4i4gBX7ZL9r7JM7Kv5H
         BJIjmlgtAIZwyfWphqaexxULbk9r7nS8iWit6JpiX+sIUiNg++yp/ouTLgnmuHWK38Pi
         agdwAdFeWTP0Z5hw6xzOg+7biEJmvU4NzOyyxjwa1iwJCD8tmxv62016B8QylPJ00h8X
         Vgk6LD1Rbh47RYg2CTRRVnj7At0Alj7PUAO9FsJJESUQtpJnqnOSPAjdNoq6HRE9JJiW
         AH7Q==
X-Gm-Message-State: ALoCoQlwewNlqwQDDtARdFLqqCXQ4WYGVoQ8geDhlvBOSNwDqGjUg4zpf3F8/tksJaKwOx66S63R
X-Received: by 10.153.4.5 with SMTP id ca5mr656741lad.28.1423184527106; Thu,
 05 Feb 2015 17:02:07 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.185.97 with HTTP; Thu, 5 Feb 2015 17:01:46 -0800 (PST)
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 5 Feb 2015 17:01:46 -0800
Message-ID: <CACdU-dTR7tG6_saH6DZs-16bj_Njj-Vp8tbaPmbHwHe4k7wAAg@mail.gmail.com>
Subject: spark 1.3 sbt build seems to be broken
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134163c303d3b050e60f820
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134163c303d3b050e60f820
Content-Type: text/plain; charset=UTF-8

https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/

we're seeing java OOMs and heap space errors:
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop1.0,label=centos/19/console
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop1.0,label=centos/18/console

memory leak?  i checked the systems (ganglia + logging in and 'free -g')
and there's nothing going on there.

20 is building right now:
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/20/console

--001a1134163c303d3b050e60f820--

From dev-return-11495-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 01:10:36 2015
Return-Path: <dev-return-11495-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5289E17C77
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 01:10:36 +0000 (UTC)
Received: (qmail 65448 invoked by uid 500); 6 Feb 2015 01:10:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65376 invoked by uid 500); 6 Feb 2015 01:10:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65365 invoked by uid 99); 6 Feb 2015 01:10:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:10:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:10:31 +0000
Received: by mail-lb0-f172.google.com with SMTP id l4so13518825lbv.3
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 17:07:54 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=yRPOnNkuH/yUN+ePK0oyuX24JycyIYFkS1DQ90/8E7c=;
        b=X9FxSt3esb9RLI4V4YB2VZ9BhLq4B1TsHQYUxfHAogiTR39/cN/xac1hVZInE+PZFG
         Wi/xyrbsbgcuDLLFRYNmvxJQcSdWmjygflriwL1eoHWYP9jswpem4O88Q+TAPKNxG11L
         NWVXPXia7r2WBJqATIH6eXphu+EM42qQPbnEnit4Qwn2sQWZbiaY7S0pqq4sAFp/BZMc
         xdU7Mw1YLmSW5GgnloiyVgQGW4pSXZ4ZpjhiDDeSioqhDFmDQAv10M0+MZXb2Fc5sTPr
         iDqFGS64bVBA99DMVsd/+isumXpeId1+TKuenzHwBjwuznwfrJUg/M5hrh8AH8tI+Dgt
         RXEA==
X-Gm-Message-State: ALoCoQmvUNEzA8KGroJDjbrDs0a+BVUFTMdFWMNe05eNLJWHQFnknusGDQIixkyRK21kquFFYVr4
X-Received: by 10.112.98.202 with SMTP id ek10mr640845lbb.30.1423184874421;
 Thu, 05 Feb 2015 17:07:54 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.185.97 with HTTP; Thu, 5 Feb 2015 17:07:34 -0800 (PST)
In-Reply-To: <CACdU-dTR7tG6_saH6DZs-16bj_Njj-Vp8tbaPmbHwHe4k7wAAg@mail.gmail.com>
References: <CACdU-dTR7tG6_saH6DZs-16bj_Njj-Vp8tbaPmbHwHe4k7wAAg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 5 Feb 2015 17:07:34 -0800
Message-ID: <CACdU-dRizS_DFCa0uLJby5zL948LH_cOx91XpMT9QK0K32u5RA@mail.gmail.com>
Subject: Re: spark 1.3 sbt build seems to be broken
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11347600e3d42a050e610c43
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11347600e3d42a050e610c43
Content-Type: text/plain; charset=UTF-8

here's the hash of the breaking commit:

Started on Feb 5, 2015 12:01:01 PM
Using strategy: Default
[poll] Last Built Revision: Revision
de112a2096a2b84ce2cac112f12b50b5068d6c35
(refs/remotes/origin/branch-1.3)
 > git ls-remote -h https://github.com/apache/spark.git branch-1.3 # timeout=10
[poll] Latest remote head revision is: fba2dc663a644cfe76a744b5cace93e9d6646a25
Done. Took 2.5 sec
Changes found


from:  https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/18/pollingLog/


On Thu, Feb 5, 2015 at 5:01 PM, shane knapp <sknapp@berkeley.edu> wrote:

> https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/
>
> we're seeing java OOMs and heap space errors:
>
> https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop1.0,label=centos/19/console
>
> https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/AMPLAB_JENKINS_BUILD_PROFILE=hadoop1.0,label=centos/18/console
>
> memory leak?  i checked the systems (ganglia + logging in and 'free -g')
> and there's nothing going on there.
>
> 20 is building right now:
> https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.3-SBT/20/console
>

--001a11347600e3d42a050e610c43--

From dev-return-11496-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 01:31:48 2015
Return-Path: <dev-return-11496-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 01A7B17CF2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 01:31:48 +0000 (UTC)
Received: (qmail 7780 invoked by uid 500); 6 Feb 2015 01:31:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7707 invoked by uid 500); 6 Feb 2015 01:31:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7696 invoked by uid 99); 6 Feb 2015 01:31:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:31:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 01:31:21 +0000
Received: by mail-ig0-f172.google.com with SMTP id l13so3777231iga.5
        for <dev@spark.apache.org>; Thu, 05 Feb 2015 17:29:29 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=MRlP7K4k4k9P5U6uEiSBIKJSMRYr+i6CmvZZAK/IsBA=;
        b=VIwoJ2sGWXhlVQ9DOa+PXZqimxYjX/GtmWM1lNpmS3680GWW+ER4O8icKBxuxgz75a
         f98FqsIpx7iYsBOxAMW/3ODj20v328UCv7+tHZYoiyK6zJF8HAQSE5P/vjkIfmeHNOX7
         VVsAZYEy9tzQdI2wPfdXD+K9rqUlsT2VCTOrs2a/0S6hARySHKa3rHBfWjsG2HmBUKG5
         QGbEw44cLgrruvW5rcAai3o6HphmdngBBeCv86c6jPCTSiEeJ4AS6p+Q8YQ31aCF+qnO
         9I4wshnMRTFLCKYpQwI6GrrF/zAbkMibphy/reAfx2d8IF95pU347sE/SCI8qy1N6Mo0
         rc9Q==
X-Gm-Message-State: ALoCoQlUolIWrirx72dInxN7SGVNZj0m8Pnmfi0P7EDPcVkifjZaFLpf/pnao67ka+iL8xei0X4C
MIME-Version: 1.0
X-Received: by 10.42.61.12 with SMTP id s12mr10468543ich.94.1423186169200;
 Thu, 05 Feb 2015 17:29:29 -0800 (PST)
Received: by 10.36.66.15 with HTTP; Thu, 5 Feb 2015 17:29:29 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
Date: Thu, 5 Feb 2015 17:29:29 -0800
Message-ID: <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Joseph Bradley <joseph@databricks.com>
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: "Evan R. Sparks" <evan.sparks@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf301cc0aa109283050e615aa3
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf301cc0aa109283050e615aa3
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Alexander,

Using GPUs with Spark would be very exciting.  Small comment: Concerning
your question earlier about keeping data stored on the GPU rather than
having to move it between main memory and GPU memory on each iteration, I
would guess this would be critical to getting good performance.  If you
could do multiple local iterations before aggregating results, then the
cost of data movement to the GPU could be amortized (and I believe that is
done in practice).  Having Spark be aware of the GPU and using it as
another part of memory sounds like a much bigger undertaking.

Joseph

On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>
>
>
>

--20cf301cc0aa109283050e615aa3--

From dev-return-11497-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 11:41:25 2015
Return-Path: <dev-return-11497-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8EEC217D10
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 11:41:25 +0000 (UTC)
Received: (qmail 51135 invoked by uid 500); 6 Feb 2015 11:41:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51048 invoked by uid 500); 6 Feb 2015 11:41:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51030 invoked by uid 99); 6 Feb 2015 11:41:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 11:41:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 11:41:18 +0000
Received: by mail-qg0-f53.google.com with SMTP id f51so10663014qge.12
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 03:39:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=Nf0HDKyhpDP2UewS0MF6epfVw8LFxGV/trc2qCyKTn4=;
        b=VlyC4kXgIW6LpvNsacx0zKtMln6IE4ZtadjBw+J6ghjQ64sTOUqXOgyA22an5DHZ3A
         ObAaMdCbrjqYcFnN376K6wHKRXYDaZyAbnu+A4Yu8Jzs/Xasja6qXD7JXPI4iHyKZ1kW
         u8nywssryBWEy7vuXEcTh6ULXcaBgbfyP+qVV8jFrGAZwCyYLp8AE7LJ8hokF7HP4DzB
         JmS/x+B4POYDO0xcsUzANHyeSKkDY8CQ4PWUKNgAgJwfIYNGNzU9mYP6csfMKcGjSCV/
         ZUDJi6mJVzpQkujD8ThivZ5j+nqsVSugs2umQ8YCu8V4NkFde9W2OorAWnHN6+KVrkia
         P89A==
X-Received: by 10.140.102.82 with SMTP id v76mr6870303qge.32.1423222767515;
 Fri, 06 Feb 2015 03:39:27 -0800 (PST)
MIME-Version: 1.0
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Date: Fri, 06 Feb 2015 11:39:27 +0000
Message-ID: <CAJOb8bsgJ7LwYhCuxO67Xmga8R=27XcN00HYM3wcccuLu9r_Tw@mail.gmail.com>
Subject: Data source API | sizeInBytes should be to *Scan
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16a907e7cea050e69dfef
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16a907e7cea050e69dfef
Content-Type: text/plain; charset=UTF-8

Hi Spark SQL committers

I have started experimenting with data sources API and I was wondering if
it makes sense to move the method sizeInBytes from BaseRelation to Scan
interfaces. This is because that a relation may be able to leverage filter
push down to estimate size potentially making a very large relation
broadcast-able. Thoughts?

Aniket

--001a11c16a907e7cea050e69dfef--

From dev-return-11498-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 14:46:12 2015
Return-Path: <dev-return-11498-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3BC12175DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 14:46:12 +0000 (UTC)
Received: (qmail 81766 invoked by uid 500); 6 Feb 2015 14:46:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81689 invoked by uid 500); 6 Feb 2015 14:46:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81678 invoked by uid 99); 6 Feb 2015 14:46:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 14:46:10 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 14:46:02 +0000
Received: by mail-we0-f172.google.com with SMTP id x3so8559513wes.3
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 06:45:42 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=uYlz1W3wGMil9kI56V3nCZ9/Cz/+Imf4rPjSy8dFzKg=;
        b=dQOk83jUINlyypA3uc2v+lgzxGly5AAD5F6tfBWW5l2kbPplvD4qiowp8ht0dttP1O
         LJ+N8vSl+8y7M9Ubk07WB1eY4Oxvm+A+1TpVCTLoupgUruNmqWukfaZguUcWfiQgMk+S
         /u3RL8u9z51G9BOAwJ9NQ9iDBfnaFZkXhPRpefo64VKzOMMpQBiVNmnN5bvQLbdwVrvL
         3363EpmmleO8pQtm70UPPXF2grof4vF5HboEe6ZF9lhRqA9TLr5qKC37YdUugiBQBv9j
         tWkLFqEMTnVPH3jL++96nIsuQvqnX518Xnf61hjkwSLHVC1AFpV0IljBoFNTF6QnJIqd
         dTgw==
X-Gm-Message-State: ALoCoQn5tM4BMLQWotfce+J7m0OwrUBk1uyVXUgLYigax6zuZduveos8lXN8MQT79kb3VBlCAD8C
X-Received: by 10.180.19.228 with SMTP id i4mr4062768wie.13.1423233941924;
 Fri, 06 Feb 2015 06:45:41 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Fri, 6 Feb 2015 06:45:20 -0800 (PST)
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 6 Feb 2015 08:45:20 -0600
Message-ID: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
Subject: Improving metadata in Spark JIRA
To: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I've wasted no time in wielding the commit bit to complete a number of
small, uncontroversial changes. I wouldn't commit anything that didn't
already appear to have review, consensus and little risk, but please
let me know if anything looked a little too bold, so I can calibrate.


Anyway, I'd like to continue some small house-cleaning by improving
the state of JIRA's metadata, in order to let it give us a little
clearer view on what's happening in the project:

a. Add Component to every (open) issue that's missing one
b. Review all Critical / Blocker issues to de-escalate ones that seem
obviously neither
c. Correct open issues that list a Fix version that has already been released
d. Close all issues Resolved for a release that has already been released

The problem with doing so is that it will create a tremendous amount
of email to the list, like, several hundred. It's possible to make
bulk changes and suppress e-mail though, which could be done for all
but b.

Better to suppress the emails when making such changes? or just not
bother on some of these?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11499-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 17:52:59 2015
Return-Path: <dev-return-11499-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 06BE917E81
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 17:52:59 +0000 (UTC)
Received: (qmail 37537 invoked by uid 500); 6 Feb 2015 17:52:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37469 invoked by uid 500); 6 Feb 2015 17:52:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37455 invoked by uid 99); 6 Feb 2015 17:52:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 17:52:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 17:52:32 +0000
Received: by iecat20 with SMTP id at20so3095939iec.3
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 09:50:15 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=dwq6+HyKnShfRuAEF/G006f5RHnx7YPShlfIMmyAz4Y=;
        b=WkDNuXq2olQeQjWJ1Vj3wV1TZ5mloAAN8H8hOLX1y8eqyZFycfvFpF2BqJW6ydKsYP
         6ydzVAWPjM6N6o5/ZGSXPIpWnp141J3h0ZldgCuQ3TFOE7Lp2wPfbHSvVJ3V9X2cFkXL
         voBGtAP/ENnoIDNri4qIiBen6JGBz5q9v09lUN7qS2fvU7JshBq587/2TtHUA7GcXwzQ
         Gbt6SnVSkHN/AZai4pXHFfX1mvK66ur4aw1UhmdwER15c4gcP2wvD2kNGT+WmfQq+huc
         qk7MA1G+ItDyrwmmk+bARqDD5XnkpglpqXNxfvNpVrOJkkHEdhyEiY/HQ7YSCPXdcXq2
         Rfwg==
X-Gm-Message-State: ALoCoQnxd/zHeSCF4Jx7lWDSV4hxkjm+tqO15G5zuePHFF+6fJ7YQXkJtdunnxQNHtSdQYySOT67
MIME-Version: 1.0
X-Received: by 10.107.138.195 with SMTP id c64mr6464557ioj.47.1423245015470;
 Fri, 06 Feb 2015 09:50:15 -0800 (PST)
Received: by 10.36.28.208 with HTTP; Fri, 6 Feb 2015 09:50:15 -0800 (PST)
In-Reply-To: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
Date: Fri, 6 Feb 2015 09:50:15 -0800
Message-ID: <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113ea122936e4a050e6f0daf
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ea122936e4a050e6f0daf
Content-Type: text/plain; charset=UTF-8

JIRA updates don't go to this list, they go to issues@spark.apache.org.  I
don't think many are signed up for that list, and those that are probably
have a flood of emails anyway.

So I'd definitely be in favor of any JIRA cleanup that you're up for.

-Sandy

On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:

> I've wasted no time in wielding the commit bit to complete a number of
> small, uncontroversial changes. I wouldn't commit anything that didn't
> already appear to have review, consensus and little risk, but please
> let me know if anything looked a little too bold, so I can calibrate.
>
>
> Anyway, I'd like to continue some small house-cleaning by improving
> the state of JIRA's metadata, in order to let it give us a little
> clearer view on what's happening in the project:
>
> a. Add Component to every (open) issue that's missing one
> b. Review all Critical / Blocker issues to de-escalate ones that seem
> obviously neither
> c. Correct open issues that list a Fix version that has already been
> released
> d. Close all issues Resolved for a release that has already been released
>
> The problem with doing so is that it will create a tremendous amount
> of email to the list, like, several hundred. It's possible to make
> bulk changes and suppress e-mail though, which could be done for all
> but b.
>
> Better to suppress the emails when making such changes? or just not
> bother on some of these?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113ea122936e4a050e6f0daf--

From dev-return-11500-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 18:53:28 2015
Return-Path: <dev-return-11500-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E6F861732B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 18:53:28 +0000 (UTC)
Received: (qmail 99230 invoked by uid 500); 6 Feb 2015 18:53:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99154 invoked by uid 500); 6 Feb 2015 18:53:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99137 invoked by uid 99); 6 Feb 2015 18:53:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 18:53:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 18:53:01 +0000
Received: by mail-ig0-f175.google.com with SMTP id hn18so4759475igb.2
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 10:50:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=p/BDb/c/6DiX6czM+wgYxgC8iHvqskZR2y3ZUAe9pf8=;
        b=aGXzB5c6IFIxgxl0yBxDuQ1eZAoNJMWRIag85nRuDz6wSok0IAZ3Sry5NfIwFTAdMy
         BiPUR1mTsBQSd/MNwHI7q8ZhQeFvrcFtypK5O8JlIKILleBpwrx9AqOs9+Vr1pQ3SO4B
         RfVCjj8RUvHoX+68ygz7Audo2rPPM9DPw4tJ4W+tmTt1WIO85QUoVZs6sVPLqyRMjb9R
         yD+hZnXSG7AxNuWLGgMEppv1LCs/QPOrhgChVpWd4a/qnG/gt1bVDtUunp06nF9kZ75O
         Q5RpHENGf6xhu/K5p5k90Do7gAVLGLAprAoLUjQrDLldz+uWXmtK+k4NMJwlJdnzrVut
         pWmA==
X-Received: by 10.50.112.98 with SMTP id ip2mr3393025igb.15.1423248644046;
 Fri, 06 Feb 2015 10:50:44 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 06 Feb 2015 18:50:43 +0000
Message-ID: <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b414162db4009050e6fe5d6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b414162db4009050e6fe5d6
Content-Type: text/plain; charset=UTF-8

+9000 on cleaning up JIRA.

Thank you Sean for laying out some specific things to tackle. I will assist
with this.

Regarding email, I think Sandy is right. I only get JIRA email for issues
I'm watching.

Nick

On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com> wrote:

> JIRA updates don't go to this list, they go to issues@spark.apache.org.  I
> don't think many are signed up for that list, and those that are probably
> have a flood of emails anyway.
>
> So I'd definitely be in favor of any JIRA cleanup that you're up for.
>
> -Sandy
>
> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
>
> > I've wasted no time in wielding the commit bit to complete a number of
> > small, uncontroversial changes. I wouldn't commit anything that didn't
> > already appear to have review, consensus and little risk, but please
> > let me know if anything looked a little too bold, so I can calibrate.
> >
> >
> > Anyway, I'd like to continue some small house-cleaning by improving
> > the state of JIRA's metadata, in order to let it give us a little
> > clearer view on what's happening in the project:
> >
> > a. Add Component to every (open) issue that's missing one
> > b. Review all Critical / Blocker issues to de-escalate ones that seem
> > obviously neither
> > c. Correct open issues that list a Fix version that has already been
> > released
> > d. Close all issues Resolved for a release that has already been released
> >
> > The problem with doing so is that it will create a tremendous amount
> > of email to the list, like, several hundred. It's possible to make
> > bulk changes and suppress e-mail though, which could be done for all
> > but b.
> >
> > Better to suppress the emails when making such changes? or just not
> > bother on some of these?
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--047d7b414162db4009050e6fe5d6--

From dev-return-11501-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 19:55:56 2015
Return-Path: <dev-return-11501-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 915971760B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 19:55:56 +0000 (UTC)
Received: (qmail 89059 invoked by uid 500); 6 Feb 2015 19:55:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88982 invoked by uid 500); 6 Feb 2015 19:55:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88965 invoked by uid 99); 6 Feb 2015 19:55:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 19:55:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.169 as permitted sender)
Received: from [209.85.213.169] (HELO mail-ig0-f169.google.com) (209.85.213.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 19:55:29 +0000
Received: by mail-ig0-f169.google.com with SMTP id hl2so4854974igb.0
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 11:53:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=oj3CzHme6wbBYOq1pUs5QPshtIbZQrBZ+jNc8Ejo1gw=;
        b=vXQjK4r3oBn2Hi4ZtTPyqQdinvyUSKGtffMYvVNa3S3UwI5P/3LYP42eQfYjJtoqr2
         gsTBQfodu75oFY+n8kZDvpktFFwD+mm2EUzdXLwqv3lxkK62orODm7xTQHHvKt7tE7/h
         MX6F6xB6737v0wpyQ1unto0Z72AQnC3JYFaDkxbCfVWwmfu6tjQmEe/7kOII8gJHFe2b
         WA3UOWUIoLYpsfFoGtXox5XZR6zmxJENhwjjkyocD1yBvuf53iMOnDMP2o0x4Us1WPIG
         VyGc1SPuURkv5AtXORSjR/hEUCa+JtB62nwht7uZN3kJZISJcyjX0e0Tj0PSz5uQeNWy
         HBtA==
X-Received: by 10.107.161.75 with SMTP id k72mr12827406ioe.46.1423252392880;
 Fri, 06 Feb 2015 11:53:12 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com> <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 06 Feb 2015 19:53:12 +0000
Message-ID: <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114100b04db0c0050e70c5d2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114100b04db0c0050e70c5d2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Do we need some new components to be added to the JIRA project?

Like:

   -

   scheduler
    -

   YARN
    - spark-submit
   - =E2=80=A6?

Nick
=E2=80=8B

On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> +9000 on cleaning up JIRA.
>
> Thank you Sean for laying out some specific things to tackle. I will
> assist with this.
>
> Regarding email, I think Sandy is right. I only get JIRA email for issues
> I'm watching.
>
> Nick
>
> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com>
> wrote:
>
>> JIRA updates don't go to this list, they go to issues@spark.apache.org.
>> I
>> don't think many are signed up for that list, and those that are probabl=
y
>> have a flood of emails anyway.
>>
>> So I'd definitely be in favor of any JIRA cleanup that you're up for.
>>
>> -Sandy
>>
>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> > I've wasted no time in wielding the commit bit to complete a number of
>> > small, uncontroversial changes. I wouldn't commit anything that didn't
>> > already appear to have review, consensus and little risk, but please
>> > let me know if anything looked a little too bold, so I can calibrate.
>> >
>> >
>> > Anyway, I'd like to continue some small house-cleaning by improving
>> > the state of JIRA's metadata, in order to let it give us a little
>> > clearer view on what's happening in the project:
>> >
>> > a. Add Component to every (open) issue that's missing one
>> > b. Review all Critical / Blocker issues to de-escalate ones that seem
>> > obviously neither
>> > c. Correct open issues that list a Fix version that has already been
>> > released
>> > d. Close all issues Resolved for a release that has already been
>> released
>> >
>> > The problem with doing so is that it will create a tremendous amount
>> > of email to the list, like, several hundred. It's possible to make
>> > bulk changes and suppress e-mail though, which could be done for all
>> > but b.
>> >
>> > Better to suppress the emails when making such changes? or just not
>> > bother on some of these?
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>
>

--001a114100b04db0c0050e70c5d2--

From dev-return-11502-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 19:59:28 2015
Return-Path: <dev-return-11502-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D6E41764D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 19:59:28 +0000 (UTC)
Received: (qmail 99817 invoked by uid 500); 6 Feb 2015 19:59:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99736 invoked by uid 500); 6 Feb 2015 19:59:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99720 invoked by uid 99); 6 Feb 2015 19:59:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 19:59:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hshreedharan@cloudera.com designates 209.85.216.169 as permitted sender)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 19:58:59 +0000
Received: by mail-qc0-f169.google.com with SMTP id b13so13745925qcw.0
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 11:56:42 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:in-reply-to
         :references:from:to:cc:subject:content-type;
        bh=FihXK+GPT6r6BkKVDfhgwh1MkgT5SDu++xlQEaKzFig=;
        b=eN88pXZ7/fsUQxZtAm+iAzjK+xCDK3TPux0hpfc5WV60XR0I3agN+WQQZp/rDcgkxM
         J5K4VyrRhO+8fDtnuWFL/JM0CnVbmtLeO89DkDRnSy7Qa7gTquGuvQ+IlpoN0rGTE01L
         sdShJAn5chcSHCNWjjSPoiCeDPBp4H6bT+2CoxFYrAoQvx7Wy6MSe3YGP+XpXnmgN8Rl
         nqGZwnG39C4ZkUSPzokB1nBFgIeMBTLEybg71bcl84nRb3rYJRgJUyVC43DGhuhWgKbl
         wsYrp/z6tAnOMKvl2TthoPL7xaeypbNIDpu6f9+i9xnOpLgRVm0qrE0TyCit5IGnMWOK
         xNOw==
X-Gm-Message-State: ALoCoQlbCka9ETJjcn2DYEMu8Nt9FYcpe8PK7a9hNp6UqbXIBQY4Pu+cwv8y39D2AUMzlKbTCtlw
X-Received: by 10.224.134.202 with SMTP id k10mr12007827qat.32.1423252602410;
        Fri, 06 Feb 2015 11:56:42 -0800 (PST)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id e13sm3541806qaw.8.2015.02.06.11.56.41
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 06 Feb 2015 11:56:41 -0800 (PST)
Date: Fri, 06 Feb 2015 11:56:41 -0800 (PST)
X-Google-Original-Date: Fri, 06 Feb 2015 19:56:41 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1423252601386.8c2fa6c9@Nodemailer>
In-Reply-To: <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
References: <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
X-Orchestra-Oid: 0995A028-511C-40EF-B5B3-2F150D0365D4
X-Orchestra-Sig: 31853a361fc1819dd6640771ecc27d5e50301c0a
X-Orchestra-Thrid: TEB56D109-7104-46FE-9747-57A7D6EE5D69_1492368989676794112
X-Orchestra-Thrid-Sig: b48ad088e4c8c8e00f468dda206c4905f16dcfbe
X-Orchestra-Account: bd0073b468d275222a8813c950c174a8c234f65c
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: "Nicholas Chammas" <nicholas.chammas@gmail.com>
Cc: "Sandy Ryza" <sandy.ryza@cloudera.com>, "Sean Owen"
 <sowen@cloudera.com>, "dev" <dev@spark.apache.org>
Subject: Re: Improving metadata in Spark JIRA
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1423252601764"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1423252601764
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

+1. Jira cleanup would be good. Please let me know if I can help in some =
way!




Thanks,=C2=A0Hari

On Fri, Feb 6, 2015 at 11:56 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:

> Do we need some new components to be added to the JIRA project=3F
> Like:
>    -
>    scheduler
>     -
>    YARN
>     - spark-submit
>    - =E2=80=A6=3F
> Nick
> =E2=80=8B
> On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>> +9000 on cleaning up JIRA.
>>
>> Thank you Sean for laying out some specific things to tackle. I will
>> assist with this.
>>
>> Regarding email, I think Sandy is right. I only get JIRA email for =
issues
>> I'm watching.
>>
>> Nick
>>
>> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com>
>> wrote:
>>
>>> JIRA updates don't go to this list, they go to issues@spark.apache.org.=

>>> I
>>> don't think many are signed up for that list, and those that are =
probably
>>> have a flood of emails anyway.
>>>
>>> So I'd definitely be in favor of any JIRA cleanup that you're up for.
>>>
>>> -Sandy
>>>
>>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
>>>
>>> > I've wasted no time in wielding the commit bit to complete a number =
of
>>> > small, uncontroversial changes. I wouldn't commit anything that =
didn't
>>> > already appear to have review, consensus and little risk, but please
>>> > let me know if anything looked a little too bold, so I can calibrate.=

>>> >
>>> >
>>> > Anyway, I'd like to continue some small house-cleaning by improving
>>> > the state of JIRA's metadata, in order to let it give us a little
>>> > clearer view on what's happening in the project:
>>> >
>>> > a. Add Component to every (open) issue that's missing one
>>> > b. Review all Critical / Blocker issues to de-escalate ones that =
seem
>>> > obviously neither
>>> > c. Correct open issues that list a Fix version that has already been
>>> > released
>>> > d. Close all issues Resolved for a release that has already been
>>> released
>>> >
>>> > The problem with doing so is that it will create a tremendous amount
>>> > of email to the list, like, several hundred. It's possible to make
>>> > bulk changes and suppress e-mail though, which could be done for all
>>> > but b.
>>> >
>>> > Better to suppress the emails when making such changes=3F or just =
not
>>> > bother on some of these=3F
>>> >
>>> > ---------------------------------------------------------------------=

>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>> >
>>>
>>
------Nodemailer-0.5.0-?=_1-1423252601764--

From dev-return-11503-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb  6 20:27:51 2015
Return-Path: <dev-return-11503-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 01AC3177D1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  6 Feb 2015 20:27:51 +0000 (UTC)
Received: (qmail 79923 invoked by uid 500); 6 Feb 2015 20:27:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79848 invoked by uid 500); 6 Feb 2015 20:27:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79799 invoked by uid 99); 6 Feb 2015 20:27:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 20:27:46 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 20:27:42 +0000
Received: by mail-oi0-f47.google.com with SMTP id a141so13862380oig.6
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 12:25:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=tmVirAFKKZqzNJ4gdri5gUaVGWB9GvScYpLpjfy60q4=;
        b=Bz8Irb9IYSFg/tT4pdfDU/cwQXLDce13UJ7WU1e6Q5eTsenNQqb8d7UqDT4ZU2HVB0
         DcmsY5RR/gqiIh6IP04TUMAIhmoSzyUFwdj3cYFYDZhPbKQbrzGIbfPmlEfwzOzhksk5
         KapRPV56wr+AY/IiyUan4rJ0SmLqApwA5GWH2a09cKM8E94bEuefyCtZkiO0JiDaDUa0
         uTdCiDD3LdWWnq8eYPto4/CNnhdzPWlVU95Sjj+zsK0+fVxaoRPIWzjSU9HA9IAfGDMP
         Dbs0YRI0jhVLTl4BkAgw7Zx7tugyyfvFoQ0ZOShA35ompqfnedgHg/w4S/XusLF9jAmH
         YwCg==
MIME-Version: 1.0
X-Received: by 10.182.215.163 with SMTP id oj3mr3801358obc.49.1423254351300;
 Fri, 06 Feb 2015 12:25:51 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Fri, 6 Feb 2015 12:25:51 -0800 (PST)
In-Reply-To: <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
	<CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
	<CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
	<CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
Date: Fri, 6 Feb 2015 12:25:51 -0800
Message-ID: <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Per Nick's suggestion I added two components:

1. Spark Submit
2. Spark Scheduler

I figured I would just add these since if we decide later we don't
want them, we can simply merge them into Spark Core.

On Fri, Feb 6, 2015 at 11:53 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> Do we need some new components to be added to the JIRA project?
>
> Like:
>
>    -
>
>    scheduler
>     -
>
>    YARN
>     - spark-submit
>    - ...?
>
> Nick
>
>
> On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> +9000 on cleaning up JIRA.
>>
>> Thank you Sean for laying out some specific things to tackle. I will
>> assist with this.
>>
>> Regarding email, I think Sandy is right. I only get JIRA email for issues
>> I'm watching.
>>
>> Nick
>>
>> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com>
>> wrote:
>>
>>> JIRA updates don't go to this list, they go to issues@spark.apache.org.
>>> I
>>> don't think many are signed up for that list, and those that are probably
>>> have a flood of emails anyway.
>>>
>>> So I'd definitely be in favor of any JIRA cleanup that you're up for.
>>>
>>> -Sandy
>>>
>>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
>>>
>>> > I've wasted no time in wielding the commit bit to complete a number of
>>> > small, uncontroversial changes. I wouldn't commit anything that didn't
>>> > already appear to have review, consensus and little risk, but please
>>> > let me know if anything looked a little too bold, so I can calibrate.
>>> >
>>> >
>>> > Anyway, I'd like to continue some small house-cleaning by improving
>>> > the state of JIRA's metadata, in order to let it give us a little
>>> > clearer view on what's happening in the project:
>>> >
>>> > a. Add Component to every (open) issue that's missing one
>>> > b. Review all Critical / Blocker issues to de-escalate ones that seem
>>> > obviously neither
>>> > c. Correct open issues that list a Fix version that has already been
>>> > released
>>> > d. Close all issues Resolved for a release that has already been
>>> released
>>> >
>>> > The problem with doing so is that it will create a tremendous amount
>>> > of email to the list, like, several hundred. It's possible to make
>>> > bulk changes and suppress e-mail though, which could be done for all
>>> > but b.
>>> >
>>> > Better to suppress the emails when making such changes? or just not
>>> > bother on some of these?
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>> >
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11504-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:16:43 2015
Return-Path: <dev-return-11504-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90368174C3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:16:43 +0000 (UTC)
Received: (qmail 40894 invoked by uid 500); 8 Feb 2015 09:16:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40816 invoked by uid 500); 8 Feb 2015 09:16:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12658 invoked by uid 99); 8 Feb 2015 02:10:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 02:10:02 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 02:09:58 +0000
Received: by pdjy10 with SMTP id y10so562406pdj.6
        for <dev@spark.apache.org>; Sat, 07 Feb 2015 18:09:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=IQZoGQ3B/uCuR623Ji7wvuerqAXh+/3MvLjeyQL4/5Y=;
        b=J1c99111GnDewOaAJp4e2eoiSgl9wVLmEc7ptbgNaUmXSZhqt2ng7VqyIyee3gvvJb
         BwX72SwaIzvPTS6TGmiFky53miScmlDJj6sjzXxwfMg3boP/4igaTIR5a6shQKeRF9Ho
         1UGi5G6xz6N1THNrMcRQOWcfHiXmESQSno986Y8VXGeKFrnnqnpALphE1Mrm+yv2faDC
         clB99wIL5tVCZyLEzZASkk2E9QpGZvnynz3MQfQno+2kuFEQtcnv6JO/GjGbxJOQBRuc
         Adwyn4A4MWE6lVMznpQajwEibG7EnnqYb1gWjRKw51OthmSH3VYkNX0e5I+15shQISZX
         t90w==
X-Received: by 10.70.88.79 with SMTP id be15mr17594273pdb.126.1423361377971;
        Sat, 07 Feb 2015 18:09:37 -0800 (PST)
Received: from josh-db-windows.att.net ([2602:306:cdd1:b10:c1fd:a5ca:175f:72cb])
        by mx.google.com with ESMTPSA id mm9sm12151198pbc.76.2015.02.07.18.09.24
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 07 Feb 2015 18:09:28 -0800 (PST)
Date: Sat, 7 Feb 2015 18:09:23 -0800
From: Josh Rosen <rosenville@gmail.com>
To: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Patrick
 Wendell <pwendell@gmail.com>
Message-ID: <etPan.54d6c553.6b8b4567.111@josh-db-windows.att.net>
In-Reply-To: <CABPQxsuBD5rVsQPT4NiQQG3LDkqRf5-6yv_YnmwsO5_RZJvTRw@mail.gmail.com>
References: <CABPQxsuBD5rVsQPT4NiQQG3LDkqRf5-6yv_YnmwsO5_RZJvTRw@mail.gmail.com>
Subject: Re: Temporary jenkins issue
X-Mailer: Airmail (286)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54d6c553_327b23c6_111"
X-Virus-Checked: Checked by ClamAV on apache.org

--54d6c553_327b23c6_111
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

It looks like this may be fixed soon in Jenkins:

https://issues.jenkins-ci.org/browse/JENKINS-25446
https://github.com/jenkinsci/flaky-test-handler-plugin/pull/1

On February 2, 2015 at 7:38:19 PM, Patrick Wendell (pwendell@gmail.com) wrote:

Hey All, 

I made a change to the Jenkins configuration that caused most builds 
to fail (attempting to enable a new plugin), I've reverted the change 
effective about 10 minutes ago. 

If you've seen recent build failures like below, this was caused by 
that change. Sorry about that. 

==== 
ERROR: Publisher 
com.google.jenkins.flakyTestHandler.plugin.JUnitFlakyResultArchiver 
aborted due to exception 
java.lang.NoSuchMethodError: 
hudson.model.AbstractBuild.getTestResultAction()Lhudson/tasks/test/AbstractTestResultAction; 
at com.google.jenkins.flakyTestHandler.plugin.FlakyTestResultAction.<init>(FlakyTestResultAction.java:78) 
at com.google.jenkins.flakyTestHandler.plugin.JUnitFlakyResultArchiver.perform(JUnitFlakyResultArchiver.java:89) 
at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:20) 
at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:770) 
at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:734) 
at hudson.model.Build$BuildExecution.post2(Build.java:183) 
at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:683) 
at hudson.model.Run.execute(Run.java:1784) 
at hudson.matrix.MatrixRun.run(MatrixRun.java:146) 
at hudson.model.ResourceController.execute(ResourceController.java:89) 
at hudson.model.Executor.run(Executor.java:240) 
==== 

- Patrick 

--------------------------------------------------------------------- 
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org 
For additional commands, e-mail: dev-help@spark.apache.org 


--54d6c553_327b23c6_111--


From dev-return-11505-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:19:49 2015
Return-Path: <dev-return-11505-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D14D17512
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:19:49 +0000 (UTC)
Received: (qmail 62793 invoked by uid 500); 8 Feb 2015 09:19:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62727 invoked by uid 500); 8 Feb 2015 09:19:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28955 invoked by uid 99); 7 Feb 2015 01:13:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:13:08 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.43 as permitted sender)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:12:42 +0000
Received: by mail-oi0-f43.google.com with SMTP id z81so14782226oif.2
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 17:12:40 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ozTgokztirAuykHD5KOTCL3xAWjb8BdK65DlsmsvvSw=;
        b=kFEOx65YRcp/g910Hv2yNgHI1dIGInJdGReN8JdwEy1opXqsOp4WMfGd0RH+qum/pr
         RaV+ya450g+RJb6RWnYZ9P9ZNqZGvoDBpR9ahH0sXbaSkIT9Ip7MXOK8/RvyzdFNcjs1
         sTuNhyVBONeE3hAMFDqie72JG2N7GE9aa+Zaxjj+IdxOkDDi1Y9OQo5TmclvteIULUyU
         Us8TJtf1rGJ1MhjA5H39AqjMb1Yrc9LBtkNc3k4tveM0IGIvRhVkO5xjsKSGLoRjZV2U
         zWD5aUrvDKtX4ErLEZwN1quuruy/+zaqQ4K+OWk4oioaEcGhX8V/ZfbxkrDVqU0SlWtE
         WAtw==
MIME-Version: 1.0
X-Received: by 10.202.80.198 with SMTP id e189mr2863993oib.75.1423271560567;
 Fri, 06 Feb 2015 17:12:40 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Fri, 6 Feb 2015 17:12:40 -0800 (PST)
In-Reply-To: <4308883B-6E54-416C-B0B2-FE2D6653AAEA@gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
	<4308883B-6E54-416C-B0B2-FE2D6653AAEA@gmail.com>
Date: Fri, 6 Feb 2015 17:12:40 -0800
Message-ID: <CABPQxss_UYqe8x+0Kesti+=SjXEPPKcJrrfYMYFDia2ggXuYyg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
From: Patrick Wendell <pwendell@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I'll add a +1 as well.

On Fri, Feb 6, 2015 at 2:38 PM, Matei Zaharia <matei.zaharia@gmail.com> wrote:
> +1
>
> Tested on Mac OS X.
>
> Matei
>
>
>> On Feb 2, 2015, at 8:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> Please vote on releasing the following candidate as Apache Spark version 1.2.1!
>>
>> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97
>>
>> The release files, including signatures, digests, etc. can be found at:
>> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
>>
>> Release artifacts are signed with the following key:
>> https://people.apache.org/keys/committer/pwendell.asc
>>
>> The staging repository for this release can be found at:
>> https://repository.apache.org/content/repositories/orgapachespark-1065/
>>
>> The documentation corresponding to this release can be found at:
>> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
>>
>> Changes from rc2:
>> A single patch fixing a windows issue.
>>
>> Please vote on releasing this package as Apache Spark 1.2.1!
>>
>> The vote is open until Friday, February 06, at 05:00 UTC and passes
>> if a majority of at least 3 +1 PMC votes are cast.
>>
>> [ ] +1 Release this package as Apache Spark 1.2.1
>> [ ] -1 Do not release this package because ...
>>
>> For a list of fixes in this release, see http://s.apache.org/Mpn.
>>
>> To learn more about Apache Spark, please see
>> http://spark.apache.org/
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11506-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:22:50 2015
Return-Path: <dev-return-11506-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 765FA17573
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:22:50 +0000 (UTC)
Received: (qmail 81869 invoked by uid 500); 8 Feb 2015 09:22:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81799 invoked by uid 500); 8 Feb 2015 09:22:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97279 invoked by uid 99); 6 Feb 2015 23:21:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 23:21:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.192.42] (HELO mail-qg0-f42.google.com) (209.85.192.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 23:21:04 +0000
Received: by mail-qg0-f42.google.com with SMTP id z107so7883057qgd.1
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 15:20:23 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=rLwqBfPZyZDVMzFQzgyZ7wS75iZw7ngPMFJkph2nO38=;
        b=KLgnCF2+eeOzZrXBDjYgq5l4A2SJsU6px8JrKrUzcQ1dWhds5RneHIITFRp9YbpClp
         WtLIc+IZ6twk8TrhfZpsVLB/iL19nOwsmshbJwF2k/deMGBiPQJyHzIWaaTXf6xjTk6P
         ewNCioVJlkPd+OYzgI+xvsa8nHP3sdUJzlce878c0XgqGWUOO3HSwrV4ziLGXJfK1G46
         UebTiVgopW1HEWmFiYWfgp+JbmhzNbWbmklyndDrXILOOoLGqKE/uJsH65AKq1v6BSCi
         xY1FQdiBQw7lvXDq05jfkFvSkXwfKrNyE0BzKsgPERIui9xWSCnXYFBD9Cx8BaMutukt
         8Z9w==
X-Gm-Message-State: ALoCoQmaYbASTFmptTwA4vX1JSZDrFztoAIhgfxukekE44CtHfW+R86broA1rsi64l83LFBeLqG6
X-Received: by 10.224.43.72 with SMTP id v8mr458540qae.30.1423264823212; Fri,
 06 Feb 2015 15:20:23 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Fri, 6 Feb 2015 15:20:03 -0800 (PST)
In-Reply-To: <CAJOb8bsgJ7LwYhCuxO67Xmga8R=27XcN00HYM3wcccuLu9r_Tw@mail.gmail.com>
References: <CAJOb8bsgJ7LwYhCuxO67Xmga8R=27XcN00HYM3wcccuLu9r_Tw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Fri, 6 Feb 2015 15:20:03 -0800
Message-ID: <CAPh_B=a1a+tp71QKTeevipqvxMm7uFRqY_OYtH5TqFZoE63k=Q@mail.gmail.com>
Subject: Re: Data source API | sizeInBytes should be to *Scan
To: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc9f703591f9050e73aa8d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc9f703591f9050e73aa8d
Content-Type: text/plain; charset=UTF-8

We thought about this today after seeing this email. I actually built a
patch for this (adding filter/column to data source stat estimation), but
ultimately dropped it due to the potential problems the change the cause.

The main problem I see is that column pruning/predicate pushdowns are
advisory, i.e. the data source might or might not apply those filters.

Without significantly complicating the data source API, it is hard for the
optimizer (and future cardinality estimation) to know whether the
filter/column pushdowns are advisory, and whether to incorporate that in
cardinality estimation.

Imagine this scenario: a data source applies a filter and estimates the
filter's selectivity is 0.1, then the data set is reduced to 10% of the
size. Catalyst's own cardinality estimation estimates the filter
selectivity to 0.1 again, and thus the estimated data size is now 1% of the
original data size, lowering than some threshold. Catalyst decides to
broadcast the table. The actual table size is actually 10x the size.





On Fri, Feb 6, 2015 at 3:39 AM, Aniket Bhatnagar <aniket.bhatnagar@gmail.com
> wrote:

> Hi Spark SQL committers
>
> I have started experimenting with data sources API and I was wondering if
> it makes sense to move the method sizeInBytes from BaseRelation to Scan
> interfaces. This is because that a relation may be able to leverage filter
> push down to estimate size potentially making a very large relation
> broadcast-able. Thoughts?
>
> Aniket
>

--047d7bdc9f703591f9050e73aa8d--

From dev-return-11507-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:23:17 2015
Return-Path: <dev-return-11507-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 91CD017580
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:23:17 +0000 (UTC)
Received: (qmail 84941 invoked by uid 500); 8 Feb 2015 09:23:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84867 invoked by uid 500); 8 Feb 2015 09:23:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33264 invoked by uid 99); 7 Feb 2015 01:16:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:16:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.178 as permitted sender)
Received: from [209.85.214.178] (HELO mail-ob0-f178.google.com) (209.85.214.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:16:11 +0000
Received: by mail-ob0-f178.google.com with SMTP id uz6so16655412obc.9
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 17:14:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:cc:content-type;
        bh=PyGbIZmpa7rTc3B5ShHXveoaBDRBOgoH6PWVo2ZVziw=;
        b=U+jBR4Dz4ysjBP+cG78bO8j76W24CutVEqNlrUAnUR1G4cz3rkRSuyBhT8MggzIdIb
         MiT4FOxa5R8XN89nDcVrCSskVPcAkme2VPFFAZz3PbvN5hQkb1cC40xG3jCy/tQEUaZk
         aFFJOtPPTo68HhLGqk1cv8xVaeS9682gCCOXTWqUKe6tPetW5RpBgvx3uH47LFW5SH7C
         9PY3rh4cNp0S5Mh66rApaV862xfTzCZ2fChMW0aAFc4V5eRknTPEC09Yq+GcSZqYyBVQ
         01xdnEYrrimDqvgXai8peRj53aqqgS1fM4VbMAmuuu0dWRVFLKWA3fgiLlGy1njkl+U1
         ZkfQ==
MIME-Version: 1.0
X-Received: by 10.202.45.9 with SMTP id t9mr4237542oit.100.1423271679336; Fri,
 06 Feb 2015 17:14:39 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Fri, 6 Feb 2015 17:14:39 -0800 (PST)
Date: Fri, 6 Feb 2015 17:14:39 -0800
Message-ID: <CABPQxsvV56yVern8U_9iGR2Sg+iZgDg=CS-3YwDv2y4c7GV4pQ@mail.gmail.com>
Subject: [RESULT] [VOTE] Release Apache Spark 1.2.1 (RC3)
From: Patrick Wendell <pwendell@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

This vote passes with 5 +1 votes (3 binding) and no 0 or -1 votes.

+1 Votes:
Krishna Sankar
Sean Owen*
Chip Senkbeil
Matei Zaharia*
Patrick Wendell*

0 Votes:
(none)

-1 Votes:
(none)

On Fri, Feb 6, 2015 at 5:12 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> I'll add a +1 as well.
>
> On Fri, Feb 6, 2015 at 2:38 PM, Matei Zaharia <matei.zaharia@gmail.com> wrote:
>> +1
>>
>> Tested on Mac OS X.
>>
>> Matei
>>
>>
>>> On Feb 2, 2015, at 8:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>>
>>> Please vote on releasing the following candidate as Apache Spark version 1.2.1!
>>>
>>> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
>>> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=b6eaf77d4332bfb0a698849b1f5f917d20d70e97
>>>
>>> The release files, including signatures, digests, etc. can be found at:
>>> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
>>>
>>> Release artifacts are signed with the following key:
>>> https://people.apache.org/keys/committer/pwendell.asc
>>>
>>> The staging repository for this release can be found at:
>>> https://repository.apache.org/content/repositories/orgapachespark-1065/
>>>
>>> The documentation corresponding to this release can be found at:
>>> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
>>>
>>> Changes from rc2:
>>> A single patch fixing a windows issue.
>>>
>>> Please vote on releasing this package as Apache Spark 1.2.1!
>>>
>>> The vote is open until Friday, February 06, at 05:00 UTC and passes
>>> if a majority of at least 3 +1 PMC votes are cast.
>>>
>>> [ ] +1 Release this package as Apache Spark 1.2.1
>>> [ ] -1 Do not release this package because ...
>>>
>>> For a list of fixes in this release, see http://s.apache.org/Mpn.
>>>
>>> To learn more about Apache Spark, please see
>>> http://spark.apache.org/
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11508-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:25:17 2015
Return-Path: <dev-return-11508-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B39EE175B8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:25:17 +0000 (UTC)
Received: (qmail 97909 invoked by uid 500); 8 Feb 2015 09:25:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97804 invoked by uid 500); 8 Feb 2015 09:25:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88325 invoked by uid 99); 8 Feb 2015 01:23:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:23:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.41 as permitted sender)
Received: from [209.85.218.41] (HELO mail-oi0-f41.google.com) (209.85.218.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:23:11 +0000
Received: by mail-oi0-f41.google.com with SMTP id z81so17630557oif.0
        for <dev@spark.apache.org>; Sat, 07 Feb 2015 17:23:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ob/H4E2iuEADkxnGF50nUtIRSDVicjPBkMpV9QZjHHY=;
        b=R9KS5v+tm0Nh//xsMfyXGqH77Bgj+ZBR1ZlFCjLgsict6Hs0bTygRR38IQzjzaci/Z
         0ZvsfWlpluS9RTQ2l/nrPhVFJVNXaPMDmEHRfjfsM4jMt5tIk1Q0qSK58fLvBNSz33kK
         SXq6/5KpFs6NDwg2E5pb3HlKKg4y02LKM5U6wXxgmGdsMUYOSis6v1KOzfFs91zA+qvp
         2J8HsuSIqTdONkhYW4ZrcUUJ5NFNLwaPzvc3mHXAfli+8uk6v67urIHD1YF7XEzHKaqv
         hz/PocYhfrQJMLLa55dccH5gavsPOsooPAh+rvQLVPMPWWUNwOESHPU2vf6J0H1YhjKF
         cOaw==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr47263oit.100.1423358589959;
 Sat, 07 Feb 2015 17:23:09 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Sat, 7 Feb 2015 17:23:09 -0800 (PST)
In-Reply-To: <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
	<CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
	<CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
	<CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
	<CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
	<CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
Date: Sat, 7 Feb 2015 17:23:09 -0800
Message-ID: <CABPQxstsv+3ZjVzx+obeACw5pspwERmzV6RjM1ZsBs-m5g9bBg@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I think we already have a YARN component.

https://issues.apache.org/jira/issues/?jql=project%20%3D%20SPARK%20AND%20component%20%3D%20YARN

I don't think JIRA allows it to be mandatory, but if it does, that
would be useful.

On Sat, Feb 7, 2015 at 5:08 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> By the way, isn't it possible to make the "Component" field mandatory when
> people open new issues? Shouldn't we do that?
>
> Btw Patrick, don't we need a YARN component? I think our JIRA components
> should roughly match the components on the PR dashboard.
>
> Nick
>
> On Fri Feb 06 2015 at 12:25:52 PM Patrick Wendell <pwendell@gmail.com>
> wrote:
>>
>> Per Nick's suggestion I added two components:
>>
>> 1. Spark Submit
>> 2. Spark Scheduler
>>
>> I figured I would just add these since if we decide later we don't
>> want them, we can simply merge them into Spark Core.
>>
>> On Fri, Feb 6, 2015 at 11:53 AM, Nicholas Chammas
>> <nicholas.chammas@gmail.com> wrote:
>> > Do we need some new components to be added to the JIRA project?
>> >
>> > Like:
>> >
>> >    -
>> >
>> >    scheduler
>> >     -
>> >
>> >    YARN
>> >     - spark-submit
>> >    - ...?
>> >
>> > Nick
>> >
>> >
>> > On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
>> > nicholas.chammas@gmail.com> wrote:
>> >
>> >> +9000 on cleaning up JIRA.
>> >>
>> >> Thank you Sean for laying out some specific things to tackle. I will
>> >> assist with this.
>> >>
>> >> Regarding email, I think Sandy is right. I only get JIRA email for
>> >> issues
>> >> I'm watching.
>> >>
>> >> Nick
>> >>
>> >> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com>
>> >> wrote:
>> >>
>> >>> JIRA updates don't go to this list, they go to
>> >>> issues@spark.apache.org.
>> >>> I
>> >>> don't think many are signed up for that list, and those that are
>> >>> probably
>> >>> have a flood of emails anyway.
>> >>>
>> >>> So I'd definitely be in favor of any JIRA cleanup that you're up for.
>> >>>
>> >>> -Sandy
>> >>>
>> >>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
>> >>>
>> >>> > I've wasted no time in wielding the commit bit to complete a number
>> >>> > of
>> >>> > small, uncontroversial changes. I wouldn't commit anything that
>> >>> > didn't
>> >>> > already appear to have review, consensus and little risk, but please
>> >>> > let me know if anything looked a little too bold, so I can
>> >>> > calibrate.
>> >>> >
>> >>> >
>> >>> > Anyway, I'd like to continue some small house-cleaning by improving
>> >>> > the state of JIRA's metadata, in order to let it give us a little
>> >>> > clearer view on what's happening in the project:
>> >>> >
>> >>> > a. Add Component to every (open) issue that's missing one
>> >>> > b. Review all Critical / Blocker issues to de-escalate ones that
>> >>> > seem
>> >>> > obviously neither
>> >>> > c. Correct open issues that list a Fix version that has already been
>> >>> > released
>> >>> > d. Close all issues Resolved for a release that has already been
>> >>> released
>> >>> >
>> >>> > The problem with doing so is that it will create a tremendous amount
>> >>> > of email to the list, like, several hundred. It's possible to make
>> >>> > bulk changes and suppress e-mail though, which could be done for all
>> >>> > but b.
>> >>> >
>> >>> > Better to suppress the emails when making such changes? or just not
>> >>> > bother on some of these?
>> >>> >
>> >>> >
>> >>> > ---------------------------------------------------------------------
>> >>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >>> >
>> >>> >
>> >>>
>> >>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11509-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:27:56 2015
Return-Path: <dev-return-11509-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4345B175FE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:27:56 +0000 (UTC)
Received: (qmail 17784 invoked by uid 500); 8 Feb 2015 09:27:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17709 invoked by uid 500); 8 Feb 2015 09:27:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37310 invoked by uid 99); 7 Feb 2015 01:21:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:21:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.172 as permitted sender)
Received: from [209.85.220.172] (HELO mail-vc0-f172.google.com) (209.85.220.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:20:50 +0000
Received: by mail-vc0-f172.google.com with SMTP id le20so6348339vcb.3
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 17:19:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=lyg3nQqA04yz6wEI8evS+mpQ7CuLm4FqmDlymn+DZkg=;
        b=E5pfZ6dRFbmf2mPfGuFNPxz/8IHRLa8wNpPCDw7Wx3n6j56RgcN0papKVU9hPxLdzr
         LYgU4xhu4Q4qnw4g4hNuFx4ZIVcLTcYHu8eP3/HO6eW981tPGzrW6XOgdlShUORYo5Ro
         ULutroMDAFc9E2Z279IVWcwr4gMuevG0gvqmEt3trNuKNLbUg1IZBtXOkOOwiDvCvSa9
         087hucZ4U5ztQsk49rKHo9VO8rJzoifKLneJnEeAM8UiGPBWjA87/n5yF8q0YtdqgtFT
         gPCoGOM2mrCitOQvtbJE2ft9L4Nv34lJWhUXZWiss57jy/r4wLGsbpliekbnB8tm//PP
         WKpA==
X-Received: by 10.52.250.6 with SMTP id yy6mr3568283vdc.45.1423271958364; Fri,
 06 Feb 2015 17:19:18 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Fri, 6 Feb 2015 17:18:57 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Fri, 6 Feb 2015 17:18:57 -0800
Message-ID: <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136744e7f4c01050e755392
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136744e7f4c01050e755392
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Getting breeze to pick up the right blas library is critical for
performance. I recommend using OpenBLAS (or MKL, if you already have it).
It might make sense to force BIDMat to use the same underlying BLAS library
as well.

On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

> Hi Evan, Joseph
>
> I did few matrix multiplication test and BIDMat seems to be ~10x faster
> than netlib-java+breeze (sorry for weird table formatting):
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
> Breeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
> Linux, Scala 2.11.
>
> Later I will make tests with Cuda. I need to install new Cuda version for
> this purpose.
>
> Do you have any ideas why breeze-netlib with native blas is so much slowe=
r
> than BIDMat MKL?
>
> Best regards, Alexander
>
> From: Joseph Bradley [mailto:joseph@databricks.com]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Hi Alexander,
>
> Using GPUs with Spark would be very exciting.  Small comment: Concerning
> your question earlier about keeping data stored on the GPU rather than
> having to move it between main memory and GPU memory on each iteration, I
> would guess this would be critical to getting good performance.  If you
> could do multiple local iterations before aggregating results, then the
> cost of data movement to the GPU could be amortized (and I believe that i=
s
> done in practice).  Having Spark be aware of the GPU and using it as
> another part of memory sounds like a much bigger undertaking.
>
> Joseph
>
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>
>
>
>

--001a1136744e7f4c01050e755392--

From dev-return-11510-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:33:18 2015
Return-Path: <dev-return-11510-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7080D1765D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:33:18 +0000 (UTC)
Received: (qmail 39515 invoked by uid 500); 8 Feb 2015 09:33:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39442 invoked by uid 500); 8 Feb 2015 09:33:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94420 invoked by uid 99); 8 Feb 2015 01:31:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:31:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:31:33 +0000
Received: by iecrp18 with SMTP id rp18so3071634iec.7
        for <dev@spark.apache.org>; Sat, 07 Feb 2015 17:29:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=dMSuLVqLIsoMgLFoQtgGJbQo6oDISyhTVSILNS2Sxu8=;
        b=RiCfsWeOdlerc5frfJWzkCYB0iO3vOVGa5efykjRUeJsXPgDkEgIuPVqfh5PzKA/NB
         hmnex//GZya6KsvsHdBFuvGh8WgL9wKLwAWDNFFZsgPz9hw3UD5U6Ex4heOl1kncFDgs
         vfclB4py02aYWks1iJdkQ1/auUWuNNUCwZHLs/fpEmij5GwdlsoY+SURCwlyw+QJRLYi
         GEZ716wWE0uVAAefteaYuy+HcUAnrjvJ7JK6hwN/xUk8eKBvbEca4S67D6Bhj7HL8ezp
         Ktp45QH4TEogFvwdE1V4I2kGQUTEf/xS9F1aDDSNGM1+LLL7CPTiz7r4xzQNq9SSue/C
         YaVg==
X-Received: by 10.50.112.98 with SMTP id ip2mr9673452igb.15.1423358983451;
 Sat, 07 Feb 2015 17:29:43 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
 <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
 <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
 <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
 <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com> <CABPQxstsv+3ZjVzx+obeACw5pspwERmzV6RjM1ZsBs-m5g9bBg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 08 Feb 2015 01:29:43 +0000
Message-ID: <CAOhmDzcVsF4K+V6fs8Z1HcbqbkyNz+6XaEyR8mEOZdDV-P+wEA@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Patrick Wendell <pwendell@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b41416298b8ed050e8996ea
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b41416298b8ed050e8996ea
Content-Type: text/plain; charset=UTF-8

Oh derp, missed the YARN component.

JIRA, does allow admins to make fields mandatory:
https://confluence.atlassian.com/display/JIRA/Specifying+Field+Behavior#SpecifyingFieldBehavior-Makingafieldrequiredoroptional

Nick

On Sat Feb 07 2015 at 5:23:10 PM Patrick Wendell <pwendell@gmail.com> wrote:

> I think we already have a YARN component.
>
> https://issues.apache.org/jira/issues/?jql=project%20%
> 3D%20SPARK%20AND%20component%20%3D%20YARN
>
> I don't think JIRA allows it to be mandatory, but if it does, that
> would be useful.
>
> On Sat, Feb 7, 2015 at 5:08 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > By the way, isn't it possible to make the "Component" field mandatory
> when
> > people open new issues? Shouldn't we do that?
> >
> > Btw Patrick, don't we need a YARN component? I think our JIRA components
> > should roughly match the components on the PR dashboard.
> >
> > Nick
> >
> > On Fri Feb 06 2015 at 12:25:52 PM Patrick Wendell <pwendell@gmail.com>
> > wrote:
> >>
> >> Per Nick's suggestion I added two components:
> >>
> >> 1. Spark Submit
> >> 2. Spark Scheduler
> >>
> >> I figured I would just add these since if we decide later we don't
> >> want them, we can simply merge them into Spark Core.
> >>
> >> On Fri, Feb 6, 2015 at 11:53 AM, Nicholas Chammas
> >> <nicholas.chammas@gmail.com> wrote:
> >> > Do we need some new components to be added to the JIRA project?
> >> >
> >> > Like:
> >> >
> >> >    -
> >> >
> >> >    scheduler
> >> >     -
> >> >
> >> >    YARN
> >> >     - spark-submit
> >> >    - ...?
> >> >
> >> > Nick
> >> >
> >> >
> >> > On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
> >> > nicholas.chammas@gmail.com> wrote:
> >> >
> >> >> +9000 on cleaning up JIRA.
> >> >>
> >> >> Thank you Sean for laying out some specific things to tackle. I will
> >> >> assist with this.
> >> >>
> >> >> Regarding email, I think Sandy is right. I only get JIRA email for
> >> >> issues
> >> >> I'm watching.
> >> >>
> >> >> Nick
> >> >>
> >> >> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com
> >
> >> >> wrote:
> >> >>
> >> >>> JIRA updates don't go to this list, they go to
> >> >>> issues@spark.apache.org.
> >> >>> I
> >> >>> don't think many are signed up for that list, and those that are
> >> >>> probably
> >> >>> have a flood of emails anyway.
> >> >>>
> >> >>> So I'd definitely be in favor of any JIRA cleanup that you're up
> for.
> >> >>>
> >> >>> -Sandy
> >> >>>
> >> >>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com>
> wrote:
> >> >>>
> >> >>> > I've wasted no time in wielding the commit bit to complete a
> number
> >> >>> > of
> >> >>> > small, uncontroversial changes. I wouldn't commit anything that
> >> >>> > didn't
> >> >>> > already appear to have review, consensus and little risk, but
> please
> >> >>> > let me know if anything looked a little too bold, so I can
> >> >>> > calibrate.
> >> >>> >
> >> >>> >
> >> >>> > Anyway, I'd like to continue some small house-cleaning by
> improving
> >> >>> > the state of JIRA's metadata, in order to let it give us a little
> >> >>> > clearer view on what's happening in the project:
> >> >>> >
> >> >>> > a. Add Component to every (open) issue that's missing one
> >> >>> > b. Review all Critical / Blocker issues to de-escalate ones that
> >> >>> > seem
> >> >>> > obviously neither
> >> >>> > c. Correct open issues that list a Fix version that has already
> been
> >> >>> > released
> >> >>> > d. Close all issues Resolved for a release that has already been
> >> >>> released
> >> >>> >
> >> >>> > The problem with doing so is that it will create a tremendous
> amount
> >> >>> > of email to the list, like, several hundred. It's possible to make
> >> >>> > bulk changes and suppress e-mail though, which could be done for
> all
> >> >>> > but b.
> >> >>> >
> >> >>> > Better to suppress the emails when making such changes? or just
> not
> >> >>> > bother on some of these?
> >> >>> >
> >> >>> >
> >> >>> > ------------------------------------------------------------
> ---------
> >> >>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> >>> > For additional commands, e-mail: dev-help@spark.apache.org
> >> >>> >
> >> >>> >
> >> >>>
> >> >>
>

--047d7b41416298b8ed050e8996ea--

From dev-return-11511-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:37:21 2015
Return-Path: <dev-return-11511-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9CCCB176CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:37:21 +0000 (UTC)
Received: (qmail 65742 invoked by uid 500); 8 Feb 2015 09:37:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65666 invoked by uid 500); 8 Feb 2015 09:37:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44028 invoked by uid 99); 7 Feb 2015 01:30:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:30:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.176 as permitted sender)
Received: from [209.85.220.176] (HELO mail-vc0-f176.google.com) (209.85.220.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:30:16 +0000
Received: by mail-vc0-f176.google.com with SMTP id kv7so6352865vcb.7
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 17:29:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=PC9Rc3iAE+QcnW2WH9zvXt+RvtP2j513xGSGhkBn6oQ=;
        b=WxRnx/xzyN44bFyiifp45WnMIohE9OV2Wvonci60kSrM+UMptMrw9D1XacPmNRyO7P
         ew/aoqEsABDUgnHjrTW6yc//fBzSgqie7gCR4eDVY9Qo5qIQAi0M+CPkePeFCTy/oNp+
         plwKY0fibM5SkcNjGobZC4kiK0TQ3AZ+ht5s4LGvVKuAIxA7DgLrMbihBP8o3dVWb8at
         Unj8BI1edujjQB2a0AvvfwvllulNt6ywNi+bii9hM64u11gcK5gUIraEG2izAkbfqq9S
         m6ILwKAghzd8D3uQlObbRofKLLQx8paCnL3NavjapVyLW7GNVYcHXO8W+7oMuk0bE9sm
         UYog==
X-Received: by 10.220.17.144 with SMTP id s16mr4348503vca.10.1423272569639;
 Fri, 06 Feb 2015 17:29:29 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Fri, 6 Feb 2015 17:29:09 -0800 (PST)
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Fri, 6 Feb 2015 17:29:09 -0800
Message-ID: <CABjXkq47J2A0pN62UJpSE0xPQppN_js7WRg5dOQ7jykZ32BCVA@mail.gmail.com>
Subject: Spark SQL Window Functions
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3c76eee977e050e75777a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3c76eee977e050e75777a
Content-Type: text/plain; charset=UTF-8

Currently there's no standard way of handling time series data in Spark. We
were kicking around some ideas in the lab today and one thing that came up
was SQL Window Functions as a way to support them and query over time
series (do things like moving average, etc.)

These don't seem to be implemented in Spark SQL yet, but there's some
discussion on JIRA (https://issues.apache.org/jira/browse/SPARK-3587)
asking for them, and there have also been a couple of pull requests -
https://github.com/apache/spark/pull/3703 and
https://github.com/apache/spark/pull/2953.

Is any work currently underway here?

--001a11c3c76eee977e050e75777a--

From dev-return-11512-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:39:50 2015
Return-Path: <dev-return-11512-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEAAD17715
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:39:50 +0000 (UTC)
Received: (qmail 84243 invoked by uid 500); 8 Feb 2015 09:39:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84167 invoked by uid 500); 8 Feb 2015 09:39:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85153 invoked by uid 99); 7 Feb 2015 21:24:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 21:24:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 21:24:43 +0000
Received: by mail-qa0-f51.google.com with SMTP id f12so15908958qad.10
        for <dev@spark.apache.org>; Sat, 07 Feb 2015 13:23:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:cc:content-type;
        bh=IszkVX/nknt/LQYmGvk/f9rlC79MKO0kcOi/+HwY37U=;
        b=GJzWz0N2MkDYZ83sKSHCmjI0tHFprHYxF219h3UyrTt3sailobI9UH+3A8pnOmT/DA
         iW11+ZxKsd7E7gUDwnVE4mnDwF6L3TW0WXs1TY9lGPVOfMoEgJRtxotfpd6zC6b29Ks4
         Nx+a5SGX8uqMue/J/8Ei6stCpIkZUgf0vtulw2qoYwEnToAhLc8aoAQGLDPYGpplqatw
         U6jnGRcU+iy79KhFlkX+anLgmcY9BqAP2RMFr+xpKFYpFpGdWomcxPgdCJ8KDjaSOLhX
         VZjn+xdGS+uJC/6z0ok1jKakZjtiAVICbrQSUlhggyqFGKUSmGt66rfdV2q/XLzvmEn6
         qDAA==
X-Received: by 10.140.20.83 with SMTP id 77mr22073781qgi.40.1423344218366;
 Sat, 07 Feb 2015 13:23:38 -0800 (PST)
MIME-Version: 1.0
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Date: Sat, 07 Feb 2015 21:23:37 +0000
Message-ID: <CAJOb8bsKtZJrEX0PkmEW+ghthFt1AZTrfhd1FvKogkGTBRUJww@mail.gmail.com>
Subject: Re: Data source API | sizeInBytes should be to *Scan
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c12bca876a23050e8626ce
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c12bca876a23050e8626ce
Content-Type: text/plain; charset=UTF-8

Thanks for looking into this. If this true, isn't this an issue today? The
default implementation of sizeInBytes is 1 + broadcast threshold. So, if
catalyst's cardinality estimation estimates even a small filter
selectivity, it will result in broadcasting the relation. Therefore,
shouldn't the default be much higher than broadcast threshold?

Also, since the default implementation of sizeInBytes already exists in
BaseRelation, I am not sure why the same/similar default implementation
can't be provided with in *Scan specific sizeInBytes functions and have
Catalyst always trust the size returned by DataSourceAPI (with default
implementation being to never broadcast). Another thing that could be done
is have sizeInBytes return Option[Long] so that Catalyst explicitly knows
when DataSource was able to optimize the size. The reason why I would push
for sizeInBytes in *Scan interfaces is because at times the data source
implementation can more accurately predict the size output. For example,
DataSource implementations for MongoDB, ElasticSearch, Cassandra, etc can
easy use filter push downs to query the underlying storage to predict the
size. Such predictions will be more accurate than Catalyst's prediction.
Therefore, if its not a fundamental change in Catalyst, I would think this
makes sense.


Thanks,
Aniket


On Sat, Feb 7, 2015, 4:50 AM Reynold Xin <rxin@databricks.com> wrote:

> We thought about this today after seeing this email. I actually built a
> patch for this (adding filter/column to data source stat estimation), but
> ultimately dropped it due to the potential problems the change the cause.
>
> The main problem I see is that column pruning/predicate pushdowns are
> advisory, i.e. the data source might or might not apply those filters.
>
> Without significantly complicating the data source API, it is hard for the
> optimizer (and future cardinality estimation) to know whether the
> filter/column pushdowns are advisory, and whether to incorporate that in
> cardinality estimation.
>
> Imagine this scenario: a data source applies a filter and estimates the
> filter's selectivity is 0.1, then the data set is reduced to 10% of the
> size. Catalyst's own cardinality estimation estimates the filter
> selectivity to 0.1 again, and thus the estimated data size is now 1% of the
> original data size, lowering than some threshold. Catalyst decides to
> broadcast the table. The actual table size is actually 10x the size.
>
>
>
>
>
> On Fri, Feb 6, 2015 at 3:39 AM, Aniket Bhatnagar <
> aniket.bhatnagar@gmail.com> wrote:
>
>> Hi Spark SQL committers
>>
>> I have started experimenting with data sources API and I was wondering if
>> it makes sense to move the method sizeInBytes from BaseRelation to Scan
>> interfaces. This is because that a relation may be able to leverage filter
>> push down to estimate size potentially making a very large relation
>> broadcast-able. Thoughts?
>>
>> Aniket
>>
>
>

--001a11c12bca876a23050e8626ce--

From dev-return-11513-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:44:11 2015
Return-Path: <dev-return-11513-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A8E7D1776F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:44:11 +0000 (UTC)
Received: (qmail 22937 invoked by uid 500); 8 Feb 2015 09:44:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22858 invoked by uid 500); 8 Feb 2015 09:44:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49168 invoked by uid 99); 7 Feb 2015 01:37:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:37:30 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of sam.halliday@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:37:25 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id EC72A13209C6
	for <dev@spark.apache.org>; Fri,  6 Feb 2015 17:37:05 -0800 (PST)
Date: Fri, 6 Feb 2015 18:37:05 -0700 (MST)
From: fommil <sam.halliday@gmail.com>
To: dev@spark.apache.org
Message-ID: <1423273025027-10502.post@n3.nabble.com>
Subject: Pull Requests on github
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I'm the author of netlib-java and I noticed that the documentation in MLlib
was out of date and misleading, so I submitted a pull request on github
which will hopefully make things easier for everybody to understand the
benefits of system optimised natives and how to use them :-)

  https://github.com/apache/spark/pull/4448

However, it looks like there are a *lot* of outstanding PRs and that this is
just a mirror repository.

Will somebody please look at my PR and merge into the canonical source (and
let me know)?

Best regards,
Sam



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11514-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 09:53:59 2015
Return-Path: <dev-return-11514-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6B12117842
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 09:53:59 +0000 (UTC)
Received: (qmail 84625 invoked by uid 500); 8 Feb 2015 09:53:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84548 invoked by uid 500); 8 Feb 2015 09:53:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61211 invoked by uid 99); 7 Feb 2015 01:47:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:47:18 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 01:46:51 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id A44B03B9;
	Sat,  7 Feb 2015 01:46:18 +0000 (UTC)
Received: from G4W6300.americas.hpqcorp.net (16.210.26.225) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Sat, 7 Feb 2015 01:43:42 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G4W6300.americas.hpqcorp.net ([16.210.26.225]) with mapi id 14.03.0169.001;
 Sat, 7 Feb 2015 01:43:42 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0A=
Date: Sat, 7 Feb 2015 01:43:41 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
In-Reply-To: <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451G4W3292americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451G4W3292americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451G4W3292americas_--

From dev-return-11515-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:07:24 2015
Return-Path: <dev-return-11515-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A008A1798A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:07:24 +0000 (UTC)
Received: (qmail 79888 invoked by uid 500); 8 Feb 2015 10:07:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79813 invoked by uid 500); 8 Feb 2015 10:07:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73838 invoked by uid 99); 7 Feb 2015 02:00:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 02:00:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.170 as permitted sender)
Received: from [209.85.220.170] (HELO mail-vc0-f170.google.com) (209.85.220.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 02:00:17 +0000
Received: by mail-vc0-f170.google.com with SMTP id kv7so6400261vcb.1
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 17:58:45 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=8eLpYOibkWFEtLNHNgPLIkUBPISS8Gqmet8LmZkbsSo=;
        b=xweM/lKAILsND8fAqEdD38nEOH2i3+AXwHiGPZBRoL9BMp/R52zkT7W9B1EhLjraip
         C2FUNaMKMuu8JLxicnp4+l/N2V/j7Pp9hfekS4nWjAH+vBK47v1LKUmPh0kKmSviB1XT
         hIKyqswmXysY1AukyVrMeic/iXw2ZJYrm0E9SBVGVCvVPcZzUYIjQNm89AIg4p+3NMph
         UOmkgAw/hxE7+jVN+J0YN1D/ysM0N4ZVWntjp2ysv/XvaiZkDra+mm2HUAlXfBM463XY
         hzAa5pRB280Q2fAOWmu63INukBKUIJF35CbKISdGeRNzf0Hxd4/IiMQETgcR4Wtvmv/O
         gKsA==
X-Received: by 10.52.75.202 with SMTP id e10mr3580602vdw.73.1423274325434;
 Fri, 06 Feb 2015 17:58:45 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Fri, 6 Feb 2015 17:58:25 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Fri, 6 Feb 2015 17:58:25 -0800
Message-ID: <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf3071ca4495eb1f050e75e04b
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3071ca4495eb1f050e75e04b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I would build OpenBLAS yourself, since good BLAS performance comes from
getting cache sizes, etc. set up correctly for your particular hardware -
this is often a very tricky process (see, e.g. ATLAS), but we found that on
relatively modern Xeon chips, OpenBLAS builds quickly and yields
performance competitive with MKL.

To make sure the right library is getting used, you have to make sure it's
first on the search path - export LD_LIBRARY_PATH=3D/path/to/blas/library.s=
o
will do the trick here.

For some examples of getting netlib-java setup on an ec2 node and some
example benchmarking code we ran a while back, see:
https://github.com/shivaram/matrix-bench

In particular - build-openblas-ec2.sh shows you how to build the library
and set up symlinks correctly, and scala/run-netlib.sh shows you how to get
the path setup and get that library picked up by netlib-java.

In this way - you could probably get cuBLAS set up to be used by
netlib-java as well.

- Evan

On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

>  Evan, could you elaborate on how to force BIDMat and netlib-java to
> force loading the right blas? For netlib, I there are few JVM flags, such
> as -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so=
 I
> can force it to use Java implementation. Not sure I understand how to for=
ce
> use a specific blas (not specific wrapper for blas).
>
>
>
> Btw. I have installed openblas (yum install openblas), so I suppose that
> netlib is using it.
>
>
>
> *From:* Evan R. Sparks [mailto:evan.sparks@gmail.com]
> *Sent:* Friday, February 06, 2015 5:19 PM
> *To:* Ulanov, Alexander
> *Cc:* Joseph Bradley; dev@spark.apache.org
>
> *Subject:* Re: Using CUDA within Spark / boosting linear algebra
>
>
>
> Getting breeze to pick up the right blas library is critical for
> performance. I recommend using OpenBLAS (or MKL, if you already have it).
> It might make sense to force BIDMat to use the same underlying BLAS libra=
ry
> as well.
>
>
>
> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
>
> Hi Evan, Joseph
>
> I did few matrix multiplication test and BIDMat seems to be ~10x faster
> than netlib-java+breeze (sorry for weird table formatting):
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
> Breeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
> Linux, Scala 2.11.
>
> Later I will make tests with Cuda. I need to install new Cuda version for
> this purpose.
>
> Do you have any ideas why breeze-netlib with native blas is so much slowe=
r
> than BIDMat MKL?
>
> Best regards, Alexander
>
> From: Joseph Bradley [mailto:joseph@databricks.com]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org
>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Hi Alexander,
>
> Using GPUs with Spark would be very exciting.  Small comment: Concerning
> your question earlier about keeping data stored on the GPU rather than
> having to move it between main memory and GPU memory on each iteration, I
> would guess this would be critical to getting good performance.  If you
> could do multiple local iterations before aggregating results, then the
> cost of data movement to the GPU could be amortized (and I believe that i=
s
> done in practice).  Having Spark be aware of the GPU and using it as
> another part of memory sounds like a much bigger undertaking.
>
> Joseph
>
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>
>
>
>

--20cf3071ca4495eb1f050e75e04b--

From dev-return-11516-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:09:40 2015
Return-Path: <dev-return-11516-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 556CC179B7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:09:40 +0000 (UTC)
Received: (qmail 95084 invoked by uid 500); 8 Feb 2015 10:09:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95011 invoked by uid 500); 8 Feb 2015 10:09:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81077 invoked by uid 99); 8 Feb 2015 01:09:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:09:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.173 as permitted sender)
Received: from [209.85.213.173] (HELO mail-ig0-f173.google.com) (209.85.213.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 01:09:35 +0000
Received: by mail-ig0-f173.google.com with SMTP id a13so10101610igq.0
        for <dev@spark.apache.org>; Sat, 07 Feb 2015 17:08:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=Kx/bHU3ib9JZrKQmkTSk3aS2Nw1afNvVffehhftI1KM=;
        b=ifKe2JSWeVLXtG05jy/2pXzO+wBWPztWR8PyMOe1U/dIKV3XOfIp7v3NQwUTtrreBU
         Cwo41QMzCzOQeisw5sDj4smBiLhdM5yJiDnEVIBH3JvFwZqIYBWVySi8Sn/xnpTic3Wb
         tDBEoiiPByFi+4S9cBsW1wikVjUusnSszbX+VCykzloIaKYj8v8HQ3pxAoogXk6bBfsq
         ScLUK9AFtXfiNO9BE5pWz3CAyc8nlmXT7y1dY2HJ5ot5OU4M4/Wl0RuVdKxR4qQa4XyG
         szY/DJK/hqzVperyI2d2NvJ+o7XgjPEO6GCpvuyI/Jc/bv0wFsi68pEgKesvmxIUlTIA
         zh4g==
X-Received: by 10.42.88.9 with SMTP id a9mr19433607icm.34.1423357710125; Sat,
 07 Feb 2015 17:08:30 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
 <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
 <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com> <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 08 Feb 2015 01:08:29 +0000
Message-ID: <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Patrick Wendell <pwendell@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=90e6ba61486eb35470050e894a02
X-Virus-Checked: Checked by ClamAV on apache.org

--90e6ba61486eb35470050e894a02
Content-Type: text/plain; charset=UTF-8

By the way, isn't it possible to make the "Component" field mandatory when
people open new issues? Shouldn't we do that?

Btw Patrick, don't we need a YARN component? I think our JIRA components
should roughly match the components on the PR dashboard
<https://spark-prs.appspot.com/>.

Nick

On Fri Feb 06 2015 at 12:25:52 PM Patrick Wendell <pwendell@gmail.com>
wrote:

> Per Nick's suggestion I added two components:
>
> 1. Spark Submit
> 2. Spark Scheduler
>
> I figured I would just add these since if we decide later we don't
> want them, we can simply merge them into Spark Core.
>
> On Fri, Feb 6, 2015 at 11:53 AM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > Do we need some new components to be added to the JIRA project?
> >
> > Like:
> >
> >    -
> >
> >    scheduler
> >     -
> >
> >    YARN
> >     - spark-submit
> >    - ...?
> >
> > Nick
> >
> >
> > On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
> > nicholas.chammas@gmail.com> wrote:
> >
> >> +9000 on cleaning up JIRA.
> >>
> >> Thank you Sean for laying out some specific things to tackle. I will
> >> assist with this.
> >>
> >> Regarding email, I think Sandy is right. I only get JIRA email for
> issues
> >> I'm watching.
> >>
> >> Nick
> >>
> >> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <sandy.ryza@cloudera.com>
> >> wrote:
> >>
> >>> JIRA updates don't go to this list, they go to issues@spark.apache.org
> .
> >>> I
> >>> don't think many are signed up for that list, and those that are
> probably
> >>> have a flood of emails anyway.
> >>>
> >>> So I'd definitely be in favor of any JIRA cleanup that you're up for.
> >>>
> >>> -Sandy
> >>>
> >>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com> wrote:
> >>>
> >>> > I've wasted no time in wielding the commit bit to complete a number
> of
> >>> > small, uncontroversial changes. I wouldn't commit anything that
> didn't
> >>> > already appear to have review, consensus and little risk, but please
> >>> > let me know if anything looked a little too bold, so I can calibrate.
> >>> >
> >>> >
> >>> > Anyway, I'd like to continue some small house-cleaning by improving
> >>> > the state of JIRA's metadata, in order to let it give us a little
> >>> > clearer view on what's happening in the project:
> >>> >
> >>> > a. Add Component to every (open) issue that's missing one
> >>> > b. Review all Critical / Blocker issues to de-escalate ones that seem
> >>> > obviously neither
> >>> > c. Correct open issues that list a Fix version that has already been
> >>> > released
> >>> > d. Close all issues Resolved for a release that has already been
> >>> released
> >>> >
> >>> > The problem with doing so is that it will create a tremendous amount
> >>> > of email to the list, like, several hundred. It's possible to make
> >>> > bulk changes and suppress e-mail though, which could be done for all
> >>> > but b.
> >>> >
> >>> > Better to suppress the emails when making such changes? or just not
> >>> > bother on some of these?
> >>> >
> >>> > ------------------------------------------------------------
> ---------
> >>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>> > For additional commands, e-mail: dev-help@spark.apache.org
> >>> >
> >>> >
> >>>
> >>
>

--90e6ba61486eb35470050e894a02--

From dev-return-11517-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:39:09 2015
Return-Path: <dev-return-11517-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A01E17BE6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:39:09 +0000 (UTC)
Received: (qmail 33014 invoked by uid 500); 8 Feb 2015 10:39:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32938 invoked by uid 500); 8 Feb 2015 10:39:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89305 invoked by uid 99); 6 Feb 2015 22:39:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 22:39:08 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 22:39:01 +0000
Received: by pdjz10 with SMTP id z10so136440pdj.9
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 14:38:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=OlQ8ThsLW87dHfUEypBA5BAnTE6qa9JYR9zsfIhBHAk=;
        b=xQW6bNZW9O65lsM9welxgp6ixCNAsNj0p7rFgLlV6Cp4EnPfe/adg2BdB7fvAHLq/2
         NZHf7vpdR0Z7+cuUx16q98DniaghEgEjmV5bddDQoK0aQ0UamGWUkZ/b933h/1Dp3ZrF
         jkatXrUCl4BRPRN55HWcihxPBzq8qBNIriDYct3IZIU9H4KB7MBYikgiaX8PW0XoVDuq
         qaX2/vjOqCIvaw0wfyYqeWooVmXMRppKiHn0JiOdiZ8scMQxGECdq8ZXm3XKIPTX8TzY
         drVEHXbWFga8dvNUcaq6OqDUG64axn+p/TB8x9yDMEBsBr6yPuJXZ0JdFhcDj839e/oI
         KyAQ==
X-Received: by 10.67.15.194 with SMTP id fq2mr9188507pad.12.1423262321401;
        Fri, 06 Feb 2015 14:38:41 -0800 (PST)
Received: from [192.168.1.100] (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id gi3sm9018987pbc.83.2015.02.06.14.38.40
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 06 Feb 2015 14:38:40 -0800 (PST)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
Date: Fri, 6 Feb 2015 14:38:39 -0800
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <4308883B-6E54-416C-B0B2-FE2D6653AAEA@gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

+1

Tested on Mac OS X.

Matei


> On Feb 2, 2015, at 8:57 PM, Patrick Wendell <pwendell@gmail.com> =
wrote:
>=20
> Please vote on releasing the following candidate as Apache Spark =
version 1.2.1!
>=20
> The tag to be voted on is v1.2.1-rc3 (commit b6eaf77):
> =
https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Db6eaf=
77d4332bfb0a698849b1f5f917d20d70e97
>=20
> The release files, including signatures, digests, etc. can be found =
at:
> http://people.apache.org/~pwendell/spark-1.2.1-rc3/
>=20
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>=20
> The staging repository for this release can be found at:
> =
https://repository.apache.org/content/repositories/orgapachespark-1065/
>=20
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.2.1-rc3-docs/
>=20
> Changes from rc2:
> A single patch fixing a windows issue.
>=20
> Please vote on releasing this package as Apache Spark 1.2.1!
>=20
> The vote is open until Friday, February 06, at 05:00 UTC and passes
> if a majority of at least 3 +1 PMC votes are cast.
>=20
> [ ] +1 Release this package as Apache Spark 1.2.1
> [ ] -1 Do not release this package because ...
>=20
> For a list of fixes in this release, see http://s.apache.org/Mpn.
>=20
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11518-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:48:20 2015
Return-Path: <dev-return-11518-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3976817C65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:48:20 +0000 (UTC)
Received: (qmail 61536 invoked by uid 500); 8 Feb 2015 10:48:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61454 invoked by uid 500); 8 Feb 2015 10:48:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80690 invoked by uid 99); 7 Feb 2015 00:46:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 00:46:39 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.55] (HELO g4t3427.houston.hp.com) (15.201.208.55)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 00:46:34 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3427.houston.hp.com (Postfix) with ESMTPS id BBCDB169;
	Sat,  7 Feb 2015 00:44:43 +0000 (UTC)
Received: from G4W6304.americas.hpqcorp.net (16.210.26.229) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Sat, 7 Feb 2015 00:42:24 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G4W6304.americas.hpqcorp.net ([16.210.26.229]) with mapi id 14.03.0169.001;
 Sat, 7 Feb 2015 00:42:24 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: Joseph Bradley <joseph@databricks.com>
CC: "Evan R. Sparks" <evan.sparks@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08A==
Date: Sat, 7 Feb 2015 00:42:23 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
In-Reply-To: <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-11519-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:50:58 2015
Return-Path: <dev-return-11519-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8125117C7C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:50:58 +0000 (UTC)
Received: (qmail 68154 invoked by uid 500); 8 Feb 2015 10:50:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68081 invoked by uid 500); 8 Feb 2015 10:50:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92990 invoked by uid 99); 7 Feb 2015 06:24:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 06:24:16 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=SPF_FAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: encountered temporary error during SPF processing of domain of barneystinson@aliyun.com)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 07 Feb 2015 06:23:51 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 021E21323725
	for <dev@spark.apache.org>; Fri,  6 Feb 2015 22:23:24 -0800 (PST)
Date: Fri, 6 Feb 2015 23:23:23 -0700 (MST)
From: WangTaoTheTonic <barneystinson@aliyun.com>
To: dev@spark.apache.org
Message-ID: <1423290203904-10503.post@n3.nabble.com>
In-Reply-To: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
References: <CABPQxstiDvgPGOP4Tp3U7=gnY3=ToN=AMO+oSMr2q_J6=3rtjA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.2.1 (RC3)
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Should we merge this commit into branch1.2 too?

https://github.com/apache/spark/commit/2483c1efb6429a7d8a20c96d18ce2fec93a1aff9



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/VOTE-Release-Apache-Spark-1-2-1-RC3-tp10405p10503.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11520-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 10:59:33 2015
Return-Path: <dev-return-11520-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7B8FB17CC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 10:59:33 +0000 (UTC)
Received: (qmail 90451 invoked by uid 500); 8 Feb 2015 10:59:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90350 invoked by uid 500); 8 Feb 2015 10:59:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61919 invoked by uid 99); 6 Feb 2015 20:57:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 20:57:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_DBL_ABUSE_REDIR
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 06 Feb 2015 20:57:47 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so15677458obc.1
        for <dev@spark.apache.org>; Fri, 06 Feb 2015 12:55:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=pV0HC5t8/vf8kr8ONjZhAhzooNlqx3TcT6ax9+EMosU=;
        b=aKK5B6gA8B6KHLaDECsZwinjBLuCdQNi/EkMlV1m1Rcv+mt3Zy3MBu/24HvGpd3TaA
         gfR3ENn7SkgXuztjqiAT1BiH/+mfA6nFljXNIzND/36ziVLfkGq0PDMfanN9z722095z
         xkaMy2t8US38beU4pPp0ju+gOIyQ9MLzePGxkJTBoDjahbsMVN6mozXXLL8KgiqcInSK
         Glza326U43IL/P8ATWqEIixlLBDB1R+o/4b+iwPr5lddvj2pel0avyLmmtHIo5BkCgZX
         BhJJ2Nucet3JkDV74U4DIwgzxekxgkv3Wau8zAPHbbhwyhdGF+LHd2R9tj4DQTENgLjj
         K7Bw==
MIME-Version: 1.0
X-Received: by 10.202.45.9 with SMTP id t9mr3692880oit.100.1423256111960; Fri,
 06 Feb 2015 12:55:11 -0800 (PST)
Received: by 10.202.198.67 with HTTP; Fri, 6 Feb 2015 12:55:11 -0800 (PST)
Date: Fri, 6 Feb 2015 12:55:11 -0800
Message-ID: <CABPQxsupNXhGv_58pPMEwTY71RQwK2GpsGbU3SNoT5rFZDZF1Q@mail.gmail.com>
Subject: Unit tests
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

The tests are in a not-amazing state right now due to a few compounding factors:

1. We've merged a large volume of patches recently.
2. The load on jenkins has been relatively high, exposing races and
other behavior not seen at lower load.

For those not familiar, the main issue is flaky (non deterministic)
test failures. Right now I'm trying to prioritize keeping the
PullReqeustBuilder in good shape since it will block development if it
is down.

For other tests, let's try to keep filing JIRA's when we see issues
and use the flaky-test label (see http://bit.ly/1yRif9S):

I may contact people regarding specific tests. This is a very high
priority to get in good shape. This kind of thing is no one's "fault"
but just the result of a lot of concurrent development, and everyone
needs to pitch in to get back in a good place.

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11521-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb  8 22:44:48 2015
Return-Path: <dev-return-11521-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4765817EAE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  8 Feb 2015 22:44:48 +0000 (UTC)
Received: (qmail 58367 invoked by uid 500); 8 Feb 2015 22:44:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58281 invoked by uid 500); 8 Feb 2015 22:44:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58268 invoked by uid 99); 8 Feb 2015 22:44:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 22:44:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 08 Feb 2015 22:44:42 +0000
Received: by iery20 with SMTP id y20so4167343ier.9
        for <dev@spark.apache.org>; Sun, 08 Feb 2015 14:42:52 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=wwb63xvUSVMX3rQhw9ldz+mN9YhITAs4x4Lh2XSNrI4=;
        b=wODSKQ3/dyrTG0MNledXWRNlpfnfHP0tYUl1rdYiWDhHqNwRs0SyHJ5H3XKjam/QmI
         iguC5a3RdKV7qMCKWhzjcxF7vO+TWDueHat4CxfyhKLEAtwuzaFsVaqmL1nD/J4TR1o9
         ATdIiNRkvh5TUoyA7/njEVBGDfcgk/xYVVxsPTU3EmjxUlVbSVIZSGLjeUk1ledNvaf0
         PQ8qcsuMmYj6D2FJn6/mjmuNVAtDpGx1NnuVtANJdxCaPXH4wJ5ytu7UP/NrPsgMmFfv
         YHcWd/T9dbGnvw/1UoH08PNM6F2or+4K+uiHb/hy6c3AYQPFUT0MNblY4KgzkOZdNRD4
         0Ltg==
X-Received: by 10.43.54.4 with SMTP id vs4mr22326539icb.72.1423435372351; Sun,
 08 Feb 2015 14:42:52 -0800 (PST)
MIME-Version: 1.0
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 08 Feb 2015 22:42:51 +0000
Message-ID: <CAOhmDzer_oEB+bMOAgfD5Qdg5E3gz99wjGhzpeKYuCxtSw_Mzg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>, Joseph Bradley <joseph@databricks.com>
Cc: "Evan R. Sparks" <evan.sparks@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51b1c19bad581050e9b5f09
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51b1c19bad581050e9b5f09
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Lemme butt in randomly here and say there is an interesting discussion on
this Spark PR <https://github.com/apache/spark/pull/4448> about
netlib-java, JBLAS, Breeze, and other things I know nothing of, that y'all
may find interesting. Among the participants is the author of netlib-java.

On Sun Feb 08 2015 at 2:48:19 AM Ulanov, Alexander <alexander.ulanov@hp.com=
>
wrote:

> Hi Evan, Joseph
>
> I did few matrix multiplication test and BIDMat seems to be ~10x faster
> than netlib-java+breeze (sorry for weird table formatting):
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
> Breeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
> Linux, Scala 2.11.
>
> Later I will make tests with Cuda. I need to install new Cuda version for
> this purpose.
>
> Do you have any ideas why breeze-netlib with native blas is so much slowe=
r
> than BIDMat MKL?
>
> Best regards, Alexander
>
> From: Joseph Bradley [mailto:joseph@databricks.com]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Hi Alexander,
>
> Using GPUs with Spark would be very exciting.  Small comment: Concerning
> your question earlier about keeping data stored on the GPU rather than
> having to move it between main memory and GPU memory on each iteration, I
> would guess this would be critical to getting good performance.  If you
> could do multiple local iterations before aggregating results, then the
> cost of data movement to the GPU could be amortized (and I believe that i=
s
> done in practice).  Having Spark be aware of the GPU and using it as
> another part of memory sounds like a much bigger undertaking.
>
> Joseph
>
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page https://github.com/fommil/
> netlib-java. I also confirmed it with my experiments with training of
> artificial neural network https://github.com/apache/
> spark/pull/1290#issuecomment-70313952. However, I would like to boost
> performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>
>
>
>

--bcaec51b1c19bad581050e9b5f09--

From dev-return-11522-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 04:49:15 2015
Return-Path: <dev-return-11522-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2FCCD178C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 04:49:15 +0000 (UTC)
Received: (qmail 98453 invoked by uid 500); 9 Feb 2015 00:45:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98382 invoked by uid 500); 9 Feb 2015 00:45:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98371 invoked by uid 99); 9 Feb 2015 00:45:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 00:45:12 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jacky.likun@huawei.com designates 119.145.14.66 as permitted sender)
Received: from [119.145.14.66] (HELO szxga03-in.huawei.com) (119.145.14.66)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 00:44:46 +0000
Received: from 172.24.2.119 (EHLO szxeml432-hub.china.huawei.com) ([172.24.2.119])
	by szxrg03-dlp.huawei.com (MOS 4.4.3-GA FastPath queued)
	with ESMTP id BBO89441;
	Mon, 09 Feb 2015 08:44:42 +0800 (CST)
Received: from SZXEML521-MBS.china.huawei.com ([169.254.8.155]) by
 szxeml432-hub.china.huawei.com ([10.82.67.209]) with mapi id 14.03.0158.001;
 Mon, 9 Feb 2015 08:44:40 +0800
From: "Likun (Jacky)" <jacky.likun@huawei.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
CC: dev <dev@spark.apache.org>, Joseph Bradley <joseph@databricks.com>,
        "Sean
 Owen" <sowen@cloudera.com>, Cheng Lian <lian@databricks.com>
Subject: Re: Welcoming three new committers
Thread-Topic: Welcoming three new committers
Thread-Index: AQHQQAHWJyO5xoGWcUGpoucmFzbJ0ZzngyhS
Date: Mon, 9 Feb 2015 00:44:40 +0000
Message-ID: <DFE72E29DADE544098E3774505E8626F56AB325D@szxeml521-mbs.china.huawei.com>
References: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
In-Reply-To: <A5884ACF-A079-4575-85E3-61114D3BE74C@gmail.com>
Accept-Language: zh-CN, en-US
Content-Language: zh-CN
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Content-Type: multipart/alternative;
	boundary="_000_DFE72E29DADE544098E3774505E8626F56AB325Dszxeml521mbschi_"
MIME-Version: 1.0
X-CFilter-Loop: Reflected
X-Mirapoint-Virus-RAPID-Raw: score=unknown(0),
	refid=str=0001.0A020205.54D802FA.00A9,ss=1,re=0.000,recu=0.000,reip=0.000,cl=1,cld=1,fgs=0,
	ip=169.254.8.155,
	so=2013-05-26 15:14:31,
	dmn=2013-03-21 17:37:32
X-Mirapoint-Loop-Id: a41f300619cce5651c7ab6b3a9733c2c
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_DFE72E29DADE544098E3774505E8626F56AB325Dszxeml521mbschi_
Content-Type: text/plain; charset="gb2312"
Content-Transfer-Encoding: base64

Q29uZ3JhdHVsYXRpb25zIGd1eXMhIEtlZXAgaGVscGluZyB0aGlzIGF3ZXNvbWUgY29tbXVuaXR5
Lg0KDQpCUiwNCkphY2t5IExpDQoNCi0gt6LX1CBTbWFydGlzYW4gVDEgLQ0KDQoyMDE1xOoy1MI0
yNWjrMnPzuc2OjM209ogTWF0ZWkgWmFoYXJpYSA8bWF0ZWkuemFoYXJpYUBnbWFpbC5jb20+INC0
tcCjug0KDQpIaSBhbGwsDQoNClRoZSBQTUMgcmVjZW50bHkgdm90ZWQgdG8gYWRkIHRocmVlIG5l
dyBjb21taXR0ZXJzOiBDaGVuZyBMaWFuLCBKb3NlcGggQnJhZGxleSBhbmQgU2VhbiBPd2VuLiBB
bGwgdGhyZWUgaGF2ZSBiZWVuIG1ham9yIGNvbnRyaWJ1dG9ycyB0byBTcGFyayBpbiB0aGUgcGFz
dCB5ZWFyOiBDaGVuZyBvbiBTcGFyayBTUUwsIEpvc2VwaCBvbiBNTGxpYiwgYW5kIFNlYW4gb24g
TUwgYW5kIG1hbnkgcGllY2VzIHRocm91Z2hvdXQgU3BhcmsgQ29yZS4gSm9pbiBtZSBpbiB3ZWxj
b21pbmcgdGhlbSBhcyBjb21taXR0ZXJzIQ0KDQpNYXRlaQ0KLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tDQpUbyB1bnN1
YnNjcmliZSwgZS1tYWlsOiBkZXYtdW5zdWJzY3JpYmVAc3BhcmsuYXBhY2hlLm9yZw0KRm9yIGFk
ZGl0aW9uYWwgY29tbWFuZHMsIGUtbWFpbDogZGV2LWhlbHBAc3BhcmsuYXBhY2hlLm9yZw0KDQo=

--_000_DFE72E29DADE544098E3774505E8626F56AB325Dszxeml521mbschi_--


From dev-return-11523-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 05:58:30 2015
Return-Path: <dev-return-11523-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 109B017AEE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 05:58:30 +0000 (UTC)
Received: (qmail 79517 invoked by uid 500); 9 Feb 2015 05:58:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79447 invoked by uid 500); 9 Feb 2015 05:58:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79436 invoked by uid 99); 9 Feb 2015 05:58:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 05:58:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.174] (HELO mail-qc0-f174.google.com) (209.85.216.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 05:58:03 +0000
Received: by mail-qc0-f174.google.com with SMTP id w7so2608782qcr.5
        for <dev@spark.apache.org>; Sun, 08 Feb 2015 21:56:56 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=IdZNmsedA6S5gP+W11NzX7EE4D/tyBRfrDGHu8MiR78=;
        b=HHvDNQnrxiu/WZZZC+UrcO0g98eaQGqjT82265+26/f4KzT37fxP2v5trafwt4NYLs
         nrDmdFFFFUFziUJN6skCamkeKsUUHyKMNwS5icsTW3rbGF9kSwB1oNScyXp/B4cvthQH
         gczmVzNPAU2ABxSY3muL55Y/LjFnblyw98CDfEj3YNjuRaZV25zGuP11FYCzutqd4msC
         dwfLuyzGIEFa5gJMmpWqqIp+zcyRc/COXaF9rnQdG5/RUpFoz6xAnLjhwtqk173pEQ5z
         cWvG7F85/biieS64lp4q4CZT1v54ef4XYcIzQaGk3zcDg8DS2fYqnKervzKtuJRCvOaT
         sVXw==
X-Gm-Message-State: ALoCoQlmkLBo9QNDBLH5akcpO6Q/jmtBtMxI7LRUKSNmxS0Y98Ptujwy2Gx8WXdYo1l7III4yPBA
X-Received: by 10.224.43.10 with SMTP id u10mr37388604qae.20.1423461416372;
 Sun, 08 Feb 2015 21:56:56 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Sun, 8 Feb 2015 21:56:35 -0800 (PST)
In-Reply-To: <CABjXkq47J2A0pN62UJpSE0xPQppN_js7WRg5dOQ7jykZ32BCVA@mail.gmail.com>
References: <CABjXkq47J2A0pN62UJpSE0xPQppN_js7WRg5dOQ7jykZ32BCVA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 8 Feb 2015 21:56:35 -0800
Message-ID: <CAPh_B=a-ggOHwU5-q-sry9F6_QarsO8_g0NV1X4X5-qM_XG-0Q@mail.gmail.com>
Subject: Re: Spark SQL Window Functions
To: "Evan R. Sparks" <evan.sparks@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b8ca1320c1050ea170c4
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b8ca1320c1050ea170c4
Content-Type: text/plain; charset=UTF-8

This is the original ticket:
https://issues.apache.org/jira/browse/SPARK-1442

I believe it will happen, one way or another :)


On Fri, Feb 6, 2015 at 5:29 PM, Evan R. Sparks <evan.sparks@gmail.com>
wrote:

> Currently there's no standard way of handling time series data in Spark. We
> were kicking around some ideas in the lab today and one thing that came up
> was SQL Window Functions as a way to support them and query over time
> series (do things like moving average, etc.)
>
> These don't seem to be implemented in Spark SQL yet, but there's some
> discussion on JIRA (https://issues.apache.org/jira/browse/SPARK-3587)
> asking for them, and there have also been a couple of pull requests -
> https://github.com/apache/spark/pull/3703 and
> https://github.com/apache/spark/pull/2953.
>
> Is any work currently underway here?
>

--089e0158b8ca1320c1050ea170c4--

From dev-return-11524-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 06:06:22 2015
Return-Path: <dev-return-11524-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA5B217B16
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 06:06:22 +0000 (UTC)
Received: (qmail 90883 invoked by uid 500); 9 Feb 2015 06:06:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90804 invoked by uid 500); 9 Feb 2015 06:06:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90791 invoked by uid 99); 9 Feb 2015 06:06:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 06:06:21 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 06:06:17 +0000
Received: by labhv19 with SMTP id hv19so11190623lab.10
        for <dev@spark.apache.org>; Sun, 08 Feb 2015 22:04:06 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=VTHZNDybHC5ENGljXfD/EpktC8QXWbNTKSFpn8KhrxQ=;
        b=B+r5AlSwwOcGnc/MENafe6UP7Q556etn9DQPrFUJiC91BL7cVnOA+0zB8PTX0CNn6V
         g2S9ufY/uxgNCqBNe1hoAor0MBsswsm9HI2WfyPYIVnb9xlWbfsfrHcU9XfOiNIKU+Gg
         SVBBPpANRj6i3TqdRbalda4RLjjAHMKdE7zHBOLLjqeCZIdhuFwXsq4B/yJ2Zo229kDq
         b3mJXsvvcpoSug9Zc6TjM+vQ0slacKEmugo+eVZ0i3oAVXjtTRrqlIoCzRYjrqnOJ+Wv
         VBWy9RfhFVD3Tcx8yYCOrAFacx7x3r6/VJIZgbKbGhYtZD8sotfsQFi9uBasaY0Sbbee
         IsSA==
X-Gm-Message-State: ALoCoQmlMWLLtHnhlEpSnJgvcoSamBHKjOsbW/qvHQg6XhJsDICgyPnTapnFICNr6v9qjalyPZtr
MIME-Version: 1.0
X-Received: by 10.112.37.197 with SMTP id a5mr14759277lbk.19.1423461846249;
 Sun, 08 Feb 2015 22:04:06 -0800 (PST)
Received: by 10.152.124.38 with HTTP; Sun, 8 Feb 2015 22:04:06 -0800 (PST)
In-Reply-To: <1423273025027-10502.post@n3.nabble.com>
References: <1423273025027-10502.post@n3.nabble.com>
Date: Mon, 9 Feb 2015 11:34:06 +0530
Message-ID: <CAHUQ+_ajuMV090D=-jZsBnyzpPotLxF6sBBRWnfH9awN-P+v1g@mail.gmail.com>
Subject: Re: Pull Requests on github
From: Akhil Das <akhil@sigmoidanalytics.com>
To: fommil <sam.halliday@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11347340b27884050ea18963
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11347340b27884050ea18963
Content-Type: text/plain; charset=UTF-8

You can open a Jira issue pointing this PR to get it processed faster. :)

Thanks
Best Regards

On Sat, Feb 7, 2015 at 7:07 AM, fommil <sam.halliday@gmail.com> wrote:

> Hi all,
>
> I'm the author of netlib-java and I noticed that the documentation in MLlib
> was out of date and misleading, so I submitted a pull request on github
> which will hopefully make things easier for everybody to understand the
> benefits of system optimised natives and how to use them :-)
>
>   https://github.com/apache/spark/pull/4448
>
> However, it looks like there are a *lot* of outstanding PRs and that this
> is
> just a mirror repository.
>
> Will somebody please look at my PR and merge into the canonical source (and
> let me know)?
>
> Best regards,
> Sam
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11347340b27884050ea18963--

From dev-return-11525-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 10:43:26 2015
Return-Path: <dev-return-11525-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 21820105C2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 10:43:26 +0000 (UTC)
Received: (qmail 25345 invoked by uid 500); 9 Feb 2015 10:43:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25262 invoked by uid 500); 9 Feb 2015 10:43:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25251 invoked by uid 99); 9 Feb 2015 10:43:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 10:43:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.53 as permitted sender)
Received: from [74.125.82.53] (HELO mail-wg0-f53.google.com) (74.125.82.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 10:43:20 +0000
Received: by mail-wg0-f53.google.com with SMTP id x13so5910872wgg.12
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 02:42:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=XnBuEI8lAal6DpBi047MWElN+Ck0AbsQlgd4kurgaf0=;
        b=EVSCCIZXuHt97Cc1pk9r4p9jMGJW6yvl7bd4bPwFkghm4QYqwcWT7boc6FDWwafg1i
         FHYrpmxKX1r4ZA38zLA8xa+IUsSAcM+n0BBJtuwvIQNU5BqqVZ4bQka9GBNfIZp8be2B
         Mvq+VmqeqGZL86iDd8HwqxxYDhCBR3HtRRToQFjinsOmmU/cwtEvmh/XCTfx6j7mulNy
         6OzPECWCyz5Ild+Xk1BaKLSpfGtnMSBtSj1ZH+g30lwTkLMVCSY362jD+jguanaeelaH
         Autv+Z9rzjCXMjqLaQtGpmJyyBy57kclhLZjeHM/d1BgIHBUBIF4uyu4LAD6zBM49qA5
         bMoQ==
X-Gm-Message-State: ALoCoQmu5gKFN3KGfqAeyYWT0tU4jG+B3Lv67fOtpaO+H2nsk2Lq0sUxC5mdlTsar6UXn5OgVpWH
X-Received: by 10.194.80.193 with SMTP id t1mr8337481wjx.8.1423478534603; Mon,
 09 Feb 2015 02:42:14 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Mon, 9 Feb 2015 02:41:54 -0800 (PST)
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 9 Feb 2015 10:41:54 +0000
Message-ID: <CAMAsSdK3-DfF8QtjxiVJO8Z+mKQYs=TKDKS-ubtojmveQFUXbQ@mail.gmail.com>
Subject: Keep or remove Debian packaging in Spark?
To: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

This is a straw poll to assess whether there is support to keep and
fix, or remove, the Debian packaging-related config in Spark.

I see several oldish outstanding JIRAs relating to problems in the packaging:

https://issues.apache.org/jira/browse/SPARK-1799
https://issues.apache.org/jira/browse/SPARK-2614
https://issues.apache.org/jira/browse/SPARK-3624
https://issues.apache.org/jira/browse/SPARK-4436
(and a similar idea about making RPMs)
https://issues.apache.org/jira/browse/SPARK-665

The original motivation seems related to Chef:

https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14070908

Mark's recent comments cast some doubt on whether it is essential:

https://github.com/apache/spark/pull/4277#issuecomment-72114226

and in recent conversations I didn't hear dissent to the idea of removing this.

Is this still useful enough to fix up? All else equal I'd like to
start to walk back some of the complexity of the build, but I don't
know how all-else-equal it is. Certainly, it sounds like nobody
intends these to be used to actually deploy Spark.

I don't doubt it's useful to someone, but can they maintain the
packaging logic elsewhere?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11526-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 11:23:05 2015
Return-Path: <dev-return-11526-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 340D810D2B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 11:23:05 +0000 (UTC)
Received: (qmail 48927 invoked by uid 500); 9 Feb 2015 11:23:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48850 invoked by uid 500); 9 Feb 2015 11:23:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48839 invoked by uid 99); 9 Feb 2015 11:23:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 11:23:03 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gilv@il.ibm.com designates 195.75.94.106 as permitted sender)
Received: from [195.75.94.106] (HELO e06smtp10.uk.ibm.com) (195.75.94.106)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 11:22:36 +0000
Received: from /spool/local
	by e06smtp10.uk.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
	for <dev@spark.apache.org> from <gilv@il.ibm.com>;
	Mon, 9 Feb 2015 11:22:34 -0000
Received: from d06dlp01.portsmouth.uk.ibm.com (9.149.20.13)
	by e06smtp10.uk.ibm.com (192.168.101.140) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
	Mon, 9 Feb 2015 11:22:33 -0000
Received: from b06cxnps4075.portsmouth.uk.ibm.com (d06relay12.portsmouth.uk.ibm.com [9.149.109.197])
	by d06dlp01.portsmouth.uk.ibm.com (Postfix) with ESMTP id A73CD17D8056
	for <dev@spark.apache.org>; Mon,  9 Feb 2015 11:22:42 +0000 (GMT)
Received: from d06av08.portsmouth.uk.ibm.com (d06av08.portsmouth.uk.ibm.com [9.149.37.249])
	by b06cxnps4075.portsmouth.uk.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id t19BMW1D39125240
	for <dev@spark.apache.org>; Mon, 9 Feb 2015 11:22:32 GMT
Received: from d06av08.portsmouth.uk.ibm.com (localhost [127.0.0.1])
	by d06av08.portsmouth.uk.ibm.com (8.14.4/8.14.4/NCO v10.0 AVout) with ESMTP id t19BMW6T024535
	for <dev@spark.apache.org>; Mon, 9 Feb 2015 04:22:32 -0700
Received: from d06ml319.portsmouth.uk.ibm.com (d06ml319.portsmouth.uk.ibm.com [9.149.76.146])
	by d06av08.portsmouth.uk.ibm.com (8.14.4/8.14.4/NCO v10.0 AVin) with ESMTP id t19BMWMb024530
	for <dev@spark.apache.org>; Mon, 9 Feb 2015 04:22:32 -0700
In-Reply-To: <CAMAsSdJ7q_wVaD8cOg35OtcUW6WShGMo6YxfJ=saxBSYFWEneQ@mail.gmail.com>
References: <OF67E8C1B6.947D6EC2-ONC2257DD1.00215569-C2257DD1.00236627@il.ibm.com> <CALte62y9m9zNmnmWqXXXVQ-Dd7OixoB4BRD8sJX_BgSXP-6-HA@mail.gmail.com> <CAMAsSdJ7q_wVaD8cOg35OtcUW6WShGMo6YxfJ=saxBSYFWEneQ@mail.gmail.com>
To: dev <dev@spark.apache.org>
MIME-Version: 1.0
Subject: Re: run time exceptions in Spark 1.2.0 manual build together with OpenStack
 hadoop driver
X-KeepSent: 34E2BA36:F439875C-C2257DE7:003E2316;
 type=4; name=$KeepSent
X-Mailer: IBM Notes Release 9.0.1SHF211 December 19, 2013
From: Gil Vernik <GILV@il.ibm.com>
Message-ID: <OF34E2BA36.F439875C-ONC2257DE7.003E2316-C2257DE7.003E7CDF@il.ibm.com>
Date: Mon, 9 Feb 2015 13:22:31 +0200
X-MIMETrack: Serialize by Router on D06ML319/06/M/IBM(Release 9.0.1FP2|August  03, 2014) at
 09/02/2015 13:22:31,
	Serialize complete at 09/02/2015 13:22:31
Content-Type: multipart/alternative; boundary="=_alternative 003E7C4FC2257DE7_="
X-TM-AS-MML: disable
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 15020911-0041-0000-0000-000003309FD4
X-Virus-Checked: Checked by ClamAV on apache.org

--=_alternative 003E7C4FC2257DE7_=
Content-Type: text/plain; charset="US-ASCII"

Hi All,

I understand that https://github.com/apache/spark/pull/3938 was closed and 
merged into Spark? And this suppose to fix this Jackson issue.
If so, is there any way to update binary distributions of Spark so that it 
will contain this fix? Current binary versions of Spark available for 
download were built with jackson 1.8.8 which makes them  impossible to use 
with Hadoop 2.6.0 jars

Thanks
Gil Vernik.






From:   Sean Owen <sowen@cloudera.com>
To:     Ted Yu <yuzhihong@gmail.com>
Cc:     Gil Vernik/Haifa/IBM@IBMIL, dev <dev@spark.apache.org>
Date:   18/01/2015 08:23 PM
Subject:        Re: run time exceptions in Spark 1.2.0 manual build 
together with OpenStack hadoop driver



Agree, I think this can / should be fixed with a slightly more
conservative version of https://github.com/apache/spark/pull/3938
related to SPARK-5108.

On Sun, Jan 18, 2015 at 3:41 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> Please tale a look at SPARK-4048 and SPARK-5108
>
> Cheers
>
> On Sat, Jan 17, 2015 at 10:26 PM, Gil Vernik <GILV@il.ibm.com> wrote:
>
>> Hi,
>>
>> I took a source code of Spark 1.2.0 and tried to build it together with
>> hadoop-openstack.jar ( To allow Spark an access to OpenStack Swift )
>> I used Hadoop 2.6.0.
>>
>> The build was fine without problems, however in run time, while trying 
to
>> access "swift://" name space i got an exception:
>> java.lang.NoClassDefFoundError: org/codehaus/jackson/annotate/JsonClass
>>                  at
>>
>> 
org.codehaus.jackson.map.introspect.JacksonAnnotationIntrospector.findDeserializationType(JacksonAnnotationIntrospector.java:524)
>>                  at
>>
>> 
org.codehaus.jackson.map.deser.BasicDeserializerFactory.modifyTypeByAnnotation(BasicDeserializerFactory.java:732)
>>                 ...and the long stack trace goes here
>>
>> Digging into the problem i saw the following:
>> Jackson versions 1.9.X are not backward compatible, in particular they
>> removed JsonClass annotation.
>> Hadoop 2.6.0 uses jackson-asl version 1.9.13, while Spark has reference 
to
>> older version of jackson.
>>
>> This is the main  pom.xml of Spark 1.2.0 :
>>
>>       <dependency>
>>         <!-- Matches the version of jackson-core-asl pulled in by avro 
-->
>>         <groupId>org.codehaus.jackson</groupId>
>>         <artifactId>jackson-mapper-asl</artifactId>
>>         <version>1.8.8</version>
>>       </dependency>
>>
>> Referencing 1.8.8 version, which is not compatible with Hadoop 2.6.0 .
>> If we change version to 1.9.13, than all will work fine and there will 
be
>> no run time exceptions while accessing Swift. The following change will
>> solve the problem:
>>
>>       <dependency>
>>         <!-- Matches the version of jackson-core-asl pulled in by avro 
-->
>>         <groupId>org.codehaus.jackson</groupId>
>>         <artifactId>jackson-mapper-asl</artifactId>
>>         <version>1.9.13</version>
>>       </dependency>
>>
>> I am trying to resolve this somehow so people will not get into this
>> issue.
>> Is there any particular need in Spark for jackson 1.8.8 and not 1.9.13?
>> Can we remove 1.8.8 and put 1.9.13 for Avro?
>> It looks to me that all works fine when Spark build with jackson 
1.9.13,
>> but i am not an expert and not sure what should be tested.
>>
>> Thanks,
>> Gil Vernik.
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org



--=_alternative 003E7C4FC2257DE7_=--


From dev-return-11527-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 11:30:28 2015
Return-Path: <dev-return-11527-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1F28010DA2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 11:30:28 +0000 (UTC)
Received: (qmail 68146 invoked by uid 500); 9 Feb 2015 11:30:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68075 invoked by uid 500); 9 Feb 2015 11:30:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68064 invoked by uid 99); 9 Feb 2015 11:30:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 11:30:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.179 as permitted sender)
Received: from [74.125.82.179] (HELO mail-we0-f179.google.com) (74.125.82.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 11:30:22 +0000
Received: by mail-we0-f179.google.com with SMTP id u56so20709448wes.10
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 03:29:15 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=YiOvQvutf8nnBgmD3UIUrCUzVPH2FduRjVmNlbNLn9s=;
        b=PZgGh5AKRSrcSjmARYvhHoFjW0iFCGapBBzA0cfWFx4oDBKCDjuH/JZ6rJM0DjxrWm
         JKjocj2fWORcchC9QhE94/H9G5VAKHhbHG0/hUhpkSy6GnW3ifea9waiSb6bXOnQmn9u
         5Df2ckz89v9e7nE1KEd+Q2on1Ds6qE343bRLpehBoT5L3rKkODwjUGv3kt/3dNdo4t0a
         3G6tVj8pThDp3qAfn2daJPhWuj5YhpQpht0oFi09P1FuRHj8FcbYA4QaNlPLiRGxDDTh
         bfhGDHNKLJ7eOb5K5QGaV99ReXhba9Z0ZvraJnljR6l9Tkj9e1rOIIMEPYqyXHjZgIZN
         D4yA==
X-Gm-Message-State: ALoCoQlVfCyHLy8FQDFANP4dh2KhhZyu2VorN+vd5CV6tNKp9zpnFrcanxkz9lOnQ+n/8qKjqNMh
X-Received: by 10.194.243.1 with SMTP id wu1mr41753543wjc.69.1423481355744;
 Mon, 09 Feb 2015 03:29:15 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Mon, 9 Feb 2015 03:28:55 -0800 (PST)
In-Reply-To: <OF34E2BA36.F439875C-ONC2257DE7.003E2316-C2257DE7.003E7CDF@il.ibm.com>
References: <OF67E8C1B6.947D6EC2-ONC2257DD1.00215569-C2257DD1.00236627@il.ibm.com>
 <CALte62y9m9zNmnmWqXXXVQ-Dd7OixoB4BRD8sJX_BgSXP-6-HA@mail.gmail.com>
 <CAMAsSdJ7q_wVaD8cOg35OtcUW6WShGMo6YxfJ=saxBSYFWEneQ@mail.gmail.com> <OF34E2BA36.F439875C-ONC2257DE7.003E2316-C2257DE7.003E7CDF@il.ibm.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 9 Feb 2015 11:28:55 +0000
Message-ID: <CAMAsSdJ0z72DKOo9ctrRc8shUzoNhpVw1MHbDEZYKiMiwnwewQ@mail.gmail.com>
Subject: Re: run time exceptions in Spark 1.2.0 manual build together with
 OpenStack hadoop driver
To: Gil Vernik <GILV@il.ibm.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Old releases can't be changed, but new ones can. This was merged into
the 1.3 branch for the upcoming 1.3.0 release.

If you really had to, you could do some surgery on existing
distributions to swap in/out Jackson.

On Mon, Feb 9, 2015 at 11:22 AM, Gil Vernik <GILV@il.ibm.com> wrote:
> Hi All,
>
> I understand that https://github.com/apache/spark/pull/3938 was closed and
> merged into Spark? And this suppose to fix this Jackson issue.
> If so, is there any way to update binary distributions of Spark so that it
> will contain this fix? Current binary versions of Spark available for
> download were built with jackson 1.8.8 which makes them  impossible to use
> with Hadoop 2.6.0 jars
>
> Thanks
> Gil Vernik.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11528-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 13:48:00 2015
Return-Path: <dev-return-11528-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 611EB10351
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 13:48:00 +0000 (UTC)
Received: (qmail 19543 invoked by uid 500); 9 Feb 2015 13:47:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19449 invoked by uid 500); 9 Feb 2015 13:47:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19370 invoked by uid 99); 9 Feb 2015 13:47:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 13:47:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_DBL_ABUSE_REDIR
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of iulian.dragos@typesafe.com designates 209.85.218.51 as permitted sender)
Received: from [209.85.218.51] (HELO mail-oi0-f51.google.com) (209.85.218.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 13:47:34 +0000
Received: by mail-oi0-f51.google.com with SMTP id g201so2801881oib.10
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 05:46:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=typesafe.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=vzRVBxl20so8gc+5A3jK9FTUC3yeeMEOg9nCKNvp8Ro=;
        b=YgcBAXfTvSG9mYqYLr/XZ9EDAJH5J/i5skeoIb1qeSH0z+yCVbYXyNtAakxWBwgclF
         UzreiH071FDf/+q17UwbOXepm3bOZbAmccprxaRZpZyedYuMeIPbcNPh3Z5xbcBLJjPK
         OWSXoShhyXpSV+Zgd1rnTlADXE3h2D82QKwkA=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=vzRVBxl20so8gc+5A3jK9FTUC3yeeMEOg9nCKNvp8Ro=;
        b=CiIrHj4rDl8jkRF6b0uptjw/FKTE+/Ll7Mx3t5xB9a5ETHtkKxq4x14kDooLmK2gfM
         TN14iar50eckMDXxMR80zCi+bAFmGdLkImhJBFtdV05AbEIx4tkDrpQNc9t4ERbRYSiM
         97vweYt7WtVaYaYREBiUf4kcICiVGyo3/ER/qwiTHuwMJVq0vhoLAz1J371VSybg0qW0
         tTX0cyow+oA4kVvj/rred49Xu64SJb4S6ppxSrFBXPikUDv1mKrkUQw+DoQqoeeFMk22
         cS+bE39Oo/OqwfPqMUwXPGSK4uLzmAxJKMtlx+pyWAp3lXIbgPzbbprzeH+AwZNPzwIp
         mrng==
X-Gm-Message-State: ALoCoQluxZbzDf1AlRMSXXT2HM7vSD+WAhlcMzHk5ZFi6b8kGYOBairSY/2p3LWXg7suIiBR2jbC
X-Received: by 10.202.187.5 with SMTP id l5mr11089472oif.51.1423489607487;
 Mon, 09 Feb 2015 05:46:47 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.50.11 with HTTP; Mon, 9 Feb 2015 05:46:27 -0800 (PST)
In-Reply-To: <CABPQxsupNXhGv_58pPMEwTY71RQwK2GpsGbU3SNoT5rFZDZF1Q@mail.gmail.com>
References: <CABPQxsupNXhGv_58pPMEwTY71RQwK2GpsGbU3SNoT5rFZDZF1Q@mail.gmail.com>
From: =?UTF-8?Q?Iulian_Drago=C8=99?= <iulian.dragos@typesafe.com>
Date: Mon, 9 Feb 2015 14:46:27 +0100
Message-ID: <CAD2BF0+eQUbs5-DW6dviLECn4+D2we=+JE4paQJky1uwKjvU1w@mail.gmail.com>
Subject: Re: Unit tests
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113ccb246568b2050ea800ec
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ccb246568b2050ea800ec
Content-Type: text/plain; charset=UTF-8

Hi Patrick,

Thanks for the heads up. I was trying to set up our own infrastructure for
testing Spark (essentially, running `run-tests` every night) on EC2. I
stumbled upon a number of flaky tests, but none of them look similar to
anything in Jira with the flaky-test tag. I wonder if there's something
wrong with our infrastructure, or I should simply open Jira tickets with
the failures I find. For example, one that appears fairly often on our
setup is in AkkaUtilsSuite "remote fetch ssl on - untrusted server"
(exception `ActorNotFound`, instead of `TimeoutException`).

thanks,
iulian


On Fri, Feb 6, 2015 at 9:55 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey All,
>
> The tests are in a not-amazing state right now due to a few compounding
> factors:
>
> 1. We've merged a large volume of patches recently.
> 2. The load on jenkins has been relatively high, exposing races and
> other behavior not seen at lower load.
>
> For those not familiar, the main issue is flaky (non deterministic)
> test failures. Right now I'm trying to prioritize keeping the
> PullReqeustBuilder in good shape since it will block development if it
> is down.
>
> For other tests, let's try to keep filing JIRA's when we see issues
> and use the flaky-test label (see http://bit.ly/1yRif9S):
>
> I may contact people regarding specific tests. This is a very high
> priority to get in good shape. This kind of thing is no one's "fault"
> but just the result of a lot of concurrent development, and everyone
> needs to pitch in to get back in a good place.
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 

--
Iulian Dragos

------
Reactive Apps on the JVM
www.typesafe.com

--001a113ccb246568b2050ea800ec--

From dev-return-11529-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 15:34:00 2015
Return-Path: <dev-return-11529-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6E55A1097E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 15:34:00 +0000 (UTC)
Received: (qmail 24852 invoked by uid 500); 9 Feb 2015 15:33:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24785 invoked by uid 500); 9 Feb 2015 15:33:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24774 invoked by uid 99); 9 Feb 2015 15:33:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 15:33:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 15:33:54 +0000
Received: by mail-wg0-f46.google.com with SMTP id a1so6116619wgh.5
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 07:31:11 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=vLBDeXI4qk0ZgrpdJ4IyLvLp25IgFlJI1v6TytNHhFY=;
        b=a1nTJHS87xOlediR64vX2+2bENqc3d7Fh/iL1Q2Ac7br0Nxonazg/7NmPrrL6JRNUr
         LYPorw4xLkarKB8ilwRBGjd5lJVhHeNh7NuvBD8f2q401/+QjuYMb3p8i9Vxz2gFXRE1
         c+8RohAMwyLC1sEC7kqBmyS+bBJoVx4AFbePL6NrpplHAAUZ7pQrbZN2QJ6FNZ2aamKw
         VTtMk/ZNYPDp4g4bCccuXK3SA+sktOeGujnPS5ooWdxBvgCsiQ62osP72Vv5bjeM5176
         NcudfDHmJzGHGjEx1irGTMkgvh2nU3P8CT8Apkxdd6sledoHGVb6ZvtQnADt3GDYH6lk
         TqSw==
X-Gm-Message-State: ALoCoQmlNmvn4Hg5uEwqtBmkFQX1P59LSSEWMoav/PwguXX8NuIevQOq0n7oreLAmttyTMNQrVDq
MIME-Version: 1.0
X-Received: by 10.180.73.84 with SMTP id j20mr36154898wiv.43.1423495869726;
 Mon, 09 Feb 2015 07:31:09 -0800 (PST)
Received: by 10.217.171.69 with HTTP; Mon, 9 Feb 2015 07:31:09 -0800 (PST)
In-Reply-To: <CAMAsSdK3-DfF8QtjxiVJO8Z+mKQYs=TKDKS-ubtojmveQFUXbQ@mail.gmail.com>
References: <CAMAsSdK3-DfF8QtjxiVJO8Z+mKQYs=TKDKS-ubtojmveQFUXbQ@mail.gmail.com>
Date: Mon, 9 Feb 2015 07:31:09 -0800
Message-ID: <CAAsvFP=zvLpNvsw_WS5A7q-sqfDjX=7srLeArnRK3XQfuHHygA@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
From: Mark Hamstra <mark@clearstorydata.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d04374949a79a06050ea9753d
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04374949a79a06050ea9753d
Content-Type: text/plain; charset=UTF-8

>
> it sounds like nobody intends these to be used to actually deploy Spark


I wouldn't go quite that far.  What we have now can serve as useful input
to a deployment tool like Chef, but the user is then going to need to add
some customization or configuration within the context of that tooling to
get Spark installed just the way they want.  So it is not so much that the
current Debian packaging can't be used as that it has never really been
intended to be a completely finished product that a newcomer could, for
example, use to install Spark completely and quickly to Ubuntu and have a
fully-functional environment in which they could then run all of the
examples, tutorials, etc.

Getting to that level of packaging (and maintenance) is something that I'm
not sure we want to do since that is a better fit with Bigtop and the
efforts of Cloudera, Horton Works, MapR, etc. to distribute Spark.

On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> wrote:

> This is a straw poll to assess whether there is support to keep and
> fix, or remove, the Debian packaging-related config in Spark.
>
> I see several oldish outstanding JIRAs relating to problems in the
> packaging:
>
> https://issues.apache.org/jira/browse/SPARK-1799
> https://issues.apache.org/jira/browse/SPARK-2614
> https://issues.apache.org/jira/browse/SPARK-3624
> https://issues.apache.org/jira/browse/SPARK-4436
> (and a similar idea about making RPMs)
> https://issues.apache.org/jira/browse/SPARK-665
>
> The original motivation seems related to Chef:
>
>
> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14070908
>
> Mark's recent comments cast some doubt on whether it is essential:
>
> https://github.com/apache/spark/pull/4277#issuecomment-72114226
>
> and in recent conversations I didn't hear dissent to the idea of removing
> this.
>
> Is this still useful enough to fix up? All else equal I'd like to
> start to walk back some of the complexity of the build, but I don't
> know how all-else-equal it is. Certainly, it sounds like nobody
> intends these to be used to actually deploy Spark.
>
> I don't doubt it's useful to someone, but can they maintain the
> packaging logic elsewhere?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--f46d04374949a79a06050ea9753d--

From dev-return-11530-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 18:08:28 2015
Return-Path: <dev-return-11530-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 684B610200
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 18:08:28 +0000 (UTC)
Received: (qmail 98473 invoked by uid 500); 9 Feb 2015 18:08:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98395 invoked by uid 500); 9 Feb 2015 18:08:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98383 invoked by uid 99); 9 Feb 2015 18:08:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:08:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.42 as permitted sender)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:08:02 +0000
Received: by mail-oi0-f42.google.com with SMTP id h136so6835007oig.1
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 10:08:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=qeQdnTe5UBUjxDHb0BaOmJqo4H1D0hM9QwZ81vooShU=;
        b=M4bQbA4nfjIqMGkYs6SNPLrusQqkaanFodL1wg1flyMM1VacqxA1ymXc/ZBdUolL3M
         +9XFoK1S3RGfNqNMqDD7lWd83fpD2OeHEnT6WW8Mp5OjqOoLJ6WTZzBro5SbE0RvEp9e
         2Tk9T1/WiakbeNbzUDTOiFjbonbKjvLeGNJYziStVShT2Ovs2LQ1Bo3EcFIlLrhf1oI4
         pVE3js9DuvsycyQwthHDPr3nqjwfGL8ckD+FliknCJsVL6EiJBqAMvGSDrh6BQ0ITPB8
         DCqHgCza90UUU4N6ZHHgCwUo7tYPJw8dI5fyKwvwZKJLVrT5CWbNA1O07rYfm5sobPeA
         aoqg==
MIME-Version: 1.0
X-Received: by 10.182.71.73 with SMTP id s9mr12855787obu.15.1423505280752;
 Mon, 09 Feb 2015 10:08:00 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 10:08:00 -0800 (PST)
In-Reply-To: <CAAsvFP=zvLpNvsw_WS5A7q-sqfDjX=7srLeArnRK3XQfuHHygA@mail.gmail.com>
References: <CAMAsSdK3-DfF8QtjxiVJO8Z+mKQYs=TKDKS-ubtojmveQFUXbQ@mail.gmail.com>
	<CAAsvFP=zvLpNvsw_WS5A7q-sqfDjX=7srLeArnRK3XQfuHHygA@mail.gmail.com>
Date: Mon, 9 Feb 2015 10:08:00 -0800
Message-ID: <CABPQxss0nPLgdBXgaZBog1Cgh8m3Y6SZ0y=_ti=ZdkQ2M+pm8w@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
From: Patrick Wendell <pwendell@gmail.com>
To: Mark Hamstra <mark@clearstorydata.com>
Cc: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I have wondered whether we should sort of deprecated it more
officially, since otherwise I think people have the reasonable
expectation based on the current code that Spark intends to support
"complete" Debian packaging as part of the upstream build. Having
something that's sort-of maintained but no one is helping review and
merge patches on it or make it fully functional, IMO that doesn't
benefit us or our users. There are a bunch of other projects that are
specifically devoted to packaging, so it seems like there is a clear
separation of concerns here.

On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra <mark@clearstorydata.com> wrote:
>>
>> it sounds like nobody intends these to be used to actually deploy Spark
>
>
> I wouldn't go quite that far.  What we have now can serve as useful input
> to a deployment tool like Chef, but the user is then going to need to add
> some customization or configuration within the context of that tooling to
> get Spark installed just the way they want.  So it is not so much that the
> current Debian packaging can't be used as that it has never really been
> intended to be a completely finished product that a newcomer could, for
> example, use to install Spark completely and quickly to Ubuntu and have a
> fully-functional environment in which they could then run all of the
> examples, tutorials, etc.
>
> Getting to that level of packaging (and maintenance) is something that I'm
> not sure we want to do since that is a better fit with Bigtop and the
> efforts of Cloudera, Horton Works, MapR, etc. to distribute Spark.
>
> On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> wrote:
>
>> This is a straw poll to assess whether there is support to keep and
>> fix, or remove, the Debian packaging-related config in Spark.
>>
>> I see several oldish outstanding JIRAs relating to problems in the
>> packaging:
>>
>> https://issues.apache.org/jira/browse/SPARK-1799
>> https://issues.apache.org/jira/browse/SPARK-2614
>> https://issues.apache.org/jira/browse/SPARK-3624
>> https://issues.apache.org/jira/browse/SPARK-4436
>> (and a similar idea about making RPMs)
>> https://issues.apache.org/jira/browse/SPARK-665
>>
>> The original motivation seems related to Chef:
>>
>>
>> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14070908
>>
>> Mark's recent comments cast some doubt on whether it is essential:
>>
>> https://github.com/apache/spark/pull/4277#issuecomment-72114226
>>
>> and in recent conversations I didn't hear dissent to the idea of removing
>> this.
>>
>> Is this still useful enough to fix up? All else equal I'd like to
>> start to walk back some of the complexity of the build, but I don't
>> know how all-else-equal it is. Certainly, it sounds like nobody
>> intends these to be used to actually deploy Spark.
>>
>> I don't doubt it's useful to someone, but can they maintain the
>> packaging logic elsewhere?
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11531-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 18:47:21 2015
Return-Path: <dev-return-11531-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A130A10480
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 18:47:21 +0000 (UTC)
Received: (qmail 46167 invoked by uid 500); 9 Feb 2015 18:47:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46100 invoked by uid 500); 9 Feb 2015 18:47:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46087 invoked by uid 99); 9 Feb 2015 18:47:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:47:20 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_DBL_ABUSE_REDIR
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:47:15 +0000
Received: by mail-pa0-f54.google.com with SMTP id kx10so20378245pab.13
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 10:45:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=uVfmpn42iCwB7i5WAufUYSUhIUWcfgP0kJs5Rva2ZZc=;
        b=bq/mohA8AKkaLSYnThwG4utGCAJqLv9o8Viyj0AKETcN83qYzoz7BeEvUhc7deeYWf
         wt/YPfUa3kB8pxar2lsHfsvUOyLdNWp8MQMoVN7y3OapBjMBqDULMV9NevTGQIVyJK1s
         m2CC308VsWjN8txVGz4dgxcE4gN724h4WVGwHqvMrhTn+nFPg40rrUL1EHlvoiqXCdtv
         w1dH58yi6EBUm5C9UWp6orLiT6q4cTRmpRCAnFFpCEaABoNzjlWFZ7hJLsEBHmJkc1Qw
         K7bRMTkuov7tsBBXxNBDF4A5r8anC03+2O4wfQpiBn4eXYSVhMMBVeL/wORosfZG4OgJ
         sW9g==
X-Received: by 10.70.129.36 with SMTP id nt4mr30692245pdb.59.1423507525336;
        Mon, 09 Feb 2015 10:45:25 -0800 (PST)
Received: from Joshs-MacBook-Pro.local (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id qs3sm17042780pbc.28.2015.02.09.10.45.16
        (version=TLSv1.2 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 09 Feb 2015 10:45:24 -0800 (PST)
Date: Mon, 9 Feb 2015 10:45:16 -0800
From: Josh Rosen <rosenville@gmail.com>
To: =?utf-8?Q?Iulian_Drago=C8=99?= <iulian.dragos@typesafe.com>, 
 Patrick Wendell <pwendell@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.54d9003c.66334873.124@Joshs-MacBook-Pro.local>
In-Reply-To: <CAD2BF0+eQUbs5-DW6dviLECn4+D2we=+JE4paQJky1uwKjvU1w@mail.gmail.com>
References: <CABPQxsupNXhGv_58pPMEwTY71RQwK2GpsGbU3SNoT5rFZDZF1Q@mail.gmail.com>
 <CAD2BF0+eQUbs5-DW6dviLECn4+D2we=+JE4paQJky1uwKjvU1w@mail.gmail.com>
Subject: Re: Unit tests
X-Mailer: Airmail (286)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54d9003c_74b0dc51_124"
X-Virus-Checked: Checked by ClamAV on apache.org

--54d9003c_74b0dc51_124
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi Iulian,

I think the AkakUtilsSuite failure that you observed has been fixed in=C2=
=A0https://issues.apache.org/jira/browse/SPARK-5548=C2=A0/=C2=A0https://g=
ithub.com/apache/spark/pull/4343
On =46ebruary 9, 2015 at 5:47:59 AM, Iulian Drago=C8=99 (iulian.dragos=40=
typesafe.com) wrote:

Hi Patrick, =20

Thanks for the heads up. I was trying to set up our own infrastructure fo=
r =20
testing Spark (essentially, running =60run-tests=60 every night) on EC2. =
I =20
stumbled upon a number of flaky tests, but none of them look similar to =20
anything in Jira with the flaky-test tag. I wonder if there's something =20
wrong with our infrastructure, or I should simply open Jira tickets with =
=20
the failures I find. =46or example, one that appears fairly often on our =
=20
setup is in AkkaUtilsSuite =22remote fetch ssl on - untrusted server=22 =20
(exception =60ActorNot=46ound=60, instead of =60TimeoutException=60). =20

thanks, =20
iulian =20


On =46ri, =46eb 6, 2015 at 9:55 PM, Patrick Wendell <pwendell=40gmail.com=
> wrote: =20

> Hey All, =20
> =20
> The tests are in a not-amazing state right now due to a few compounding=
 =20
> factors: =20
> =20
> 1. We've merged a large volume of patches recently. =20
> 2. The load on jenkins has been relatively high, exposing races and =20
> other behavior not seen at lower load. =20
> =20
> =46or those not familiar, the main issue is flaky (non deterministic) =20
> test failures. Right now I'm trying to prioritize keeping the =20
> PullReqeustBuilder in good shape since it will block development if it =
=20
> is down. =20
> =20
> =46or other tests, let's try to keep filing JIRA's when we see issues =20
> and use the flaky-test label (see http://bit.ly/1yRif9S): =20
> =20
> I may contact people regarding specific tests. This is a very high =20
> priority to get in good shape. This kind of thing is no one's =22fault=22=
 =20
> but just the result of a lot of concurrent development, and everyone =20
> needs to pitch in to get back in a good place. =20
> =20
> - Patrick =20
> =20
> --------------------------------------------------------------------- =20
> To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> =20
> =20


-- =20

-- =20
Iulian Dragos =20

------ =20
Reactive Apps on the JVM =20
www.typesafe.com =20

--54d9003c_74b0dc51_124--


From dev-return-11532-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 18:48:29 2015
Return-Path: <dev-return-11532-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CEA8F104A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 18:48:29 +0000 (UTC)
Received: (qmail 56405 invoked by uid 500); 9 Feb 2015 18:48:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56333 invoked by uid 500); 9 Feb 2015 18:48:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56320 invoked by uid 99); 9 Feb 2015 18:48:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:48:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 18:48:19 +0000
Received: by mail-ig0-f180.google.com with SMTP id b16so18376255igk.1
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 10:47:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:cc:content-type;
        bh=1QoOvXytJRMBxIhZvYyt6K9k3h6n57HUKYiXFX5PlVo=;
        b=xAV3P38wFOlTuBX4pfPO9Qq2RkEoq/i5PBpHHAa3KyZJ2kHMnLYGcks10GWpSp3UIM
         D851f4abyATtHatSZflfLFjorsvSbcB93qGI9eAnAOn3pxw8hNAh0gHYAs0IFqqHuMlj
         BnDF91zl87ymz/pvRbyx+ndtw9eJNdZPx2fE6bcxOteoOO0mmJZQ1pq19pHf+bEjMDw2
         lkTILv2pYGJmizjTel1yh67m7YnFdH3fT7Mq9EXw2pf3s1m03/2pnaJZZfZnFGEcG3gw
         AAxzTCPSyrjRyjJY+xDeCdccuMT7IqPkC15TfN4zJhqo5j5IbLmVS3JS3wfsWo7/fPVq
         +GMQ==
X-Received: by 10.107.161.75 with SMTP id k72mr27669230ioe.46.1423507679056;
 Mon, 09 Feb 2015 10:47:59 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 09 Feb 2015 18:47:58 +0000
Message-ID: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
To: Patrick Wendell <pwendell@gmail.com>, Mark Hamstra <mark@clearstorydata.com>
Cc: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114100b08b9e5a050eac35dc
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114100b08b9e5a050eac35dc
Content-Type: text/plain; charset=UTF-8

+1 to an "official" deprecation + redirecting users to some other project
that will or already is taking this on.

Nate?


On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
wrote:

> I have wondered whether we should sort of deprecated it more
> officially, since otherwise I think people have the reasonable
> expectation based on the current code that Spark intends to support
> "complete" Debian packaging as part of the upstream build. Having
> something that's sort-of maintained but no one is helping review and
> merge patches on it or make it fully functional, IMO that doesn't
> benefit us or our users. There are a bunch of other projects that are
> specifically devoted to packaging, so it seems like there is a clear
> separation of concerns here.
>
> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
> >>
> >> it sounds like nobody intends these to be used to actually deploy Spark
> >
> >
> > I wouldn't go quite that far.  What we have now can serve as useful input
> > to a deployment tool like Chef, but the user is then going to need to add
> > some customization or configuration within the context of that tooling to
> > get Spark installed just the way they want.  So it is not so much that
> the
> > current Debian packaging can't be used as that it has never really been
> > intended to be a completely finished product that a newcomer could, for
> > example, use to install Spark completely and quickly to Ubuntu and have a
> > fully-functional environment in which they could then run all of the
> > examples, tutorials, etc.
> >
> > Getting to that level of packaging (and maintenance) is something that
> I'm
> > not sure we want to do since that is a better fit with Bigtop and the
> > efforts of Cloudera, Horton Works, MapR, etc. to distribute Spark.
> >
> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> wrote:
> >
> >> This is a straw poll to assess whether there is support to keep and
> >> fix, or remove, the Debian packaging-related config in Spark.
> >>
> >> I see several oldish outstanding JIRAs relating to problems in the
> >> packaging:
> >>
> >> https://issues.apache.org/jira/browse/SPARK-1799
> >> https://issues.apache.org/jira/browse/SPARK-2614
> >> https://issues.apache.org/jira/browse/SPARK-3624
> >> https://issues.apache.org/jira/browse/SPARK-4436
> >> (and a similar idea about making RPMs)
> >> https://issues.apache.org/jira/browse/SPARK-665
> >>
> >> The original motivation seems related to Chef:
> >>
> >>
> >> https://issues.apache.org/jira/browse/SPARK-2614?focusedComm
> entId=14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:
> comment-tabpanel#comment-14070908
> >>
> >> Mark's recent comments cast some doubt on whether it is essential:
> >>
> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
> >>
> >> and in recent conversations I didn't hear dissent to the idea of
> removing
> >> this.
> >>
> >> Is this still useful enough to fix up? All else equal I'd like to
> >> start to walk back some of the complexity of the build, but I don't
> >> know how all-else-equal it is. Certainly, it sounds like nobody
> >> intends these to be used to actually deploy Spark.
> >>
> >> I don't doubt it's useful to someone, but can they maintain the
> >> packaging logic elsewhere?
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a114100b08b9e5a050eac35dc--

From dev-return-11533-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 20:20:04 2015
Return-Path: <dev-return-11533-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A214910AB4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 20:20:04 +0000 (UTC)
Received: (qmail 26062 invoked by uid 500); 9 Feb 2015 20:20:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25974 invoked by uid 500); 9 Feb 2015 20:20:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25961 invoked by uid 99); 9 Feb 2015 20:20:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 20:20:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 74.125.82.182 as permitted sender)
Received: from [74.125.82.182] (HELO mail-we0-f182.google.com) (74.125.82.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 20:19:59 +0000
Received: by mail-we0-f182.google.com with SMTP id l61so29300344wev.13
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 12:18:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=80IPNkD9DhS2g9WjoDwHIMslt9nr7n2AWJwuA04Kgvc=;
        b=gmBCDc9tKQcztiO9fKrm6fHg8WirdsmxKpBers+HsUDJsSvTz8icci7Ua5qcAY0v/v
         k4dm7Mfy57kQOEN2AME6hEpuNoLW3DFd07GK1KOx169pvwQP9wZg9OCsXtzmt+Fgp4Zl
         R0sth4MyJ+i16ZNZK9f2vwZxB01FXXWGdZYoAUI4JDWjPyIxssXRCn4MiLByPcwnvLAu
         ZX3haD1DYnXyhH0nqE+Mo3kQiEwDDHjZWJx1Ql+O5xz73i2Ew/iU0B1FoPTzwU7rlych
         fB0zSLzL4bPdMQ4DZFweV2t/tzAfGdzv1AvrC4QSa4hz6QpEj6CJ/3LVa3dOZpYcvb8U
         BaRA==
MIME-Version: 1.0
X-Received: by 10.180.84.100 with SMTP id x4mr2653504wiy.89.1423513088418;
 Mon, 09 Feb 2015 12:18:08 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Mon, 9 Feb 2015 12:18:08 -0800 (PST)
In-Reply-To: <CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
	<CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
	<CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
Date: Mon, 9 Feb 2015 12:18:08 -0800
Message-ID: <CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
Subject: Re: multi-line comment style
From: Xiangrui Meng <mengxr@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: shivaram@eecs.berkeley.edu, Patrick Wendell <pwendell@gmail.com>, 
	Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I like the `/* .. */` style more. Because it is easier for IDEs to
recognize it as a block comment. If you press enter in the comment
block with the `//` style, IDEs won't add `//` for you. -Xiangrui

On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com> wrote:
> We should update the style doc to reflect what we have in most places
> (which I think is //).
>
>
>
> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
> shivaram@eecs.berkeley.edu> wrote:
>
>> FWIW I like the multi-line // over /* */ from a purely style standpoint.
>> The Google Java style guide[1] has some comment about code formatting tools
>> working better with /* */ but there doesn't seem to be any strong arguments
>> for one over the other I can find
>>
>> Thanks
>> Shivaram
>>
>> [1]
>>
>> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
>>
>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Personally I have no opinion, but agree it would be nice to standardize.
>> >
>> > - Patrick
>> >
>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
>> > > One thing Marcelo pointed out to me is that the // style does not
>> > > interfere with commenting out blocks of code with /* */, which is a
>> > > small good thing. I am also accustomed to // style for multiline, and
>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
>> > > inline always looks a little funny to me.
>> > >
>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
>> kayousterhout@gmail.com>
>> > wrote:
>> > >> Hi all,
>> > >>
>> > >> The Spark Style Guide
>> > >> <
>> > https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
>> >
>> > >> says multi-line comments should formatted as:
>> > >>
>> > >> /*
>> > >>  * This is a
>> > >>  * very
>> > >>  * long comment.
>> > >>  */
>> > >>
>> > >> But in my experience, we almost always use "//" for multi-line
>> comments:
>> > >>
>> > >> // This is a
>> > >> // very
>> > >> // long comment.
>> > >>
>> > >> Here are some examples:
>> > >>
>> > >>    - Recent commit by Reynold, king of style:
>> > >>
>> >
>> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
>> > >>    - RDD.scala:
>> > >>
>> >
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
>> > >>    - DAGScheduler.scala:
>> > >>
>> >
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
>> > >>
>> > >>
>> > >> Any objections to me updating the style guide to reflect this?  As
>> with
>> > >> other style issues, I think consistency here is helpful (and
>> formatting
>> > >> multi-line comments as "//" does nicely visually distinguish code
>> > comments
>> > >> from doc comments).
>> > >>
>> > >> -Kay
>> > >
>> > > ---------------------------------------------------------------------
>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > For additional commands, e-mail: dev-help@spark.apache.org
>> > >
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11534-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 20:27:26 2015
Return-Path: <dev-return-11534-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A67A910B10
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 20:27:26 +0000 (UTC)
Received: (qmail 55859 invoked by uid 500); 9 Feb 2015 20:27:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55784 invoked by uid 500); 9 Feb 2015 20:27:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55772 invoked by uid 99); 9 Feb 2015 20:27:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 20:27:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 20:27:00 +0000
Received: by mail-wg0-f51.google.com with SMTP id k14so29080288wgh.10
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 12:25:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=+/IZzo3VO5JSyT8KuDwfTv0Bwwk907+cLMPKffNoSj0=;
        b=oMQPV/8GUwexMZhi1QOzx3+7gap5vc+2X1ITUz5LKwMok50u7VtAkK4hNCBctHymF4
         S5LUjo4DS26qvFLSkwUkE/7Ky30Gwb3q6OxJtw5BRxpaMzW4odlfDEETyXlAqnw2cI35
         7Ob67RweyUSDdyrkjbjTxeeiJ4ak/69F1NVuEMYRs2dzJhXhhoeU0gUAiJcCh6EhI30w
         0MzuHitAmD85Glsqg2up1BXrfhfA/573xZ52PSGKJL7FR46DcmPT6GbsVlrpPGdcCnUq
         2/0lOaMwTbyVKJ/WLzqLLgnL4wfmAKXhsS0zIuU9czQQUGr2/InqcjQ+v69N0A+qn5Yd
         cprg==
MIME-Version: 1.0
X-Received: by 10.180.89.131 with SMTP id bo3mr3339841wib.89.1423513528696;
 Mon, 09 Feb 2015 12:25:28 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Mon, 9 Feb 2015 12:25:28 -0800 (PST)
In-Reply-To: <CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
	<CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
	<CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
	<CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
Date: Mon, 9 Feb 2015 12:25:28 -0800
Message-ID: <CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com>
Subject: Re: multi-line comment style
From: Xiangrui Meng <mengxr@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: shivaram@eecs.berkeley.edu, Patrick Wendell <pwendell@gmail.com>, 
	Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Btw, I think allowing `/* ... */` without the leading `*` in lines is
also useful. Check this line:
https://github.com/apache/spark/pull/4259/files#diff-e9dcb3b5f3de77fc31b3aff7831110eaR55,
where we put the R commands that can reproduce the test result. It is
easier if we write in the following style:

~~~
/*
 Using the following R code to load the data and train the model using
glmnet package.

 library("glmnet")
 data <- read.csv("path", header=FALSE, stringsAsFactors=FALSE)
 features <- as.matrix(data.frame(as.numeric(data$V2), as.numeric(data$V3)))
 label <- as.numeric(data$V1)
 weights <- coef(glmnet(features, label, family="gaussian", alpha = 0,
lambda = 0))
 */
~~~

So people can copy & paste the R commands directly.

Xiangrui

On Mon, Feb 9, 2015 at 12:18 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> I like the `/* .. */` style more. Because it is easier for IDEs to
> recognize it as a block comment. If you press enter in the comment
> block with the `//` style, IDEs won't add `//` for you. -Xiangrui
>
> On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com> wrote:
>> We should update the style doc to reflect what we have in most places
>> (which I think is //).
>>
>>
>>
>> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
>> shivaram@eecs.berkeley.edu> wrote:
>>
>>> FWIW I like the multi-line // over /* */ from a purely style standpoint.
>>> The Google Java style guide[1] has some comment about code formatting tools
>>> working better with /* */ but there doesn't seem to be any strong arguments
>>> for one over the other I can find
>>>
>>> Thanks
>>> Shivaram
>>>
>>> [1]
>>>
>>> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
>>>
>>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>> > Personally I have no opinion, but agree it would be nice to standardize.
>>> >
>>> > - Patrick
>>> >
>>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
>>> > > One thing Marcelo pointed out to me is that the // style does not
>>> > > interfere with commenting out blocks of code with /* */, which is a
>>> > > small good thing. I am also accustomed to // style for multiline, and
>>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
>>> > > inline always looks a little funny to me.
>>> > >
>>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
>>> kayousterhout@gmail.com>
>>> > wrote:
>>> > >> Hi all,
>>> > >>
>>> > >> The Spark Style Guide
>>> > >> <
>>> > https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
>>> >
>>> > >> says multi-line comments should formatted as:
>>> > >>
>>> > >> /*
>>> > >>  * This is a
>>> > >>  * very
>>> > >>  * long comment.
>>> > >>  */
>>> > >>
>>> > >> But in my experience, we almost always use "//" for multi-line
>>> comments:
>>> > >>
>>> > >> // This is a
>>> > >> // very
>>> > >> // long comment.
>>> > >>
>>> > >> Here are some examples:
>>> > >>
>>> > >>    - Recent commit by Reynold, king of style:
>>> > >>
>>> >
>>> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
>>> > >>    - RDD.scala:
>>> > >>
>>> >
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
>>> > >>    - DAGScheduler.scala:
>>> > >>
>>> >
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
>>> > >>
>>> > >>
>>> > >> Any objections to me updating the style guide to reflect this?  As
>>> with
>>> > >> other style issues, I think consistency here is helpful (and
>>> formatting
>>> > >> multi-line comments as "//" does nicely visually distinguish code
>>> > comments
>>> > >> from doc comments).
>>> > >>
>>> > >> -Kay
>>> > >
>>> > > ---------------------------------------------------------------------
>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > > For additional commands, e-mail: dev-help@spark.apache.org
>>> > >
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>> >
>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11535-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 21:27:16 2015
Return-Path: <dev-return-11535-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B1F4610EF4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 21:27:16 +0000 (UTC)
Received: (qmail 50153 invoked by uid 500); 9 Feb 2015 21:27:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50081 invoked by uid 500); 9 Feb 2015 21:27:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50070 invoked by uid 99); 9 Feb 2015 21:27:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:27:15 +0000
X-ASF-Spam-Status: No, hits=1.3 required=10.0
	tests=URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: unknown (athena.apache.org: error in processing during lookup of mark.khaitman@chango.com)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:27:10 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id C357D135D667
	for <dev@spark.apache.org>; Mon,  9 Feb 2015 13:26:48 -0800 (PST)
Date: Mon, 9 Feb 2015 14:26:48 -0700 (MST)
From: mkhaitman <mark.khaitman@chango.com>
To: dev@spark.apache.org
Message-ID: <1423517208678-10533.post@n3.nabble.com>
Subject: pyspark.daemon issues?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I've noticed a couple oddities with the pyspark.daemons which are causing us
a bit of memory problems within some of our heavy spark jobs, especially
when they run at the same time...

It seems that there is typically a 1-to-1 ratio of pyspark.daemons to cores
per executor during aggregations. By default the spark.python.worker.memory
is left at the default of 512MB, after which, the remainder of the
aggregations are supposed to spill to disk. 

However:
          *1)* I'm not entirely sure what cases would result in random
numbers of pyspark daemons which do not respect the python worker memory
limit. I've seen some go up to as far as 2GB each (well over the 512MB
limit) which is when we run into some crazy memory problems for jobs making
use of many cores on each executor. To be clear here, they ARE spilling to
disk as well, but also blowing past the memory limits at the same time
somehow. 

          *2)* Another scenario specifically relates to when we want to join
RDDs, where for example, say there are 4 cores per executor, and therefore 4
pyspark daemons during most aggregations. It seems that if a Join occurs, it
will spawn up 4 additional pyspark daemons as opposed to simply re-using the
ones that were already present during the aggregation stage that occurred
before it. This, combined with the case where the python worker memory limit
is not strictly respected, can pose problems for using way more memory per
node. 

The fact that the python worker memory appears to use memory *outside* of
the executor memory is what poses the biggest challenge for preventing
memory depletion on a node. Is there something obvious, or some environment
variable I may have missed that could potentially help with one/both of the
above memory concerns? Alternatively, any suggestions would be greatly
appreciated! :)

Thanks,
Mark.






--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/pyspark-daemon-issues-tp10533.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11536-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 21:33:10 2015
Return-Path: <dev-return-11536-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9DCCA10F29
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 21:33:10 +0000 (UTC)
Received: (qmail 61930 invoked by uid 500); 9 Feb 2015 21:33:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61799 invoked by uid 500); 9 Feb 2015 21:33:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61072 invoked by uid 99); 9 Feb 2015 21:33:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:33:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:32:55 +0000
Received: by mail-ob0-f176.google.com with SMTP id wo20so28155076obc.7;
        Mon, 09 Feb 2015 13:31:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=9V6Vep2F8EnOTTsIVLgv3PAc5f/bbUujuBLeguVhzhQ=;
        b=shJcT5oTB3tOVoLYQhhStZ6wW093byqHZ2zTKdua0r06GpKyPCjDAbXpDdsTiT6nF8
         1iSStQTxJsuJwwzPjHfVPrxC7TldoNGvp8XqjWcfCwRpBTHQPmDFAJghtwRR/IjMKkYd
         ZOEWBXXKgaHkec9iuKnjvsdzBkpLXFHA/aEf4QZx+bclPuUHZQ3tdFxDkDkVt3gnXzlP
         ESFaaDQhG+q7NGn9lsvDbeqdKWOQDvt+z+8ib43FXFeG5egexsYrmsSs5zssZ06UCaMw
         BoRaD4BPgdErCUa5CjBeDAO+Xtp/3/Hfk7kQCS99vtlWbTHz9jq2Ma8iVVFHDqJ/bp/U
         8v7A==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr5817622oit.100.1423517465338;
 Mon, 09 Feb 2015 13:31:05 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 13:31:05 -0800 (PST)
Date: Mon, 9 Feb 2015 13:31:05 -0800
Message-ID: <CABPQxsuVUc_2DdYo6k4YZ8vn=9Sg+zD+PFfigk4njo6dztthFQ@mail.gmail.com>
Subject: [ANNOUNCE] Apache Spark 1.2.1 Released
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hi All,

I've just posted the 1.2.1 maintenance release of Apache Spark. We
recommend all 1.2.0 users upgrade to this release, as this release
includes stability fixes across all components of Spark.

- Download this release: http://spark.apache.org/downloads.html
- View the release notes:
http://spark.apache.org/releases/spark-release-1-2-1.html
- Full list of JIRA issues resolved in this release: http://s.apache.org/Mpn

Thanks to everyone who helped work on this release!

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11537-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 21:34:13 2015
Return-Path: <dev-return-11537-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E90B010F3B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 21:34:13 +0000 (UTC)
Received: (qmail 67426 invoked by uid 500); 9 Feb 2015 21:34:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67355 invoked by uid 500); 9 Feb 2015 21:34:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67338 invoked by uid 99); 9 Feb 2015 21:34:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:34:12 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.182 as permitted sender)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:34:08 +0000
Received: by mail-ob0-f182.google.com with SMTP id nt9so27503447obb.13
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 13:33:48 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HapZmDcCSHtuf3RwU617wUaHWPy60zVcZlIxsI9v4ls=;
        b=Vfac+cPApwmS8pjqhXvJfPWNBB0qU4uW/lJZ9gvi6BGLn6hJbK1rXV3/BLPZx7R51S
         PlQ2pvAxuKScd2M5lUruE2uoLIM59jkNxe1HdsyVC7wNQ4s89oto9ZxOcll9A0NPU4LY
         OcwUildNuxz4q+MXsjp0MhNzlT7Hss3l5rEm9EhLWMDgj4AISknVtGTzD4b1WSNKOBQB
         80eoPDRSs7XPfAS/dkjfBBkbKP/Phpkbs12+HRCNcHfCfemX8hdNFHUPVkBAxwArJ0Ft
         exiEmy5jz4y8VdDDhIUJKoxwysq5RHk58M72EdwLegoZs97DaORfhZ/TX5g4vrSQGlMN
         NyVA==
MIME-Version: 1.0
X-Received: by 10.60.133.137 with SMTP id pc9mr13543642oeb.68.1423517628585;
 Mon, 09 Feb 2015 13:33:48 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 13:33:48 -0800 (PST)
In-Reply-To: <CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
	<CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
	<CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
	<CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
	<CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com>
Date: Mon, 9 Feb 2015 13:33:48 -0800
Message-ID: <CABPQxsvHyH7Qfvm7D0TbGL5tDThfPzkKOqNL31_bvRf21FZj0w@mail.gmail.com>
Subject: Re: multi-line comment style
From: Patrick Wendell <pwendell@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, 
	Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Clearly there isn't a strictly optimal commenting format (pro's and
cons for both '//' and '/*'). My thought is for consistency we should
just chose one and put in the style guide.

On Mon, Feb 9, 2015 at 12:25 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> Btw, I think allowing `/* ... */` without the leading `*` in lines is
> also useful. Check this line:
> https://github.com/apache/spark/pull/4259/files#diff-e9dcb3b5f3de77fc31b3aff7831110eaR55,
> where we put the R commands that can reproduce the test result. It is
> easier if we write in the following style:
>
> ~~~
> /*
>  Using the following R code to load the data and train the model using
> glmnet package.
>
>  library("glmnet")
>  data <- read.csv("path", header=FALSE, stringsAsFactors=FALSE)
>  features <- as.matrix(data.frame(as.numeric(data$V2), as.numeric(data$V3)))
>  label <- as.numeric(data$V1)
>  weights <- coef(glmnet(features, label, family="gaussian", alpha = 0,
> lambda = 0))
>  */
> ~~~
>
> So people can copy & paste the R commands directly.
>
> Xiangrui
>
> On Mon, Feb 9, 2015 at 12:18 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>> I like the `/* .. */` style more. Because it is easier for IDEs to
>> recognize it as a block comment. If you press enter in the comment
>> block with the `//` style, IDEs won't add `//` for you. -Xiangrui
>>
>> On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com> wrote:
>>> We should update the style doc to reflect what we have in most places
>>> (which I think is //).
>>>
>>>
>>>
>>> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
>>> shivaram@eecs.berkeley.edu> wrote:
>>>
>>>> FWIW I like the multi-line // over /* */ from a purely style standpoint.
>>>> The Google Java style guide[1] has some comment about code formatting tools
>>>> working better with /* */ but there doesn't seem to be any strong arguments
>>>> for one over the other I can find
>>>>
>>>> Thanks
>>>> Shivaram
>>>>
>>>> [1]
>>>>
>>>> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
>>>>
>>>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>>
>>>> > Personally I have no opinion, but agree it would be nice to standardize.
>>>> >
>>>> > - Patrick
>>>> >
>>>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com> wrote:
>>>> > > One thing Marcelo pointed out to me is that the // style does not
>>>> > > interfere with commenting out blocks of code with /* */, which is a
>>>> > > small good thing. I am also accustomed to // style for multiline, and
>>>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */ style
>>>> > > inline always looks a little funny to me.
>>>> > >
>>>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
>>>> kayousterhout@gmail.com>
>>>> > wrote:
>>>> > >> Hi all,
>>>> > >>
>>>> > >> The Spark Style Guide
>>>> > >> <
>>>> > https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
>>>> >
>>>> > >> says multi-line comments should formatted as:
>>>> > >>
>>>> > >> /*
>>>> > >>  * This is a
>>>> > >>  * very
>>>> > >>  * long comment.
>>>> > >>  */
>>>> > >>
>>>> > >> But in my experience, we almost always use "//" for multi-line
>>>> comments:
>>>> > >>
>>>> > >> // This is a
>>>> > >> // very
>>>> > >> // long comment.
>>>> > >>
>>>> > >> Here are some examples:
>>>> > >>
>>>> > >>    - Recent commit by Reynold, king of style:
>>>> > >>
>>>> >
>>>> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
>>>> > >>    - RDD.scala:
>>>> > >>
>>>> >
>>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
>>>> > >>    - DAGScheduler.scala:
>>>> > >>
>>>> >
>>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
>>>> > >>
>>>> > >>
>>>> > >> Any objections to me updating the style guide to reflect this?  As
>>>> with
>>>> > >> other style issues, I think consistency here is helpful (and
>>>> formatting
>>>> > >> multi-line comments as "//" does nicely visually distinguish code
>>>> > comments
>>>> > >> from doc comments).
>>>> > >>
>>>> > >> -Kay
>>>> > >
>>>> > > ---------------------------------------------------------------------
>>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> > > For additional commands, e-mail: dev-help@spark.apache.org
>>>> > >
>>>> >
>>>> > ---------------------------------------------------------------------
>>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>>> >
>>>> >
>>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11538-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 21:38:45 2015
Return-Path: <dev-return-11538-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0FF7810F6E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 21:38:45 +0000 (UTC)
Received: (qmail 79680 invoked by uid 500); 9 Feb 2015 21:38:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79618 invoked by uid 500); 9 Feb 2015 21:38:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79602 invoked by uid 99); 9 Feb 2015 21:38:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:38:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:38:10 +0000
Received: by mail-qg0-f53.google.com with SMTP id f51so23817936qge.12
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 13:37:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=qKgmtxj8zVL+bu24bMrZ7X4QnTfp1SmaeukbFuCLXkU=;
        b=DU/Se9ayH7ecAj3VV7ISf+z142NbsteODAK7RAU8Jn82AZlrxzg5EXi441xrGbln8f
         lbtuBRKFInFp80tKqlmPpS+FeRTM/dee/hb4DD1Z4K9BnqHMK0xRlTaQeGBucyXAbqkQ
         XMovmGGxGzGhgx3RWSXESa55IHiisbVIxO2EkmhJSARwlAPM8Zt5Lmaoh+nDutlufcyR
         IMVQvYexroUc82oAxomSfr2mM66rfr8gEGViaAl5ZleD2U+XDnoDBCRjsKiyf/XhdWm2
         bSKYqEOSv4ELO91A+RSTyRoYo2vwDxNNZ1C8LHEA4DxzuAJxT0vJqu5/8/CFhD9Ik5lE
         /c4Q==
X-Gm-Message-State: ALoCoQnJDTZ4QGzwYhzD8zIud5BjMZiJnrlkb1De9YiShk7RMHqsdleYxTIIfVVmdJCKxYcODCYI
X-Received: by 10.140.102.142 with SMTP id w14mr42920059qge.88.1423517822908;
 Mon, 09 Feb 2015 13:37:02 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Mon, 9 Feb 2015 13:36:42 -0800 (PST)
In-Reply-To: <CABPQxsvHyH7Qfvm7D0TbGL5tDThfPzkKOqNL31_bvRf21FZj0w@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
 <CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
 <CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
 <CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
 <CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
 <CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
 <CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com> <CABPQxsvHyH7Qfvm7D0TbGL5tDThfPzkKOqNL31_bvRf21FZj0w@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 9 Feb 2015 13:36:42 -0800
Message-ID: <CAPh_B=YoOLFPRwMvh8nN0CPzZ2hUPbsBv7RhWvLkBsk+Fhw4JQ@mail.gmail.com>
Subject: Re: multi-line comment style
To: Patrick Wendell <pwendell@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, 
	Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c163e02a93ca050eae92b9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c163e02a93ca050eae92b9
Content-Type: text/plain; charset=UTF-8

Why don't we just pick // as the default (by encouraging it in the style
guide), since it is mostly used, and then do not disallow /* */? I don't
think it is that big of a deal to have slightly deviations here since it is
dead simple to understand what's going on.


On Mon, Feb 9, 2015 at 1:33 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Clearly there isn't a strictly optimal commenting format (pro's and
> cons for both '//' and '/*'). My thought is for consistency we should
> just chose one and put in the style guide.
>
> On Mon, Feb 9, 2015 at 12:25 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> > Btw, I think allowing `/* ... */` without the leading `*` in lines is
> > also useful. Check this line:
> >
> https://github.com/apache/spark/pull/4259/files#diff-e9dcb3b5f3de77fc31b3aff7831110eaR55
> ,
> > where we put the R commands that can reproduce the test result. It is
> > easier if we write in the following style:
> >
> > ~~~
> > /*
> >  Using the following R code to load the data and train the model using
> > glmnet package.
> >
> >  library("glmnet")
> >  data <- read.csv("path", header=FALSE, stringsAsFactors=FALSE)
> >  features <- as.matrix(data.frame(as.numeric(data$V2),
> as.numeric(data$V3)))
> >  label <- as.numeric(data$V1)
> >  weights <- coef(glmnet(features, label, family="gaussian", alpha = 0,
> > lambda = 0))
> >  */
> > ~~~
> >
> > So people can copy & paste the R commands directly.
> >
> > Xiangrui
> >
> > On Mon, Feb 9, 2015 at 12:18 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> >> I like the `/* .. */` style more. Because it is easier for IDEs to
> >> recognize it as a block comment. If you press enter in the comment
> >> block with the `//` style, IDEs won't add `//` for you. -Xiangrui
> >>
> >> On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >>> We should update the style doc to reflect what we have in most places
> >>> (which I think is //).
> >>>
> >>>
> >>>
> >>> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
> >>> shivaram@eecs.berkeley.edu> wrote:
> >>>
> >>>> FWIW I like the multi-line // over /* */ from a purely style
> standpoint.
> >>>> The Google Java style guide[1] has some comment about code formatting
> tools
> >>>> working better with /* */ but there doesn't seem to be any strong
> arguments
> >>>> for one over the other I can find
> >>>>
> >>>> Thanks
> >>>> Shivaram
> >>>>
> >>>> [1]
> >>>>
> >>>>
> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
> >>>>
> >>>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com>
> >>>> wrote:
> >>>>
> >>>> > Personally I have no opinion, but agree it would be nice to
> standardize.
> >>>> >
> >>>> > - Patrick
> >>>> >
> >>>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com>
> wrote:
> >>>> > > One thing Marcelo pointed out to me is that the // style does not
> >>>> > > interfere with commenting out blocks of code with /* */, which is
> a
> >>>> > > small good thing. I am also accustomed to // style for multiline,
> and
> >>>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */
> style
> >>>> > > inline always looks a little funny to me.
> >>>> > >
> >>>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
> >>>> kayousterhout@gmail.com>
> >>>> > wrote:
> >>>> > >> Hi all,
> >>>> > >>
> >>>> > >> The Spark Style Guide
> >>>> > >> <
> >>>> >
> https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
> >>>> >
> >>>> > >> says multi-line comments should formatted as:
> >>>> > >>
> >>>> > >> /*
> >>>> > >>  * This is a
> >>>> > >>  * very
> >>>> > >>  * long comment.
> >>>> > >>  */
> >>>> > >>
> >>>> > >> But in my experience, we almost always use "//" for multi-line
> >>>> comments:
> >>>> > >>
> >>>> > >> // This is a
> >>>> > >> // very
> >>>> > >> // long comment.
> >>>> > >>
> >>>> > >> Here are some examples:
> >>>> > >>
> >>>> > >>    - Recent commit by Reynold, king of style:
> >>>> > >>
> >>>> >
> >>>>
> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
> >>>> > >>    - RDD.scala:
> >>>> > >>
> >>>> >
> >>>>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
> >>>> > >>    - DAGScheduler.scala:
> >>>> > >>
> >>>> >
> >>>>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
> >>>> > >>
> >>>> > >>
> >>>> > >> Any objections to me updating the style guide to reflect this?
> As
> >>>> with
> >>>> > >> other style issues, I think consistency here is helpful (and
> >>>> formatting
> >>>> > >> multi-line comments as "//" does nicely visually distinguish code
> >>>> > comments
> >>>> > >> from doc comments).
> >>>> > >>
> >>>> > >> -Kay
> >>>> > >
> >>>> > >
> ---------------------------------------------------------------------
> >>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>> > > For additional commands, e-mail: dev-help@spark.apache.org
> >>>> > >
> >>>> >
> >>>> >
> ---------------------------------------------------------------------
> >>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>> > For additional commands, e-mail: dev-help@spark.apache.org
> >>>> >
> >>>> >
> >>>>
>

--001a11c163e02a93ca050eae92b9--

From dev-return-11539-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 21:49:32 2015
Return-Path: <dev-return-11539-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7F02210FCA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 21:49:32 +0000 (UTC)
Received: (qmail 14262 invoked by uid 500); 9 Feb 2015 21:49:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14187 invoked by uid 500); 9 Feb 2015 21:49:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14173 invoked by uid 99); 9 Feb 2015 21:49:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:49:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 21:49:06 +0000
Received: by lams18 with SMTP id s18so16459210lam.13
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 13:48:44 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=snlv9vjqqqZXWuippCeHRoHpXDGfzVdQ5csVGPGZpD0=;
        b=B2uWYnjipv8j6+GTuPjjfOEI6AKNNxo0+MPoKnny5TGzLJEO9nRu6Jj1Rg0QvLY/8t
         Kg7dJv2MesQUnCePlm70DrtgbCxUF1cYXMjkRNU3lQXX+AUXfka+/oEIdU5FAfmVsA2z
         2mjQ2JXxbX/0GRpBwz3b3P0p2uqaM1R0HKfmjimamrcoQrrpYcXJnHfs8DHO/QwnM+k0
         6bngUFDDiU+gvdQ7wvjXgjopJj4ace8xmIS0llPrtbwKefmhsrMc8ZELakIc5OUEvHJL
         uqjF8cQWcubYNbhon+qWFYe23P49NbAVXrln3noo2PhNmWbAODpa22wEX98ubE1cpYve
         ug3g==
X-Gm-Message-State: ALoCoQlIiVHMknQh3ydgjci3LExMhuhCNyHD0lfqyAPMM7wH0zth0OtV4E3g5yFUAD0d6HKzctEY
MIME-Version: 1.0
X-Received: by 10.112.212.42 with SMTP id nh10mr1052596lbc.102.1423518524527;
 Mon, 09 Feb 2015 13:48:44 -0800 (PST)
Received: by 10.112.204.225 with HTTP; Mon, 9 Feb 2015 13:48:44 -0800 (PST)
In-Reply-To: <CAPh_B=YoOLFPRwMvh8nN0CPzZ2hUPbsBv7RhWvLkBsk+Fhw4JQ@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
	<CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
	<CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
	<CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
	<CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com>
	<CABPQxsvHyH7Qfvm7D0TbGL5tDThfPzkKOqNL31_bvRf21FZj0w@mail.gmail.com>
	<CAPh_B=YoOLFPRwMvh8nN0CPzZ2hUPbsBv7RhWvLkBsk+Fhw4JQ@mail.gmail.com>
Date: Mon, 9 Feb 2015 13:48:44 -0800
Message-ID: <CAMJOb8nNp1+3vzyvMUO1U3DoDnadyXLWbvdog7XxrPyAGHrxrg@mail.gmail.com>
Subject: Re: multi-line comment style
From: Andrew Or <andrew@databricks.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Xiangrui Meng <mengxr@gmail.com>, 
	Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, Sean Owen <sowen@cloudera.com>, 
	Kay Ousterhout <kayousterhout@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134c48afc6e68050eaebb19
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134c48afc6e68050eaebb19
Content-Type: text/plain; charset=UTF-8

In my experience I find it much more natural to use // for short multi-line
comments (2 or 3 lines), and /* */ for long multi-line comments involving
one or more paragraphs. For short multi-line comments, there is no reason
not to use // if it just so happens that your first line exceeded 100
characters and you have to wrap it. For long multi-line comments, however,
using // all the way looks really awkward especially if you have multiple
paragraphs.

Thus, I would actually suggest that we don't try to pick a favorite and
document that both are acceptable. I don't expect developers to follow my
exact usage (i.e. with a tipping point of 2-3 lines) so I wouldn't enforce
anything specific either.

2015-02-09 13:36 GMT-08:00 Reynold Xin <rxin@databricks.com>:

> Why don't we just pick // as the default (by encouraging it in the style
> guide), since it is mostly used, and then do not disallow /* */? I don't
> think it is that big of a deal to have slightly deviations here since it is
> dead simple to understand what's going on.
>
>
> On Mon, Feb 9, 2015 at 1:33 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Clearly there isn't a strictly optimal commenting format (pro's and
> > cons for both '//' and '/*'). My thought is for consistency we should
> > just chose one and put in the style guide.
> >
> > On Mon, Feb 9, 2015 at 12:25 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> > > Btw, I think allowing `/* ... */` without the leading `*` in lines is
> > > also useful. Check this line:
> > >
> >
> https://github.com/apache/spark/pull/4259/files#diff-e9dcb3b5f3de77fc31b3aff7831110eaR55
> > ,
> > > where we put the R commands that can reproduce the test result. It is
> > > easier if we write in the following style:
> > >
> > > ~~~
> > > /*
> > >  Using the following R code to load the data and train the model using
> > > glmnet package.
> > >
> > >  library("glmnet")
> > >  data <- read.csv("path", header=FALSE, stringsAsFactors=FALSE)
> > >  features <- as.matrix(data.frame(as.numeric(data$V2),
> > as.numeric(data$V3)))
> > >  label <- as.numeric(data$V1)
> > >  weights <- coef(glmnet(features, label, family="gaussian", alpha = 0,
> > > lambda = 0))
> > >  */
> > > ~~~
> > >
> > > So people can copy & paste the R commands directly.
> > >
> > > Xiangrui
> > >
> > > On Mon, Feb 9, 2015 at 12:18 PM, Xiangrui Meng <mengxr@gmail.com>
> wrote:
> > >> I like the `/* .. */` style more. Because it is easier for IDEs to
> > >> recognize it as a block comment. If you press enter in the comment
> > >> block with the `//` style, IDEs won't add `//` for you. -Xiangrui
> > >>
> > >> On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com>
> > wrote:
> > >>> We should update the style doc to reflect what we have in most places
> > >>> (which I think is //).
> > >>>
> > >>>
> > >>>
> > >>> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
> > >>> shivaram@eecs.berkeley.edu> wrote:
> > >>>
> > >>>> FWIW I like the multi-line // over /* */ from a purely style
> > standpoint.
> > >>>> The Google Java style guide[1] has some comment about code
> formatting
> > tools
> > >>>> working better with /* */ but there doesn't seem to be any strong
> > arguments
> > >>>> for one over the other I can find
> > >>>>
> > >>>> Thanks
> > >>>> Shivaram
> > >>>>
> > >>>> [1]
> > >>>>
> > >>>>
> >
> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
> > >>>>
> > >>>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <pwendell@gmail.com
> >
> > >>>> wrote:
> > >>>>
> > >>>> > Personally I have no opinion, but agree it would be nice to
> > standardize.
> > >>>> >
> > >>>> > - Patrick
> > >>>> >
> > >>>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com>
> > wrote:
> > >>>> > > One thing Marcelo pointed out to me is that the // style does
> not
> > >>>> > > interfere with commenting out blocks of code with /* */, which
> is
> > a
> > >>>> > > small good thing. I am also accustomed to // style for
> multiline,
> > and
> > >>>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /* */
> > style
> > >>>> > > inline always looks a little funny to me.
> > >>>> > >
> > >>>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
> > >>>> kayousterhout@gmail.com>
> > >>>> > wrote:
> > >>>> > >> Hi all,
> > >>>> > >>
> > >>>> > >> The Spark Style Guide
> > >>>> > >> <
> > >>>> >
> > https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
> > >>>> >
> > >>>> > >> says multi-line comments should formatted as:
> > >>>> > >>
> > >>>> > >> /*
> > >>>> > >>  * This is a
> > >>>> > >>  * very
> > >>>> > >>  * long comment.
> > >>>> > >>  */
> > >>>> > >>
> > >>>> > >> But in my experience, we almost always use "//" for multi-line
> > >>>> comments:
> > >>>> > >>
> > >>>> > >> // This is a
> > >>>> > >> // very
> > >>>> > >> // long comment.
> > >>>> > >>
> > >>>> > >> Here are some examples:
> > >>>> > >>
> > >>>> > >>    - Recent commit by Reynold, king of style:
> > >>>> > >>
> > >>>> >
> > >>>>
> >
> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
> > >>>> > >>    - RDD.scala:
> > >>>> > >>
> > >>>> >
> > >>>>
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
> > >>>> > >>    - DAGScheduler.scala:
> > >>>> > >>
> > >>>> >
> > >>>>
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
> > >>>> > >>
> > >>>> > >>
> > >>>> > >> Any objections to me updating the style guide to reflect this?
> > As
> > >>>> with
> > >>>> > >> other style issues, I think consistency here is helpful (and
> > >>>> formatting
> > >>>> > >> multi-line comments as "//" does nicely visually distinguish
> code
> > >>>> > comments
> > >>>> > >> from doc comments).
> > >>>> > >>
> > >>>> > >> -Kay
> > >>>> > >
> > >>>> > >
> > ---------------------------------------------------------------------
> > >>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >>>> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >>>> > >
> > >>>> >
> > >>>> >
> > ---------------------------------------------------------------------
> > >>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >>>> > For additional commands, e-mail: dev-help@spark.apache.org
> > >>>> >
> > >>>> >
> > >>>>
> >
>

--001a1134c48afc6e68050eaebb19--

From dev-return-11540-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 22:24:43 2015
Return-Path: <dev-return-11540-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B5D1F101E0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 22:24:43 +0000 (UTC)
Received: (qmail 20760 invoked by uid 500); 9 Feb 2015 22:24:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20694 invoked by uid 500); 9 Feb 2015 22:24:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20683 invoked by uid 99); 9 Feb 2015 22:24:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 22:24:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandy.ryza@cloudera.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 22:24:38 +0000
Received: by iecrd18 with SMTP id rd18so8213813iec.8
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 14:22:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=3JufLieAsq/isffdc/6eOWdtPlPRquK5D2iaawuw4go=;
        b=HCVQ3P9Zd2jdScLaUnOwcKeYgqiiHjsOrwd8qxMkb10H7pqwVsh2KQIpNaKHXNLz7g
         STbc3ViCBR3U7V7DDf2znisPF1B2tN1NieB4tUru5I8dyeWbc4Cdb/p8dgk8dULzBkRw
         QUHZpayrKBRh8vE/LVggRDrED0SzoJG06d35tDLjhSrvGU9dPiuCKWUTBZ1oUqLdvUiL
         UqHDvwqjKh0E+wq00vTnwApkAXj2M4Fd5ovVoQ5F5hzndqyzCMlRoTHRwD0pWel5CduD
         kxulv/enm5PPIlThM+8QNcIkjvwZP4Ini1ZZnO3GHTjtPjkgP8MKhe7CHK0k5CnslU3h
         35Fg==
X-Gm-Message-State: ALoCoQneQ/mb43IDKHi6jDEVDqYu8Ho04JL57FYHw3HCgiLvhjr2uu+Ka4cDnzc40JabQfHSoLhx
MIME-Version: 1.0
X-Received: by 10.107.19.38 with SMTP id b38mr28141340ioj.35.1423520568112;
 Mon, 09 Feb 2015 14:22:48 -0800 (PST)
Received: by 10.36.28.208 with HTTP; Mon, 9 Feb 2015 14:22:47 -0800 (PST)
In-Reply-To: <CAMJOb8nNp1+3vzyvMUO1U3DoDnadyXLWbvdog7XxrPyAGHrxrg@mail.gmail.com>
References: <CAKJXNjGB4fMDX1qtE3UgmE5mr1NgmEAfnBROGWaxz8N5uMWUQA@mail.gmail.com>
	<CAMAsSdJ8=7KHFNBuZY_qMHP+b881YQ+OxEQDRKpn9Cwj2ZeNfA@mail.gmail.com>
	<CABPQxsvXmm+=FrySgrpsJR5mzPnOzGtaN5_ZDnwau7nk=GnGag@mail.gmail.com>
	<CAKx7Bf-u4iNZWB5e8v2zEKutMtp_qFKO+oW_BB1CNn9zz_YYNg@mail.gmail.com>
	<CAPh_B=a11kboEb65bj12i5txgipDSJvnMhwbHzYLfPuBhGYEVw@mail.gmail.com>
	<CAJgQjQ-0QFXF1gABHkyaPfW82yjPcuWk_Sqyk5B9i-+16pMC9w@mail.gmail.com>
	<CAJgQjQ8=4HPhKmfqNy2ZxWmi1-8RxfScERuK5+8Xf2ZOLqvh5A@mail.gmail.com>
	<CABPQxsvHyH7Qfvm7D0TbGL5tDThfPzkKOqNL31_bvRf21FZj0w@mail.gmail.com>
	<CAPh_B=YoOLFPRwMvh8nN0CPzZ2hUPbsBv7RhWvLkBsk+Fhw4JQ@mail.gmail.com>
	<CAMJOb8nNp1+3vzyvMUO1U3DoDnadyXLWbvdog7XxrPyAGHrxrg@mail.gmail.com>
Date: Mon, 9 Feb 2015 14:22:47 -0800
Message-ID: <CACBYxKJY0WGz2bbVj747s7dj91tvWQysF7S_Cmc6US+YDqnSUw@mail.gmail.com>
Subject: Re: multi-line comment style
From: Sandy Ryza <sandy.ryza@cloudera.com>
To: Andrew Or <andrew@databricks.com>
Cc: Reynold Xin <rxin@databricks.com>, Patrick Wendell <pwendell@gmail.com>, 
	Xiangrui Meng <mengxr@gmail.com>, Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, 
	Sean Owen <sowen@cloudera.com>, Kay Ousterhout <kayousterhout@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113eeb18cb30af050eaf358c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113eeb18cb30af050eaf358c
Content-Type: text/plain; charset=UTF-8

+1 to what Andrew said, I think both make sense in different situations and
trusting developer discretion here is reasonable.

On Mon, Feb 9, 2015 at 1:48 PM, Andrew Or <andrew@databricks.com> wrote:

> In my experience I find it much more natural to use // for short multi-line
> comments (2 or 3 lines), and /* */ for long multi-line comments involving
> one or more paragraphs. For short multi-line comments, there is no reason
> not to use // if it just so happens that your first line exceeded 100
> characters and you have to wrap it. For long multi-line comments, however,
> using // all the way looks really awkward especially if you have multiple
> paragraphs.
>
> Thus, I would actually suggest that we don't try to pick a favorite and
> document that both are acceptable. I don't expect developers to follow my
> exact usage (i.e. with a tipping point of 2-3 lines) so I wouldn't enforce
> anything specific either.
>
> 2015-02-09 13:36 GMT-08:00 Reynold Xin <rxin@databricks.com>:
>
> > Why don't we just pick // as the default (by encouraging it in the style
> > guide), since it is mostly used, and then do not disallow /* */? I don't
> > think it is that big of a deal to have slightly deviations here since it
> is
> > dead simple to understand what's going on.
> >
> >
> > On Mon, Feb 9, 2015 at 1:33 PM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> >
> > > Clearly there isn't a strictly optimal commenting format (pro's and
> > > cons for both '//' and '/*'). My thought is for consistency we should
> > > just chose one and put in the style guide.
> > >
> > > On Mon, Feb 9, 2015 at 12:25 PM, Xiangrui Meng <mengxr@gmail.com>
> wrote:
> > > > Btw, I think allowing `/* ... */` without the leading `*` in lines is
> > > > also useful. Check this line:
> > > >
> > >
> >
> https://github.com/apache/spark/pull/4259/files#diff-e9dcb3b5f3de77fc31b3aff7831110eaR55
> > > ,
> > > > where we put the R commands that can reproduce the test result. It is
> > > > easier if we write in the following style:
> > > >
> > > > ~~~
> > > > /*
> > > >  Using the following R code to load the data and train the model
> using
> > > > glmnet package.
> > > >
> > > >  library("glmnet")
> > > >  data <- read.csv("path", header=FALSE, stringsAsFactors=FALSE)
> > > >  features <- as.matrix(data.frame(as.numeric(data$V2),
> > > as.numeric(data$V3)))
> > > >  label <- as.numeric(data$V1)
> > > >  weights <- coef(glmnet(features, label, family="gaussian", alpha =
> 0,
> > > > lambda = 0))
> > > >  */
> > > > ~~~
> > > >
> > > > So people can copy & paste the R commands directly.
> > > >
> > > > Xiangrui
> > > >
> > > > On Mon, Feb 9, 2015 at 12:18 PM, Xiangrui Meng <mengxr@gmail.com>
> > wrote:
> > > >> I like the `/* .. */` style more. Because it is easier for IDEs to
> > > >> recognize it as a block comment. If you press enter in the comment
> > > >> block with the `//` style, IDEs won't add `//` for you. -Xiangrui
> > > >>
> > > >> On Wed, Feb 4, 2015 at 2:15 PM, Reynold Xin <rxin@databricks.com>
> > > wrote:
> > > >>> We should update the style doc to reflect what we have in most
> places
> > > >>> (which I think is //).
> > > >>>
> > > >>>
> > > >>>
> > > >>> On Wed, Feb 4, 2015 at 2:09 PM, Shivaram Venkataraman <
> > > >>> shivaram@eecs.berkeley.edu> wrote:
> > > >>>
> > > >>>> FWIW I like the multi-line // over /* */ from a purely style
> > > standpoint.
> > > >>>> The Google Java style guide[1] has some comment about code
> > formatting
> > > tools
> > > >>>> working better with /* */ but there doesn't seem to be any strong
> > > arguments
> > > >>>> for one over the other I can find
> > > >>>>
> > > >>>> Thanks
> > > >>>> Shivaram
> > > >>>>
> > > >>>> [1]
> > > >>>>
> > > >>>>
> > >
> >
> https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.8.6.1-block-comment-style
> > > >>>>
> > > >>>> On Wed, Feb 4, 2015 at 2:05 PM, Patrick Wendell <
> pwendell@gmail.com
> > >
> > > >>>> wrote:
> > > >>>>
> > > >>>> > Personally I have no opinion, but agree it would be nice to
> > > standardize.
> > > >>>> >
> > > >>>> > - Patrick
> > > >>>> >
> > > >>>> > On Wed, Feb 4, 2015 at 1:58 PM, Sean Owen <sowen@cloudera.com>
> > > wrote:
> > > >>>> > > One thing Marcelo pointed out to me is that the // style does
> > not
> > > >>>> > > interfere with commenting out blocks of code with /* */, which
> > is
> > > a
> > > >>>> > > small good thing. I am also accustomed to // style for
> > multiline,
> > > and
> > > >>>> > > reserve /** */ for javadoc / scaladoc. Meaning, seeing the /*
> */
> > > style
> > > >>>> > > inline always looks a little funny to me.
> > > >>>> > >
> > > >>>> > > On Wed, Feb 4, 2015 at 3:53 PM, Kay Ousterhout <
> > > >>>> kayousterhout@gmail.com>
> > > >>>> > wrote:
> > > >>>> > >> Hi all,
> > > >>>> > >>
> > > >>>> > >> The Spark Style Guide
> > > >>>> > >> <
> > > >>>> >
> > >
> https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide
> > > >>>> >
> > > >>>> > >> says multi-line comments should formatted as:
> > > >>>> > >>
> > > >>>> > >> /*
> > > >>>> > >>  * This is a
> > > >>>> > >>  * very
> > > >>>> > >>  * long comment.
> > > >>>> > >>  */
> > > >>>> > >>
> > > >>>> > >> But in my experience, we almost always use "//" for
> multi-line
> > > >>>> comments:
> > > >>>> > >>
> > > >>>> > >> // This is a
> > > >>>> > >> // very
> > > >>>> > >> // long comment.
> > > >>>> > >>
> > > >>>> > >> Here are some examples:
> > > >>>> > >>
> > > >>>> > >>    - Recent commit by Reynold, king of style:
> > > >>>> > >>
> > > >>>> >
> > > >>>>
> > >
> >
> https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
> > > >>>> > >>    - RDD.scala:
> > > >>>> > >>
> > > >>>> >
> > > >>>>
> > >
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
> > > >>>> > >>    - DAGScheduler.scala:
> > > >>>> > >>
> > > >>>> >
> > > >>>>
> > >
> >
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
> > > >>>> > >>
> > > >>>> > >>
> > > >>>> > >> Any objections to me updating the style guide to reflect
> this?
> > > As
> > > >>>> with
> > > >>>> > >> other style issues, I think consistency here is helpful (and
> > > >>>> formatting
> > > >>>> > >> multi-line comments as "//" does nicely visually distinguish
> > code
> > > >>>> > comments
> > > >>>> > >> from doc comments).
> > > >>>> > >>
> > > >>>> > >> -Kay
> > > >>>> > >
> > > >>>> > >
> > > ---------------------------------------------------------------------
> > > >>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > >>>> > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >>>> > >
> > > >>>> >
> > > >>>> >
> > > ---------------------------------------------------------------------
> > > >>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > >>>> > For additional commands, e-mail: dev-help@spark.apache.org
> > > >>>> >
> > > >>>> >
> > > >>>>
> > >
> >
>

--001a113eeb18cb30af050eaf358c--

From dev-return-11541-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb  9 23:52:18 2015
Return-Path: <dev-return-11541-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE9FB106F2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  9 Feb 2015 23:52:18 +0000 (UTC)
Received: (qmail 72714 invoked by uid 500); 9 Feb 2015 23:52:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72650 invoked by uid 500); 9 Feb 2015 23:52:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72636 invoked by uid 99); 9 Feb 2015 23:52:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 23:52:17 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 09 Feb 2015 23:51:52 +0000
Received: by mail-wg0-f46.google.com with SMTP id a1so8709655wgh.5
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 15:51:51 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Zg1ZZVmpVa9HlxvXfurXHOG7I2bVTa23JalD5qRtX5A=;
        b=JhaENMviLY8S0P/0gycBQfqELofQ7P7eP041siHtclaAr2tXevPv0Z08iaKRYqVEaY
         qj6pi5QaxPAMd0rNkHvMWiSupp1cSHBpjAzwlH4wF2e02BmY5hXVlFk+VRziGAd4o/2y
         39yR/R93Kw5Sx5Ecn4ufgwiHSMODpHCmOFEsLLEMOwr/ka6/1XCXpkQSX1R1t24lXlnb
         7SOcbPtbTCA0WM7pL1MvpswwXlFLDo1YyvF5cU4VQxZ6Nf1CqRmzPdI5X7rGuvlJ3cgy
         /GPeHa+ZjrG8x3Si/kBbeaosfNdCywo8CpWNI4snryEJzdQdLaEEFg+GU5YFoNECWtKq
         pueA==
X-Gm-Message-State: ALoCoQlTVetOWu3zGdG3LTBnM6oV5KuTN+6O/OAXolckeXO/mWxlCK8bmXuw2x0qUnk9cOU3HANG
X-Received: by 10.180.89.210 with SMTP id bq18mr40455565wib.45.1423525911272;
 Mon, 09 Feb 2015 15:51:51 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.76 with HTTP; Mon, 9 Feb 2015 15:51:30 -0800 (PST)
In-Reply-To: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
References: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 9 Feb 2015 23:51:30 +0000
Message-ID: <CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Mark Hamstra <mark@clearstorydata.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

What about this straw man proposal: deprecate in 1.3 with some kind of
message in the build, and remove for 1.4? And add a pointer to any
third-party packaging that might provide similar functionality?

On Mon, Feb 9, 2015 at 6:47 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> +1 to an "official" deprecation + redirecting users to some other project
> that will or already is taking this on.
>
> Nate?
>
>
>
> On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
> wrote:
>>
>> I have wondered whether we should sort of deprecated it more
>> officially, since otherwise I think people have the reasonable
>> expectation based on the current code that Spark intends to support
>> "complete" Debian packaging as part of the upstream build. Having
>> something that's sort-of maintained but no one is helping review and
>> merge patches on it or make it fully functional, IMO that doesn't
>> benefit us or our users. There are a bunch of other projects that are
>> specifically devoted to packaging, so it seems like there is a clear
>> separation of concerns here.
>>
>> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra <mark@clearstorydata.com>
>> wrote:
>> >>
>> >> it sounds like nobody intends these to be used to actually deploy Spark
>> >
>> >
>> > I wouldn't go quite that far.  What we have now can serve as useful
>> > input
>> > to a deployment tool like Chef, but the user is then going to need to
>> > add
>> > some customization or configuration within the context of that tooling
>> > to
>> > get Spark installed just the way they want.  So it is not so much that
>> > the
>> > current Debian packaging can't be used as that it has never really been
>> > intended to be a completely finished product that a newcomer could, for
>> > example, use to install Spark completely and quickly to Ubuntu and have
>> > a
>> > fully-functional environment in which they could then run all of the
>> > examples, tutorials, etc.
>> >
>> > Getting to that level of packaging (and maintenance) is something that
>> > I'm
>> > not sure we want to do since that is a better fit with Bigtop and the
>> > efforts of Cloudera, Horton Works, MapR, etc. to distribute Spark.
>> >
>> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> wrote:
>> >
>> >> This is a straw poll to assess whether there is support to keep and
>> >> fix, or remove, the Debian packaging-related config in Spark.
>> >>
>> >> I see several oldish outstanding JIRAs relating to problems in the
>> >> packaging:
>> >>
>> >> https://issues.apache.org/jira/browse/SPARK-1799
>> >> https://issues.apache.org/jira/browse/SPARK-2614
>> >> https://issues.apache.org/jira/browse/SPARK-3624
>> >> https://issues.apache.org/jira/browse/SPARK-4436
>> >> (and a similar idea about making RPMs)
>> >> https://issues.apache.org/jira/browse/SPARK-665
>> >>
>> >> The original motivation seems related to Chef:
>> >>
>> >>
>> >>
>> >> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14070908
>> >>
>> >> Mark's recent comments cast some doubt on whether it is essential:
>> >>
>> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
>> >>
>> >> and in recent conversations I didn't hear dissent to the idea of
>> >> removing
>> >> this.
>> >>
>> >> Is this still useful enough to fix up? All else equal I'd like to
>> >> start to walk back some of the complexity of the build, but I don't
>> >> know how all-else-equal it is. Certainly, it sounds like nobody
>> >> intends these to be used to actually deploy Spark.
>> >>
>> >> I don't doubt it's useful to someone, but can they maintain the
>> >> packaging logic elsewhere?
>> >>
>> >> ---------------------------------------------------------------------
>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>> >>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11542-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 00:02:57 2015
Return-Path: <dev-return-11542-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DF88C10741
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 00:02:56 +0000 (UTC)
Received: (qmail 94350 invoked by uid 500); 10 Feb 2015 00:02:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94271 invoked by uid 500); 10 Feb 2015 00:02:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94260 invoked by uid 99); 10 Feb 2015 00:02:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:02:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of shivaram@berkeley.edu designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:02:51 +0000
Received: by mail-wi0-f178.google.com with SMTP id hm9so10177507wib.5
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 16:00:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type;
        bh=UCuKHj8EksdJGbxPI0LelX98FsstH67gOMwmvczRATo=;
        b=eS1ZhO9xSLnNa1N6ErsvmogH9wCsMQs1iVY7Yleq/TB13gvB/5f/q2gvyW3WGGZ0gM
         3e3I0mSYgNOFQkzTEUPcrNuEehmPO4oXJhUbTqU1L372BaX7mwF91lDEtckPLqtryME1
         fvkyambUtU5w4t62YqRxzRr9tZ5A8gQkUDvkD1YeKd9Cza6tXgb4oXMzlrsxG1TvZJ1P
         dfYVkLr4pmQf8oQCG6KIEUplZeyIgykjvPxg0xFHz3ybANvdt0kv3gdaX02/jy/uyips
         bvyDTp7S2gTBVU+0KnQ0wQjxz7O0v9ooH8J4q3gf/rPOwVwBIzg9Ey8WyqtoYbZrQjjA
         xaNA==
X-Gm-Message-State: ALoCoQnliARVdsZQKKuSNfXt7F0N6ma+SBqWwYBfSViTmiViOl60Rj5UcZLNnjQzp7DmIUt4UMop
MIME-Version: 1.0
X-Received: by 10.180.189.240 with SMTP id gl16mr40094300wic.20.1423526413410;
 Mon, 09 Feb 2015 16:00:13 -0800 (PST)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.216.163.6 with HTTP; Mon, 9 Feb 2015 16:00:13 -0800 (PST)
In-Reply-To: <CAB0iJzApMeasmzHtPamx5BPU1nNkNR6-Z+XP5_eYEq7f03v8eQ@mail.gmail.com>
References: <CAB0iJzApMeasmzHtPamx5BPU1nNkNR6-Z+XP5_eYEq7f03v8eQ@mail.gmail.com>
Date: Mon, 9 Feb 2015 16:00:13 -0800
Message-ID: <CAKx7Bf8TmU-3815ENQdmbVFepZoBzOVBpBb9-=ZgRV70xvihkg@mail.gmail.com>
Subject: Re: spark-ec2 licensing clarification
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Florian Verhein <florian@arkig.com>
Cc: dev@mesos.apache.org, Shivaram Venkataraman <shivaram@eecs.berkeley.edu>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c22818332e52050eb092ef
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c22818332e52050eb092ef
Content-Type: text/plain; charset=UTF-8

+spark dev list

Yes, we should add an Apache license to it -- Feel free to open a PR for
it. BTW though it is a part of the mesos github account, it is almost
exclusively used by the Spark Project AFAIK.

Longer term it may make sense to move it to a more appropriate github
account (we could move it to amplab/ for instance as the AMPLab provides
Jenkins support etc. too)

Thanks
Shivaram

On Mon, Feb 9, 2015 at 3:26 PM, Florian Verhein <florian@arkig.com> wrote:

> Hi guys,
>
> Are there any plans to add licensing information to the mesos/spark-ec2
> repo?
> I'd assumed it would be Apache 2.0 but then noticed there's no info in the
> repo.
>
> Background:
> https://issues.apache.org/jira/browse/SPARK-5676
>
> Regards,
>    Florian
>
>
>

--001a11c22818332e52050eb092ef--

From dev-return-11543-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 00:11:23 2015
Return-Path: <dev-return-11543-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A476107D5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 00:11:23 +0000 (UTC)
Received: (qmail 8268 invoked by uid 500); 10 Feb 2015 00:11:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8191 invoked by uid 500); 10 Feb 2015 00:11:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8176 invoked by uid 99); 10 Feb 2015 00:11:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:11:22 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [216.70.64.187] (HELO n60.mail01.mtsvc.net) (216.70.64.187)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:10:56 +0000
Received: from 173-11-124-254-sfba.hfc.comcastbusiness.net ([173.11.124.254]:62443 helo=bebopredux)
	by n60.mail01.mtsvc.net with esmtpsa (UNKNOWN:AES256-GCM-SHA384:256)
	(Exim 4.72)
	(envelope-from <nate@reactor8.com>)
	id 1YKyPl-000AMg-Py; Mon, 09 Feb 2015 19:10:54 -0500
From: <nate@reactor8.com>
To: "'Sean Owen'" <sowen@cloudera.com>,
	"'Nicholas Chammas'" <nicholas.chammas@gmail.com>
Cc: "'Patrick Wendell'" <pwendell@gmail.com>,
	"'Mark Hamstra'" <mark@clearstorydata.com>,
	"'dev'" <dev@spark.apache.org>
References: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com> <CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
In-Reply-To: <CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
Subject: RE: Keep or remove Debian packaging in Spark?
Date: Mon, 9 Feb 2015 16:10:50 -0800
Message-ID: <028601d044c6$085de910$1919bb30$@reactor8.com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Outlook 15.0
Thread-Index: AQEmAKAxDYPftjPmdqO0cORP4Rv1UQKA9s7xnimALyA=
Content-Language: en-us
X-Authenticated-User: 917868 nate@reactor8.com
X-MT-ID: 3CB1E6102B94980D10544FA93FD5F01BC02E0A63
X-Virus-Checked: Checked by ClamAV on apache.org

This could be something if the spark community wanted to not maintain =
debs/rpms directly via the project could direct interested efforts =
towards apache bigtop.  Right now debs/rpms of bigtop components, as =
well as related tests is a focus.

Something that would be great is if at least one spark committer with =
interests in config/pkg/testing could be liason and pt for bigtop =
efforts.

Right now focus on bigtop 0.9, which currently includes spark 1.2.  Jira =
for items included in 0.9 can be found here:

https://issues.apache.org/jira/browse/BIGTOP-1480



-----Original Message-----
From: Sean Owen [mailto:sowen@cloudera.com]=20
Sent: Monday, February 9, 2015 3:52 PM
To: Nicholas Chammas
Cc: Patrick Wendell; Mark Hamstra; dev
Subject: Re: Keep or remove Debian packaging in Spark?

What about this straw man proposal: deprecate in 1.3 with some kind of =
message in the build, and remove for 1.4? And add a pointer to any =
third-party packaging that might provide similar functionality?

On Mon, Feb 9, 2015 at 6:47 PM, Nicholas Chammas =
<nicholas.chammas@gmail.com> wrote:
> +1 to an "official" deprecation + redirecting users to some other=20
> +project
> that will or already is taking this on.
>
> Nate?
>
>
>
> On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
> wrote:
>>
>> I have wondered whether we should sort of deprecated it more=20
>> officially, since otherwise I think people have the reasonable=20
>> expectation based on the current code that Spark intends to support=20
>> "complete" Debian packaging as part of the upstream build. Having=20
>> something that's sort-of maintained but no one is helping review and=20
>> merge patches on it or make it fully functional, IMO that doesn't=20
>> benefit us or our users. There are a bunch of other projects that are =

>> specifically devoted to packaging, so it seems like there is a clear=20
>> separation of concerns here.
>>
>> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra=20
>> <mark@clearstorydata.com>
>> wrote:
>> >>
>> >> it sounds like nobody intends these to be used to actually deploy=20
>> >> Spark
>> >
>> >
>> > I wouldn't go quite that far.  What we have now can serve as useful =

>> > input to a deployment tool like Chef, but the user is then going to =

>> > need to add some customization or configuration within the context=20
>> > of that tooling to get Spark installed just the way they want.  So=20
>> > it is not so much that the current Debian packaging can't be used=20
>> > as that it has never really been intended to be a completely=20
>> > finished product that a newcomer could, for example, use to install =

>> > Spark completely and quickly to Ubuntu and have a fully-functional=20
>> > environment in which they could then run all of the examples,=20
>> > tutorials, etc.
>> >
>> > Getting to that level of packaging (and maintenance) is something=20
>> > that I'm not sure we want to do since that is a better fit with=20
>> > Bigtop and the efforts of Cloudera, Horton Works, MapR, etc. to=20
>> > distribute Spark.
>> >
>> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> =
wrote:
>> >
>> >> This is a straw poll to assess whether there is support to keep=20
>> >> and fix, or remove, the Debian packaging-related config in Spark.
>> >>
>> >> I see several oldish outstanding JIRAs relating to problems in the
>> >> packaging:
>> >>
>> >> https://issues.apache.org/jira/browse/SPARK-1799
>> >> https://issues.apache.org/jira/browse/SPARK-2614
>> >> https://issues.apache.org/jira/browse/SPARK-3624
>> >> https://issues.apache.org/jira/browse/SPARK-4436
>> >> (and a similar idea about making RPMs)
>> >> https://issues.apache.org/jira/browse/SPARK-665
>> >>
>> >> The original motivation seems related to Chef:
>> >>
>> >>
>> >>
>> >> =
https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=3D
>> >> =
14070908&page=3Dcom.atlassian.jira.plugin.system.issuetabpanels:comm
>> >> ent-tabpanel#comment-14070908
>> >>
>> >> Mark's recent comments cast some doubt on whether it is essential:
>> >>
>> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
>> >>
>> >> and in recent conversations I didn't hear dissent to the idea of=20
>> >> removing this.
>> >>
>> >> Is this still useful enough to fix up? All else equal I'd like to=20
>> >> start to walk back some of the complexity of the build, but I=20
>> >> don't know how all-else-equal it is. Certainly, it sounds like=20
>> >> nobody intends these to be used to actually deploy Spark.
>> >>
>> >> I don't doubt it's useful to someone, but can they maintain the=20
>> >> packaging logic elsewhere?
>> >>
>> >> ------------------------------------------------------------------
>> >> --- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For=20
>> >> additional commands, e-mail: dev-help@spark.apache.org
>> >>
>> >>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For=20
>> additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional =
commands, e-mail: dev-help@spark.apache.org



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11544-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 00:51:16 2015
Return-Path: <dev-return-11544-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3EA3F10AE8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 00:51:16 +0000 (UTC)
Received: (qmail 34473 invoked by uid 500); 10 Feb 2015 00:51:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34378 invoked by uid 500); 10 Feb 2015 00:51:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34362 invoked by uid 99); 10 Feb 2015 00:51:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:51:14 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.54] (HELO g4t3426.houston.hp.com) (15.201.208.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 00:50:48 +0000
Received: from G4W6310.americas.hpqcorp.net (g4w6310.houston.hp.com [16.210.26.217])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3426.houston.hp.com (Postfix) with ESMTPS id 5D025A8;
	Tue, 10 Feb 2015 00:49:45 +0000 (UTC)
Received: from G4W6304.americas.hpqcorp.net (16.210.26.229) by
 G4W6310.americas.hpqcorp.net (16.210.26.217) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Tue, 10 Feb 2015 00:48:17 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G4W6304.americas.hpqcorp.net ([16.210.26.229]) with mapi id 14.03.0169.001;
 Tue, 10 Feb 2015 00:48:17 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0AAAKwxgACUAsfw
Date: Tue, 10 Feb 2015 00:48:16 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
In-Reply-To: <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.216.65.177]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BFG4W3292americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BFG4W3292americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BFG4W3292americas_--

From dev-return-11545-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 01:34:47 2015
Return-Path: <dev-return-11545-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 831B310CA6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 01:34:47 +0000 (UTC)
Received: (qmail 36675 invoked by uid 500); 10 Feb 2015 01:34:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36605 invoked by uid 500); 10 Feb 2015 01:34:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93080 invoked by uid 99); 10 Feb 2015 01:19:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 01:19:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 01:19:40 +0000
Received: by mail-lb0-f179.google.com with SMTP id w7so9202429lbi.10
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 17:18:35 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=M7nkMcG6N8q/leKjN4MNw2qflJDxTr2++twePCVpfgI=;
        b=gWt1HWy+fCmIXXniDwFrIX+xdz5yEDWorCyr8QIoLwNhXnS4itt878qoCKwDuXFmNx
         KZwCduN075rebImuWygdU667L2dYOW2CzaSwKY2w420JQ6BQDoaGoT1NlY8lL8yQMEIc
         2yupHTz7448mxvz0tlJBlBskCX0BQo6mcShzb8DRZ+gDK15t9g1fp1H0S/G77Pu8//WC
         nNGWpjBPwkh3Z7xJMqe/aw7fCHj2pwIaMp/B66zB4EZd0bv1R7PZEMq3I9bRUx8fuHgo
         yXDRzaPJiWSxWz858pVhvWJarn9/oSzVl6dgiJcGhJ+3KwgoVjTvhqA0yJqJh2ebw5vR
         uE5Q==
X-Gm-Message-State: ALoCoQku5O1rvxhSz0H5YkEuTAG8qmdQSA8+nfhZXd/TQmmelG+IsebIZ66nR37+HVxkTvQG4skB
X-Received: by 10.152.87.168 with SMTP id az8mr19897243lab.74.1423531114566;
 Mon, 09 Feb 2015 17:18:34 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.185.97 with HTTP; Mon, 9 Feb 2015 17:18:14 -0800 (PST)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 9 Feb 2015 17:18:14 -0800
Message-ID: <CACdU-dTXnSw0ksNQuytngXZnDtZS13HKC=UkE3ghJizVBjEKUg@mail.gmail.com>
Subject: adding some temporary jenkins worker nodes...
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c34e0e6926da050eb1aaf2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c34e0e6926da050eb1aaf2
Content-Type: text/plain; charset=UTF-8

...to help w/the build backlog.  let's all welcome
amp-jenkins-slave-{01..03} back to the fray!

--001a11c34e0e6926da050eb1aaf2--

From dev-return-11546-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 01:38:07 2015
Return-Path: <dev-return-11546-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B7B0D10CE1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 01:38:07 +0000 (UTC)
Received: (qmail 63190 invoked by uid 500); 10 Feb 2015 01:38:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63120 invoked by uid 500); 10 Feb 2015 01:38:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74496 invoked by uid 99); 10 Feb 2015 01:11:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 01:11:26 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of chester@alpinenow.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 01:11:00 +0000
Received: by mail-pa0-f51.google.com with SMTP id eu11so15603239pac.10
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 17:09:28 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:content-type:mime-version:subject:from
         :in-reply-to:date:cc:content-transfer-encoding:message-id:references
         :to;
        bh=KxQlMdymGH3fQf8jXrYsPZedL3nYnYm6VDehrQ/wR6k=;
        b=YD49/IZ7YiO3nC05bZRE4D8MVOWU5Saobi4E8SMu5iC/sVGdDVjzrQqifi4/xmYPnK
         /ppsXAYy0XDqXDfhOMYK00K3dzKXGZNq0/1rsOGO4rNybAfWYqXjmJmLwSrbZCxoRkO9
         w1JmsFanaJDlabgAIjO+mM0E9KpSogDL3148wV4BAw7L5W3WjYj+WgIUSUAMVLAQD6EB
         QhD6FznDQxePnCCwGA35LiLrJwuDaE/S3kffXTZgVWTOBzggbGyDsM3NYhmqm20n+K1i
         1LO7Gw3YUKxuwVgXGqQVIonfXfl1rkIBsp+djjp91Ez1v+pxnblHPl/D8RhD1AONL2+u
         xSYg==
X-Gm-Message-State: ALoCoQll+FCJzCrKwLVrlF2gHI10Kfyoy1f/ngMr/HKjjnYRkmMaSJOnI4MHtHtIFj1cWRt0U8xV
X-Received: by 10.68.57.228 with SMTP id l4mr13809888pbq.43.1423530568593;
        Mon, 09 Feb 2015 17:09:28 -0800 (PST)
Received: from [26.27.92.236] ([172.56.16.42])
        by mx.google.com with ESMTPSA id bu6sm8527194pad.45.2015.02.09.17.09.27
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 09 Feb 2015 17:09:27 -0800 (PST)
Content-Type: text/plain;
	charset=gb2312
Mime-Version: 1.0 (1.0)
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: "Chester @work" <chester@alpinenow.com>
X-Mailer: iPhone Mail (11D201)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
Date: Mon, 9 Feb 2015 17:09:26 -0800
Cc: "Evan R. Sparks" <evan.sparks@gmail.com>,
 Joseph Bradley <joseph@databricks.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <F378FBCD-9C35-46D7-9479-69AF9C5FC469@alpinenow.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net> <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net> <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net> <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net> <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net> <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
X-Virus-Checked: Checked by ClamAV on apache.org

Maybe you can ask prof john canny himself:-)  as I invited him to give a tal=
k at Alpine data labs in March's meetup (SF big Analytics & SF machine learn=
ing joined meetup) , 3/11. To be announced in next day or so.=20

Chester

Sent from my iPhone

> On Feb 9, 2015, at 4:48 PM, "Ulanov, Alexander" <alexander.ulanov@hp.com> w=
rote:
>=20
> Hi Evan,
>=20
> Thank you for explanation and useful link. I am going to build OpenBLAS, l=
ink it with Netlib-java and perform benchmark again.
>=20
> Do I understand correctly that BIDMat binaries contain statically linked I=
ntel MKL BLAS? It might be the reason why I am able to run BIDMat not having=
 MKL BLAS installed on my server. If it is true, I wonder if it is OK becaus=
e Intel sells this library. Nevertheless, it seems that in my case precompil=
ed MKL BLAS performs better than precompiled OpenBLAS given that BIDMat and N=
etlib-java are supposed to be on par with JNI overheads.
>=20
> Though, it might be interesting to link Netlib-java with Intel MKL, as you=
 suggested. I wonder, are John Canny (BIDMat) and Sam Halliday (Netlib-java)=
 interested to compare their libraries.
>=20
> Best regards, Alexander
>=20
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Friday, February 06, 2015 5:58 PM
> To: Ulanov, Alexander
> Cc: Joseph Bradley; dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>=20
> I would build OpenBLAS yourself, since good BLAS performance comes from ge=
tting cache sizes, etc. set up correctly for your particular hardware - this=
 is often a very tricky process (see, e.g. ATLAS), but we found that on rela=
tively modern Xeon chips, OpenBLAS builds quickly and yields performance com=
petitive with MKL.
>=20
> To make sure the right library is getting used, you have to make sure it's=
 first on the search path - export LD_LIBRARY_PATH=3D/path/to/blas/library.s=
o will do the trick here.
>=20
> For some examples of getting netlib-java setup on an ec2 node and some exa=
mple benchmarking code we ran a while back, see: https://github.com/shivaram=
/matrix-bench
>=20
> In particular - build-openblas-ec2.sh shows you how to build the library a=
nd set up symlinks correctly, and scala/run-netlib.sh shows you how to get t=
he path setup and get that library picked up by netlib-java.
>=20
> In this way - you could probably get cuBLAS set up to be used by netlib-ja=
va as well.
>=20
> - Evan
>=20
> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <alexander.ulanov@hp.com=
<mailto:alexander.ulanov@hp.com>> wrote:
> Evan, could you elaborate on how to force BIDMat and netlib-java to force l=
oading the right blas? For netlib, I there are few JVM flags, such as -Dcom.=
github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so I can force=
 it to use Java implementation. Not sure I understand how to force use a spe=
cific blas (not specific wrapper for blas).
>=20
> Btw. I have installed openblas (yum install openblas), so I suppose that n=
etlib is using it.
>=20
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmai=
l.com>]
> Sent: Friday, February 06, 2015 5:19 PM
> To: Ulanov, Alexander
> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>=20
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>=20
> Getting breeze to pick up the right blas library is critical for performan=
ce. I recommend using OpenBLAS (or MKL, if you already have it). It might ma=
ke sense to force BIDMat to use the same underlying BLAS library as well.
>=20
> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <alexander.ulanov@hp.com=
<mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan, Joseph
>=20
> I did few matrix multiplication test and BIDMat seems to be ~10x faster th=
an netlib-java+breeze (sorry for weird table formatting):
>=20
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64| B=
reeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>=20
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19 Lin=
ux, Scala 2.11.
>=20
> Later I will make tests with Cuda. I need to install new Cuda version for t=
his purpose.
>=20
> Do you have any ideas why breeze-netlib with native blas is so much slower=
 than BIDMat MKL?
>=20
> Best regards, Alexander
>=20
> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databrick=
s.com>]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>=20
> Hi Alexander,
>=20
> Using GPUs with Spark would be very exciting.  Small comment: Concerning y=
our question earlier about keeping data stored on the GPU rather than having=
 to move it between main memory and GPU memory on each iteration, I would gu=
ess this would be critical to getting good performance.  If you could do mul=
tiple local iterations before aggregating results, then the cost of data mov=
ement to the GPU could be amortized (and I believe that is done in practice)=
.  Having Spark be aware of the GPU and using it as another part of memory s=
ounds like a much bigger undertaking.
>=20
> Joseph
>=20
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.com=
<mailto:alexander.ulanov@hp.com>> wrote:
> Thank you for explanation! I=A1=AFve watched the BIDMach presentation by J=
ohn Canny and I am really inspired by his talk and comparisons with Spark ML=
lib.
>=20
> I am very interested to find out what will be better within Spark: BIDMat o=
r netlib-java with CPU or GPU natives. Could you suggest a fair way to bench=
mark them? Currently I do benchmarks on artificial neural networks in batch m=
ode. While it is not a =A1=B0pure=A1=B1 test of linear algebra, it involves s=
ome other things that are essential to machine learning.
>=20
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmai=
l.com>]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>=20
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than netlib-j=
ava+OpenBLAS, but if it is much faster it's probably due to data layout and f=
ewer levels of indirection - it's definitely a worthwhile experiment to run.=
 The main speedups I've seen from using it come from highly optimized GPU co=
de for linear algebra. I know that in the past Canny has gone as far as to w=
rite custom GPU kernels for performance-critical regions of code.[1]
>=20
> BIDMach is highly optimized for single node performance or performance on s=
mall clusters.[2] Once data doesn't fit easily in GPU memory (or can be batc=
hed in that way) the performance tends to fall off. Canny argues for hardwar=
e/software codesign and as such prefers machine configurations that are quit=
e different than what we find in most commodity cluster nodes - e.g. 10 disk=
 cahnnels and 4 GPUs.
>=20
> In contrast, MLlib was designed for horizontal scalability on commodity cl=
usters and works best on very big datasets - order of terabytes.
>=20
> For the most part, these projects developed concurrently to address slight=
ly different use cases. That said, there may be bits of BIDMach we could rep=
urpose for MLlib - keep in mind we need to be careful about maintaining cros=
s-language compatibility for our Java and Python-users, though.
>=20
> - Evan
>=20
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>=20
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.com=
<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexa=
nder.ulanov@hp.com>>> wrote:
> Hi Evan,
>=20
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you know=
 what makes them faster than netlib-java?
>=20
> The same group has BIDMach library that implements machine learning. For s=
ome examples they use Caffe convolutional neural network library owned by an=
other group in Berkeley. Could you elaborate on how these all might be conne=
cted with Spark Mllib? If you take BIDMat for linear algebra why don=A1=AFt y=
ou take BIDMach for optimization and learning?
>=20
> Best regards, Alexander
>=20
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmai=
l.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apa=
che.org<mailto:dev@spark.apache.org>>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>=20
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in m=
any cases.
>=20
> You might consider taking a look at the codepaths that BIDMat (https://git=
hub.com/BIDData/BIDMat) takes and comparing them to netlib-java/breeze. John=
 Canny et. al. have done a bunch of work optimizing to make this work really=
 fast from Scala. I've run it on my laptop and compared to MKL and in certai=
n cases it's 10x faster at matrix multiply. There are a lot of layers of ind=
irection here and you really want to avoid data copying as much as possible.=

>=20
> We could also consider swapping out BIDMat for Breeze, but that would be a=
 big project and if we can figure out how to get breeze+cublas to comparable=
 performance that would be a big win.
>=20
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <alexander.ulanov@hp.co=
m<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alex=
ander.ulanov@hp.com>>> wrote:
> Dear Spark developers,
>=20
> I am exploring how to make linear algebra operations faster within Spark. O=
ne way of doing this is to use Scala Breeze library that is bundled with Spa=
rk. For matrix operations, it employs Netlib-java that has a Java wrapper fo=
r BLAS (basic linear algebra subprograms) and LAPACK native binaries if they=
 are available on the worker node. It also has its own optimized Java implem=
entation of BLAS. It is worth mentioning, that native binaries provide bette=
r performance only for BLAS level 3, i.e. matrix-matrix operations or genera=
l matrix multiplication (GEMM). This is confirmed by GEMM test on Netlib-jav=
a page https://github.com/fommil/netlib-java. I also confirmed it with my ex=
periments with training of artificial neural network https://github.com/apac=
he/spark/pull/1290#issuecomment-70313952. However, I would like to boost per=
formance more.
>=20
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA i=
mplementation of BLAS, called cublas. I have one Linux server with Nvidia GP=
U and I was able to do the following. I linked cublas (instead of cpu-based b=
las) with Netlib-java wrapper and put it into Spark, so Breeze/Netlib is usi=
ng it. Then I did some performance measurements with regards to artificial n=
eural network batch learning in Spark MLlib that involves matrix-matrix mult=
iplications. It turns out that for matrices of size less than ~1000x780 GPU c=
ublas has the same speed as CPU blas. Cublas becomes slower for bigger matri=
ces. It worth mentioning that it is was not a test for ONLY multiplication s=
ince there are other operations involved. One of the reasons for slowdown mi=
ght be the overhead of copying the matrices from computer memory to graphic c=
ard memory and back.
>=20
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that allo=
w to force intermediate results to stay in graphic card memory thus removing=
 the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>=20
> Thank you, Alexander
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubs=
cribe@spark.apache.org><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-u=
nsubscribe@spark.apache.org>>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev-help=
@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.ap=
ache.org>>
>=20
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11547-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 02:06:53 2015
Return-Path: <dev-return-11547-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7DF7E10E21
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 02:06:53 +0000 (UTC)
Received: (qmail 20779 invoked by uid 500); 10 Feb 2015 02:06:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20692 invoked by uid 500); 10 Feb 2015 02:06:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20674 invoked by uid 99); 10 Feb 2015 02:06:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 02:06:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.173 as permitted sender)
Received: from [209.85.220.173] (HELO mail-vc0-f173.google.com) (209.85.220.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 02:06:47 +0000
Received: by mail-vc0-f173.google.com with SMTP id hy4so6608094vcb.4
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 18:06:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=DL+ICVC4ljkpeX3aoMWwAStprRCd3FiHpaZVr9osZUE=;
        b=vdEH6hvXAUj5vFju1xFzuRlyNd8jud++F3xBp6hk4sVoJYPbXVXk3XPURcY+a+x7J0
         oisdh4bQ1cmuHGVtlUBApEm+z2S8QTeca5FES/deM59VUg9HHvS6oCjEiSMSJyGNUB/t
         XCG7oUV+mMkV9UEsigXGdraW1E9PGjEaQIA7wAPPB2Unqj1fYDfFE0ZiAjKMut/Kg3m1
         KdEjWKothUYaXgxoOH/nof7Q2AW1PyosMIdrflrORKAc3nH0Zyu1qKkttqnGO9QuCHeg
         IeIU+NYbMbW1gCGF20eoI6diREQB+LH+aVfsKMInpslenB+6W+XHGTiYF3WxSzzsrRth
         u+hQ==
X-Received: by 10.52.156.130 with SMTP id we2mr10957278vdb.72.1423533986616;
 Mon, 09 Feb 2015 18:06:26 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Mon, 9 Feb 2015 18:06:06 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Mon, 9 Feb 2015 18:06:06 -0800
Message-ID: <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01634cca991c6f050eb25580
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01634cca991c6f050eb25580
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Great - perhaps we can move this discussion off-list and onto a JIRA
ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705)

It seems like this is going to be somewhat exploratory for a while (and
there's probably only a handful of us who really care about fast linear
algebra!)

- Evan

On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <alexander.ulanov@hp.com>
wrote:

>  Hi Evan,
>
>
>
> Thank you for explanation and useful link. I am going to build OpenBLAS,
> link it with Netlib-java and perform benchmark again.
>
>
>
> Do I understand correctly that BIDMat binaries contain statically linked
> Intel MKL BLAS? It might be the reason why I am able to run BIDMat not
> having MKL BLAS installed on my server. If it is true, I wonder if it is =
OK
> because Intel sells this library. Nevertheless, it seems that in my case
> precompiled MKL BLAS performs better than precompiled OpenBLAS given that
> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>
>
>
> Though, it might be interesting to link Netlib-java with Intel MKL, as yo=
u
> suggested. I wonder, are John Canny (BIDMat) and Sam Halliday (Netlib-jav=
a)
> interested to compare their libraries.
>
>
>
> Best regards, Alexander
>
>
>
> *From:* Evan R. Sparks [mailto:evan.sparks@gmail.com]
> *Sent:* Friday, February 06, 2015 5:58 PM
>
> *To:* Ulanov, Alexander
> *Cc:* Joseph Bradley; dev@spark.apache.org
> *Subject:* Re: Using CUDA within Spark / boosting linear algebra
>
>
>
> I would build OpenBLAS yourself, since good BLAS performance comes from
> getting cache sizes, etc. set up correctly for your particular hardware -
> this is often a very tricky process (see, e.g. ATLAS), but we found that =
on
> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> performance competitive with MKL.
>
>
>
> To make sure the right library is getting used, you have to make sure it'=
s
> first on the search path - export LD_LIBRARY_PATH=3D/path/to/blas/library=
.so
> will do the trick here.
>
>
>
> For some examples of getting netlib-java setup on an ec2 node and some
> example benchmarking code we ran a while back, see:
> https://github.com/shivaram/matrix-bench
>
>
>
> In particular - build-openblas-ec2.sh shows you how to build the library
> and set up symlinks correctly, and scala/run-netlib.sh shows you how to g=
et
> the path setup and get that library picked up by netlib-java.
>
>
>
> In this way - you could probably get cuBLAS set up to be used by
> netlib-java as well.
>
>
>
> - Evan
>
>
>
> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
>
>  Evan, could you elaborate on how to force BIDMat and netlib-java to
> force loading the right blas? For netlib, I there are few JVM flags, such
> as -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so=
 I
> can force it to use Java implementation. Not sure I understand how to for=
ce
> use a specific blas (not specific wrapper for blas).
>
>
>
> Btw. I have installed openblas (yum install openblas), so I suppose that
> netlib is using it.
>
>
>
> *From:* Evan R. Sparks [mailto:evan.sparks@gmail.com]
> *Sent:* Friday, February 06, 2015 5:19 PM
> *To:* Ulanov, Alexander
> *Cc:* Joseph Bradley; dev@spark.apache.org
>
>
> *Subject:* Re: Using CUDA within Spark / boosting linear algebra
>
>
>
> Getting breeze to pick up the right blas library is critical for
> performance. I recommend using OpenBLAS (or MKL, if you already have it).
> It might make sense to force BIDMat to use the same underlying BLAS libra=
ry
> as well.
>
>
>
> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
>
> Hi Evan, Joseph
>
> I did few matrix multiplication test and BIDMat seems to be ~10x faster
> than netlib-java+breeze (sorry for weird table formatting):
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
> Breeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
> Linux, Scala 2.11.
>
> Later I will make tests with Cuda. I need to install new Cuda version for
> this purpose.
>
> Do you have any ideas why breeze-netlib with native blas is so much slowe=
r
> than BIDMat MKL?
>
> Best regards, Alexander
>
> From: Joseph Bradley [mailto:joseph@databricks.com]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org
>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Hi Alexander,
>
> Using GPUs with Spark would be very exciting.  Small comment: Concerning
> your question earlier about keeping data stored on the GPU rather than
> having to move it between main memory and GPU memory on each iteration, I
> would guess this would be critical to getting good performance.  If you
> could do multiple local iterations before aggregating results, then the
> cost of data movement to the GPU could be amortized (and I believe that i=
s
> done in practice).  Having Spark be aware of the GPU and using it as
> another part of memory sounds like a much bigger undertaking.
>
> Joseph
>
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m>
> wrote:
> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>
>
>
>
>
>

--089e01634cca991c6f050eb25580--

From dev-return-11548-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 04:12:15 2015
Return-Path: <dev-return-11548-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BD1B81751D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 04:12:15 +0000 (UTC)
Received: (qmail 57904 invoked by uid 500); 10 Feb 2015 04:12:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57832 invoked by uid 500); 10 Feb 2015 04:12:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57818 invoked by uid 99); 10 Feb 2015 04:12:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 04:12:14 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.218.49] (HELO mail-oi0-f49.google.com) (209.85.218.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 04:12:10 +0000
Received: by mail-oi0-f49.google.com with SMTP id v63so6659079oia.8
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 20:09:58 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=o/U0/MQojo74H6+L8vWkSI0KS9R5SfhBNOuBsDdy0Ss=;
        b=diJP2LLu0qJjuQUxUAG1oDp3y5IIEMvPMRoqT50rfMRDOY+WWQHfmI7QE9ot1Wy7OW
         Ht6OThKTrdPNfpN8xIQs/BVTlyvpPBZOlkGVXBeSllv6AhtGvZlK0p1OyDeecKeGM+N3
         OEtuexadOY5CLReM82EOGJPOruc0Ur8pldR+G+a+PIaCQB/dK6lxCEaCvcY7tWTROMWc
         nzVs42ykZFqMRHL/sZV8mTcSp+ObvE0vP2P13S4ptdD6cLBv9vxpM5I/eLxin8LjaZp9
         Y84VeS+kQgJ0KrZypJ9dXcd3tZvU6Hg+67h5PPL7tfdP3YwnRkKNNst7yAVqDx+pxQEL
         TFaA==
X-Gm-Message-State: ALoCoQnc6/6fqqdSWQ65M2cdJfMKYWnxRoYm8gH+8Wlzs/Wr029cIYjBp1B0yrN0yyuHhXADMTzX
X-Received: by 10.202.56.133 with SMTP id f127mr13290540oia.101.1423541398785;
        Mon, 09 Feb 2015 20:09:58 -0800 (PST)
Received: from mail-oi0-f41.google.com (mail-oi0-f41.google.com. [209.85.218.41])
        by mx.google.com with ESMTPSA id zv15sm6578283obb.24.2015.02.09.20.09.57
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 09 Feb 2015 20:09:57 -0800 (PST)
Received: by mail-oi0-f41.google.com with SMTP id z81so26448516oif.0
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 20:09:57 -0800 (PST)
X-Received: by 10.60.144.135 with SMTP id sm7mr14111401oeb.28.1423541397090;
 Mon, 09 Feb 2015 20:09:57 -0800 (PST)
MIME-Version: 1.0
Received: by 10.182.182.7 with HTTP; Mon, 9 Feb 2015 20:09:36 -0800 (PST)
In-Reply-To: <CAHUQ+_ajuMV090D=-jZsBnyzpPotLxF6sBBRWnfH9awN-P+v1g@mail.gmail.com>
References: <1423273025027-10502.post@n3.nabble.com> <CAHUQ+_ajuMV090D=-jZsBnyzpPotLxF6sBBRWnfH9awN-P+v1g@mail.gmail.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Mon, 9 Feb 2015 23:09:36 -0500
Message-ID: <CA+-p3AE1ynYt9XE3Gqg=hSZKVqPTb00NAw_EuJ2vYpA12w7yjQ@mail.gmail.com>
Subject: Re: Pull Requests on github
To: Akhil Das <akhil@sigmoidanalytics.com>
Cc: fommil <sam.halliday@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b4722924bfcce050eb40fe3
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b4722924bfcce050eb40fe3
Content-Type: text/plain; charset=UTF-8

Sam, I see your PR was merged -- many thanks for sending it in and getting
it merged!

In general for future reference, the most effective way to contribute is
outlined on this wiki page:
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark

On Mon, Feb 9, 2015 at 1:04 AM, Akhil Das <akhil@sigmoidanalytics.com>
wrote:

> You can open a Jira issue pointing this PR to get it processed faster. :)
>
> Thanks
> Best Regards
>
> On Sat, Feb 7, 2015 at 7:07 AM, fommil <sam.halliday@gmail.com> wrote:
>
> > Hi all,
> >
> > I'm the author of netlib-java and I noticed that the documentation in
> MLlib
> > was out of date and misleading, so I submitted a pull request on github
> > which will hopefully make things easier for everybody to understand the
> > benefits of system optimised natives and how to use them :-)
> >
> >   https://github.com/apache/spark/pull/4448
> >
> > However, it looks like there are a *lot* of outstanding PRs and that this
> > is
> > just a mirror repository.
> >
> > Will somebody please look at my PR and merge into the canonical source
> (and
> > let me know)?
> >
> > Best regards,
> > Sam
> >
> >
> >
> > --
> > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502.html
> > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--047d7b4722924bfcce050eb40fe3--

From dev-return-11549-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 05:04:30 2015
Return-Path: <dev-return-11549-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A784176E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 05:04:30 +0000 (UTC)
Received: (qmail 43641 invoked by uid 500); 10 Feb 2015 05:04:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43562 invoked by uid 500); 10 Feb 2015 05:04:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43550 invoked by uid 99); 10 Feb 2015 05:04:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 05:04:28 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HTML_MESSAGE,HTTP_ESCAPED_HOST,MIME_HTML_MOSTLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [66.46.182.53] (HELO relay.ihostexchange.net) (66.46.182.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 05:04:22 +0000
Received: from [192.168.125.249] (125.17.228.30) by smtp.ihostexchange.net
 (66.46.182.50) with Microsoft SMTP Server (TLS) id 8.3.389.2; Tue, 10 Feb
 2015 00:03:39 -0500
Message-ID: <54D9908A.8060109@flytxt.com>
Date: Tue, 10 Feb 2015 10:30:58 +0530
From: Meethu Mathew <meethu.mathew@flytxt.com>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Mail to user@spark.apache.org failing
Content-Type: multipart/alternative;
	boundary="------------010803040200030805070508"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------010803040200030805070508
Content-Type: text/plain; charset="utf-8"; format=flowed
Content-Transfer-Encoding: 7bit

Hi,

The mail id given in 
https://cwiki.apache.org/confluence/display/SPARK/Powered+By+Spark seems 
to be failing. Can anyone tell me how to get added to Powered By Spark list?

-- 

Regards,

*Meethu*

--------------010803040200030805070508--

From dev-return-11550-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 05:49:22 2015
Return-Path: <dev-return-11550-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 324211787A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 05:49:22 +0000 (UTC)
Received: (qmail 11671 invoked by uid 500); 10 Feb 2015 05:49:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11593 invoked by uid 500); 10 Feb 2015 05:49:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11579 invoked by uid 99); 10 Feb 2015 05:49:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 05:49:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.43 as permitted sender)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 05:48:56 +0000
Received: by mail-oi0-f43.google.com with SMTP id z81so26715767oif.2
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 21:48:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ongdcOTd9N6idSmAbUuoDZyK/OddM1m0KH/zdXl4/QA=;
        b=Eb1OlENsvPAGOm7YD3ef1vvzelbfp+IU2/AMK3xVB2wsOCrJJOJaFUiOXzFzdKZQ1Y
         Ost3FiFcqBqjIpOHB6HcLw/FSm56SM5dgRwDTDtZZDWD/UwU2HyRyebWJlW+xmH9/LPu
         xkI3Eytld93HKLFQ8Y67tvbZDAUsljZMv8KX6ATUB6Nu9BL9vGoBvQ932hemNfmwd/1K
         QG+5T2XXvEju0s355ylnX43lQnkYMAmfEox0yPECAxSXm2sBRcorJTFauPhvE+sVIfj0
         RbLfx4XXxvd8ChK+JSSsqes6DcCJ/YvwiVaYMqYs7Zx/antEbl5tA5ZmLJeeqL1AxoGJ
         lsCA==
MIME-Version: 1.0
X-Received: by 10.202.196.137 with SMTP id u131mr13527306oif.78.1423547334857;
 Mon, 09 Feb 2015 21:48:54 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 21:48:54 -0800 (PST)
In-Reply-To: <54D9908A.8060109@flytxt.com>
References: <54D9908A.8060109@flytxt.com>
Date: Mon, 9 Feb 2015 21:48:54 -0800
Message-ID: <CABPQxsvH7zXSnEJ4btvueJpYL5Via1PsXELtWr2HtPsT3Cq2tw@mail.gmail.com>
Subject: Re: Mail to user@spark.apache.org failing
From: Patrick Wendell <pwendell@gmail.com>
To: Meethu Mathew <meethu.mathew@flytxt.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Ah - we should update it to suggest mailing the dev@ list (and if
there is enough traffic maybe do something else).

I'm happy to add you if you can give an organization name, URL, a list
of which Spark components you are using, and a short description of
your use case..

On Mon, Feb 9, 2015 at 9:00 PM, Meethu Mathew <meethu.mathew@flytxt.com> wrote:
> Hi,
>
> The mail id given in
> https://cwiki.apache.org/confluence/display/SPARK/Powered+By+Spark seems to
> be failing. Can anyone tell me how to get added to Powered By Spark list?
>
> --
>
> Regards,
>
> *Meethu*

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11551-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:03:40 2015
Return-Path: <dev-return-11551-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8CB8A178BD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:03:40 +0000 (UTC)
Received: (qmail 35370 invoked by uid 500); 10 Feb 2015 06:03:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35295 invoked by uid 500); 10 Feb 2015 06:03:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35284 invoked by uid 99); 10 Feb 2015 06:03:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:03:38 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_IMAGE_ONLY_32,HTML_IMAGE_RATIO_04,HTML_MESSAGE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of judynash@exchange.microsoft.com designates 157.55.158.27 as permitted sender)
Received: from [157.55.158.27] (HELO na01-sn2-obe.outbound.o365filtering.com) (157.55.158.27)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:03:30 +0000
Received: from CH1SR01CA102.namsdf01.sdf.exchangelabs.com (10.255.157.19) by
 BL2SR01MB604.namsdf01.sdf.exchangelabs.com (10.255.109.166) with Microsoft
 SMTP Server (TLS) id 15.1.93.2; Tue, 10 Feb 2015 06:02:49 +0000
Received: from SN2FFOFD004.ffo.gbl (2a01:111:f400:7c04::25) by
 CH1SR01CA102.outlook.office365.com (2a01:111:e400:1801::19) with Microsoft
 SMTP Server (TLS) id 15.1.99.3 via Frontend Transport; Tue, 10 Feb 2015
 06:02:49 +0000
Received: from hybrid.exchange.microsoft.com (131.107.159.100) by
 SN2FFOFD004.mail.o365filtering.com (10.111.201.41) with Microsoft SMTP Server
 (TLS) id 15.1.87.3 via Frontend Transport; Tue, 10 Feb 2015 06:02:48 +0000
Received: from DFM-TK5MBX15-01.exchange.corp.microsoft.com (157.54.110.8) by
 DFM-TK5EDG15-02.exchange.corp.microsoft.com (157.54.27.97) with Microsoft
 SMTP Server (TLS) id 15.0.1044.22; Tue, 10 Feb 2015 06:02:42 +0000
Received: from DFM-DB3MBX15-07.exchange.corp.microsoft.com (10.221.22.29) by
 DFM-TK5MBX15-01.exchange.corp.microsoft.com (157.54.110.8) with Microsoft
 SMTP Server (TLS) id 15.0.1076.3; Mon, 9 Feb 2015 22:02:40 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DFM-DB3MBX15-07.exchange.corp.microsoft.com (10.221.22.29) with Microsoft
 SMTP Server (TLS) id 15.0.1076.3; Mon, 9 Feb 2015 22:02:38 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92])
 by DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92]) with mapi id
 15.00.1076.000; Mon, 9 Feb 2015 22:02:38 -0800
From: Judy Nash <judynash@exchange.microsoft.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: New Metrics Sink class not packaged in spark-assembly jar 
Thread-Topic: New Metrics Sink class not packaged in spark-assembly jar 
Thread-Index: AdBE9wjzZBWFK9AcTp6mEiMCd89AQQ==
Date: Tue, 10 Feb 2015 06:02:37 +0000
Message-ID: <93a33a9fbc404ba8859c2629684db67a@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [157.59.235.233]
Content-Type: multipart/mixed;
	boundary="_006_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_"
MIME-Version: 1.0
X-EOPAttributedMessage: 0
X-Forefront-Antispam-Report:
	CIP:131.107.159.100;IPV:NLI;EFV:NLI;SFV:NSPM;SFS:(10019020)(189002)(57704003)(199003)(41574002)(46102003)(62966003)(450100001)(77156002)(568964001)(18206015028)(108616004)(2900100001)(92566002)(84326002)(4610100001)(105596002)(50986999)(512954002)(106466001)(87936001)(54356999)(64706001)(33646002)(16236675004)(2656002)(6806004)(2501002)(5000100001)(66066001)(2351001)(107886001)(229853001)(86362001)(92726002)(15975445007)(102836002)(19617315012)(97736003)(19580395003)(110136001)(68736005)(99936001)(19300405004)(19625215002)(19627595001)(17760045003)(19580405001)(24736002);DIR:OUT;SFP:1102;SCL:1;SRVR:BL2SR01MB604;H:hybrid.exchange.microsoft.com;FPR:;SPF:SoftFail;PTR:InfoDomainNonexistent;MX:1;A:1;LANG:en;
X-Microsoft-Antispam: UriScan:;
X-Microsoft-Antispam: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB604;
X-Exchange-Antispam-Report-Test: UriScan:;
X-Exchange-Antispam-Report-CFA-Test: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB604;
X-Forefront-PRVS: 048396AFA0
Received-SPF: SoftFail (protection.outlook.com: domain of transitioning
 exchange.microsoft.com discourages use of 131.107.159.100 as permitted
 sender)
Authentication-Results: spf=softfail (sender IP is 131.107.159.100)
 smtp.mailfrom=judynash@exchange.microsoft.com; 
X-Exchange-Antispam-Report-CFA-Test: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB604;
X-OriginatorOrg: exchange.microsoft.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 10 Feb 2015 06:02:48.9980
 (UTC)
X-MS-Exchange-CrossTenant-Id: f686d426-8d16-42db-81b7-ab578e110ccd
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f686d426-8d16-42db-81b7-ab578e110ccd;Ip=[131.107.159.100]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: BL2SR01MB604
X-Virus-Checked: Checked by ClamAV on apache.org

--_006_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: multipart/related;
	boundary="_005_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_";
	type="multipart/alternative"

--_005_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: multipart/alternative;
	boundary="_000_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_"

--_000_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hello,

Working on SPARK-5708<https://issues.apache.org/jira/browse/SPARK-5708> - A=
dd Slf4jSink to Spark Metrics Sink.

Wrote a new Slf4jSink class (see patch attached), but the new class is not =
packaged as part of spark-assembly jar.

Do I need to update build config somewhere to have this packaged?

Current packaged class:
[cid:image001.png@01D044B4.1B17A1C0]

Thought I must have missed something basic but can't figure out why.

Thanks!
Judy

--_000_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: text/html; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

<html xmlns:v=3D"urn:schemas-microsoft-com:vml" xmlns:o=3D"urn:schemas-micr=
osoft-com:office:office" xmlns:w=3D"urn:schemas-microsoft-com:office:word" =
xmlns:m=3D"http://schemas.microsoft.com/office/2004/12/omml" xmlns=3D"http:=
//www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Dus-ascii"=
>
<meta name=3D"Generator" content=3D"Microsoft Word 15 (filtered medium)">
<!--[if !mso]><style>v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style><![endif]--><style><!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:#0563C1;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:#954F72;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal-compose;
	font-family:"Calibri","sans-serif";
	color:windowtext;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext=3D"edit" spidmax=3D"1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext=3D"edit">
<o:idmap v:ext=3D"edit" data=3D"1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang=3D"EN-US" link=3D"#0563C1" vlink=3D"#954F72">
<div class=3D"WordSection1">
<p class=3D"MsoNormal">Hello,<o:p></o:p></p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Working on <a href=3D"https://issues.apache.org/jira=
/browse/SPARK-5708">
SPARK-5708</a> &#8211; Add Slf4jSink to Spark Metrics Sink. <o:p></o:p></p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Wrote a new Slf4jSink class (see patch attached), bu=
t the new class is not packaged as part of spark-assembly jar.<o:p></o:p></=
p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Do I need to update build config somewhere to have t=
his packaged?
<o:p></o:p></p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Current packaged class: <o:p></o:p></p>
<p class=3D"MsoNormal"><img border=3D"0" width=3D"523" height=3D"230" id=3D=
"Picture_x0020_1" src=3D"cid:image001.png@01D044B4.1B17A1C0"><o:p></o:p></p=
>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Thought I must have missed something basic but can&#=
8217;t figure out why.<o:p></o:p></p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<p class=3D"MsoNormal">Thanks!<o:p></o:p></p>
<p class=3D"MsoNormal">Judy<o:p></o:p></p>
</div>
</body>
</html>

--_000_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_--

--_005_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: image/png; name="image001.png"
Content-Description: image001.png
Content-Disposition: inline; filename="image001.png"; size=60284;
	creation-date="Tue, 10 Feb 2015 06:02:36 GMT";
	modification-date="Tue, 10 Feb 2015 06:02:36 GMT"
Content-ID: <image001.png@01D044B4.1B17A1C0>
Content-Transfer-Encoding: base64
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--_005_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_--


--_006_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_
Content-Type: text/plain; charset=us-ascii


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--_006_93a33a9fbc404ba8859c2629684db67aDFMDB3MBX1508exchangeco_--

From dev-return-11552-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:09:26 2015
Return-Path: <dev-return-11552-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E47C7178CF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:09:26 +0000 (UTC)
Received: (qmail 45704 invoked by uid 500); 10 Feb 2015 06:09:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45622 invoked by uid 500); 10 Feb 2015 06:09:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45610 invoked by uid 99); 10 Feb 2015 06:09:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:09:25 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:09:21 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so29916326obc.1
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:09:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=onsrALVR44OkPKdS9xWOUTcycdh50vflPlnE1rnRlDc=;
        b=KQKfdwU695Vmg985A0wrPK5F0Q5rj8Dg6IRKecfK3SVASZ9fG9ucNSpvQs/LSoK3ug
         pOoYwTaHyauH9kV+5b1NGxMzB4GwXvZLtvi5DQeCpEOBx/zoHplgLyPk05QijDjlEU6A
         9odVpdYL802S1zFlbhc13XXTIGed+af29up4Zn2jHgHzMKr9sgNCvmDmyAZv3Hr+WenT
         RxjL95pgeP+SwuNIALhWLbgbCO31tV9q99tp9c7kRdOeeqqt9XebyQSpmc2QfqtzAXf6
         KEO3ev3yYQcImy2jffsR4SXZVs6cNZKB9VIReETe/JrWhxRkhn/6F40dATcEympNIiVD
         yKCQ==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr6856342oit.100.1423548541260;
 Mon, 09 Feb 2015 22:09:01 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 22:09:01 -0800 (PST)
In-Reply-To: <028601d044c6$085de910$1919bb30$@reactor8.com>
References: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
	<CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
	<028601d044c6$085de910$1919bb30$@reactor8.com>
Date: Mon, 9 Feb 2015 22:09:01 -0800
Message-ID: <CABPQxstyVft_LA5PUyfOvDf7ynHNK4000nqYGkMbbRK13NvYzw@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
From: Patrick Wendell <pwendell@gmail.com>
To: "Nate D'Amico" <nate@reactor8.com>
Cc: Sean Owen <sowen@cloudera.com>, Nicholas Chammas <nicholas.chammas@gmail.com>, 
	Mark Hamstra <mark@clearstorydata.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Mark was involved in adding this code (IIRC) and has also been the
most active in maintaining it. So I'd be interested in hearing his
thoughts on that proposal. Mark - would you be okay deprecating this
and having Spark instead work with the upstream projects that focus on
packaging?

My feeling is that it's better to just have nothing than to have
something not usable out-of-the-box (which to your point, is a lot
more work).

On Mon, Feb 9, 2015 at 4:10 PM,  <nate@reactor8.com> wrote:
> This could be something if the spark community wanted to not maintain debs/rpms directly via the project could direct interested efforts towards apache bigtop.  Right now debs/rpms of bigtop components, as well as related tests is a focus.
>
> Something that would be great is if at least one spark committer with interests in config/pkg/testing could be liason and pt for bigtop efforts.
>
> Right now focus on bigtop 0.9, which currently includes spark 1.2.  Jira for items included in 0.9 can be found here:
>
> https://issues.apache.org/jira/browse/BIGTOP-1480
>
>
>
> -----Original Message-----
> From: Sean Owen [mailto:sowen@cloudera.com]
> Sent: Monday, February 9, 2015 3:52 PM
> To: Nicholas Chammas
> Cc: Patrick Wendell; Mark Hamstra; dev
> Subject: Re: Keep or remove Debian packaging in Spark?
>
> What about this straw man proposal: deprecate in 1.3 with some kind of message in the build, and remove for 1.4? And add a pointer to any third-party packaging that might provide similar functionality?
>
> On Mon, Feb 9, 2015 at 6:47 PM, Nicholas Chammas <nicholas.chammas@gmail.com> wrote:
>> +1 to an "official" deprecation + redirecting users to some other
>> +project
>> that will or already is taking this on.
>>
>> Nate?
>>
>>
>>
>> On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>>
>>> I have wondered whether we should sort of deprecated it more
>>> officially, since otherwise I think people have the reasonable
>>> expectation based on the current code that Spark intends to support
>>> "complete" Debian packaging as part of the upstream build. Having
>>> something that's sort-of maintained but no one is helping review and
>>> merge patches on it or make it fully functional, IMO that doesn't
>>> benefit us or our users. There are a bunch of other projects that are
>>> specifically devoted to packaging, so it seems like there is a clear
>>> separation of concerns here.
>>>
>>> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra
>>> <mark@clearstorydata.com>
>>> wrote:
>>> >>
>>> >> it sounds like nobody intends these to be used to actually deploy
>>> >> Spark
>>> >
>>> >
>>> > I wouldn't go quite that far.  What we have now can serve as useful
>>> > input to a deployment tool like Chef, but the user is then going to
>>> > need to add some customization or configuration within the context
>>> > of that tooling to get Spark installed just the way they want.  So
>>> > it is not so much that the current Debian packaging can't be used
>>> > as that it has never really been intended to be a completely
>>> > finished product that a newcomer could, for example, use to install
>>> > Spark completely and quickly to Ubuntu and have a fully-functional
>>> > environment in which they could then run all of the examples,
>>> > tutorials, etc.
>>> >
>>> > Getting to that level of packaging (and maintenance) is something
>>> > that I'm not sure we want to do since that is a better fit with
>>> > Bigtop and the efforts of Cloudera, Horton Works, MapR, etc. to
>>> > distribute Spark.
>>> >
>>> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com> wrote:
>>> >
>>> >> This is a straw poll to assess whether there is support to keep
>>> >> and fix, or remove, the Debian packaging-related config in Spark.
>>> >>
>>> >> I see several oldish outstanding JIRAs relating to problems in the
>>> >> packaging:
>>> >>
>>> >> https://issues.apache.org/jira/browse/SPARK-1799
>>> >> https://issues.apache.org/jira/browse/SPARK-2614
>>> >> https://issues.apache.org/jira/browse/SPARK-3624
>>> >> https://issues.apache.org/jira/browse/SPARK-4436
>>> >> (and a similar idea about making RPMs)
>>> >> https://issues.apache.org/jira/browse/SPARK-665
>>> >>
>>> >> The original motivation seems related to Chef:
>>> >>
>>> >>
>>> >>
>>> >> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=
>>> >> 14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comm
>>> >> ent-tabpanel#comment-14070908
>>> >>
>>> >> Mark's recent comments cast some doubt on whether it is essential:
>>> >>
>>> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
>>> >>
>>> >> and in recent conversations I didn't hear dissent to the idea of
>>> >> removing this.
>>> >>
>>> >> Is this still useful enough to fix up? All else equal I'd like to
>>> >> start to walk back some of the complexity of the build, but I
>>> >> don't know how all-else-equal it is. Certainly, it sounds like
>>> >> nobody intends these to be used to actually deploy Spark.
>>> >>
>>> >> I don't doubt it's useful to someone, but can they maintain the
>>> >> packaging logic elsewhere?
>>> >>
>>> >> ------------------------------------------------------------------
>>> >> --- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
>>> >> additional commands, e-mail: dev-help@spark.apache.org
>>> >>
>>> >>
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
>>> additional commands, e-mail: dev-help@spark.apache.org
>>>
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11553-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:12:10 2015
Return-Path: <dev-return-11553-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 218EB178DF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:12:10 +0000 (UTC)
Received: (qmail 52452 invoked by uid 500); 10 Feb 2015 06:12:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52371 invoked by uid 500); 10 Feb 2015 06:12:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52358 invoked by uid 99); 10 Feb 2015 06:12:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:12:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:11:44 +0000
Received: by mail-pa0-f54.google.com with SMTP id kx10so23877657pab.13
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:11:42 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=Zkgk8cKjMyjJ1Eh3OL8lXHFnKd/wc2jflJWlLYlW/GY=;
        b=u9MBJ/d9ExKbeNI4jAlqscCUeUDdqyr82trItmnNNpgEYKYntDzqg47d+kEVJaH8ES
         CZRO9jjoaTDDi1IkITUmUGMw4ciod1qbd9o+asbdltv7z3BxpuvXiP8vdBwkXibNSb0F
         tRu6NQM9Qb3ygD5hGojWRyqMxfzOXNjpUZXX0UK0LjpYH6nqp2682NtdpuJNST/v4K0p
         aF5Z/G8gz+TfLua8avgrFPEsfU/cuNzhuJPwGNZec2JC0q/f2XOdY+ON/KFkDhebMBoy
         ww2lABCE5D4tlJvE5XUVLVJmEeWXObRw8NhC2N1dehKCWGHgHmI3bR4BfN5+3/4Xh/DS
         VEIA==
X-Received: by 10.68.222.40 with SMTP id qj8mr34893720pbc.51.1423548702728;
 Mon, 09 Feb 2015 22:11:42 -0800 (PST)
MIME-Version: 1.0
From: Denny Lee <denny.g.lee@gmail.com>
Date: Tue, 10 Feb 2015 06:11:41 +0000
Message-ID: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
Subject: Powered by Spark: Concur
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b2ee2e9bf28cf050eb5c296
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b2ee2e9bf28cf050eb5c296
Content-Type: text/plain; charset=UTF-8

Forgot to add Concur to the "Powered by Spark" wiki:

Concur
https://www.concur.com
Spark SQL, MLLib
Using Spark for travel and expenses analytics and personalization

Thanks!
Denny

--047d7b2ee2e9bf28cf050eb5c296--

From dev-return-11554-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:25:54 2015
Return-Path: <dev-return-11554-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 36B711792A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:25:54 +0000 (UTC)
Received: (qmail 63260 invoked by uid 500); 10 Feb 2015 06:25:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63183 invoked by uid 500); 10 Feb 2015 06:25:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63124 invoked by uid 99); 10 Feb 2015 06:25:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:25:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.175 as permitted sender)
Received: from [209.85.192.175] (HELO mail-pd0-f175.google.com) (209.85.192.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:25:47 +0000
Received: by pdbfp1 with SMTP id fp1so6263221pdb.9
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:23:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=9HnRVb6ftuYNT5U8lOBWodB0bDamZZPsGX9zNFq3Fwk=;
        b=y0VA2czlFz7ent/YGGMs+5WqKH854NKHXlpmiv0qaE25i/WCEFr5REmzR64HL4e93k
         TB4tAO1e9wrhMW8/dfY/gHrnqqEUDN42sLLTPdNTCRiBl4Ez60cWJPuzTtrfd4pGpYcs
         LBl8WBPsb8ErEVb9RmWOzleb4dqCf0WDaUqxOcuaPBdp0EMuJf6qcO4VTXEKzgKQb/69
         sf7VvjLERblYv65M6ZxBsE9uTgPRgK9T/BhpJ7K90AooDzsxvY+K6LEq6JDp+3D1f4ke
         IEt0MoHVgEaeDm1MY1XHXLmCMFrWrVHa9777Bq51cXUErjdoV9UAUWKAsteQU+podXmD
         XEhA==
X-Received: by 10.66.141.42 with SMTP id rl10mr35124738pab.124.1423549437589;
        Mon, 09 Feb 2015 22:23:57 -0800 (PST)
Received: from [192.168.1.100] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id q2sm18202678pde.27.2015.02.09.22.23.56
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 09 Feb 2015 22:23:56 -0800 (PST)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
Subject: Re: Powered by Spark: Concur
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
Date: Mon, 9 Feb 2015 22:23:55 -0800
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: 7bit
Message-Id: <7C2AEFFC-DBDB-41DB-9EF0-42AD838E2085@gmail.com>
References: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
To: Denny Lee <denny.g.lee@gmail.com>
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Denny; added you.

Matei

> On Feb 9, 2015, at 10:11 PM, Denny Lee <denny.g.lee@gmail.com> wrote:
> 
> Forgot to add Concur to the "Powered by Spark" wiki:
> 
> Concur
> https://www.concur.com
> Spark SQL, MLLib
> Using Spark for travel and expenses analytics and personalization
> 
> Thanks!
> Denny


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11555-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:41:19 2015
Return-Path: <dev-return-11555-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 52693179A9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:41:19 +0000 (UTC)
Received: (qmail 91243 invoked by uid 500); 10 Feb 2015 06:41:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91169 invoked by uid 500); 10 Feb 2015 06:41:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91156 invoked by uid 99); 10 Feb 2015 06:41:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:41:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.192.181 as permitted sender)
Received: from [209.85.192.181] (HELO mail-pd0-f181.google.com) (209.85.192.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:40:53 +0000
Received: by pdjp10 with SMTP id p10so26968149pdj.3
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:39:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=OjLNc3c02r4OebZEfJxYvxocbdXL7GWzmGslyfHrj9g=;
        b=yOnZ1c6nq9Insd+SFiTmsT0nbNkqRyKXnTnlGSO6aAn++9AbbxxjcYCD7iBfjQnfaB
         LqkWG9KrfdJ12kQD7rQuYLIMsraCouTFCtBtOjj81xQmMqjdryo6wND4usCeQbNTQDiD
         OY+y8REZAM7QIM3OQ56CCyvtDBedRtjLE9GhkMnFPLIRGUPDvos0HthGRE38Nw9l/p6r
         yRvY9qrhr4+fneKw0Wh53LJS/ShbKM8Ku9jIwxk0NDWxpT++z/R+ojSVAWsg/UqhqAHl
         0wgMOIfsgqyDi6v1gTotGBEfjOdJLr4Xv+q8jCRVygSG2sVCWtra0ji/O5f82VZnKYai
         CdBg==
X-Received: by 10.70.91.106 with SMTP id cd10mr35701681pdb.48.1423550361447;
 Mon, 09 Feb 2015 22:39:21 -0800 (PST)
MIME-Version: 1.0
References: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
 <7C2AEFFC-DBDB-41DB-9EF0-42AD838E2085@gmail.com>
From: Denny Lee <denny.g.lee@gmail.com>
Date: Tue, 10 Feb 2015 06:39:20 +0000
Message-ID: <CABjYQ39rUp5gRE2Jz7BOKT5hUUs3ZEfG2akpGf79UvfWbXN3fg@mail.gmail.com>
Subject: Re: Powered by Spark: Concur
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c231349d31cd050eb625c2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c231349d31cd050eb625c2
Content-Type: text/plain; charset=UTF-8

Thanks Matei - much appreciated!

On Mon Feb 09 2015 at 10:23:57 PM Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Thanks Denny; added you.
>
> Matei
>
> > On Feb 9, 2015, at 10:11 PM, Denny Lee <denny.g.lee@gmail.com> wrote:
> >
> > Forgot to add Concur to the "Powered by Spark" wiki:
> >
> > Concur
> > https://www.concur.com
> > Spark SQL, MLLib
> > Using Spark for travel and expenses analytics and personalization
> >
> > Thanks!
> > Denny
>
>

--001a11c231349d31cd050eb625c2--

From dev-return-11556-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:44:36 2015
Return-Path: <dev-return-11556-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D657179FE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:44:36 +0000 (UTC)
Received: (qmail 98934 invoked by uid 500); 10 Feb 2015 06:44:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98856 invoked by uid 500); 10 Feb 2015 06:44:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98844 invoked by uid 99); 10 Feb 2015 06:44:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:44:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_IMAGE_ONLY_32,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:44:26 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so30023975obc.1
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:43:20 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=G3S4eNKa69uyRs6msiH6h/pkCs1/KSmukmdqEbAz9T8=;
        b=HHURuXuCxQ8ZlDpaTzPXZVNEdjIh24OHqrK3d6qhu54F1DP60SWBBaLLRgrzEAlH8O
         fb4eLlAIoGuCRsK+uIGLAqNA1s0dnJW3GoPNek79RefN5C9f828CLHPa7P40+iy9c86I
         DP66F9a6ewR7UuojOFjnKzXJPLC94PrcjuLLv5EaiwfDEN42mLAraMhiwznRtOWcPWjE
         HKAMN+okTj8+720lULCvnbacjtWSgNIfKo/sdXXs6DEUP7s/QeGalaqVLw5JP7tAXRvh
         MXwOrUstiio1wxgn0DmLh9FBvKZre7nAKVRkNYvTyEJZ8yX+BKSrYPwXA2TveAv080sc
         Pm4Q==
MIME-Version: 1.0
X-Received: by 10.60.176.34 with SMTP id cf2mr14333691oec.52.1423550600870;
 Mon, 09 Feb 2015 22:43:20 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 22:43:20 -0800 (PST)
In-Reply-To: <CABPQxsstUZU5-GUY5zupsdn72kTcJou8YGBT3c3F99_Zq9SBUg@mail.gmail.com>
References: <93a33a9fbc404ba8859c2629684db67a@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
	<CABPQxsstUZU5-GUY5zupsdn72kTcJou8YGBT3c3F99_Zq9SBUg@mail.gmail.com>
Date: Mon, 9 Feb 2015 22:43:20 -0800
Message-ID: <CABPQxsvsYrFSgRN9GTvUytBbshUX+-d7u8JL4tX8Fgd6mttPfg@mail.gmail.com>
Subject: Re: New Metrics Sink class not packaged in spark-assembly jar
From: Patrick Wendell <pwendell@gmail.com>
To: Judy Nash <judynash@exchange.microsoft.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/related; boundary=089e01182b88e34925050eb63306
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01182b88e34925050eb63306
Content-Type: multipart/alternative; boundary=089e01182b88e34921050eb63305

--089e01182b88e34921050eb63305
Content-Type: text/plain; charset=ISO-8859-1

Actually, to correct myself, the assembly jar is in
assembly/target/scala-2.11 (I think).

On Mon, Feb 9, 2015 at 10:42 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hi Judy,
>
> If you have added source files in the sink/ source folder, they should
> appear in the assembly jar when you build. One thing I noticed is that you
> are looking inside the "/dist" folder. That only gets populated if you run
> "make-distribution". The normal development process is just to do "mvn
> package" and then look at the assembly jar that is contained in core/target.
>
> - Patrick
>
> On Mon, Feb 9, 2015 at 10:02 PM, Judy Nash <
> judynash@exchange.microsoft.com> wrote:
>
>>  Hello,
>>
>>
>>
>> Working on SPARK-5708 <https://issues.apache.org/jira/browse/SPARK-5708>
>> - Add Slf4jSink to Spark Metrics Sink.
>>
>>
>>
>> Wrote a new Slf4jSink class (see patch attached), but the new class is
>> not packaged as part of spark-assembly jar.
>>
>>
>>
>> Do I need to update build config somewhere to have this packaged?
>>
>>
>>
>> Current packaged class:
>>
>>
>>
>> Thought I must have missed something basic but can't figure out why.
>>
>>
>>
>> Thanks!
>>
>> Judy
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
>

--089e01182b88e34921050eb63305
Content-Type: text/html; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Actually, to correct myself, the assembly jar is in assemb=
ly/target/scala-2.11 (I think).</div><div class=3D"gmail_extra"><br><div cl=
ass=3D"gmail_quote">On Mon, Feb 9, 2015 at 10:42 PM, Patrick Wendell <span =
dir=3D"ltr">&lt;<a href=3D"mailto:pwendell@gmail.com" target=3D"_blank">pwe=
ndell@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" =
style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><di=
v dir=3D"ltr">Hi Judy,<div><br></div><div>If you have added source files in=
 the sink/ source folder, they should appear in the assembly jar when you b=
uild. One thing I noticed is that you are looking inside the &quot;/dist&qu=
ot; folder. That only gets populated if you run &quot;make-distribution&quo=
t;. The normal development process is just to do &quot;mvn package&quot; an=
d then look at the assembly jar that is contained in core/target.</div><div=
><br></div><div>- Patrick</div></div><div class=3D"gmail_extra"><br><div cl=
ass=3D"gmail_quote"><div><div class=3D"h5">On Mon, Feb 9, 2015 at 10:02 PM,=
 Judy Nash <span dir=3D"ltr">&lt;<a href=3D"mailto:judynash@exchange.micros=
oft.com" target=3D"_blank">judynash@exchange.microsoft.com</a>&gt;</span> w=
rote:<br></div></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 =
0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div><div class=3D"h5">





<div lang=3D"EN-US" link=3D"#0563C1" vlink=3D"#954F72">
<div>
<p class=3D"MsoNormal">Hello,<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Working on <a href=3D"https://issues.apache.org/jira=
/browse/SPARK-5708" target=3D"_blank">
SPARK-5708</a> &ndash; Add Slf4jSink to Spark Metrics Sink. <u></u><u></u><=
/p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Wrote a new Slf4jSink class (see patch attached), bu=
t the new class is not packaged as part of spark-assembly jar.<u></u><u></u=
></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Do I need to update build config somewhere to have t=
his packaged?
<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Current packaged class: <u></u><u></u></p>
<p class=3D"MsoNormal"><img border=3D"0" width=3D"523" height=3D"230" src=
=3D"cid:image001.png@01D044B4.1B17A1C0"><u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Thought I must have missed something basic but can&r=
squo;t figure out why.<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Thanks!<span><font color=3D"#888888"><u></u><u></u><=
/font></span></p><span><font color=3D"#888888">
<p class=3D"MsoNormal">Judy<u></u><u></u></p>
</font></span></div>
</div>

<br><br></div></div>
---------------------------------------------------------------------<br>
To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache.org"=
 target=3D"_blank">dev-unsubscribe@spark.apache.org</a><br>
For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apache.or=
g" target=3D"_blank">dev-help@spark.apache.org</a><br></blockquote></div><b=
r></div>
</blockquote></div><br></div>

--089e01182b88e34921050eb63305--
--089e01182b88e34925050eb63306--

From dev-return-11557-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 06:45:38 2015
Return-Path: <dev-return-11557-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1CF8F17A00
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 06:45:38 +0000 (UTC)
Received: (qmail 1549 invoked by uid 500); 10 Feb 2015 06:45:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1472 invoked by uid 500); 10 Feb 2015 06:45:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1460 invoked by uid 99); 10 Feb 2015 06:45:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:45:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_IMAGE_ONLY_28,HTML_IMAGE_RATIO_08,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.53 as permitted sender)
Received: from [209.85.218.53] (HELO mail-oi0-f53.google.com) (209.85.218.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 06:45:08 +0000
Received: by mail-oi0-f53.google.com with SMTP id u20so9694824oif.12
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 22:42:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Vp3MVm1XMDr3pUQ+hzPLestKy++1PQwl8MUsIk0l5hQ=;
        b=fuYr5vGXajQOU98ArQCbSnuk4byu41vybfsj9N7SfmJKanyE3iKzTVx4417cs8Uo7r
         osWmWAe6hbIAJOIFzLNdP65pgRZH49WXXzxZ8wduuoo1tOgtXqiLU7IPzYmN0x1vFDaZ
         iX6m7isMR+b4JKC7myAIHX15iYiDu1WIOiYIvlk2DiBX0+hUaIVUSD3SYkaB84ELIqWY
         nlif5C8Uq7wBY69/gMq2r56+Zajb7Jg8l6RCOMojMY6pOH9oMLSkfNHPKkRIOz2gMAO/
         peARrORjuYwt/NERplIIrYplwkrf7i/tKYDQ9MRbUxFay60rejKP/UsQvO56wXA1s9JL
         Cwzg==
MIME-Version: 1.0
X-Received: by 10.60.46.136 with SMTP id v8mr14705610oem.18.1423550571317;
 Mon, 09 Feb 2015 22:42:51 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 22:42:51 -0800 (PST)
In-Reply-To: <93a33a9fbc404ba8859c2629684db67a@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
References: <93a33a9fbc404ba8859c2629684db67a@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
Date: Mon, 9 Feb 2015 22:42:51 -0800
Message-ID: <CABPQxsstUZU5-GUY5zupsdn72kTcJou8YGBT3c3F99_Zq9SBUg@mail.gmail.com>
Subject: Re: New Metrics Sink class not packaged in spark-assembly jar
From: Patrick Wendell <pwendell@gmail.com>
To: Judy Nash <judynash@exchange.microsoft.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/related; boundary=089e01537e80201dea050eb632fd
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01537e80201dea050eb632fd
Content-Type: multipart/alternative; boundary=089e01537e80201de6050eb632fc

--089e01537e80201de6050eb632fc
Content-Type: text/plain; charset=ISO-8859-1

Hi Judy,

If you have added source files in the sink/ source folder, they should
appear in the assembly jar when you build. One thing I noticed is that you
are looking inside the "/dist" folder. That only gets populated if you run
"make-distribution". The normal development process is just to do "mvn
package" and then look at the assembly jar that is contained in core/target.

- Patrick

On Mon, Feb 9, 2015 at 10:02 PM, Judy Nash <judynash@exchange.microsoft.com>
wrote:

>  Hello,
>
>
>
> Working on SPARK-5708 <https://issues.apache.org/jira/browse/SPARK-5708>
> - Add Slf4jSink to Spark Metrics Sink.
>
>
>
> Wrote a new Slf4jSink class (see patch attached), but the new class is not
> packaged as part of spark-assembly jar.
>
>
>
> Do I need to update build config somewhere to have this packaged?
>
>
>
> Current packaged class:
>
>
>
> Thought I must have missed something basic but can't figure out why.
>
>
>
> Thanks!
>
> Judy
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

--089e01537e80201de6050eb632fc
Content-Type: text/html; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Judy,<div><br></div><div>If you have added source files=
 in the sink/ source folder, they should appear in the assembly jar when yo=
u build. One thing I noticed is that you are looking inside the &quot;/dist=
&quot; folder. That only gets populated if you run &quot;make-distribution&=
quot;. The normal development process is just to do &quot;mvn package&quot;=
 and then look at the assembly jar that is contained in core/target.</div><=
div><br></div><div>- Patrick</div></div><div class=3D"gmail_extra"><br><div=
 class=3D"gmail_quote">On Mon, Feb 9, 2015 at 10:02 PM, Judy Nash <span dir=
=3D"ltr">&lt;<a href=3D"mailto:judynash@exchange.microsoft.com" target=3D"_=
blank">judynash@exchange.microsoft.com</a>&gt;</span> wrote:<br><blockquote=
 class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc soli=
d;padding-left:1ex">





<div lang=3D"EN-US" link=3D"#0563C1" vlink=3D"#954F72">
<div>
<p class=3D"MsoNormal">Hello,<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Working on <a href=3D"https://issues.apache.org/jira=
/browse/SPARK-5708" target=3D"_blank">
SPARK-5708</a> &ndash; Add Slf4jSink to Spark Metrics Sink. <u></u><u></u><=
/p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Wrote a new Slf4jSink class (see patch attached), bu=
t the new class is not packaged as part of spark-assembly jar.<u></u><u></u=
></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Do I need to update build config somewhere to have t=
his packaged?
<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Current packaged class: <u></u><u></u></p>
<p class=3D"MsoNormal"><img border=3D"0" width=3D"523" height=3D"230" src=
=3D"cid:image001.png@01D044B4.1B17A1C0"><u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Thought I must have missed something basic but can&r=
squo;t figure out why.<u></u><u></u></p>
<p class=3D"MsoNormal"><u></u>&nbsp;<u></u></p>
<p class=3D"MsoNormal">Thanks!<span class=3D"HOEnZb"><font color=3D"#888888=
"><u></u><u></u></font></span></p><span class=3D"HOEnZb"><font color=3D"#88=
8888">
<p class=3D"MsoNormal">Judy<u></u><u></u></p>
</font></span></div>
</div>

<br><br>
---------------------------------------------------------------------<br>
To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache.org"=
>dev-unsubscribe@spark.apache.org</a><br>
For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apache.or=
g">dev-help@spark.apache.org</a><br></blockquote></div><br></div>

--089e01537e80201de6050eb632fc--
--089e01537e80201dea050eb632fd--

From dev-return-11558-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 07:07:11 2015
Return-Path: <dev-return-11558-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE56917B8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 07:07:11 +0000 (UTC)
Received: (qmail 49577 invoked by uid 500); 10 Feb 2015 07:07:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49504 invoked by uid 500); 10 Feb 2015 07:07:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49493 invoked by uid 99); 10 Feb 2015 07:07:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:07:10 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of judynash@exchange.microsoft.com designates 64.4.22.89 as permitted sender)
Received: from [64.4.22.89] (HELO na01-by1-obe.outbound.o365filtering.com) (64.4.22.89)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:07:00 +0000
Received: from CH1SR01CA101.namsdf01.sdf.exchangelabs.com (10.255.157.18) by
 BL2SR01MB606.namsdf01.sdf.exchangelabs.com (10.255.109.168) with Microsoft
 SMTP Server (TLS) id 15.1.93.2; Tue, 10 Feb 2015 07:06:37 +0000
Received: from SN2FFOFD003.ffo.gbl (2a01:111:f400:7c04::24) by
 CH1SR01CA101.outlook.office365.com (2a01:111:e400:1801::18) with Microsoft
 SMTP Server (TLS) id 15.1.99.3 via Frontend Transport; Tue, 10 Feb 2015
 07:06:37 +0000
Received: from hybrid.exchange.microsoft.com (131.107.159.100) by
 SN2FFOFD003.mail.o365filtering.com (10.111.201.40) with Microsoft SMTP Server
 (TLS) id 15.1.87.3 via Frontend Transport; Tue, 10 Feb 2015 07:06:37 +0000
Received: from df-h14-01.exchange.corp.microsoft.com (157.54.78.139) by
 DFM-TK5EDG15-02.exchange.corp.microsoft.com (157.54.27.97) with Microsoft
 SMTP Server (TLS) id 15.0.1044.22; Tue, 10 Feb 2015 07:06:30 +0000
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DF-H14-01.exchange.corp.microsoft.com (157.54.78.139) with Microsoft SMTP
 Server (TLS) id 14.3.235.0; Tue, 10 Feb 2015 07:06:29 +0000
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) with Microsoft
 SMTP Server (TLS) id 15.0.1076.3; Mon, 9 Feb 2015 23:06:27 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92])
 by DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92]) with mapi id
 15.00.1076.000; Mon, 9 Feb 2015 23:06:27 -0800
From: Judy Nash <judynash@exchange.microsoft.com>
To: Patrick Wendell <pwendell@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: New Metrics Sink class not packaged in spark-assembly jar
Thread-Topic: New Metrics Sink class not packaged in spark-assembly jar
Thread-Index: AQHQRPzO03hs3PBCYkGlMQ/jKNG1l5zp9dkA//9+jUA=
Date: Tue, 10 Feb 2015 07:06:26 +0000
Message-ID: <df399d24ec014267832cdfcf7ecc50b7@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
References: <93a33a9fbc404ba8859c2629684db67a@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
	<CABPQxsstUZU5-GUY5zupsdn72kTcJou8YGBT3c3F99_Zq9SBUg@mail.gmail.com>
 <CABPQxsvsYrFSgRN9GTvUytBbshUX+-d7u8JL4tX8Fgd6mttPfg@mail.gmail.com>
In-Reply-To: <CABPQxsvsYrFSgRN9GTvUytBbshUX+-d7u8JL4tX8Fgd6mttPfg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [157.59.235.233]
Content-Type: multipart/related;
	boundary="_004_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_";
	type="multipart/alternative"
MIME-Version: 1.0
X-EOPAttributedMessage: 0
X-Forefront-Antispam-Report:
	CIP:131.107.159.100;IPV:NLI;EFV:NLI;SFV:NSPM;SFS:(10019020)(199003)(189002)(377454003)(57704003)(24454002)(41574002)(252514010)(92566002)(99936001)(66926002)(97736003)(33646002)(19627595001)(106116001)(19617315012)(50986999)(54356999)(110136001)(76176999)(66066001)(2900100001)(2950100001)(86362001)(68736005)(67866002)(102836002)(15975445007)(92726002)(18206015028)(19580395003)(19580405001)(17760045003)(84326002)(64706001)(19300405004)(46102003)(87936001)(6806004)(1411001)(106466001)(2656002)(77156002)(62966003)(16236675004)(108616004)(19625215002)(512954002)(105596002)(24736002);DIR:OUT;SFP:1102;SCL:1;SRVR:BL2SR01MB606;H:hybrid.exchange.microsoft.com;FPR:;SPF:SoftFail;PTR:InfoDomainNonexistent;A:1;MX:1;LANG:en;
X-Microsoft-Antispam: UriScan:;
X-Microsoft-Antispam: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB606;
X-Exchange-Antispam-Report-Test: UriScan:;
X-Exchange-Antispam-Report-CFA-Test: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB606;
X-Forefront-PRVS: 048396AFA0
Received-SPF: SoftFail (protection.outlook.com: domain of transitioning
 exchange.microsoft.com discourages use of 131.107.159.100 as permitted
 sender)
Authentication-Results: spf=softfail (sender IP is 131.107.159.100)
 smtp.mailfrom=judynash@exchange.microsoft.com; 
X-Exchange-Antispam-Report-CFA-Test: BCL:0;PCL:0;RULEID:;SRVR:BL2SR01MB606;
X-OriginatorOrg: exchange.microsoft.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 10 Feb 2015 07:06:37.0530
 (UTC)
X-MS-Exchange-CrossTenant-Id: f686d426-8d16-42db-81b7-ab578e110ccd
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f686d426-8d16-42db-81b7-ab578e110ccd;Ip=[131.107.159.100]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: BL2SR01MB606
X-Virus-Checked: Checked by ClamAV on apache.org

--_004_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_
Content-Type: multipart/alternative;
	boundary="_000_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_"

--_000_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Thanks Patrick! That was the issue.
Built the jars on windows env with mvn and forgot to run make-distributions=
.ps1  afterward, so was looking at old jars.

From: Patrick Wendell [mailto:pwendell@gmail.com]
Sent: Monday, February 9, 2015 10:43 PM
To: Judy Nash
Cc: dev@spark.apache.org
Subject: Re: New Metrics Sink class not packaged in spark-assembly jar

Actually, to correct myself, the assembly jar is in assembly/target/scala-2=
.11 (I think).

On Mon, Feb 9, 2015 at 10:42 PM, Patrick Wendell <pwendell@gmail.com<mailto=
:pwendell@gmail.com>> wrote:
Hi Judy,

If you have added source files in the sink/ source folder, they should appe=
ar in the assembly jar when you build. One thing I noticed is that you are =
looking inside the "/dist" folder. That only gets populated if you run "mak=
e-distribution". The normal development process is just to do "mvn package"=
 and then look at the assembly jar that is contained in core/target.

- Patrick

On Mon, Feb 9, 2015 at 10:02 PM, Judy Nash <judynash@exchange.microsoft.com=
<mailto:judynash@exchange.microsoft.com>> wrote:
Hello,

Working on SPARK-5708<https://issues.apache.org/jira/browse/SPARK-5708> - A=
dd Slf4jSink to Spark Metrics Sink.

Wrote a new Slf4jSink class (see patch attached), but the new class is not =
packaged as part of spark-assembly jar.

Do I need to update build config somewhere to have this packaged?

Current packaged class:
[cid:image001.png@01D044BC.8FE515C0]

Thought I must have missed something basic but can't figure out why.

Thanks!
Judy

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubsc=
ribe@spark.apache.org>
For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev-help@=
spark.apache.org>



--_000_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_
Content-Type: text/html; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

<html xmlns:v=3D"urn:schemas-microsoft-com:vml" xmlns:o=3D"urn:schemas-micr=
osoft-com:office:office" xmlns:w=3D"urn:schemas-microsoft-com:office:word" =
xmlns:m=3D"http://schemas.microsoft.com/office/2004/12/omml" xmlns=3D"http:=
//www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Dus-ascii"=
>
<meta name=3D"Generator" content=3D"Microsoft Word 15 (filtered medium)">
<!--[if !mso]><style>v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style><![endif]--><style><!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:"Times New Roman","serif";}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-priority:99;
	color:purple;
	text-decoration:underline;}
span.EmailStyle17
	{mso-style-type:personal-reply;
	font-family:"Calibri","sans-serif";
	color:#1F497D;}
.MsoChpDefault
	{mso-style-type:export-only;
	font-family:"Calibri","sans-serif";}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--></style><!--[if gte mso 9]><xml>
<o:shapedefaults v:ext=3D"edit" spidmax=3D"1026" />
</xml><![endif]--><!--[if gte mso 9]><xml>
<o:shapelayout v:ext=3D"edit">
<o:idmap v:ext=3D"edit" data=3D"1" />
</o:shapelayout></xml><![endif]-->
</head>
<body lang=3D"EN-US" link=3D"blue" vlink=3D"purple">
<div class=3D"WordSection1">
<p class=3D"MsoNormal"><span style=3D"font-size:11.0pt;font-family:&quot;Ca=
libri&quot;,&quot;sans-serif&quot;;color:#1F497D">Thanks Patrick! That was =
the issue.<o:p></o:p></span></p>
<p class=3D"MsoNormal"><span style=3D"font-size:11.0pt;font-family:&quot;Ca=
libri&quot;,&quot;sans-serif&quot;;color:#1F497D">Built the jars on windows=
 env with mvn and forgot to run make-distributions.ps1 &nbsp;afterward, so =
was looking at old jars.
<o:p></o:p></span></p>
<p class=3D"MsoNormal"><span style=3D"font-size:11.0pt;font-family:&quot;Ca=
libri&quot;,&quot;sans-serif&quot;;color:#1F497D"><o:p>&nbsp;</o:p></span><=
/p>
<p class=3D"MsoNormal"><b><span style=3D"font-size:11.0pt;font-family:&quot=
;Calibri&quot;,&quot;sans-serif&quot;">From:</span></b><span style=3D"font-=
size:11.0pt;font-family:&quot;Calibri&quot;,&quot;sans-serif&quot;"> Patric=
k Wendell [mailto:pwendell@gmail.com]
<br>
<b>Sent:</b> Monday, February 9, 2015 10:43 PM<br>
<b>To:</b> Judy Nash<br>
<b>Cc:</b> dev@spark.apache.org<br>
<b>Subject:</b> Re: New Metrics Sink class not packaged in spark-assembly j=
ar<o:p></o:p></span></p>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<p class=3D"MsoNormal">Actually, to correct myself, the assembly jar is in =
assembly/target/scala-2.11 (I think).<o:p></o:p></p>
</div>
<div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<p class=3D"MsoNormal">On Mon, Feb 9, 2015 at 10:42 PM, Patrick Wendell &lt=
;<a href=3D"mailto:pwendell@gmail.com" target=3D"_blank">pwendell@gmail.com=
</a>&gt; wrote:<o:p></o:p></p>
<blockquote style=3D"border:none;border-left:solid #CCCCCC 1.0pt;padding:0i=
n 0in 0in 6.0pt;margin-left:4.8pt;margin-right:0in">
<div>
<p class=3D"MsoNormal">Hi Judy,<o:p></o:p></p>
<div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class=3D"MsoNormal">If you have added source files in the sink/ source f=
older, they should appear in the assembly jar when you build. One thing I n=
oticed is that you are looking inside the &quot;/dist&quot; folder. That on=
ly gets populated if you run &quot;make-distribution&quot;.
 The normal development process is just to do &quot;mvn package&quot; and t=
hen look at the assembly jar that is contained in core/target.<o:p></o:p></=
p>
</div>
<div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
<div>
<p class=3D"MsoNormal">- Patrick<o:p></o:p></p>
</div>
</div>
<div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
<div>
<div>
<div>
<p class=3D"MsoNormal">On Mon, Feb 9, 2015 at 10:02 PM, Judy Nash &lt;<a hr=
ef=3D"mailto:judynash@exchange.microsoft.com" target=3D"_blank">judynash@ex=
change.microsoft.com</a>&gt; wrote:<o:p></o:p></p>
</div>
</div>
<blockquote style=3D"border:none;border-left:solid #CCCCCC 1.0pt;padding:0i=
n 0in 0in 6.0pt;margin-left:4.8pt;margin-right:0in">
<div>
<div>
<div>
<div>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Hello,<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Working on
<a href=3D"https://issues.apache.org/jira/browse/SPARK-5708" target=3D"_bla=
nk">SPARK-5708</a> &#8211; Add Slf4jSink to Spark Metrics Sink.
<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Wrote a new Slf4jSink class (see patch attached), but the new clas=
s is not packaged as part of spark-assembly jar.<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Do I need to update build config somewhere to have this packaged?
<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Current packaged class:
<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto"><img border=3D"0" width=3D"523" height=3D"230" id=3D"_x0000_i1025"=
 src=3D"cid:image001.png@01D044BC.8FE515C0"><o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Thought I must have missed something basic but can&#8217;t figure =
out why.<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">&nbsp;<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto">Thanks!<o:p></o:p></p>
<p class=3D"MsoNormal" style=3D"mso-margin-top-alt:auto;mso-margin-bottom-a=
lt:auto"><span style=3D"color:#888888">Judy<o:p></o:p></span></p>
</div>
</div>
<p class=3D"MsoNormal" style=3D"margin-bottom:12.0pt"><o:p>&nbsp;</o:p></p>
</div>
</div>
<p class=3D"MsoNormal">----------------------------------------------------=
-----------------<br>
To unsubscribe, e-mail: <a href=3D"mailto:dev-unsubscribe@spark.apache.org"=
 target=3D"_blank">
dev-unsubscribe@spark.apache.org</a><br>
For additional commands, e-mail: <a href=3D"mailto:dev-help@spark.apache.or=
g" target=3D"_blank">
dev-help@spark.apache.org</a><o:p></o:p></p>
</blockquote>
</div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</blockquote>
</div>
<p class=3D"MsoNormal"><o:p>&nbsp;</o:p></p>
</div>
</div>
</body>
</html>

--_000_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_--

--_004_df399d24ec014267832cdfcf7ecc50b7DFMDB3MBX1508exchangeco_--

From dev-return-11559-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 07:10:41 2015
Return-Path: <dev-return-11559-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C71D717BB1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 07:10:41 +0000 (UTC)
Received: (qmail 61900 invoked by uid 500); 10 Feb 2015 07:10:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61826 invoked by uid 500); 10 Feb 2015 07:10:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61812 invoked by uid 99); 10 Feb 2015 07:10:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:10:40 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of paolo.platter@agilelab.it designates 157.56.112.61 as permitted sender)
Received: from [157.56.112.61] (HELO emea01-am1-obe.outbound.protection.outlook.com) (157.56.112.61)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:10:35 +0000
Received: from AM3PR05MB0822.eurprd05.prod.outlook.com (25.161.33.13) by
 AM3PR05MB0824.eurprd05.prod.outlook.com (25.161.33.14) with Microsoft SMTP
 Server (TLS) id 15.1.81.19; Tue, 10 Feb 2015 07:10:13 +0000
Received: from AM3PR05MB0822.eurprd05.prod.outlook.com ([25.161.33.13]) by
 AM3PR05MB0822.eurprd05.prod.outlook.com ([25.161.33.13]) with mapi id
 15.01.0081.018; Tue, 10 Feb 2015 07:10:13 +0000
From: Paolo Platter <paolo.platter@agilelab.it>
To: Denny Lee <denny.g.lee@gmail.com>, Matei Zaharia <matei.zaharia@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: R: Powered by Spark: Concur
Thread-Topic: Powered by Spark: Concur
Thread-Index: AQHQRPiDfyB+Wg5QO0CAlp9pElxL9pzpalmAgAAE4cGAAAgPUg==
Date: Tue, 10 Feb 2015 07:10:13 +0000
Message-ID: <AM3PR05MB0822A94F1F553FDBA7C73E84F9240@AM3PR05MB0822.eurprd05.prod.outlook.com>
References: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
 <7C2AEFFC-DBDB-41DB-9EF0-42AD838E2085@gmail.com>,<CABjYQ39rUp5gRE2Jz7BOKT5hUUs3ZEfG2akpGf79UvfWbXN3fg@mail.gmail.com>
In-Reply-To: <CABjYQ39rUp5gRE2Jz7BOKT5hUUs3ZEfG2akpGf79UvfWbXN3fg@mail.gmail.com>
Accept-Language: it-IT, en-US
Content-Language: it-IT
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [91.253.251.216]
authentication-results: gmail.com; dkim=none (message not signed)
 header.d=none;
x-microsoft-antispam: BCL:0;PCL:0;RULEID:;SRVR:AM3PR05MB0824;
x-exchange-antispam-report-test: UriScan:;
x-exchange-antispam-report-cfa-test: BCL:0;PCL:0;RULEID:;SRVR:AM3PR05MB0824;
x-forefront-prvs: 048396AFA0
x-forefront-antispam-report: SFV:NSPM;SFS:(10009020)(41574002)(51704005)(24454002)(377454003)(19625215002)(15974865002)(86362001)(19617315012)(87936001)(106116001)(2656002)(62966003)(77156002)(19580395003)(19580405001)(229853001)(76576001)(2900100001)(2950100001)(74482002)(46102003)(40100003)(66066001)(33656002)(16236675004)(122556002)(92566002)(50986999)(54356999)(76176999)(74316001)(102836002)(15975445007);DIR:OUT;SFP:1101;SCL:1;SRVR:AM3PR05MB0824;H:AM3PR05MB0822.eurprd05.prod.outlook.com;FPR:;SPF:None;MLV:sfv;LANG:en;
Content-Type: multipart/alternative;
	boundary="_000_AM3PR05MB0822A94F1F553FDBA7C73E84F9240AM3PR05MB0822eurp_"
MIME-Version: 1.0
X-OriginatorOrg: agilelab.it
X-MS-Exchange-CrossTenant-originalarrivaltime: 10 Feb 2015 07:10:13.4891
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: eee7e750-299f-468f-a6c3-9f28923f6133
X-MS-Exchange-Transport-CrossTenantHeadersStamped: AM3PR05MB0824
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_AM3PR05MB0822A94F1F553FDBA7C73E84F9240AM3PR05MB0822eurp_
Content-Type: text/plain; charset="windows-1256"
Content-Transfer-Encoding: quoted-printable

Hi,

I checked the powered by wiki too and Agile Labs should be Agile Lab. The l=
ink is wrong too, it should be www.agilelab.it.
The description is correct.

Thanks a lot

Paolo

Inviata dal mio Windows Phone
________________________________
Da: Denny Lee<mailto:denny.g.lee@gmail.com>
Inviato: =FD10/=FD02/=FD2015 07:41
A: Matei Zaharia<mailto:matei.zaharia@gmail.com>
Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
Oggetto: Re: Powered by Spark: Concur

Thanks Matei - much appreciated!

On Mon Feb 09 2015 at 10:23:57 PM Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Thanks Denny; added you.
>
> Matei
>
> > On Feb 9, 2015, at 10:11 PM, Denny Lee <denny.g.lee@gmail.com> wrote:
> >
> > Forgot to add Concur to the "Powered by Spark" wiki:
> >
> > Concur
> > https://www.concur.com
> > Spark SQL, MLLib
> > Using Spark for travel and expenses analytics and personalization
> >
> > Thanks!
> > Denny
>
>

--_000_AM3PR05MB0822A94F1F553FDBA7C73E84F9240AM3PR05MB0822eurp_--

From dev-return-11560-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 07:49:09 2015
Return-Path: <dev-return-11560-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E9D2A17CA9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 07:49:08 +0000 (UTC)
Received: (qmail 28896 invoked by uid 500); 10 Feb 2015 07:49:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28819 invoked by uid 500); 10 Feb 2015 07:49:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28796 invoked by uid 99); 10 Feb 2015 07:49:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:49:07 +0000
X-ASF-Spam-Status: No, hits=4.5 required=10.0
	tests=HTML_MESSAGE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of sam.halliday@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:49:02 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 615B313666F7
	for <dev@spark.apache.org>; Mon,  9 Feb 2015 23:48:12 -0800 (PST)
Date: Tue, 10 Feb 2015 00:48:11 -0700 (MST)
From: fommil <sam.halliday@gmail.com>
To: dev@spark.apache.org
Message-ID: <CALR_T9CjHs54kn5h_evVw6GnzjAsNbRZQov=Mb4bJSq=p9WqEg@mail.gmail.com>
In-Reply-To: <CA+-p3AE1ynYt9XE3Gqg=hSZKVqPTb00NAw_EuJ2vYpA12w7yjQ@mail.gmail.com>
References: <1423273025027-10502.post@n3.nabble.com> <CAHUQ+_ajuMV090D=-jZsBnyzpPotLxF6sBBRWnfH9awN-P+v1g@mail.gmail.com> <CA+-p3AE1ynYt9XE3Gqg=hSZKVqPTb00NAw_EuJ2vYpA12w7yjQ@mail.gmail.com>
Subject: Re: Pull Requests on github
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_54183_552267303.1423554491949"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_54183_552267303.1423554491949
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Cool, thanks! Let me know if there are any more core numerical libraries
that you'd like to see to support Spark with optimised natives using a
similar packaging model at netlib-java.

I'm interested in fast random number generation next, and I keep wondering
if anybody would be interested in paying for FPGA or GPU / APU backends for
netlib-java. It would be a *lot* of work but I'd be very interested to talk
to an organisation with such a requirement and I'd be able to do it in less
time than they would internally.
On 10 Feb 2015 04:12, "Andrew Ash [via Apache Spark Developers List]" <
ml-node+s1001551n10546h44@n3.nabble.com> wrote:

> Sam, I see your PR was merged -- many thanks for sending it in and getting
> it merged!
>
> In general for future reference, the most effective way to contribute is
> outlined on this wiki page:
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
>
> On Mon, Feb 9, 2015 at 1:04 AM, Akhil Das <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=10546&i=0>>
> wrote:
>
> > You can open a Jira issue pointing this PR to get it processed faster.
> :)
> >
> > Thanks
> > Best Regards
> >
> > On Sat, Feb 7, 2015 at 7:07 AM, fommil <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=10546&i=1>> wrote:
> >
> > > Hi all,
> > >
> > > I'm the author of netlib-java and I noticed that the documentation in
> > MLlib
> > > was out of date and misleading, so I submitted a pull request on
> github
> > > which will hopefully make things easier for everybody to understand
> the
> > > benefits of system optimised natives and how to use them :-)
> > >
> > >   https://github.com/apache/spark/pull/4448
> > >
> > > However, it looks like there are a *lot* of outstanding PRs and that
> this
> > > is
> > > just a mirror repository.
> > >
> > > Will somebody please look at my PR and merge into the canonical source
> > (and
> > > let me know)?
> > >
> > > Best regards,
> > > Sam
> > >
> > >
> > >
> > > --
> > > View this message in context:
> > >
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502.html
> > > Sent from the Apache Spark Developers List mailing list archive at
> > > Nabble.com.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=10546&i=2>
> > > For additional commands, e-mail: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=10546&i=3>
> > >
> > >
> >
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502p10546.html
>  To unsubscribe from Pull Requests on github, click here
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=10502&code=c2FtLmhhbGxpZGF5QGdtYWlsLmNvbXwxMDUwMnwtMzI4MzQzMDI0>
> .
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Pull-Requests-on-github-tp10502p10558.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_54183_552267303.1423554491949--

From dev-return-11561-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 08:00:16 2015
Return-Path: <dev-return-11561-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C811F17D03
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 08:00:16 +0000 (UTC)
Received: (qmail 46602 invoked by uid 500); 10 Feb 2015 08:00:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46534 invoked by uid 500); 10 Feb 2015 08:00:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46518 invoked by uid 99); 10 Feb 2015 08:00:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 08:00:15 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 07:59:51 +0000
Received: by mail-ob0-f180.google.com with SMTP id vb8so30316596obc.11
        for <dev@spark.apache.org>; Mon, 09 Feb 2015 23:59:04 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=AinKqxACcB5f/CNT6UoCMnXncpb56K0+Zwx/d6OAiAc=;
        b=ko200ibspF8BhpC9nmowhZ+XtSOHTERRos5mq27UdMeQInDl71JE9DCkXG78I171qO
         oQS7zOTZsvI8+3JY3ZPsingkNyAn9Rvy+oNptJI7gwyPWvlXj0JP3UQS1DQSkxan8Dsd
         Px759XvzjD6zu4HlYe0osPbBA4wbqCcXmC7xQO2MpjZ9On2SZ4Ro9OwCKA3ZZ+dEkxUe
         DtmaQp8fPWH0q/C5Q7gfsmBcrFYssHjN3vFwAyDrZGKLEdIXCwBQD+BRDxHporr2IfiT
         a4ct2L2OoshaznozTx24Hl4gqtKHKxCx3xW+Ujx3H+a9SqHSr8sIHU497jkIXyscv3rp
         eKdA==
MIME-Version: 1.0
X-Received: by 10.182.144.229 with SMTP id sp5mr14359397obb.14.1423555144233;
 Mon, 09 Feb 2015 23:59:04 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 9 Feb 2015 23:59:04 -0800 (PST)
In-Reply-To: <AM3PR05MB0822A94F1F553FDBA7C73E84F9240@AM3PR05MB0822.eurprd05.prod.outlook.com>
References: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
	<7C2AEFFC-DBDB-41DB-9EF0-42AD838E2085@gmail.com>
	<CABjYQ39rUp5gRE2Jz7BOKT5hUUs3ZEfG2akpGf79UvfWbXN3fg@mail.gmail.com>
	<AM3PR05MB0822A94F1F553FDBA7C73E84F9240@AM3PR05MB0822.eurprd05.prod.outlook.com>
Date: Mon, 9 Feb 2015 23:59:04 -0800
Message-ID: <CABPQxsvAowQfrFbvY3Y7xawB79EP6D=7bQssP6d2E2wFCfvG4Q@mail.gmail.com>
Subject: Re: Powered by Spark: Concur
From: Patrick Wendell <pwendell@gmail.com>
To: Paolo Platter <paolo.platter@agilelab.it>
Cc: Denny Lee <denny.g.lee@gmail.com>, Matei Zaharia <matei.zaharia@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Paolo - I've fixed it.

On Mon, Feb 9, 2015 at 11:10 PM, Paolo Platter
<paolo.platter@agilelab.it> wrote:
> Hi,
>
> I checked the powered by wiki too and Agile Labs should be Agile Lab. The link is wrong too, it should be www.agilelab.it.
> The description is correct.
>
> Thanks a lot
>
> Paolo
>
> Inviata dal mio Windows Phone
> ________________________________
> Da: Denny Lee<mailto:denny.g.lee@gmail.com>
> Inviato: 10/02/2015 07:41
> A: Matei Zaharia<mailto:matei.zaharia@gmail.com>
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Oggetto: Re: Powered by Spark: Concur
>
> Thanks Matei - much appreciated!
>
> On Mon Feb 09 2015 at 10:23:57 PM Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>
>> Thanks Denny; added you.
>>
>> Matei
>>
>> > On Feb 9, 2015, at 10:11 PM, Denny Lee <denny.g.lee@gmail.com> wrote:
>> >
>> > Forgot to add Concur to the "Powered by Spark" wiki:
>> >
>> > Concur
>> > https://www.concur.com
>> > Spark SQL, MLLib
>> > Using Spark for travel and expenses analytics and personalization
>> >
>> > Thanks!
>> > Denny
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11562-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 08:03:29 2015
Return-Path: <dev-return-11562-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 83A8A17D0C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 08:03:29 +0000 (UTC)
Received: (qmail 49041 invoked by uid 500); 10 Feb 2015 08:03:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48966 invoked by uid 500); 10 Feb 2015 08:03:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48955 invoked by uid 99); 10 Feb 2015 08:03:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 08:03:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of paolo.platter@agilelab.it designates 157.55.234.72 as permitted sender)
Received: from [157.55.234.72] (HELO emea01-db3-obe.outbound.protection.outlook.com) (157.55.234.72)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 08:03:02 +0000
Received: from AM3PR05MB0822.eurprd05.prod.outlook.com (25.161.33.13) by
 AM3PR05MB0821.eurprd05.prod.outlook.com (25.161.33.12) with Microsoft SMTP
 Server (TLS) id 15.1.81.19; Tue, 10 Feb 2015 08:02:39 +0000
Received: from AM3PR05MB0822.eurprd05.prod.outlook.com ([25.161.33.13]) by
 AM3PR05MB0822.eurprd05.prod.outlook.com ([25.161.33.13]) with mapi id
 15.01.0081.018; Tue, 10 Feb 2015 08:02:39 +0000
From: Paolo Platter <paolo.platter@agilelab.it>
To: Patrick Wendell <pwendell@gmail.com>
CC: Denny Lee <denny.g.lee@gmail.com>, Matei Zaharia
	<matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Subject: R: Powered by Spark: Concur
Thread-Topic: Powered by Spark: Concur
Thread-Index: AQHQRPiDfyB+Wg5QO0CAlp9pElxL9pzpalmAgAAE4cGAAAgPUoAADaUAgAABAa8=
Date: Tue, 10 Feb 2015 08:02:39 +0000
Message-ID: <AM3PR05MB082227497C55106E42087DFDF9240@AM3PR05MB0822.eurprd05.prod.outlook.com>
References: <CABjYQ395nJ_HfaVhc8OcMJSPB5s_Bq4DMgEQ6d+uhQ6QeMgLqw@mail.gmail.com>
	<7C2AEFFC-DBDB-41DB-9EF0-42AD838E2085@gmail.com>
	<CABjYQ39rUp5gRE2Jz7BOKT5hUUs3ZEfG2akpGf79UvfWbXN3fg@mail.gmail.com>
	<AM3PR05MB0822A94F1F553FDBA7C73E84F9240@AM3PR05MB0822.eurprd05.prod.outlook.com>,<CABPQxsvAowQfrFbvY3Y7xawB79EP6D=7bQssP6d2E2wFCfvG4Q@mail.gmail.com>
In-Reply-To: <CABPQxsvAowQfrFbvY3Y7xawB79EP6D=7bQssP6d2E2wFCfvG4Q@mail.gmail.com>
Accept-Language: it-IT, en-US
Content-Language: it-IT
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [37.227.185.60]
authentication-results: gmail.com; dkim=none (message not signed)
 header.d=none;
x-microsoft-antispam: BCL:0;PCL:0;RULEID:;SRVR:AM3PR05MB0821;
x-exchange-antispam-report-test: UriScan:;
x-exchange-antispam-report-cfa-test: BCL:0;PCL:0;RULEID:;SRVR:AM3PR05MB0821;
x-forefront-prvs: 048396AFA0
x-forefront-antispam-report: SFV:NSPM;SFS:(10009020)(41574002)(24454002)(51704005)(479174004)(377454003)(122556002)(1411001)(50986999)(77156002)(74316001)(76576001)(66066001)(2900100001)(2950100001)(16236675004)(62966003)(33656002)(19625215002)(16601075003)(102836002)(15975445007)(40100003)(54356999)(93886004)(87936001)(86362001)(19580395003)(106116001)(19580405001)(2656002)(74482002)(92566002)(46102003)(14971765001)(19617315012)(229853001)(110136001);DIR:OUT;SFP:1101;SCL:1;SRVR:AM3PR05MB0821;H:AM3PR05MB0822.eurprd05.prod.outlook.com;FPR:;SPF:None;MLV:sfv;LANG:en;
Content-Type: multipart/alternative;
	boundary="_000_AM3PR05MB082227497C55106E42087DFDF9240AM3PR05MB0822eurp_"
MIME-Version: 1.0
X-OriginatorOrg: agilelab.it
X-MS-Exchange-CrossTenant-originalarrivaltime: 10 Feb 2015 08:02:39.5593
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: eee7e750-299f-468f-a6c3-9f28923f6133
X-MS-Exchange-Transport-CrossTenantHeadersStamped: AM3PR05MB0821
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_AM3PR05MB082227497C55106E42087DFDF9240AM3PR05MB0822eurp_
Content-Type: text/plain; charset="windows-1256"
Content-Transfer-Encoding: quoted-printable

Thank you!

Paolo

Inviata dal mio Windows Phone
________________________________
Da: Patrick Wendell<mailto:pwendell@gmail.com>
Inviato: =FD10/=FD02/=FD2015 08:59
A: Paolo Platter<mailto:paolo.platter@agilelab.it>
Cc: Denny Lee<mailto:denny.g.lee@gmail.com>; Matei Zaharia<mailto:matei.zah=
aria@gmail.com>; dev@spark.apache.org<mailto:dev@spark.apache.org>
Oggetto: Re: Powered by Spark: Concur

Thanks Paolo - I've fixed it.

On Mon, Feb 9, 2015 at 11:10 PM, Paolo Platter
<paolo.platter@agilelab.it> wrote:
> Hi,
>
> I checked the powered by wiki too and Agile Labs should be Agile Lab. The=
 link is wrong too, it should be www.agilelab.it<http://www.agilelab.it>.
> The description is correct.
>
> Thanks a lot
>
> Paolo
>
> Inviata dal mio Windows Phone
> ________________________________
> Da: Denny Lee<mailto:denny.g.lee@gmail.com>
> Inviato: 10/02/2015 07:41
> A: Matei Zaharia<mailto:matei.zaharia@gmail.com>
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Oggetto: Re: Powered by Spark: Concur
>
> Thanks Matei - much appreciated!
>
> On Mon Feb 09 2015 at 10:23:57 PM Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>
>> Thanks Denny; added you.
>>
>> Matei
>>
>> > On Feb 9, 2015, at 10:11 PM, Denny Lee <denny.g.lee@gmail.com> wrote:
>> >
>> > Forgot to add Concur to the "Powered by Spark" wiki:
>> >
>> > Concur
>> > https://www.concur.com
>> > Spark SQL, MLLib
>> > Using Spark for travel and expenses analytics and personalization
>> >
>> > Thanks!
>> > Denny
>>
>>

--_000_AM3PR05MB082227497C55106E42087DFDF9240AM3PR05MB0822eurp_--

From dev-return-11563-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 13:40:44 2015
Return-Path: <dev-return-11563-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A793210C58
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 13:40:44 +0000 (UTC)
Received: (qmail 99713 invoked by uid 500); 10 Feb 2015 13:40:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99639 invoked by uid 500); 10 Feb 2015 13:40:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99628 invoked by uid 99); 10 Feb 2015 13:40:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 13:40:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.223.173] (HELO mail-ie0-f173.google.com) (209.85.223.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 13:40:12 +0000
Received: by iebtr6 with SMTP id tr6so24542957ieb.4
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 05:39:50 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:from:content-type:content-transfer-encoding
         :subject:message-id:date:to:mime-version;
        bh=UgRp6blHHtCPmDOcBo9SNya8p3Z0KJcGFoR2Aqpuu4c=;
        b=FH/3B0oZK3fZ0D78mHRkAlITspLW9H3t5N0dnzYBlKSlVhFP5QMzoqbtvrFhZKh0pI
         dY5ixnB2W13DoFYlgFT8D4+6+fOf2nkULbNkpksHYaBrV4b1aZzZfa9d/noNbfr4UFjT
         ya0i2Cq3pmYlV/pv2FENVzl247jU5xqoI+XOhbClgScVf5fXOH7rTNUyMw2/9KjCv0B9
         Mm4Gdmr2619bCFIvkLMDCdsDvS6C5ZE9hGPlmgw9Ny0zMa2SPeYsgQ1N1WRL/mZXC5uj
         7JmHT7+vqSBCxXwQ49V/Jke6FFYq6c9SNe5BJ8/griYbuyyaY3nBiHwz/I9eqkSlcuAf
         41pg==
X-Gm-Message-State: ALoCoQkrEr94Ke/9xhlpkUscYqewphmDfeitqOudOsFql/BC8bGGffoDv533IouuraaoZ+jjvjAp
X-Received: by 10.107.12.196 with SMTP id 65mr31674742iom.71.1423575589898;
        Tue, 10 Feb 2015 05:39:49 -0800 (PST)
Received: from [192.168.1.8] (c-68-42-78-10.hsd1.mi.comcast.net. [68.42.78.10])
        by mx.google.com with ESMTPSA id a204sm8596609ioe.2.2015.02.10.05.39.49
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 10 Feb 2015 05:39:49 -0800 (PST)
From: Brock Palen <brockp@umich.edu>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Subject: Spark On HPC Podcast
Message-Id: <CABCD8C6-C335-47E5-8FC7-2F7A2F7F1A19@umich.edu>
Date: Tue, 10 Feb 2015 08:39:48 -0500
To: dev@spark.apache.org
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Sorry to pollute the list.

I am one half the HPC podcast www.rce-cast.com and we are looking to =
feature Spark on the show.

We are looking for a developer or two who can answer questions to =
educate the research community about Spark.

Please contact me off list.  It takes about an hour over the phone or =
Skype and is a friendly interview.

Thanks!

Brock Palen
www.umich.edu/~brockp
CAEN Advanced Computing
XSEDE Campus Champion
brockp@umich.edu
(734)936-1985




---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11564-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 13:51:36 2015
Return-Path: <dev-return-11564-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7406B10CAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 13:51:36 +0000 (UTC)
Received: (qmail 18299 invoked by uid 500); 10 Feb 2015 13:51:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18225 invoked by uid 500); 10 Feb 2015 13:51:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18212 invoked by uid 99); 10 Feb 2015 13:51:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 13:51:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_DBL_ABUSE_REDIR
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of iulian.dragos@typesafe.com designates 209.85.214.178 as permitted sender)
Received: from [209.85.214.178] (HELO mail-ob0-f178.google.com) (209.85.214.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 13:51:01 +0000
Received: by mail-ob0-f178.google.com with SMTP id uz6so31878045obc.9
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 05:49:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=typesafe.com; s=google;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=8cwKQvBXcRahVjnaDHZYAk3vMA7PCjHqqhqS0c4bQ/A=;
        b=eIzQH18AYvD4O51zGSBYsO1mvoQf4FxW5XhSLKPUrkQ2hMx/lT+3qwpdUmoNyMPx8i
         FBl3jcA58nBkUs9hSvQMUtQP1VINRj0iF+vNUhkFR2pqXGTTbaMt0RQh6VfmlJGWBVj8
         2IiNcIRQgxyljQ7LzHen86mWg01Thl0M+VQQY=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=8cwKQvBXcRahVjnaDHZYAk3vMA7PCjHqqhqS0c4bQ/A=;
        b=TvMYFv4M4mrXrwT6vfOxTo3euCS+Sjld59G/9cc2WW+NHNcCEPLWiu+wolLQmyjRk2
         Cd7kPAbPk9w0iQ6dZ1a2dzRiD/nJVfONUn0Rmwr5eclK19KmfLYfckbITTV8O/1DrUJc
         iKzmDpJ+LwlCSutYWy/Iw+TKr4vXmKczbQxtq/GK5kuCxnGEBCVTDtjp2UqvilHAlA/4
         isYCOAg7+tYhb2RJ1fS3TM75Qyq2XMB3F9Hgsvcxw39TvsDzOBVjc6YqCDuga9wUA9pu
         qI8wOwwVMg/EAgGDSPU4XIxdY+xwp+JKj74014o54VY1ktZx4uqteTJNGRXEEGB/Rhlr
         trhw==
X-Gm-Message-State: ALoCoQkMFNnvNYck3M7eYahO3Cjvm9fobWBqfjq1fJxRiBh8xpBBaElgBynVTjh6EdZvOaqskSfe
X-Received: by 10.202.186.85 with SMTP id k82mr14595307oif.69.1423576168777;
 Tue, 10 Feb 2015 05:49:28 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.50.11 with HTTP; Tue, 10 Feb 2015 05:49:08 -0800 (PST)
In-Reply-To: <etPan.54d9003c.66334873.124@Joshs-MacBook-Pro.local>
References: <CABPQxsupNXhGv_58pPMEwTY71RQwK2GpsGbU3SNoT5rFZDZF1Q@mail.gmail.com>
 <CAD2BF0+eQUbs5-DW6dviLECn4+D2we=+JE4paQJky1uwKjvU1w@mail.gmail.com> <etPan.54d9003c.66334873.124@Joshs-MacBook-Pro.local>
From: =?UTF-8?Q?Iulian_Drago=C8=99?= <iulian.dragos@typesafe.com>
Date: Tue, 10 Feb 2015 14:49:08 +0100
Message-ID: <CAD2BF0JO7k+AHC=dBs8MBoXvjKUC4PgcS9nateCjNuvc_BeURg@mail.gmail.com>
Subject: Re: Unit tests
To: Josh Rosen <rosenville@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113cdebad9df49050ebc2727
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cdebad9df49050ebc2727
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thank, Josh, I missed that PR.

On Mon, Feb 9, 2015 at 7:45 PM, Josh Rosen <rosenville@gmail.com> wrote:

> Hi Iulian,
>
> I think the AkakUtilsSuite failure that you observed has been fixed in
> https://issues.apache.org/jira/browse/SPARK-5548 /
> https://github.com/apache/spark/pull/4343
>
> On February 9, 2015 at 5:47:59 AM, Iulian Drago=C8=99 (
> iulian.dragos@typesafe.com) wrote:
>
> Hi Patrick,
>
> Thanks for the heads up. I was trying to set up our own infrastructure fo=
r
> testing Spark (essentially, running `run-tests` every night) on EC2. I
> stumbled upon a number of flaky tests, but none of them look similar to
> anything in Jira with the flaky-test tag. I wonder if there's something
> wrong with our infrastructure, or I should simply open Jira tickets with
> the failures I find. For example, one that appears fairly often on our
> setup is in AkkaUtilsSuite "remote fetch ssl on - untrusted server"
> (exception `ActorNotFound`, instead of `TimeoutException`).
>
> thanks,
> iulian
>
>
> On Fri, Feb 6, 2015 at 9:55 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Hey All,
> >
> > The tests are in a not-amazing state right now due to a few compounding
> > factors:
> >
> > 1. We've merged a large volume of patches recently.
> > 2. The load on jenkins has been relatively high, exposing races and
> > other behavior not seen at lower load.
> >
> > For those not familiar, the main issue is flaky (non deterministic)
> > test failures. Right now I'm trying to prioritize keeping the
> > PullReqeustBuilder in good shape since it will block development if it
> > is down.
> >
> > For other tests, let's try to keep filing JIRA's when we see issues
> > and use the flaky-test label (see http://bit.ly/1yRif9S):
> >
> > I may contact people regarding specific tests. This is a very high
> > priority to get in good shape. This kind of thing is no one's "fault"
> > but just the result of a lot of concurrent development, and everyone
> > needs to pitch in to get back in a good place.
> >
> > - Patrick
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>
>
> --
>
> --
> Iulian Dragos
>
> ------
> Reactive Apps on the JVM
> www.typesafe.com
>
>


--=20

--
Iulian Dragos

------
Reactive Apps on the JVM
www.typesafe.com

--001a113cdebad9df49050ebc2727--

From dev-return-11565-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 16:01:41 2015
Return-Path: <dev-return-11565-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AEFE710352
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 16:01:41 +0000 (UTC)
Received: (qmail 63795 invoked by uid 500); 10 Feb 2015 16:01:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63719 invoked by uid 500); 10 Feb 2015 16:01:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63701 invoked by uid 99); 10 Feb 2015 16:01:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 16:01:40 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 16:01:34 +0000
Received: by labge10 with SMTP id ge10so21069666lab.12
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 08:01:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=eY5tT3NIslqo2cci66h5MqKx0ysiXWigfIpihmqBT1M=;
        b=I1uUFOy2HiLla6T8LnT8bCNf1SrKCEoEDxGAu0EgYW29qD7u92LoPvEi32K0nqR045
         kVzxKhyUcHcJgvqi2jbuUP46wjPQQancJgOeLLA6/eP1qwEEeUU2mSC/eB3cxQmp+Sjf
         35Fkzr5wkkpQ8kELxStUtbhIj3DecaVMsBfBy4vpOQq6o5AWLH70rOKRnKYFfrvrxVE2
         Tl6Ij5zJpzlYII2UPSx00DtjjySiJXHuZCno961wzl343eTkhi0fcHjvob8J4XTjt2Im
         A+z59GKkzy/7WllfQD3426J8efia5uZ4wACXKXCiILg+Ei2BZpz0XDedF/Swe2ARwW2T
         Gmjg==
MIME-Version: 1.0
X-Received: by 10.112.213.38 with SMTP id np6mr23466988lbc.36.1423584073859;
 Tue, 10 Feb 2015 08:01:13 -0800 (PST)
Received: by 10.25.212.3 with HTTP; Tue, 10 Feb 2015 08:01:13 -0800 (PST)
Date: Tue, 10 Feb 2015 08:01:13 -0800
Message-ID: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
Subject: Batch prediciton for ALS
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134779807c6e4050ebdff83
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134779807c6e4050ebdff83
Content-Type: text/plain; charset=UTF-8

Hi,

Will it be possible to merge this PR to 1.3 ?

https://github.com/apache/spark/pull/3098

The batch prediction API in ALS will be useful for us who want to cross
validate on prec@k and MAP...

Thanks.
Deb

--001a1134779807c6e4050ebdff83--

From dev-return-11566-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 16:38:40 2015
Return-Path: <dev-return-11566-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9CB2E105F0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 16:38:40 +0000 (UTC)
Received: (qmail 73315 invoked by uid 500); 10 Feb 2015 16:38:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73240 invoked by uid 500); 10 Feb 2015 16:38:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73228 invoked by uid 99); 10 Feb 2015 16:38:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 16:38:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jayunit100.apache@gmail.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 16:38:14 +0000
Received: by mail-wi0-f179.google.com with SMTP id hi2so5352295wib.0
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 08:37:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=pPMUMx0K/I7XK1VY0YsMpaasqhUCsVUb6iGeYbcEDoA=;
        b=TIRd2uLZjAA/aioYAAZCWEGBWEqE/ar3f9uLRxohlJD7fvXz3lEEEQdmNX92uulAFy
         DS0ENVBZP8JV9mNotcCxV7GZOJWA0O+22Xal3FF0MFcTs+6SwfdXT052jOTYjQdYtTB0
         TRSxbqjf1VvtBvpnScMj2KV4oUXZfPaqktocW3NtiAZbF3cF8L+AfGd8Ktl6ahgbS7gl
         McCh7WiLvDhlChD3IgiQScvBuHNzlfW6jNPgTPekHyVul3bw0DCF5hfWjUHH0e6sBJpj
         x7katOLmFy4IlcW2ddJ/FqDWoS1pJFpyiNT9tBF0YYW7CwOtrcWHk0CrPXrSXwpI49yW
         aZfg==
MIME-Version: 1.0
X-Received: by 10.195.17.137 with SMTP id ge9mr54748226wjd.44.1423586247661;
 Tue, 10 Feb 2015 08:37:27 -0800 (PST)
Received: by 10.27.175.144 with HTTP; Tue, 10 Feb 2015 08:37:27 -0800 (PST)
In-Reply-To: <CABPQxstyVft_LA5PUyfOvDf7ynHNK4000nqYGkMbbRK13NvYzw@mail.gmail.com>
References: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
	<CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
	<028601d044c6$085de910$1919bb30$@reactor8.com>
	<CABPQxstyVft_LA5PUyfOvDf7ynHNK4000nqYGkMbbRK13NvYzw@mail.gmail.com>
Date: Tue, 10 Feb 2015 11:37:27 -0500
Message-ID: <CACVCA=dZ016AhwrvOmS0Ni+FgL+hh66dYBK7pKXkJAjAX2ghBQ@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
From: jay vyas <jayunit100.apache@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "Nate D'Amico" <nate@reactor8.com>, Sean Owen <sowen@cloudera.com>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, Mark Hamstra <mark@clearstorydata.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e016817f8995db5050ebe800b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e016817f8995db5050ebe800b
Content-Type: text/plain; charset=UTF-8

@patrick @nate  good idea,  might as well join forces... right now in
bigtop we already have

- packaging of both deb and rpm versions of spark in bigtop, +
- puppet recipes which work for standalone deployment, +
- curation of e2e vagrant tests + bigpetstore-spark, for automated testing
spark in both docker and VMs.
- builds for YARN, hive, and so on.

We have a maintainers.txt file which we would be happy to add folks from
spark contrib to, if there is interest in coordinating packaging.



On Tue, Feb 10, 2015 at 1:09 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> Mark was involved in adding this code (IIRC) and has also been the
> most active in maintaining it. So I'd be interested in hearing his
> thoughts on that proposal. Mark - would you be okay deprecating this
> and having Spark instead work with the upstream projects that focus on
> packaging?
>
> My feeling is that it's better to just have nothing than to have
> something not usable out-of-the-box (which to your point, is a lot
> more work).
>
> On Mon, Feb 9, 2015 at 4:10 PM,  <nate@reactor8.com> wrote:
> > This could be something if the spark community wanted to not maintain
> debs/rpms directly via the project could direct interested efforts towards
> apache bigtop.  Right now debs/rpms of bigtop components, as well as
> related tests is a focus.
> >
> > Something that would be great is if at least one spark committer with
> interests in config/pkg/testing could be liason and pt for bigtop efforts.
> >
> > Right now focus on bigtop 0.9, which currently includes spark 1.2.  Jira
> for items included in 0.9 can be found here:
> >
> > https://issues.apache.org/jira/browse/BIGTOP-1480
> >
> >
> >
> > -----Original Message-----
> > From: Sean Owen [mailto:sowen@cloudera.com]
> > Sent: Monday, February 9, 2015 3:52 PM
> > To: Nicholas Chammas
> > Cc: Patrick Wendell; Mark Hamstra; dev
> > Subject: Re: Keep or remove Debian packaging in Spark?
> >
> > What about this straw man proposal: deprecate in 1.3 with some kind of
> message in the build, and remove for 1.4? And add a pointer to any
> third-party packaging that might provide similar functionality?
> >
> > On Mon, Feb 9, 2015 at 6:47 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
> >> +1 to an "official" deprecation + redirecting users to some other
> >> +project
> >> that will or already is taking this on.
> >>
> >> Nate?
> >>
> >>
> >>
> >> On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >>>
> >>> I have wondered whether we should sort of deprecated it more
> >>> officially, since otherwise I think people have the reasonable
> >>> expectation based on the current code that Spark intends to support
> >>> "complete" Debian packaging as part of the upstream build. Having
> >>> something that's sort-of maintained but no one is helping review and
> >>> merge patches on it or make it fully functional, IMO that doesn't
> >>> benefit us or our users. There are a bunch of other projects that are
> >>> specifically devoted to packaging, so it seems like there is a clear
> >>> separation of concerns here.
> >>>
> >>> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra
> >>> <mark@clearstorydata.com>
> >>> wrote:
> >>> >>
> >>> >> it sounds like nobody intends these to be used to actually deploy
> >>> >> Spark
> >>> >
> >>> >
> >>> > I wouldn't go quite that far.  What we have now can serve as useful
> >>> > input to a deployment tool like Chef, but the user is then going to
> >>> > need to add some customization or configuration within the context
> >>> > of that tooling to get Spark installed just the way they want.  So
> >>> > it is not so much that the current Debian packaging can't be used
> >>> > as that it has never really been intended to be a completely
> >>> > finished product that a newcomer could, for example, use to install
> >>> > Spark completely and quickly to Ubuntu and have a fully-functional
> >>> > environment in which they could then run all of the examples,
> >>> > tutorials, etc.
> >>> >
> >>> > Getting to that level of packaging (and maintenance) is something
> >>> > that I'm not sure we want to do since that is a better fit with
> >>> > Bigtop and the efforts of Cloudera, Horton Works, MapR, etc. to
> >>> > distribute Spark.
> >>> >
> >>> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com>
> wrote:
> >>> >
> >>> >> This is a straw poll to assess whether there is support to keep
> >>> >> and fix, or remove, the Debian packaging-related config in Spark.
> >>> >>
> >>> >> I see several oldish outstanding JIRAs relating to problems in the
> >>> >> packaging:
> >>> >>
> >>> >> https://issues.apache.org/jira/browse/SPARK-1799
> >>> >> https://issues.apache.org/jira/browse/SPARK-2614
> >>> >> https://issues.apache.org/jira/browse/SPARK-3624
> >>> >> https://issues.apache.org/jira/browse/SPARK-4436
> >>> >> (and a similar idea about making RPMs)
> >>> >> https://issues.apache.org/jira/browse/SPARK-665
> >>> >>
> >>> >> The original motivation seems related to Chef:
> >>> >>
> >>> >>
> >>> >>
> >>> >> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=
> >>> >> 14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comm
> >>> >> ent-tabpanel#comment-14070908
> >>> >>
> >>> >> Mark's recent comments cast some doubt on whether it is essential:
> >>> >>
> >>> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
> >>> >>
> >>> >> and in recent conversations I didn't hear dissent to the idea of
> >>> >> removing this.
> >>> >>
> >>> >> Is this still useful enough to fix up? All else equal I'd like to
> >>> >> start to walk back some of the complexity of the build, but I
> >>> >> don't know how all-else-equal it is. Certainly, it sounds like
> >>> >> nobody intends these to be used to actually deploy Spark.
> >>> >>
> >>> >> I don't doubt it's useful to someone, but can they maintain the
> >>> >> packaging logic elsewhere?
> >>> >>
> >>> >> ------------------------------------------------------------------
> >>> >> --- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
> >>> >> additional commands, e-mail: dev-help@spark.apache.org
> >>> >>
> >>> >>
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
> >>> additional commands, e-mail: dev-help@spark.apache.org
> >>>
> >>
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional
> commands, e-mail: dev-help@spark.apache.org
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
jay vyas

--089e016817f8995db5050ebe800b--

From dev-return-11567-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 17:06:24 2015
Return-Path: <dev-return-11567-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F2DB610745
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 17:06:24 +0000 (UTC)
Received: (qmail 4732 invoked by uid 500); 10 Feb 2015 17:06:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4654 invoked by uid 500); 10 Feb 2015 17:06:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4638 invoked by uid 99); 10 Feb 2015 17:06:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 17:06:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mark@clearstorydata.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 17:05:58 +0000
Received: by mail-wg0-f48.google.com with SMTP id x12so34693206wgg.7
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 09:05:11 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=rlTa8J78i9SEti2BRVo7Xt22+sAFQi9iZVE0NlZAjQw=;
        b=E8CakjeleuROjCGMx6/DcwP/aMXeECZpXOP6DN6k/aM21tw8qTPLDHSLAbt7j0BOXo
         BYnKfTZEk3X2EtQHIo7FGBxwXZADgxOz87RR3UwfYsdKsHBHPPwCu4/ZLFO6X4QPx4PF
         cJCwJiectdn8EHIUL80FDbSSqU8Tpxgi4yjMLKAIfamyJ3Pyt6U1zvLwJ0CULuA+SGIT
         XrUwIHmIBDp9h6ew7lWTRiHnjNf72XTXtG4wggKCwpMj9onOU8k1rDjI04Gk/p/9faAY
         bkQk/T9OdfsdmcfUvflkZCTwrPmdzYwLQhe4zbFN8ZuwVkFJz71PONdBFxWWce5T7Bp2
         /mLw==
X-Gm-Message-State: ALoCoQnApm4JKRfXdLeDYCw2rZPAkMwTkwCGmvrLQKglGQlVBEYhX246QMzDeLeA0QboLj26nvqy
MIME-Version: 1.0
X-Received: by 10.194.185.15 with SMTP id ey15mr55761769wjc.3.1423587911515;
 Tue, 10 Feb 2015 09:05:11 -0800 (PST)
Received: by 10.217.171.69 with HTTP; Tue, 10 Feb 2015 09:05:11 -0800 (PST)
In-Reply-To: <CABPQxstyVft_LA5PUyfOvDf7ynHNK4000nqYGkMbbRK13NvYzw@mail.gmail.com>
References: <CAOhmDzdMGSOhmWt5HGKY05T9hYfK1OhTNX0NFCTHU+F95TbMhA@mail.gmail.com>
	<CAMAsSdLVxVaf+YNVrh1UkZnY9p8VLHYPOfOgche7eqoKNhdb4Q@mail.gmail.com>
	<028601d044c6$085de910$1919bb30$@reactor8.com>
	<CABPQxstyVft_LA5PUyfOvDf7ynHNK4000nqYGkMbbRK13NvYzw@mail.gmail.com>
Date: Tue, 10 Feb 2015 09:05:11 -0800
Message-ID: <CAAsvFP=rMQ9tVRjO1y4psacx1Cv+RKrj_Xvx=Pcnx_3Yq_GaFQ@mail.gmail.com>
Subject: Re: Keep or remove Debian packaging in Spark?
From: Mark Hamstra <mark@clearstorydata.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "Nate D'Amico" <nate@reactor8.com>, Sean Owen <sowen@cloudera.com>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7ba977c6c5df3a050ebee3af
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7ba977c6c5df3a050ebee3af
Content-Type: text/plain; charset=UTF-8

Yeah, I'm fine with that.

On Mon, Feb 9, 2015 at 10:09 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Mark was involved in adding this code (IIRC) and has also been the
> most active in maintaining it. So I'd be interested in hearing his
> thoughts on that proposal. Mark - would you be okay deprecating this
> and having Spark instead work with the upstream projects that focus on
> packaging?
>
> My feeling is that it's better to just have nothing than to have
> something not usable out-of-the-box (which to your point, is a lot
> more work).
>
> On Mon, Feb 9, 2015 at 4:10 PM,  <nate@reactor8.com> wrote:
> > This could be something if the spark community wanted to not maintain
> debs/rpms directly via the project could direct interested efforts towards
> apache bigtop.  Right now debs/rpms of bigtop components, as well as
> related tests is a focus.
> >
> > Something that would be great is if at least one spark committer with
> interests in config/pkg/testing could be liason and pt for bigtop efforts.
> >
> > Right now focus on bigtop 0.9, which currently includes spark 1.2.  Jira
> for items included in 0.9 can be found here:
> >
> > https://issues.apache.org/jira/browse/BIGTOP-1480
> >
> >
> >
> > -----Original Message-----
> > From: Sean Owen [mailto:sowen@cloudera.com]
> > Sent: Monday, February 9, 2015 3:52 PM
> > To: Nicholas Chammas
> > Cc: Patrick Wendell; Mark Hamstra; dev
> > Subject: Re: Keep or remove Debian packaging in Spark?
> >
> > What about this straw man proposal: deprecate in 1.3 with some kind of
> message in the build, and remove for 1.4? And add a pointer to any
> third-party packaging that might provide similar functionality?
> >
> > On Mon, Feb 9, 2015 at 6:47 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
> >> +1 to an "official" deprecation + redirecting users to some other
> >> +project
> >> that will or already is taking this on.
> >>
> >> Nate?
> >>
> >>
> >>
> >> On Mon Feb 09 2015 at 10:08:27 AM Patrick Wendell <pwendell@gmail.com>
> >> wrote:
> >>>
> >>> I have wondered whether we should sort of deprecated it more
> >>> officially, since otherwise I think people have the reasonable
> >>> expectation based on the current code that Spark intends to support
> >>> "complete" Debian packaging as part of the upstream build. Having
> >>> something that's sort-of maintained but no one is helping review and
> >>> merge patches on it or make it fully functional, IMO that doesn't
> >>> benefit us or our users. There are a bunch of other projects that are
> >>> specifically devoted to packaging, so it seems like there is a clear
> >>> separation of concerns here.
> >>>
> >>> On Mon, Feb 9, 2015 at 7:31 AM, Mark Hamstra
> >>> <mark@clearstorydata.com>
> >>> wrote:
> >>> >>
> >>> >> it sounds like nobody intends these to be used to actually deploy
> >>> >> Spark
> >>> >
> >>> >
> >>> > I wouldn't go quite that far.  What we have now can serve as useful
> >>> > input to a deployment tool like Chef, but the user is then going to
> >>> > need to add some customization or configuration within the context
> >>> > of that tooling to get Spark installed just the way they want.  So
> >>> > it is not so much that the current Debian packaging can't be used
> >>> > as that it has never really been intended to be a completely
> >>> > finished product that a newcomer could, for example, use to install
> >>> > Spark completely and quickly to Ubuntu and have a fully-functional
> >>> > environment in which they could then run all of the examples,
> >>> > tutorials, etc.
> >>> >
> >>> > Getting to that level of packaging (and maintenance) is something
> >>> > that I'm not sure we want to do since that is a better fit with
> >>> > Bigtop and the efforts of Cloudera, Horton Works, MapR, etc. to
> >>> > distribute Spark.
> >>> >
> >>> > On Mon, Feb 9, 2015 at 2:41 AM, Sean Owen <sowen@cloudera.com>
> wrote:
> >>> >
> >>> >> This is a straw poll to assess whether there is support to keep
> >>> >> and fix, or remove, the Debian packaging-related config in Spark.
> >>> >>
> >>> >> I see several oldish outstanding JIRAs relating to problems in the
> >>> >> packaging:
> >>> >>
> >>> >> https://issues.apache.org/jira/browse/SPARK-1799
> >>> >> https://issues.apache.org/jira/browse/SPARK-2614
> >>> >> https://issues.apache.org/jira/browse/SPARK-3624
> >>> >> https://issues.apache.org/jira/browse/SPARK-4436
> >>> >> (and a similar idea about making RPMs)
> >>> >> https://issues.apache.org/jira/browse/SPARK-665
> >>> >>
> >>> >> The original motivation seems related to Chef:
> >>> >>
> >>> >>
> >>> >>
> >>> >> https://issues.apache.org/jira/browse/SPARK-2614?focusedCommentId=
> >>> >> 14070908&page=com.atlassian.jira.plugin.system.issuetabpanels:comm
> >>> >> ent-tabpanel#comment-14070908
> >>> >>
> >>> >> Mark's recent comments cast some doubt on whether it is essential:
> >>> >>
> >>> >> https://github.com/apache/spark/pull/4277#issuecomment-72114226
> >>> >>
> >>> >> and in recent conversations I didn't hear dissent to the idea of
> >>> >> removing this.
> >>> >>
> >>> >> Is this still useful enough to fix up? All else equal I'd like to
> >>> >> start to walk back some of the complexity of the build, but I
> >>> >> don't know how all-else-equal it is. Certainly, it sounds like
> >>> >> nobody intends these to be used to actually deploy Spark.
> >>> >>
> >>> >> I don't doubt it's useful to someone, but can they maintain the
> >>> >> packaging logic elsewhere?
> >>> >>
> >>> >> ------------------------------------------------------------------
> >>> >> --- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
> >>> >> additional commands, e-mail: dev-help@spark.apache.org
> >>> >>
> >>> >>
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For
> >>> additional commands, e-mail: dev-help@spark.apache.org
> >>>
> >>
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional
> commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--047d7ba977c6c5df3a050ebee3af--

From dev-return-11568-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 18:11:45 2015
Return-Path: <dev-return-11568-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 185BB10AFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 18:11:45 +0000 (UTC)
Received: (qmail 33323 invoked by uid 500); 10 Feb 2015 18:11:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33255 invoked by uid 500); 10 Feb 2015 18:11:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33244 invoked by uid 99); 10 Feb 2015 18:11:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 18:11:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of chester@alpinenow.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 18:11:18 +0000
Received: by mail-qa0-f46.google.com with SMTP id n4so7186649qaq.5
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 10:11:16 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=HghcZF0JOL8KVH7vfLKE4KpD/2QLeFFECkYEKBRyLNw=;
        b=e0JBP6Q97tRG+zS8+LOFBif7Kvpbrcias6wtF5A7ki5ET+RODpHr1hBAReegXRMaau
         a6p/4Ydi0D6b15qF+F3TekAGZk81uSgdGmErC/PHt01WnCuZZUrImU4d0JV5QTIcQ4E2
         d1XXIjEpfx4UQYGSmxhiaovgAViwLFieOzNxgaYo3YmfQCBcg17T0fgMXmCyJHFT+nlE
         vWr4yKbeb/wiUO/vUyuDVcoWlMvr5B0njLHv0CVcI9JNoAZBDiYtTermZQ/sU/Dtb0Ip
         lhSOPasaBbdf5XgFALz4aJ4uyCZ91ADRySiC6JIDrFurOKvw+MyBHlG+RNIvUK9DGuOk
         7trQ==
X-Gm-Message-State: ALoCoQnE3bDKTq/+DUVKE35vyxl+QWV/nIJiYfAOf8cF323ieUqi0t10RGec/Gz00wSctYfEhTqJ
MIME-Version: 1.0
X-Received: by 10.140.101.119 with SMTP id t110mr54577204qge.9.1423591876454;
 Tue, 10 Feb 2015 10:11:16 -0800 (PST)
Received: by 10.96.149.39 with HTTP; Tue, 10 Feb 2015 10:11:16 -0800 (PST)
Date: Tue, 10 Feb 2015 10:11:16 -0800
Message-ID: <CAPYnQ0VZFc+BMSfFAxR9q6fOZE8aa37w1MGX8kQsBXiwnDpuCA@mail.gmail.com>
Subject: FYI: Prof John Canny is giving a talk on "Machine Learning at the
 limit" in SF Big Analytics Meetup
From: Chester Chen <chester@alpinenow.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16e5e1a0916050ebfd05c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16e5e1a0916050ebfd05c
Content-Type: text/plain; charset=UTF-8

Just in case you are in San Francisco, we are having a meetup by Prof John
Canny

http://www.meetup.com/SF-Big-Analytics/events/220427049/


Chester

--001a11c16e5e1a0916050ebfd05c--

From dev-return-11569-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 18:45:19 2015
Return-Path: <dev-return-11569-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 48FFA10C99
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 18:45:19 +0000 (UTC)
Received: (qmail 73925 invoked by uid 500); 10 Feb 2015 18:45:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73851 invoked by uid 500); 10 Feb 2015 18:45:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73831 invoked by uid 99); 10 Feb 2015 18:45:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 18:45:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of imranrashi@gmail.com designates 209.85.216.50 as permitted sender)
Received: from [209.85.216.50] (HELO mail-qa0-f50.google.com) (209.85.216.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 18:45:08 +0000
Received: by mail-qa0-f50.google.com with SMTP id f12so9295336qad.9
        for <dev@spark.incubator.apache.org>; Tue, 10 Feb 2015 10:44:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:date:message-id:subject:from:to:content-type;
        bh=oQrF58k3rhB7DViQCOXhYTrHfm6Da2xiyGu3LI0Ri6A=;
        b=YqnjYsLqF9QbTcq+kKLa4BEVaEbiTKlhab5R3QY+uq8JkI3zevH4r77hkmWEnL6eKm
         Qd0A39TIooOcxTF1Qb9kaAWc/7yEIr4TIgAbLrP4dzj3kIUMzijscq4VZ1vxLO4ilQR0
         8kzWtUvzofh4IO4OTX5jePpUddEqGmIXEEMHFxE0LDOvntEwOLAaqNXpvpwPverf/KKz
         gX7IujGKdYrZ4Db36N1D369thLh9Rt8abWZcZuJ0GOgn29aW/FP2U9cT4/AtQTKZsC3A
         J4kwqzbztEKT8qO2ICmTmeJHanmbeJed91uAZBE/ZI7mfkMHNXYzY31AlWfmr0K/02oK
         UIdQ==
MIME-Version: 1.0
X-Received: by 10.140.102.82 with SMTP id v76mr53571941qge.32.1423593842990;
 Tue, 10 Feb 2015 10:44:02 -0800 (PST)
Sender: imranrashi@gmail.com
Received: by 10.96.118.4 with HTTP; Tue, 10 Feb 2015 10:44:02 -0800 (PST)
Date: Tue, 10 Feb 2015 12:44:02 -0600
X-Google-Sender-Auth: GN1PImzwTmHoX_m5NACEUpBbYCU
Message-ID: <CAN_Cyt-R5B0fMp6bof92=csywrL5A+QZz_Qo8sByYHuYDb4bOQ@mail.gmail.com>
Subject: new committer criteria
From: Imran Rashid <imran@therashids.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16a9050ece9050ec04563
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16a9050ece9050ec04563
Content-Type: text/plain; charset=UTF-8

Hi all,

We've been considering changing criteria for being a committer (
http://s.apache.org/VFw), but I don't think there are any conclusions yet.
I had proposed eliminating (or at least weakening) this requirement:

> ...have contributed at least one major component where they have taken an
> "ownership" role. An ownership role means that existing contributors feel
> that they should run patches for this component by this person.
>
> do we have any other ideas on what the new criteria should be?

I realize it might be hard to nail down what the criteria are very
precisely; alternatively we could just start nominating individuals that
are good candidates, and see what sticks.  I can think of a few more
community members that might make the cut -- some that I think are almost
definitely in, others that it kinda depends where we draw the line.

thank,
Imran

--001a11c16a9050ece9050ec04563--

From dev-return-11570-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 19:49:28 2015
Return-Path: <dev-return-11570-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C7F1817212
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 19:49:28 +0000 (UTC)
Received: (qmail 4502 invoked by uid 500); 10 Feb 2015 19:49:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4427 invoked by uid 500); 10 Feb 2015 19:49:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4416 invoked by uid 99); 10 Feb 2015 19:49:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:49:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:49:22 +0000
Received: by mail-wi0-f180.google.com with SMTP id z2so17005241wiv.1
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 11:47:56 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=xfodV5UedX5dSbAkK+zT3c+WJSe8+N3UfCQigTLG5gw=;
        b=LgsvWnZWEpVRfOOntdS8V3lN8L7vbmSkRMezbo8nldkAdITGtzactzE2rpjOS/HSdg
         vQEDutN/VM+PHFYA5lPQBQfdFOhqEYW3fbGfBynh01erpc0M7trnmkhKboInN0zXN9vg
         ztZuuVOSc3U/CYKCbORmyTv9tPv+AAj4rxwh1W14n5lV4zk18jzUByn3Vq3Lduu7sH3e
         pnq7yAufucHhqG/7RYyam9REdcX2goTviiASwd5YLN+80TYWXTFValdEY/IQpc8ieQyc
         otauMUvu4JIaOOBKorjzP2ugu56XWWzcX1mpD8ihDb98qla5ST/FTmkPUklT57tnK/VZ
         EiGA==
X-Gm-Message-State: ALoCoQmguRQKSy2hZdSeRp4z3BJVZuBSYQX2ElLPB4AmULhD3+OmLamX1lityKBEBa5yQhc5jQ5o
MIME-Version: 1.0
X-Received: by 10.180.210.203 with SMTP id mw11mr49531867wic.53.1423597676122;
 Tue, 10 Feb 2015 11:47:56 -0800 (PST)
Received: by 10.217.122.200 with HTTP; Tue, 10 Feb 2015 11:47:55 -0800 (PST)
X-Originating-IP: [204.148.13.62]
In-Reply-To: <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
	<CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
	<CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
	<CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
	<CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
	<D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com>
	<CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
	<CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
	<CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
	<CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
	<CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
	<CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
	<CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
	<CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
	<54CAAD2D.8030407@gmail.com>
	<CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
Date: Tue, 10 Feb 2015 14:47:55 -0500
Message-ID: <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
From: Koert Kuipers <koert@tresata.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c267dac9e63d050ec1295e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c267dac9e63d050ec1295e
Content-Type: text/plain; charset=UTF-8

so i understand the success or spark.sql. besides the fact that anything
with the words SQL in its name will have thousands of developers running
towards it because of the familiarity, there is also a genuine need for a
generic RDD that holds record-like objects, with field names and runtime
types. after all that is a successfull generic abstraction used in many
structured data tools.

but to me that abstraction is as simple as:

trait SchemaRDD extends RDD[Row] {
  def schema: StructType
}

and perhaps another abstraction to indicate it intends to be column
oriented (with a few methods to efficiently extract a subset of columns).
so that could be DataFrame.

such simple contracts would allow many people to write loaders for this
(say from csv) and whatnot.

what i do not understand why it has to be much more complex than this. but
if i look at DataFrame it has so much additional stuff, that has (in my
eyes) nothing to do with generic structured data analysis.

for example to implement DataFrame i need to implement about 40 additional
methods!? and for some the SQLness is obviously leaking into the
abstraction. for example why would i care about:
  def registerTempTable(tableName: String): Unit


best, koert

On Sun, Feb 1, 2015 at 3:31 AM, Evan Chan <velvia.github@gmail.com> wrote:

> It is true that you can persist SchemaRdds / DataFrames to disk via
> Parquet, but a lot of time and inefficiencies is lost.   The in-memory
> columnar cached representation is completely different from the
> Parquet file format, and I believe there has to be a translation into
> a Row (because ultimately Spark SQL traverses Row's -- even the
> InMemoryColumnarTableScan has to then convert the columns into Rows
> for row-based processing).   On the other hand, traditional data
> frames process in a columnar fashion.   Columnar storage is good, but
> nowhere near as good as columnar processing.
>
> Another issue, which I don't know if it is solved yet, but it is
> difficult for Tachyon to efficiently cache Parquet files without
> understanding the file format itself.
>
> I gave a talk at last year's Spark Summit on this topic.
>
> I'm working on efforts to change this, however.  Shoot me an email at
> velvia at gmail if you're interested in joining forces.
>
> On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> > Yes, when a DataFrame is cached in memory, it's stored in an efficient
> > columnar format. And you can also easily persist it on disk using
> Parquet,
> > which is also columnar.
> >
> > Cheng
> >
> >
> > On 1/29/15 1:24 PM, Koert Kuipers wrote:
> >>
> >> to me the word DataFrame does come with certain expectations. one of
> them
> >> is that the data is stored columnar. in R data.frame internally uses a
> >> list
> >> of sequences i think, but since lists can have labels its more like a
> >> SortedMap[String, Array[_]]. this makes certain operations very cheap
> >> (such
> >> as adding a column).
> >>
> >> in Spark the closest thing would be a data structure where per Partition
> >> the data is also stored columnar. does spark SQL already use something
> >> like
> >> that? Evan mentioned "Spark SQL columnar compression", which sounds like
> >> it. where can i find that?
> >>
> >> thanks
> >>
> >> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan <velvia.github@gmail.com>
> >> wrote:
> >>
> >>> +1.... having proper NA support is much cleaner than using null, at
> >>> least the Java null.
> >>>
> >>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks <evan.sparks@gmail.com
> >
> >>> wrote:
> >>>>
> >>>> You've got to be a little bit careful here. "NA" in systems like R or
> >>>
> >>> pandas
> >>>>
> >>>> may have special meaning that is distinct from "null".
> >>>>
> >>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
> >>>>
> >>>>
> >>>>
> >>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin <rxin@databricks.com>
> >>>
> >>> wrote:
> >>>>>
> >>>>> Isn't that just "null" in SQL?
> >>>>>
> >>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan <velvia.github@gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> I believe that most DataFrame implementations out there, like
> Pandas,
> >>>>>> supports the idea of missing values / NA, and some support the idea
> of
> >>>>>> Not Meaningful as well.
> >>>>>>
> >>>>>> Does Row support anything like that?  That is important for certain
> >>>>>> applications.  I thought that Row worked by being a mutable object,
> >>>>>> but haven't looked into the details in a while.
> >>>>>>
> >>>>>> -Evan
> >>>>>>
> >>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin <rxin@databricks.com>
> >>>>>> wrote:
> >>>>>>>
> >>>>>>> It shouldn't change the data source api at all because data sources
> >>>>>>
> >>>>>> create
> >>>>>>>
> >>>>>>> RDD[Row], and that gets converted into a DataFrame automatically
> >>>>>>
> >>>>>> (previously
> >>>>>>>
> >>>>>>> to SchemaRDD).
> >>>>>>>
> >>>>>>>
> >>>>>>
> >>>
> >>>
> https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala
> >>>>>>>
> >>>>>>> One thing that will break the data source API in 1.3 is the
> location
> >>>>>>> of
> >>>>>>> types. Types were previously defined in sql.catalyst.types, and now
> >>>>>>
> >>>>>> moved to
> >>>>>>>
> >>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and all
> >>>>>>> public
> >>>>>>
> >>>>>> APIs
> >>>>>>>
> >>>>>>> have first class classes/objects defined in sql directly.
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <
> velvia.github@gmail.com
> >>>>>>
> >>>>>> wrote:
> >>>>>>>>
> >>>>>>>> Hey guys,
> >>>>>>>>
> >>>>>>>> How does this impact the data sources API?  I was planning on
> using
> >>>>>>>> this for a project.
> >>>>>>>>
> >>>>>>>> +1 that many things from spark-sql / DataFrame is universally
> >>>>>>>> desirable and useful.
> >>>>>>>>
> >>>>>>>> By the way, one thing that prevents the columnar compression stuff
> >>>
> >>> in
> >>>>>>>>
> >>>>>>>> Spark SQL from being more useful is, at least from previous talks
> >>>>>>>> with
> >>>>>>>> Reynold and Michael et al., that the format was not designed for
> >>>>>>>> persistence.
> >>>>>>>>
> >>>>>>>> I have a new project that aims to change that.  It is a
> >>>>>>>> zero-serialisation, high performance binary vector library,
> >>>
> >>> designed
> >>>>>>>>
> >>>>>>>> from the outset to be a persistent storage friendly.  May be one
> >>>
> >>> day
> >>>>>>>>
> >>>>>>>> it can replace the Spark SQL columnar compression.
> >>>>>>>>
> >>>>>>>> Michael told me this would be a lot of work, and recreates parts
> of
> >>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
> >>>
> >>> details.
> >>>>>>>>
> >>>>>>>> -Evan
> >>>>>>>>
> >>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin <rxin@databricks.com
> >
> >>>>>>
> >>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>> Alright I have merged the patch (
> >>>>>>>>> https://github.com/apache/spark/pull/4173
> >>>>>>>>> ) since I don't see any strong opinions against it (as a matter
> >>>
> >>> of
> >>>>>>
> >>>>>> fact
> >>>>>>>>>
> >>>>>>>>> most were for it). We can still change it if somebody lays out a
> >>>>>>
> >>>>>> strong
> >>>>>>>>>
> >>>>>>>>> argument.
> >>>>>>>>>
> >>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
> >>>>>>>>> <matei.zaharia@gmail.com>
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>>> The type alias means your methods can specify either type and
> >>>
> >>> they
> >>>>>>
> >>>>>> will
> >>>>>>>>>>
> >>>>>>>>>> work. It's just another name for the same type. But Scaladocs
> >>>
> >>> and
> >>>>>>
> >>>>>> such
> >>>>>>>>>>
> >>>>>>>>>> will
> >>>>>>>>>> show DataFrame as the type.
> >>>>>>>>>>
> >>>>>>>>>> Matei
> >>>>>>>>>>
> >>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
> >>>>>>>>>>
> >>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> >>>>>>>>>>>
> >>>>>>>>>>> Reynold,
> >>>>>>>>>>> But with type alias we will have the same problem, right?
> >>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will have
> >>>>>>>>>>> to
> >>>>>>>>>>> change
> >>>>>>>>>>> our code to migrade from schema to dataframe. Unless we have
> >>>
> >>> an
> >>>>>>>>>>>
> >>>>>>>>>>> implicit
> >>>>>>>>>>> conversion between DataFrame and SchemaRDD
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin <rxin@databricks.com>:
> >>>>>>>>>>>
> >>>>>>>>>>>> Dirceu,
> >>>>>>>>>>>>
> >>>>>>>>>>>> That is not possible because one cannot overload return
> >>>
> >>> types.
> >>>>>>>>>>>>
> >>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
> >>>
> >>> return
> >>>>>>
> >>>>>> some
> >>>>>>>>>>
> >>>>>>>>>> type,
> >>>>>>>>>>>>
> >>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
> >>>>>>>>>>>>
> >>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
> >>>>>>>>>>>> SchemaRDD
> >>>>>>>>>>>> to
> >>>>>>>>>>
> >>>>>>>>>> not
> >>>>>>>>>>>>
> >>>>>>>>>>>> break source compatibility for Scala.
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
> >>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> >>>>>>>>>>>>
> >>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and be
> >>>>>>
> >>>>>> removed
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> in
> >>>>>>>>>>
> >>>>>>>>>> the
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been added
> >>>>>>>>>>>>> to
> >>>>>>>>>>
> >>>>>>>>>> DataFrame?
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> With this, we don't impact in existing code for the next few
> >>>>>>>>>>>>> releases.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
> >>>>>>>>>>>>> <kushal.datta@gmail.com>:
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>> I want to address the issue that Matei raised about the
> >>>
> >>> heavy
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> lifting
> >>>>>>>>>>>>>> required for a full SQL support. It is amazing that even
> >>>>>>>>>>>>>> after
> >>>>>>
> >>>>>> 30
> >>>>>>>>>>
> >>>>>>>>>> years
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> of
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> research there is not a single good open source columnar
> >>>>>>
> >>>>>> database
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> like
> >>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but it is
> >>>>>>>>>>>>>> not
> >>>>>>>>>>>>>> nearly
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> as
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
> >>>
> >>> need
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> for
> >>>>>>>>>>>>>> such
> >>>>>>>>>>
> >>>>>>>>>> a
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> system. I wonder why so and it's high time to change that.
> >>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
> >>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
> >>>>>>>>>>
> >>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though I
> >>>
> >>> like
> >>>>>>
> >>>>>> the
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> former
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> slightly better because it's more descriptive.
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under the
> >>>>>>
> >>>>>> covers,
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> it
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> would
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> be more clear from a user-facing perspective to at least
> >>>>>>
> >>>>>> choose a
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> package
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> name for it that omits "sql".
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark Schema
> >>>>>>
> >>>>>> module
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Spark
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large a
> >>>>>>>>>>>>>>> change
> >>>>>>
> >>>>>> at
> >>>>>>>>>>
> >>>>>>>>>> this
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> point?
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> -Sandy
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> matei.zaharia@gmail.com>
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of giving
> >>>>>>>>>>>>>>>> it
> >>>>>>>>>>>>>>>> another
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> name,
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL since
> >>>>>>>>>>>>>>>> that
> >>>>>>>>>>>>>>>> was
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> the
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> most
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> obvious use case to many users.)
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> Matei
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> matei.zaharia@gmail.com>
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>> While it might be possible to move this concept to Spark
> >>>>>>>>>>>>>>>>> Core
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> long-term,
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> supporting structured data efficiently does require
> >>>
> >>> quite a
> >>>>>>
> >>>>>> bit
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> of
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> the
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning and
> >>>>>>
> >>>>>> columnar
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> storage.
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a SQL
> >>>>>>>>>>>>>>>> server
> >>>>>>>>>>>>>>>> --
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> it's
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> meant to be a library for manipulating structured data.
> >>>>>>>>>>>>>>>> Since
> >>>>>>>>>>>>>>>> this
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> is
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> possible to build over the core API, it's pretty natural
> >>>
> >>> to
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> organize it
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
> >>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>> Matei
> >>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
> >>>>>>
> >>>>>> koert@tresata.com>
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
> >>>
> >>> data
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> format
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> used
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
> >>>
> >>> used
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> various
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API."
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in spark
> >>>>>>>>>>>>>>>>>> core,
> >>>>>>
> >>>>>> not
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> sql
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
> >>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
> >>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it yet,
> >>>>>>>>>>>>>>>>>>> the
> >>>>>>>>>>>>>>>>>>> Jan.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> 13
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> Bay
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> Area
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of background
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> information
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> on
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> this
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=YWppYPWznSQ
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> ________________________________
> >>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
> >>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
> >>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
> >>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
> >>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
> >>>
> >>> there
> >>>>>>
> >>>>>> will
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> be
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> a
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> 1:1
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
> >>>>>>
> >>>>>> DataFrame.
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> rxin@databricks.com>
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> wrote:
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> Hi,
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD -> DataFrame in
> >>>>>>>>>>>>>>>>>>>> 1.3,
> >>>>>>>>>>>>>>>>>>>> and
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> wanted
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> to
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> get the community's opinion.
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a common
> >>>
> >>> data
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> format
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> used
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
> >>>>>>>>>>>>>>>>>>>> used
> >>>>>>
> >>>>>> for
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> various
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API.
> >>>
> >>> We
> >>>>>>
> >>>>>> also
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> expect
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> more
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> and
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> more users to be programming directly against
> >>>
> >>> SchemaRDD
> >>>>>>
> >>>>>> API
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> rather
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> than
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> the
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less commonly
> >>>
> >>> used
> >>>>>>
> >>>>>> DSL
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> originally
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
> >>>>>>>>>>>>>>>>>>>> data-frame
> >>>>>>>>>>>>>>>>>>>> like
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> API.
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> In
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
> >>>
> >>> usable
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>>>>>>>> end
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> users.
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
> >>>
> >>> than
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> SchemaRDD.
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to be an
> >>>>>>>>>>>>>>>>>>>> RDD
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> anymore
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> (even
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like map,
> >>>>>>>>>>>>>>>>>>>> flatMap,
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> etc),
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> and
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
> >>>
> >>> highly
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> confusing.
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> Instead.
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for all
> >>>>>>>>>>>>>>>>>>>> RDD
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> methods.
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
> >>>>>>>>>>>>>>>>>>>> directly
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> against
> >>>>>>>>>>>>>>
> >>>>>>>>>>>>>> the
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
> >>>
> >>> well
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> documented.
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> However,
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can create a
> >>>>>>>>>>>>>>>>>>>> type
> >>>>>>>>>>>>>>>>>>>> alias
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> DataFrame
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
> >>>>>>>>>>>>>>>>>>>> source
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> compatibility
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> for
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all existing
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> materials to
> >>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>> use
> >>>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>
> ---------------------------------------------------------------------
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> >>>
> >>> dev-unsubscribe@spark.apache.org
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>
> >>>>>>
> ---------------------------------------------------------------------
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> >>>
> >>> dev-unsubscribe@spark.apache.org
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>
> ---------------------------------------------------------------------
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>>>>>>>>>>>>>> For additional commands, e-mail:
> >>>
> >>> dev-help@spark.apache.org
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>> ---------------------------------------------------------------------
> >>>>>>>>>>
> >>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>
> >>>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>> For additional commands, e-mail: dev-help@spark.apache.org
> >>>
> >>>
> >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>

--001a11c267dac9e63d050ec1295e--

From dev-return-11571-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 19:58:47 2015
Return-Path: <dev-return-11571-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BCBBB172CF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 19:58:47 +0000 (UTC)
Received: (qmail 36488 invoked by uid 500); 10 Feb 2015 19:58:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36419 invoked by uid 500); 10 Feb 2015 19:58:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36407 invoked by uid 99); 10 Feb 2015 19:58:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:58:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:58:32 +0000
Received: by pdbfl12 with SMTP id fl12so16511221pdb.4
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 11:57:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=2qjZWNVyrRJ72QLMINcAFKSYMvWDlkmdeZhQEgL3N9w=;
        b=H616rQkTAmhMZ3VpFi27M+mE2tDNZIyjms3u3LqOWx/KKsyX5GsWFNlbEujwlClHkf
         uEsMIKriLOpg4KFzhdfC7agvMJNGkeY6EXCvhnWXFa53KAdEbgaXe7iHZVS1dh5ta0IL
         G/KIU3tWVgGLnBKOsH5a+A40G+7Yu5KK9zm7Lbw1/e5cOoQpS37FUp6wmHZlccXskEIE
         QfQyVqiDjql4NfCqinkurl2Sc6uKcfqyfF1g+aFiTUUoIHEakDxw+isosB+/pCy+dN/g
         ubkULQBM2mChekayAGqyTXvsk/49bZr2nw4Y3CR48oBRKJrabpUpaHGweW3wFbaS1qHt
         4n0A==
X-Received: by 10.70.101.4 with SMTP id fc4mr40981813pdb.92.1423598247370;
        Tue, 10 Feb 2015 11:57:27 -0800 (PST)
Received: from [192.168.1.100] (DATABRICKS.bar1.SanFrancisco1.Level3.net. [4.15.73.18])
        by mx.google.com with ESMTPSA id si8sm20147908pbc.26.2015.02.10.11.57.25
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 10 Feb 2015 11:57:26 -0800 (PST)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.2 \(2070.6\))
Subject: Re: renaming SchemaRDD -> DataFrame
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
Date: Tue, 10 Feb 2015 11:57:24 -0800
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <7613D89B-FD77-43C7-B20D-D432D6611ABB@gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
 <CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
 <CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
 <CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
 <CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
 <D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com> <CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
 <CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
 <CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
 <CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
 <CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
 <CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
 <CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
 <CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
 <54CAAD2D.8030407@gmail.com> <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
 <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
To: Koert Kuipers <koert@tresata.com>
X-Mailer: Apple Mail (2.2070.6)
X-Virus-Checked: Checked by ClamAV on apache.org

You're not really supposed to subclass DataFrame, instead you can make =
it from an RDD of Rows and a schema (e.g. with SQLContext.applySchema). =
Actually the Spark SQL data source API supports that too =
(org.apache.spark.sql.sources). Think of DataFrame as a container for =
structured data, not as a class that all data sources will have to =
implement. If you want to do something fancy like compute the Rows =
dynamically, your RDD can implement its own compute() method to do that.

Matei

> On Feb 10, 2015, at 11:47 AM, Koert Kuipers <koert@tresata.com> wrote:
>=20
> so i understand the success or spark.sql. besides the fact that =
anything
> with the words SQL in its name will have thousands of developers =
running
> towards it because of the familiarity, there is also a genuine need =
for a
> generic RDD that holds record-like objects, with field names and =
runtime
> types. after all that is a successfull generic abstraction used in =
many
> structured data tools.
>=20
> but to me that abstraction is as simple as:
>=20
> trait SchemaRDD extends RDD[Row] {
>  def schema: StructType
> }
>=20
> and perhaps another abstraction to indicate it intends to be column
> oriented (with a few methods to efficiently extract a subset of =
columns).
> so that could be DataFrame.
>=20
> such simple contracts would allow many people to write loaders for =
this
> (say from csv) and whatnot.
>=20
> what i do not understand why it has to be much more complex than this. =
but
> if i look at DataFrame it has so much additional stuff, that has (in =
my
> eyes) nothing to do with generic structured data analysis.
>=20
> for example to implement DataFrame i need to implement about 40 =
additional
> methods!? and for some the SQLness is obviously leaking into the
> abstraction. for example why would i care about:
>  def registerTempTable(tableName: String): Unit
>=20
>=20
> best, koert
>=20
> On Sun, Feb 1, 2015 at 3:31 AM, Evan Chan <velvia.github@gmail.com> =
wrote:
>=20
>> It is true that you can persist SchemaRdds / DataFrames to disk via
>> Parquet, but a lot of time and inefficiencies is lost.   The =
in-memory
>> columnar cached representation is completely different from the
>> Parquet file format, and I believe there has to be a translation into
>> a Row (because ultimately Spark SQL traverses Row's -- even the
>> InMemoryColumnarTableScan has to then convert the columns into Rows
>> for row-based processing).   On the other hand, traditional data
>> frames process in a columnar fashion.   Columnar storage is good, but
>> nowhere near as good as columnar processing.
>>=20
>> Another issue, which I don't know if it is solved yet, but it is
>> difficult for Tachyon to efficiently cache Parquet files without
>> understanding the file format itself.
>>=20
>> I gave a talk at last year's Spark Summit on this topic.
>>=20
>> I'm working on efforts to change this, however.  Shoot me an email at
>> velvia at gmail if you're interested in joining forces.
>>=20
>> On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com> =
wrote:
>>> Yes, when a DataFrame is cached in memory, it's stored in an =
efficient
>>> columnar format. And you can also easily persist it on disk using
>> Parquet,
>>> which is also columnar.
>>>=20
>>> Cheng
>>>=20
>>>=20
>>> On 1/29/15 1:24 PM, Koert Kuipers wrote:
>>>>=20
>>>> to me the word DataFrame does come with certain expectations. one =
of
>> them
>>>> is that the data is stored columnar. in R data.frame internally =
uses a
>>>> list
>>>> of sequences i think, but since lists can have labels its more like =
a
>>>> SortedMap[String, Array[_]]. this makes certain operations very =
cheap
>>>> (such
>>>> as adding a column).
>>>>=20
>>>> in Spark the closest thing would be a data structure where per =
Partition
>>>> the data is also stored columnar. does spark SQL already use =
something
>>>> like
>>>> that? Evan mentioned "Spark SQL columnar compression", which sounds =
like
>>>> it. where can i find that?
>>>>=20
>>>> thanks
>>>>=20
>>>> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan =
<velvia.github@gmail.com>
>>>> wrote:
>>>>=20
>>>>> +1.... having proper NA support is much cleaner than using null, =
at
>>>>> least the Java null.
>>>>>=20
>>>>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks =
<evan.sparks@gmail.com
>>>=20
>>>>> wrote:
>>>>>>=20
>>>>>> You've got to be a little bit careful here. "NA" in systems like =
R or
>>>>>=20
>>>>> pandas
>>>>>>=20
>>>>>> may have special meaning that is distinct from "null".
>>>>>>=20
>>>>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
>>>>>>=20
>>>>>>=20
>>>>>>=20
>>>>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin =
<rxin@databricks.com>
>>>>>=20
>>>>> wrote:
>>>>>>>=20
>>>>>>> Isn't that just "null" in SQL?
>>>>>>>=20
>>>>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan =
<velvia.github@gmail.com>
>>>>>>> wrote:
>>>>>>>=20
>>>>>>>> I believe that most DataFrame implementations out there, like
>> Pandas,
>>>>>>>> supports the idea of missing values / NA, and some support the =
idea
>> of
>>>>>>>> Not Meaningful as well.
>>>>>>>>=20
>>>>>>>> Does Row support anything like that?  That is important for =
certain
>>>>>>>> applications.  I thought that Row worked by being a mutable =
object,
>>>>>>>> but haven't looked into the details in a while.
>>>>>>>>=20
>>>>>>>> -Evan
>>>>>>>>=20
>>>>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin =
<rxin@databricks.com>
>>>>>>>> wrote:
>>>>>>>>>=20
>>>>>>>>> It shouldn't change the data source api at all because data =
sources
>>>>>>>>=20
>>>>>>>> create
>>>>>>>>>=20
>>>>>>>>> RDD[Row], and that gets converted into a DataFrame =
automatically
>>>>>>>>=20
>>>>>>>> (previously
>>>>>>>>>=20
>>>>>>>>> to SchemaRDD).
>>>>>>>>>=20
>>>>>>>>>=20
>>>>>>>>=20
>>>>>=20
>>>>>=20
>> =
https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/ap=
ache/spark/sql/sources/interfaces.scala
>>>>>>>>>=20
>>>>>>>>> One thing that will break the data source API in 1.3 is the
>> location
>>>>>>>>> of
>>>>>>>>> types. Types were previously defined in sql.catalyst.types, =
and now
>>>>>>>>=20
>>>>>>>> moved to
>>>>>>>>>=20
>>>>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and =
all
>>>>>>>>> public
>>>>>>>>=20
>>>>>>>> APIs
>>>>>>>>>=20
>>>>>>>>> have first class classes/objects defined in sql directly.
>>>>>>>>>=20
>>>>>>>>>=20
>>>>>>>>>=20
>>>>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <
>> velvia.github@gmail.com
>>>>>>>>=20
>>>>>>>> wrote:
>>>>>>>>>>=20
>>>>>>>>>> Hey guys,
>>>>>>>>>>=20
>>>>>>>>>> How does this impact the data sources API?  I was planning on
>> using
>>>>>>>>>> this for a project.
>>>>>>>>>>=20
>>>>>>>>>> +1 that many things from spark-sql / DataFrame is universally
>>>>>>>>>> desirable and useful.
>>>>>>>>>>=20
>>>>>>>>>> By the way, one thing that prevents the columnar compression =
stuff
>>>>>=20
>>>>> in
>>>>>>>>>>=20
>>>>>>>>>> Spark SQL from being more useful is, at least from previous =
talks
>>>>>>>>>> with
>>>>>>>>>> Reynold and Michael et al., that the format was not designed =
for
>>>>>>>>>> persistence.
>>>>>>>>>>=20
>>>>>>>>>> I have a new project that aims to change that.  It is a
>>>>>>>>>> zero-serialisation, high performance binary vector library,
>>>>>=20
>>>>> designed
>>>>>>>>>>=20
>>>>>>>>>> from the outset to be a persistent storage friendly.  May be =
one
>>>>>=20
>>>>> day
>>>>>>>>>>=20
>>>>>>>>>> it can replace the Spark SQL columnar compression.
>>>>>>>>>>=20
>>>>>>>>>> Michael told me this would be a lot of work, and recreates =
parts
>> of
>>>>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
>>>>>=20
>>>>> details.
>>>>>>>>>>=20
>>>>>>>>>> -Evan
>>>>>>>>>>=20
>>>>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin =
<rxin@databricks.com
>>>=20
>>>>>>>>=20
>>>>>>>> wrote:
>>>>>>>>>>>=20
>>>>>>>>>>> Alright I have merged the patch (
>>>>>>>>>>> https://github.com/apache/spark/pull/4173
>>>>>>>>>>> ) since I don't see any strong opinions against it (as a =
matter
>>>>>=20
>>>>> of
>>>>>>>>=20
>>>>>>>> fact
>>>>>>>>>>>=20
>>>>>>>>>>> most were for it). We can still change it if somebody lays =
out a
>>>>>>>>=20
>>>>>>>> strong
>>>>>>>>>>>=20
>>>>>>>>>>> argument.
>>>>>>>>>>>=20
>>>>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
>>>>>>>>>>> <matei.zaharia@gmail.com>
>>>>>>>>>>> wrote:
>>>>>>>>>>>=20
>>>>>>>>>>>> The type alias means your methods can specify either type =
and
>>>>>=20
>>>>> they
>>>>>>>>=20
>>>>>>>> will
>>>>>>>>>>>>=20
>>>>>>>>>>>> work. It's just another name for the same type. But =
Scaladocs
>>>>>=20
>>>>> and
>>>>>>>>=20
>>>>>>>> such
>>>>>>>>>>>>=20
>>>>>>>>>>>> will
>>>>>>>>>>>> show DataFrame as the type.
>>>>>>>>>>>>=20
>>>>>>>>>>>> Matei
>>>>>>>>>>>>=20
>>>>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
>>>>>>>>>>>>=20
>>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> Reynold,
>>>>>>>>>>>>> But with type alias we will have the same problem, right?
>>>>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will =
have
>>>>>>>>>>>>> to
>>>>>>>>>>>>> change
>>>>>>>>>>>>> our code to migrade from schema to dataframe. Unless we =
have
>>>>>=20
>>>>> an
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> implicit
>>>>>>>>>>>>> conversion between DataFrame and SchemaRDD
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin =
<rxin@databricks.com>:
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> Dirceu,
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> That is not possible because one cannot overload return
>>>>>=20
>>>>> types.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
>>>>>=20
>>>>> return
>>>>>>>>=20
>>>>>>>> some
>>>>>>>>>>>>=20
>>>>>>>>>>>> type,
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
>>>>>>>>>>>>>> SchemaRDD
>>>>>>>>>>>>>> to
>>>>>>>>>>>>=20
>>>>>>>>>>>> not
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> break source compatibility for Scala.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
>>>>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and =
be
>>>>>>>>=20
>>>>>>>> removed
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> in
>>>>>>>>>>>>=20
>>>>>>>>>>>> the
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been =
added
>>>>>>>>>>>>>>> to
>>>>>>>>>>>>=20
>>>>>>>>>>>> DataFrame?
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> With this, we don't impact in existing code for the next =
few
>>>>>>>>>>>>>>> releases.
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
>>>>>>>>>>>>>>> <kushal.datta@gmail.com>:
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> I want to address the issue that Matei raised about the
>>>>>=20
>>>>> heavy
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> lifting
>>>>>>>>>>>>>>>> required for a full SQL support. It is amazing that =
even
>>>>>>>>>>>>>>>> after
>>>>>>>>=20
>>>>>>>> 30
>>>>>>>>>>>>=20
>>>>>>>>>>>> years
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> of
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> research there is not a single good open source =
columnar
>>>>>>>>=20
>>>>>>>> database
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> like
>>>>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but =
it is
>>>>>>>>>>>>>>>> not
>>>>>>>>>>>>>>>> nearly
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> as
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
>>>>>=20
>>>>> need
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>> such
>>>>>>>>>>>>=20
>>>>>>>>>>>> a
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> system. I wonder why so and it's high time to change =
that.
>>>>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
>>>>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
>>>>>>>>>>>>=20
>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though =
I
>>>>>=20
>>>>> like
>>>>>>>>=20
>>>>>>>> the
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> former
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> slightly better because it's more descriptive.
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under =
the
>>>>>>>>=20
>>>>>>>> covers,
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> it
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> would
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> be more clear from a user-facing perspective to at =
least
>>>>>>>>=20
>>>>>>>> choose a
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> package
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> name for it that omits "sql".
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark =
Schema
>>>>>>>>=20
>>>>>>>> module
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> Spark
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large =
a
>>>>>>>>>>>>>>>>> change
>>>>>>>>=20
>>>>>>>> at
>>>>>>>>>>>>=20
>>>>>>>>>>>> this
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> point?
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> -Sandy
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> matei.zaharia@gmail.com>
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of =
giving
>>>>>>>>>>>>>>>>>> it
>>>>>>>>>>>>>>>>>> another
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> name,
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL =
since
>>>>>>>>>>>>>>>>>> that
>>>>>>>>>>>>>>>>>> was
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> most
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> obvious use case to many users.)
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> Matei
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> matei.zaharia@gmail.com>
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>> While it might be possible to move this concept to =
Spark
>>>>>>>>>>>>>>>>>>> Core
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> long-term,
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> supporting structured data efficiently does require
>>>>>=20
>>>>> quite a
>>>>>>>>=20
>>>>>>>> bit
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> of
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning =
and
>>>>>>>>=20
>>>>>>>> columnar
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> storage.
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a =
SQL
>>>>>>>>>>>>>>>>>> server
>>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> it's
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> meant to be a library for manipulating structured =
data.
>>>>>>>>>>>>>>>>>> Since
>>>>>>>>>>>>>>>>>> this
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> is
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> possible to build over the core API, it's pretty =
natural
>>>>>=20
>>>>> to
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> organize it
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>> Matei
>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
>>>>>>>>=20
>>>>>>>> koert@tresata.com>
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
>>>>>=20
>>>>> data
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> format
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> used
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
>>>>>=20
>>>>> used
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> various
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline =
API."
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in =
spark
>>>>>>>>>>>>>>>>>>>> core,
>>>>>>>>=20
>>>>>>>> not
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> sql
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
>>>>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it =
yet,
>>>>>>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>>>> Jan.
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> 13
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> Bay
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> Area
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of =
background
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> information
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> on
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> this
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=3DYWppYPWznSQ
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> ________________________________
>>>>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
>>>>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
>>>>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
>>>>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
>>>>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
>>>>>=20
>>>>> there
>>>>>>>>=20
>>>>>>>> will
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> be
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> a
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> 1:1
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
>>>>>>>>=20
>>>>>>>> DataFrame.
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> rxin@databricks.com>
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> Hi,
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD -> =
DataFrame in
>>>>>>>>>>>>>>>>>>>>>> 1.3,
>>>>>>>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> wanted
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> to
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> get the community's opinion.
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a =
common
>>>>>=20
>>>>> data
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> format
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> used
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, =
and
>>>>>>>>>>>>>>>>>>>>>> used
>>>>>>>>=20
>>>>>>>> for
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> various
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline =
API.
>>>>>=20
>>>>> We
>>>>>>>>=20
>>>>>>>> also
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> expect
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> more
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> more users to be programming directly against
>>>>>=20
>>>>> SchemaRDD
>>>>>>>>=20
>>>>>>>> API
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> rather
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> than
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less =
commonly
>>>>>=20
>>>>> used
>>>>>>>>=20
>>>>>>>> DSL
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> originally
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
>>>>>>>>>>>>>>>>>>>>>> data-frame
>>>>>>>>>>>>>>>>>>>>>> like
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> API.
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> In
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
>>>>>=20
>>>>> usable
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>>> end
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> users.
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
>>>>>=20
>>>>> than
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> SchemaRDD.
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to =
be an
>>>>>>>>>>>>>>>>>>>>>> RDD
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> anymore
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> (even
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like =
map,
>>>>>>>>>>>>>>>>>>>>>> flatMap,
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> etc),
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> and
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
>>>>>=20
>>>>> highly
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> confusing.
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> Instead.
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for =
all
>>>>>>>>>>>>>>>>>>>>>> RDD
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> methods.
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
>>>>>>>>>>>>>>>>>>>>>> directly
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> against
>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
>>>>>=20
>>>>> well
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> documented.
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> However,
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can create =
a
>>>>>>>>>>>>>>>>>>>>>> type
>>>>>>>>>>>>>>>>>>>>>> alias
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> DataFrame
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
>>>>>>>>>>>>>>>>>>>>>> source
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> compatibility
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> for
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all =
existing
>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>> materials to
>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>> use
>>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>=20
>>>>>>>>=20
>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>>>>>=20
>>>>> dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>=20
>>>>>>>>=20
>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>>>>>=20
>>>>> dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>=20
>>>>>>>>=20
>> ---------------------------------------------------------------------
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail: =
dev-unsubscribe@spark.apache.org
>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>>>>>=20
>>>>> dev-help@spark.apache.org
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>=20
>>>>>>>>>>>>=20
>>>>>>>>>>>>=20
>>>>> =
---------------------------------------------------------------------
>>>>>>>>>>>>=20
>>>>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>>>>>>>>=20
>>>>>>>>>>>>=20
>>>>>>>>>=20
>>>>>>=20
>>>>> =
---------------------------------------------------------------------
>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>=20
>>>>>=20
>>>=20
>>>=20
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>=20
>>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11572-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 19:59:15 2015
Return-Path: <dev-return-11572-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 61E12172DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 19:59:15 +0000 (UTC)
Received: (qmail 41741 invoked by uid 500); 10 Feb 2015 19:59:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41670 invoked by uid 500); 10 Feb 2015 19:59:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41659 invoked by uid 99); 10 Feb 2015 19:59:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:59:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.192.45] (HELO mail-qg0-f45.google.com) (209.85.192.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 19:58:45 +0000
Received: by mail-qg0-f45.google.com with SMTP id h3so22899620qgf.4
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 11:58:22 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=rINn1Xwpgx++gDqT0fWq8EOKHNVEfT1T17Yoa9D/8E0=;
        b=ejEQ60zKBHrCXdo4XRvTuP+UBqJapIDcMzXGbp1gg6CEeQQq6poviUsz56IYb63lGf
         Fz2Zf3inZy7ByX8QpLiALNGpn7kHrBmxBRAAhckhkjhi9rTRbblEkfk7Ssp82YG1ZEz0
         e7WTnfVgiNWF0bMg+lEmimpfJjvbmGCc8EgCls4BK/+3jGAwuaqfwzO+33RnCheFfc1Y
         bcsJgFTXC95qyCHAsQ1U2VmmBdpXoNZJQ1Hh67rr0+Eqn0oev79LZgTc7ZFpsmCsrBFx
         xl3b5/rx+9rvQioeyyZILTKZvW5Y7YfC8loqzcIHhYcKaY7ps3Mbana5wrgWGbMSGbqD
         ydTg==
X-Gm-Message-State: ALoCoQmwPf3BCeBnbH/XpGTIMaX3UgI1Rc1hdJe9zOKe92aU4497QqytujdhB5sABt5wBBhf7eTb
X-Received: by 10.140.109.99 with SMTP id k90mr54280284qgf.35.1423598302339;
 Tue, 10 Feb 2015 11:58:22 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Tue, 10 Feb 2015 11:58:01 -0800 (PST)
In-Reply-To: <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
 <CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
 <CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
 <CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
 <CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
 <D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com> <CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
 <CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
 <CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
 <CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
 <CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
 <CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
 <CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
 <CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
 <54CAAD2D.8030407@gmail.com> <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
 <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 10 Feb 2015 11:58:01 -0800
Message-ID: <CAPh_B=ZaHB2iWtx0sBGMuAJQde7cTaB=fR7Wm9S4bTCLfygqYQ@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139872e1d42b0050ec14f38
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139872e1d42b0050ec14f38
Content-Type: text/plain; charset=UTF-8

Koert,

Don't get too hang up on the name SQL. This is exactly what you want: a
collection with record-like objects with field names and runtime types.

Almost all of the 40 methods are transformations for structured data, such
as aggregation on a field, or filtering on a field. If all you have is the
old RDD style map/flatMap, then any transformation would lose the schema
information, making the extra schema information useless.




On Tue, Feb 10, 2015 at 11:47 AM, Koert Kuipers <koert@tresata.com> wrote:

> so i understand the success or spark.sql. besides the fact that anything
> with the words SQL in its name will have thousands of developers running
> towards it because of the familiarity, there is also a genuine need for a
> generic RDD that holds record-like objects, with field names and runtime
> types. after all that is a successfull generic abstraction used in many
> structured data tools.
>
> but to me that abstraction is as simple as:
>
> trait SchemaRDD extends RDD[Row] {
>   def schema: StructType
> }
>
> and perhaps another abstraction to indicate it intends to be column
> oriented (with a few methods to efficiently extract a subset of columns).
> so that could be DataFrame.
>
> such simple contracts would allow many people to write loaders for this
> (say from csv) and whatnot.
>
> what i do not understand why it has to be much more complex than this. but
> if i look at DataFrame it has so much additional stuff, that has (in my
> eyes) nothing to do with generic structured data analysis.
>
> for example to implement DataFrame i need to implement about 40 additional
> methods!? and for some the SQLness is obviously leaking into the
> abstraction. for example why would i care about:
>   def registerTempTable(tableName: String): Unit
>
>
> best, koert
>
> On Sun, Feb 1, 2015 at 3:31 AM, Evan Chan <velvia.github@gmail.com> wrote:
>
> > It is true that you can persist SchemaRdds / DataFrames to disk via
> > Parquet, but a lot of time and inefficiencies is lost.   The in-memory
> > columnar cached representation is completely different from the
> > Parquet file format, and I believe there has to be a translation into
> > a Row (because ultimately Spark SQL traverses Row's -- even the
> > InMemoryColumnarTableScan has to then convert the columns into Rows
> > for row-based processing).   On the other hand, traditional data
> > frames process in a columnar fashion.   Columnar storage is good, but
> > nowhere near as good as columnar processing.
> >
> > Another issue, which I don't know if it is solved yet, but it is
> > difficult for Tachyon to efficiently cache Parquet files without
> > understanding the file format itself.
> >
> > I gave a talk at last year's Spark Summit on this topic.
> >
> > I'm working on efforts to change this, however.  Shoot me an email at
> > velvia at gmail if you're interested in joining forces.
> >
> > On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com>
> wrote:
> > > Yes, when a DataFrame is cached in memory, it's stored in an efficient
> > > columnar format. And you can also easily persist it on disk using
> > Parquet,
> > > which is also columnar.
> > >
> > > Cheng
> > >
> > >
> > > On 1/29/15 1:24 PM, Koert Kuipers wrote:
> > >>
> > >> to me the word DataFrame does come with certain expectations. one of
> > them
> > >> is that the data is stored columnar. in R data.frame internally uses a
> > >> list
> > >> of sequences i think, but since lists can have labels its more like a
> > >> SortedMap[String, Array[_]]. this makes certain operations very cheap
> > >> (such
> > >> as adding a column).
> > >>
> > >> in Spark the closest thing would be a data structure where per
> Partition
> > >> the data is also stored columnar. does spark SQL already use something
> > >> like
> > >> that? Evan mentioned "Spark SQL columnar compression", which sounds
> like
> > >> it. where can i find that?
> > >>
> > >> thanks
> > >>
> > >> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan <velvia.github@gmail.com>
> > >> wrote:
> > >>
> > >>> +1.... having proper NA support is much cleaner than using null, at
> > >>> least the Java null.
> > >>>
> > >>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks <
> evan.sparks@gmail.com
> > >
> > >>> wrote:
> > >>>>
> > >>>> You've got to be a little bit careful here. "NA" in systems like R
> or
> > >>>
> > >>> pandas
> > >>>>
> > >>>> may have special meaning that is distinct from "null".
> > >>>>
> > >>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
> > >>>>
> > >>>>
> > >>>>
> > >>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin <rxin@databricks.com>
> > >>>
> > >>> wrote:
> > >>>>>
> > >>>>> Isn't that just "null" in SQL?
> > >>>>>
> > >>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan <
> velvia.github@gmail.com>
> > >>>>> wrote:
> > >>>>>
> > >>>>>> I believe that most DataFrame implementations out there, like
> > Pandas,
> > >>>>>> supports the idea of missing values / NA, and some support the
> idea
> > of
> > >>>>>> Not Meaningful as well.
> > >>>>>>
> > >>>>>> Does Row support anything like that?  That is important for
> certain
> > >>>>>> applications.  I thought that Row worked by being a mutable
> object,
> > >>>>>> but haven't looked into the details in a while.
> > >>>>>>
> > >>>>>> -Evan
> > >>>>>>
> > >>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin <rxin@databricks.com
> >
> > >>>>>> wrote:
> > >>>>>>>
> > >>>>>>> It shouldn't change the data source api at all because data
> sources
> > >>>>>>
> > >>>>>> create
> > >>>>>>>
> > >>>>>>> RDD[Row], and that gets converted into a DataFrame automatically
> > >>>>>>
> > >>>>>> (previously
> > >>>>>>>
> > >>>>>>> to SchemaRDD).
> > >>>>>>>
> > >>>>>>>
> > >>>>>>
> > >>>
> > >>>
> >
> https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala
> > >>>>>>>
> > >>>>>>> One thing that will break the data source API in 1.3 is the
> > location
> > >>>>>>> of
> > >>>>>>> types. Types were previously defined in sql.catalyst.types, and
> now
> > >>>>>>
> > >>>>>> moved to
> > >>>>>>>
> > >>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and all
> > >>>>>>> public
> > >>>>>>
> > >>>>>> APIs
> > >>>>>>>
> > >>>>>>> have first class classes/objects defined in sql directly.
> > >>>>>>>
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <
> > velvia.github@gmail.com
> > >>>>>>
> > >>>>>> wrote:
> > >>>>>>>>
> > >>>>>>>> Hey guys,
> > >>>>>>>>
> > >>>>>>>> How does this impact the data sources API?  I was planning on
> > using
> > >>>>>>>> this for a project.
> > >>>>>>>>
> > >>>>>>>> +1 that many things from spark-sql / DataFrame is universally
> > >>>>>>>> desirable and useful.
> > >>>>>>>>
> > >>>>>>>> By the way, one thing that prevents the columnar compression
> stuff
> > >>>
> > >>> in
> > >>>>>>>>
> > >>>>>>>> Spark SQL from being more useful is, at least from previous
> talks
> > >>>>>>>> with
> > >>>>>>>> Reynold and Michael et al., that the format was not designed for
> > >>>>>>>> persistence.
> > >>>>>>>>
> > >>>>>>>> I have a new project that aims to change that.  It is a
> > >>>>>>>> zero-serialisation, high performance binary vector library,
> > >>>
> > >>> designed
> > >>>>>>>>
> > >>>>>>>> from the outset to be a persistent storage friendly.  May be one
> > >>>
> > >>> day
> > >>>>>>>>
> > >>>>>>>> it can replace the Spark SQL columnar compression.
> > >>>>>>>>
> > >>>>>>>> Michael told me this would be a lot of work, and recreates parts
> > of
> > >>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
> > >>>
> > >>> details.
> > >>>>>>>>
> > >>>>>>>> -Evan
> > >>>>>>>>
> > >>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin <
> rxin@databricks.com
> > >
> > >>>>>>
> > >>>>>> wrote:
> > >>>>>>>>>
> > >>>>>>>>> Alright I have merged the patch (
> > >>>>>>>>> https://github.com/apache/spark/pull/4173
> > >>>>>>>>> ) since I don't see any strong opinions against it (as a matter
> > >>>
> > >>> of
> > >>>>>>
> > >>>>>> fact
> > >>>>>>>>>
> > >>>>>>>>> most were for it). We can still change it if somebody lays out
> a
> > >>>>>>
> > >>>>>> strong
> > >>>>>>>>>
> > >>>>>>>>> argument.
> > >>>>>>>>>
> > >>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
> > >>>>>>>>> <matei.zaharia@gmail.com>
> > >>>>>>>>> wrote:
> > >>>>>>>>>
> > >>>>>>>>>> The type alias means your methods can specify either type and
> > >>>
> > >>> they
> > >>>>>>
> > >>>>>> will
> > >>>>>>>>>>
> > >>>>>>>>>> work. It's just another name for the same type. But Scaladocs
> > >>>
> > >>> and
> > >>>>>>
> > >>>>>> such
> > >>>>>>>>>>
> > >>>>>>>>>> will
> > >>>>>>>>>> show DataFrame as the type.
> > >>>>>>>>>>
> > >>>>>>>>>> Matei
> > >>>>>>>>>>
> > >>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
> > >>>>>>>>>>
> > >>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> > >>>>>>>>>>>
> > >>>>>>>>>>> Reynold,
> > >>>>>>>>>>> But with type alias we will have the same problem, right?
> > >>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will
> have
> > >>>>>>>>>>> to
> > >>>>>>>>>>> change
> > >>>>>>>>>>> our code to migrade from schema to dataframe. Unless we have
> > >>>
> > >>> an
> > >>>>>>>>>>>
> > >>>>>>>>>>> implicit
> > >>>>>>>>>>> conversion between DataFrame and SchemaRDD
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin <rxin@databricks.com
> >:
> > >>>>>>>>>>>
> > >>>>>>>>>>>> Dirceu,
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> That is not possible because one cannot overload return
> > >>>
> > >>> types.
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
> > >>>
> > >>> return
> > >>>>>>
> > >>>>>> some
> > >>>>>>>>>>
> > >>>>>>>>>> type,
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
> > >>>>>>>>>>>> SchemaRDD
> > >>>>>>>>>>>> to
> > >>>>>>>>>>
> > >>>>>>>>>> not
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> break source compatibility for Scala.
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
> > >>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and be
> > >>>>>>
> > >>>>>> removed
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> in
> > >>>>>>>>>>
> > >>>>>>>>>> the
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been
> added
> > >>>>>>>>>>>>> to
> > >>>>>>>>>>
> > >>>>>>>>>> DataFrame?
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> With this, we don't impact in existing code for the next
> few
> > >>>>>>>>>>>>> releases.
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
> > >>>>>>>>>>>>> <kushal.datta@gmail.com>:
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>> I want to address the issue that Matei raised about the
> > >>>
> > >>> heavy
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> lifting
> > >>>>>>>>>>>>>> required for a full SQL support. It is amazing that even
> > >>>>>>>>>>>>>> after
> > >>>>>>
> > >>>>>> 30
> > >>>>>>>>>>
> > >>>>>>>>>> years
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> of
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> research there is not a single good open source columnar
> > >>>>>>
> > >>>>>> database
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> like
> > >>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but it
> is
> > >>>>>>>>>>>>>> not
> > >>>>>>>>>>>>>> nearly
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> as
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
> > >>>
> > >>> need
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>> such
> > >>>>>>>>>>
> > >>>>>>>>>> a
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> system. I wonder why so and it's high time to change that.
> > >>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
> > >>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
> > >>>>>>>>>>
> > >>>>>>>>>> wrote:
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though I
> > >>>
> > >>> like
> > >>>>>>
> > >>>>>> the
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> former
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> slightly better because it's more descriptive.
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under the
> > >>>>>>
> > >>>>>> covers,
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> it
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> would
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> be more clear from a user-facing perspective to at least
> > >>>>>>
> > >>>>>> choose a
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> package
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> name for it that omits "sql".
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark
> Schema
> > >>>>>>
> > >>>>>> module
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> Spark
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large a
> > >>>>>>>>>>>>>>> change
> > >>>>>>
> > >>>>>> at
> > >>>>>>>>>>
> > >>>>>>>>>> this
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> point?
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> -Sandy
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> wrote:
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of
> giving
> > >>>>>>>>>>>>>>>> it
> > >>>>>>>>>>>>>>>> another
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> name,
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL
> since
> > >>>>>>>>>>>>>>>> that
> > >>>>>>>>>>>>>>>> was
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> the
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> most
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> obvious use case to many users.)
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> Matei
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> wrote:
> > >>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>> While it might be possible to move this concept to
> Spark
> > >>>>>>>>>>>>>>>>> Core
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> long-term,
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> supporting structured data efficiently does require
> > >>>
> > >>> quite a
> > >>>>>>
> > >>>>>> bit
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> of
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> the
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning and
> > >>>>>>
> > >>>>>> columnar
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> storage.
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a SQL
> > >>>>>>>>>>>>>>>> server
> > >>>>>>>>>>>>>>>> --
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> it's
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> meant to be a library for manipulating structured data.
> > >>>>>>>>>>>>>>>> Since
> > >>>>>>>>>>>>>>>> this
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> is
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> possible to build over the core API, it's pretty natural
> > >>>
> > >>> to
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> organize it
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
> > >>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>> Matei
> > >>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
> > >>>>>>
> > >>>>>> koert@tresata.com>
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> wrote:
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
> > >>>
> > >>> data
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> format
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> used
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
> > >>>
> > >>> used
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> various
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API."
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in spark
> > >>>>>>>>>>>>>>>>>> core,
> > >>>>>>
> > >>>>>> not
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> sql
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
> > >>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
> > >>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it yet,
> > >>>>>>>>>>>>>>>>>>> the
> > >>>>>>>>>>>>>>>>>>> Jan.
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> 13
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> Bay
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> Area
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of background
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> information
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> on
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> this
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=YWppYPWznSQ
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> ________________________________
> > >>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
> > >>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
> > >>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
> > >>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
> > >>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
> > >>>
> > >>> there
> > >>>>>>
> > >>>>>> will
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> be
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> a
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> 1:1
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
> > >>>>>>
> > >>>>>> DataFrame.
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> rxin@databricks.com>
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> wrote:
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> Hi,
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD -> DataFrame
> in
> > >>>>>>>>>>>>>>>>>>>> 1.3,
> > >>>>>>>>>>>>>>>>>>>> and
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> wanted
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> to
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> get the community's opinion.
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a common
> > >>>
> > >>> data
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> format
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> used
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
> > >>>>>>>>>>>>>>>>>>>> used
> > >>>>>>
> > >>>>>> for
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> various
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API.
> > >>>
> > >>> We
> > >>>>>>
> > >>>>>> also
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> expect
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> more
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> and
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> more users to be programming directly against
> > >>>
> > >>> SchemaRDD
> > >>>>>>
> > >>>>>> API
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> rather
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> than
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> the
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less commonly
> > >>>
> > >>> used
> > >>>>>>
> > >>>>>> DSL
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> originally
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
> > >>>>>>>>>>>>>>>>>>>> data-frame
> > >>>>>>>>>>>>>>>>>>>> like
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> API.
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> In
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
> > >>>
> > >>> usable
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>>>>>>>> end
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> users.
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
> > >>>
> > >>> than
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> SchemaRDD.
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to be
> an
> > >>>>>>>>>>>>>>>>>>>> RDD
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> anymore
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> (even
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like map,
> > >>>>>>>>>>>>>>>>>>>> flatMap,
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> etc),
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> and
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
> > >>>
> > >>> highly
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> confusing.
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> Instead.
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for all
> > >>>>>>>>>>>>>>>>>>>> RDD
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> methods.
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
> > >>>>>>>>>>>>>>>>>>>> directly
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> against
> > >>>>>>>>>>>>>>
> > >>>>>>>>>>>>>> the
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
> > >>>
> > >>> well
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> documented.
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> However,
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can create a
> > >>>>>>>>>>>>>>>>>>>> type
> > >>>>>>>>>>>>>>>>>>>> alias
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> DataFrame
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
> > >>>>>>>>>>>>>>>>>>>> source
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> compatibility
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> for
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all
> existing
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> materials to
> > >>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>> use
> > >>>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>
> > ---------------------------------------------------------------------
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> > >>>
> > >>> dev-unsubscribe@spark.apache.org
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>
> > >>>>>>
> > ---------------------------------------------------------------------
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> > >>>
> > >>> dev-unsubscribe@spark.apache.org
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>
> > >>>>>>
> > ---------------------------------------------------------------------
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> dev-unsubscribe@spark.apache.org
> > >>>>>>>>>>>>>>>> For additional commands, e-mail:
> > >>>
> > >>> dev-help@spark.apache.org
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>> ---------------------------------------------------------------------
> > >>>>>>>>>>
> > >>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
> > >>>>>>>>>>
> > >>>>>>>>>>
> > >>>>>>>
> > >>>>
> > >>> ---------------------------------------------------------------------
> > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > >>> For additional commands, e-mail: dev-help@spark.apache.org
> > >>>
> > >>>
> > >
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
>

--001a1139872e1d42b0050ec14f38--

From dev-return-11573-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 20:12:56 2015
Return-Path: <dev-return-11573-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 22FEE17384
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 20:12:56 +0000 (UTC)
Received: (qmail 87888 invoked by uid 500); 10 Feb 2015 20:12:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87800 invoked by uid 500); 10 Feb 2015 20:12:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87788 invoked by uid 99); 10 Feb 2015 20:12:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 20:12:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [74.125.82.42] (HELO mail-wg0-f42.google.com) (74.125.82.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 20:12:26 +0000
Received: by mail-wg0-f42.google.com with SMTP id x13so35819639wgg.1
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 12:10:34 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=07OoidIe6SGx5c8yVJIOQrDH7btIg55oOUc49e760qs=;
        b=a95djsDWl7zukrUWFXgWJhUz9UjwAskH/sC3EMnhYmbyIn0EBQqtAByEgM7h1o05Gt
         25TgUbMJhmP2ghwEfhQUU48EYHPrIJlWfkAysRiwEcLfsPikN7w6f2mqVeKc/lUR2T3B
         99b4wyuwZ3SeRBI25GrFENBqJ37VZbhEtoZ1Lt8WLeB65facmbqGUvPw5PNz8JrlYZvZ
         8T2r+P4kV6i3/PUMSOWCQlyqjbA8vtVvpKlsB1M8eBlP//mj47xVkhUX/gvlHO+OSK1t
         4Ldtbw1+6H2pG8yCUZzpy9cw1Qf1eHnnwrubpirMOqaBmG/RQ38LOKUGGsNccriLKq5a
         /tWA==
X-Gm-Message-State: ALoCoQm4QXaJojtOnkhDVz7f/pdymZ7b/k8dW4OGN2VVTjd7OKY5T5vQrpnweamlMbaHk/mO6t+5
MIME-Version: 1.0
X-Received: by 10.180.92.199 with SMTP id co7mr49354292wib.47.1423599034431;
 Tue, 10 Feb 2015 12:10:34 -0800 (PST)
Received: by 10.217.122.200 with HTTP; Tue, 10 Feb 2015 12:10:34 -0800 (PST)
X-Originating-IP: [204.148.13.62]
In-Reply-To: <CAPh_B=ZaHB2iWtx0sBGMuAJQde7cTaB=fR7Wm9S4bTCLfygqYQ@mail.gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
	<CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
	<CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
	<CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
	<CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
	<D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com>
	<CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
	<CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
	<CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
	<CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
	<CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
	<CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
	<CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
	<CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
	<54CAAD2D.8030407@gmail.com>
	<CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
	<CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
	<CAPh_B=ZaHB2iWtx0sBGMuAJQde7cTaB=fR7Wm9S4bTCLfygqYQ@mail.gmail.com>
Date: Tue, 10 Feb 2015 15:10:34 -0500
Message-ID: <CANx3uAgMOWYEt7sWibsxB59jBG4ai3z5zOdFavctgKVf3OXF2w@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
From: Koert Kuipers <koert@tresata.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c0776c00f39050ec17a42
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c0776c00f39050ec17a42
Content-Type: text/plain; charset=UTF-8

thanks matei its good to know i can create them like that

reynold, yeah somehow the words sql gets me going :) sorry...
yeah agreed that you need new transformations to preserve the schema info.
i misunderstood and thought i had to implement the bunch but that is
clearly not necessary as matei indicated.

allright i am clearly being slow/dense here, but now it makes sense to
me....






On Tue, Feb 10, 2015 at 2:58 PM, Reynold Xin <rxin@databricks.com> wrote:

> Koert,
>
> Don't get too hang up on the name SQL. This is exactly what you want: a
> collection with record-like objects with field names and runtime types.
>
> Almost all of the 40 methods are transformations for structured data, such
> as aggregation on a field, or filtering on a field. If all you have is the
> old RDD style map/flatMap, then any transformation would lose the schema
> information, making the extra schema information useless.
>
>
>
>
> On Tue, Feb 10, 2015 at 11:47 AM, Koert Kuipers <koert@tresata.com> wrote:
>
>> so i understand the success or spark.sql. besides the fact that anything
>> with the words SQL in its name will have thousands of developers running
>> towards it because of the familiarity, there is also a genuine need for a
>> generic RDD that holds record-like objects, with field names and runtime
>> types. after all that is a successfull generic abstraction used in many
>> structured data tools.
>>
>> but to me that abstraction is as simple as:
>>
>> trait SchemaRDD extends RDD[Row] {
>>   def schema: StructType
>> }
>>
>> and perhaps another abstraction to indicate it intends to be column
>> oriented (with a few methods to efficiently extract a subset of columns).
>> so that could be DataFrame.
>>
>> such simple contracts would allow many people to write loaders for this
>> (say from csv) and whatnot.
>>
>> what i do not understand why it has to be much more complex than this. but
>> if i look at DataFrame it has so much additional stuff, that has (in my
>> eyes) nothing to do with generic structured data analysis.
>>
>> for example to implement DataFrame i need to implement about 40 additional
>> methods!? and for some the SQLness is obviously leaking into the
>> abstraction. for example why would i care about:
>>   def registerTempTable(tableName: String): Unit
>>
>>
>> best, koert
>>
>> On Sun, Feb 1, 2015 at 3:31 AM, Evan Chan <velvia.github@gmail.com>
>> wrote:
>>
>> > It is true that you can persist SchemaRdds / DataFrames to disk via
>> > Parquet, but a lot of time and inefficiencies is lost.   The in-memory
>> > columnar cached representation is completely different from the
>> > Parquet file format, and I believe there has to be a translation into
>> > a Row (because ultimately Spark SQL traverses Row's -- even the
>> > InMemoryColumnarTableScan has to then convert the columns into Rows
>> > for row-based processing).   On the other hand, traditional data
>> > frames process in a columnar fashion.   Columnar storage is good, but
>> > nowhere near as good as columnar processing.
>> >
>> > Another issue, which I don't know if it is solved yet, but it is
>> > difficult for Tachyon to efficiently cache Parquet files without
>> > understanding the file format itself.
>> >
>> > I gave a talk at last year's Spark Summit on this topic.
>> >
>> > I'm working on efforts to change this, however.  Shoot me an email at
>> > velvia at gmail if you're interested in joining forces.
>> >
>> > On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com>
>> wrote:
>> > > Yes, when a DataFrame is cached in memory, it's stored in an efficient
>> > > columnar format. And you can also easily persist it on disk using
>> > Parquet,
>> > > which is also columnar.
>> > >
>> > > Cheng
>> > >
>> > >
>> > > On 1/29/15 1:24 PM, Koert Kuipers wrote:
>> > >>
>> > >> to me the word DataFrame does come with certain expectations. one of
>> > them
>> > >> is that the data is stored columnar. in R data.frame internally uses
>> a
>> > >> list
>> > >> of sequences i think, but since lists can have labels its more like a
>> > >> SortedMap[String, Array[_]]. this makes certain operations very cheap
>> > >> (such
>> > >> as adding a column).
>> > >>
>> > >> in Spark the closest thing would be a data structure where per
>> Partition
>> > >> the data is also stored columnar. does spark SQL already use
>> something
>> > >> like
>> > >> that? Evan mentioned "Spark SQL columnar compression", which sounds
>> like
>> > >> it. where can i find that?
>> > >>
>> > >> thanks
>> > >>
>> > >> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan <velvia.github@gmail.com>
>> > >> wrote:
>> > >>
>> > >>> +1.... having proper NA support is much cleaner than using null, at
>> > >>> least the Java null.
>> > >>>
>> > >>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks <
>> evan.sparks@gmail.com
>> > >
>> > >>> wrote:
>> > >>>>
>> > >>>> You've got to be a little bit careful here. "NA" in systems like R
>> or
>> > >>>
>> > >>> pandas
>> > >>>>
>> > >>>> may have special meaning that is distinct from "null".
>> > >>>>
>> > >>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
>> > >>>>
>> > >>>>
>> > >>>>
>> > >>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin <rxin@databricks.com>
>> > >>>
>> > >>> wrote:
>> > >>>>>
>> > >>>>> Isn't that just "null" in SQL?
>> > >>>>>
>> > >>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan <
>> velvia.github@gmail.com>
>> > >>>>> wrote:
>> > >>>>>
>> > >>>>>> I believe that most DataFrame implementations out there, like
>> > Pandas,
>> > >>>>>> supports the idea of missing values / NA, and some support the
>> idea
>> > of
>> > >>>>>> Not Meaningful as well.
>> > >>>>>>
>> > >>>>>> Does Row support anything like that?  That is important for
>> certain
>> > >>>>>> applications.  I thought that Row worked by being a mutable
>> object,
>> > >>>>>> but haven't looked into the details in a while.
>> > >>>>>>
>> > >>>>>> -Evan
>> > >>>>>>
>> > >>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin <
>> rxin@databricks.com>
>> > >>>>>> wrote:
>> > >>>>>>>
>> > >>>>>>> It shouldn't change the data source api at all because data
>> sources
>> > >>>>>>
>> > >>>>>> create
>> > >>>>>>>
>> > >>>>>>> RDD[Row], and that gets converted into a DataFrame automatically
>> > >>>>>>
>> > >>>>>> (previously
>> > >>>>>>>
>> > >>>>>>> to SchemaRDD).
>> > >>>>>>>
>> > >>>>>>>
>> > >>>>>>
>> > >>>
>> > >>>
>> >
>> https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala
>> > >>>>>>>
>> > >>>>>>> One thing that will break the data source API in 1.3 is the
>> > location
>> > >>>>>>> of
>> > >>>>>>> types. Types were previously defined in sql.catalyst.types, and
>> now
>> > >>>>>>
>> > >>>>>> moved to
>> > >>>>>>>
>> > >>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and all
>> > >>>>>>> public
>> > >>>>>>
>> > >>>>>> APIs
>> > >>>>>>>
>> > >>>>>>> have first class classes/objects defined in sql directly.
>> > >>>>>>>
>> > >>>>>>>
>> > >>>>>>>
>> > >>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <
>> > velvia.github@gmail.com
>> > >>>>>>
>> > >>>>>> wrote:
>> > >>>>>>>>
>> > >>>>>>>> Hey guys,
>> > >>>>>>>>
>> > >>>>>>>> How does this impact the data sources API?  I was planning on
>> > using
>> > >>>>>>>> this for a project.
>> > >>>>>>>>
>> > >>>>>>>> +1 that many things from spark-sql / DataFrame is universally
>> > >>>>>>>> desirable and useful.
>> > >>>>>>>>
>> > >>>>>>>> By the way, one thing that prevents the columnar compression
>> stuff
>> > >>>
>> > >>> in
>> > >>>>>>>>
>> > >>>>>>>> Spark SQL from being more useful is, at least from previous
>> talks
>> > >>>>>>>> with
>> > >>>>>>>> Reynold and Michael et al., that the format was not designed
>> for
>> > >>>>>>>> persistence.
>> > >>>>>>>>
>> > >>>>>>>> I have a new project that aims to change that.  It is a
>> > >>>>>>>> zero-serialisation, high performance binary vector library,
>> > >>>
>> > >>> designed
>> > >>>>>>>>
>> > >>>>>>>> from the outset to be a persistent storage friendly.  May be
>> one
>> > >>>
>> > >>> day
>> > >>>>>>>>
>> > >>>>>>>> it can replace the Spark SQL columnar compression.
>> > >>>>>>>>
>> > >>>>>>>> Michael told me this would be a lot of work, and recreates
>> parts
>> > of
>> > >>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
>> > >>>
>> > >>> details.
>> > >>>>>>>>
>> > >>>>>>>> -Evan
>> > >>>>>>>>
>> > >>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin <
>> rxin@databricks.com
>> > >
>> > >>>>>>
>> > >>>>>> wrote:
>> > >>>>>>>>>
>> > >>>>>>>>> Alright I have merged the patch (
>> > >>>>>>>>> https://github.com/apache/spark/pull/4173
>> > >>>>>>>>> ) since I don't see any strong opinions against it (as a
>> matter
>> > >>>
>> > >>> of
>> > >>>>>>
>> > >>>>>> fact
>> > >>>>>>>>>
>> > >>>>>>>>> most were for it). We can still change it if somebody lays
>> out a
>> > >>>>>>
>> > >>>>>> strong
>> > >>>>>>>>>
>> > >>>>>>>>> argument.
>> > >>>>>>>>>
>> > >>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
>> > >>>>>>>>> <matei.zaharia@gmail.com>
>> > >>>>>>>>> wrote:
>> > >>>>>>>>>
>> > >>>>>>>>>> The type alias means your methods can specify either type and
>> > >>>
>> > >>> they
>> > >>>>>>
>> > >>>>>> will
>> > >>>>>>>>>>
>> > >>>>>>>>>> work. It's just another name for the same type. But Scaladocs
>> > >>>
>> > >>> and
>> > >>>>>>
>> > >>>>>> such
>> > >>>>>>>>>>
>> > >>>>>>>>>> will
>> > >>>>>>>>>> show DataFrame as the type.
>> > >>>>>>>>>>
>> > >>>>>>>>>> Matei
>> > >>>>>>>>>>
>> > >>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
>> > >>>>>>>>>>
>> > >>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> Reynold,
>> > >>>>>>>>>>> But with type alias we will have the same problem, right?
>> > >>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will
>> have
>> > >>>>>>>>>>> to
>> > >>>>>>>>>>> change
>> > >>>>>>>>>>> our code to migrade from schema to dataframe. Unless we have
>> > >>>
>> > >>> an
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> implicit
>> > >>>>>>>>>>> conversion between DataFrame and SchemaRDD
>> > >>>>>>>>>>>
>> > >>>>>>>>>>>
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin <rxin@databricks.com
>> >:
>> > >>>>>>>>>>>
>> > >>>>>>>>>>>> Dirceu,
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> That is not possible because one cannot overload return
>> > >>>
>> > >>> types.
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
>> > >>>
>> > >>> return
>> > >>>>>>
>> > >>>>>> some
>> > >>>>>>>>>>
>> > >>>>>>>>>> type,
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
>> > >>>>>>>>>>>> SchemaRDD
>> > >>>>>>>>>>>> to
>> > >>>>>>>>>>
>> > >>>>>>>>>> not
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> break source compatibility for Scala.
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
>> > >>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and
>> be
>> > >>>>>>
>> > >>>>>> removed
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> in
>> > >>>>>>>>>>
>> > >>>>>>>>>> the
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been
>> added
>> > >>>>>>>>>>>>> to
>> > >>>>>>>>>>
>> > >>>>>>>>>> DataFrame?
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> With this, we don't impact in existing code for the next
>> few
>> > >>>>>>>>>>>>> releases.
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
>> > >>>>>>>>>>>>> <kushal.datta@gmail.com>:
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> I want to address the issue that Matei raised about the
>> > >>>
>> > >>> heavy
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> lifting
>> > >>>>>>>>>>>>>> required for a full SQL support. It is amazing that even
>> > >>>>>>>>>>>>>> after
>> > >>>>>>
>> > >>>>>> 30
>> > >>>>>>>>>>
>> > >>>>>>>>>> years
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> of
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> research there is not a single good open source columnar
>> > >>>>>>
>> > >>>>>> database
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> like
>> > >>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but it
>> is
>> > >>>>>>>>>>>>>> not
>> > >>>>>>>>>>>>>> nearly
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> as
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
>> > >>>
>> > >>> need
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>> such
>> > >>>>>>>>>>
>> > >>>>>>>>>> a
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> system. I wonder why so and it's high time to change
>> that.
>> > >>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
>> > >>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
>> > >>>>>>>>>>
>> > >>>>>>>>>> wrote:
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though I
>> > >>>
>> > >>> like
>> > >>>>>>
>> > >>>>>> the
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> former
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> slightly better because it's more descriptive.
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under the
>> > >>>>>>
>> > >>>>>> covers,
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> it
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> would
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> be more clear from a user-facing perspective to at least
>> > >>>>>>
>> > >>>>>> choose a
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> package
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> name for it that omits "sql".
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark
>> Schema
>> > >>>>>>
>> > >>>>>> module
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> Spark
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large a
>> > >>>>>>>>>>>>>>> change
>> > >>>>>>
>> > >>>>>> at
>> > >>>>>>>>>>
>> > >>>>>>>>>> this
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> point?
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> -Sandy
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> wrote:
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of
>> giving
>> > >>>>>>>>>>>>>>>> it
>> > >>>>>>>>>>>>>>>> another
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> name,
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL
>> since
>> > >>>>>>>>>>>>>>>> that
>> > >>>>>>>>>>>>>>>> was
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> the
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> most
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> obvious use case to many users.)
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> Matei
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> wrote:
>> > >>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>> While it might be possible to move this concept to
>> Spark
>> > >>>>>>>>>>>>>>>>> Core
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> long-term,
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> supporting structured data efficiently does require
>> > >>>
>> > >>> quite a
>> > >>>>>>
>> > >>>>>> bit
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> of
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> the
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning and
>> > >>>>>>
>> > >>>>>> columnar
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> storage.
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a SQL
>> > >>>>>>>>>>>>>>>> server
>> > >>>>>>>>>>>>>>>> --
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> it's
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> meant to be a library for manipulating structured data.
>> > >>>>>>>>>>>>>>>> Since
>> > >>>>>>>>>>>>>>>> this
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> is
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> possible to build over the core API, it's pretty
>> natural
>> > >>>
>> > >>> to
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> organize it
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
>> > >>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>> Matei
>> > >>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
>> > >>>>>>
>> > >>>>>> koert@tresata.com>
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> wrote:
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
>> > >>>
>> > >>> data
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> format
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> used
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
>> > >>>
>> > >>> used
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> various
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API."
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in spark
>> > >>>>>>>>>>>>>>>>>> core,
>> > >>>>>>
>> > >>>>>> not
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> sql
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
>> > >>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
>> > >>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it
>> yet,
>> > >>>>>>>>>>>>>>>>>>> the
>> > >>>>>>>>>>>>>>>>>>> Jan.
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> 13
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> Bay
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> Area
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of
>> background
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> information
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> on
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> this
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=YWppYPWznSQ
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> ________________________________
>> > >>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
>> > >>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
>> > >>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
>> > >>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
>> > >>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
>> > >>>
>> > >>> there
>> > >>>>>>
>> > >>>>>> will
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> be
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> a
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> 1:1
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
>> > >>>>>>
>> > >>>>>> DataFrame.
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> rxin@databricks.com>
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> wrote:
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> Hi,
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD -> DataFrame
>> in
>> > >>>>>>>>>>>>>>>>>>>> 1.3,
>> > >>>>>>>>>>>>>>>>>>>> and
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> wanted
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> to
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> get the community's opinion.
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a common
>> > >>>
>> > >>> data
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> format
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> used
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
>> > >>>>>>>>>>>>>>>>>>>> used
>> > >>>>>>
>> > >>>>>> for
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> various
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline API.
>> > >>>
>> > >>> We
>> > >>>>>>
>> > >>>>>> also
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> expect
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> more
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> and
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> more users to be programming directly against
>> > >>>
>> > >>> SchemaRDD
>> > >>>>>>
>> > >>>>>> API
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> rather
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> than
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> the
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less commonly
>> > >>>
>> > >>> used
>> > >>>>>>
>> > >>>>>> DSL
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> originally
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
>> > >>>>>>>>>>>>>>>>>>>> data-frame
>> > >>>>>>>>>>>>>>>>>>>> like
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> API.
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> In
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
>> > >>>
>> > >>> usable
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>>>>>>>> end
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> users.
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
>> > >>>
>> > >>> than
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> SchemaRDD.
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to be
>> an
>> > >>>>>>>>>>>>>>>>>>>> RDD
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> anymore
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> (even
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like
>> map,
>> > >>>>>>>>>>>>>>>>>>>> flatMap,
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> etc),
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> and
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
>> > >>>
>> > >>> highly
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> confusing.
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> Instead.
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for
>> all
>> > >>>>>>>>>>>>>>>>>>>> RDD
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> methods.
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
>> > >>>>>>>>>>>>>>>>>>>> directly
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> against
>> > >>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>> the
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
>> > >>>
>> > >>> well
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> documented.
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> However,
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can create a
>> > >>>>>>>>>>>>>>>>>>>> type
>> > >>>>>>>>>>>>>>>>>>>> alias
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> DataFrame
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
>> > >>>>>>>>>>>>>>>>>>>> source
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> compatibility
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> for
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all
>> existing
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> materials to
>> > >>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>> use
>> > >>>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>
>> > >>>>>>
>> > ---------------------------------------------------------------------
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>> > >>>
>> > >>> dev-unsubscribe@spark.apache.org
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>
>> > >>>>>>
>> > ---------------------------------------------------------------------
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>> > >>>
>> > >>> dev-unsubscribe@spark.apache.org
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
>> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>
>> > >>>>>>
>> > ---------------------------------------------------------------------
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>> To unsubscribe, e-mail:
>> dev-unsubscribe@spark.apache.org
>> > >>>>>>>>>>>>>>>> For additional commands, e-mail:
>> > >>>
>> > >>> dev-help@spark.apache.org
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>
>> > >>>>>>>>>>
>> > >>>>>>>>>>
>> > >>>
>> ---------------------------------------------------------------------
>> > >>>>>>>>>>
>> > >>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > >>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>> > >>>>>>>>>>
>> > >>>>>>>>>>
>> > >>>>>>>
>> > >>>>
>> > >>>
>> ---------------------------------------------------------------------
>> > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > >>> For additional commands, e-mail: dev-help@spark.apache.org
>> > >>>
>> > >>>
>> > >
>> > >
>> > > ---------------------------------------------------------------------
>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > For additional commands, e-mail: dev-help@spark.apache.org
>> > >
>> >
>>
>
>

--f46d043c0776c00f39050ec17a42--

From dev-return-11574-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 20:16:34 2015
Return-Path: <dev-return-11574-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 41A671739E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 20:16:34 +0000 (UTC)
Received: (qmail 4294 invoked by uid 500); 10 Feb 2015 20:16:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4226 invoked by uid 500); 10 Feb 2015 20:16:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4213 invoked by uid 99); 10 Feb 2015 20:16:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 20:16:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 20:16:28 +0000
Received: by mail-qg0-f53.google.com with SMTP id f51so28840569qge.12
        for <dev@spark.apache.org>; Tue, 10 Feb 2015 12:15:01 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=0roWBiyp/SGsKW/uu2I0rDFwqmPZ4/eDj8rj6EGyEmM=;
        b=d31iayhTjvVZqYq0a/ciC3390naNyye6Q8HOl2vlF0u7cDlYWcJ6lP6I/dUMhSJTUR
         19OfFTbVWoxKUESZyPeECEWg2n922iHotUy99SXwwqFInd3LT0UYOq/pfGeIctXf9sQl
         5Wdem5XM37t9K+WAUZeKufeVMWaKWMIY8XLKE2yG8oeRWlZdBki2WFNApoMBFB2edBAv
         1ZFFxQskJs1UG3N5jIWLRsADbREkKNYZ0tlphBftAJhh71577V+ueN26CDv35GRDR9l/
         bNhWgOe/DE7aaFs9OCNlhQ7BbxTeqboNp08V+GSKGk3d2Xj8Ib4WPk+BpGLGyHmj8T17
         91uA==
X-Gm-Message-State: ALoCoQmoqeM8Arou5oM1FRQCwqaxfoDoGa8fC6azD9HYmwAx/yzL+YOFjGwOKQgJ5QZYXMcKScet
X-Received: by 10.229.190.6 with SMTP id dg6mr57388119qcb.16.1423599301508;
 Tue, 10 Feb 2015 12:15:01 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Tue, 10 Feb 2015 12:14:41 -0800 (PST)
In-Reply-To: <CANx3uAgMOWYEt7sWibsxB59jBG4ai3z5zOdFavctgKVf3OXF2w@mail.gmail.com>
References: <CABPQxsutcmwwZOgWUj36HcWsUPz+S9003MNZZoxcNZTx6Fnwaw@mail.gmail.com>
 <CANjHi9rj8aFrZWohEoNU+-gmmRDsRp8OQdUOLxjnEuf3ZS+Tug@mail.gmail.com>
 <CAO4-Pq9-+sVSf-R4EcdcH_2ytb74fGLVevY_T3OCezt1UXiJCA@mail.gmail.com>
 <CAPh_B=bvP4upD7SNg-vbYRQGhjfLYTtzOSfysq4-g_DHxyaS7g@mail.gmail.com>
 <CAO4-Pq9G1KbsM3UR2O_cfUKruKcGcfVsDG5HxYjEPR1eD4VSww@mail.gmail.com>
 <D4F5E5C6-14C9-4566-806D-E94AA7D5B0C7@gmail.com> <CAPh_B=ZdTZv_8zFjE3YH0qPvEqnaSfaRW=DgbjEy-V9BjvxiBA@mail.gmail.com>
 <CAN6Vra04d2x+aP6-L4eC-bx3_hEiJZCok7DhtJTGYsD2VE1=Ew@mail.gmail.com>
 <CAPh_B=anVaSM5=bEBvNpV+0PLonW9y4NG3tsOpeXjxTJVRRAOA@mail.gmail.com>
 <CAN6Vra05sqS3GBccyj6GUj6iCWqxNwG7BDc1j3+s9wZTjeiTDw@mail.gmail.com>
 <CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com>
 <CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com>
 <CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com>
 <CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com>
 <54CAAD2D.8030407@gmail.com> <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com>
 <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com>
 <CAPh_B=ZaHB2iWtx0sBGMuAJQde7cTaB=fR7Wm9S4bTCLfygqYQ@mail.gmail.com> <CANx3uAgMOWYEt7sWibsxB59jBG4ai3z5zOdFavctgKVf3OXF2w@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 10 Feb 2015 12:14:41 -0800
Message-ID: <CAPh_B=Z5Wefghcne7kiovpxobXnStJ=40hNTkS+WSz6s0xhyFw@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11336798ab59b9050ec18a0d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11336798ab59b9050ec18a0d
Content-Type: text/plain; charset=UTF-8

It's a good point. I will update the documentation to say that this is not
meant to be subclassed externally.


On Tue, Feb 10, 2015 at 12:10 PM, Koert Kuipers <koert@tresata.com> wrote:

> thanks matei its good to know i can create them like that
>
> reynold, yeah somehow the words sql gets me going :) sorry...
> yeah agreed that you need new transformations to preserve the schema info.
> i misunderstood and thought i had to implement the bunch but that is
> clearly not necessary as matei indicated.
>
> allright i am clearly being slow/dense here, but now it makes sense to
> me....
>
>
>
>
>
>
> On Tue, Feb 10, 2015 at 2:58 PM, Reynold Xin <rxin@databricks.com> wrote:
>
> > Koert,
> >
> > Don't get too hang up on the name SQL. This is exactly what you want: a
> > collection with record-like objects with field names and runtime types.
> >
> > Almost all of the 40 methods are transformations for structured data,
> such
> > as aggregation on a field, or filtering on a field. If all you have is
> the
> > old RDD style map/flatMap, then any transformation would lose the schema
> > information, making the extra schema information useless.
> >
> >
> >
> >
> > On Tue, Feb 10, 2015 at 11:47 AM, Koert Kuipers <koert@tresata.com>
> wrote:
> >
> >> so i understand the success or spark.sql. besides the fact that anything
> >> with the words SQL in its name will have thousands of developers running
> >> towards it because of the familiarity, there is also a genuine need for
> a
> >> generic RDD that holds record-like objects, with field names and runtime
> >> types. after all that is a successfull generic abstraction used in many
> >> structured data tools.
> >>
> >> but to me that abstraction is as simple as:
> >>
> >> trait SchemaRDD extends RDD[Row] {
> >>   def schema: StructType
> >> }
> >>
> >> and perhaps another abstraction to indicate it intends to be column
> >> oriented (with a few methods to efficiently extract a subset of
> columns).
> >> so that could be DataFrame.
> >>
> >> such simple contracts would allow many people to write loaders for this
> >> (say from csv) and whatnot.
> >>
> >> what i do not understand why it has to be much more complex than this.
> but
> >> if i look at DataFrame it has so much additional stuff, that has (in my
> >> eyes) nothing to do with generic structured data analysis.
> >>
> >> for example to implement DataFrame i need to implement about 40
> additional
> >> methods!? and for some the SQLness is obviously leaking into the
> >> abstraction. for example why would i care about:
> >>   def registerTempTable(tableName: String): Unit
> >>
> >>
> >> best, koert
> >>
> >> On Sun, Feb 1, 2015 at 3:31 AM, Evan Chan <velvia.github@gmail.com>
> >> wrote:
> >>
> >> > It is true that you can persist SchemaRdds / DataFrames to disk via
> >> > Parquet, but a lot of time and inefficiencies is lost.   The in-memory
> >> > columnar cached representation is completely different from the
> >> > Parquet file format, and I believe there has to be a translation into
> >> > a Row (because ultimately Spark SQL traverses Row's -- even the
> >> > InMemoryColumnarTableScan has to then convert the columns into Rows
> >> > for row-based processing).   On the other hand, traditional data
> >> > frames process in a columnar fashion.   Columnar storage is good, but
> >> > nowhere near as good as columnar processing.
> >> >
> >> > Another issue, which I don't know if it is solved yet, but it is
> >> > difficult for Tachyon to efficiently cache Parquet files without
> >> > understanding the file format itself.
> >> >
> >> > I gave a talk at last year's Spark Summit on this topic.
> >> >
> >> > I'm working on efforts to change this, however.  Shoot me an email at
> >> > velvia at gmail if you're interested in joining forces.
> >> >
> >> > On Thu, Jan 29, 2015 at 1:59 PM, Cheng Lian <lian.cs.zju@gmail.com>
> >> wrote:
> >> > > Yes, when a DataFrame is cached in memory, it's stored in an
> efficient
> >> > > columnar format. And you can also easily persist it on disk using
> >> > Parquet,
> >> > > which is also columnar.
> >> > >
> >> > > Cheng
> >> > >
> >> > >
> >> > > On 1/29/15 1:24 PM, Koert Kuipers wrote:
> >> > >>
> >> > >> to me the word DataFrame does come with certain expectations. one
> of
> >> > them
> >> > >> is that the data is stored columnar. in R data.frame internally
> uses
> >> a
> >> > >> list
> >> > >> of sequences i think, but since lists can have labels its more
> like a
> >> > >> SortedMap[String, Array[_]]. this makes certain operations very
> cheap
> >> > >> (such
> >> > >> as adding a column).
> >> > >>
> >> > >> in Spark the closest thing would be a data structure where per
> >> Partition
> >> > >> the data is also stored columnar. does spark SQL already use
> >> something
> >> > >> like
> >> > >> that? Evan mentioned "Spark SQL columnar compression", which sounds
> >> like
> >> > >> it. where can i find that?
> >> > >>
> >> > >> thanks
> >> > >>
> >> > >> On Thu, Jan 29, 2015 at 2:32 PM, Evan Chan <
> velvia.github@gmail.com>
> >> > >> wrote:
> >> > >>
> >> > >>> +1.... having proper NA support is much cleaner than using null,
> at
> >> > >>> least the Java null.
> >> > >>>
> >> > >>> On Wed, Jan 28, 2015 at 6:10 PM, Evan R. Sparks <
> >> evan.sparks@gmail.com
> >> > >
> >> > >>> wrote:
> >> > >>>>
> >> > >>>> You've got to be a little bit careful here. "NA" in systems like
> R
> >> or
> >> > >>>
> >> > >>> pandas
> >> > >>>>
> >> > >>>> may have special meaning that is distinct from "null".
> >> > >>>>
> >> > >>>> See, e.g. http://www.r-bloggers.com/r-na-vs-null/
> >> > >>>>
> >> > >>>>
> >> > >>>>
> >> > >>>> On Wed, Jan 28, 2015 at 4:42 PM, Reynold Xin <
> rxin@databricks.com>
> >> > >>>
> >> > >>> wrote:
> >> > >>>>>
> >> > >>>>> Isn't that just "null" in SQL?
> >> > >>>>>
> >> > >>>>> On Wed, Jan 28, 2015 at 4:41 PM, Evan Chan <
> >> velvia.github@gmail.com>
> >> > >>>>> wrote:
> >> > >>>>>
> >> > >>>>>> I believe that most DataFrame implementations out there, like
> >> > Pandas,
> >> > >>>>>> supports the idea of missing values / NA, and some support the
> >> idea
> >> > of
> >> > >>>>>> Not Meaningful as well.
> >> > >>>>>>
> >> > >>>>>> Does Row support anything like that?  That is important for
> >> certain
> >> > >>>>>> applications.  I thought that Row worked by being a mutable
> >> object,
> >> > >>>>>> but haven't looked into the details in a while.
> >> > >>>>>>
> >> > >>>>>> -Evan
> >> > >>>>>>
> >> > >>>>>> On Wed, Jan 28, 2015 at 4:23 PM, Reynold Xin <
> >> rxin@databricks.com>
> >> > >>>>>> wrote:
> >> > >>>>>>>
> >> > >>>>>>> It shouldn't change the data source api at all because data
> >> sources
> >> > >>>>>>
> >> > >>>>>> create
> >> > >>>>>>>
> >> > >>>>>>> RDD[Row], and that gets converted into a DataFrame
> automatically
> >> > >>>>>>
> >> > >>>>>> (previously
> >> > >>>>>>>
> >> > >>>>>>> to SchemaRDD).
> >> > >>>>>>>
> >> > >>>>>>>
> >> > >>>>>>
> >> > >>>
> >> > >>>
> >> >
> >>
> https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala
> >> > >>>>>>>
> >> > >>>>>>> One thing that will break the data source API in 1.3 is the
> >> > location
> >> > >>>>>>> of
> >> > >>>>>>> types. Types were previously defined in sql.catalyst.types,
> and
> >> now
> >> > >>>>>>
> >> > >>>>>> moved to
> >> > >>>>>>>
> >> > >>>>>>> sql.types. After 1.3, sql.catalyst is hidden from users, and
> all
> >> > >>>>>>> public
> >> > >>>>>>
> >> > >>>>>> APIs
> >> > >>>>>>>
> >> > >>>>>>> have first class classes/objects defined in sql directly.
> >> > >>>>>>>
> >> > >>>>>>>
> >> > >>>>>>>
> >> > >>>>>>> On Wed, Jan 28, 2015 at 4:20 PM, Evan Chan <
> >> > velvia.github@gmail.com
> >> > >>>>>>
> >> > >>>>>> wrote:
> >> > >>>>>>>>
> >> > >>>>>>>> Hey guys,
> >> > >>>>>>>>
> >> > >>>>>>>> How does this impact the data sources API?  I was planning on
> >> > using
> >> > >>>>>>>> this for a project.
> >> > >>>>>>>>
> >> > >>>>>>>> +1 that many things from spark-sql / DataFrame is universally
> >> > >>>>>>>> desirable and useful.
> >> > >>>>>>>>
> >> > >>>>>>>> By the way, one thing that prevents the columnar compression
> >> stuff
> >> > >>>
> >> > >>> in
> >> > >>>>>>>>
> >> > >>>>>>>> Spark SQL from being more useful is, at least from previous
> >> talks
> >> > >>>>>>>> with
> >> > >>>>>>>> Reynold and Michael et al., that the format was not designed
> >> for
> >> > >>>>>>>> persistence.
> >> > >>>>>>>>
> >> > >>>>>>>> I have a new project that aims to change that.  It is a
> >> > >>>>>>>> zero-serialisation, high performance binary vector library,
> >> > >>>
> >> > >>> designed
> >> > >>>>>>>>
> >> > >>>>>>>> from the outset to be a persistent storage friendly.  May be
> >> one
> >> > >>>
> >> > >>> day
> >> > >>>>>>>>
> >> > >>>>>>>> it can replace the Spark SQL columnar compression.
> >> > >>>>>>>>
> >> > >>>>>>>> Michael told me this would be a lot of work, and recreates
> >> parts
> >> > of
> >> > >>>>>>>> Parquet, but I think it's worth it.  LMK if you'd like more
> >> > >>>
> >> > >>> details.
> >> > >>>>>>>>
> >> > >>>>>>>> -Evan
> >> > >>>>>>>>
> >> > >>>>>>>> On Tue, Jan 27, 2015 at 4:35 PM, Reynold Xin <
> >> rxin@databricks.com
> >> > >
> >> > >>>>>>
> >> > >>>>>> wrote:
> >> > >>>>>>>>>
> >> > >>>>>>>>> Alright I have merged the patch (
> >> > >>>>>>>>> https://github.com/apache/spark/pull/4173
> >> > >>>>>>>>> ) since I don't see any strong opinions against it (as a
> >> matter
> >> > >>>
> >> > >>> of
> >> > >>>>>>
> >> > >>>>>> fact
> >> > >>>>>>>>>
> >> > >>>>>>>>> most were for it). We can still change it if somebody lays
> >> out a
> >> > >>>>>>
> >> > >>>>>> strong
> >> > >>>>>>>>>
> >> > >>>>>>>>> argument.
> >> > >>>>>>>>>
> >> > >>>>>>>>> On Tue, Jan 27, 2015 at 12:25 PM, Matei Zaharia
> >> > >>>>>>>>> <matei.zaharia@gmail.com>
> >> > >>>>>>>>> wrote:
> >> > >>>>>>>>>
> >> > >>>>>>>>>> The type alias means your methods can specify either type
> and
> >> > >>>
> >> > >>> they
> >> > >>>>>>
> >> > >>>>>> will
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> work. It's just another name for the same type. But
> Scaladocs
> >> > >>>
> >> > >>> and
> >> > >>>>>>
> >> > >>>>>> such
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> will
> >> > >>>>>>>>>> show DataFrame as the type.
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> Matei
> >> > >>>>>>>>>>
> >> > >>>>>>>>>>> On Jan 27, 2015, at 12:10 PM, Dirceu Semighini Filho <
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>> Reynold,
> >> > >>>>>>>>>>> But with type alias we will have the same problem, right?
> >> > >>>>>>>>>>> If the methods doesn't receive schemardd anymore, we will
> >> have
> >> > >>>>>>>>>>> to
> >> > >>>>>>>>>>> change
> >> > >>>>>>>>>>> our code to migrade from schema to dataframe. Unless we
> have
> >> > >>>
> >> > >>> an
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>> implicit
> >> > >>>>>>>>>>> conversion between DataFrame and SchemaRDD
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>> 2015-01-27 17:18 GMT-02:00 Reynold Xin <
> rxin@databricks.com
> >> >:
> >> > >>>>>>>>>>>
> >> > >>>>>>>>>>>> Dirceu,
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> That is not possible because one cannot overload return
> >> > >>>
> >> > >>> types.
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> SQLContext.parquetFile (and many other methods) needs to
> >> > >>>
> >> > >>> return
> >> > >>>>>>
> >> > >>>>>> some
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> type,
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> and that type cannot be both SchemaRDD and DataFrame.
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> In 1.3, we will create a type alias for DataFrame called
> >> > >>>>>>>>>>>> SchemaRDD
> >> > >>>>>>>>>>>> to
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> not
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> break source compatibility for Scala.
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>> On Tue, Jan 27, 2015 at 6:28 AM, Dirceu Semighini Filho <
> >> > >>>>>>>>>>>> dirceu.semighini@gmail.com> wrote:
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>>>> Can't the SchemaRDD remain the same, but deprecated, and
> >> be
> >> > >>>>>>
> >> > >>>>>> removed
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> in
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> the
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> release 1.5(+/- 1)  for example, and the new code been
> >> added
> >> > >>>>>>>>>>>>> to
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> DataFrame?
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> With this, we don't impact in existing code for the next
> >> few
> >> > >>>>>>>>>>>>> releases.
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> 2015-01-27 0:02 GMT-02:00 Kushal Datta
> >> > >>>>>>>>>>>>> <kushal.datta@gmail.com>:
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> I want to address the issue that Matei raised about the
> >> > >>>
> >> > >>> heavy
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> lifting
> >> > >>>>>>>>>>>>>> required for a full SQL support. It is amazing that
> even
> >> > >>>>>>>>>>>>>> after
> >> > >>>>>>
> >> > >>>>>> 30
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> years
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> of
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> research there is not a single good open source
> columnar
> >> > >>>>>>
> >> > >>>>>> database
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> like
> >> > >>>>>>>>>>>>>> Vertica. There is a column store option in MySQL, but
> it
> >> is
> >> > >>>>>>>>>>>>>> not
> >> > >>>>>>>>>>>>>> nearly
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> as
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> sophisticated as Vertica or MonetDB. But there's a true
> >> > >>>
> >> > >>> need
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>> such
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> a
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> system. I wonder why so and it's high time to change
> >> that.
> >> > >>>>>>>>>>>>>> On Jan 26, 2015 5:47 PM, "Sandy Ryza"
> >> > >>>>>>>>>>>>>> <sandy.ryza@cloudera.com>
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> wrote:
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> Both SchemaRDD and DataFrame sound fine to me, though
> I
> >> > >>>
> >> > >>> like
> >> > >>>>>>
> >> > >>>>>> the
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> former
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> slightly better because it's more descriptive.
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> Even if SchemaRDD's needs to rely on Spark SQL under
> the
> >> > >>>>>>
> >> > >>>>>> covers,
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> it
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> would
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> be more clear from a user-facing perspective to at
> least
> >> > >>>>>>
> >> > >>>>>> choose a
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> package
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> name for it that omits "sql".
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> I would also be in favor of adding a separate Spark
> >> Schema
> >> > >>>>>>
> >> > >>>>>> module
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> Spark
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> SQL to rely on, but I imagine that might be too large
> a
> >> > >>>>>>>>>>>>>>> change
> >> > >>>>>>
> >> > >>>>>> at
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> this
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> point?
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> -Sandy
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 5:32 PM, Matei Zaharia <
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> wrote:
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> (Actually when we designed Spark SQL we thought of
> >> giving
> >> > >>>>>>>>>>>>>>>> it
> >> > >>>>>>>>>>>>>>>> another
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> name,
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> like Spark Schema, but we decided to stick with SQL
> >> since
> >> > >>>>>>>>>>>>>>>> that
> >> > >>>>>>>>>>>>>>>> was
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> the
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> most
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> obvious use case to many users.)
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> Matei
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>> On Jan 26, 2015, at 5:31 PM, Matei Zaharia <
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> matei.zaharia@gmail.com>
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> wrote:
> >> > >>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>> While it might be possible to move this concept to
> >> Spark
> >> > >>>>>>>>>>>>>>>>> Core
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> long-term,
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> supporting structured data efficiently does require
> >> > >>>
> >> > >>> quite a
> >> > >>>>>>
> >> > >>>>>> bit
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> of
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> the
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> infrastructure in Spark SQL, such as query planning
> and
> >> > >>>>>>
> >> > >>>>>> columnar
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> storage.
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> The intent of Spark SQL though is to be more than a
> SQL
> >> > >>>>>>>>>>>>>>>> server
> >> > >>>>>>>>>>>>>>>> --
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> it's
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> meant to be a library for manipulating structured
> data.
> >> > >>>>>>>>>>>>>>>> Since
> >> > >>>>>>>>>>>>>>>> this
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> is
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> possible to build over the core API, it's pretty
> >> natural
> >> > >>>
> >> > >>> to
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> organize it
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> that way, same as Spark Streaming is a library.
> >> > >>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>> Matei
> >> > >>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> On Jan 26, 2015, at 4:26 PM, Koert Kuipers <
> >> > >>>>>>
> >> > >>>>>> koert@tresata.com>
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> wrote:
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> "The context is that SchemaRDD is becoming a common
> >> > >>>
> >> > >>> data
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> format
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> used
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> bringing data into Spark from external systems, and
> >> > >>>
> >> > >>> used
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> various
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline
> API."
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> i agree. this to me also implies it belongs in
> spark
> >> > >>>>>>>>>>>>>>>>>> core,
> >> > >>>>>>
> >> > >>>>>> not
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> sql
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 6:11 PM, Michael Malak <
> >> > >>>>>>>>>>>>>>>>>> michaelmalak@yahoo.com.invalid> wrote:
> >> > >>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> And in the off chance that anyone hasn't seen it
> >> yet,
> >> > >>>>>>>>>>>>>>>>>>> the
> >> > >>>>>>>>>>>>>>>>>>> Jan.
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> 13
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> Bay
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> Area
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> Spark Meetup YouTube contained a wealth of
> >> background
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> information
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> on
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> this
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> idea (mostly from Patrick and Reynold :-).
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> https://www.youtube.com/watch?v=YWppYPWznSQ
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> ________________________________
> >> > >>>>>>>>>>>>>>>>>>> From: Patrick Wendell <pwendell@gmail.com>
> >> > >>>>>>>>>>>>>>>>>>> To: Reynold Xin <rxin@databricks.com>
> >> > >>>>>>>>>>>>>>>>>>> Cc: "dev@spark.apache.org" <dev@spark.apache.org>
> >> > >>>>>>>>>>>>>>>>>>> Sent: Monday, January 26, 2015 4:01 PM
> >> > >>>>>>>>>>>>>>>>>>> Subject: Re: renaming SchemaRDD -> DataFrame
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> One thing potentially not clear from this e-mail,
> >> > >>>
> >> > >>> there
> >> > >>>>>>
> >> > >>>>>> will
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> be
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> a
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> 1:1
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> correspondence where you can get an RDD to/from a
> >> > >>>>>>
> >> > >>>>>> DataFrame.
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> On Mon, Jan 26, 2015 at 2:18 PM, Reynold Xin <
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> rxin@databricks.com>
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> wrote:
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> Hi,
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> We are considering renaming SchemaRDD ->
> DataFrame
> >> in
> >> > >>>>>>>>>>>>>>>>>>>> 1.3,
> >> > >>>>>>>>>>>>>>>>>>>> and
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> wanted
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> to
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> get the community's opinion.
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> The context is that SchemaRDD is becoming a
> common
> >> > >>>
> >> > >>> data
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> format
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> used
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> bringing data into Spark from external systems,
> and
> >> > >>>>>>>>>>>>>>>>>>>> used
> >> > >>>>>>
> >> > >>>>>> for
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> various
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> components of Spark, e.g. MLlib's new pipeline
> API.
> >> > >>>
> >> > >>> We
> >> > >>>>>>
> >> > >>>>>> also
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> expect
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> more
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> and
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> more users to be programming directly against
> >> > >>>
> >> > >>> SchemaRDD
> >> > >>>>>>
> >> > >>>>>> API
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> rather
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> than
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> the
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> core RDD API. SchemaRDD, through its less
> commonly
> >> > >>>
> >> > >>> used
> >> > >>>>>>
> >> > >>>>>> DSL
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> originally
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> designed for writing test cases, always has the
> >> > >>>>>>>>>>>>>>>>>>>> data-frame
> >> > >>>>>>>>>>>>>>>>>>>> like
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> API.
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> In
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> 1.3, we are redesigning the API to make the API
> >> > >>>
> >> > >>> usable
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>>>>>>>> end
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> users.
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> There are two motivations for the renaming:
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> 1. DataFrame seems to be a more self-evident name
> >> > >>>
> >> > >>> than
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> SchemaRDD.
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> 2. SchemaRDD/DataFrame is actually not going to
> be
> >> an
> >> > >>>>>>>>>>>>>>>>>>>> RDD
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> anymore
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> (even
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> though it would contain some RDD functions like
> >> map,
> >> > >>>>>>>>>>>>>>>>>>>> flatMap,
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> etc),
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> and
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> calling it Schema*RDD* while it is not an RDD is
> >> > >>>
> >> > >>> highly
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> confusing.
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> Instead.
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> DataFrame.rdd will return the underlying RDD for
> >> all
> >> > >>>>>>>>>>>>>>>>>>>> RDD
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> methods.
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> My understanding is that very few users program
> >> > >>>>>>>>>>>>>>>>>>>> directly
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> against
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>> the
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> SchemaRDD API at the moment, because they are not
> >> > >>>
> >> > >>> well
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> documented.
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> However,
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> oo maintain backward compatibility, we can
> create a
> >> > >>>>>>>>>>>>>>>>>>>> type
> >> > >>>>>>>>>>>>>>>>>>>> alias
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> DataFrame
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> that is still named SchemaRDD. This will maintain
> >> > >>>>>>>>>>>>>>>>>>>> source
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> compatibility
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> for
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> Scala. That said, we will have to update all
> >> existing
> >> > >>>>>>>>>>>>>
> >> > >>>>>>>>>>>>> materials to
> >> > >>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>> use
> >> > >>>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>> DataFrame rather than SchemaRDD.
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>
> >> > ---------------------------------------------------------------------
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> >> > >>>
> >> > >>> dev-unsubscribe@spark.apache.org
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> >> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>
> >> > >>>>>>
> >> > ---------------------------------------------------------------------
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> >> > >>>
> >> > >>> dev-unsubscribe@spark.apache.org
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>> For additional commands, e-mail:
> >> > >>>>>>>>>>>>>>>>>>> dev-help@spark.apache.org
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>
> >> > >>>>>>
> >> > ---------------------------------------------------------------------
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>> To unsubscribe, e-mail:
> >> dev-unsubscribe@spark.apache.org
> >> > >>>>>>>>>>>>>>>> For additional commands, e-mail:
> >> > >>>
> >> > >>> dev-help@spark.apache.org
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>>>>>
> >> > >>>>>>>>>>>>
> >> > >>>>>>>>>>
> >> > >>>>>>>>>>
> >> > >>>>>>>>>>
> >> > >>>
> >> ---------------------------------------------------------------------
> >> > >>>>>>>>>>
> >> > >>>>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> > >>>>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
> >> > >>>>>>>>>>
> >> > >>>>>>>>>>
> >> > >>>>>>>
> >> > >>>>
> >> > >>>
> >> ---------------------------------------------------------------------
> >> > >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> > >>> For additional commands, e-mail: dev-help@spark.apache.org
> >> > >>>
> >> > >>>
> >> > >
> >> > >
> >> > >
> ---------------------------------------------------------------------
> >> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> > > For additional commands, e-mail: dev-help@spark.apache.org
> >> > >
> >> >
> >>
> >
> >
>

--001a11336798ab59b9050ec18a0d--

From dev-return-11575-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 22:14:39 2015
Return-Path: <dev-return-11575-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8DF87179C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 22:14:39 +0000 (UTC)
Received: (qmail 28793 invoked by uid 500); 10 Feb 2015 22:14:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28720 invoked by uid 500); 10 Feb 2015 22:14:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28709 invoked by uid 99); 10 Feb 2015 22:14:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 22:14:38 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.55] (HELO g4t3427.houston.hp.com) (15.201.208.55)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 22:14:11 +0000
Received: from G4W6310.americas.hpqcorp.net (g4w6310.houston.hp.com [16.210.26.217])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3427.houston.hp.com (Postfix) with ESMTPS id 4AEEAB1;
	Tue, 10 Feb 2015 22:13:39 +0000 (UTC)
Received: from G9W3613.americas.hpqcorp.net (16.216.186.48) by
 G4W6310.americas.hpqcorp.net (16.210.26.217) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Tue, 10 Feb 2015 22:11:58 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G9W3613.americas.hpqcorp.net ([16.216.186.48]) with mapi id 14.03.0169.001;
 Tue, 10 Feb 2015 22:11:58 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0AAAKwxgACUAsfwAAMhugAAKb0RoA==
Date: Tue, 10 Feb 2015 22:11:56 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
 <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
In-Reply-To: <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.216.65.181]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26G4W3292americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26G4W3292americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26G4W3292americas_--

From dev-return-11576-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 10 23:09:33 2015
Return-Path: <dev-return-11576-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1AEA317C2E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 10 Feb 2015 23:09:33 +0000 (UTC)
Received: (qmail 15569 invoked by uid 500); 10 Feb 2015 23:09:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15323 invoked by uid 500); 10 Feb 2015 23:09:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14602 invoked by uid 99); 10 Feb 2015 23:09:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 23:09:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,HTML_OBFUSCATE_05_10,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of scottwalent@gmail.com designates 209.85.217.171 as permitted sender)
Received: from [209.85.217.171] (HELO mail-lb0-f171.google.com) (209.85.217.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 10 Feb 2015 23:09:01 +0000
Received: by mail-lb0-f171.google.com with SMTP id b6so67118lbj.2;
        Tue, 10 Feb 2015 15:08:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=76djMsv6Zyu6KUjplP8WPxHbZuu+wJW6sD9Xr3sSgEg=;
        b=qCjhO6ORw41ecbZoPKgBdDS1Y16HZ3HAkDLJsIaeCuByktw4xGsKVKlZPHZKlbb/dn
         6tdh7SvVdSC+uo5MhkiurE+McTrP8aE7WOfyUl3mS+FQef0BcDpV1HXG0+9TrpZpkvb4
         LHjLjaqb0oqut2rczxsKp2zhUPJ3gT/qqTrBoQ2DjYWRzgQd+8BVYIA5d2tnQic4axOJ
         otmRQpI7wrWmHD5mYuVEMW+RbMQAlfrHv9UzcklMvbogS14TJJ1AbRQxxuc4aMs8QX92
         6OuVY0Kye30KroSEvZ1wINu0SGog+cpnh+o5imgQ51bHo+pN2jfmmpsO2Jc1AwR3ht4l
         x2VQ==
MIME-Version: 1.0
X-Received: by 10.112.12.228 with SMTP id b4mr24266772lbc.83.1423609695145;
 Tue, 10 Feb 2015 15:08:15 -0800 (PST)
Received: by 10.114.175.129 with HTTP; Tue, 10 Feb 2015 15:08:15 -0800 (PST)
Date: Tue, 10 Feb 2015 15:08:15 -0800
Message-ID: <CAP7HBy04Ac79ocMvxcr2WfLSmXWmXgsXNGGV5JZZkyj73SqmXw@mail.gmail.com>
Subject: Spark Summit East - March 18-19 - NYC
From: Scott walent <scottwalent@gmail.com>
To: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3a7b02d94e1050ec3f697
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3a7b02d94e1050ec3f697
Content-Type: text/plain; charset=UTF-8

The inaugural Spark Summit East, an event to bring the Apache Spark
community together, will be in New York City on March 18, 2015. We are
excited about the growth of Spark and to bring the event to the east coast.

At Spark Summit East you can look forward to hearing from Matei Zaharia,
Databricks CEO Ion Stoica, representatives from Palantir, Goldman Sachs,
Baidu, Salesforce, Cloudera, Box, and many others. (See the full agenda at
http://spark-summit.org/east/2015)  All of these companies are utilizing
Spark. Come see what their experience has been and get a chance to talk
with some of the creators and committers.

If you are new to Spark or looking to improve on your knowledge of the
technology, there will be three levels of Spark Training: Intro to Spark,
Advanced Spark Training, and Data Science with Spark.

Space is limited, but we want to make sure those active in the community
are aware of the this new event in NYC. Use promo code "DevList15" for 15%
off your registration fee when registering before March 1, 2015.

Register at http://spark-summit.org/east/2015/register

Looking forward to seeing you there!

Best,
Scott & The Spark Summit Organizers

--001a11c3a7b02d94e1050ec3f697--

From dev-return-11577-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 04:09:56 2015
Return-Path: <dev-return-11577-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 37CA810950
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 04:09:56 +0000 (UTC)
Received: (qmail 34325 invoked by uid 500); 11 Feb 2015 04:09:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33517 invoked by uid 500); 11 Feb 2015 04:09:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33488 invoked by uid 99); 11 Feb 2015 04:09:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 04:09:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tianyi.asiainfo@gmail.com designates 209.85.192.171 as permitted sender)
Received: from [209.85.192.171] (HELO mail-pd0-f171.google.com) (209.85.192.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 04:09:45 +0000
Received: by pdjg10 with SMTP id g10so1609890pdj.1;
        Tue, 10 Feb 2015 20:08:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:organization:user-agent:mime-version:to:cc
         :subject:content-type;
        bh=Rf/fy+49extHZdNJwukIrKGSirhM6uOJB4SwQ0l7EuM=;
        b=ff78DVFy1y+yC1fMdZ/DaBdBVO6L5oVUqT9/0To5Ur7rGMg268CSYBbvf4kxig+DNu
         0A1yIF9Ss3KreBXgeX8c5NQ/1BIriAnQOJX+PqJDdi/omOejO73TvyFVLrgAeNzfl4BE
         ++3hHXs3QRxk07xfS2a6laWph20xSV+KgUs1KOplm5dARDSM8vV0aIJsT3hvkHnlK1z3
         1Vpncgq98y/keqK3ciKIGonVPNH4xvmw18pAu02u5gpyZKid5HMD8YRiMcHGbLvGytl1
         nU4eGazbCYKs+D4l7pXORbOt//CazBlr2V8ENaI76VN2oUNlPic9fi4pYs7pYpsP3WA/
         4hbA==
X-Received: by 10.70.100.35 with SMTP id ev3mr43329360pdb.11.1423627719700;
        Tue, 10 Feb 2015 20:08:39 -0800 (PST)
Received: from [10.1.48.43] ([202.85.218.126])
        by mx.google.com with ESMTPSA id xw1sm20981603pac.47.2015.02.10.20.08.37
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 10 Feb 2015 20:08:39 -0800 (PST)
Message-ID: <54DAD5C0.1020300@gmail.com>
Date: Wed, 11 Feb 2015 12:08:32 +0800
From: Yi Tian <tianyi.asiainfo@gmail.com>
Organization: Asiainfo.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: dev@spark.apache.org
CC: user@spark.apache.org
Subject: Build spark failed with maven
Content-Type: multipart/alternative;
 boundary="------------090708060206040605090504"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------090708060206040605090504
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hi, all

I got an ERROR when I build spark master branch with maven (commit: 
|2d1e916730492f5d61b97da6c483d3223ca44315|)

|[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] Building Spark Project Catalyst 1.3.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO]
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-versions) @ spark-catalyst_2.10 ---
[INFO]
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-scala-sources) @ spark-catalyst_2.10 ---
[INFO] Source directory: /Users/tianyi/github/community/apache-spark/sql/catalyst/src/main/scala added.
[INFO]
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-catalyst_2.10 ---
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-catalyst_2.10 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/tianyi/github/community/apache-spark/sql/catalyst/src/main/resources
[INFO] Copying 3 resources
[INFO]
[INFO] --- scala-maven-plugin:3.2.0:compile (scala-compile-first) @ spark-catalyst_2.10 ---
[INFO] Using zinc server for incremental compilation
[INFO] compiler plugin: BasicArtifact(org.scalamacros,paradise_2.10.4,2.0.1,null)
[info] Compiling 69 Scala sources and 3 Java sources to /Users/tianyi/github/community/apache-spark/sql/catalyst/target/scala-2.10/classes...
[error] /Users/tianyi/github/community/apache-spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/dsl/package.scala:314: polymorphic expression cannot be instantiated to expected type;
[error]  found   : [T(in method apply)]org.apache.spark.sql.catalyst.dsl.ScalaUdfBuilder[T(in method apply)]
[error]  required: org.apache.spark.sql.catalyst.dsl.package.ScalaUdfBuilder[T(in method functionToUdfBuilder)]
[error]   implicit def functionToUdfBuilder[T: TypeTag](func: Function1[_, T]): ScalaUdfBuilder[T] = ScalaUdfBuilder(func)
|

Any suggestion?

​

--------------090708060206040605090504--

From dev-return-11578-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 08:33:17 2015
Return-Path: <dev-return-11578-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5BB4710208
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 08:33:17 +0000 (UTC)
Received: (qmail 3886 invoked by uid 500); 11 Feb 2015 08:33:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 3815 invoked by uid 500); 11 Feb 2015 08:33:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 3803 invoked by uid 99); 11 Feb 2015 08:33:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 08:33:15 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of todd.gao.2013@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 08:33:10 +0000
Received: by mail-ig0-f177.google.com with SMTP id z20so2910029igj.4
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 00:32:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:date:message-id:subject:from:to:content-type;
        bh=snfMVbILyc/DYblWqYcq0k7WL5ukcSK9Z55kFECgclo=;
        b=Zh3eOIFEcYfzpIXn1l+DwIgcaPR6cYjM5WkQuoXrNus1H5B1PCjdORrs88Bq5xukqQ
         /PUFS544XVC4q/z28DASxeuepWGGqfS5DqmFPOMKG1UzLOpM3xwsk7l6fcmXkVL0CN+C
         C4F4UoVAxa9X4Mg/w8ViyDFhHTEYJSEhFN9F4eilp/MB6b2Df4RlVJ+5t4f9MpgsdHc/
         ifPnZxO3ysSvI88UMZQJRTWEVYca2G8nvpaaPvoas8etgBeZNobvpxwVwDvKnlJP3MAA
         ZM4zfKuO02NMjlIHcPdjhJ01FWXsvb3WnETJV2dxH+Ee5HXx6keXGutKxrFn4Q6OhNgP
         AQPA==
MIME-Version: 1.0
X-Received: by 10.50.79.229 with SMTP id m5mr3186205igx.23.1423643569950; Wed,
 11 Feb 2015 00:32:49 -0800 (PST)
Sender: todd.gao.2013@gmail.com
Received: by 10.36.46.143 with HTTP; Wed, 11 Feb 2015 00:32:49 -0800 (PST)
Date: Wed, 11 Feb 2015 16:32:49 +0800
X-Google-Sender-Auth: EOKAw0kqDl5mXoHbgpuTyOFGT4Q
Message-ID: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
Subject: CallbackServer in PySpark Streaming
From: Todd Gao <todd.gao.2013+spark@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e0122a3fa461a7c050ecbd91b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a3fa461a7c050ecbd91b
Content-Type: text/plain; charset=UTF-8

Hi all,

I am reading the code of PySpark and its Streaming module.

In PySpark Streaming, when the `compute` method of the instance of
PythonTransformedDStream is invoked, a connection to the CallbackServer
is created internally.
I wonder where is the CallbackServer for each PythonTransformedDStream
instance on the slave nodes in distributed environment.
Is there a CallbackServer running on every slave node?

thanks
Todd

--089e0122a3fa461a7c050ecbd91b--

From dev-return-11579-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 11:30:50 2015
Return-Path: <dev-return-11579-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 00BB510A99
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 11:30:50 +0000 (UTC)
Received: (qmail 19440 invoked by uid 500); 11 Feb 2015 11:30:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19364 invoked by uid 500); 11 Feb 2015 11:30:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19350 invoked by uid 99); 11 Feb 2015 11:30:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 11:30:46 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_FONT_LOW_CONTRAST,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 11:30:22 +0000
Received: by mail-wg0-f48.google.com with SMTP id x12so2792896wgg.7
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 03:30:20 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:cc:content-type;
        bh=OoEk+wmV13SUXAXHQCiKQyIkfHySLbevBRu7Ix9rCMM=;
        b=xtMCUs9NHvucfvj+Iem0ZQeY2JIs+inxCpptFSHh3pjo+0OmiE5QWFegoGU6g+hTCl
         joW6G23aA6qltvfpa6hsNUmcwoIclvI1ieQlW4tCSqh8w4XpQ6SX/KjomcKwXr+S6NKu
         ReHW/BecIxnsYYWzFeW4VjL5lYf8qqACOj7OrYPD7csL8U4vQm2ToZIkNANJrJv8HUyy
         VBVDiWiQ7BFJbHsIEKyMhUcClRaiBfiKvTVCWKo5iialM5dTywkcknOmao06172nG0l1
         CSfnjGPSXROmw8xcMKZJHgS67FtP46gPqjUBsE4PXEhJbgc7NNU8ivAfJ2ilze1CBYEp
         0J7g==
MIME-Version: 1.0
X-Received: by 10.180.19.228 with SMTP id i4mr4812260wie.13.1423654219478;
 Wed, 11 Feb 2015 03:30:19 -0800 (PST)
Received: by 10.216.67.197 with HTTP; Wed, 11 Feb 2015 03:30:19 -0800 (PST)
Date: Wed, 11 Feb 2015 19:30:19 +0800
Message-ID: <CACdk1M5vYy-LY1YYORDCuQbQUDrecGeijR0n6AhwiVDOgJwiCg@mail.gmail.com>
Subject: [GraphX] Estimating Average distance of a big graph using GraphX
From: James <alcaid1801@gmail.com>
To: dev@spark.apache.org
Cc: Ankur Dave <ankurdave@gmail.com>
Content-Type: multipart/alternative; boundary=bcaec53d550708fcc2050ece54b9
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53d550708fcc2050ece54b9
Content-Type: text/plain; charset=UTF-8

Hello,

Recently  I am trying to estimate the average distance of a big graph using
spark with the help of [HyperAnf](http://dl.acm.org/citation.cfm?id=1963493
).

It works like Connect Componenet algorithm, while the attribute of a vertex
is a HyperLogLog counter that at k-th iteration it estimates the number of
vertices it could reaches less than k hops.

I have successfully run the code on a graph with 20M vertices. But I still
need help:


*I think the code could work more efficiently especially the "Send message"
function, but I am not sure about what will happen if a vertex receive no
message at a iteration.*

Here is my code: https://github.com/alcaid1801/Erdos

Any returns is appreciated.

--bcaec53d550708fcc2050ece54b9--

From dev-return-11580-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 18:39:45 2015
Return-Path: <dev-return-11580-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D972D17D30
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 18:39:44 +0000 (UTC)
Received: (qmail 77339 invoked by uid 500); 11 Feb 2015 18:39:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77215 invoked by uid 500); 11 Feb 2015 18:39:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77200 invoked by uid 99); 11 Feb 2015 18:39:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 18:39:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 18:39:15 +0000
Received: by labgf13 with SMTP id gf13so5266726lab.9
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 10:38:33 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=b9Qr6zRc7WeGayzTGf7RbgskQBhCdU2ALpkepYZxdrs=;
        b=VEhhtm9valmPUVKBey3kKi/yaX74fUGJ/UAxe0yjYGdDDcnckekKfmSfEWpouB4d9k
         EZQs+8yOuCvC0nPW0IQRylsj/BjQbXWZn+GYcYTiJE4x2lg7GVKRPRR+WBahZpozFgsX
         9RXHiK42taKpM8K1/k6su4vByKM8plugMLoYWCzKvEdhDZ8z8n7THCMkunb8S6T1eG1h
         mXVxE7tT3nhO4x5OlJ+zJKZiE+m8b6g8fa2E+CxV0EjPnkIJsonLvx5U1Px0+p5nfq1A
         n4sblHRcYDbetDiC2k8DSjQICPrfojFL79MBFIX2GuzRix1dfn9AlVtOTKpCt+g3wmD8
         FilA==
X-Gm-Message-State: ALoCoQkDTdRIMEToDvTfm3rFWBgoyjuEong6BjeLamPVNg1mqCscpz/OizbmWHthA2Zqh7x3iraZ
MIME-Version: 1.0
X-Received: by 10.152.23.73 with SMTP id k9mr3417laf.54.1423679913675; Wed, 11
 Feb 2015 10:38:33 -0800 (PST)
Received: by 10.25.166.136 with HTTP; Wed, 11 Feb 2015 10:38:33 -0800 (PST)
In-Reply-To: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
References: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
Date: Wed, 11 Feb 2015 10:38:33 -0800
Message-ID: <CA+2Pv=ht83tu4Y9v+i1r7LEii18Fkbi+fmBLF3iW1GLhJfzT=Q@mail.gmail.com>
Subject: Re: CallbackServer in PySpark Streaming
From: Davies Liu <davies@databricks.com>
To: Todd Gao <todd.gao.2013+spark@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

The CallbackServer is part of Py4j, it's only used in driver, not used
in slaves or workers.

On Wed, Feb 11, 2015 at 12:32 AM, Todd Gao
<todd.gao.2013+spark@gmail.com> wrote:
> Hi all,
>
> I am reading the code of PySpark and its Streaming module.
>
> In PySpark Streaming, when the `compute` method of the instance of
> PythonTransformedDStream is invoked, a connection to the CallbackServer
> is created internally.
> I wonder where is the CallbackServer for each PythonTransformedDStream
> instance on the slave nodes in distributed environment.
> Is there a CallbackServer running on every slave node?
>
> thanks
> Todd

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11581-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 18:47:32 2015
Return-Path: <dev-return-11581-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A106117D89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 18:47:32 +0000 (UTC)
Received: (qmail 11357 invoked by uid 500); 11 Feb 2015 18:47:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11275 invoked by uid 500); 11 Feb 2015 18:47:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11262 invoked by uid 99); 11 Feb 2015 18:47:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 18:47:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of aniket.bhatnagar@gmail.com designates 209.85.216.175 as permitted sender)
Received: from [209.85.216.175] (HELO mail-qc0-f175.google.com) (209.85.216.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 18:47:05 +0000
Received: by mail-qc0-f175.google.com with SMTP id c9so4585259qcz.6
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 10:47:04 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=Mz9yjoY+ZYKaaENuGzbViusTUP40WaACSKxzbkNVh1o=;
        b=XofAoAZ0dyXuQy3t2rof+6QtxbBoQUz2XjEQ2awCQSkysJdUh7hYMS+//jCUxWZF60
         hiMsF+Qgwtiy1UfbjL2W2eERvHoV2f4omT9zvbVl2z+JvJCY0OVa6+uUCUCqZFQjYw7E
         9YPe2FoKqlvpZAdtYGM/O3ani1eNDY3TfGi01sVfrmwHAdaERYLhzTSdJlC5uYN0Z42E
         U2qqd4dhASFPDOVOJMCAWm1OCQiMsTwsXUet8CyB4pkNKZViRm4RVKv948/+7/LVDn8Z
         hs6KC4KCBieQb07aGnEE66FJwtRAxlREd57Wq756NjL6B2rGmn3hZp+NVjjoMXKtZJhd
         PTPg==
X-Received: by 10.229.64.67 with SMTP id d3mr102924qci.9.1423680424018; Wed,
 11 Feb 2015 10:47:04 -0800 (PST)
MIME-Version: 1.0
References: <CAJOb8bsKtZJrEX0PkmEW+ghthFt1AZTrfhd1FvKogkGTBRUJww@mail.gmail.com>
From: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Date: Wed, 11 Feb 2015 18:47:03 +0000
Message-ID: <CAJOb8bvUtL+shu3Cf8X_wGh5eOCoBwPxJVb=t6LB55TUXV6M1g@mail.gmail.com>
Subject: Re: Data source API | sizeInBytes should be to *Scan
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2b526f28896050ed46d94
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2b526f28896050ed46d94
Content-Type: text/plain; charset=UTF-8

Circling back on this. Did you get a chance to re-look at this?

Thanks,
Aniket

On Sun, Feb 8, 2015, 2:53 AM Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
wrote:

> Thanks for looking into this. If this true, isn't this an issue today? The
> default implementation of sizeInBytes is 1 + broadcast threshold. So, if
> catalyst's cardinality estimation estimates even a small filter
> selectivity, it will result in broadcasting the relation. Therefore,
> shouldn't the default be much higher than broadcast threshold?
>
> Also, since the default implementation of sizeInBytes already exists in
> BaseRelation, I am not sure why the same/similar default implementation
> can't be provided with in *Scan specific sizeInBytes functions and have
> Catalyst always trust the size returned by DataSourceAPI (with default
> implementation being to never broadcast). Another thing that could be done
> is have sizeInBytes return Option[Long] so that Catalyst explicitly knows
> when DataSource was able to optimize the size. The reason why I would push
> for sizeInBytes in *Scan interfaces is because at times the data source
> implementation can more accurately predict the size output. For example,
> DataSource implementations for MongoDB, ElasticSearch, Cassandra, etc can
> easy use filter push downs to query the underlying storage to predict the
> size. Such predictions will be more accurate than Catalyst's prediction.
> Therefore, if its not a fundamental change in Catalyst, I would think this
> makes sense.
>
>
> Thanks,
> Aniket
>
>
> On Sat, Feb 7, 2015, 4:50 AM Reynold Xin <rxin@databricks.com> wrote:
>
>> We thought about this today after seeing this email. I actually built a
>> patch for this (adding filter/column to data source stat estimation), but
>> ultimately dropped it due to the potential problems the change the cause.
>>
>> The main problem I see is that column pruning/predicate pushdowns are
>> advisory, i.e. the data source might or might not apply those filters.
>>
>> Without significantly complicating the data source API, it is hard for
>> the optimizer (and future cardinality estimation) to know whether the
>> filter/column pushdowns are advisory, and whether to incorporate that in
>> cardinality estimation.
>>
>> Imagine this scenario: a data source applies a filter and estimates the
>> filter's selectivity is 0.1, then the data set is reduced to 10% of the
>> size. Catalyst's own cardinality estimation estimates the filter
>> selectivity to 0.1 again, and thus the estimated data size is now 1% of the
>> original data size, lowering than some threshold. Catalyst decides to
>> broadcast the table. The actual table size is actually 10x the size.
>>
>>
>>
>>
>>
>> On Fri, Feb 6, 2015 at 3:39 AM, Aniket Bhatnagar <
>> aniket.bhatnagar@gmail.com> wrote:
>>
>>> Hi Spark SQL committers
>>>
>>> I have started experimenting with data sources API and I was wondering if
>>> it makes sense to move the method sizeInBytes from BaseRelation to Scan
>>> interfaces. This is because that a relation may be able to leverage
>>> filter
>>> push down to estimate size potentially making a very large relation
>>> broadcast-able. Thoughts?
>>>
>>> Aniket
>>>
>>
>>

--001a11c2b526f28896050ed46d94--

From dev-return-11582-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 19:11:31 2015
Return-Path: <dev-return-11582-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7882517E9D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 19:11:31 +0000 (UTC)
Received: (qmail 22281 invoked by uid 500); 11 Feb 2015 19:11:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22205 invoked by uid 500); 11 Feb 2015 19:11:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22194 invoked by uid 99); 11 Feb 2015 19:11:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 19:11:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 19:11:04 +0000
Received: by mail-qa0-f51.google.com with SMTP id i13so4159691qae.10
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 11:09:12 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=aruWNGuxzaXPuip5uEVyrfi2HPreABdmQs0vrvKo1qU=;
        b=lcRA+8KzQYkaD4pFB1zGhMxFGRtFySgoWhGkPkIj21PfPd560qrEX5+/1MJRowO6Ad
         mwtvsSJhu/POsjhj48Kxd6PKDJpqrQXE0qzYrQRp5MXmos+OGZ75KiXTVJw5vin3Cp4x
         iixq7rnMCwbdv9YkXBKLTMmavPvkrtd4KKlJjZ3DoW4U9gi9THs98aAr+KiEhE3wLhZ1
         SA8NI0W8DpcVYVzVW4QG1sE1GdYSRvaDeQd962JUoWoqClZj4+Qlc4NmLhSkCTP7153P
         nyNh07b1SvqYTeIBU2SnZl96crzBxMeZsH5PzDhJwhgcbYScnmdqzwshwPuLIvbhhG7s
         fkHA==
X-Gm-Message-State: ALoCoQlSk9A3F7+Qf28IAPraei/rqQ9wnOutw11X1eSwFTPdgssm3E0/YLQiIwyrCVCu+9w1ltSQ
X-Received: by 10.224.43.10 with SMTP id u10mr391624qae.20.1423681752205; Wed,
 11 Feb 2015 11:09:12 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Wed, 11 Feb 2015 11:08:50 -0800 (PST)
In-Reply-To: <CAJOb8bvUtL+shu3Cf8X_wGh5eOCoBwPxJVb=t6LB55TUXV6M1g@mail.gmail.com>
References: <CAJOb8bsKtZJrEX0PkmEW+ghthFt1AZTrfhd1FvKogkGTBRUJww@mail.gmail.com>
 <CAJOb8bvUtL+shu3Cf8X_wGh5eOCoBwPxJVb=t6LB55TUXV6M1g@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 11 Feb 2015 11:08:50 -0800
Message-ID: <CAPh_B=a48zpuOO6QgHCwXEretu+7jvYcq0uRcxCsEjnnwFy3SA@mail.gmail.com>
Subject: Re: Data source API | sizeInBytes should be to *Scan
To: Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b8ca1d1fbd050ed4bd89
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b8ca1d1fbd050ed4bd89
Content-Type: text/plain; charset=UTF-8

Unfortunately this is not to happen for 1.3 (as a snapshot release is
already cut). We need to figure out how we are going to do cardinality
estimation before implementing this. If we need to do this in the future, I
think we can do it in a way that doesn't break existing APIs. Given I think
this won't bring much benefit right now (the only use for it is broadcast
joins), I think it is ok to push this till later.

The issue I asked still stands. What should the optimizer do w.r.t. filters
that are pushed into the data source? Should it ignore those filters, or
apply statistics again?

This also depends on how we want to do statistics. Hive (and a lot of other
database systems) does a scan to figure out statistics, and put all of
those statistics in a catalog. That is a more unified way to solve the
stats problem.

That said, in the world of federated databases, I can see why we might want
to push cardinality estimation to the data sources, since if the use case
is selecting a very small subset of the data from the sources, then it
might be hard for the statistics to be accurate in the catalog built from
data scan.



On Wed, Feb 11, 2015 at 10:47 AM, Aniket Bhatnagar <
aniket.bhatnagar@gmail.com> wrote:

> Circling back on this. Did you get a chance to re-look at this?
>
> Thanks,
> Aniket
>
> On Sun, Feb 8, 2015, 2:53 AM Aniket Bhatnagar <aniket.bhatnagar@gmail.com>
> wrote:
>
>> Thanks for looking into this. If this true, isn't this an issue today?
>> The default implementation of sizeInBytes is 1 + broadcast threshold. So,
>> if catalyst's cardinality estimation estimates even a small filter
>> selectivity, it will result in broadcasting the relation. Therefore,
>> shouldn't the default be much higher than broadcast threshold?
>>
>> Also, since the default implementation of sizeInBytes already exists in
>> BaseRelation, I am not sure why the same/similar default implementation
>> can't be provided with in *Scan specific sizeInBytes functions and have
>> Catalyst always trust the size returned by DataSourceAPI (with default
>> implementation being to never broadcast). Another thing that could be done
>> is have sizeInBytes return Option[Long] so that Catalyst explicitly knows
>> when DataSource was able to optimize the size. The reason why I would push
>> for sizeInBytes in *Scan interfaces is because at times the data source
>> implementation can more accurately predict the size output. For example,
>> DataSource implementations for MongoDB, ElasticSearch, Cassandra, etc can
>> easy use filter push downs to query the underlying storage to predict the
>> size. Such predictions will be more accurate than Catalyst's prediction.
>> Therefore, if its not a fundamental change in Catalyst, I would think this
>> makes sense.
>>
>>
>> Thanks,
>> Aniket
>>
>>
>> On Sat, Feb 7, 2015, 4:50 AM Reynold Xin <rxin@databricks.com> wrote:
>>
>>> We thought about this today after seeing this email. I actually built a
>>> patch for this (adding filter/column to data source stat estimation), but
>>> ultimately dropped it due to the potential problems the change the cause.
>>>
>>> The main problem I see is that column pruning/predicate pushdowns are
>>> advisory, i.e. the data source might or might not apply those filters.
>>>
>>> Without significantly complicating the data source API, it is hard for
>>> the optimizer (and future cardinality estimation) to know whether the
>>> filter/column pushdowns are advisory, and whether to incorporate that in
>>> cardinality estimation.
>>>
>>> Imagine this scenario: a data source applies a filter and estimates the
>>> filter's selectivity is 0.1, then the data set is reduced to 10% of the
>>> size. Catalyst's own cardinality estimation estimates the filter
>>> selectivity to 0.1 again, and thus the estimated data size is now 1% of the
>>> original data size, lowering than some threshold. Catalyst decides to
>>> broadcast the table. The actual table size is actually 10x the size.
>>>
>>>
>>>
>>>
>>>
>>> On Fri, Feb 6, 2015 at 3:39 AM, Aniket Bhatnagar <
>>> aniket.bhatnagar@gmail.com> wrote:
>>>
>>>> Hi Spark SQL committers
>>>>
>>>> I have started experimenting with data sources API and I was wondering
>>>> if
>>>> it makes sense to move the method sizeInBytes from BaseRelation to Scan
>>>> interfaces. This is because that a relation may be able to leverage
>>>> filter
>>>> push down to estimate size potentially making a very large relation
>>>> broadcast-able. Thoughts?
>>>>
>>>> Aniket
>>>>
>>>
>>>

--089e0158b8ca1d1fbd050ed4bd89--

From dev-return-11583-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 19:15:16 2015
Return-Path: <dev-return-11583-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 080F417ECC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 19:15:16 +0000 (UTC)
Received: (qmail 46790 invoked by uid 500); 11 Feb 2015 19:15:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46718 invoked by uid 500); 11 Feb 2015 19:15:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46704 invoked by uid 99); 11 Feb 2015 19:15:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 19:15:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of petro.rudenko@gmail.com designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 19:14:55 +0000
Received: by mail-lb0-f179.google.com with SMTP id w7so5144219lbi.10
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 11:13:04 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:from:to:message-id:date:user-agent:mime-version
         :content-type;
        bh=qHxwt7/fRPNCjNbBv81HgQW4KQaplOYDi54Qi8tKd+8=;
        b=vsWYGnrKCXAxFAx/i7ozu5VnklWLmqyCTLnEkKkGfgiATnG5vjGHVfvRHvgnqZXTVP
         qtulYd1DlaDCTyxQhPqOrPLH3o8D270AFAs55j0SWc/K0BFTQG56xbjIG1Q28sQjJY67
         LMb5V8BWBx7N3RF6JYSp7qqUdPVsegYd0k1YPawceSktA1si0VwABdUrAx5+LzfLjk5h
         Dlvh6dJ4mRMljPg39WXnB0abSaAxk5gXR9dJcAmkgqEcMsUOf3cz0goEU0PrY4PNWa1f
         5yIUf5UMIY22V50ugx9wfBC0fBH/884lKqcjgEqifsA9Ujw3lR6UXhlqguoX93QlfdbF
         V+oA==
X-Received: by 10.112.212.42 with SMTP id nh10mr83577lbc.102.1423681984287;
        Wed, 11 Feb 2015 11:13:04 -0800 (PST)
Received: from [192.168.1.4] ([5.248.107.224])
        by mx.google.com with ESMTPSA id fb5sm323497lbc.34.2015.02.11.11.13.02
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 11 Feb 2015 11:13:03 -0800 (PST)
Subject: [ml] Lost persistence for fold in crossvalidation.
From: Peter Rudenko <petro.rudenko@gmail.com>
To: dev@spark.apache.org
message-id: <54DBA9BF.5080508@gmail.com>
Date: Wed, 11 Feb 2015 21:13:03 +0200
user-agent:
 Mozilla/5.0 (X11; Linux x86_64; rv:37.0) Gecko/20100101 Thunderbird/37.0a2
mime-version: 1.0
Content-Type: multipart/alternative;
 boundary="------------040307040308010601020606"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------040307040308010601020606
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hi i have a problem. Using spark 1.2 with Pipeline + GridSearch + 
LogisticRegression. I’ve reimplemented LogisticRegression.fit method and 
comment out instances.unpersist()

|override  def  fit(dataset:SchemaRDD, paramMap:ParamMap):LogisticRegressionModel  = {
     println(s"Fitting dataset ${dataset.take(1000).toSeq.hashCode()} with ParamMap $paramMap.")
     transformSchema(dataset.schema, paramMap, logging =true)
     import  dataset.sqlContext._
     val  map  =  this.paramMap ++ paramMap
     val  instances  =  dataset.select(map(labelCol).attr, map(featuresCol).attr)
       .map {
         case  Row(label:Double, features:Vector) =>
           LabeledPoint(label, features)
       }

     if  (instances.getStorageLevel ==StorageLevel.NONE) {
       println("Instances not persisted")
       instances.persist(StorageLevel.MEMORY_AND_DISK)
     }

      val  lr  =  (new  LogisticRegressionWithLBFGS)
       .setValidateData(false)
       .setIntercept(true)
     lr.optimizer
       .setRegParam(map(regParam))
       .setNumIterations(map(maxIter))
     val  lrm  =  new  LogisticRegressionModel(this, map, lr.run(instances).weights)
     //instances.unpersist()
     // copy model params
     Params.inheritValues(map,this, lrm)
     lrm
   }
|

CrossValidator feeds the same SchemaRDD for each parameter (same hash 
code), but somewhere cache being flushed. The memory is enough. Here’s 
the output:

|Fitting dataset 2051470010 with ParamMap {
     DRLogisticRegression-f35ae4d3-regParam: 0.1
}.
Instances not persisted
Fitting dataset 2051470010 with ParamMap {
     DRLogisticRegression-f35ae4d3-regParam: 0.01
}.
Instances not persisted
Fitting dataset 2051470010 with ParamMap {
     DRLogisticRegression-f35ae4d3-regParam: 0.001
}.
Instances not persisted
Fitting dataset 802615223 with ParamMap {
     DRLogisticRegression-f35ae4d3-regParam: 0.1
}.
Instances not persisted
Fitting dataset 802615223 with ParamMap {
     DRLogisticRegression-f35ae4d3-regParam: 0.01
}.
Instances not persisted
|

I have 3 parameters in GridSearch and 3 folds for CrossValidation:

|
val  paramGrid  =  new  ParamGridBuilder()
   .addGrid(model.regParam,Array(0.1,0.01,0.001))
   .build()

crossval.setEstimatorParamMaps(paramGrid)
crossval.setNumFolds(3)
|

I assume that the data should be read and cached 3 times (1 to 
numFolds).combinations(2) and be independent from number of parameters. 
But i have 9 times data being read and cached.

Thanks,
Peter Rudenko

​

--------------040307040308010601020606--

From dev-return-11584-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 20:08:16 2015
Return-Path: <dev-return-11584-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4F3811020E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 20:08:16 +0000 (UTC)
Received: (qmail 72090 invoked by uid 500); 11 Feb 2015 20:08:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72022 invoked by uid 500); 11 Feb 2015 20:08:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71823 invoked by uid 99); 11 Feb 2015 20:08:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 20:08:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.171 as permitted sender)
Received: from [209.85.213.171] (HELO mail-ig0-f171.google.com) (209.85.213.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 20:08:10 +0000
Received: by mail-ig0-f171.google.com with SMTP id h15so33205785igd.4
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 12:07:49 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=xTjFLZs1RyBMpLDitwxgcHtbfjaiQ2fTnbvg4iD7B/o=;
        b=bYitMjn2QY73bpneorrU9i+FaegTZD8U2WE0DzqeuGuvyqcKtYcO7tot7iPjgTvx3D
         gnDi0LmRy6OdLVhHAg1vIL6Cz4PRvB4981DU72kN1fSUUNiNXFXSJdCRM6q9rAy++EoW
         QFGcgVw2Dv5WA5fUZq3DWSN4x1EJAJhJMJJUFTwCuvjjn9DVNwaSUedasv1rx5LMX8oz
         eUzNj4JovAPl279eU+22HUgyAMZhjWuCW9EUzaT04kdODozEZQnQy6LPLvm+QU2ht8sh
         sgWKqQd95zl8YHmLob1but8VAlZCHnUC6b9lOo5vOXLa2uLjI8wD34iZdIfEsfL0VqTG
         tuNg==
X-Received: by 10.43.54.4 with SMTP id vs4mr4859852icb.72.1423685269811; Wed,
 11 Feb 2015 12:07:49 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 20:07:48 +0000
Message-ID: <CAOhmDzfSuWqv197ZOcpmUuFTc2UgDvOJM_JX-skzuv1cmFmeWg@mail.gmail.com>
Subject: numpy on PyPy - potential benefit to PySpark
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51b1c19c77864050ed58e15
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51b1c19c77864050ed58e15
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Random question for the PySpark and Python experts/enthusiasts on here:

How big of a deal would it be for PySpark and PySpark users if you could
run numpy on PyPy?

PySpark already supports running on PyPy
<https://github.com/apache/spark/pull/2144>, but libraries like MLlib that
use numpy are not supported.

There is an ongoing initiative to support numpy on PyPy
<http://morepypy.blogspot.com/2015/02/numpypy-status-january-2015.html>,
and they are taking donations <http://pypy.org/numpydonate.html> to support
the effort.

I=E2=80=99m wondering if any companies using PySpark in production would be
interested in pushing this initiative along, or if it=E2=80=99s not that bi=
g of a
deal.

Nick
=E2=80=8B

--bcaec51b1c19c77864050ed58e15--

From dev-return-11585-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:28:00 2015
Return-Path: <dev-return-11585-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7E61510A1D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:28:00 +0000 (UTC)
Received: (qmail 42758 invoked by uid 500); 11 Feb 2015 22:27:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42677 invoked by uid 500); 11 Feb 2015 22:27:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42665 invoked by uid 99); 11 Feb 2015 22:27:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:27:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:27:31 +0000
Received: by mail-ig0-f172.google.com with SMTP id l13so33993006iga.5
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:27:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=1Ynl5W4IfSaZ21P/4dOZ7jij5Udxd1Q1lcLcvyiIX44=;
        b=R3QNFUek3ABO79AiaZwAaPjb9oDgzuufmhhUcPerGIcV/d9dgq5twbsqx87jNAXBXr
         qLz4sXCNrAkIHpO5xIWFWKxwftQkYubPOHj2jNWwcBqyo1GXX3KTB3PhnXQ4xZLuWg37
         OeZptUVqQYwRYg5Uy1WXiBgngwbz7ftE9OQhGs98Rnww+xGA7dXQMEWFogwupJYXOJgy
         wjCohUzbEIuV+p7aK3qIW8Y0VvIKjHmMBMYGK+i/8WRU//auWIQkj/iqBb1ynCWAwIDh
         6m1rFxbErveufSEQxtR3CWcq1NkHvS6MIhtCOXM3pG+UcF4TBLXmUJWvZh6DWfVxZt7R
         MypA==
X-Received: by 10.42.226.5 with SMTP id iu5mr5768320icb.0.1423693650091; Wed,
 11 Feb 2015 14:27:30 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 22:27:29 +0000
Message-ID: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
Subject: 1.2.1 start-all.sh broken?
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c30e9c4882ea050ed78294
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c30e9c4882ea050ed78294
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran sbin/start-all.sh
on my OS X.

Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/lib
You need to build Spark before running this program.

Did the same for 1.2.0 and it worked fine.

Nick
=E2=80=8B

--001a11c30e9c4882ea050ed78294--

From dev-return-11586-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:35:42 2015
Return-Path: <dev-return-11586-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EA0BA10A5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:35:41 +0000 (UTC)
Received: (qmail 58412 invoked by uid 500); 11 Feb 2015 22:35:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58334 invoked by uid 500); 11 Feb 2015 22:35:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58322 invoked by uid 99); 11 Feb 2015 22:35:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:35:39 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.54 as permitted sender)
Received: from [74.125.82.54] (HELO mail-wg0-f54.google.com) (74.125.82.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:35:15 +0000
Received: by mail-wg0-f54.google.com with SMTP id y19so6407678wgg.13
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:34:28 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=VeQkOr86rasyz8+cOFq3h1c0wnenwTt2bvgyoktYurU=;
        b=C4rYef8V2HB9MbMkqrSuuihQ3xvX9L7+kiL2fI7kKN6V1NOjV3fxGK6LCyv2y7JhIX
         Oz8vwQjSGkF8WvGi6keVw/vBUdDK591mngWJ9ovtPVCVTJclf3sOudp+alN91iHbuBfw
         v3PUx0hVcQ326UC/Z5B1vFKmQr5elCmmV/3QSS/HKg2P8LKPNQ0Yyz7HcnMLhThAbzAZ
         goNZrBn2bec38FcaFZwCGDMObo7EyVqTcPXRlPnxfgRyOKSeC/llT0ZKreD3aBXv599u
         szIstOXxmRr0qmN+tDIOxuJSA3jTbROOQBllLgKOy3h7KmXaD21jZzIFFFpxmWlAL69Z
         7jfA==
X-Gm-Message-State: ALoCoQlm76lqOkYjMElmf5GVoJv+yPEip9Qa7q38Hdra7kfGgh7YPuPTFQ97aoJLJDB1qjbkkQ7l
X-Received: by 10.180.74.141 with SMTP id t13mr242874wiv.45.1423694068731;
 Wed, 11 Feb 2015 14:34:28 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 11 Feb 2015 14:34:08 -0800 (PST)
In-Reply-To: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 11 Feb 2015 22:34:08 +0000
Message-ID: <CAMAsSdKOeU26XGcNNTtD7FHoPj0-3afHwV-wg+hvSZ-5-xmvew@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Seems to work OK for me on OS X. I ran ./sbin/start-all.sh from the
root. Both processes say they started successfully.

On Wed, Feb 11, 2015 at 10:27 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran sbin/start-all.sh
> on my OS X.
>
> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/lib
> You need to build Spark before running this program.
>
> Did the same for 1.2.0 and it worked fine.
>
> Nick
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11587-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:36:03 2015
Return-Path: <dev-return-11587-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7E15510A61
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:36:03 +0000 (UTC)
Received: (qmail 60161 invoked by uid 500); 11 Feb 2015 22:36:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60075 invoked by uid 500); 11 Feb 2015 22:36:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60058 invoked by uid 99); 11 Feb 2015 22:36:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:36:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:35:57 +0000
Received: by mail-ob0-f180.google.com with SMTP id vb8so6342121obc.11
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:34:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ZaGGjPuDMKkG1xfXrOzZahxUvIwQ34MpXZtTWVV7lWM=;
        b=b3qNmRGQIdC+oNtKNIDIQDcfP+RZmueUP6z9u7huZRILkxOz0XqRY/DfCSCbXcTCxa
         mC7SKaPqT+4du82zRB/IHbXQHbPJZzP+isRw/wONav/jz4nWfoY5ytgeDPw1wDG+p3IS
         A2hw5AyELea5kXQWcJGiHYOmGFyuQrJQscX9nk89JRkQ8kgV3KGUghWqOgnmlnPALRwo
         tKgB7mnuMdOfKQ3AzXILFW92EabrlulPwzh19TKuZr4865R03NY3M1v6852SWFOWhQF6
         Y8GhIVigkd8xckpDFryjQQI/F8LUcGVTkwEHl3rvX0yHEipJDgrqS2xYXnCOvDCYIhhz
         c33Q==
MIME-Version: 1.0
X-Received: by 10.202.201.71 with SMTP id z68mr635850oif.32.1423694091533;
 Wed, 11 Feb 2015 14:34:51 -0800 (PST)
Received: by 10.202.227.137 with HTTP; Wed, 11 Feb 2015 14:34:51 -0800 (PST)
In-Reply-To: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
Date: Wed, 11 Feb 2015 14:34:51 -0800
Message-ID: <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
From: Ted Yu <yuzhihong@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134e8d49845b4050ed79cfe
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134e8d49845b4050ed79cfe
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I downloaded 1.2.1 tar ball for hadoop 2.4
I got:

ls lib/
datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
spark-assembly-1.2.1-hadoop2.4.0.jar
datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
 spark-examples-1.2.1-hadoop2.4.0.jar

FYI

On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran sbin/start-all.=
sh
> on my OS X.
>
> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/lib
> You need to build Spark before running this program.
>
> Did the same for 1.2.0 and it worked fine.
>
> Nick
> =E2=80=8B
>

--001a1134e8d49845b4050ed79cfe--

From dev-return-11588-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:39:39 2015
Return-Path: <dev-return-11588-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5550010A80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:39:39 +0000 (UTC)
Received: (qmail 71704 invoked by uid 500); 11 Feb 2015 22:39:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71636 invoked by uid 500); 11 Feb 2015 22:39:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71624 invoked by uid 99); 11 Feb 2015 22:39:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:39:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:39:12 +0000
Received: by iecvy18 with SMTP id vy18so7740164iec.6
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:37:40 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=vHBBGHFSTIayIkyv0bcmPVIVp30/l5EgYJAhwYiIdaY=;
        b=0MNZBHSmwPSwmzmarsncpGfaoQdoY/9MUk2tVqfmNBgYkBmsWkHXEurj/Mo4e0of31
         uRSkvUL4+WBZZ6sfia27GLeNMT4YhbWgeCMPsRdoKFlfAflKgixBkkV+13S1dm3HCgt9
         7Gjj4MIOEZTXkDJ+iSIVFH60W16IPSrE1zpVMfEjphVwUndtQJ8C52NKVcu3vdRVtdMn
         6EP2SanUthmZW3hKqa6+96Xf7R3akKpQJ6jWB9PU03/fKBUz7/vBx1jwDaSQyD9GDGhZ
         H6uO2Fakv0+uVBUebijMzOXOlm8ZZFX8Kiy+gvPexrJlTnQ9ObVSykxl7CFIuTG+w5QK
         UOnw==
X-Received: by 10.107.161.75 with SMTP id k72mr1248302ioe.46.1423694260438;
 Wed, 11 Feb 2015 14:37:40 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
 <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 22:37:40 +0000
Message-ID: <CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Ted Yu <yuzhihong@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114100b0a98d34050ed7a66a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114100b0a98d34050ed7a66a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

This is what get:

spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
datanucleus-api-jdo-3.2.6.jar
datanucleus-core-3.2.10.jar
datanucleus-rdbms-3.2.9.jar
spark-1.2.1-yarn-shuffle.jar
spark-assembly-1.2.1-hadoop2.4.0.jar
spark-examples-1.2.1-hadoop2.4.0.jar

So that looks correct=E2=80=A6 Hmm.

Nick
=E2=80=8B

On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:

> I downloaded 1.2.1 tar ball for hadoop 2.4
> I got:
>
> ls lib/
> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
> spark-assembly-1.2.1-hadoop2.4.0.jar
> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>  spark-examples-1.2.1-hadoop2.4.0.jar
>
> FYI
>
> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>> sbin/start-all.sh
>> on my OS X.
>>
>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/lib
>> You need to build Spark before running this program.
>>
>> Did the same for 1.2.0 and it worked fine.
>>
>> Nick
>> =E2=80=8B
>>
>
>

--001a114100b0a98d34050ed7a66a--

From dev-return-11589-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:41:46 2015
Return-Path: <dev-return-11589-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0DB5310A8B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:41:46 +0000 (UTC)
Received: (qmail 81473 invoked by uid 500); 11 Feb 2015 22:41:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81398 invoked by uid 500); 11 Feb 2015 22:41:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81386 invoked by uid 99); 11 Feb 2015 22:41:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:41:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:41:39 +0000
Received: by iecrl12 with SMTP id rl12so5386796iec.4
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:41:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=BGiKawli2svW8FDcPRW+68whZT4GZUGxs8nzSweA424=;
        b=IF2tX8D76Ik6dEk98eYPiNZCVv4ZVGmeesJmDo+CkVKeieL0FhLc4V6aJ8H6/Ce7qk
         n76jjlVFa+PW8t/HEUhA6mefqU0fAGwRNsvEqN6RnmZE1UFMcyOko2UJ7yEKpvNiOolm
         hTbnOWwyQnJx6ORXkXHRvG1aXakJS64QQzsbapwkmmXi8ppY4iE0ZWIETX8KbHmAKuO7
         wUPKtkUr+CcZR6fJ3IxPO9FmOn+5esdEtmqSPFcAIOezmdWDn/Xw49AvQyKx3idis8IC
         PG2kY+aPM+b+Wj9eTlZHePgBwkKB4ANsQ1YLTtPLbd6IBNKXikHxLysKPlkMqBq7mEPq
         3uKw==
X-Received: by 10.50.66.243 with SMTP id i19mr329018igt.7.1423694479032; Wed,
 11 Feb 2015 14:41:19 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
 <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com> <CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 22:41:18 +0000
Message-ID: <CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Ted Yu <yuzhihong@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc11d6b118e7050ed7b321
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc11d6b118e7050ed7b321
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Found it:

https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-73058f8e51951e=
c0b4cb3d48ade91a1fR73

GRRR BASH WORD SPLITTING

My path has a space in it...

Nick

On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> This is what get:
>
> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
> datanucleus-api-jdo-3.2.6.jar
> datanucleus-core-3.2.10.jar
> datanucleus-rdbms-3.2.9.jar
> spark-1.2.1-yarn-shuffle.jar
> spark-assembly-1.2.1-hadoop2.4.0.jar
> spark-examples-1.2.1-hadoop2.4.0.jar
>
> So that looks correct=E2=80=A6 Hmm.
>
> Nick
> =E2=80=8B
>
> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>
>> I downloaded 1.2.1 tar ball for hadoop 2.4
>> I got:
>>
>> ls lib/
>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>> spark-assembly-1.2.1-hadoop2.4.0.jar
>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>
>> FYI
>>
>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>> sbin/start-all.sh
>>> on my OS X.
>>>
>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/lib
>>> You need to build Spark before running this program.
>>>
>>> Did the same for 1.2.0 and it worked fine.
>>>
>>> Nick
>>> =E2=80=8B
>>>
>>
>>

--047d7bdc11d6b118e7050ed7b321--

From dev-return-11590-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:45:51 2015
Return-Path: <dev-return-11590-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF8AB10AB7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:45:51 +0000 (UTC)
Received: (qmail 255 invoked by uid 500); 11 Feb 2015 22:45:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 179 invoked by uid 500); 11 Feb 2015 22:45:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 166 invoked by uid 99); 11 Feb 2015 22:45:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:45:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yuzhihong@gmail.com designates 209.85.218.50 as permitted sender)
Received: from [209.85.218.50] (HELO mail-oi0-f50.google.com) (209.85.218.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:45:25 +0000
Received: by mail-oi0-f50.google.com with SMTP id v1so89003oia.9
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:43:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=UN0hZLeyqxwRwUb/evZqbXkQBjmT/1GW7aarE3D9jMM=;
        b=GhVydXGu8Cn7yIMXh3dXEhDHMHbm6XKnW4Tg7f0DkkYPIc0YM4QfApsv09tA2p+DUa
         LXpTx+t3/hT+dw6l75h1ISIU3UGyu9c4gR7pk4mLmY0n6OE9pRlnatEXYTfHqah1zDzX
         hZ98YSx4n6g5aVSz7gCB0XAg/3eZA3TLXJQuOlTR7PfyzXu9811Il8s/sGKbqfsGYHJI
         +bG6Bxkew0LDT6QL6FpspeILd9RgBRhxB4CCedOeNua4uJ26b8sCKgJ1v6VHzG6eKe4D
         gruMoUHoekwBnr+hY+cPJBJJjfm+hH03PwXYq5cgiqPIdwx+ENl+l7fyl0rI6F8EbX5Y
         KunA==
MIME-Version: 1.0
X-Received: by 10.60.134.200 with SMTP id pm8mr624076oeb.61.1423694588839;
 Wed, 11 Feb 2015 14:43:08 -0800 (PST)
Received: by 10.202.227.137 with HTTP; Wed, 11 Feb 2015 14:43:08 -0800 (PST)
In-Reply-To: <CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
	<CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
	<CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
	<CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
Date: Wed, 11 Feb 2015 14:43:08 -0800
Message-ID: <CALte62z=cjTLG9Urw1MNoSZK3Fbk8nzK5h+dD4AHcM25nnXwRw@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
From: Ted Yu <yuzhihong@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b4178313c8f7b050ed7ba27
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b4178313c8f7b050ed7ba27
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I see.
'/path/to/spark-1.2.1-bin-hadoop2.4' didn't contain space :-)

On Wed, Feb 11, 2015 at 2:41 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Found it:
>
>
> https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-73058f8e5195=
1ec0b4cb3d48ade91a1fR73
>
> GRRR BASH WORD SPLITTING
>
> My path has a space in it...
>
> Nick
>
> On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> This is what get:
>>
>> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
>> datanucleus-api-jdo-3.2.6.jar
>> datanucleus-core-3.2.10.jar
>> datanucleus-rdbms-3.2.9.jar
>> spark-1.2.1-yarn-shuffle.jar
>> spark-assembly-1.2.1-hadoop2.4.0.jar
>> spark-examples-1.2.1-hadoop2.4.0.jar
>>
>> So that looks correct=E2=80=A6 Hmm.
>>
>> Nick
>> =E2=80=8B
>>
>> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>
>>> I downloaded 1.2.1 tar ball for hadoop 2.4
>>> I got:
>>>
>>> ls lib/
>>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>>
>>> FYI
>>>
>>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>>> sbin/start-all.sh
>>>> on my OS X.
>>>>
>>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoop2.4/li=
b
>>>> You need to build Spark before running this program.
>>>>
>>>> Did the same for 1.2.0 and it worked fine.
>>>>
>>>> Nick
>>>> =E2=80=8B
>>>>
>>>
>>>

--047d7b4178313c8f7b050ed7ba27--

From dev-return-11591-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:47:04 2015
Return-Path: <dev-return-11591-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D565310ABF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:47:04 +0000 (UTC)
Received: (qmail 3021 invoked by uid 500); 11 Feb 2015 22:47:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2948 invoked by uid 500); 11 Feb 2015 22:47:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2936 invoked by uid 99); 11 Feb 2015 22:47:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:47:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.181 as permitted sender)
Received: from [209.85.223.181] (HELO mail-ie0-f181.google.com) (209.85.223.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:46:37 +0000
Received: by iecar1 with SMTP id ar1so7858174iec.0
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:46:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=sp/Wb/hFeP5XetqSRLC/0ZI8WVxc6gC3yYeozx+32Ps=;
        b=zOYvnuptjhxl223Rnw4kfpPFWj1sLT7NsJX/mQt7loZbcUGxrm166HI2vJ+1yXqMsZ
         8j8rTT0WoowIJdcqqw8u4apwPy2tLcqWFLFR2wkFRgENT1ZRkahMnSbvh7qfgGQrwYKu
         XxCM9vg2z1BDDQr/HlWxdlQO0IbYXrrDO+AvWDx2TQA0PNpfPBZ1gcTFYNKbP6RoQ7Gh
         Fg2i1fOE+fV4LrIAsHAZDSsZTc/sya3h25kVbqVJpauEC/Pb8f6QFdpgNIRgk3kveUN6
         ouUN5vVZo0RGcr6jX93+yS3TQ370OviW5CKx/rHub8z9LqgQQbwH/TejF/heovyvY1w+
         yJCA==
X-Received: by 10.50.112.98 with SMTP id ip2mr344712igb.15.1423694795854; Wed,
 11 Feb 2015 14:46:35 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
 <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
 <CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
 <CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com> <CALte62z=cjTLG9Urw1MNoSZK3Fbk8nzK5h+dD4AHcM25nnXwRw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 22:46:35 +0000
Message-ID: <CAOhmDzcpmoGLdDe4DHhjc+YSdpECwDEjV0of0RBeUE=0FWkWvA@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Ted Yu <yuzhihong@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b414162935a7b050ed7c657
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b414162935a7b050ed7c657
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

lol yeah, I changed the path for the email... turned out to be the issue
itself.

On Wed Feb 11 2015 at 2:43:09 PM Ted Yu <yuzhihong@gmail.com> wrote:

> I see.
> '/path/to/spark-1.2.1-bin-hadoop2.4' didn't contain space :-)
>
> On Wed, Feb 11, 2015 at 2:41 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Found it:
>>
>>
>> https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-73058f8e519=
51ec0b4cb3d48ade91a1fR73
>>
>> GRRR BASH WORD SPLITTING
>>
>> My path has a space in it...
>>
>> Nick
>>
>> On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> This is what get:
>>>
>>> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
>>> datanucleus-api-jdo-3.2.6.jar
>>> datanucleus-core-3.2.10.jar
>>> datanucleus-rdbms-3.2.9.jar
>>> spark-1.2.1-yarn-shuffle.jar
>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>> spark-examples-1.2.1-hadoop2.4.0.jar
>>>
>>> So that looks correct=E2=80=A6 Hmm.
>>>
>>> Nick
>>> =E2=80=8B
>>>
>>> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>>> I downloaded 1.2.1 tar ball for hadoop 2.4
>>>> I got:
>>>>
>>>> ls lib/
>>>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>>>
>>>> FYI
>>>>
>>>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>>>> sbin/start-all.sh
>>>>> on my OS X.
>>>>>
>>>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-
>>>>> hadoop2.4/lib
>>>>> You need to build Spark before running this program.
>>>>>
>>>>> Did the same for 1.2.0 and it worked fine.
>>>>>
>>>>> Nick
>>>>> =E2=80=8B
>>>>>
>>>>
>>>>
>

--047d7b414162935a7b050ed7c657--

From dev-return-11592-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 22:49:07 2015
Return-Path: <dev-return-11592-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 98BC110AC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 22:49:07 +0000 (UTC)
Received: (qmail 6854 invoked by uid 500); 11 Feb 2015 22:49:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6777 invoked by uid 500); 11 Feb 2015 22:49:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6765 invoked by uid 99); 11 Feb 2015 22:49:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:49:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 22:49:01 +0000
Received: by mail-ig0-f172.google.com with SMTP id l13so73056iga.5
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 14:47:56 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=pe7CVSDqPWZYinA7fEu1O8Cf9BeMKRkaK0I/kE9DxUw=;
        b=I+QyFe5WCcB4QQhEBKEnHd6LDB6i5KqNxMqHL8RmiiOZ+NcwGP/nJazsgBlGm4UE4k
         gKVKZG4aufszFO/eRyYO8k7pxY7xwYq/f/ycP1YF5Uquqv7uUlyyb/dBXpu/A0x3ANWa
         fIb2IpMIu8HFpHjsoD2tCWQklIIHFOAhmBk9Kmf9f1Rjjrk8sAalicygPcjfKYBa0cWY
         KoCFO/6s7UTbgBTCZLgvA1wLZfnhqjY+E8bwe/pVVkp+/kCwbfp3T+U379q1u+O7jhfr
         yvNHdBXv8CgDsBOppGMaaJYGxvjwUkYNCUQ68sDFUSqs0K38ldn73Hgv64J8CXlx4Y9x
         2Uhg==
X-Received: by 10.43.54.4 with SMTP id vs4mr5532398icb.72.1423694876270; Wed,
 11 Feb 2015 14:47:56 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
 <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
 <CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
 <CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
 <CALte62z=cjTLG9Urw1MNoSZK3Fbk8nzK5h+dD4AHcM25nnXwRw@mail.gmail.com> <CAOhmDzcpmoGLdDe4DHhjc+YSdpECwDEjV0of0RBeUE=0FWkWvA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 22:47:55 +0000
Message-ID: <CAOhmDzdah+eoU2FmGh+A7hVN=-v5fs8fMJvBtKV=8UyFVikdrQ@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Ted Yu <yuzhihong@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51b1c195e6758050ed7cb27
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51b1c195e6758050ed7cb27
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

The tragic thing here is that I was asked to review the patch that
introduced this
<https://github.com/apache/spark/pull/3377#issuecomment-68077315>, and
totally missed it... :(

On Wed Feb 11 2015 at 2:46:35 PM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> lol yeah, I changed the path for the email... turned out to be the issue
> itself.
>
>
> On Wed Feb 11 2015 at 2:43:09 PM Ted Yu <yuzhihong@gmail.com> wrote:
>
>> I see.
>> '/path/to/spark-1.2.1-bin-hadoop2.4' didn't contain space :-)
>>
>> On Wed, Feb 11, 2015 at 2:41 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Found it:
>>>
>>> https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-
>>> 73058f8e51951ec0b4cb3d48ade91a1fR73
>>>
>>> GRRR BASH WORD SPLITTING
>>>
>>> My path has a space in it...
>>>
>>> Nick
>>>
>>> On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> This is what get:
>>>>
>>>> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
>>>> datanucleus-api-jdo-3.2.6.jar
>>>> datanucleus-core-3.2.10.jar
>>>> datanucleus-rdbms-3.2.9.jar
>>>> spark-1.2.1-yarn-shuffle.jar
>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>> spark-examples-1.2.1-hadoop2.4.0.jar
>>>>
>>>> So that looks correct=E2=80=A6 Hmm.
>>>>
>>>> Nick
>>>> =E2=80=8B
>>>>
>>>> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>>>
>>>>> I downloaded 1.2.1 tar ball for hadoop 2.4
>>>>> I got:
>>>>>
>>>>> ls lib/
>>>>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>>>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>>>>
>>>>> FYI
>>>>>
>>>>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>
>>>>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>>>>> sbin/start-all.sh
>>>>>> on my OS X.
>>>>>>
>>>>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoo
>>>>>> p2.4/lib
>>>>>> You need to build Spark before running this program.
>>>>>>
>>>>>> Did the same for 1.2.0 and it worked fine.
>>>>>>
>>>>>> Nick
>>>>>> =E2=80=8B
>>>>>>
>>>>>
>>>>>
>>

--bcaec51b1c195e6758050ed7cb27--

From dev-return-11593-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 23:08:23 2015
Return-Path: <dev-return-11593-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 16DFE10BE3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 23:08:23 +0000 (UTC)
Received: (qmail 74834 invoked by uid 500); 11 Feb 2015 23:08:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74763 invoked by uid 500); 11 Feb 2015 23:08:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74751 invoked by uid 99); 11 Feb 2015 23:08:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 23:08:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.48 as permitted sender)
Received: from [209.85.213.48] (HELO mail-yh0-f48.google.com) (209.85.213.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 23:08:11 +0000
Received: by mail-yh0-f48.google.com with SMTP id t59so2914178yho.7
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 15:07:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=JKgr3xGDxW/j7PrApT2hO6b7ZG1uJ00ePH2uRXaDQ/A=;
        b=BAFSAUNS5sHsqRC4J15Apro8L3m0J60U3yC3mB4qpK6b38vH3i9n9XqqeItCxWFT2a
         lfp4ZfkwX8qio3ZztQhiR1mZ3R1FgW29BQ5Se3jfr0NLitWqmHZFQB849xB30wOHrwrb
         U1dpPyZ58sK9fzMmXq9yd3kXD31uWa1jit9KqUrNFf9tz8web3Eo8zf2CRNUlfabVIk7
         Qkm4RNpLUgHLkys/u5qCcphw8hoMLH+yv/UhptWBnsVAQgwFYrOl/YnAaKV10jyZP9yM
         1r+8pmBdUwkxZ9ujoE0zpKKsN/GAUPCK5VHXLhTemJtfZ6ZJYdHhX59ddHzWRJvm8hKU
         v7ng==
MIME-Version: 1.0
X-Received: by 10.170.69.7 with SMTP id l7mr1033894ykl.114.1423696071380; Wed,
 11 Feb 2015 15:07:51 -0800 (PST)
Received: by 10.170.157.3 with HTTP; Wed, 11 Feb 2015 15:07:51 -0800 (PST)
In-Reply-To: <CAOhmDzdah+eoU2FmGh+A7hVN=-v5fs8fMJvBtKV=8UyFVikdrQ@mail.gmail.com>
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
	<CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
	<CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
	<CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
	<CALte62z=cjTLG9Urw1MNoSZK3Fbk8nzK5h+dD4AHcM25nnXwRw@mail.gmail.com>
	<CAOhmDzcpmoGLdDe4DHhjc+YSdpECwDEjV0of0RBeUE=0FWkWvA@mail.gmail.com>
	<CAOhmDzdah+eoU2FmGh+A7hVN=-v5fs8fMJvBtKV=8UyFVikdrQ@mail.gmail.com>
Date: Wed, 11 Feb 2015 15:07:51 -0800
Message-ID: <CALte62yNd9QMAUa=m=eKGgtZS_Uji0MKUWqD4fd-FUmPE0wsRg@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
From: Ted Yu <yuzhihong@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139d5529a546d050ed81252
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139d5529a546d050ed81252
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

After some googling / trial and error, I got the following working (against
a directory with space in its name):

#!/usr/bin/env bash
OLDIFS=3D"$IFS"  # save it
IFS=3D"" # don't split on any white space
dir=3D"$1/*"
for f in "$dir"; do
  cat $f
done
IFS=3D$OLDIFS # restore IFS

Cheers

On Wed, Feb 11, 2015 at 2:47 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> The tragic thing here is that I was asked to review the patch that
> introduced this
> <https://github.com/apache/spark/pull/3377#issuecomment-68077315>, and
> totally missed it... :(
>
> On Wed Feb 11 2015 at 2:46:35 PM Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> lol yeah, I changed the path for the email... turned out to be the issue
>> itself.
>>
>>
>> On Wed Feb 11 2015 at 2:43:09 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>
>>> I see.
>>> '/path/to/spark-1.2.1-bin-hadoop2.4' didn't contain space :-)
>>>
>>> On Wed, Feb 11, 2015 at 2:41 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> Found it:
>>>>
>>>> https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-
>>>> 73058f8e51951ec0b4cb3d48ade91a1fR73
>>>>
>>>> GRRR BASH WORD SPLITTING
>>>>
>>>> My path has a space in it...
>>>>
>>>> Nick
>>>>
>>>> On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> This is what get:
>>>>>
>>>>> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
>>>>> datanucleus-api-jdo-3.2.6.jar
>>>>> datanucleus-core-3.2.10.jar
>>>>> datanucleus-rdbms-3.2.9.jar
>>>>> spark-1.2.1-yarn-shuffle.jar
>>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>>> spark-examples-1.2.1-hadoop2.4.0.jar
>>>>>
>>>>> So that looks correct=E2=80=A6 Hmm.
>>>>>
>>>>> Nick
>>>>> =E2=80=8B
>>>>>
>>>>> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>>>>
>>>>>> I downloaded 1.2.1 tar ball for hadoop 2.4
>>>>>> I got:
>>>>>>
>>>>>> ls lib/
>>>>>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>>>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>>>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>>>>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>>>>>
>>>>>> FYI
>>>>>>
>>>>>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>
>>>>>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>>>>>> sbin/start-all.sh
>>>>>>> on my OS X.
>>>>>>>
>>>>>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoo
>>>>>>> p2.4/lib
>>>>>>> You need to build Spark before running this program.
>>>>>>>
>>>>>>> Did the same for 1.2.0 and it worked fine.
>>>>>>>
>>>>>>> Nick
>>>>>>> =E2=80=8B
>>>>>>>
>>>>>>
>>>>>>
>>>

--001a1139d5529a546d050ed81252--

From dev-return-11594-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 11 23:17:00 2015
Return-Path: <dev-return-11594-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2BDE810C79
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 11 Feb 2015 23:17:00 +0000 (UTC)
Received: (qmail 11949 invoked by uid 500); 11 Feb 2015 23:16:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11873 invoked by uid 500); 11 Feb 2015 23:16:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11861 invoked by uid 99); 11 Feb 2015 23:16:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 23:16:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.169 as permitted sender)
Received: from [209.85.223.169] (HELO mail-ie0-f169.google.com) (209.85.223.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 11 Feb 2015 23:16:33 +0000
Received: by iecrd18 with SMTP id rd18so7943164iec.5
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 15:15:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=DKSQCOZGaNJXDr77RIuhGApJ7HzXm+Bc9YVFoVLzJu4=;
        b=zb2pywMOJyS/eonHDjSXg5muEOIxQf6cC3iTLE6GVPPRNp9SPG6pIHpP/IxYV6Iy3j
         DXqQT+JS7eSA6bZHdD/+yZP7rapdZk7PPlNz0SRuJJbuQMaeZwHud1tmmzZdg74CuYcT
         BfPu4nxsoj9INsXhY4JLevEUjUaCkbhghrG4EhjarCdw6osnkGCTrpNnnFns6+1onIkD
         VZzA/WBEaNdN3+UvQm/MIeVePTpQsHjS9AqZD9QxtAhocUZAMLE64NWdF8WevSsSZ8Ks
         o20A0xVdz36njLeQM7wgFTccTz4+pRUHQjYRO3ghHtrb9QU4i28P2ltkXlXzfSVVgPvj
         UIHA==
X-Received: by 10.50.66.243 with SMTP id i19mr487712igt.7.1423696546398; Wed,
 11 Feb 2015 15:15:46 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzegkmdp2dMZh_iT8As9t=D-Pzi0nimfAkBtpms5S4YpFQ@mail.gmail.com>
 <CALte62zSQiN1T7h2sBB8j0PdkBhCTF8PZBP2L4BWzThQyL+cww@mail.gmail.com>
 <CAOhmDzfC5scgohhN=z0MJh2EwLDx3w_NRLL3Lb0C2hWRgE+Obw@mail.gmail.com>
 <CAOhmDzcqA56Zo9pgEY_URNt1YVsv0utZDRWj6KA_QWaqTx00ZQ@mail.gmail.com>
 <CALte62z=cjTLG9Urw1MNoSZK3Fbk8nzK5h+dD4AHcM25nnXwRw@mail.gmail.com>
 <CAOhmDzcpmoGLdDe4DHhjc+YSdpECwDEjV0of0RBeUE=0FWkWvA@mail.gmail.com>
 <CAOhmDzdah+eoU2FmGh+A7hVN=-v5fs8fMJvBtKV=8UyFVikdrQ@mail.gmail.com> <CALte62yNd9QMAUa=m=eKGgtZS_Uji0MKUWqD4fd-FUmPE0wsRg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 11 Feb 2015 23:15:46 +0000
Message-ID: <CAOhmDzc+sf5eu255iup6pAE3S3ozz+FE5mGSN188fodfzK7xUQ@mail.gmail.com>
Subject: Re: 1.2.1 start-all.sh broken?
To: Ted Yu <yuzhihong@gmail.com>
Cc: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc11d6eaa906050ed82ea6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc11d6eaa906050ed82ea6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

SPARK-5747 <https://issues.apache.org/jira/browse/SPARK-5747>: Review all
Bash scripts for word splitting bugs

I=E2=80=99ll file sub-tasks under this issue. Feel free to pitch in people!

Nick
=E2=80=8B

On Wed Feb 11 2015 at 3:07:51 PM Ted Yu <yuzhihong@gmail.com> wrote:

> After some googling / trial and error, I got the following working
> (against a directory with space in its name):
>
> #!/usr/bin/env bash
> OLDIFS=3D"$IFS"  # save it
> IFS=3D"" # don't split on any white space
> dir=3D"$1/*"
> for f in "$dir"; do
>   cat $f
> done
> IFS=3D$OLDIFS # restore IFS
>
> Cheers
>
> On Wed, Feb 11, 2015 at 2:47 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> The tragic thing here is that I was asked to review the patch that
>> introduced this
>> <https://github.com/apache/spark/pull/3377#issuecomment-68077315>, and
>> totally missed it... :(
>>
>> On Wed Feb 11 2015 at 2:46:35 PM Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> lol yeah, I changed the path for the email... turned out to be the issu=
e
>>> itself.
>>>
>>>
>>> On Wed Feb 11 2015 at 2:43:09 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>>> I see.
>>>> '/path/to/spark-1.2.1-bin-hadoop2.4' didn't contain space :-)
>>>>
>>>> On Wed, Feb 11, 2015 at 2:41 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> Found it:
>>>>>
>>>>> https://github.com/apache/spark/compare/v1.2.0...v1.2.1#diff-
>>>>> 73058f8e51951ec0b4cb3d48ade91a1fR73
>>>>>
>>>>> GRRR BASH WORD SPLITTING
>>>>>
>>>>> My path has a space in it...
>>>>>
>>>>> Nick
>>>>>
>>>>> On Wed Feb 11 2015 at 2:37:39 PM Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>
>>>>>> This is what get:
>>>>>>
>>>>>> spark-1.2.1-bin-hadoop2.4$ ls -1 lib/
>>>>>> datanucleus-api-jdo-3.2.6.jar
>>>>>> datanucleus-core-3.2.10.jar
>>>>>> datanucleus-rdbms-3.2.9.jar
>>>>>> spark-1.2.1-yarn-shuffle.jar
>>>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>>>> spark-examples-1.2.1-hadoop2.4.0.jar
>>>>>>
>>>>>> So that looks correct=E2=80=A6 Hmm.
>>>>>>
>>>>>> Nick
>>>>>> =E2=80=8B
>>>>>>
>>>>>> On Wed Feb 11 2015 at 2:34:51 PM Ted Yu <yuzhihong@gmail.com> wrote:
>>>>>>
>>>>>>> I downloaded 1.2.1 tar ball for hadoop 2.4
>>>>>>> I got:
>>>>>>>
>>>>>>> ls lib/
>>>>>>> datanucleus-api-jdo-3.2.6.jar  datanucleus-rdbms-3.2.9.jar
>>>>>>> spark-assembly-1.2.1-hadoop2.4.0.jar
>>>>>>> datanucleus-core-3.2.10.jar    spark-1.2.1-yarn-shuffle.jar
>>>>>>>  spark-examples-1.2.1-hadoop2.4.0.jar
>>>>>>>
>>>>>>> FYI
>>>>>>>
>>>>>>> On Wed, Feb 11, 2015 at 2:27 PM, Nicholas Chammas <
>>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>>
>>>>>>>> I just downloaded 1.2.1 pre-built for Hadoop 2.4+ and ran
>>>>>>>> sbin/start-all.sh
>>>>>>>> on my OS X.
>>>>>>>>
>>>>>>>> Failed to find Spark assembly in /path/to/spark-1.2.1-bin-hadoo
>>>>>>>> p2.4/lib
>>>>>>>> You need to build Spark before running this program.
>>>>>>>>
>>>>>>>> Did the same for 1.2.0 and it worked fine.
>>>>>>>>
>>>>>>>> Nick
>>>>>>>> =E2=80=8B
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>
>

--047d7bdc11d6eaa906050ed82ea6--

From dev-return-11595-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 01:45:48 2015
Return-Path: <dev-return-11595-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A6C6D17410
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 01:45:48 +0000 (UTC)
Received: (qmail 35564 invoked by uid 500); 12 Feb 2015 01:45:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35485 invoked by uid 500); 12 Feb 2015 01:45:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35471 invoked by uid 99); 12 Feb 2015 01:45:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 01:45:46 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of todd.gao.2013@gmail.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 01:45:42 +0000
Received: by mail-ig0-f170.google.com with SMTP id l13so460502iga.1
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 17:44:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=aTGT3IyAH75UnifC63dsY4cpte95Gcra+j8D96uvFM0=;
        b=xSyfXLeYBPZWHHXmQGEsUZ+FCxv99TBFLNKuDiRpIu13OiUnORyDnYiF18gIugRtiL
         m6DG8YsLBROk3By3Ot5lxPdbLZOgEYu8w9ko9t8PYrVhfnz2sbD8NCRdWy91XWK93L3L
         VBVeZZ5T/S8Q4sSfcJ2sVZBSr4Wx50eLhcRbLwQ/m/mibTyyJR0oPYKzn2eRPTEQdF91
         gmiFGTOuky85IU0XKjezYiKFP4MbsfuZpSkGAslTO/CThG7wDGSWDQVEC8e8aA5t2fhV
         ZH0P2LzGOlkAJzVgLWO5OhpuCEihvJBJn8c77qvEIys46wVa9mO7UgZDumBB05TLPxBo
         UtWw==
MIME-Version: 1.0
X-Received: by 10.50.66.170 with SMTP id g10mr1015609igt.49.1423705477114;
 Wed, 11 Feb 2015 17:44:37 -0800 (PST)
Sender: todd.gao.2013@gmail.com
Received: by 10.36.46.143 with HTTP; Wed, 11 Feb 2015 17:44:37 -0800 (PST)
In-Reply-To: <CA+2Pv=ht83tu4Y9v+i1r7LEii18Fkbi+fmBLF3iW1GLhJfzT=Q@mail.gmail.com>
References: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
	<CA+2Pv=ht83tu4Y9v+i1r7LEii18Fkbi+fmBLF3iW1GLhJfzT=Q@mail.gmail.com>
Date: Thu, 12 Feb 2015 09:44:37 +0800
X-Google-Sender-Auth: z9LLPC9YqY8TCnU35Fu-Auz_Yqc
Message-ID: <CACAP3TXmHe4FbYR6i=-UWkWH-MLdOzH45WaXnK9sFLKBSCKOGQ@mail.gmail.com>
Subject: Re: CallbackServer in PySpark Streaming
From: Todd Gao <todd.gao.2013+spark@gmail.com>
To: Davies Liu <davies@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc07ae3a6f29050eda43e4
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc07ae3a6f29050eda43e4
Content-Type: text/plain; charset=UTF-8

Thanks Davies.
I am not quite familiar with Spark Streaming. Do you mean that the compute
routine of DStream is only invoked in the driver node,
while only the compute routines of RDD are distributed to the slaves?

On Thu, Feb 12, 2015 at 2:38 AM, Davies Liu <davies@databricks.com> wrote:

> The CallbackServer is part of Py4j, it's only used in driver, not used
> in slaves or workers.
>
> On Wed, Feb 11, 2015 at 12:32 AM, Todd Gao
> <todd.gao.2013+spark@gmail.com> wrote:
> > Hi all,
> >
> > I am reading the code of PySpark and its Streaming module.
> >
> > In PySpark Streaming, when the `compute` method of the instance of
> > PythonTransformedDStream is invoked, a connection to the CallbackServer
> > is created internally.
> > I wonder where is the CallbackServer for each PythonTransformedDStream
> > instance on the slave nodes in distributed environment.
> > Is there a CallbackServer running on every slave node?
> >
> > thanks
> > Todd
>

--047d7bdc07ae3a6f29050eda43e4--

From dev-return-11596-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 01:51:34 2015
Return-Path: <dev-return-11596-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1BFFD1744B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 01:51:34 +0000 (UTC)
Received: (qmail 51367 invoked by uid 500); 12 Feb 2015 01:51:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51291 invoked by uid 500); 12 Feb 2015 01:51:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51280 invoked by uid 99); 12 Feb 2015 01:51:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 01:51:32 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 01:51:28 +0000
Received: by labgq15 with SMTP id gq15so7236356lab.6
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 17:50:01 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=aokPZ3v3e1U/qDsZIj0mZE5+Ua/k/qnz/W3kHG8M47g=;
        b=k/3fmw3/1fqfqKfmm8l77RYbhrUVyoXfTvDC2O7qPXM3BoKsvDzr6kBP6kSG1XU61B
         7w/ouv/tTaeFZLCAy4ICtaATnbNBXUGJiMF2f0tpN4j04c0INyipZsHoQY6x8MRHh1D+
         KZ21KCBIMV55ONgSG22yHH0JEuRki+5FhPdibvVASyaxQqonHmSAV0JmGBforLwwCbrt
         sPI5fkFWvYXcX74Q8q8XW1ko6ZnwUAsxydjZJ//oE0RiNFk2OyAPT7id7W36KcdCkmGM
         vpjxazl0ZlKSy/8uxW+6cMTGCE3FP0tW/yauTRsszjxSbTr6/4iH/VVP8w++xMb3vX/o
         5xiw==
X-Gm-Message-State: ALoCoQkvyG2qC00QqGjj4EjbECR2Q92K44oEigUzuZfZLax6ssuokpQAWk/axDCz7nBoMVlpVI7z
MIME-Version: 1.0
X-Received: by 10.112.148.34 with SMTP id tp2mr1212792lbb.94.1423705801145;
 Wed, 11 Feb 2015 17:50:01 -0800 (PST)
Received: by 10.25.166.136 with HTTP; Wed, 11 Feb 2015 17:50:01 -0800 (PST)
In-Reply-To: <CACAP3TXmHe4FbYR6i=-UWkWH-MLdOzH45WaXnK9sFLKBSCKOGQ@mail.gmail.com>
References: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
	<CA+2Pv=ht83tu4Y9v+i1r7LEii18Fkbi+fmBLF3iW1GLhJfzT=Q@mail.gmail.com>
	<CACAP3TXmHe4FbYR6i=-UWkWH-MLdOzH45WaXnK9sFLKBSCKOGQ@mail.gmail.com>
Date: Wed, 11 Feb 2015 17:50:01 -0800
Message-ID: <CA+2Pv=jDMsmm94wY6KMzRubMNXnu3obw-Jpz9-mQ9fqWwWXxTA@mail.gmail.com>
Subject: Re: CallbackServer in PySpark Streaming
From: Davies Liu <davies@databricks.com>
To: Todd Gao <todd.gao.2013+spark@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Yes.

On Wed, Feb 11, 2015 at 5:44 PM, Todd Gao <todd.gao.2013+spark@gmail.com> wrote:
> Thanks Davies.
> I am not quite familiar with Spark Streaming. Do you mean that the compute
> routine of DStream is only invoked in the driver node,
> while only the compute routines of RDD are distributed to the slaves?
>
> On Thu, Feb 12, 2015 at 2:38 AM, Davies Liu <davies@databricks.com> wrote:
>>
>> The CallbackServer is part of Py4j, it's only used in driver, not used
>> in slaves or workers.
>>
>> On Wed, Feb 11, 2015 at 12:32 AM, Todd Gao
>> <todd.gao.2013+spark@gmail.com> wrote:
>> > Hi all,
>> >
>> > I am reading the code of PySpark and its Streaming module.
>> >
>> > In PySpark Streaming, when the `compute` method of the instance of
>> > PythonTransformedDStream is invoked, a connection to the CallbackServer
>> > is created internally.
>> > I wonder where is the CallbackServer for each PythonTransformedDStream
>> > instance on the slave nodes in distributed environment.
>> > Is there a CallbackServer running on every slave node?
>> >
>> > thanks
>> > Todd
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11597-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 02:00:07 2015
Return-Path: <dev-return-11597-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4ACF01749B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 02:00:07 +0000 (UTC)
Received: (qmail 72700 invoked by uid 500); 12 Feb 2015 02:00:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72623 invoked by uid 500); 12 Feb 2015 02:00:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72611 invoked by uid 99); 12 Feb 2015 02:00:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 02:00:05 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of todd.gao.2013@gmail.com designates 209.85.213.169 as permitted sender)
Received: from [209.85.213.169] (HELO mail-ig0-f169.google.com) (209.85.213.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 01:59:39 +0000
Received: by mail-ig0-f169.google.com with SMTP id hl2so2577732igb.0
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 17:57:23 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=bWid5DyX3MKgddjmB3Qn/zfiuZ7OdQBvrStu/WjwyVg=;
        b=SSjMN0AmeyxUaUVr0FoJhZieH5PYw6YwGWBwQ7/Xtn9G4+2CuaBZfx0jx84aT71YMl
         +I7SoVXMKvsX3jnnz+MK3vpH4k0DOJ1HJ4KvtuzcPA4YiwdyVX5iKiYDqkFCp7EPU2Et
         01S9ewb4azfGWIo4N+uDlrNfXOUP4sC+DdLm0WOZNFPbLEX9E1nU+rg7j7VaCokRTmD5
         ZCeRGRdNg1g/P3Mb76YphDHt5FXRCdp1Ak1ZBvqXOCvxAVBlbtnFzsPrv2mlKdWm0/zK
         Vxy7BSAX98BU76QdSjPpoq/PtvzuBue6RIs6opnCFxUHFaxcfdBIa+hVIDaKbvyt/Mr8
         5LvA==
MIME-Version: 1.0
X-Received: by 10.50.66.170 with SMTP id g10mr1057375igt.49.1423706243212;
 Wed, 11 Feb 2015 17:57:23 -0800 (PST)
Sender: todd.gao.2013@gmail.com
Received: by 10.36.46.143 with HTTP; Wed, 11 Feb 2015 17:57:23 -0800 (PST)
In-Reply-To: <CA+2Pv=jDMsmm94wY6KMzRubMNXnu3obw-Jpz9-mQ9fqWwWXxTA@mail.gmail.com>
References: <CACAP3TWAWBdGgAyHKH+ei+C=vwB9gKMzDTruJn7Jf6vSi8yt5Q@mail.gmail.com>
	<CA+2Pv=ht83tu4Y9v+i1r7LEii18Fkbi+fmBLF3iW1GLhJfzT=Q@mail.gmail.com>
	<CACAP3TXmHe4FbYR6i=-UWkWH-MLdOzH45WaXnK9sFLKBSCKOGQ@mail.gmail.com>
	<CA+2Pv=jDMsmm94wY6KMzRubMNXnu3obw-Jpz9-mQ9fqWwWXxTA@mail.gmail.com>
Date: Thu, 12 Feb 2015 09:57:23 +0800
X-Google-Sender-Auth: 8cylox8xPgVSzBH0hC8r2M1L91Y
Message-ID: <CACAP3TXtTLLxyMjcuRBS7RsDrL084JmiDemOBfoathV+UKfbKA@mail.gmail.com>
Subject: Re: CallbackServer in PySpark Streaming
From: Todd Gao <todd.gao.2013+spark@gmail.com>
To: Davies Liu <davies@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bdc07aee42b36050eda70f2
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdc07aee42b36050eda70f2
Content-Type: text/plain; charset=UTF-8

Oh I see! Thank you very much, Davies. You correct some of my wrong
understandings.

On Thu, Feb 12, 2015 at 9:50 AM, Davies Liu <davies@databricks.com> wrote:

> Yes.
>
> On Wed, Feb 11, 2015 at 5:44 PM, Todd Gao <todd.gao.2013+spark@gmail.com>
> wrote:
> > Thanks Davies.
> > I am not quite familiar with Spark Streaming. Do you mean that the
> compute
> > routine of DStream is only invoked in the driver node,
> > while only the compute routines of RDD are distributed to the slaves?
> >
> > On Thu, Feb 12, 2015 at 2:38 AM, Davies Liu <davies@databricks.com>
> wrote:
> >>
> >> The CallbackServer is part of Py4j, it's only used in driver, not used
> >> in slaves or workers.
> >>
> >> On Wed, Feb 11, 2015 at 12:32 AM, Todd Gao
> >> <todd.gao.2013+spark@gmail.com> wrote:
> >> > Hi all,
> >> >
> >> > I am reading the code of PySpark and its Streaming module.
> >> >
> >> > In PySpark Streaming, when the `compute` method of the instance of
> >> > PythonTransformedDStream is invoked, a connection to the
> CallbackServer
> >> > is created internally.
> >> > I wonder where is the CallbackServer for each PythonTransformedDStream
> >> > instance on the slave nodes in distributed environment.
> >> > Is there a CallbackServer running on every slave node?
> >> >
> >> > thanks
> >> > Todd
> >
> >
>

--047d7bdc07aee42b36050eda70f2--

From dev-return-11598-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 03:35:14 2015
Return-Path: <dev-return-11598-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEEA717740
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 03:35:13 +0000 (UTC)
Received: (qmail 46550 invoked by uid 500); 12 Feb 2015 03:35:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46470 invoked by uid 500); 12 Feb 2015 03:35:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46457 invoked by uid 99); 12 Feb 2015 03:35:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 03:35:12 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 03:35:06 +0000
Received: by iecrp18 with SMTP id rp18so9011855iec.10
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 19:32:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=xf0y4GCbLYWDmLmZ6UJ1s7Hk5/xoHzDuulr3UKYMo70=;
        b=UyNmb1T7fXWQkQ9Nqkr/Kc5VHVbRxTRlENJMPgb3/uyXC97m0L44BbatLHyNPa8II+
         7FlF375o3WstO335SOIvhv8PvO2Q2Izd26eWAKzMFr/tgdtYOp8qat23nYqER6nGxEYz
         Vh6TF4Nc9saHHLlZuwS6IhZOOcOShgGlq6uuMzOrhYfQ6puKfaTHLMsN2qCb9lqRLVl/
         o4FuZx34gU98O8IQViAH80pQik8iTUJjqCVLkFCSkE3kMDAdwRYxTpQv7nPzufXXyVSG
         YAAmiim2CpxVGS73fYDGii6z4CMHaWFMleUpZWR6dUt4sloXtAHSRarCqoJaL24za7ll
         UpIw==
MIME-Version: 1.0
X-Received: by 10.107.133.36 with SMTP id h36mr2431245iod.40.1423711948422;
 Wed, 11 Feb 2015 19:32:28 -0800 (PST)
Received: by 10.36.55.5 with HTTP; Wed, 11 Feb 2015 19:32:28 -0800 (PST)
Date: Wed, 11 Feb 2015 19:32:28 -0800
Message-ID: <CABPQxsv5jP9svEWqWUvBsX991X1_zmihwZY7isEvXn-j9q4WPg@mail.gmail.com>
Subject: [ANNOUNCE] Spark 1.3.0 Snapshot 1
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

I've posted Spark 1.3.0 snapshot 1. At this point the 1.3 branch is
ready for community testing and we are strictly merging fixes and
documentation across all components.

The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-snapshot1/

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1068/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-snapshot1-docs/

Please report any issues with the release to this thread and/or to our
project JIRA. Thanks!

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11599-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 06:50:19 2015
Return-Path: <dev-return-11599-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6E55817D8C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 06:50:19 +0000 (UTC)
Received: (qmail 31658 invoked by uid 500); 12 Feb 2015 06:50:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31567 invoked by uid 500); 12 Feb 2015 06:50:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 64834 invoked by uid 99); 12 Feb 2015 05:37:50 -0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of fightfate@163.com designates 220.181.12.12 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:Mime-Version:Message-ID; bh=+jgoU
	z5PKMSINxJPB4PXxg/OISht+YxQIZ7sFKtAOm0=; b=lXhkvP8mHrCuOOWN0K/4M
	OIvbLGs1YjTKkbwzoVk0KXW+zlHb2DCBF7NdUYeamHkjy4aoDJathdm8MIemaNuf
	HjSco03yYbfZ+jE7mR62bLVv51m3wd+ZREmndpeILQ/iXH6j891nuWubvn37iCir
	Cv5JL2QzIggenKCNiQdd4M=
X-Coremail-DSSMTP: 221.226.67.42
Date: Thu, 12 Feb 2015 13:37:16 +0800
From: "fightfate@163.com" <fightfate@163.com>
To: user <user@spark.apache.org>, 
	dev <dev@spark.apache.org>
Subject: Re: Re: Sort Shuffle performance issues about using AppendOnlyMap for large data sets
References: <2015020617540850535545@163.com>, 
	<201502091156140505700@163.com>
X-Priority: 3
X-GUID: 6A9F8060-C3E6-4220-9A8C-D5948E3224C3
X-Has-Attach: no
X-Mailer: Foxmail 7, 2, 5, 140[cn]
Mime-Version: 1.0
Message-ID: <201502121337150451911@163.com>
Content-Type: multipart/alternative;
	boundary="----=_001_NextPart205816444074_=----"
X-CM-TRANSID:DMCowEDJ4lEPPNxUxDeXAw--.909S2
X-Coremail-Antispam: 1Uf129KBjvJXoW7uF4kGF15Kw47WF17Cr4kZwb_yoW8Zr48pF
	WkCa1vkw4rJrWSyw12y3y8Wr10vrW8A34YgF18GryUCFn8KF92vrWkKa1ruFWkW3s29r1U
	JayYvw1DAa1DZa7anT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU5nxnvy2
	9KBjDUYxBIdaVFxhVjvjDU0xZFpf9x07jbrcfUUUUU=
X-Originating-IP: [221.226.67.42]
X-CM-SenderInfo: hiljx3pidwvqqrwthudrp/xtbBEQCehFD+a0UtkAAAs2
X-Virus-Checked: Checked by ClamAV on apache.org

------=_001_NextPart205816444074_=----
Content-Type: text/plain;
	charset="ISO-8859-1"
Content-Transfer-Encoding: base64
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------=_001_NextPart205816444074_=------



From dev-return-11600-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 07:24:59 2015
Return-Path: <dev-return-11600-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 60F8317E94
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 07:24:59 +0000 (UTC)
Received: (qmail 89564 invoked by uid 500); 12 Feb 2015 07:24:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89459 invoked by uid 500); 12 Feb 2015 07:24:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89447 invoked by uid 99); 12 Feb 2015 07:24:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 07:24:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kurtt.lin@gmail.com designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 07:24:32 +0000
Received: by labhz20 with SMTP id hz20so8181076lab.0
        for <dev@spark.apache.org>; Wed, 11 Feb 2015 23:24:31 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=97qbZAUcNZsSevAhRSkup9N+pGO4WuUXlm8LhdbTBNU=;
        b=mhFjiAuChy23sWyKsxPs7lUM3D6h6PAh0vDq1w5kdt35lUSEqj88N+eWA95tp+Zqu4
         WavXCE9OWOY/cnjdn5jbAsZW7Su9fAspAWB4R/eOih1/1uzHLEXn2OrX/yXSwQ4zEhTc
         8vYIWJtuOA5eUrIkJS5+VG+fcjvAnACUiRNU91PQA//CInQJm+2N6eG2OjF81xiLAVdG
         1dbgtg+UIKUQKOES00cHmKwgmuHS5nLRrE6+bwNKfxM1r1aQ8NWXO1TmB4nBApg3wL5n
         aJtAIlWCFQ5vCMfjCvmnyYtOMPi1lf+KwVn61O4L8mldULcAe75vssb9A3i61sXZniE0
         GvUA==
MIME-Version: 1.0
X-Received: by 10.152.87.84 with SMTP id v20mr1912843laz.81.1423725871115;
 Wed, 11 Feb 2015 23:24:31 -0800 (PST)
Received: by 10.25.160.19 with HTTP; Wed, 11 Feb 2015 23:24:31 -0800 (PST)
Date: Thu, 12 Feb 2015 15:24:31 +0800
Message-ID: <CAMkjUhpDdivcTUfbH9_7qZC8FHoXdVW7_Ue_Ygybt9qOLXEdqw@mail.gmail.com>
Subject: driver fail-over in Spark streaming 1.2.0
From: lin <kurtt.lin@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3337ece35c7050edf025e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3337ece35c7050edf025e
Content-Type: text/plain; charset=UTF-8

Hi, all

In Spark Streaming 1.2.0, when the driver fails and a new driver starts
with the most updated check-pointed data, will the former Executors
connects to the new driver, or will the new driver starts out its own set
of new Executors? In which piece of codes is that done?

Any reply will be appreciated :)

regards,

lin

--001a11c3337ece35c7050edf025e--

From dev-return-11601-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:14:54 2015
Return-Path: <dev-return-11601-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A7C7E17FD1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:14:54 +0000 (UTC)
Received: (qmail 85982 invoked by uid 500); 12 Feb 2015 08:14:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85672 invoked by uid 500); 12 Feb 2015 08:14:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85099 invoked by uid 99); 12 Feb 2015 08:14:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:14:50 +0000
X-ASF-Spam-Status: No, hits=0.3 required=5.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:14:45 +0000
Received: by mail-oi0-f52.google.com with SMTP id u20so1884952oif.11;
        Thu, 12 Feb 2015 00:12:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=LQqTD6f6YxHi9P0fDUvG17amV0rtrzKSMJJN0p9psec=;
        b=AA8VuZyH7nxeFWefNhhdFKI77EImv4TXOdW32cDmMs4eBXSisPlnm99DASf3e5nhrt
         TfivFAKIi14IGiDamw/BQua17SdgJhDOF7r6NTFQNjQIbH0McVldxmwZPkJmHo7vF4OL
         vVL9QYlicbYx4V6ZOfDktiDnI5/7m8BL1bM/xKfMkvOsxXnY8kiNGG5xQO1duwPKDNox
         SjJvMo3qgDX99jg0TBNHM/UgQaAhzbV+GOOAAbvHNzWWW+zjdkUSLktXX+qYTooP5UgC
         qQD/aNh3R4OMLrDpYak1mptr9F04MSuOc0xLdZQ5WWmc8nZjuAlmZ5fpkBaB5NVC8dBU
         AcFQ==
MIME-Version: 1.0
X-Received: by 10.60.133.137 with SMTP id pc9mr1900225oeb.68.1423728775053;
 Thu, 12 Feb 2015 00:12:55 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Thu, 12 Feb 2015 00:12:54 -0800 (PST)
In-Reply-To: <201502121337150451911@163.com>
References: <2015020617540850535545@163.com>
	<201502091156140505700@163.com>
	<201502121337150451911@163.com>
Date: Thu, 12 Feb 2015 00:12:54 -0800
Message-ID: <CABPQxsv7bUAQ69siF_G1GTm+0JRKT6LgKcqwOSpjgsuVk0M2kQ@mail.gmail.com>
Subject: Re: Re: Sort Shuffle performance issues about using AppendOnlyMap for
 large data sets
From: Patrick Wendell <pwendell@gmail.com>
To: "fightfate@163.com" <fightfate@163.com>
Cc: user <user@spark.apache.org>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

The map will start with a capacity of 64, but will grow to accommodate
new data. Are you using the groupBy operator in Spark or are you using
Spark SQL's group by? This usually happens if you are grouping or
aggregating in a way that doesn't sufficiently condense the data
created from each input partition.

- Patrick

On Wed, Feb 11, 2015 at 9:37 PM, fightfate@163.com <fightfate@163.com> wrote:
> Hi,
>
> Really have no adequate solution got for this issue. Expecting any available
> analytical rules or hints.
>
> Thanks,
> Sun.
>
> ________________________________
> fightfate@163.com
>
>
> From: fightfate@163.com
> Date: 2015-02-09 11:56
> To: user; dev
> Subject: Re: Sort Shuffle performance issues about using AppendOnlyMap for
> large data sets
> Hi,
> Problem still exists. Any experts would take a look at this?
>
> Thanks,
> Sun.
>
> ________________________________
> fightfate@163.com
>
>
> From: fightfate@163.com
> Date: 2015-02-06 17:54
> To: user; dev
> Subject: Sort Shuffle performance issues about using AppendOnlyMap for large
> data sets
> Hi, all
> Recently we had caught performance issues when using spark 1.2.0 to read
> data from hbase and do some summary work.
> Our scenario means to : read large data sets from hbase (maybe 100G+ file) ,
> form hbaseRDD, transform to schemardd,
> groupby and aggregate the data while got fewer new summary data sets,
> loading data into hbase (phoenix).
>
> Our major issue lead to : aggregate large datasets to get summary data sets
> would consume too long time (1 hour +) , while that
> should be supposed not so bad performance. We got the dump file attached and
> stacktrace from jstack like the following:
>
> From the stacktrace and dump file we can identify that processing large
> datasets would cause frequent AppendOnlyMap growing, and
> leading to huge map entrysize. We had referenced the source code of
> org.apache.spark.util.collection.AppendOnlyMap and found that
> the map had been initialized with capacity of 64. That would be too small
> for our use case.
>
> So the question is : Does anyone had encounted such issues before? How did
> that be resolved? I cannot find any jira issues for such problems and
> if someone had seen, please kindly let us know.
>
> More specified solution would goes to : Does any possibility exists for user
> defining the map capacity releatively in spark? If so, please
> tell how to achieve that.
>
> Best Thanks,
> Sun.
>
>    Thread 22432: (state = IN_JAVA)
> - org.apache.spark.util.collection.AppendOnlyMap.growTable() @bci=87,
> line=224 (Compiled frame; information may be imprecise)
> - org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.growTable()
> @bci=1, line=38 (Interpreted frame)
> - org.apache.spark.util.collection.AppendOnlyMap.incrementSize() @bci=22,
> line=198 (Compiled frame)
> -
> org.apache.spark.util.collection.AppendOnlyMap.changeValue(java.lang.Object,
> scala.Function2) @bci=201, line=145 (Compiled frame)
> -
> org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(java.lang.Object,
> scala.Function2) @bci=3, line=32 (Compiled frame)
> -
> org.apache.spark.util.collection.ExternalSorter.insertAll(scala.collection.Iterator)
> @bci=141, line=205 (Compiled frame)
> -
> org.apache.spark.shuffle.sort.SortShuffleWriter.write(scala.collection.Iterator)
> @bci=74, line=58 (Interpreted frame)
> -
> org.apache.spark.scheduler.ShuffleMapTask.runTask(org.apache.spark.TaskContext)
> @bci=169, line=68 (Interpreted frame)
> -
> org.apache.spark.scheduler.ShuffleMapTask.runTask(org.apache.spark.TaskContext)
> @bci=2, line=41 (Interpreted frame)
> - org.apache.spark.scheduler.Task.run(long) @bci=77, line=56 (Interpreted
> frame)
> - org.apache.spark.executor.Executor$TaskRunner.run() @bci=310, line=196
> (Interpreted frame)
> -
> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker)
> @bci=95, line=1145 (Interpreted frame)
> - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615
> (Interpreted frame)
> - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>
>
> Thread 22431: (state = IN_JAVA)
> - org.apache.spark.util.collection.AppendOnlyMap.growTable() @bci=87,
> line=224 (Compiled frame; information may be imprecise)
> - org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.growTable()
> @bci=1, line=38 (Interpreted frame)
> - org.apache.spark.util.collection.AppendOnlyMap.incrementSize() @bci=22,
> line=198 (Compiled frame)
> -
> org.apache.spark.util.collection.AppendOnlyMap.changeValue(java.lang.Object,
> scala.Function2) @bci=201, line=145 (Compiled frame)
> -
> org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(java.lang.Object,
> scala.Function2) @bci=3, line=32 (Compiled frame)
> -
> org.apache.spark.util.collection.ExternalSorter.insertAll(scala.collection.Iterator)
> @bci=141, line=205 (Compiled frame)
> -
> org.apache.spark.shuffle.sort.SortShuffleWriter.write(scala.collection.Iterator)
> @bci=74, line=58 (Interpreted frame)
> -
> org.apache.spark.scheduler.ShuffleMapTask.runTask(org.apache.spark.TaskContext)
> @bci=169, line=68 (Interpreted frame)
> -
> org.apache.spark.scheduler.ShuffleMapTask.runTask(org.apache.spark.TaskContext)
> @bci=2, line=41 (Interpreted frame)
> - org.apache.spark.scheduler.Task.run(long) @bci=77, line=56 (Interpreted
> frame)
> - org.apache.spark.executor.Executor$TaskRunner.run() @bci=310, line=196
> (Interpreted frame)
> -
> java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker)
> @bci=95, line=1145 (Interpreted frame)
> - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615
> (Interpreted frame)
> - java.lang.Thread.run() @bci=11, line=744 (Interpreted frame)
>
>
> fightfate@163.com
> 1 attachments
> dump.png(42K) download preview

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11602-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:15:43 2015
Return-Path: <dev-return-11602-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2C2A117FD8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:15:43 +0000 (UTC)
Received: (qmail 92118 invoked by uid 500); 12 Feb 2015 08:15:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92028 invoked by uid 500); 12 Feb 2015 08:15:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92016 invoked by uid 99); 12 Feb 2015 08:15:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:15:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:15:16 +0000
Received: by mail-ob0-f172.google.com with SMTP id nt9so8487491obb.3
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 00:13:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=12rhVJDPs9F6OdPRTBu7MBOmJYHfVxnBw8EozGHL4H8=;
        b=YgLqUjXmXAOoKhT5bi3SlbEGPwZC3T7zMj1WBSOwnTVeGWLjWGYu3DAPmMVBRoitV8
         9CNYDve+YRV9t62PxMtOfIVibHRUQ+VKX0GTQps5snEBMcJyDQ92c6zv7et0EJWeeDFq
         BB0r3txMEx2oc0Bg2/iCijO1hsXUswFnQ/QmVd2NKsNalobREWL16Xn0V7/InOO8VXnM
         Pj1H0ZNfjSnL2mmAoqPVBtqdhARyeKrKg1gjwS+iby3syYYrKgrcEJ4gqGjkU2tH49dy
         uMEOtAQTi1SAsrzLXlogVtByp49HkTN5QTYxY+g3BdTzAXN0uNVJ215CWjD5R2aFkg21
         9hzQ==
MIME-Version: 1.0
X-Received: by 10.182.71.73 with SMTP id s9mr1884426obu.15.1423728824596; Thu,
 12 Feb 2015 00:13:44 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Thu, 12 Feb 2015 00:13:44 -0800 (PST)
In-Reply-To: <CAMkjUhpDdivcTUfbH9_7qZC8FHoXdVW7_Ue_Ygybt9qOLXEdqw@mail.gmail.com>
References: <CAMkjUhpDdivcTUfbH9_7qZC8FHoXdVW7_Ue_Ygybt9qOLXEdqw@mail.gmail.com>
Date: Thu, 12 Feb 2015 00:13:44 -0800
Message-ID: <CABPQxsupxdCCDNDzKgtaVU57M=t+Y6Vj1SF70UoZiqLKALsC_Q@mail.gmail.com>
Subject: Re: driver fail-over in Spark streaming 1.2.0
From: Patrick Wendell <pwendell@gmail.com>
To: lin <kurtt.lin@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

It will create and connect to new executors. The executors are mostly
stateless, so the program can resume with new executors.

On Wed, Feb 11, 2015 at 11:24 PM, lin <kurtt.lin@gmail.com> wrote:
> Hi, all
>
> In Spark Streaming 1.2.0, when the driver fails and a new driver starts
> with the most updated check-pointed data, will the former Executors
> connects to the new driver, or will the new driver starts out its own set
> of new Executors? In which piece of codes is that done?
>
> Any reply will be appreciated :)
>
> regards,
>
> lin

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11603-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:28:19 2015
Return-Path: <dev-return-11603-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 684DC1003A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:28:19 +0000 (UTC)
Received: (qmail 34272 invoked by uid 500); 12 Feb 2015 08:28:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34163 invoked by uid 500); 12 Feb 2015 08:28:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33735 invoked by uid 99); 12 Feb 2015 08:28:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:28:13 +0000
X-ASF-Spam-Status: No, hits=3.2 required=5.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of fightfate@163.com designates 220.181.12.15 as permitted sender)
Received: from [220.181.12.15] (HELO m12-15.163.com) (220.181.12.15)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:27:45 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:Mime-Version:Message-ID; bh=kqC9r
	Nn7sd6aFjyWdCaftjGyGjY3xm99kLAiQiU1vfE=; b=ofGlLAoUgaSNgUMpqAMz6
	bdsnZ4xV8BlN4sKazVpCz9TAzxEtMZEBSczQsgjT4yNz0+Qgl77iH6on9DTnUb4s
	Cv6YMNF3978tOnkyQZVOg6obyDvKuEVfGwYE8gRnZsH1Ih5R5qE0HNOVHxbgHiyy
	BVD6N2ALBtcq7YKInaXIS4=
Received: from Foxmail (unknown [221.226.67.42])
	by smtp11 (Coremail) with SMTP id D8CowEA5cUrIY9xUZIqLAw--.800S2;
	Thu, 12 Feb 2015 16:26:49 +0800 (CST)
X-Coremail-DSSMTP: 221.226.67.42
Date: Thu, 12 Feb 2015 16:26:45 +0800
From: "fightfate@163.com" <fightfate@163.com>
To: "Patrick Wendell" <pwendell@gmail.com>
Cc: user <user@spark.apache.org>, 
	dev <dev@spark.apache.org>
Subject: Re: Re: Sort Shuffle performance issues about using AppendOnlyMap for large data sets
References: <2015020617540850535545@163.com>, 
	<201502091156140505700@163.com>, 
	<201502121337150451911@163.com>, 
	<CABPQxsv7bUAQ69siF_G1GTm+0JRKT6LgKcqwOSpjgsuVk0M2kQ@mail.gmail.com>
X-Priority: 3
X-GUID: 8B7718E7-1FA1-45AE-9161-FC4D278F6C27
X-Has-Attach: no
X-Mailer: Foxmail 7, 2, 5, 140[cn]
Mime-Version: 1.0
Message-ID: <201502121626446941388@163.com>
Content-Type: multipart/alternative;
	boundary="----=_001_NextPart304878071580_=----"
X-CM-TRANSID:D8CowEA5cUrIY9xUZIqLAw--.800S2
X-Coremail-Antispam: 1Uf129KBjvJXoWxKr1rJFW3KF4xKryfXF4xJFb_yoWxuFy5pa
	1kJrn7uw15Xr4Yy34jv3y8XFyjvr4vv3y8KF1rWryUXFZ8WF12vFWktrs5Aa4kJwn7CrZI
	qw4j9w4jkw4UCFJanT9S1TB71UUUUUUqnTZGkaVYY2UrUUUUjbIjqfuFe4nvWSU5nxnvy2
	9KBjDUYxBIdaVFxhVjvjDU0xZFpf9x07UOyCXUUUUU=
X-Originating-IP: [221.226.67.42]
X-CM-SenderInfo: hiljx3pidwvqqrwthudrp/1tbiSgqehFO-rs+-SQAAsh
X-Virus-Checked: Checked by ClamAV on apache.org

------=_001_NextPart304878071580_=----
Content-Type: text/plain;
	charset="ISO-8859-1"
Content-Transfer-Encoding: base64
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------=_001_NextPart304878071580_=------



From dev-return-11604-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:43:51 2015
Return-Path: <dev-return-11604-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9566100AC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:43:51 +0000 (UTC)
Received: (qmail 62943 invoked by uid 500); 12 Feb 2015 08:43:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62865 invoked by uid 500); 12 Feb 2015 08:43:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62854 invoked by uid 99); 12 Feb 2015 08:43:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:43:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.169 as permitted sender)
Received: from [74.125.82.169] (HELO mail-we0-f169.google.com) (74.125.82.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:43:42 +0000
Received: by mail-we0-f169.google.com with SMTP id k48so8549282wev.0
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 00:42:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=wfLt/z9Sao2u7GCgiSzCa38OTmRYYLCsQbfEyGrI8GI=;
        b=ieSNCaZhFo7xMrbCayvcDrNVcNG062Q2c2R+QtZ7SHwWf3V7QK6qy9IVpXs9RInVFt
         RcvN6H+lXiskVYsXyu+Lm95Om3h+3W8Vb08ckSlXGJRKErJMkADI0r0opbKFG9o8HMow
         EKppBbaPequi8FgMCvbMl2TMrcPZxeHsEiOJjSe70REBfiZgIpcnD7YEfDXhuNXYO/XT
         XiKGyuNNxguWFwjvsxW0gn144Vo6KgJJCtARzc/jReilzd+nVXbIwNRzZlG7W3iCg28L
         Ku9kM90ClXhEdRKf/PYZklmwZV2znzxfmi0xvpP68YE+C/h6AlMOpWKGvAbLHUdUZZ+4
         x85A==
X-Gm-Message-State: ALoCoQlkkvOVQCQvErxYC93ufD1UIM0jsPe02gbifeAvTpwgd9A+vNMGa6xJilI7ZkXrZv1YuvlC
X-Received: by 10.180.90.177 with SMTP id bx17mr3918079wib.36.1423730552554;
 Thu, 12 Feb 2015 00:42:32 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Thu, 12 Feb 2015 00:42:12 -0800 (PST)
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 12 Feb 2015 08:42:12 +0000
Message-ID: <CAMAsSdJBY+YgnGD__q2QEAA-gi=VL_KHqvryxVBLJ1-Lg1pJ5g@mail.gmail.com>
Subject: How to track issues that must wait for Spark 2.x in JIRA?
To: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Patrick and I were chatting about how to handle several issues which
clearly need a fix, and are easy, but can't be implemented until a
next major release like Spark 2.x since it would change APIs.
Examples:

https://issues.apache.org/jira/browse/SPARK-3266
https://issues.apache.org/jira/browse/SPARK-3369
https://issues.apache.org/jira/browse/SPARK-4819

We could simply make version 2.0.0 in JIRA. Although straightforward,
it might imply that release planning has begun for 2.0.0.

The version could be called "2+" for now to better indicate its status.

There is also a "Later" JIRA resolution. Although resolving the above
seems a little wrong, it might be reasonable if we're sure to revisit
"Later", well, at some well defined later. The three issues above risk
getting lost in the shuffle.

We also wondered whether using "Later" is good or bad. It takes items
off the radar that aren't going to be acted on anytime soon -- and
there are lots of those right now. It might send a message that these
will be revisited when they are even less likely to if resolved.

Any opinions?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11605-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:48:57 2015
Return-Path: <dev-return-11605-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9733A100C8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:48:57 +0000 (UTC)
Received: (qmail 73428 invoked by uid 500); 12 Feb 2015 08:48:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73351 invoked by uid 500); 12 Feb 2015 08:48:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73339 invoked by uid 99); 12 Feb 2015 08:48:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:48:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.216.173] (HELO mail-qc0-f173.google.com) (209.85.216.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:48:17 +0000
Received: by mail-qc0-f173.google.com with SMTP id w7so7367617qcr.4
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 00:47:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=z+Sagh7tlmk/MUw5NyeB5IlISyTlj4Sf7Ps4gHbNIWc=;
        b=EsDuuLHj8uFE2gPz6d1I32IQXbwrRFvDi8yAyU70gd1hoNN3kjbpd1I1kNpKeMsLzM
         xAG6a3glHIe2a97Yriiz5jeCF6IkJhWwsLHMpzqaLUfDMW+4w2Jmk/hO1ftucu9wiRwt
         6aHOGVCgsAvU9itAWUU0vqXNek4s8wmKXjUdCz2f5COx9hdPPp5L1Ohd53i5pCgHQ2me
         Jh5MtM1ELEPd06r4/cdOEERkW2mbXnqXnURRtaNl6PUrOUJJAP78zwhhrP3OgSCF2qk/
         /iR8Dbdbjb8FXFAe2EU+PwVHnRiCUlPKDlNonx1SBqSkOhDguVqIqcz/JIhEZBGytkPk
         HuOg==
X-Gm-Message-State: ALoCoQkjQAN0e9MBLsX6T5P4Z61dGiST22Bh6/ol1EuH1bGzB4AV852IF3ll22FvoDwGyNL2pS1g
X-Received: by 10.140.89.41 with SMTP id u38mr7722613qgd.20.1423730856307;
 Thu, 12 Feb 2015 00:47:36 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Thu, 12 Feb 2015 00:47:16 -0800 (PST)
In-Reply-To: <CAMAsSdJBY+YgnGD__q2QEAA-gi=VL_KHqvryxVBLJ1-Lg1pJ5g@mail.gmail.com>
References: <CAMAsSdJBY+YgnGD__q2QEAA-gi=VL_KHqvryxVBLJ1-Lg1pJ5g@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Thu, 12 Feb 2015 00:47:16 -0800
Message-ID: <CAPh_B=Y2fv2EYN8Pb27W1YKDkdCM-DRrPEZagiDw80Cy21_tZQ@mail.gmail.com>
Subject: Re: How to track issues that must wait for Spark 2.x in JIRA?
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c135def24862050ee02b56
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c135def24862050ee02b56
Content-Type: text/plain; charset=UTF-8

It seems to me having a version that is 2+ is good for that? Once we move
to 2.0, we can retag those that are not going to be fixed in 2.0 as 2.0.1
or 2.1.0 .

On Thu, Feb 12, 2015 at 12:42 AM, Sean Owen <sowen@cloudera.com> wrote:

> Patrick and I were chatting about how to handle several issues which
> clearly need a fix, and are easy, but can't be implemented until a
> next major release like Spark 2.x since it would change APIs.
> Examples:
>
> https://issues.apache.org/jira/browse/SPARK-3266
> https://issues.apache.org/jira/browse/SPARK-3369
> https://issues.apache.org/jira/browse/SPARK-4819
>
> We could simply make version 2.0.0 in JIRA. Although straightforward,
> it might imply that release planning has begun for 2.0.0.
>
> The version could be called "2+" for now to better indicate its status.
>
> There is also a "Later" JIRA resolution. Although resolving the above
> seems a little wrong, it might be reasonable if we're sure to revisit
> "Later", well, at some well defined later. The three issues above risk
> getting lost in the shuffle.
>
> We also wondered whether using "Later" is good or bad. It takes items
> off the radar that aren't going to be acted on anytime soon -- and
> there are lots of those right now. It might send a message that these
> will be revisited when they are even less likely to if resolved.
>
> Any opinions?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c135def24862050ee02b56--

From dev-return-11606-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 08:55:28 2015
Return-Path: <dev-return-11606-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 416521010C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 08:55:28 +0000 (UTC)
Received: (qmail 92286 invoked by uid 500); 12 Feb 2015 08:55:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92210 invoked by uid 500); 12 Feb 2015 08:55:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92197 invoked by uid 99); 12 Feb 2015 08:55:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:55:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 08:54:56 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so8508227obc.5
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 00:54:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5agfNB5KdNX8oPtPsKdsUpQBdbNh52Rp/7t4YzTq/mE=;
        b=CxmwG7xzmT+vxl5WRk8J/ww4Oaf7+nuGrqbyY/FbrsN3S7La5U35TBbm9e2lqG7TXZ
         kjN6vrqF9H5CV7JdsieZaF7hFNk8HptAHN3rIXP0M7duWqeTAfMIBLLBReanDeujbnHq
         zPvQ/TS5yJUjcQSgCo3dBBNhs9L7tqnfhmAsxHOVh9bSXYpuvGpgnpEow+DlBpiMOIjo
         rcnzT04+52zU2VdRz7dsbYIcRT5lADY6S0TDBBmKsl9pwsmGZud8DLQz280uU2U2NfUi
         j0rmDa+ZbPsukOhfrEabhlqvrph8/luNsFk5qmXwXHnuk2dgRSAQccscEi19RW1DMGBY
         WVyw==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr1858955oit.100.1423731295055;
 Thu, 12 Feb 2015 00:54:55 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Thu, 12 Feb 2015 00:54:54 -0800 (PST)
In-Reply-To: <CAPh_B=Y2fv2EYN8Pb27W1YKDkdCM-DRrPEZagiDw80Cy21_tZQ@mail.gmail.com>
References: <CAMAsSdJBY+YgnGD__q2QEAA-gi=VL_KHqvryxVBLJ1-Lg1pJ5g@mail.gmail.com>
	<CAPh_B=Y2fv2EYN8Pb27W1YKDkdCM-DRrPEZagiDw80Cy21_tZQ@mail.gmail.com>
Date: Thu, 12 Feb 2015 00:54:54 -0800
Message-ID: <CABPQxsu+JbfkGnHE4XDwiGOXuyseXt6G3cdEyX1noQVu_dFz5A@mail.gmail.com>
Subject: Re: How to track issues that must wait for Spark 2.x in JIRA?
From: Patrick Wendell <pwendell@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Yeah my preferred is also having a more open ended "2+" for issues
that are clearly desirable but blocked by compatibility concerns.

What I would really want to avoid is major feature proposals sitting
around in our JIRA and tagged under some 2.X version. IMO JIRA isn't
the place for thoughts about very-long-term things. When we get these,
I'd be include to either close them as "won't fix" or "later".

On Thu, Feb 12, 2015 at 12:47 AM, Reynold Xin <rxin@databricks.com> wrote:
> It seems to me having a version that is 2+ is good for that? Once we move
> to 2.0, we can retag those that are not going to be fixed in 2.0 as 2.0.1
> or 2.1.0 .
>
> On Thu, Feb 12, 2015 at 12:42 AM, Sean Owen <sowen@cloudera.com> wrote:
>
>> Patrick and I were chatting about how to handle several issues which
>> clearly need a fix, and are easy, but can't be implemented until a
>> next major release like Spark 2.x since it would change APIs.
>> Examples:
>>
>> https://issues.apache.org/jira/browse/SPARK-3266
>> https://issues.apache.org/jira/browse/SPARK-3369
>> https://issues.apache.org/jira/browse/SPARK-4819
>>
>> We could simply make version 2.0.0 in JIRA. Although straightforward,
>> it might imply that release planning has begun for 2.0.0.
>>
>> The version could be called "2+" for now to better indicate its status.
>>
>> There is also a "Later" JIRA resolution. Although resolving the above
>> seems a little wrong, it might be reasonable if we're sure to revisit
>> "Later", well, at some well defined later. The three issues above risk
>> getting lost in the shuffle.
>>
>> We also wondered whether using "Later" is good or bad. It takes items
>> off the radar that aren't going to be acted on anytime soon -- and
>> there are lots of those right now. It might send a message that these
>> will be revisited when they are even less likely to if resolved.
>>
>> Any opinions?
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11607-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 10:54:56 2015
Return-Path: <dev-return-11607-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90C771073D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 10:54:56 +0000 (UTC)
Received: (qmail 62743 invoked by uid 500); 12 Feb 2015 10:54:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62656 invoked by uid 500); 12 Feb 2015 10:54:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62643 invoked by uid 99); 12 Feb 2015 10:54:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 10:54:49 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 10:54:45 +0000
Received: by mail-wg0-f48.google.com with SMTP id l18so6131599wgh.7
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 02:54:24 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=t2/dnZlQkvzX7LOesMTUBPEfR6P0KQBunDtMsVZn4L4=;
        b=Fkd51QFBmB5x2lQ3mEDhCFrqJ43FSUsDtYoMyQAYRKVNpd4DQa35zXxkdv4sfl1Vve
         56ScvJlW4h8chP9B8iUlnj689wCKsp8VcXQqAmyhZd8tqGtT6SaTq7HNkkthi2CALbsC
         Zn+9do5NDqEZOzblTQWb2u7O9M9Rx4wOVuvX3DkZh0NgAVaw+EjAMZuAZea26Ky1FEdV
         qex7y2VABcxweVWm+FrQY1ATEPZSd0Gw79sQ35g4ltvXu2bHd+1N2wbHFJJFpsqVpVjw
         VhCMQclzKtHlUCvoBOqEKmydx2aM5m0odB6gsqnJ2b8kMxPlweuBYjoFVXr2ZoiCVCwi
         jXkw==
X-Gm-Message-State: ALoCoQlPudfcRFwtVsrl0wZfmyhYFF6xIP/T56cOzDsAYzLGuGuE6RgY6kYqab2+4tX6pOCwHaB7
X-Received: by 10.194.58.141 with SMTP id r13mr6374137wjq.144.1423738464094;
 Thu, 12 Feb 2015 02:54:24 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Thu, 12 Feb 2015 02:54:03 -0800 (PST)
In-Reply-To: <CABPQxsu+JbfkGnHE4XDwiGOXuyseXt6G3cdEyX1noQVu_dFz5A@mail.gmail.com>
References: <CAMAsSdJBY+YgnGD__q2QEAA-gi=VL_KHqvryxVBLJ1-Lg1pJ5g@mail.gmail.com>
 <CAPh_B=Y2fv2EYN8Pb27W1YKDkdCM-DRrPEZagiDw80Cy21_tZQ@mail.gmail.com> <CABPQxsu+JbfkGnHE4XDwiGOXuyseXt6G3cdEyX1noQVu_dFz5A@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 12 Feb 2015 10:54:03 +0000
Message-ID: <CAMAsSdKUXzvY+wEtV-PXXOFX8_+pNp4Xxuj7iixTuzM4GYzpwg@mail.gmail.com>
Subject: Re: How to track issues that must wait for Spark 2.x in JIRA?
To: Patrick Wendell <pwendell@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Let me start with a version "2+" tag and at least write in the
description that it's only for issues that are clearly to be fixed,
but must wait until 2.x.

On Thu, Feb 12, 2015 at 8:54 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Yeah my preferred is also having a more open ended "2+" for issues
> that are clearly desirable but blocked by compatibility concerns.
>
> What I would really want to avoid is major feature proposals sitting
> around in our JIRA and tagged under some 2.X version. IMO JIRA isn't
> the place for thoughts about very-long-term things. When we get these,
> I'd be include to either close them as "won't fix" or "later".
>
> On Thu, Feb 12, 2015 at 12:47 AM, Reynold Xin <rxin@databricks.com> wrote:
>> It seems to me having a version that is 2+ is good for that? Once we move
>> to 2.0, we can retag those that are not going to be fixed in 2.0 as 2.0.1
>> or 2.1.0 .
>>
>> On Thu, Feb 12, 2015 at 12:42 AM, Sean Owen <sowen@cloudera.com> wrote:
>>
>>> Patrick and I were chatting about how to handle several issues which
>>> clearly need a fix, and are easy, but can't be implemented until a
>>> next major release like Spark 2.x since it would change APIs.
>>> Examples:
>>>
>>> https://issues.apache.org/jira/browse/SPARK-3266
>>> https://issues.apache.org/jira/browse/SPARK-3369
>>> https://issues.apache.org/jira/browse/SPARK-4819
>>>
>>> We could simply make version 2.0.0 in JIRA. Although straightforward,
>>> it might imply that release planning has begun for 2.0.0.
>>>
>>> The version could be called "2+" for now to better indicate its status.
>>>
>>> There is also a "Later" JIRA resolution. Although resolving the above
>>> seems a little wrong, it might be reasonable if we're sure to revisit
>>> "Later", well, at some well defined later. The three issues above risk
>>> getting lost in the shuffle.
>>>
>>> We also wondered whether using "Later" is good or bad. It takes items
>>> off the radar that aren't going to be acted on anytime soon -- and
>>> there are lots of those right now. It might send a message that these
>>> will be revisited when they are even less likely to if resolved.
>>>
>>> Any opinions?
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11608-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 14:27:16 2015
Return-Path: <dev-return-11608-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D091117676
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 14:27:16 +0000 (UTC)
Received: (qmail 27722 invoked by uid 500); 12 Feb 2015 14:27:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27642 invoked by uid 500); 12 Feb 2015 14:27:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27630 invoked by uid 99); 12 Feb 2015 14:27:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 14:27:15 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_FONT_LOW_CONTRAST,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.177 as permitted sender)
Received: from [74.125.82.177] (HELO mail-we0-f177.google.com) (74.125.82.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 14:27:11 +0000
Received: by mail-we0-f177.google.com with SMTP id m14so4558404wev.8
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 06:26:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=LPJPko+cEk2o3W5BQClmNHhgBQ9Q8y0EeMb8H+8RXAE=;
        b=GUeVuLFRyU8lAL8AYmIhG8S/3JyqkbHBz5Jq0VMStpHW7rA8PeooFfGnkM7y+ItzeC
         ezH6gYnhnTmj+SPgWM9zRq17AU9X4oqHv3k5nwHms1chvE2vtkdH8u46d6X30wu943If
         dGPkgYE7GWJ/uph6iA5addaij01UxtNgE0J2HkWrdMk7rzJ1k4x09UtEzgbE6pLVvyKw
         2H6x7Kwr4U2DCwqEs9wSYSEr7XUwO5k6CgYoh5/a5bdJfszFPS6Xb07zSzHJf+yMhuDG
         5CA4avF2KX7gOub6qgHsgawxL+usQCA1YPfyZ6ouSyT1ix7CRgq/yDREh4q0AXtJezcA
         i6JA==
MIME-Version: 1.0
X-Received: by 10.180.8.98 with SMTP id q2mr4081809wia.80.1423751210753; Thu,
 12 Feb 2015 06:26:50 -0800 (PST)
Received: by 10.216.67.197 with HTTP; Thu, 12 Feb 2015 06:26:50 -0800 (PST)
Date: Thu, 12 Feb 2015 22:26:50 +0800
Message-ID: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
Subject: Why a program would receive null from send message of mapReduceTriplets
From: James <alcaid1801@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=f46d04426e382a653d050ee4e9b9
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04426e382a653d050ee4e9b9
Content-Type: text/plain; charset=UTF-8

Hello,

When I am running the code on a much bigger size graph, I met
NullPointerException.

I found that is because the sendMessage() function receive a triplet that
edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen as I
am sure every vertices have a attr.

Any returns is appreciated.

Alcaid


2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:

> Hello,
>
> Recently  I am trying to estimate the average distance of a big graph
> using spark with the help of [HyperAnf](
> http://dl.acm.org/citation.cfm?id=1963493).
>
> It works like Connect Componenet algorithm, while the attribute of a
> vertex is a HyperLogLog counter that at k-th iteration it estimates the
> number of vertices it could reaches less than k hops.
>
> I have successfully run the code on a graph with 20M vertices. But I still
> need help:
>
>
> *I think the code could work more efficiently especially the "Send
> message" function, but I am not sure about what will happen if a vertex
> receive no message at a iteration.*
>
> Here is my code: https://github.com/alcaid1801/Erdos
>
> Any returns is appreciated.
>

--f46d04426e382a653d050ee4e9b9--

From dev-return-11609-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 16:56:40 2015
Return-Path: <dev-return-11609-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 990FA10051
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 16:56:40 +0000 (UTC)
Received: (qmail 62694 invoked by uid 500); 12 Feb 2015 16:56:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62623 invoked by uid 500); 12 Feb 2015 16:56:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62610 invoked by uid 99); 12 Feb 2015 16:56:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 16:56:39 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of vha14@msn.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 16:56:14 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 6FA8B13B127C
	for <dev@spark.apache.org>; Thu, 12 Feb 2015 08:56:14 -0800 (PST)
Date: Thu, 12 Feb 2015 09:56:12 -0700 (MST)
From: vha14 <vha14@msn.com>
To: dev@spark.apache.org
Message-ID: <1423760172365-10607.post@n3.nabble.com>
Subject: Spark SQL value proposition in batch pipelines
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

My team is building a batch data processing pipeline using Spark API and
trying to understand if Spark SQL can help us. Below are what we found so
far:

- SQL's declarative style may be more readable in some cases (e.g. joining
of more than two RDDs), although some devs prefer the fluent style
regardless. 
- Cogrouping of more than 4 RDDs is not supported and it's not clear if
Spark SQL supports joining of arbitrary number of RDDs.
- It seems that Spark SQL's features such as optimization based on predicate
pushdown and dynamic schema inference are less applicable in a batch
environment.

Your inputs/suggestions are most welcome!

Thanks,
Vu Ha
CTO, Semantic Scholar
http://www.quora.com/What-is-Semantic-Scholar-and-how-will-it-work



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-value-proposition-in-batch-pipelines-tp10607.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11610-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 17:31:26 2015
Return-Path: <dev-return-11610-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D76E510226
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 17:31:26 +0000 (UTC)
Received: (qmail 5235 invoked by uid 500); 12 Feb 2015 17:31:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5157 invoked by uid 500); 12 Feb 2015 17:31:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5145 invoked by uid 99); 12 Feb 2015 17:31:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 17:31:25 +0000
X-ASF-Spam-Status: No, hits=2.9 required=10.0
	tests=HTML_MESSAGE,JOIN_MILLIONS,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.173 as permitted sender)
Received: from [209.85.220.173] (HELO mail-vc0-f173.google.com) (209.85.220.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 17:31:21 +0000
Received: by mail-vc0-f173.google.com with SMTP id hy4so4222017vcb.4
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 09:30:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=0cu4yyMmbPl4osigAhcXEOSksTtrsJEfHK1yDHPbw/k=;
        b=b9+Mx/hKwnVSLndQKj6AbIc5OOYhUhdKPv75kpGIcbii7OwVKZC6CvTWHccaXUw6KE
         XB00uU0vstCWnjui7y1R6Va+dxmLn7Eg/DZeNYOsMZu/iydUvXZGE8us1NIgz3KuZnU9
         xZzkLXU/BNz5YMQTWaORS87IjKSShRhtb4rWZpCbJG9IW5pvc4jKmNI1FN8j4YuDxP0D
         cfoFWS3pJxi8MUtAa96h01IbILYzSPNlUxwKCkryS9BVQK7tcx6VkADmIbhQwxZSGh2f
         ktBnBsQlVSQ6hIT/+JvlgkJe4VklB7wNnScRGxbnMXKMeX1jzWMA+fwDYtml/P8H5HEI
         u1NQ==
X-Received: by 10.52.245.3 with SMTP id xk3mr2775406vdc.87.1423762215698; Thu,
 12 Feb 2015 09:30:15 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Thu, 12 Feb 2015 09:29:55 -0800 (PST)
In-Reply-To: <1423760172365-10607.post@n3.nabble.com>
References: <1423760172365-10607.post@n3.nabble.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Thu, 12 Feb 2015 09:29:55 -0800
Message-ID: <CABjXkq5gDXVyV4t-QwfK3eCcQ7bZuoUcz60Qcg+bPeHyDKWEig@mail.gmail.com>
Subject: Re: Spark SQL value proposition in batch pipelines
To: vha14 <vha14@msn.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2575a1c87b4050ee7796d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2575a1c87b4050ee7796d
Content-Type: text/plain; charset=UTF-8

Well, you can always join as many RDDs as you want by chaining them
together, e.g. a.join(b).join(c)... - I probably wouldn't join thousands of
RDDs in this way but 10 is probably doable.

That said - SparkSQL has an optimizer under the covers that can make clever
decisions e.g. pushing the predicates in the WHERE clause down to the base
data (even to external data sources if you have them), ordering joins, and
choosing between join implementations (like using broadcast joins instead
of the default shuffle-based hash join in RDD.join). These decisions can
make your queries run orders of magnitude faster than they would if you
implemented them using basic RDD transformations. The best part is at this
stage, I'd expect the optimizer will continue to improve - meaning many of
your queries will get faster with each new release.

I'm sure the SparkSQL devs can enumerate many other benefits - but as soon
as you're working with multiple tables and doing fairly textbook SQL stuff
- you likely want the engine figuring this stuff out for you rather than
hand coding it yourself. That said - with Spark, you can always drop back
to plain old RDDs and use map/reduce/filter/cogroup, etc. when you need to.

On Thu, Feb 12, 2015 at 8:56 AM, vha14 <vha14@msn.com> wrote:

> My team is building a batch data processing pipeline using Spark API and
> trying to understand if Spark SQL can help us. Below are what we found so
> far:
>
> - SQL's declarative style may be more readable in some cases (e.g. joining
> of more than two RDDs), although some devs prefer the fluent style
> regardless.
> - Cogrouping of more than 4 RDDs is not supported and it's not clear if
> Spark SQL supports joining of arbitrary number of RDDs.
> - It seems that Spark SQL's features such as optimization based on
> predicate
> pushdown and dynamic schema inference are less applicable in a batch
> environment.
>
> Your inputs/suggestions are most welcome!
>
> Thanks,
> Vu Ha
> CTO, Semantic Scholar
> http://www.quora.com/What-is-Semantic-Scholar-and-how-will-it-work
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-value-proposition-in-batch-pipelines-tp10607.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c2575a1c87b4050ee7796d--

From dev-return-11611-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 19:42:55 2015
Return-Path: <dev-return-11611-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 397D010949
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 19:42:55 +0000 (UTC)
Received: (qmail 50129 invoked by uid 500); 12 Feb 2015 19:42:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50048 invoked by uid 500); 12 Feb 2015 19:42:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50031 invoked by uid 99); 12 Feb 2015 19:42:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 19:42:54 +0000
X-ASF-Spam-Status: No, hits=2.9 required=10.0
	tests=HTML_MESSAGE,JOIN_MILLIONS,RCVD_IN_DNSWL_LOW,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.181] (HELO mail-qc0-f181.google.com) (209.85.216.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 19:42:29 +0000
Received: by mail-qc0-f181.google.com with SMTP id p6so10305153qcv.12
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 11:41:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=JSGKYJ0xsZU+9uJahxJZII0jRB8c6Y8iMDZ9YvZZLSE=;
        b=CCWWgzsla+ufNg1ENG5xrTHZqsTrxsbtHuMa9AI/tmEWnjITsM/n+koXYYiVUs9ZGC
         gf09B38NZh42sFwgqlNJJAjGhhTddRv280cXssVqAf9EMIwNzUd+0GRZxaH6+MkFCKbr
         hJcmXu/o9sSQSXEbhbROfvsxwosU/v/xA5tzlab151qCdOWOcYDSQbcnmaOXyTMVV+WT
         XckTUq1EvMGS9Uvk1ccHUcDIC3tzi9NARqr9EHpLMRexZsy96l873TLUR/v71B6lw5Rx
         wHeZpOZTA8lte+NYuIl9DxtNpGcff8LXGig0G1HIb1gBtr3yLrlF7zOScmsgc63s6HXh
         1aSA==
X-Gm-Message-State: ALoCoQlPiFZAeoW17ETpsPjkQ070xMHzFYZiWUqyY7dhivmbMvNmsOk8J4VCB2nUKXJWfRISTqvk
X-Received: by 10.140.146.87 with SMTP id 84mr519529qhs.12.1423770081587; Thu,
 12 Feb 2015 11:41:21 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Thu, 12 Feb 2015 11:41:01 -0800 (PST)
In-Reply-To: <CABjXkq5gDXVyV4t-QwfK3eCcQ7bZuoUcz60Qcg+bPeHyDKWEig@mail.gmail.com>
References: <1423760172365-10607.post@n3.nabble.com> <CABjXkq5gDXVyV4t-QwfK3eCcQ7bZuoUcz60Qcg+bPeHyDKWEig@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Thu, 12 Feb 2015 11:41:01 -0800
Message-ID: <CAPh_B=YCiR+guP87p-2txPCp3e5UzvDkVj3NMYouUgLS3hFf5g@mail.gmail.com>
Subject: Re: Spark SQL value proposition in batch pipelines
To: "Evan R. Sparks" <evan.sparks@gmail.com>
Cc: vha14 <vha14@msn.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113560c6f49f10050ee94dc9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113560c6f49f10050ee94dc9
Content-Type: text/plain; charset=UTF-8

Evan articulated it well.


On Thu, Feb 12, 2015 at 9:29 AM, Evan R. Sparks <evan.sparks@gmail.com>
wrote:

> Well, you can always join as many RDDs as you want by chaining them
> together, e.g. a.join(b).join(c)... - I probably wouldn't join thousands of
> RDDs in this way but 10 is probably doable.
>
> That said - SparkSQL has an optimizer under the covers that can make clever
> decisions e.g. pushing the predicates in the WHERE clause down to the base
> data (even to external data sources if you have them), ordering joins, and
> choosing between join implementations (like using broadcast joins instead
> of the default shuffle-based hash join in RDD.join). These decisions can
> make your queries run orders of magnitude faster than they would if you
> implemented them using basic RDD transformations. The best part is at this
> stage, I'd expect the optimizer will continue to improve - meaning many of
> your queries will get faster with each new release.
>
> I'm sure the SparkSQL devs can enumerate many other benefits - but as soon
> as you're working with multiple tables and doing fairly textbook SQL stuff
> - you likely want the engine figuring this stuff out for you rather than
> hand coding it yourself. That said - with Spark, you can always drop back
> to plain old RDDs and use map/reduce/filter/cogroup, etc. when you need to.
>
> On Thu, Feb 12, 2015 at 8:56 AM, vha14 <vha14@msn.com> wrote:
>
> > My team is building a batch data processing pipeline using Spark API and
> > trying to understand if Spark SQL can help us. Below are what we found so
> > far:
> >
> > - SQL's declarative style may be more readable in some cases (e.g.
> joining
> > of more than two RDDs), although some devs prefer the fluent style
> > regardless.
> > - Cogrouping of more than 4 RDDs is not supported and it's not clear if
> > Spark SQL supports joining of arbitrary number of RDDs.
> > - It seems that Spark SQL's features such as optimization based on
> > predicate
> > pushdown and dynamic schema inference are less applicable in a batch
> > environment.
> >
> > Your inputs/suggestions are most welcome!
> >
> > Thanks,
> > Vu Ha
> > CTO, Semantic Scholar
> > http://www.quora.com/What-is-Semantic-Scholar-and-how-will-it-work
> >
> >
> >
> > --
> > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-value-proposition-in-batch-pipelines-tp10607.html
> > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a113560c6f49f10050ee94dc9--

From dev-return-11612-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 22:29:58 2015
Return-Path: <dev-return-11612-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B881317406
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 22:29:58 +0000 (UTC)
Received: (qmail 25005 invoked by uid 500); 12 Feb 2015 22:29:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24928 invoked by uid 500); 12 Feb 2015 22:29:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24917 invoked by uid 99); 12 Feb 2015 22:29:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 22:29:57 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of vha14@msn.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 22:29:32 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id D23A513B9F5E
	for <dev@spark.apache.org>; Thu, 12 Feb 2015 14:29:31 -0800 (PST)
Date: Thu, 12 Feb 2015 15:29:29 -0700 (MST)
From: vha14 <vha14@msn.com>
To: dev@spark.apache.org
Message-ID: <1423780169596-10610.post@n3.nabble.com>
In-Reply-To: <CAPh_B=YCiR+guP87p-2txPCp3e5UzvDkVj3NMYouUgLS3hFf5g@mail.gmail.com>
References: <1423760172365-10607.post@n3.nabble.com> <CABjXkq5gDXVyV4t-QwfK3eCcQ7bZuoUcz60Qcg+bPeHyDKWEig@mail.gmail.com> <CAPh_B=YCiR+guP87p-2txPCp3e5UzvDkVj3NMYouUgLS3hFf5g@mail.gmail.com>
Subject: Re: Spark SQL value proposition in batch pipelines
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

This is super helpful, thanks Evan and Reynold!




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-value-proposition-in-batch-pipelines-tp10607p10610.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11613-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 22:53:56 2015
Return-Path: <dev-return-11613-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0925B17532
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 22:53:56 +0000 (UTC)
Received: (qmail 74911 invoked by uid 500); 12 Feb 2015 22:53:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74836 invoked by uid 500); 12 Feb 2015 22:53:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74825 invoked by uid 99); 12 Feb 2015 22:53:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 22:53:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 22:53:41 +0000
Received: by mail-qc0-f169.google.com with SMTP id m20so11076097qcx.0
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 14:52:59 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=lwXxul1J/aKHPv2ImAkw/dfaq2hAiPVhVFPnI1hyjTM=;
        b=QiDfLrD+SgcQ7/7ckADEWconal443t0Bd5n2Bl8f6lJaTcRu61Mw3vJ0ksBd3KoPrj
         ns3/HODh4MzgW5ENr4VSd+zBZFpXIAEZfB5yScrNnCH1SCzeKuFnpPtdAfiwWyv4DMLr
         dNEwupOfKdNfqCHr79z/CUaX6mZl0+kt/JnMzwkL8Nc3H/x1LgZeK7LUWwTJ7Wu5NThv
         AHhHts3sobarI6L2nDg233jY/gmqXa8B49bSxVKR5PA/KiSIjJh/ctCCLBsiB8lshaOH
         3NCO9UOr1j8jEr1sT3LXEidFBGMwf8SkeA0Xk6OPnYmF1wMHlqx08pD/r27SPVnIJ3E5
         Fo+w==
X-Gm-Message-State: ALoCoQlxsEvpSliNRmpAPTBncxE6FlI+ijfXKN/QPdeXUIvCzm6zQiK4J2uSa8Hm+Gu7a65muPEI
X-Received: by 10.140.146.87 with SMTP id 84mr852281qhs.12.1423781579598; Thu,
 12 Feb 2015 14:52:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Thu, 12 Feb 2015 14:52:39 -0800 (PST)
In-Reply-To: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
References: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Thu, 12 Feb 2015 14:52:39 -0800
Message-ID: <CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com>
Subject: Re: Why a program would receive null from send message of mapReduceTriplets
To: James <alcaid1801@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113560c64a692d050eebfb0d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113560c64a692d050eebfb0d
Content-Type: text/plain; charset=UTF-8

Can you use the new aggregateNeighbors method? I suspect the null is coming
from "automatic join elimination", which detects bytecode to see if you
need the src or dst vertex data. Occasionally it can fail to detect. In the
new aggregateNeighbors API, the caller needs to explicitly specifying that,
making it more robust.


On Thu, Feb 12, 2015 at 6:26 AM, James <alcaid1801@gmail.com> wrote:

> Hello,
>
> When I am running the code on a much bigger size graph, I met
> NullPointerException.
>
> I found that is because the sendMessage() function receive a triplet that
> edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen as I
> am sure every vertices have a attr.
>
> Any returns is appreciated.
>
> Alcaid
>
>
> 2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:
>
> > Hello,
> >
> > Recently  I am trying to estimate the average distance of a big graph
> > using spark with the help of [HyperAnf](
> > http://dl.acm.org/citation.cfm?id=1963493).
> >
> > It works like Connect Componenet algorithm, while the attribute of a
> > vertex is a HyperLogLog counter that at k-th iteration it estimates the
> > number of vertices it could reaches less than k hops.
> >
> > I have successfully run the code on a graph with 20M vertices. But I
> still
> > need help:
> >
> >
> > *I think the code could work more efficiently especially the "Send
> > message" function, but I am not sure about what will happen if a vertex
> > receive no message at a iteration.*
> >
> > Here is my code: https://github.com/alcaid1801/Erdos
> >
> > Any returns is appreciated.
> >
>

--001a113560c64a692d050eebfb0d--

From dev-return-11614-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 12 23:55:20 2015
Return-Path: <dev-return-11614-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DE2D91781A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 12 Feb 2015 23:55:19 +0000 (UTC)
Received: (qmail 61279 invoked by uid 500); 12 Feb 2015 23:55:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61202 invoked by uid 500); 12 Feb 2015 23:55:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61191 invoked by uid 99); 12 Feb 2015 23:55:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 23:55:18 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of vha14@msn.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 12 Feb 2015 23:55:13 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 10F5A13BB561
	for <dev@spark.apache.org>; Thu, 12 Feb 2015 15:53:25 -0800 (PST)
Date: Thu, 12 Feb 2015 16:53:22 -0700 (MST)
From: vha14 <vha14@msn.com>
To: dev@spark.apache.org
Message-ID: <1423785202766-10612.post@n3.nabble.com>
In-Reply-To: <CAPh_B=Z5Wefghcne7kiovpxobXnStJ=40hNTkS+WSz6s0xhyFw@mail.gmail.com>
References: <CAPh_B=YtiASt6Cue+9dEFHCuTv7HnVx3i9BjTaCEPRx82QoTPA@mail.gmail.com> <CABjXkq6f+5L507810fE51Y9v0UsAqSYMVCih0agSw2epiJ-ijA@mail.gmail.com> <CAN6Vra1Pr9ouShTMzp8fmDfaK_E51=gAkxhnGhdC1GpJDYO54w@mail.gmail.com> <CANx3uAjOvdKeUx1cuadSW3vy77=1juykbQRGbVbDt36hjif+vg@mail.gmail.com> <54CAAD2D.8030407@gmail.com> <CAN6Vra3+GCzvXXxrAenurmsOjBV4HA2g9jCTMj=fT6XF=gXR0Q@mail.gmail.com> <CANx3uAjyZ1igCQ-dYQ55BnyV5nNwR3ivYYd5bqEnYqKr4AXJAg@mail.gmail.com> <CAPh_B=ZaHB2iWtx0sBGMuAJQde7cTaB=fR7Wm9S4bTCLfygqYQ@mail.gmail.com> <CANx3uAgMOWYEt7sWibsxB59jBG4ai3z5zOdFavctgKVf3OXF2w@mail.gmail.com> <CAPh_B=Z5Wefghcne7kiovpxobXnStJ=40hNTkS+WSz6s0xhyFw@mail.gmail.com>
Subject: Re: renaming SchemaRDD -> DataFrame
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Matei wrote (Jan 26, 2015; 5:31pm): "The intent of Spark SQL though is to be
more than a SQL server -- it's meant to be a library for manipulating
structured data."

I think this is an important but nuanced point. There are engineers who for
various reasons associate the term "SQL" with business analyst,
non-engineering scenarios. If Matei or someone from the Spark team could
clarify this misunderstanding with respect to the potential of Spark SQL, it
would be very useful. (Potential places: Quora, StackOverflow,
Databricks.com's blog.) 

Thanks,
Vu Ha 
CTO, Semantic Scholar
http://www.quora.com/What-is-Semantic-Scholar-and-how-will-it-work



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/renaming-SchemaRDD-DataFrame-tp10271p10612.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11615-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 00:21:51 2015
Return-Path: <dev-return-11615-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 800171791E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 00:21:51 +0000 (UTC)
Received: (qmail 17868 invoked by uid 500); 13 Feb 2015 00:21:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17790 invoked by uid 500); 13 Feb 2015 00:21:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17778 invoked by uid 99); 13 Feb 2015 00:21:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 00:21:44 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.55] (HELO g4t3427.houston.hp.com) (15.201.208.55)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 00:21:39 +0000
Received: from G9W0364.americas.hpqcorp.net (g9w0364.houston.hp.com [16.216.193.45])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3427.houston.hp.com (Postfix) with ESMTPS id 64D7CBC;
	Fri, 13 Feb 2015 00:19:48 +0000 (UTC)
Received: from G4W6300.americas.hpqcorp.net (16.210.26.225) by
 G9W0364.americas.hpqcorp.net (16.216.193.45) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Fri, 13 Feb 2015 00:18:02 +0000
Received: from G4W3292.americas.hpqcorp.net ([169.254.1.188]) by
 G4W6300.americas.hpqcorp.net ([16.210.26.225]) with mapi id 14.03.0169.001;
 Fri, 13 Feb 2015 00:18:02 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
CC: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0AAAKwxgACUAsfwAAMhugAAKb0RoABpRQ1w
Date: Fri, 13 Feb 2015 00:18:01 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
 <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-11616-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 06:58:31 2015
Return-Path: <dev-return-11616-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8C664102F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 06:58:31 +0000 (UTC)
Received: (qmail 86445 invoked by uid 500); 13 Feb 2015 06:54:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85535 invoked by uid 500); 13 Feb 2015 06:54:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83825 invoked by uid 99); 13 Feb 2015 06:52:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 06:52:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.174] (HELO mail-qc0-f174.google.com) (209.85.216.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 06:51:41 +0000
Received: by mail-qc0-f174.google.com with SMTP id c9so895809qcz.5
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 22:50:34 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=irGEYAvTqN4bLkDPRuClivMbWN5FUJlgb8c13uXAIes=;
        b=FtnYmjbt9Pwg2Cc0Qobi10cvw8H0Z4umZAO8N2rNQP5EtKybQxW61J7X5VNnC+diUd
         9KOi1S4E/nvhpT6HcFJy1ystdS3SApufpmeEUV4iCZyuNmf/nZNBRpENSBm8RKGOOLDf
         U9oH4MC9Aj+JESrVb4BL5Zu78pi2pbrVnUmDiRxhPThhBVRrj+//yTXfNMVc7evU12wa
         0KX3NCj9QINNcEwyOp7joQT+uYXdoR9Qv6dotEiG9K/5O7CS4oWIgnpj0afHKnxvQYo0
         /vV+oze+ZFvjVJUlwSeAWjidQdOlWZF5nZueL5nsw0SIlc7hB8ybsrYjiiLEttkxKr1i
         CT4A==
X-Gm-Message-State: ALoCoQkfzzQSoKKDY4do0R5tRGu2hAPc24cxmS3atpZOjiuAljTRdMzAthgt55qSfiQIZ6o2HaDJ
X-Received: by 10.229.216.71 with SMTP id hh7mr6378499qcb.0.1423810233857;
 Thu, 12 Feb 2015 22:50:33 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Thu, 12 Feb 2015 22:50:13 -0800 (PST)
In-Reply-To: <CACdk1M6nCU2bq8-rmrc5WafhhWGUCywhB-8bYJ4mKQKnnRB+AA@mail.gmail.com>
References: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
 <CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com> <CACdk1M6nCU2bq8-rmrc5WafhhWGUCywhB-8bYJ4mKQKnnRB+AA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Thu, 12 Feb 2015 22:50:13 -0800
Message-ID: <CAPh_B=YwOSUx-sWWfzV3jT0KwdaV2HEP1=m6HtA4sGb_G9XrdQ@mail.gmail.com>
Subject: Re: Why a program would receive null from send message of mapReduceTriplets
To: James <alcaid1801@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134a78437901e050ef2a73a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134a78437901e050ef2a73a
Content-Type: text/plain; charset=UTF-8

Then maybe you actually had a null in your vertex attribute?


On Thu, Feb 12, 2015 at 10:47 PM, James <alcaid1801@gmail.com> wrote:

> I changed the mapReduceTriplets() func to aggregateMessages(), but it
> still failed.
>
>
> 2015-02-13 6:52 GMT+08:00 Reynold Xin <rxin@databricks.com>:
>
>> Can you use the new aggregateNeighbors method? I suspect the null is
>> coming from "automatic join elimination", which detects bytecode to see if
>> you need the src or dst vertex data. Occasionally it can fail to detect. In
>> the new aggregateNeighbors API, the caller needs to explicitly specifying
>> that, making it more robust.
>>
>>
>> On Thu, Feb 12, 2015 at 6:26 AM, James <alcaid1801@gmail.com> wrote:
>>
>>> Hello,
>>>
>>> When I am running the code on a much bigger size graph, I met
>>> NullPointerException.
>>>
>>> I found that is because the sendMessage() function receive a triplet that
>>> edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen
>>> as I
>>> am sure every vertices have a attr.
>>>
>>> Any returns is appreciated.
>>>
>>> Alcaid
>>>
>>>
>>> 2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:
>>>
>>> > Hello,
>>> >
>>> > Recently  I am trying to estimate the average distance of a big graph
>>> > using spark with the help of [HyperAnf](
>>> > http://dl.acm.org/citation.cfm?id=1963493).
>>> >
>>> > It works like Connect Componenet algorithm, while the attribute of a
>>> > vertex is a HyperLogLog counter that at k-th iteration it estimates the
>>> > number of vertices it could reaches less than k hops.
>>> >
>>> > I have successfully run the code on a graph with 20M vertices. But I
>>> still
>>> > need help:
>>> >
>>> >
>>> > *I think the code could work more efficiently especially the "Send
>>> > message" function, but I am not sure about what will happen if a vertex
>>> > receive no message at a iteration.*
>>> >
>>> > Here is my code: https://github.com/alcaid1801/Erdos
>>> >
>>> > Any returns is appreciated.
>>> >
>>>
>>
>>
>

--001a1134a78437901e050ef2a73a--

From dev-return-11617-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 06:58:53 2015
Return-Path: <dev-return-11617-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ABFCC102FF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 06:58:53 +0000 (UTC)
Received: (qmail 86748 invoked by uid 500); 13 Feb 2015 06:54:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86459 invoked by uid 500); 13 Feb 2015 06:54:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83790 invoked by uid 99); 13 Feb 2015 06:50:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 06:50:34 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 06:50:10 +0000
Received: by mail-wg0-f50.google.com with SMTP id l2so14708036wgh.9
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 22:47:53 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=BXbxxUFenoLvVWY2HqWAMuqr48MAl7K1xHiAdRU8LS4=;
        b=x/CgtiW/SpntpdfInZuK+I2PssJUWhO/65WN4YdHjBQtGgOMQOcVBYKHzDBOFrY3Ii
         GUUlpxQ8THmRppZLW116N9fMR3dXYrOV45ph7af22g1qMRpMmrAjgiqIad16Rksvln+V
         gZ4MP1WS4smk+Wfgj/U9kA+DTmBnPkC7dxFUP+loq4/TWid97MxGO0Si8uzvSjfsVs1K
         nRrO33cYWzZmDs0XDEMMTGOPmoYP2/4jtQSZzGk8A4VN0rVhcMCaDKzmAyfohHePakqY
         8pOqofj447wbxXpve9yXvqgfxqtSCgliLezbANW/BnrBPPmVqcNVGGfFJsGBQY91NviU
         bGIg==
MIME-Version: 1.0
X-Received: by 10.180.19.228 with SMTP id i4mr13353308wie.13.1423810073890;
 Thu, 12 Feb 2015 22:47:53 -0800 (PST)
Received: by 10.216.67.197 with HTTP; Thu, 12 Feb 2015 22:47:53 -0800 (PST)
In-Reply-To: <CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com>
References: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
	<CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com>
Date: Fri, 13 Feb 2015 14:47:53 +0800
Message-ID: <CACdk1M6nCU2bq8-rmrc5WafhhWGUCywhB-8bYJ4mKQKnnRB+AA@mail.gmail.com>
Subject: Re: Why a program would receive null from send message of mapReduceTriplets
From: James <alcaid1801@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec53d5507ae954c050ef29d46
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53d5507ae954c050ef29d46
Content-Type: text/plain; charset=UTF-8

I changed the mapReduceTriplets() func to aggregateMessages(), but it still
failed.


2015-02-13 6:52 GMT+08:00 Reynold Xin <rxin@databricks.com>:

> Can you use the new aggregateNeighbors method? I suspect the null is
> coming from "automatic join elimination", which detects bytecode to see if
> you need the src or dst vertex data. Occasionally it can fail to detect. In
> the new aggregateNeighbors API, the caller needs to explicitly specifying
> that, making it more robust.
>
>
> On Thu, Feb 12, 2015 at 6:26 AM, James <alcaid1801@gmail.com> wrote:
>
>> Hello,
>>
>> When I am running the code on a much bigger size graph, I met
>> NullPointerException.
>>
>> I found that is because the sendMessage() function receive a triplet that
>> edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen as
>> I
>> am sure every vertices have a attr.
>>
>> Any returns is appreciated.
>>
>> Alcaid
>>
>>
>> 2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:
>>
>> > Hello,
>> >
>> > Recently  I am trying to estimate the average distance of a big graph
>> > using spark with the help of [HyperAnf](
>> > http://dl.acm.org/citation.cfm?id=1963493).
>> >
>> > It works like Connect Componenet algorithm, while the attribute of a
>> > vertex is a HyperLogLog counter that at k-th iteration it estimates the
>> > number of vertices it could reaches less than k hops.
>> >
>> > I have successfully run the code on a graph with 20M vertices. But I
>> still
>> > need help:
>> >
>> >
>> > *I think the code could work more efficiently especially the "Send
>> > message" function, but I am not sure about what will happen if a vertex
>> > receive no message at a iteration.*
>> >
>> > Here is my code: https://github.com/alcaid1801/Erdos
>> >
>> > Any returns is appreciated.
>> >
>>
>
>

--bcaec53d5507ae954c050ef29d46--

From dev-return-11618-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 07:00:11 2015
Return-Path: <dev-return-11618-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3BE3A1037C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 07:00:11 +0000 (UTC)
Received: (qmail 70949 invoked by uid 500); 13 Feb 2015 07:00:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70868 invoked by uid 500); 13 Feb 2015 07:00:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70643 invoked by uid 99); 13 Feb 2015 07:00:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 07:00:07 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.173 as permitted sender)
Received: from [74.125.82.173] (HELO mail-we0-f173.google.com) (74.125.82.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 06:59:43 +0000
Received: by mail-we0-f173.google.com with SMTP id w55so14690752wes.4
        for <dev@spark.apache.org>; Thu, 12 Feb 2015 22:57:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=sUc+r/pBc5v96mqVxJrANtz/PwkLnampE9u6+goaRG8=;
        b=TdZmJ8JL0SiNWvNzrdsrcI02Cq4bUDScX7wKlmlGE5Nci1N9HfQqKXL68ITcu0JwkO
         NdYYXrEXiWq0unZ7O17m6SEQ5ItRNskmwo6irGVyQXhhapOG5Z5HWZwIjj6afOrKBwPI
         M7klKlXxfyJJkQBfTF6Z6YkUPRF/QqsVucIPGbuGYq2FXN0g4oxd1QyUaECziQPj+8DL
         15v60o702eUk7Vtx6Vm2ulHjcgNA9RAk+rwRDgNmXOPk44eIfeSFqV8RFiK14hYByLs4
         zJHhsohbmZlUX78rahVZ0ptq1HzpouPw5DcMChTdBCsAuJ/jc4S7PtUjQzR0MQ+3K6iB
         qu5g==
MIME-Version: 1.0
X-Received: by 10.194.173.10 with SMTP id bg10mr15273241wjc.115.1423810646883;
 Thu, 12 Feb 2015 22:57:26 -0800 (PST)
Received: by 10.216.67.197 with HTTP; Thu, 12 Feb 2015 22:57:26 -0800 (PST)
In-Reply-To: <CAPh_B=YwOSUx-sWWfzV3jT0KwdaV2HEP1=m6HtA4sGb_G9XrdQ@mail.gmail.com>
References: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
	<CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com>
	<CACdk1M6nCU2bq8-rmrc5WafhhWGUCywhB-8bYJ4mKQKnnRB+AA@mail.gmail.com>
	<CAPh_B=YwOSUx-sWWfzV3jT0KwdaV2HEP1=m6HtA4sGb_G9XrdQ@mail.gmail.com>
Date: Fri, 13 Feb 2015 14:57:26 +0800
Message-ID: <CACdk1M6p-WG6sxSifZN-COahwF8_6c8wEy+b07WoaJ3UCTW0TA@mail.gmail.com>
Subject: Re: Why a program would receive null from send message of mapReduceTriplets
From: James <alcaid1801@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122f20ed5c210050ef2bf66
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122f20ed5c210050ef2bf66
Content-Type: text/plain; charset=UTF-8

I am trying to run the data on spark-shell mode to find whether there is
something wrong in the code or data. As I could only reproduce the error on
a 50B edge graph.

2015-02-13 14:50 GMT+08:00 Reynold Xin <rxin@databricks.com>:

> Then maybe you actually had a null in your vertex attribute?
>
>
> On Thu, Feb 12, 2015 at 10:47 PM, James <alcaid1801@gmail.com> wrote:
>
>> I changed the mapReduceTriplets() func to aggregateMessages(), but it
>> still failed.
>>
>>
>> 2015-02-13 6:52 GMT+08:00 Reynold Xin <rxin@databricks.com>:
>>
>>> Can you use the new aggregateNeighbors method? I suspect the null is
>>> coming from "automatic join elimination", which detects bytecode to see if
>>> you need the src or dst vertex data. Occasionally it can fail to detect. In
>>> the new aggregateNeighbors API, the caller needs to explicitly specifying
>>> that, making it more robust.
>>>
>>>
>>> On Thu, Feb 12, 2015 at 6:26 AM, James <alcaid1801@gmail.com> wrote:
>>>
>>>> Hello,
>>>>
>>>> When I am running the code on a much bigger size graph, I met
>>>> NullPointerException.
>>>>
>>>> I found that is because the sendMessage() function receive a triplet
>>>> that
>>>> edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen
>>>> as I
>>>> am sure every vertices have a attr.
>>>>
>>>> Any returns is appreciated.
>>>>
>>>> Alcaid
>>>>
>>>>
>>>> 2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:
>>>>
>>>> > Hello,
>>>> >
>>>> > Recently  I am trying to estimate the average distance of a big graph
>>>> > using spark with the help of [HyperAnf](
>>>> > http://dl.acm.org/citation.cfm?id=1963493).
>>>> >
>>>> > It works like Connect Componenet algorithm, while the attribute of a
>>>> > vertex is a HyperLogLog counter that at k-th iteration it estimates
>>>> the
>>>> > number of vertices it could reaches less than k hops.
>>>> >
>>>> > I have successfully run the code on a graph with 20M vertices. But I
>>>> still
>>>> > need help:
>>>> >
>>>> >
>>>> > *I think the code could work more efficiently especially the "Send
>>>> > message" function, but I am not sure about what will happen if a
>>>> vertex
>>>> > receive no message at a iteration.*
>>>> >
>>>> > Here is my code: https://github.com/alcaid1801/Erdos
>>>> >
>>>> > Any returns is appreciated.
>>>> >
>>>>
>>>
>>>
>>
>

--089e0122f20ed5c210050ef2bf66--

From dev-return-11619-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 09:42:20 2015
Return-Path: <dev-return-11619-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9893108DD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 09:42:20 +0000 (UTC)
Received: (qmail 23228 invoked by uid 500); 13 Feb 2015 09:42:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23155 invoked by uid 500); 13 Feb 2015 09:42:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23144 invoked by uid 99); 13 Feb 2015 09:42:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 09:42:19 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of michael.belldavies@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 09:42:14 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 0532713C32F3
	for <dev@spark.apache.org>; Fri, 13 Feb 2015 01:40:27 -0800 (PST)
Date: Fri, 13 Feb 2015 02:40:24 -0700 (MST)
From: Mick Davies <michael.belldavies@gmail.com>
To: dev@spark.apache.org
Message-ID: <1423820424411-10617.post@n3.nabble.com>
In-Reply-To: <1421678324708-10193.post@n3.nabble.com>
References: <1421425027439-10141.post@n3.nabble.com> <CAAswR-5XQuww+AGXxY9+RK6O3YEQwG4ifRM64xnR4cY4RkceNw@mail.gmail.com> <1421658254509-10189.post@n3.nabble.com> <1421678324708-10193.post@n3.nabble.com>
Subject: Re: Optimize encoding/decoding strings when using Parquet
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I have put in a PR on Parquet to support dictionaries when filters are pushed
down, which should reduce binary conversion overhear when Spark pushes down
string predicates on columns that are dictionary encoded.

https://github.com/apache/incubator-parquet-mr/pull/117

It's blocked at the moment as I part of my parquet build fails on my Mac due
to issue getting thrift 0.7 installed. Installation instructions available
on Parquet do not seem to work I think due to this issue
https://issues.apache.org/jira/browse/THRIFT-2229
<https://issues.apache.org/jira/browse/THRIFT-2229>.

This is not directly related to Spark but I wondered if anyone has got
thrift 0.7 working on Mac Yosemite 10.0, or can suggest a work round.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Optimize-encoding-decoding-strings-when-using-Parquet-tp10141p10617.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11620-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 09:56:45 2015
Return-Path: <dev-return-11620-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C69BB10954
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 09:56:45 +0000 (UTC)
Received: (qmail 45815 invoked by uid 500); 13 Feb 2015 09:56:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45737 invoked by uid 500); 13 Feb 2015 09:56:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45726 invoked by uid 99); 13 Feb 2015 09:56:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 09:56:44 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of michael.belldavies@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 09:56:18 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 6EB3E13C3740
	for <dev@spark.apache.org>; Fri, 13 Feb 2015 01:54:48 -0800 (PST)
Date: Fri, 13 Feb 2015 02:54:45 -0700 (MST)
From: Mick Davies <michael.belldavies@gmail.com>
To: dev@spark.apache.org
Message-ID: <1423821285839-10618.post@n3.nabble.com>
In-Reply-To: <CAAswR-6MUKL1u5LwdQmuGkMN+PsiuODveQkfcpCbc5S_04gBvQ@mail.gmail.com>
References: <1422788611928-10377.post@n3.nabble.com> <CAAswR-6MUKL1u5LwdQmuGkMN+PsiuODveQkfcpCbc5S_04gBvQ@mail.gmail.com>
Subject: Re: Caching tables at column level
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks - we have tried this and it works nicely.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Caching-tables-at-column-level-tp10377p10618.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11621-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 13:35:36 2015
Return-Path: <dev-return-11621-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A25CF17408
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 13:35:36 +0000 (UTC)
Received: (qmail 20707 invoked by uid 500); 13 Feb 2015 13:35:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20620 invoked by uid 500); 13 Feb 2015 13:35:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20608 invoked by uid 99); 13 Feb 2015 13:35:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 13:35:34 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 13:35:10 +0000
Received: by mail-wg0-f48.google.com with SMTP id l18so13590809wgh.7
        for <dev@spark.apache.org>; Fri, 13 Feb 2015 05:35:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=B7ruqUBCQj8BvXG5PVKwGIJn9m7HoF9YpbjTvTlrK+g=;
        b=G9EqiBIw0h6HyirIcpLBA6YFm2g7qAQ7Kid6+WsZAFGSNJlbSIPhVBRhazeWcCZGxx
         FOWGxNzH/7yZCCtW7Pyh8DLrfFLjs6Wj4fEgmLzMs/USS7OBPZJybAfQyDZ5iUYmMD8r
         YyYTov8W2Xuw64X2LiL3CtMqFYYBfNaEI3PUTnnalPgCegF529ywLdbcogbwOUREhBL5
         3QkihqRLE7AUxmo3PcXdwAJB2i4AVEW7CuNTR46/6efHch1ctFTO8nGxNwBd827iqe7X
         If57thHjhdW0VkKrMZQJV5yaEz53jN11aK3CgzRYPUXlWLvOE9BTjwuvhCN+rShC4+k2
         N5Nw==
MIME-Version: 1.0
X-Received: by 10.180.103.102 with SMTP id fv6mr15880001wib.80.1423834507511;
 Fri, 13 Feb 2015 05:35:07 -0800 (PST)
Received: by 10.216.67.197 with HTTP; Fri, 13 Feb 2015 05:35:07 -0800 (PST)
In-Reply-To: <CAPh_B=YwOSUx-sWWfzV3jT0KwdaV2HEP1=m6HtA4sGb_G9XrdQ@mail.gmail.com>
References: <CACdk1M5rgBWOO99PEEViW-PxjiUM0+nA7Do2QYBgJfiXnEjKmg@mail.gmail.com>
	<CAPh_B=bNFnO9ePob_Wh__0H8wTUBQbk7bWvWRGrywrGBkpKmbA@mail.gmail.com>
	<CACdk1M6nCU2bq8-rmrc5WafhhWGUCywhB-8bYJ4mKQKnnRB+AA@mail.gmail.com>
	<CAPh_B=YwOSUx-sWWfzV3jT0KwdaV2HEP1=m6HtA4sGb_G9XrdQ@mail.gmail.com>
Date: Fri, 13 Feb 2015 21:35:07 +0800
Message-ID: <CACdk1M7GrYc3TwjtfhT=O=P8NBiYrg0iRZWdi09dtuDVs3yscA@mail.gmail.com>
Subject: Re: Why a program would receive null from send message of mapReduceTriplets
From: James <alcaid1801@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0444eab30a1040050ef84e16
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0444eab30a1040050ef84e16
Content-Type: text/plain; charset=UTF-8

I have a question:

*How could the attributes of triplets of a graph get update after
mapVertices() func? *

My code

```
// Initial the graph, assign a counter to each vertex that contains the
vertex id only
var anfGraph = graph.mapVertices { case (vid, _) =>
  val counter = new HyperLogLog(5)
  counter.offer(vid)
  counter
}

val nullVertex = anfGraph.triplets.filter(edge => edge.srcAttr ==
null).first

anfGraph.vertices.filter(_._1 == nullVertex).first
// I could see that the vertex has a not null attribute

// messages = anfGraph.aggregateMessages(msgFun, mergeMessage)   // <-
NullPointerException

```

I could found that some vertex attributes in some triplets are null, but
not all.


Alcaid


2015-02-13 14:50 GMT+08:00 Reynold Xin <rxin@databricks.com>:

> Then maybe you actually had a null in your vertex attribute?
>
>
> On Thu, Feb 12, 2015 at 10:47 PM, James <alcaid1801@gmail.com> wrote:
>
>> I changed the mapReduceTriplets() func to aggregateMessages(), but it
>> still failed.
>>
>>
>> 2015-02-13 6:52 GMT+08:00 Reynold Xin <rxin@databricks.com>:
>>
>>> Can you use the new aggregateNeighbors method? I suspect the null is
>>> coming from "automatic join elimination", which detects bytecode to see if
>>> you need the src or dst vertex data. Occasionally it can fail to detect. In
>>> the new aggregateNeighbors API, the caller needs to explicitly specifying
>>> that, making it more robust.
>>>
>>>
>>> On Thu, Feb 12, 2015 at 6:26 AM, James <alcaid1801@gmail.com> wrote:
>>>
>>>> Hello,
>>>>
>>>> When I am running the code on a much bigger size graph, I met
>>>> NullPointerException.
>>>>
>>>> I found that is because the sendMessage() function receive a triplet
>>>> that
>>>> edge.srcAttr or edge.dstAttr is null. Thus I wonder why it will happen
>>>> as I
>>>> am sure every vertices have a attr.
>>>>
>>>> Any returns is appreciated.
>>>>
>>>> Alcaid
>>>>
>>>>
>>>> 2015-02-11 19:30 GMT+08:00 James <alcaid1801@gmail.com>:
>>>>
>>>> > Hello,
>>>> >
>>>> > Recently  I am trying to estimate the average distance of a big graph
>>>> > using spark with the help of [HyperAnf](
>>>> > http://dl.acm.org/citation.cfm?id=1963493).
>>>> >
>>>> > It works like Connect Componenet algorithm, while the attribute of a
>>>> > vertex is a HyperLogLog counter that at k-th iteration it estimates
>>>> the
>>>> > number of vertices it could reaches less than k hops.
>>>> >
>>>> > I have successfully run the code on a graph with 20M vertices. But I
>>>> still
>>>> > need help:
>>>> >
>>>> >
>>>> > *I think the code could work more efficiently especially the "Send
>>>> > message" function, but I am not sure about what will happen if a
>>>> vertex
>>>> > receive no message at a iteration.*
>>>> >
>>>> > Here is my code: https://github.com/alcaid1801/Erdos
>>>> >
>>>> > Any returns is appreciated.
>>>> >
>>>>
>>>
>>>
>>
>

--f46d0444eab30a1040050ef84e16--

From dev-return-11622-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 15:48:05 2015
Return-Path: <dev-return-11622-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 84EDF178CC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 15:48:05 +0000 (UTC)
Received: (qmail 76279 invoked by uid 500); 13 Feb 2015 15:47:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76205 invoked by uid 500); 13 Feb 2015 15:47:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76185 invoked by uid 99); 13 Feb 2015 15:47:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 15:47:52 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 15:47:27 +0000
Received: by labgm9 with SMTP id gm9so17236666lab.2
        for <dev@spark.apache.org>; Fri, 13 Feb 2015 07:46:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=0Oske3ZoYc2kR9nJSyifoqyEQKNbz5AQgpcxaqWRWes=;
        b=DaNc//guwLzwlt1LOvPt1pJrK4GZZJhyE5rwH3oJ9Wm3/72eVBeInTAh/fuGk/dKIM
         kGnuEkgcX15TbLoc46/iaTQEXnweS0CHeRcYvusdAFs0cLmXWEAEZzhYa4qeBgw2FdMn
         qfFNv8beFv2ozmFtL9BmzvpahCDBvHZne07ksGa6JS/6ut/Gb3fcYTsLXB1krJs9SEKv
         0xgPkefeq/BPJaFV+sGPehGSKLX+lOVmtIcpr8+agOq577C5qJODFkuJFGew7ijXdx/J
         1F6RpQz+OowekUz42M8lHUIuEcNyMtdH/S2s+uJ2C5kS9U8afniv4Tnd2IfhKPinaGTn
         ORWA==
MIME-Version: 1.0
X-Received: by 10.152.1.40 with SMTP id 8mr8518175laj.97.1423842401242; Fri,
 13 Feb 2015 07:46:41 -0800 (PST)
Received: by 10.25.212.3 with HTTP; Fri, 13 Feb 2015 07:46:41 -0800 (PST)
Date: Fri, 13 Feb 2015 07:46:41 -0800
Message-ID: <CA+B-+fwL-t9sGDZ7yYfxwXDJUM6bcLiy1UYdP=NRKpfebCaBhA@mail.gmail.com>
Subject: mllib.recommendation Design
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c6b908ad2a3050efa2423
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6b908ad2a3050efa2423
Content-Type: text/plain; charset=UTF-8

Hi,

I am bit confused on the mllib design in the master. I thought that core
algorithms will stay in mllib and ml will define the pipelines over the
core algorithm but looks like in master ALS is moved from mllib to ml...

I am refactoring my PR to a factorization package and I want to build it on
top of ml.recommendation.ALS (possibly extend from ml.recommendation.ALS
since first version will use very similar RDD handling as ALS and a
proximal solver that's being added to breeze)

https://issues.apache.org/jira/browse/SPARK-2426
https://github.com/scalanlp/breeze/pull/321

Basically I am not sure if we should merge it with recommendation.ALS since
this is more generic than recommendation. I am considering calling it
ConstrainedALS where user can specify different constraint for user and
product factors (Similar to GraphLab CF structure).

I am also working on ConstrainedALM where the underlying algorithm is no
longer ALS but nonlinear alternating minimization with constraints.
https://github.com/scalanlp/breeze/pull/364
This will let us do large rank matrix completion where there is no need to
construct gram matrices. I will open up the JIRA soon after getting initial
results

I am bit confused that where should I add the factorization package. It
will use the current ALS test-cases and I have to construct more test-cases
for sparse coding and PLSA formulations.

Thanks.
Deb

--089e013c6b908ad2a3050efa2423--

From dev-return-11623-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 13 20:17:51 2015
Return-Path: <dev-return-11623-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8126D10667
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 13 Feb 2015 20:17:51 +0000 (UTC)
Received: (qmail 73564 invoked by uid 500); 13 Feb 2015 20:17:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73495 invoked by uid 500); 13 Feb 2015 20:17:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73484 invoked by uid 99); 13 Feb 2015 20:17:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 20:17:49 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chris.a.mattmann@jpl.nasa.gov designates 128.149.139.109 as permitted sender)
Received: from [128.149.139.109] (HELO mail.jpl.nasa.gov) (128.149.139.109)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 13 Feb 2015 20:17:44 +0000
Received: from mail.jpl.nasa.gov (ap-ehub-sp01.jpl.nasa.gov [128.149.137.148])
	by smtp.jpl.nasa.gov (Sentrion-MTA-4.3.1/Sentrion-MTA-4.3.1) with ESMTP id t1DKEp75018968
	(using TLSv1 with cipher AES128-SHA (128 bits) verified NO)
	for <dev@spark.apache.org>; Fri, 13 Feb 2015 12:15:24 -0800
Received: from AP-EMBX-SP40.RES.AD.JPL ([169.254.7.248]) by
 ap-ehub-sp01.RES.AD.JPL ([169.254.3.168]) with mapi id 14.03.0210.002; Fri,
 13 Feb 2015 12:14:50 -0800
From: "Mattmann, Chris A (3980)" <chris.a.mattmann@jpl.nasa.gov>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: FW: Trouble posting to the list
Thread-Topic: Trouble posting to the list
Thread-Index: AQHQRtVf/9ffOvCgz029NduMCXE+m5zvBayA
Date: Fri, 13 Feb 2015 20:14:50 +0000
Message-ID: <D1039B1C.1E46D8%chris.a.mattmann@jpl.nasa.gov>
References: <COL401-EAS39295F16003442F93709ECFDA220@phx.gbl>
In-Reply-To: <COL401-EAS39295F16003442F93709ECFDA220@phx.gbl>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
user-agent: Microsoft-MacOutlook/14.4.7.141117
x-originating-ip: [128.149.137.114]
Content-Type: text/plain; charset="utf-8"
Content-ID: <DE97572DB615434BAAC054F869CA5294@ad.jpl>
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Source-Sender: chris.a.mattmann@jpl.nasa.gov
X-AUTH: Authorized
X-Virus-Checked: Checked by ClamAV on apache.org

RllJDQoNCisrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysr
KysrKysrKysrKysrKysrKw0KQ2hyaXMgTWF0dG1hbm4sIFBoLkQuDQpDaGllZiBBcmNoaXRlY3QN
Ckluc3RydW1lbnQgU29mdHdhcmUgYW5kIFNjaWVuY2UgRGF0YSBTeXN0ZW1zIFNlY3Rpb24gKDM5
OCkNCk5BU0EgSmV0IFByb3B1bHNpb24gTGFib3JhdG9yeSBQYXNhZGVuYSwgQ0EgOTExMDkgVVNB
DQpPZmZpY2U6IDE2OC01MTksIE1haWxzdG9wOiAxNjgtNTI3DQpFbWFpbDogY2hyaXMuYS5tYXR0
bWFubkBuYXNhLmdvdg0KV1dXOiAgaHR0cDovL3N1bnNldC51c2MuZWR1L35tYXR0bWFubi8NCisr
KysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysr
KysrKysrKw0KQWRqdW5jdCBBc3NvY2lhdGUgUHJvZmVzc29yLCBDb21wdXRlciBTY2llbmNlIERl
cGFydG1lbnQNClVuaXZlcnNpdHkgb2YgU291dGhlcm4gQ2FsaWZvcm5pYSwgTG9zIEFuZ2VsZXMs
IENBIDkwMDg5IFVTQQ0KKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysrKysr
KysrKysrKysrKysrKysrKysrKysrKysrDQoNCg0KDQoNCg0KDQotLS0tLU9yaWdpbmFsIE1lc3Nh
Z2UtLS0tLQ0KRnJvbTogRGltYSBaaGl5YW5vdiA8ZGltYXpoaXlhbm92QGhvdG1haWwuY29tPg0K
RGF0ZTogVGh1cnNkYXksIEZlYnJ1YXJ5IDEyLCAyMDE1IGF0IDc6MDQgQU0NClRvOiAidXNlci1v
d25lckBzcGFyay5hcGFjaGUub3JnIiA8dXNlci1vd25lckBzcGFyay5hcGFjaGUub3JnPg0KU3Vi
amVjdDogVHJvdWJsZSBwb3N0aW5nIHRvIHRoZSBsaXN0DQoNCj5IZWxsbw0KPg0KPkFmdGVyIG51
bWVyb3VzIGF0dGVtcHRzIEkgYW0gc3RpbGwgdW5hYmxlIHRvIHBvc3QgdG8gdGhlIGxpc3QuIEFm
dGVyIEkNCj5jbGljayBTdWJzY3JpYmUgSSBkbyBub3QgZ2V0IGFuIGUtbWFpbCB3aGljaCBhbGxv
d3MgbWUgdG8gY29uZmlybSBteQ0KPnN1YnNjcmlwdGlvbi4gQ291bGQgeW91IHBsZWFzZSBhZGQg
bWUgbWFudWFsbHk/DQo+DQo+VGhhbmtzIGEgbG90DQo+RGltYQ0KPg0KPlNlbnQgZnJvbSBteSBp
UGhvbmUNCg0K
DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-11624-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 14 09:23:18 2015
Return-Path: <dev-return-11624-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 88D7410A7C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Feb 2015 09:23:18 +0000 (UTC)
Received: (qmail 47312 invoked by uid 500); 14 Feb 2015 09:15:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38762 invoked by uid 500); 14 Feb 2015 09:15:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27586 invoked by uid 99); 14 Feb 2015 07:08:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Feb 2015 07:08:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Feb 2015 07:08:31 +0000
Received: by mail-ig0-f182.google.com with SMTP id h15so15023553igd.3
        for <dev@spark.apache.org>; Fri, 13 Feb 2015 23:08:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=HlRHBXbtOKyIROi5G1aCoP9mh6ahnJ6786L52uPXCcU=;
        b=VggQQP0y/IwOe2aNVhgVrYL86uRfUVCW0Q2II85NjWoofcSg4bgch0eK8qab/InTRW
         QzkWYJmdomOGWb5Up00+2Ny5fo8O3zEzEFSxSKvSwtDfw7MXAAafsweE08Biq24A0Ysm
         hQa5yaa+m8gkN2GjPHurDf6OvpKtaWwZrT4c7su/jf+aKBTczaD7s6h/1kEwun4lH5K4
         Hypj9Oa4v7d/QOs5gsDMw0vPFTS2KEROt4mhXfCATj0o7EHZma1jiveP5QmsoaQ1yrTF
         lpakpssoFWKanYiKk1l9/oB/mo8ovW7q/PzV9BH1vOfog1t02mnYEQZOAuCeJE0DcZU6
         m05Q==
X-Received: by 10.107.167.135 with SMTP id q129mr16981980ioe.23.1423897690754;
 Fri, 13 Feb 2015 23:08:10 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
 <CACkSZy3MAt22t1XQrkfax8g3At6Uea9S7uJMB0ViCy5-pDMu=w@mail.gmail.com>
 <CAOhmDzebSdPA_WOzq=QaehUn2iUAnbC0nGfQ0Np5C79PTUNxPg@mail.gmail.com> <CAOhmDzfG7GABey-tJG-AgOQuWWXbECdk1j-ZQakvYO=x2gPg=Q@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sat, 14 Feb 2015 07:08:09 +0000
Message-ID: <CAOhmDzdt90-V7Q+UiDwOD=wbyrVGO9H3g65j4YOH0BFa=ng_7g@mail.gmail.com>
Subject: Re: Building Spark with Pants
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1142a4440df91e050f0704dd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1142a4440df91e050f0704dd
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

FYI: Here is the matching discussion over on the Pants dev list.
<https://groups.google.com/forum/#!topic/pants-devel/rTaU-iIOIFE>

On Mon Feb 02 2015 at 4:50:33 PM Nicholas Chammas nicholas.chammas@gmail.co=
m
<http://mailto:nicholas.chammas@gmail.com> wrote:

To reiterate, I'm asking from an experimental perspective. I'm not
> proposing we change Spark to build with Pants or anything like that.
>
> I'm interested in trying Pants out and I'm wondering if anyone else share=
s
> my interest or already has experience with Pants that they can share.
>
> On Mon Feb 02 2015 at 4:40:45 PM Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> I'm asking from an experimental standpoint; this is not happening anytim=
e
>> soon.
>>
>> Of course, if the experiment turns out very well, Pants would replace
>> both sbt and Maven (like it has at Twitter, for example). Pants also wor=
ks
>> with IDEs <http://pantsbuild.github.io/index.html#using-pants-with>.
>>
>> On Mon Feb 02 2015 at 4:33:11 PM Stephen Boesch <javadba@gmail.com>
>> wrote:
>>
>>> There is a significant investment in sbt and maven - and they are not a=
t
>>> all likely to be going away. A third build tool?  Note that there is al=
so
>>> the perspective of building within an IDE - which actually works presen=
tly
>>> for sbt and with a little bit of tweaking with maven as well.
>>>
>>> 2015-02-02 16:25 GMT-08:00 Nicholas Chammas <nicholas.chammas@gmail.com=
>
>>> :
>>>
>>>> Does anyone here have experience with Pants
>>>>
>>> <http://pantsbuild.github.io/index.html> or interest in trying to build
>>>
>>>
>>>> Spark with it?
>>>>
>>>> Pants has an interesting story. It was born at Twitter to help them
>>>> build
>>>> their Scala, Java, and Python projects as several independent
>>>> components in
>>>> one monolithic repo. (It was inspired by a similar build tool at Googl=
e
>>>> called blaze.) The mix of languages and sub-projects at Twitter seems
>>>> similar to the breakdown we have in Spark.
>>>>
>>>> Pants has an interesting take on how a build system should work, and
>>>> Twitter and Foursquare (who use Pants as their primary build tool)
>>>> claim it
>>>> helps enforce better build hygiene and maintainability.
>>>>
>>>> Some relevant talks:
>>>>
>>>>    - Building Scala Hygienically with Pants
>>>>    <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
>>>>    - The Pants Build Tool at Twitter
>>>>    <https://engineering.twitter.com/university/videos/the-pant
>>>> s-build-tool-at-twitter>
>>>>    - Getting Started with the Pants Build System: Why Pants?
>>>>    <https://engineering.twitter.com/university/videos/getting-
>>>> started-with-the-pants-build-system-why-pants>
>>>
>>>
>>>>
>>>> At some point I may take a shot at converting Spark to use Pants as an
>>>> experiment and just see what it=E2=80=99s like.
>>>>
>>>> Nick
>>>> =E2=80=8B
>>>>
>>> =E2=80=8B

--001a1142a4440df91e050f0704dd--

From dev-return-11625-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 14 16:58:21 2015
Return-Path: <dev-return-11625-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D759C176FA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 14 Feb 2015 16:58:21 +0000 (UTC)
Received: (qmail 24338 invoked by uid 500); 14 Feb 2015 16:58:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23788 invoked by uid 500); 14 Feb 2015 16:58:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22926 invoked by uid 99); 14 Feb 2015 16:58:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Feb 2015 16:58:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ssaboum@gmail.com designates 209.85.214.169 as permitted sender)
Received: from [209.85.214.169] (HELO mail-ob0-f169.google.com) (209.85.214.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 14 Feb 2015 16:58:11 +0000
Received: by mail-ob0-f169.google.com with SMTP id wp4so30147937obc.0;
        Sat, 14 Feb 2015 08:57:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=ht2y4RqkodEXaAdUlf1xKEVAYoo7flBbAEGtolo2Hy8=;
        b=j2+K6eT9Emrtm1C5n0Y3T87kc63gumyZO8opw+yHXxCFS50bFgZL8i5TUoaDHSi2qa
         8Ldt8k/9LubICtsajZRCi0JF+2Fa88MYgZrHcXv56IJ6biMUF9nCQN8SOr6HSIHDpnWo
         8DKI1zCarx4S/tJn+mgWwRXwb1PIWRmeSAXAWVBYriY9gXyE2as5y3+iGwl10P/Gvu+0
         vsK7GsR5/BSrKx3x8v1vw0TJz6/rWr5dG1G+i8YB1VI22F0kis/4mj1ALfOrsB8KURFH
         acLdF9QfwK2EB757nFLyceUvkn47wrspjkncvxkY+BCDPbKNdntzhNt4eYIxjsOBzTGa
         y6yg==
X-Received: by 10.202.224.9 with SMTP id x9mr9788822oig.62.1423933071350; Sat,
 14 Feb 2015 08:57:51 -0800 (PST)
MIME-Version: 1.0
Received: by 10.76.86.69 with HTTP; Sat, 14 Feb 2015 08:57:31 -0800 (PST)
In-Reply-To: <54DAD5C0.1020300@gmail.com>
References: <54DAD5C0.1020300@gmail.com>
From: Olivier Girardot <ssaboum@gmail.com>
Date: Sat, 14 Feb 2015 17:57:31 +0100
Message-ID: <CAAGLpn4psNZxUyoTFy1YC-1Pt7RryTG5v_eXxrs47_447Q15gQ@mail.gmail.com>
Subject: Re: Build spark failed with maven
To: Yi Tian <tianyi.asiainfo@gmail.com>
Cc: dev@spark.apache.org, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d593ae6dff1050f0f400a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d593ae6dff1050f0f400a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi,
this was not reproduced for me, what kind of jdk are you using for the zinc
server ?

Regards,

Olivier.

2015-02-11 5:08 GMT+01:00 Yi Tian <tianyi.asiainfo@gmail.com>:

>  Hi, all
>
> I got an ERROR when I build spark master branch with maven (commit:
> 2d1e916730492f5d61b97da6c483d3223ca44315)
>
> [INFO]
> [INFO] ------------------------------------------------------------------=
------
> [INFO] Building Spark Project Catalyst 1.3.0-SNAPSHOT
> [INFO] ------------------------------------------------------------------=
------
> [INFO]
> [INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-versions) @ spark=
-catalyst_2.10 ---
> [INFO]
> [INFO] --- build-helper-maven-plugin:1.8:add-source (add-scala-sources) @=
 spark-catalyst_2.10 ---
> [INFO] Source directory: /Users/tianyi/github/community/apache-spark/sql/=
catalyst/src/main/scala added.
> [INFO]
> [INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-ca=
talyst_2.10 ---
> [INFO]
> [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spa=
rk-catalyst_2.10 ---
> [INFO] Using 'UTF-8' encoding to copy filtered resources.
> [INFO] skip non existing resourceDirectory /Users/tianyi/github/community=
/apache-spark/sql/catalyst/src/main/resources
> [INFO] Copying 3 resources
> [INFO]
> [INFO] --- scala-maven-plugin:3.2.0:compile (scala-compile-first) @ spark=
-catalyst_2.10 ---
> [INFO] Using zinc server for incremental compilation
> [INFO] compiler plugin: BasicArtifact(org.scalamacros,paradise_2.10.4,2.0=
.1,null)
> [info] Compiling 69 Scala sources and 3 Java sources to /Users/tianyi/git=
hub/community/apache-spark/sql/catalyst/target/scala-2.10/classes...[error]=
 /Users/tianyi/github/community/apache-spark/sql/catalyst/src/main/scala/or=
g/apache/spark/sql/catalyst/dsl/package.scala:314: polymorphic expression c=
annot be instantiated to expected type;
> [error]  found   : [T(in method apply)]org.apache.spark.sql.catalyst.dsl.=
ScalaUdfBuilder[T(in method apply)]
> [error]  required: org.apache.spark.sql.catalyst.dsl.package.ScalaUdfBuil=
der[T(in method functionToUdfBuilder)]
> [error]   implicit def functionToUdfBuilder[T: TypeTag](func: Function1[_=
, T]): ScalaUdfBuilder[T] =3D ScalaUdfBuilder(func)
>
> Any suggestion?
> =E2=80=8B
>

--001a113d593ae6dff1050f0f400a--

From dev-return-11626-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 15 11:04:08 2015
Return-Path: <dev-return-11626-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A59610AF6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Feb 2015 11:04:08 +0000 (UTC)
Received: (qmail 6249 invoked by uid 500); 15 Feb 2015 11:04:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6131 invoked by uid 500); 15 Feb 2015 11:04:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6065 invoked by uid 99); 15 Feb 2015 11:04:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Feb 2015 11:04:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of watcherfr@gmail.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Feb 2015 11:04:01 +0000
Received: by iebtr6 with SMTP id tr6so17959409ieb.7
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 03:03:41 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=0ql+CtngHXTHOkqrwYXsSaA9vLd0Bso8b9tH2Yn/qJ4=;
        b=HfFqlYV5gnKsmIdQ58v8aMEZheT/wL6Ub8Pq7/Nod8vFhL7c/BEaJ9Nk1ovA3uCpA/
         S6HwhKE81arYQli2iRS2y0s6ku4/9SY3EZhgLHRpPSjGoHwPuXAIRi2ErG5mQquf1GSV
         XsG+q6bDiP8OQPq3Puv+DBu3XuCcHAPzX+XGzqWtnN17p7bjRFch4EAuZtBbu33vI4u0
         nYnBlACCMsmAmERo8M3SWk4UjPVSV2BXtGq049gWybtX4yHEIxQ6RubAM3RSEDG7gWHr
         U9t8VUTZHOyzlUO8ZczNtWAlRHTGPqnI8Or59k5gvefhNSsvHpW97a+yhHPWEOrKh/hM
         6zBA==
MIME-Version: 1.0
X-Received: by 10.42.21.78 with SMTP id j14mr24475672icb.43.1423998221387;
 Sun, 15 Feb 2015 03:03:41 -0800 (PST)
Received: by 10.36.16.81 with HTTP; Sun, 15 Feb 2015 03:03:41 -0800 (PST)
Date: Sun, 15 Feb 2015 12:03:41 +0100
Message-ID: <CAHwsXY=ceWYK+kbHGtmbOC=JdzfkX1DpGRNU=3tLRGzOjkUcFA@mail.gmail.com>
Subject: Spark & Hive
From: The Watcher <watcherfr@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf301d4152258e05050f1e6c23
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf301d4152258e05050f1e6c23
Content-Type: text/plain; charset=UTF-8

I'm a little confused around Hive & Spark, can someone shed some light ?

Using Spark, I can access the Hive metastore and run Hive queries. Since I
am able to do this in stand-alone mode, it can't be using map-reduce to run
the Hive queries and I suppose it's building a query plan and executing it
all in Spark.

So, is this the same as
https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started
?
If not, why not and aren't they likely to merge at some point ?

If Spark really builds its own query plan, joins, etc without Hive's then
is everything that requires special SQL syntax in Hive supported : window
functions, cubes, rollups, skewed tables, etc

Thanks

--20cf301d4152258e05050f1e6c23--

From dev-return-11627-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 15 20:16:56 2015
Return-Path: <dev-return-11627-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D75BF17758
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 15 Feb 2015 20:16:56 +0000 (UTC)
Received: (qmail 61174 invoked by uid 500); 15 Feb 2015 20:16:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61089 invoked by uid 500); 15 Feb 2015 20:16:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61078 invoked by uid 99); 15 Feb 2015 20:16:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Feb 2015 20:16:55 +0000
X-ASF-Spam-Status: No, hits=6.0 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,SPF_SOFTFAIL,URIBL_BLACK,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of vha14@msn.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 15 Feb 2015 20:16:50 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 55ED613F5763
	for <dev@spark.apache.org>; Sun, 15 Feb 2015 12:16:00 -0800 (PST)
Date: Sun, 15 Feb 2015 13:15:58 -0700 (MST)
From: vha14 <vha14@msn.com>
To: dev@spark.apache.org
Message-ID: <1424031358926-10626.post@n3.nabble.com>
In-Reply-To: <1424005519764-10625.post@n3.nabble.com>
References: <CAP4y_1r04Xq-fG3z8BgNy++720OC7rvU-d9bNTzRmgBiJiCX_g@mail.gmail.com> <CALDQvde2zJRvQVGGZckE_ZrtY6ZThhPRSoEj4E5DDLq0++RJFg@mail.gmail.com> <E794F018-7A2D-4F81-B058-1577F419D814@gmail.com> <1424005519764-10625.post@n3.nabble.com>
Subject: Re: A Spark Compilation Question
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

In IntelliJ:

- Open View -> Tool Windows -> Maven Projects
- Right click on Spark Project External Flume Sink
- Click Generate Sources and Update Folders

This should generate source code from sparkflume.avdl.

Vu~



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/A-Spark-Compilation-Question-tp8402p10626.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11628-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 04:06:56 2015
Return-Path: <dev-return-11628-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 06FE017DF0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 04:06:56 +0000 (UTC)
Received: (qmail 22700 invoked by uid 500); 16 Feb 2015 04:06:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22613 invoked by uid 500); 16 Feb 2015 04:06:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22601 invoked by uid 99); 16 Feb 2015 04:06:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 04:06:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.174] (HELO mail-qc0-f174.google.com) (209.85.216.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 04:06:28 +0000
Received: by mail-qc0-f174.google.com with SMTP id c9so10914645qcz.5
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 20:06:05 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=7LtsPFVH8Oe66Nso97eXnu1O6LaSKmOakcZps4QGMTY=;
        b=nHNdmesve2djahctyLbrDwJo0+JJwEk2eLRNLsQuV/N11GNnVyWmO4PKUWoj4aQyi1
         Syrm4U1zUEOIvgsVd4mrcP7M2LnqmH5v2MbgoBY/un1NLwza+ArUVaSFkWuVX00oxHhT
         slPdREmW4boVtDgqjTQqtv5ee6pyAQ9ENypiqMVdkSDxuZnFIGPrAPvUAImUpRgSlbj/
         7QQiGU8NhyvoLGKo8pw8FSmzhyFFobnjYMeSw8ESZ0dNV/vrUN27woSKtPAsMqz5UPva
         OKLrwBy0HqKvUSKpaIemLMjl8oiXB+hKhf9/Wbxlu+7xlBW8lZISQv8LNzmsRedCQrRo
         MIAg==
X-Gm-Message-State: ALoCoQmj85+vd8SUw4bDB2Q+vgBzXti82gpTuvL8C94mMTVpMm0ISN7WVnfCh1Ib/dJZGnuVmBru
X-Received: by 10.140.235.131 with SMTP id g125mr121525qhc.85.1424059565731;
 Sun, 15 Feb 2015 20:06:05 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Sun, 15 Feb 2015 20:05:45 -0800 (PST)
In-Reply-To: <CAHwsXY=ceWYK+kbHGtmbOC=JdzfkX1DpGRNU=3tLRGzOjkUcFA@mail.gmail.com>
References: <CAHwsXY=ceWYK+kbHGtmbOC=JdzfkX1DpGRNU=3tLRGzOjkUcFA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 15 Feb 2015 20:05:45 -0800
Message-ID: <CAPh_B=bWxJjL+MQjRBmHnRZgL_r0G23_+HVVJG9xPOVbBz0mbA@mail.gmail.com>
Subject: Re: Spark & Hive
To: The Watcher <watcherfr@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113768908e0b91050f2cb4e7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113768908e0b91050f2cb4e7
Content-Type: text/plain; charset=UTF-8

Spark SQL is not the same as Hive on Spark.

Spark SQL is a query engine that is designed from ground up for Spark
without the historic baggage of Hive. It also does more than SQL now -- it
is meant for structured data processing (e.g. the new DataFrame API) and
SQL. Spark SQL is mostly compatible with Hive, but 100% compatibility is
not a goal (nor desired, since Hive has a lot of weird SQL semantics in the
course of its evolution).

Hive on Spark is meant to replace Hive's MapReduce runtime with Spark's.

For more information, see this blog post:
https://databricks.com/blog/2014/07/01/shark-spark-sql-hive-on-spark-and-the-future-of-sql-on-spark.html



On Sun, Feb 15, 2015 at 3:03 AM, The Watcher <watcherfr@gmail.com> wrote:

> I'm a little confused around Hive & Spark, can someone shed some light ?
>
> Using Spark, I can access the Hive metastore and run Hive queries. Since I
> am able to do this in stand-alone mode, it can't be using map-reduce to run
> the Hive queries and I suppose it's building a query plan and executing it
> all in Spark.
>
> So, is this the same as
>
> https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started
> ?
> If not, why not and aren't they likely to merge at some point ?
>
> If Spark really builds its own query plan, joins, etc without Hive's then
> is everything that requires special SQL syntax in Hive supported : window
> functions, cubes, rollups, skewed tables, etc
>
> Thanks
>

--001a113768908e0b91050f2cb4e7--

From dev-return-11629-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 05:11:34 2015
Return-Path: <dev-return-11629-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ECF6217F63
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 05:11:34 +0000 (UTC)
Received: (qmail 63578 invoked by uid 500); 16 Feb 2015 05:11:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63504 invoked by uid 500); 16 Feb 2015 05:11:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63492 invoked by uid 99); 16 Feb 2015 05:11:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:11:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of niranda.perera@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:11:08 +0000
Received: by mail-ob0-f172.google.com with SMTP id nt9so38646756obb.3
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 21:08:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=J6TPOSIzu7wdAmU+9il+FJlCdN2pizAP3kthQkzVGas=;
        b=B/Gklk8JwdTBkQ5t5HBM16UNGEoML3Ppuqh5TZ48NlKwgczE4BCI2uJ2PWSG11dWi8
         dWidzzeOpJK3pH6kVShMJ+eIZJQU+0tnOsmIFRnM8LrShnDZurxAEjdWxepSwdqJN1d/
         Cpe72SLa4sidX0KyoJDPu+49AOAIfHaMEDNH70KrLUgRdPrEUw/vuLdrB5eqNiGJ2EAY
         bt3rWWHjASBvLgIm4mZ1tWyK91IunqIWjEX1IRp76SqhA3cJOjKWBkMCnjJcatxjT/ZJ
         tSn9ePEW35BBAW5uX2wRIs44AU91VLsWuW39t7Vsih2vvV8jyD41AQXwj8RAv0UaxzGL
         zwug==
MIME-Version: 1.0
X-Received: by 10.202.107.195 with SMTP id g186mr13166902oic.67.1424063330948;
 Sun, 15 Feb 2015 21:08:50 -0800 (PST)
Received: by 10.202.64.6 with HTTP; Sun, 15 Feb 2015 21:08:50 -0800 (PST)
Date: Mon, 16 Feb 2015 10:38:50 +0530
Message-ID: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
Subject: Replacing Jetty with TomCat
From: Niranda Perera <niranda.perera@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1141bdc6fa9c8b050f2d9490
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1141bdc6fa9c8b050f2d9490
Content-Type: text/plain; charset=UTF-8

Hi,

We are thinking of integrating Spark server inside a product. Our current
product uses Tomcat as its webserver.

Is it possible to switch the Jetty webserver in Spark to Tomcat
off-the-shelf?

Cheers

-- 
Niranda

--001a1141bdc6fa9c8b050f2d9490--

From dev-return-11630-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 05:20:09 2015
Return-Path: <dev-return-11630-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B616417F79
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 05:20:09 +0000 (UTC)
Received: (qmail 71888 invoked by uid 500); 16 Feb 2015 05:20:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71809 invoked by uid 500); 16 Feb 2015 05:20:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71792 invoked by uid 99); 16 Feb 2015 05:20:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:20:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.172] (HELO mail-qc0-f172.google.com) (209.85.216.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:19:42 +0000
Received: by mail-qc0-f172.google.com with SMTP id i8so9026573qcq.3
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 21:17:50 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=+A3Wa7j6rxesZMh1uqk2zZRUk4Z780Qqot0dPt7Wmzs=;
        b=f06E0nIaQZ6NSrmB+Q3JWchg914AKJyJGrtwcRSuN7QxDQIeYzHoG2n0aChgEL6Jbs
         Z0JIcDjrSLoGs7dhGWhKT/VmXNVczLgrvZim/cqxaQSY+VhxvehTzw3g4lAvXHS4MIbv
         5iDVQkySxf+XuavHr9i2/ShMIDdaqAqWxPt9P7eNB0hvrqnrEd69tVk3NgMbxjvplP9P
         +74YYuC7uJf9gx+nKFITVNaM6fePaUuA0UGe2qHbF2FvlyeOFe9AsUFQv0OCqR1fKk20
         lxkh1XgjAap0Pi+2TW82ICbP/zO5CTSY6TfSdW4ImUSz8AEZBAzFkMFrvPGVoEHYNWsz
         H5Tw==
X-Gm-Message-State: ALoCoQmPtK09h5qmpoP1oDmhZbhSlZdAzgO9FxtWQ5iMyP8QLHZVfGJa5j+PBqiJIdmQzdtdfCkM
X-Received: by 10.140.25.208 with SMTP id 74mr1715052qgt.58.1424063870190;
 Sun, 15 Feb 2015 21:17:50 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Sun, 15 Feb 2015 21:17:29 -0800 (PST)
In-Reply-To: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 15 Feb 2015 21:17:29 -0800
Message-ID: <CAPh_B=Yo7vApA4S-Yb0yJAqs39oHt+nqf2MyDXXusjVVGpm+KA@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Niranda Perera <niranda.perera@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1367a1edff8050f2db5f6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1367a1edff8050f2db5f6
Content-Type: text/plain; charset=UTF-8

Most likely no. We are using the embedded mode of Jetty, rather than using
servlets.

Even if it is possible, you probably wouldn't want to embed Spark in your
application server ...


On Sun, Feb 15, 2015 at 9:08 PM, Niranda Perera <niranda.perera@gmail.com>
wrote:

> Hi,
>
> We are thinking of integrating Spark server inside a product. Our current
> product uses Tomcat as its webserver.
>
> Is it possible to switch the Jetty webserver in Spark to Tomcat
> off-the-shelf?
>
> Cheers
>
> --
> Niranda
>

--001a11c1367a1edff8050f2db5f6--

From dev-return-11631-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 05:25:43 2015
Return-Path: <dev-return-11631-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6909C17F8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 05:25:43 +0000 (UTC)
Received: (qmail 78835 invoked by uid 500); 16 Feb 2015 05:25:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78755 invoked by uid 500); 16 Feb 2015 05:25:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78743 invoked by uid 99); 16 Feb 2015 05:25:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:25:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of niranda.perera@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:25:17 +0000
Received: by mail-ob0-f177.google.com with SMTP id wp18so37187202obc.8
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 21:24:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Dh/0exh1GkTaTIcuG3Q6WYRYko8S47oI7Ftp27YqBg4=;
        b=pgKevKoHgV07qC4nyGgoh3zypKnDw3N0z+lH28fEGnjk2EHKBljsZPMVcmttn5ye0k
         0nM4gsvfbuoUKV7EINi+VLQnbwIxr1hVFvUz4iVihi9Y3w8uLFQRwdaVCPC9/m9F7jWr
         u/KBFayrSEZFPLoNqSvf+7S6+5wN63aR2C66yrylwneLwcEmzAFazkfhQ8zpQWMgWie8
         XPLLLnQU3qq/T9P9ntQxMUcim2wpUpTW2bK8O2/krTySVH3vFKLd7Aoomvp+Jl2oMeaS
         vbQgUJj+X6kBaCrOhuf2rGLJXjVKMQGnP7PEGjVbe5KI9kcXF3UoRx+nb+TqZC8xF9cE
         /6WA==
MIME-Version: 1.0
X-Received: by 10.60.133.70 with SMTP id pa6mr14027962oeb.13.1424064270598;
 Sun, 15 Feb 2015 21:24:30 -0800 (PST)
Received: by 10.202.64.6 with HTTP; Sun, 15 Feb 2015 21:24:30 -0800 (PST)
In-Reply-To: <CAPh_B=Yo7vApA4S-Yb0yJAqs39oHt+nqf2MyDXXusjVVGpm+KA@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
	<CAPh_B=Yo7vApA4S-Yb0yJAqs39oHt+nqf2MyDXXusjVVGpm+KA@mail.gmail.com>
Date: Mon, 16 Feb 2015 10:54:30 +0530
Message-ID: <CANCoaU7DWn9xgytjAjADRcOu3DNUkiV493-EPg1oM7TQF73_bg@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
From: Niranda Perera <niranda.perera@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b472500fc864f050f2dccb0
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b472500fc864f050f2dccb0
Content-Type: text/plain; charset=UTF-8

Hi Reynold,

Thank you for the response. Could you please clarify the need of Jetty
server inside Spark? Is it used for Spark core functionality or is it there
for Spark jobs UI purposes?

cheers

On Mon, Feb 16, 2015 at 10:47 AM, Reynold Xin <rxin@databricks.com> wrote:

> Most likely no. We are using the embedded mode of Jetty, rather than using
> servlets.
>
> Even if it is possible, you probably wouldn't want to embed Spark in your
> application server ...
>
>
> On Sun, Feb 15, 2015 at 9:08 PM, Niranda Perera <niranda.perera@gmail.com>
> wrote:
>
>> Hi,
>>
>> We are thinking of integrating Spark server inside a product. Our current
>> product uses Tomcat as its webserver.
>>
>> Is it possible to switch the Jetty webserver in Spark to Tomcat
>> off-the-shelf?
>>
>> Cheers
>>
>> --
>> Niranda
>>
>
>


-- 
Niranda

--047d7b472500fc864f050f2dccb0--

From dev-return-11632-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 05:30:37 2015
Return-Path: <dev-return-11632-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EA3A617F9A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 05:30:36 +0000 (UTC)
Received: (qmail 82748 invoked by uid 500); 16 Feb 2015 05:30:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82655 invoked by uid 500); 16 Feb 2015 05:30:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82641 invoked by uid 99); 16 Feb 2015 05:30:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:30:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.216.176] (HELO mail-qc0-f176.google.com) (209.85.216.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 05:30:31 +0000
Received: by mail-qc0-f176.google.com with SMTP id b13so16724541qcw.7
        for <dev@spark.apache.org>; Sun, 15 Feb 2015 21:28:18 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=t2ks2MJCNgrwijcKemJvyis6uoZ+uZNmnc5hx4kY9Pk=;
        b=LSxV2xzA1TRo/1JNgk77D8mLakRe6LlnmwJokyD2uND+O/OkE3RU4IUkK2hD6S/4av
         XZlpV3UUOd9QTW8LKK+7YoVTmnWpnZD8fbP5VeNWfNklU9HTWe9lqTQjoRiUX+UbyVv5
         pstvan9Q6RobbqO+JUKtKe1/rSibGSLrS4s/ALo8Z54TUIv1Xpmf909VxM37v1klrQ/A
         xhUk/DmarNiiUGo7En7osZds0ukL/wX/64LcIBW9rSKRzZvtP5ijcshrW+/UX+ElfiDm
         1EgHc7qkdMNws3T9PLkj3VNJACMEew/6fj5q95kCVYGcQ46Yxq63zkZVVp0OIJewc6/O
         y/hw==
X-Gm-Message-State: ALoCoQkzH+7xVs+CVHayvaVm4m3Hl7KXHd9tCW/DqWWN4KHQpilitK2gvWMvPep5OtI3QtIMzolr
X-Received: by 10.140.151.8 with SMTP id 8mr312523qhx.65.1424064498257; Sun,
 15 Feb 2015 21:28:18 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Sun, 15 Feb 2015 21:27:58 -0800 (PST)
In-Reply-To: <CANCoaU7DWn9xgytjAjADRcOu3DNUkiV493-EPg1oM7TQF73_bg@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
 <CAPh_B=Yo7vApA4S-Yb0yJAqs39oHt+nqf2MyDXXusjVVGpm+KA@mail.gmail.com> <CANCoaU7DWn9xgytjAjADRcOu3DNUkiV493-EPg1oM7TQF73_bg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 15 Feb 2015 21:27:58 -0800
Message-ID: <CAPh_B=YV780oB6jgOhObgYD4OtAdH2nMejrnvaX-m+_daKZCzQ@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Niranda Perera <niranda.perera@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113538628e663f050f2dda57
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113538628e663f050f2dda57
Content-Type: text/plain; charset=UTF-8

Mostly UI.

However, we are also using Jetty as a file server I believe (for
distributing files from the driver to workers).


On Sun, Feb 15, 2015 at 9:24 PM, Niranda Perera <niranda.perera@gmail.com>
wrote:

> Hi Reynold,
>
> Thank you for the response. Could you please clarify the need of Jetty
> server inside Spark? Is it used for Spark core functionality or is it there
> for Spark jobs UI purposes?
>
> cheers
>
> On Mon, Feb 16, 2015 at 10:47 AM, Reynold Xin <rxin@databricks.com> wrote:
>
>> Most likely no. We are using the embedded mode of Jetty, rather than
>> using servlets.
>>
>> Even if it is possible, you probably wouldn't want to embed Spark in your
>> application server ...
>>
>>
>> On Sun, Feb 15, 2015 at 9:08 PM, Niranda Perera <niranda.perera@gmail.com
>> > wrote:
>>
>>> Hi,
>>>
>>> We are thinking of integrating Spark server inside a product. Our current
>>> product uses Tomcat as its webserver.
>>>
>>> Is it possible to switch the Jetty webserver in Spark to Tomcat
>>> off-the-shelf?
>>>
>>> Cheers
>>>
>>> --
>>> Niranda
>>>
>>
>>
>
>
> --
> Niranda
>

--001a113538628e663f050f2dda57--

From dev-return-11633-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 11:23:55 2015
Return-Path: <dev-return-11633-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 44CE21089B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 11:23:55 +0000 (UTC)
Received: (qmail 37567 invoked by uid 500); 16 Feb 2015 11:23:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37495 invoked by uid 500); 16 Feb 2015 11:23:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37483 invoked by uid 99); 16 Feb 2015 11:23:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 11:23:53 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 11:23:27 +0000
Received: by mail-wi0-f180.google.com with SMTP id h11so25487495wiw.1
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 03:21:56 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=7Q31Qd1+9VxG8+LgP3cQ2NT+ohZXCrCplfQ1CowRxMk=;
        b=ZNtg44wIrGo0Jww4WR4XSeN1o3BkiRtDU/CpP3l7tjjkTBruOh78nLRLc7v5KhZhzB
         tFZAANAj2eMIk/Y28yVavH8uscFhYQDFgPpAWaXJTcxNTJ+EeUneZ06Jy/1O0I9BbTsB
         K1tXAxaQ1aYmYFKZu5XXYuUOBtbVCJaRmMdPwY5y7nueR5QAZDod9BZc7XqnK+CV2MZ8
         PUVKpg6SK3lZ30QhqvIoVgBLXMuqKpWJI1HwPlK5hK/j9Jun4suVCI6F7DeNG2zhfMr6
         2t7fAcO+jUmn1/DlLCjKg8i+q6y9+7xE5A71HmpmqM/flG6qrXH7VYzxowXELhSRjxDV
         1qWg==
X-Gm-Message-State: ALoCoQmcUL5K9wbeEIjisLQpMeTGcJnIW/+polRwwkotaVea+S9hzsD6zSePzCkp7nahcHLeUmSO
X-Received: by 10.194.60.77 with SMTP id f13mr49785295wjr.105.1424085716476;
 Mon, 16 Feb 2015 03:21:56 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Mon, 16 Feb 2015 03:21:36 -0800 (PST)
In-Reply-To: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 16 Feb 2015 11:21:36 +0000
Message-ID: <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Niranda Perera <niranda.perera@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

There's no particular reason you have to remove the embedded Jetty
server, right? it doesn't prevent you from using it inside another app
that happens to run in Tomcat. You won't be able to switch it out
without rewriting a fair bit of code, no, but you don't need to.

On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
<niranda.perera@gmail.com> wrote:
> Hi,
>
> We are thinking of integrating Spark server inside a product. Our current
> product uses Tomcat as its webserver.
>
> Is it possible to switch the Jetty webserver in Spark to Tomcat
> off-the-shelf?
>
> Cheers
>
> --
> Niranda

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11634-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 12:28:05 2015
Return-Path: <dev-return-11634-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D9DC010ABC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 12:28:05 +0000 (UTC)
Received: (qmail 59590 invoked by uid 500); 16 Feb 2015 12:28:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59514 invoked by uid 500); 16 Feb 2015 12:28:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59502 invoked by uid 99); 16 Feb 2015 12:28:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 12:28:04 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 12:27:59 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01D049E4.0AF46C8A"
Subject: HiveContext cannot be serialized
Date: Mon, 16 Feb 2015 20:27:36 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: HiveContext cannot be serialized
Thread-Index: AdBJ4/KC6x1Z6CaGSTqbay5DPqldUw==
From: "Haopu Wang" <HWang@qilinsoft.com>
To: <dev@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01D049E4.0AF46C8A
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

When I'm investigating this issue (in the end of this email), I take a
look at HiveContext's code and find this change
(https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):

=20

-  @transient protected[hive] lazy val hiveconf =3D new
HiveConf(classOf[SessionState])

-  @transient protected[hive] lazy val sessionState =3D {

-    val ss =3D new SessionState(hiveconf)

-    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
initial set of HiveConf.

-    ss

-  }

+  @transient protected[hive] lazy val (hiveconf, sessionState) =3D

+    Option(SessionState.get())

+      .orElse {

=20

With the new change, Scala compiler always generate a Tuple2 field of
HiveContext as below:

=20

    private Tuple2 x$3;

    private transient OutputStream outputBuffer;

    private transient HiveConf hiveconf;

    private transient SessionState sessionState;

    private transient HiveMetastoreCatalog catalog;

=20

That "x$3" field's key is HiveConf object that cannot be serialized. So
can you suggest how to resolve this issue? Thank you very much!

=20

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D

=20

I have a streaming application which registered temp table on a
HiveContext for each batch duration.

The application runs well in Spark 1.1.0. But I get below error from
1.1.1.

Do you have any suggestions to resolve it? Thank you!

=20

java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf

    - field (class "scala.Tuple2", name: "_1", type: "class
java.lang.Object")

    - object (class "scala.Tuple2", (Configuration: core-default.xml,
core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23,org.apa
che.hadoop.hive.ql.session.SessionState@49b6eef9))

    - field (class "org.apache.spark.sql.hive.HiveContext", name: "x$3",
type: "class scala.Tuple2")

    - object (class "org.apache.spark.sql.hive.HiveContext",
org.apache.spark.sql.hive.HiveContext@4e6e66a4)

    - field (class
"example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
"sqlContext$1", type: "class org.apache.spark.sql.SQLContext")

   - object (class
"example.BaseQueryableDStream$$anonfun$registerTempTable$2",
<function1>)

    - field (class
"org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
name: "foreachFunc$1", type: "interface scala.Function1")

    - object (class
"org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
<function2>)

    - field (class "org.apache.spark.streaming.dstream.ForEachDStream",
name: "org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
type: "interface scala.Function2")

    - object (class "org.apache.spark.streaming.dstream.ForEachDStream",
org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)

    - element of array (index: 0)

    - array (class "[Ljava.lang.Object;", size: 16)

    - field (class "scala.collection.mutable.ArrayBuffer", name:
"array", type: "class [Ljava.lang.Object;")

    - object (class "scala.collection.mutable.ArrayBuffer",
ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20))

    - field (class "org.apache.spark.streaming.DStreamGraph", name:
"outputStreams", type: "class scala.collection.mutable.ArrayBuffer")

    - custom writeObject data (class
"org.apache.spark.streaming.DStreamGraph")

    - object (class "org.apache.spark.streaming.DStreamGraph",
org.apache.spark.streaming.DStreamGraph@776ae7da)

    - field (class "org.apache.spark.streaming.Checkpoint", name:
"graph", type: "class org.apache.spark.streaming.DStreamGraph")

    - root object (class "org.apache.spark.streaming.Checkpoint",
org.apache.spark.streaming.Checkpoint@5eade065)

    at java.io.ObjectOutputStream.writeObject0(Unknown Source)

=20

=20

=20


------_=_NextPart_001_01D049E4.0AF46C8A--

From dev-return-11635-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 16:42:38 2015
Return-Path: <dev-return-11635-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DDC73106DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 16:42:37 +0000 (UTC)
Received: (qmail 35187 invoked by uid 500); 16 Feb 2015 16:42:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35107 invoked by uid 500); 16 Feb 2015 16:42:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 3396 invoked by uid 99); 16 Feb 2015 16:33:53 -0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:message-id:mime-version:from:to:subject
         :importance:date:content-type;
        bh=wRpeJrFzC9MwO+Zkrb/GE9oTcPxOuiFrMI6XdOJOfFg=;
        b=hujltbmikSaQI0POVwXfxzTzAC/HynS+qCNraGFtdIYBRnEkqAVBcOIjWRiwr1jBM8
         MH0HViAbsQpjrKf+2VknAtqKjmn1UrrBDDZAZxVj3ttlkf2KD8LtvYG3W9uR7/FAreBU
         m0P0QF94b5Ivqjc/DW/94u3M3Zso3XQW2hrwVVxeuyEDtFocATwNb/77N2cw1K2M+usZ
         BfNSdWlRwZHCUvS/aPh49w9lzSk8w6nTmKvtZj+vSztEfnnwRQWRm0dfbsumMJuhfy0V
         eie2wK3l7Tlg2A2Jyglo8vYTzgNMmV/K1MAQzcZDGfEap0uUcCTXwcHGrcudoSwcCg4z
         y6Yg==
X-Gm-Message-State: ALoCoQmvNTNoOPG97PzOkAq1TDBXiQDsELq0Vzx3GFbn/sfaW+c5YazkOjEOAy9+sZ1i+eQ9fO0V
X-Received: by 10.140.91.131 with SMTP id z3mr591430qgd.1.1424104341096;
        Mon, 16 Feb 2015 08:32:21 -0800 (PST)
Message-ID: <54e21b94.d115e00a.5696.ffffc833@mx.google.com>
MIME-Version: 1.0
From: =?utf-8?Q?Mark_Payne?= <mapayn3@g.uky.edu>
To: "=?utf-8?Q?dev@spark.apache.org?=" <dev@spark.apache.org>
Subject: =?utf-8?Q?Spark_Receivers?=
Importance: Normal
Date: Mon, 16 Feb 2015 16:22:08 +0000
Content-Type: multipart/alternative;
	boundary="_0FA54C8C-1B69-4080-B5F0-EB6F93D3955A_"
X-Virus-Checked: Checked by ClamAV on apache.org

--_0FA54C8C-1B69-4080-B5F0-EB6F93D3955A_
Content-Transfer-Encoding: base64
Content-Type: text/plain; charset="utf-8"

SGVsbG8sDQoNCg0KSSBhbSBvbmUgb2YgdGhlIGNvbW1pdHRlcnMgZm9yIEFwYWNoZSBOaUZpIChp
bmN1YmF0aW5nKS4gSSBhbSBsb29raW5nIHRvIGludGVncmF0ZSBOaUZpIHdpdGggU3Bhcmsgc3Ry
ZWFtaW5nLiBJIGhhdmUgY3JlYXRlZCBhIGN1c3RvbSBSZWNlaXZlciB0byByZWNlaXZlIGRhdGEg
ZnJvbSBOaUZpLiBJ4oCZdmUgdGVzdGVkIGl0IGxvY2FsbHksIGFuZCB0aGluZ3Mgc2VlbSB0byB3
b3JrIHdlbGwuDQoNCg0KSSBmZWVsIGl0IHdvdWxkIG1ha2UgbW9yZSBzZW5zZSB0byBoYXZlIHRo
ZSBOaUZpIFJlY2VpdmVyIGluIHRoZSBTcGFyayBjb2RlYmFzZSBhbG9uZyBzaWRlIHRoZSBjb2Rl
IGZvciBGbHVtZSwgS2Fma2EsIGV0Yy4sIGFzIHRoaXMgaXMgd2hlcmUgcGVvcGxlIGFyZSBtb3Jl
IGxpa2VseSB0byBsb29rIHRvIHNlZSB3aGF0IGludGVncmF0aW9ucyBhcmUgYXZhaWxhYmxlLiBM
b29raW5nIHRoZXJlLCB0aG91Z2gsIGl0IHNlZW1zIHRoYXQgYWxsIG9mIHRob3NlIGFyZSDigJxm
dWxseSBpbnRlZ3JhdGVk4oCdIGludG8gU3BhcmssIHJhdGhlciB0aGFuIGJlaW5nIHNpbXBsZSBS
ZWNlaXZlcnMuDQoNCg0KSXMgU3BhcmsgaW50ZXJlc3RlZCBpbiBob3VzaW5nIHRoZSBjb2RlIGZv
ciBSZWNlaXZlcnMgdG8gaW50ZXJhY3Qgd2l0aCBvdGhlciBzZXJ2aWNlcywgb3Igc2hvdWxkIHRo
aXMganVzdCByZXNpZGUgaW4gdGhlIE5pRmkgY29kZWJhc2U/DQoNCg0KVGhhbmtzIGZvciBhbnkg
cG9pbnRlcnMNCg0KLU1hcms=

--_0FA54C8C-1B69-4080-B5F0-EB6F93D3955A_--


From dev-return-11636-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 18:44:37 2015
Return-Path: <dev-return-11636-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6613E10CDC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 18:44:37 +0000 (UTC)
Received: (qmail 54963 invoked by uid 500); 16 Feb 2015 18:44:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54887 invoked by uid 500); 16 Feb 2015 18:44:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54876 invoked by uid 99); 16 Feb 2015 18:44:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:44:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:44:25 +0000
Received: by labhz20 with SMTP id hz20so31369220lab.0
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 10:42:13 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Q52gcC1XfXOYiuwo6tWmjErBt3Lqu0UZF3i4+0EANV4=;
        b=XcikjvLDIJl8ijX/z4bnf6eR+exlmri87aNCSpXvAJfNXpuZM7MUb9FFIvVcO/Ijkk
         5TuSEegWt0ptuMuCUgQdRnk86tJENUD55W9GO1e71kmb/31gjs/sC5cJt/SDgOe5Dn/w
         0ljcVTDjyG325oUZbmEsT7vd8rHMmtbkWor8abAuWKo7bQjU7x9auZ9gzBrHageiiNoN
         VQSidAfWIE55A7dcnKmMSeZz3PFIy52hkKW2L7XayAvE5eyoi/iexJ5SGA7wSqKHmQTg
         FT4VBg6ZbjozkPqKHcAg1RqUiVXV8VHxFrWcC+8sR3xvA9fw5FZgYBWVw7dZBQqDNoZL
         6FCw==
X-Gm-Message-State: ALoCoQlW9lzsLlx5iM85OZTj/wgyU69H/kzWPovDIPb4jGy4CKrvdGKUd8jXGE0d2ks945hKNKEu
X-Received: by 10.152.18.133 with SMTP id w5mr24482923lad.51.1424112133597;
 Mon, 16 Feb 2015 10:42:13 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.213.18 with HTTP; Mon, 16 Feb 2015 10:41:53 -0800 (PST)
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
From: Michael Armbrust <michael@databricks.com>
Date: Mon, 16 Feb 2015 10:41:53 -0800
Message-ID: <CAAswR-4MG+GC_ogBqZJuoJ_m-1KB9E2-a_6b4Ee=eWS4OKc2rA@mail.gmail.com>
Subject: Re: HiveContext cannot be serialized
To: Haopu Wang <HWang@qilinsoft.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493d40d7ffc7050f38f117
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493d40d7ffc7050f38f117
Content-Type: text/plain; charset=UTF-8

I'd suggest marking the HiveContext as @transient since its not valid to
use it on the slaves anyway.

On Mon, Feb 16, 2015 at 4:27 AM, Haopu Wang <HWang@qilinsoft.com> wrote:

> When I'm investigating this issue (in the end of this email), I take a
> look at HiveContext's code and find this change
> (https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
> da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):
>
>
>
> -  @transient protected[hive] lazy val hiveconf = new
> HiveConf(classOf[SessionState])
>
> -  @transient protected[hive] lazy val sessionState = {
>
> -    val ss = new SessionState(hiveconf)
>
> -    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
> initial set of HiveConf.
>
> -    ss
>
> -  }
>
> +  @transient protected[hive] lazy val (hiveconf, sessionState) =
>
> +    Option(SessionState.get())
>
> +      .orElse {
>
>
>
> With the new change, Scala compiler always generate a Tuple2 field of
> HiveContext as below:
>
>
>
>     private Tuple2 x$3;
>
>     private transient OutputStream outputBuffer;
>
>     private transient HiveConf hiveconf;
>
>     private transient SessionState sessionState;
>
>     private transient HiveMetastoreCatalog catalog;
>
>
>
> That "x$3" field's key is HiveConf object that cannot be serialized. So
> can you suggest how to resolve this issue? Thank you very much!
>
>
>
> ================================
>
>
>
> I have a streaming application which registered temp table on a
> HiveContext for each batch duration.
>
> The application runs well in Spark 1.1.0. But I get below error from
> 1.1.1.
>
> Do you have any suggestions to resolve it? Thank you!
>
>
>
> java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf
>
>     - field (class "scala.Tuple2", name: "_1", type: "class
> java.lang.Object")
>
>     - object (class "scala.Tuple2", (Configuration: core-default.xml,
> core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
> yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
> org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23,org.apa
> che.hadoop.hive.ql.session.SessionState@49b6eef9))
>
>     - field (class "org.apache.spark.sql.hive.HiveContext", name: "x$3",
> type: "class scala.Tuple2")
>
>     - object (class "org.apache.spark.sql.hive.HiveContext",
> org.apache.spark.sql.hive.HiveContext@4e6e66a4)
>
>     - field (class
> "example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
> "sqlContext$1", type: "class org.apache.spark.sql.SQLContext")
>
>    - object (class
> "example.BaseQueryableDStream$$anonfun$registerTempTable$2",
> <function1>)
>
>     - field (class
> "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> name: "foreachFunc$1", type: "interface scala.Function1")
>
>     - object (class
> "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> <function2>)
>
>     - field (class "org.apache.spark.streaming.dstream.ForEachDStream",
> name: "org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
> type: "interface scala.Function2")
>
>     - object (class "org.apache.spark.streaming.dstream.ForEachDStream",
> org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)
>
>     - element of array (index: 0)
>
>     - array (class "[Ljava.lang.Object;", size: 16)
>
>     - field (class "scala.collection.mutable.ArrayBuffer", name:
> "array", type: "class [Ljava.lang.Object;")
>
>     - object (class "scala.collection.mutable.ArrayBuffer",
> ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20))
>
>     - field (class "org.apache.spark.streaming.DStreamGraph", name:
> "outputStreams", type: "class scala.collection.mutable.ArrayBuffer")
>
>     - custom writeObject data (class
> "org.apache.spark.streaming.DStreamGraph")
>
>     - object (class "org.apache.spark.streaming.DStreamGraph",
> org.apache.spark.streaming.DStreamGraph@776ae7da)
>
>     - field (class "org.apache.spark.streaming.Checkpoint", name:
> "graph", type: "class org.apache.spark.streaming.DStreamGraph")
>
>     - root object (class "org.apache.spark.streaming.Checkpoint",
> org.apache.spark.streaming.Checkpoint@5eade065)
>
>     at java.io.ObjectOutputStream.writeObject0(Unknown Source)
>
>
>
>
>
>
>
>

--089e01493d40d7ffc7050f38f117--

From dev-return-11637-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 18:46:45 2015
Return-Path: <dev-return-11637-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D6FA610CEB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 18:46:45 +0000 (UTC)
Received: (qmail 62128 invoked by uid 500); 16 Feb 2015 18:46:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62055 invoked by uid 500); 16 Feb 2015 18:46:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62043 invoked by uid 99); 16 Feb 2015 18:46:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:46:44 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nobigdealstyle@gmail.com designates 209.85.160.178 as permitted sender)
Received: from [209.85.160.178] (HELO mail-yk0-f178.google.com) (209.85.160.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:46:40 +0000
Received: by mail-yk0-f178.google.com with SMTP id 19so13895950ykq.9
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 10:46:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=Sz1gYVRwrfMbPLyrhBJ9EiGQEeKJ4fnhALALZuxjNNY=;
        b=waCoNceRwuYPF1FloJmUzKch6FtVD3FjG7gZPJ5DKegqmGMJAwwkxEc2s8btfoTUHj
         WtgQRkNp3YwXvY7NdZuedLBZslnc4zgf8Uf/AVEjayW6NlKKU+Uk6rlny+4Dw0vv56MM
         Npthd2iE0vOGqSZurDa5DoJv6hcNxyJoYSY0WOJM9WKG0tHUVHcaF6OdTi+8LWt5CsxT
         26zvAEjDh7XcOaUZAeuTvxDYj2uEGcUocbuTxr9+LG6ZoK4xrrabeWntrjiZelWDHmHd
         KOnLgrZV01hb3t8u+ljznH83Lthse/OsQD08+kQWB187zfe1L2oPXAc/jjsW2IDJVIno
         x4mA==
X-Received: by 10.170.44.80 with SMTP id 77mr19325870ykm.101.1424112379509;
 Mon, 16 Feb 2015 10:46:19 -0800 (PST)
MIME-Version: 1.0
References: <CAOhmDzdzL+D6-YuWwk6e=JcjJZ4pqMJyg+zJVXZeo7GO-PrGyA@mail.gmail.com>
 <CACkSZy3MAt22t1XQrkfax8g3At6Uea9S7uJMB0ViCy5-pDMu=w@mail.gmail.com>
 <CAOhmDzebSdPA_WOzq=QaehUn2iUAnbC0nGfQ0Np5C79PTUNxPg@mail.gmail.com>
 <CAOhmDzfG7GABey-tJG-AgOQuWWXbECdk1j-ZQakvYO=x2gPg=Q@mail.gmail.com> <CAOhmDzdt90-V7Q+UiDwOD=wbyrVGO9H3g65j4YOH0BFa=ng_7g@mail.gmail.com>
From: Ryan Williams <ryan.blake.williams@gmail.com>
Date: Mon, 16 Feb 2015 18:46:18 +0000
Message-ID: <CANeJXFNn4ZtFYeCKtwsLM=pZAHW29ejqUNJiYeA2gO3N8oH7sA@mail.gmail.com>
Subject: Re: Building Spark with Pants
To: Nicholas Chammas <nicholas.chammas@gmail.com>, Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1137a05e8043b9050f39007a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1137a05e8043b9050f39007a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I worked on Pants at Foursquare for a while and when coming up to speed on
Spark was interested in the possibility of building it with Pants,
particularly because allowing developers to share/reuse each others'
compilation artifacts seems like it would be a boon to productivity; that
was/is Pants' "killer feature" for Foursquare, as mentioned on the
pants-devel thread.

Given the monumental nature of the task of making Spark build with Pants,
most of my enthusiasm was deflected to SPARK-1517
<https://issues.apache.org/jira/browse/SPARK-1517>, which deals with
publishing nightly builds (or better, exposing all assembly JARs built by
Jenkins?) that people could use rather than having to assemble their own.

Anyway, it's an intriguing idea, Nicholas, I'm glad you are pursuing it!

On Sat Feb 14 2015 at 4:21:16 AM Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> FYI: Here is the matching discussion over on the Pants dev list.
> <https://groups.google.com/forum/#!topic/pants-devel/rTaU-iIOIFE>
>
> On Mon Feb 02 2015 at 4:50:33 PM Nicholas Chammas
> nicholas.chammas@gmail.com
> <http://mailto:nicholas.chammas@gmail.com> wrote:
>
> To reiterate, I'm asking from an experimental perspective. I'm not
> > proposing we change Spark to build with Pants or anything like that.
> >
> > I'm interested in trying Pants out and I'm wondering if anyone else
> shares
> > my interest or already has experience with Pants that they can share.
> >
> > On Mon Feb 02 2015 at 4:40:45 PM Nicholas Chammas <
> > nicholas.chammas@gmail.com> wrote:
> >
> >> I'm asking from an experimental standpoint; this is not happening
> anytime
> >> soon.
> >>
> >> Of course, if the experiment turns out very well, Pants would replace
> >> both sbt and Maven (like it has at Twitter, for example). Pants also
> works
> >> with IDEs <http://pantsbuild.github.io/index.html#using-pants-with>.
> >>
> >> On Mon Feb 02 2015 at 4:33:11 PM Stephen Boesch <javadba@gmail.com>
> >> wrote:
> >>
> >>> There is a significant investment in sbt and maven - and they are not
> at
> >>> all likely to be going away. A third build tool?  Note that there is
> also
> >>> the perspective of building within an IDE - which actually works
> presently
> >>> for sbt and with a little bit of tweaking with maven as well.
> >>>
> >>> 2015-02-02 16:25 GMT-08:00 Nicholas Chammas <
> nicholas.chammas@gmail.com>
> >>> :
> >>>
> >>>> Does anyone here have experience with Pants
> >>>>
> >>> <http://pantsbuild.github.io/index.html> or interest in trying to
> build
> >>>
> >>>
> >>>> Spark with it?
> >>>>
> >>>> Pants has an interesting story. It was born at Twitter to help them
> >>>> build
> >>>> their Scala, Java, and Python projects as several independent
> >>>> components in
> >>>> one monolithic repo. (It was inspired by a similar build tool at
> Google
> >>>> called blaze.) The mix of languages and sub-projects at Twitter seem=
s
> >>>> similar to the breakdown we have in Spark.
> >>>>
> >>>> Pants has an interesting take on how a build system should work, and
> >>>> Twitter and Foursquare (who use Pants as their primary build tool)
> >>>> claim it
> >>>> helps enforce better build hygiene and maintainability.
> >>>>
> >>>> Some relevant talks:
> >>>>
> >>>>    - Building Scala Hygienically with Pants
> >>>>    <https://www.youtube.com/watch?v=3Dukqke8iTuH0>
> >>>>    - The Pants Build Tool at Twitter
> >>>>    <https://engineering.twitter.com/university/videos/the-pant
> >>>> s-build-tool-at-twitter>
> >>>>    - Getting Started with the Pants Build System: Why Pants?
> >>>>    <https://engineering.twitter.com/university/videos/getting-
> >>>> started-with-the-pants-build-system-why-pants>
> >>>
> >>>
> >>>>
> >>>> At some point I may take a shot at converting Spark to use Pants as =
an
> >>>> experiment and just see what it=E2=80=99s like.
> >>>>
> >>>> Nick
> >>>> =E2=80=8B
> >>>>
> >>> =E2=80=8B
>

--001a1137a05e8043b9050f39007a--

From dev-return-11638-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 18:50:04 2015
Return-Path: <dev-return-11638-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D1AE10D04
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 18:50:04 +0000 (UTC)
Received: (qmail 71353 invoked by uid 500); 16 Feb 2015 18:49:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71275 invoked by uid 500); 16 Feb 2015 18:49:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71263 invoked by uid 99); 16 Feb 2015 18:49:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:49:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.48] (HELO mail-qa0-f48.google.com) (209.85.216.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:49:22 +0000
Received: by mail-qa0-f48.google.com with SMTP id dc16so17744819qab.7
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 10:47:30 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ZRNVGgYDPZpyZj6gT86zB+Jae1ZeCjaZKOvhtVTr6VQ=;
        b=ZeKGrI8OY6AX5nkrKJ77Zn/7qXwFUDuwlzR3vkw+mSTh34DgxsbAnaEHCqNDzBvhEU
         ErSrhQXHSlrz8SRSz4i/vJt3qZ69fDGramp53Jxxp3/dRKZCxpvcIdKNlV0IT3/ZQZc0
         3T+UmnL3ikbOdXltOTLM2hzZAZIypqoI2Onanx06GJJeUviBP7R62mUYWaijllfvQN7N
         U7AWpIfYpEorVR1USLoCv/5Rw5wWnbXBgeVa9iqxH1a0ggVjL0D+Sv7xyR1/F3XIilz3
         4qR/TSnnCRGRP82pbtu8vpfwlceNXZVH6Gv/BECxtQuJf876mrsdIXqaegVeTBLRrFog
         ok7Q==
X-Gm-Message-State: ALoCoQlc4lj4vtWRK5hKYNb66HNd7bXMZgR2cMXnRg+SP+KyK9EDlOxvE89OtShUbz5FfhDmCtLT
X-Received: by 10.140.34.9 with SMTP id k9mr291820qgk.95.1424112450038; Mon,
 16 Feb 2015 10:47:30 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Mon, 16 Feb 2015 10:47:09 -0800 (PST)
In-Reply-To: <CAAswR-4MG+GC_ogBqZJuoJ_m-1KB9E2-a_6b4Ee=eWS4OKc2rA@mail.gmail.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
 <CAAswR-4MG+GC_ogBqZJuoJ_m-1KB9E2-a_6b4Ee=eWS4OKc2rA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 16 Feb 2015 10:47:09 -0800
Message-ID: <CAPh_B=Y9GJi-f7m7nZpMbTGLJ=4w=YDEx5gQmfKJ3gts4v5rcg@mail.gmail.com>
Subject: Re: HiveContext cannot be serialized
To: Michael Armbrust <michael@databricks.com>
Cc: Haopu Wang <HWang@qilinsoft.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1070eb481cd050f39048c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1070eb481cd050f39048c
Content-Type: text/plain; charset=UTF-8

Michael - it is already transient. This should probably considered a bug in
the scala compiler, but we can easily work around it by removing the use of
destructuring binding.

On Mon, Feb 16, 2015 at 10:41 AM, Michael Armbrust <michael@databricks.com>
wrote:

> I'd suggest marking the HiveContext as @transient since its not valid to
> use it on the slaves anyway.
>
> On Mon, Feb 16, 2015 at 4:27 AM, Haopu Wang <HWang@qilinsoft.com> wrote:
>
> > When I'm investigating this issue (in the end of this email), I take a
> > look at HiveContext's code and find this change
> > (https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
> > da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):
> >
> >
> >
> > -  @transient protected[hive] lazy val hiveconf = new
> > HiveConf(classOf[SessionState])
> >
> > -  @transient protected[hive] lazy val sessionState = {
> >
> > -    val ss = new SessionState(hiveconf)
> >
> > -    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
> > initial set of HiveConf.
> >
> > -    ss
> >
> > -  }
> >
> > +  @transient protected[hive] lazy val (hiveconf, sessionState) =
> >
> > +    Option(SessionState.get())
> >
> > +      .orElse {
> >
> >
> >
> > With the new change, Scala compiler always generate a Tuple2 field of
> > HiveContext as below:
> >
> >
> >
> >     private Tuple2 x$3;
> >
> >     private transient OutputStream outputBuffer;
> >
> >     private transient HiveConf hiveconf;
> >
> >     private transient SessionState sessionState;
> >
> >     private transient HiveMetastoreCatalog catalog;
> >
> >
> >
> > That "x$3" field's key is HiveConf object that cannot be serialized. So
> > can you suggest how to resolve this issue? Thank you very much!
> >
> >
> >
> > ================================
> >
> >
> >
> > I have a streaming application which registered temp table on a
> > HiveContext for each batch duration.
> >
> > The application runs well in Spark 1.1.0. But I get below error from
> > 1.1.1.
> >
> > Do you have any suggestions to resolve it? Thank you!
> >
> >
> >
> > java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf
> >
> >     - field (class "scala.Tuple2", name: "_1", type: "class
> > java.lang.Object")
> >
> >     - object (class "scala.Tuple2", (Configuration: core-default.xml,
> > core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
> > yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
> > org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23,org.apa
> > che.hadoop.hive.ql.session.SessionState@49b6eef9))
> >
> >     - field (class "org.apache.spark.sql.hive.HiveContext", name: "x$3",
> > type: "class scala.Tuple2")
> >
> >     - object (class "org.apache.spark.sql.hive.HiveContext",
> > org.apache.spark.sql.hive.HiveContext@4e6e66a4)
> >
> >     - field (class
> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
> > "sqlContext$1", type: "class org.apache.spark.sql.SQLContext")
> >
> >    - object (class
> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2",
> > <function1>)
> >
> >     - field (class
> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> > name: "foreachFunc$1", type: "interface scala.Function1")
> >
> >     - object (class
> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> > <function2>)
> >
> >     - field (class "org.apache.spark.streaming.dstream.ForEachDStream",
> > name: "org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
> > type: "interface scala.Function2")
> >
> >     - object (class "org.apache.spark.streaming.dstream.ForEachDStream",
> > org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)
> >
> >     - element of array (index: 0)
> >
> >     - array (class "[Ljava.lang.Object;", size: 16)
> >
> >     - field (class "scala.collection.mutable.ArrayBuffer", name:
> > "array", type: "class [Ljava.lang.Object;")
> >
> >     - object (class "scala.collection.mutable.ArrayBuffer",
> > ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20))
> >
> >     - field (class "org.apache.spark.streaming.DStreamGraph", name:
> > "outputStreams", type: "class scala.collection.mutable.ArrayBuffer")
> >
> >     - custom writeObject data (class
> > "org.apache.spark.streaming.DStreamGraph")
> >
> >     - object (class "org.apache.spark.streaming.DStreamGraph",
> > org.apache.spark.streaming.DStreamGraph@776ae7da)
> >
> >     - field (class "org.apache.spark.streaming.Checkpoint", name:
> > "graph", type: "class org.apache.spark.streaming.DStreamGraph")
> >
> >     - root object (class "org.apache.spark.streaming.Checkpoint",
> > org.apache.spark.streaming.Checkpoint@5eade065)
> >
> >     at java.io.ObjectOutputStream.writeObject0(Unknown Source)
> >
> >
> >
> >
> >
> >
> >
> >
>

--001a11c1070eb481cd050f39048c--

From dev-return-11639-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 19:00:26 2015
Return-Path: <dev-return-11639-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DF86F10D48
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 19:00:26 +0000 (UTC)
Received: (qmail 93180 invoked by uid 500); 16 Feb 2015 19:00:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93101 invoked by uid 500); 16 Feb 2015 19:00:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93089 invoked by uid 99); 16 Feb 2015 19:00:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 19:00:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 18:59:57 +0000
Received: by lbvp9 with SMTP id p9so328752lbv.0
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 10:59:35 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=CJsudhFpoG2g8DyVXP3oNG1T5WaD/IibSl+RPwM0Odo=;
        b=Igt/HGp/E5apDyD0ghv97j4nqFI01xXs4uecptGETalCEFz1/1/4UG/khdaiAE8fQL
         3231Md6/pm8ijQzluPcpnwS5OuDAOYGB/1hm8SGDDbZ8not7sQSKe2c3z76ffb60wz7v
         5cH9wt7Jg1OTlNHv39r4vdfNqj1mP43CNxg1laRDyRGK3Hg7jHEeUl9ancPW8/xkqsvZ
         SGJn1//kByFyx5+NdUnHQo3gveqjD2vnLaBnEyNO/JyaDWpuyXM02gXUqDUIhc13Tqgk
         jFX2iV9+noi9N8UVEvk19iRJLszNE3v3OPuOpGDZNkMLNt799LEtpM6yWnCq1IHYbU4l
         LZYA==
X-Gm-Message-State: ALoCoQlL/2WHB6g5Rqb0SiM+/8nBMPMBiteM3mrIHBrgjjqBYvYFLzjNG3BkCfibxXS7rqiIK4nj
X-Received: by 10.152.18.133 with SMTP id w5mr24582603lad.51.1424113175367;
 Mon, 16 Feb 2015 10:59:35 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.213.18 with HTTP; Mon, 16 Feb 2015 10:59:15 -0800 (PST)
In-Reply-To: <CAPh_B=Y9GJi-f7m7nZpMbTGLJ=4w=YDEx5gQmfKJ3gts4v5rcg@mail.gmail.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
 <CAAswR-4MG+GC_ogBqZJuoJ_m-1KB9E2-a_6b4Ee=eWS4OKc2rA@mail.gmail.com> <CAPh_B=Y9GJi-f7m7nZpMbTGLJ=4w=YDEx5gQmfKJ3gts4v5rcg@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Mon, 16 Feb 2015 10:59:15 -0800
Message-ID: <CAAswR-6ZvvoCe6Yen_mq=ihOfK6navMb2AOPGwVeH2EO0cm0yQ@mail.gmail.com>
Subject: Re: HiveContext cannot be serialized
To: Reynold Xin <rxin@databricks.com>
Cc: Haopu Wang <HWang@qilinsoft.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493d40f01b1f050f392f71
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493d40f01b1f050f392f71
Content-Type: text/plain; charset=UTF-8

I was suggesting you mark the variable that is holding the HiveContext
'@transient' since the scala compiler is not correctly propagating this
through the tuple extraction.  This is only a workaround.  We can also
remove the tuple extraction.

On Mon, Feb 16, 2015 at 10:47 AM, Reynold Xin <rxin@databricks.com> wrote:

> Michael - it is already transient. This should probably considered a bug
> in the scala compiler, but we can easily work around it by removing the use
> of destructuring binding.
>
> On Mon, Feb 16, 2015 at 10:41 AM, Michael Armbrust <michael@databricks.com
> > wrote:
>
>> I'd suggest marking the HiveContext as @transient since its not valid to
>> use it on the slaves anyway.
>>
>> On Mon, Feb 16, 2015 at 4:27 AM, Haopu Wang <HWang@qilinsoft.com> wrote:
>>
>> > When I'm investigating this issue (in the end of this email), I take a
>> > look at HiveContext's code and find this change
>> > (
>> https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
>> > da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):
>> >
>> >
>> >
>> > -  @transient protected[hive] lazy val hiveconf = new
>> > HiveConf(classOf[SessionState])
>> >
>> > -  @transient protected[hive] lazy val sessionState = {
>> >
>> > -    val ss = new SessionState(hiveconf)
>> >
>> > -    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
>> > initial set of HiveConf.
>> >
>> > -    ss
>> >
>> > -  }
>> >
>> > +  @transient protected[hive] lazy val (hiveconf, sessionState) =
>> >
>> > +    Option(SessionState.get())
>> >
>> > +      .orElse {
>> >
>> >
>> >
>> > With the new change, Scala compiler always generate a Tuple2 field of
>> > HiveContext as below:
>> >
>> >
>> >
>> >     private Tuple2 x$3;
>> >
>> >     private transient OutputStream outputBuffer;
>> >
>> >     private transient HiveConf hiveconf;
>> >
>> >     private transient SessionState sessionState;
>> >
>> >     private transient HiveMetastoreCatalog catalog;
>> >
>> >
>> >
>> > That "x$3" field's key is HiveConf object that cannot be serialized. So
>> > can you suggest how to resolve this issue? Thank you very much!
>> >
>> >
>> >
>> > ================================
>> >
>> >
>> >
>> > I have a streaming application which registered temp table on a
>> > HiveContext for each batch duration.
>> >
>> > The application runs well in Spark 1.1.0. But I get below error from
>> > 1.1.1.
>> >
>> > Do you have any suggestions to resolve it? Thank you!
>> >
>> >
>> >
>> > java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf
>> >
>> >     - field (class "scala.Tuple2", name: "_1", type: "class
>> > java.lang.Object")
>> >
>> >     - object (class "scala.Tuple2", (Configuration: core-default.xml,
>> > core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
>> > yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
>> > org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23
>> ,org.apa
>> > che.hadoop.hive.ql.session.SessionState@49b6eef9))
>> >
>> >     - field (class "org.apache.spark.sql.hive.HiveContext", name: "x$3",
>> > type: "class scala.Tuple2")
>> >
>> >     - object (class "org.apache.spark.sql.hive.HiveContext",
>> > org.apache.spark.sql.hive.HiveContext@4e6e66a4)
>> >
>> >     - field (class
>> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
>> > "sqlContext$1", type: "class org.apache.spark.sql.SQLContext")
>> >
>> >    - object (class
>> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2",
>> > <function1>)
>> >
>> >     - field (class
>> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
>> > name: "foreachFunc$1", type: "interface scala.Function1")
>> >
>> >     - object (class
>> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
>> > <function2>)
>> >
>> >     - field (class "org.apache.spark.streaming.dstream.ForEachDStream",
>> > name: "org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
>> > type: "interface scala.Function2")
>> >
>> >     - object (class "org.apache.spark.streaming.dstream.ForEachDStream",
>> > org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)
>> >
>> >     - element of array (index: 0)
>> >
>> >     - array (class "[Ljava.lang.Object;", size: 16)
>> >
>> >     - field (class "scala.collection.mutable.ArrayBuffer", name:
>> > "array", type: "class [Ljava.lang.Object;")
>> >
>> >     - object (class "scala.collection.mutable.ArrayBuffer",
>> > ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20
>> ))
>> >
>> >     - field (class "org.apache.spark.streaming.DStreamGraph", name:
>> > "outputStreams", type: "class scala.collection.mutable.ArrayBuffer")
>> >
>> >     - custom writeObject data (class
>> > "org.apache.spark.streaming.DStreamGraph")
>> >
>> >     - object (class "org.apache.spark.streaming.DStreamGraph",
>> > org.apache.spark.streaming.DStreamGraph@776ae7da)
>> >
>> >     - field (class "org.apache.spark.streaming.Checkpoint", name:
>> > "graph", type: "class org.apache.spark.streaming.DStreamGraph")
>> >
>> >     - root object (class "org.apache.spark.streaming.Checkpoint",
>> > org.apache.spark.streaming.Checkpoint@5eade065)
>> >
>> >     at java.io.ObjectOutputStream.writeObject0(Unknown Source)
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>
>

--089e01493d40f01b1f050f392f71--

From dev-return-11640-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 16 19:46:09 2015
Return-Path: <dev-return-11640-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 173FF10FA3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 16 Feb 2015 19:46:09 +0000 (UTC)
Received: (qmail 83089 invoked by uid 500); 16 Feb 2015 19:46:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83016 invoked by uid 500); 16 Feb 2015 19:46:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82994 invoked by uid 99); 16 Feb 2015 19:46:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 19:46:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 16 Feb 2015 19:45:42 +0000
Received: by mail-qa0-f54.google.com with SMTP id x12so23487442qac.13
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 11:43:51 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=6g9/aCPr2+ueCq4xxZSUo4ks2/uKpkMPVrZhJXvOGFo=;
        b=gmxyp/TTQgOwAQp3ffeiV1r1awDaT9eHiPZWTukA9sJuIl0L43xv2O1Xi8S64/TGY0
         uLDg7ogccRBSaelgPUZCHPoOAAYZfcQ7gL82FBjuY1Z8QI6GObJdFSQR0EU13H34wORI
         Jq7ZrpgF7r2kWMfSXTJgjNIT02buZcAYLjXxDIaTk7LgtDli1lD2ni6jyJAUmwVSyPuR
         Ndi5Oz+hI07ofNIwLbrew4gWoPe99Nuw2P+5axA362o9jMVovlas+YezSEdvA5uYaauQ
         B3DEz+PSf8hItSo7fnBqOxNNqP8GdQUtnjJXHLmGFJ3gEMC+T+Sm8YQO5ChjNe7sSiG+
         bmXw==
X-Gm-Message-State: ALoCoQnsKE0KHEtFcjkx8QiA0L0uP4QBeOoGLnxJARdITtFi/tFuf7+5kwVOTzfBE2xAVFZOReFB
X-Received: by 10.140.145.12 with SMTP id 12mr1668587qhr.51.1424115830823;
 Mon, 16 Feb 2015 11:43:50 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Mon, 16 Feb 2015 11:43:30 -0800 (PST)
In-Reply-To: <CAAswR-6ZvvoCe6Yen_mq=ihOfK6navMb2AOPGwVeH2EO0cm0yQ@mail.gmail.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD728@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
 <CAAswR-4MG+GC_ogBqZJuoJ_m-1KB9E2-a_6b4Ee=eWS4OKc2rA@mail.gmail.com>
 <CAPh_B=Y9GJi-f7m7nZpMbTGLJ=4w=YDEx5gQmfKJ3gts4v5rcg@mail.gmail.com> <CAAswR-6ZvvoCe6Yen_mq=ihOfK6navMb2AOPGwVeH2EO0cm0yQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 16 Feb 2015 11:43:30 -0800
Message-ID: <CAPh_B=Y0+L1-pOdGdwDfCHyfw=f-K+bMfnqMBNWiEtrENjanew@mail.gmail.com>
Subject: Re: HiveContext cannot be serialized
To: Michael Armbrust <michael@databricks.com>
Cc: Haopu Wang <HWang@qilinsoft.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11355a7e3730f5050f39ce22
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11355a7e3730f5050f39ce22
Content-Type: text/plain; charset=UTF-8

I submitted a patch

https://github.com/apache/spark/pull/4628

On Mon, Feb 16, 2015 at 10:59 AM, Michael Armbrust <michael@databricks.com>
wrote:

> I was suggesting you mark the variable that is holding the HiveContext
> '@transient' since the scala compiler is not correctly propagating this
> through the tuple extraction.  This is only a workaround.  We can also
> remove the tuple extraction.
>
> On Mon, Feb 16, 2015 at 10:47 AM, Reynold Xin <rxin@databricks.com> wrote:
>
>> Michael - it is already transient. This should probably considered a bug
>> in the scala compiler, but we can easily work around it by removing the use
>> of destructuring binding.
>>
>> On Mon, Feb 16, 2015 at 10:41 AM, Michael Armbrust <
>> michael@databricks.com> wrote:
>>
>>> I'd suggest marking the HiveContext as @transient since its not valid to
>>> use it on the slaves anyway.
>>>
>>> On Mon, Feb 16, 2015 at 4:27 AM, Haopu Wang <HWang@qilinsoft.com> wrote:
>>>
>>> > When I'm investigating this issue (in the end of this email), I take a
>>> > look at HiveContext's code and find this change
>>> > (
>>> https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
>>> > da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):
>>> >
>>> >
>>> >
>>> > -  @transient protected[hive] lazy val hiveconf = new
>>> > HiveConf(classOf[SessionState])
>>> >
>>> > -  @transient protected[hive] lazy val sessionState = {
>>> >
>>> > -    val ss = new SessionState(hiveconf)
>>> >
>>> > -    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
>>> > initial set of HiveConf.
>>> >
>>> > -    ss
>>> >
>>> > -  }
>>> >
>>> > +  @transient protected[hive] lazy val (hiveconf, sessionState) =
>>> >
>>> > +    Option(SessionState.get())
>>> >
>>> > +      .orElse {
>>> >
>>> >
>>> >
>>> > With the new change, Scala compiler always generate a Tuple2 field of
>>> > HiveContext as below:
>>> >
>>> >
>>> >
>>> >     private Tuple2 x$3;
>>> >
>>> >     private transient OutputStream outputBuffer;
>>> >
>>> >     private transient HiveConf hiveconf;
>>> >
>>> >     private transient SessionState sessionState;
>>> >
>>> >     private transient HiveMetastoreCatalog catalog;
>>> >
>>> >
>>> >
>>> > That "x$3" field's key is HiveConf object that cannot be serialized. So
>>> > can you suggest how to resolve this issue? Thank you very much!
>>> >
>>> >
>>> >
>>> > ================================
>>> >
>>> >
>>> >
>>> > I have a streaming application which registered temp table on a
>>> > HiveContext for each batch duration.
>>> >
>>> > The application runs well in Spark 1.1.0. But I get below error from
>>> > 1.1.1.
>>> >
>>> > Do you have any suggestions to resolve it? Thank you!
>>> >
>>> >
>>> >
>>> > java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf
>>> >
>>> >     - field (class "scala.Tuple2", name: "_1", type: "class
>>> > java.lang.Object")
>>> >
>>> >     - object (class "scala.Tuple2", (Configuration: core-default.xml,
>>> > core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
>>> > yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
>>> > org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23
>>> ,org.apa
>>> > che.hadoop.hive.ql.session.SessionState@49b6eef9))
>>> >
>>> >     - field (class "org.apache.spark.sql.hive.HiveContext", name:
>>> "x$3",
>>> > type: "class scala.Tuple2")
>>> >
>>> >     - object (class "org.apache.spark.sql.hive.HiveContext",
>>> > org.apache.spark.sql.hive.HiveContext@4e6e66a4)
>>> >
>>> >     - field (class
>>> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
>>> > "sqlContext$1", type: "class org.apache.spark.sql.SQLContext")
>>> >
>>> >    - object (class
>>> > "example.BaseQueryableDStream$$anonfun$registerTempTable$2",
>>> > <function1>)
>>> >
>>> >     - field (class
>>> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
>>> > name: "foreachFunc$1", type: "interface scala.Function1")
>>> >
>>> >     - object (class
>>> > "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
>>> > <function2>)
>>> >
>>> >     - field (class "org.apache.spark.streaming.dstream.ForEachDStream",
>>> > name: "org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
>>> > type: "interface scala.Function2")
>>> >
>>> >     - object (class
>>> "org.apache.spark.streaming.dstream.ForEachDStream",
>>> > org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)
>>> >
>>> >     - element of array (index: 0)
>>> >
>>> >     - array (class "[Ljava.lang.Object;", size: 16)
>>> >
>>> >     - field (class "scala.collection.mutable.ArrayBuffer", name:
>>> > "array", type: "class [Ljava.lang.Object;")
>>> >
>>> >     - object (class "scala.collection.mutable.ArrayBuffer",
>>> > ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20
>>> ))
>>> >
>>> >     - field (class "org.apache.spark.streaming.DStreamGraph", name:
>>> > "outputStreams", type: "class scala.collection.mutable.ArrayBuffer")
>>> >
>>> >     - custom writeObject data (class
>>> > "org.apache.spark.streaming.DStreamGraph")
>>> >
>>> >     - object (class "org.apache.spark.streaming.DStreamGraph",
>>> > org.apache.spark.streaming.DStreamGraph@776ae7da)
>>> >
>>> >     - field (class "org.apache.spark.streaming.Checkpoint", name:
>>> > "graph", type: "class org.apache.spark.streaming.DStreamGraph")
>>> >
>>> >     - root object (class "org.apache.spark.streaming.Checkpoint",
>>> > org.apache.spark.streaming.Checkpoint@5eade065)
>>> >
>>> >     at java.io.ObjectOutputStream.writeObject0(Unknown Source)
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>>
>>
>>
>

--001a11355a7e3730f5050f39ce22--

From dev-return-11641-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 00:45:23 2015
Return-Path: <dev-return-11641-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EBAA31726C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 00:45:23 +0000 (UTC)
Received: (qmail 77561 invoked by uid 500); 17 Feb 2015 00:45:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77483 invoked by uid 500); 17 Feb 2015 00:45:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77472 invoked by uid 99); 17 Feb 2015 00:45:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 00:45:22 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 00:45:18 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01D04A4B.0BEDB5F8"
Subject: RE: HiveContext cannot be serialized
Date: Tue, 17 Feb 2015 08:44:54 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F1AD72A@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
In-Reply-To: <CAPh_B=Y0+L1-pOdGdwDfCHyfw=f-K+bMfnqMBNWiEtrENjanew@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: HiveContext cannot be serialized
Thread-Index: AdBKIP2boMqglKtiRU+PDy7TxDvdrgAKURHQ
From: "Haopu Wang" <HWang@qilinsoft.com>
To: "Reynold Xin" <rxin@databricks.com>,
	"Michael Armbrust" <michael@databricks.com>
Cc: <dev@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01D04A4B.0BEDB5F8
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Reynold and Michael, thank you so much for the quick response.

=20

This problem also happens on branch-1.1, would you mind resolving it on
branch-1.1 also? Thanks again!

=20

________________________________

From: Reynold Xin [mailto:rxin@databricks.com]=20
Sent: Tuesday, February 17, 2015 3:44 AM
To: Michael Armbrust
Cc: Haopu Wang; dev@spark.apache.org
Subject: Re: HiveContext cannot be serialized

=20

I submitted a patch

=20

https://github.com/apache/spark/pull/4628

=20

On Mon, Feb 16, 2015 at 10:59 AM, Michael Armbrust
<michael@databricks.com> wrote:

I was suggesting you mark the variable that is holding the HiveContext
'@transient' since the scala compiler is not correctly propagating this
through the tuple extraction.  This is only a workaround.  We can also
remove the tuple extraction.

=20

On Mon, Feb 16, 2015 at 10:47 AM, Reynold Xin <rxin@databricks.com>
wrote:

Michael - it is already transient. This should probably considered a bug
in the scala compiler, but we can easily work around it by removing the
use of destructuring binding.

=20

On Mon, Feb 16, 2015 at 10:41 AM, Michael Armbrust
<michael@databricks.com> wrote:

I'd suggest marking the HiveContext as @transient since its not valid to
use it on the slaves anyway.


On Mon, Feb 16, 2015 at 4:27 AM, Haopu Wang <HWang@qilinsoft.com> wrote:

> When I'm investigating this issue (in the end of this email), I take a
> look at HiveContext's code and find this change
>
(https://github.com/apache/spark/commit/64945f868443fbc59cb34b34c16d782d
> da0fb63d#diff-ff50aea397a607b79df9bec6f2a841db):
>
>
>
> -  @transient protected[hive] lazy val hiveconf =3D new
> HiveConf(classOf[SessionState])
>
> -  @transient protected[hive] lazy val sessionState =3D {
>
> -    val ss =3D new SessionState(hiveconf)
>
> -    setConf(hiveconf.getAllProperties)  // Have SQLConf pick up the
> initial set of HiveConf.
>
> -    ss
>
> -  }
>
> +  @transient protected[hive] lazy val (hiveconf, sessionState) =3D
>
> +    Option(SessionState.get())
>
> +      .orElse {
>
>
>
> With the new change, Scala compiler always generate a Tuple2 field of
> HiveContext as below:
>
>
>
>     private Tuple2 x$3;
>
>     private transient OutputStream outputBuffer;
>
>     private transient HiveConf hiveconf;
>
>     private transient SessionState sessionState;
>
>     private transient HiveMetastoreCatalog catalog;
>
>
>
> That "x$3" field's key is HiveConf object that cannot be serialized.
So
> can you suggest how to resolve this issue? Thank you very much!
>
>
>
> =
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D
>
>
>
> I have a streaming application which registered temp table on a
> HiveContext for each batch duration.
>
> The application runs well in Spark 1.1.0. But I get below error from
> 1.1.1.
>
> Do you have any suggestions to resolve it? Thank you!
>
>
>
> java.io.NotSerializableException: org.apache.hadoop.hive.conf.HiveConf
>
>     - field (class "scala.Tuple2", name: "_1", type: "class
> java.lang.Object")
>
>     - object (class "scala.Tuple2", (Configuration: core-default.xml,
> core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml,
> yarn-site.xml, hdfs-default.xml, hdfs-site.xml,
>
org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@2158ce23,org.apa
> che.hadoop.hive.ql.session.SessionState@49b6eef9))
>
>     - field (class "org.apache.spark.sql.hive.HiveContext", name:
"x$3",
> type: "class scala.Tuple2")
>
>     - object (class "org.apache.spark.sql.hive.HiveContext",
> org.apache.spark.sql.hive.HiveContext@4e6e66a4)
>
>     - field (class
> "example.BaseQueryableDStream$$anonfun$registerTempTable$2", name:
> "sqlContext$1", type: "class org.apache.spark.sql.SQLContext")
>
>    - object (class
> "example.BaseQueryableDStream$$anonfun$registerTempTable$2",
> <function1>)
>
>     - field (class
> "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> name: "foreachFunc$1", type: "interface scala.Function1")
>
>     - object (class
> "org.apache.spark.streaming.dstream.DStream$$anonfun$foreachRDD$1",
> <function2>)
>
>     - field (class
"org.apache.spark.streaming.dstream.ForEachDStream",
> name:
"org$apache$spark$streaming$dstream$ForEachDStream$$foreachFunc",
> type: "interface scala.Function2")
>
>     - object (class
"org.apache.spark.streaming.dstream.ForEachDStream",
> org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20)
>
>     - element of array (index: 0)
>
>     - array (class "[Ljava.lang.Object;", size: 16)
>
>     - field (class "scala.collection.mutable.ArrayBuffer", name:
> "array", type: "class [Ljava.lang.Object;")
>
>     - object (class "scala.collection.mutable.ArrayBuffer",
>
ArrayBuffer(org.apache.spark.streaming.dstream.ForEachDStream@5ccbdc20))
>
>     - field (class "org.apache.spark.streaming.DStreamGraph", name:
> "outputStreams", type: "class scala.collection.mutable.ArrayBuffer")
>
>     - custom writeObject data (class
> "org.apache.spark.streaming.DStreamGraph")
>
>     - object (class "org.apache.spark.streaming.DStreamGraph",
> org.apache.spark.streaming.DStreamGraph@776ae7da)
>
>     - field (class "org.apache.spark.streaming.Checkpoint", name:
> "graph", type: "class org.apache.spark.streaming.DStreamGraph")
>
>     - root object (class "org.apache.spark.streaming.Checkpoint",
> org.apache.spark.streaming.Checkpoint@5eade065)
>
>     at java.io.ObjectOutputStream.writeObject0(Unknown Source)
>
>
>
>
>
>
>
>

=20

=20

=20


------_=_NextPart_001_01D04A4B.0BEDB5F8--

From dev-return-11642-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 06:41:53 2015
Return-Path: <dev-return-11642-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 445EA1782E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 06:41:53 +0000 (UTC)
Received: (qmail 21539 invoked by uid 500); 17 Feb 2015 06:41:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21459 invoked by uid 500); 17 Feb 2015 06:41:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21441 invoked by uid 99); 17 Feb 2015 06:41:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 06:41:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_FILL_THIS_FORM_SHORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of qiuzhuang.lian@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 06:41:24 +0000
Received: by mail-ob0-f171.google.com with SMTP id gq1so50075771obb.2
        for <dev@spark.apache.org>; Mon, 16 Feb 2015 22:39:53 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=s2T1U8+EVKUO59Llx1jcrNpqPfFsu+mqjCmPZ1AhXJU=;
        b=V29BF4DcZpzl9DJJKuhW1plo6LtJk0vhkj14/t5af/cbD0/jaClKKimzu5TE++7hZl
         84zxdhXL4tdEjOilQwm/uzW2bDtDfh5Q2b36+HWPVIO3cwYTNWxOQyD0OLTSl6Powfi5
         bXeQcysOrJpMkTTmfLIthUnjHZi//xGxi2OkB1zjvPa3bG2VbsqUxmEdP0qt9sgEeSqU
         KZePL4oVQbSzGZd0kGekmeO9Qo1NFttRB/SAGWCnDVFSHF2QQ49lE+lAbbczVgJ4sf/W
         yXto1Nh62AojsUShgv2Xr1wiUT1AoN2WyTV3katQf8ZpXOdGyfulbyGJJ4XmErTtslQp
         +iNw==
MIME-Version: 1.0
X-Received: by 10.202.186.85 with SMTP id k82mr16444856oif.69.1424155193001;
 Mon, 16 Feb 2015 22:39:53 -0800 (PST)
Received: by 10.76.40.2 with HTTP; Mon, 16 Feb 2015 22:39:52 -0800 (PST)
Date: Tue, 17 Feb 2015 14:39:52 +0800
Message-ID: <CABKvOWtKqO2B=+up-n2LdjawTv+yxJTLUYcfRezvSE2Y8i+_sg@mail.gmail.com>
Subject: org.apache.spark.sql.sources.DDLException: Unsupported dataType:
 [1.1] failure: ``varchar'' expected but identifier char found in spark-sql
From: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a113cdeba624c73050f42f872
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cdeba624c73050f42f872
Content-Type: text/plain; charset=UTF-8

Hi,

I am not sure this has been reported already or not, I run into this error
under spark-sql shell as build from newest of spark git trunk,

spark-sql> describe qiuzhuang_hcatlog_import;
15/02/17 14:38:36 ERROR SparkSQLDriver: Failed in [describe
qiuzhuang_hcatlog_import]
org.apache.spark.sql.sources.DDLException: Unsupported dataType: [1.1]
failure: ``varchar'' expected but identifier char found

char(32)
^
at org.apache.spark.sql.sources.DDLParser.parseType(ddl.scala:52)
at
org.apache.spark.sql.hive.MetastoreRelation$SchemaAttribute.toAttribute(HiveMetastoreCatalog.scala:664)
at
org.apache.spark.sql.hive.MetastoreRelation$$anonfun$23.apply(HiveMetastoreCatalog.scala:674)
at
org.apache.spark.sql.hive.MetastoreRelation$$anonfun$23.apply(HiveMetastoreCatalog.scala:674)
at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
at scala.collection.Iterator$class.foreach(Iterator.scala:727)
at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
at scala.collection.AbstractTraversable.map(Traversable.scala:105)
at
org.apache.spark.sql.hive.MetastoreRelation.<init>(HiveMetastoreCatalog.scala:674)
at
org.apache.spark.sql.hive.HiveMetastoreCatalog.lookupRelation(HiveMetastoreCatalog.scala:185)
at org.apache.spark.sql.hive.HiveContext$$anon$2.org
$apache$spark$sql$catalyst$analysis$OverrideCatalog$$super$lookupRelation(HiveContext.scala:234)

As in hive 0.131, console, this commands works,

hive> describe qiuzhuang_hcatlog_import;
OK
id                      char(32)
assistant_no            varchar(20)
assistant_name          varchar(32)
assistant_type          int
grade                   int
shop_no                 varchar(20)
shop_name               varchar(64)
organ_no                varchar(20)
organ_name              varchar(20)
entry_date              string
education               int
commission              decimal(8,2)
tel                     varchar(20)
address                 varchar(100)
identity_card           varchar(25)
sex                     int
birthday                string
employee_type           int
status                  int
remark                  varchar(255)
create_user_no          varchar(20)
create_user             varchar(32)
create_time             string
update_user_no          varchar(20)
update_user             varchar(32)
update_time             string
Time taken: 0.49 seconds, Fetched: 26 row(s)
hive>


Regards,
Qiuzhuang

--001a113cdeba624c73050f42f872--

From dev-return-11643-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 14:38:58 2015
Return-Path: <dev-return-11643-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 828E310AAA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 14:38:58 +0000 (UTC)
Received: (qmail 91270 invoked by uid 500); 17 Feb 2015 14:38:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91207 invoked by uid 500); 17 Feb 2015 14:38:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91019 invoked by uid 99); 17 Feb 2015 14:38:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 14:38:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of josh@soundcloud.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 14:36:39 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so53531689obc.1
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 06:36:37 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=4UQvUCsjoy0cMA4Y6b4MsT+L2RB/Q1OEqdniQr+hHeU=;
        b=Xn53+d1sRw1lrUQT5kNVpWyLy0DiGafxHC+rqja7fCf0/yrggmj7m/ZFbsoufMGY2W
         Zk+7C6maV8qELWkPyWjVt5SiTfmuyKQaEagZUF9WXClk7m/kyoxrKIO4qXaHa6Sw9mYv
         dNKsg8celM5JQvktY8+Tu9vZyhNCf2tEGtTV86OL9ZyciG6oxvTkPwl+wY8b4RwbdwVB
         9YSaqN0xfvD+8CyggrYjvK0OrH0o8KqmS5ElTPuritFw6yWP5Bz4EiRJdT9kWzMK6Riw
         qEBbWNL7yddi2JKcwp61KqSm/sKTkX00E1bLABlBq/eXaRHcqaEQj4zngIJdwgO30cDY
         2p6g==
X-Gm-Message-State: ALoCoQkXY8XhYKS906qkRagehtqlha5LHSVvLCwL29SxJ42U0ijXeepqUKyqBnhu7SeeDlkcuZt/
X-Received: by 10.182.84.137 with SMTP id z9mr19056265oby.61.1424183797540;
 Tue, 17 Feb 2015 06:36:37 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.230.200 with HTTP; Tue, 17 Feb 2015 06:36:17 -0800 (PST)
In-Reply-To: <CAH5MZvM-egTZNRtxquQT=adRM_xOObDXS5D-8rfPKkErXE4+yQ@mail.gmail.com>
References: <CAH5MZvM-egTZNRtxquQT=adRM_xOObDXS5D-8rfPKkErXE4+yQ@mail.gmail.com>
From: Josh Devins <josh@soundcloud.com>
Date: Tue, 17 Feb 2015 15:36:17 +0100
Message-ID: <CAH5MZvMBjqOST-9Nr9k1z1rUODfSiczr_fV9kwqDFqAMNLC2Zw@mail.gmail.com>
Subject: Fwd: [MLlib] Performance problem in GeneralizedLinearAlgorithm
To: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Cross-posting as I got no response on the users mailing list last
week. Any response would be appreciated :)

Josh


---------- Forwarded message ----------
From: Josh Devins <josh@soundcloud.com>
Date: 9 February 2015 at 15:59
Subject: [MLlib] Performance problem in GeneralizedLinearAlgorithm
To: "user@spark.apache.org" <user@spark.apache.org>


I've been looking into a performance problem when using
LogisticRegressionWithLBFGS (and in turn GeneralizedLinearAlgorithm).
Here's an outline of what I've figured out so far and it would be
great to get some confirmation of the problem, some input on how
wide-spread this problem might be and any ideas on a nice way to fix
this.

Context:
- I will reference `branch-1.1` as we are currently on v1.1.1 however
this appears to still be a problem on `master`
- The cluster is run on YARN, on bare-metal hardware (no VMs)
- I've not filed a Jira issue yet but can do so
- This problem affects all algorithms based on
GeneralizedLinearAlgorithm (GLA) that use feature scaling (and less so
when not, but still a problem) (e.g. LogisticRegressionWithLBFGS)

Problem Outline:
- Starting at GLA line 177
(https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L177),
a feature scaler is created using the `input` RDD
- Refer next to line 186 which then maps over the `input` RDD and
produces a new `data` RDD
(https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L186)
- If you are using feature scaling or adding intercepts, the user
`input` RDD has been mapped over *after* the user has persisted it
(hopefully) and *before* going into the (iterative) optimizer on line
204 (https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L204)
- Since the RDD `data` that is iterated over in the optimizer is
unpersisted, when we are running the cost function in the optimizer
(e.g. LBFGS -- https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/optimization/LBFGS.scala#L198),
the map phase will actually first go back and rerun the feature
scaling (map tasks on `input`) and then map with the cost function
(two maps pipelined into one stage)
- As a result, parts of the StandardScaler will actually be run again
(perhaps only because the variable is `lazy`?) and this can be costly,
see line 84 (https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/feature/StandardScaler.scala#L84)
- For small datasets and/or few iterations, this is not really a
problem, however we found that by adding a `data.persist()` right
before running the optimizer, we went from map iterations in the
optimizer that went from 5:30 down to 0:45

I had a very tough time coming up with a nice way to describe my
debugging sessions in an email so I hope this gets the main points
across. Happy to clarify anything if necessary (also by live
debugging/Skype/phone if that's helpful).

Thanks,

Josh

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11644-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 16:28:01 2015
Return-Path: <dev-return-11644-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B62B710FDB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 16:28:01 +0000 (UTC)
Received: (qmail 69587 invoked by uid 500); 17 Feb 2015 16:28:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69509 invoked by uid 500); 17 Feb 2015 16:28:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 69497 invoked by uid 99); 17 Feb 2015 16:28:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:28:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.172 as permitted sender)
Received: from [209.85.220.172] (HELO mail-vc0-f172.google.com) (209.85.220.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:27:56 +0000
Received: by mail-vc0-f172.google.com with SMTP id kv7so12808498vcb.3
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 08:26:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=5XpC7X4Cnmd21jqerDW4Fgm5oY1YWivmuqEYsbNB4wk=;
        b=dNVYAueKqXtWSmQk8+UYJ5ai+m8rRdw1DaRHIASUkLoVQV5+nQLyPqQ3doomFfYrP1
         DF/SRbPoY449AzYCp5AEJxlWU1843XOIdjACAIngMwWACjFUlFWI1HQFREZ7AYjCpW3Z
         9h/RZfzUM49sYBTEW5CE/LT4BArGR1pa484iWK1hfFNRRJvY8OM48U6aqagzzVzRyfDU
         GgmxY+0C49+LZjawjoV2g05xfugkLtuOeyOnsyge6CJHENLgPcj47TASpBHIH1qWHmPG
         PvMTWtewWRLOeIcrPpmklOv400QrreAvrkpIqOTJIchBiVsHugT95BZ0fw4MyGP0vSbn
         yq5w==
X-Received: by 10.221.64.73 with SMTP id xh9mr19562629vcb.71.1424190365201;
 Tue, 17 Feb 2015 08:26:05 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Tue, 17 Feb 2015 08:25:45 -0800 (PST)
In-Reply-To: <CAH5MZvMBjqOST-9Nr9k1z1rUODfSiczr_fV9kwqDFqAMNLC2Zw@mail.gmail.com>
References: <CAH5MZvM-egTZNRtxquQT=adRM_xOObDXS5D-8rfPKkErXE4+yQ@mail.gmail.com>
 <CAH5MZvMBjqOST-9Nr9k1z1rUODfSiczr_fV9kwqDFqAMNLC2Zw@mail.gmail.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Tue, 17 Feb 2015 08:25:45 -0800
Message-ID: <CABjXkq6WktsYSgMHj3efHy8SWQ0YRt=ehErmTmQ7z5YYOJp9Fg@mail.gmail.com>
Subject: Re: [MLlib] Performance problem in GeneralizedLinearAlgorithm
To: Josh Devins <josh@soundcloud.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11332a10cf7938050f4b281d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11332a10cf7938050f4b281d
Content-Type: text/plain; charset=UTF-8

Josh - thanks for the detailed write up - this seems a little funny to me.
I agree that with the current code path there is extra work being done than
needs to be (e.g. the features are re-scaled at every iteration, but the
relatively costly process of fitting the StandardScaler should not be
re-done at each iteration. Instead, at each iteration, all points are
re-scaled according to the pre-computed standard-deviations in the
StandardScalerModel, and then an intercept is appended.

Just to be clear - you're currently calling .persist() before you pass data
to LogisticRegressionWithLBFGS?

Also - can you give some parameters about the problem/cluster size you're
solving this on? How much memory per node? How big are n and d, what is its
sparsity (if any) and how many iterations are you running for? Is 0:45 the
per-iteration time or total time for some number of iterations?

A useful test might be to call GeneralizedLinearAlgorithm useFeatureScaling
set to false (and maybe also addIntercept set to false) on persisted data,
and see if you see the same performance wins. If that's the case we've
isolated the issue and can start profiling to see where all the time is
going.

It would be great if you can open a JIRA.

Thanks!



On Tue, Feb 17, 2015 at 6:36 AM, Josh Devins <josh@soundcloud.com> wrote:

> Cross-posting as I got no response on the users mailing list last
> week. Any response would be appreciated :)
>
> Josh
>
>
> ---------- Forwarded message ----------
> From: Josh Devins <josh@soundcloud.com>
> Date: 9 February 2015 at 15:59
> Subject: [MLlib] Performance problem in GeneralizedLinearAlgorithm
> To: "user@spark.apache.org" <user@spark.apache.org>
>
>
> I've been looking into a performance problem when using
> LogisticRegressionWithLBFGS (and in turn GeneralizedLinearAlgorithm).
> Here's an outline of what I've figured out so far and it would be
> great to get some confirmation of the problem, some input on how
> wide-spread this problem might be and any ideas on a nice way to fix
> this.
>
> Context:
> - I will reference `branch-1.1` as we are currently on v1.1.1 however
> this appears to still be a problem on `master`
> - The cluster is run on YARN, on bare-metal hardware (no VMs)
> - I've not filed a Jira issue yet but can do so
> - This problem affects all algorithms based on
> GeneralizedLinearAlgorithm (GLA) that use feature scaling (and less so
> when not, but still a problem) (e.g. LogisticRegressionWithLBFGS)
>
> Problem Outline:
> - Starting at GLA line 177
> (
> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L177
> ),
> a feature scaler is created using the `input` RDD
> - Refer next to line 186 which then maps over the `input` RDD and
> produces a new `data` RDD
> (
> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L186
> )
> - If you are using feature scaling or adding intercepts, the user
> `input` RDD has been mapped over *after* the user has persisted it
> (hopefully) and *before* going into the (iterative) optimizer on line
> 204 (
> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L204
> )
> - Since the RDD `data` that is iterated over in the optimizer is
> unpersisted, when we are running the cost function in the optimizer
> (e.g. LBFGS --
> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/optimization/LBFGS.scala#L198
> ),
> the map phase will actually first go back and rerun the feature
> scaling (map tasks on `input`) and then map with the cost function
> (two maps pipelined into one stage)
> - As a result, parts of the StandardScaler will actually be run again
> (perhaps only because the variable is `lazy`?) and this can be costly,
> see line 84 (
> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/feature/StandardScaler.scala#L84
> )
> - For small datasets and/or few iterations, this is not really a
> problem, however we found that by adding a `data.persist()` right
> before running the optimizer, we went from map iterations in the
> optimizer that went from 5:30 down to 0:45
>
> I had a very tough time coming up with a nice way to describe my
> debugging sessions in an email so I hope this gets the main points
> across. Happy to clarify anything if necessary (also by live
> debugging/Skype/phone if that's helpful).
>
> Thanks,
>
> Josh
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11332a10cf7938050f4b281d--

From dev-return-11645-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 16:32:49 2015
Return-Path: <dev-return-11645-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4481B17220
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 16:32:49 +0000 (UTC)
Received: (qmail 89258 invoked by uid 500); 17 Feb 2015 16:32:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89186 invoked by uid 500); 17 Feb 2015 16:32:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89174 invoked by uid 99); 17 Feb 2015 16:32:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:32:37 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of petro.rudenko@gmail.com designates 209.85.217.171 as permitted sender)
Received: from [209.85.217.171] (HELO mail-lb0-f171.google.com) (209.85.217.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:32:12 +0000
Received: by lbiz11 with SMTP id z11so5534934lbi.8
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 08:31:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:to:references:from:message-id:date:user-agent:mime-version
         :in-reply-to:content-type:content-transfer-encoding;
        bh=QS4GQFeusQnLaYpvtmir5uMdCkzHmNG9bbmTjPPzkMc=;
        b=m2UmzYhv7TVZB14jRpJ8zO1kD17J+fhsmay+5nCC3LLzWjuDDydYAMtIe875MuG9IH
         8JPZBgjb8STHJtnvd4da5UY0FG08PSLNTbrf9sK85XwHRP9AXJJF0rMDH3XIhqXToB8J
         wTA3zLWGWZMUihFcH3eNDnbMWHjNyLxaF45vhu5gUIEEwVmee83A7wa9L8VwU9YtH8TL
         cMjRn/RX1mODQLuSznWdgIsWynj+99JRWQ3o6L/hPqcj8cKXYqQqQl78b+dZBkvsR3DR
         3JcOlWurF+FNdG8CY2qsW/ZNeuSGIHLphywlb5fp+KqCMkAvbS7IVabrK5cdvHvrj4gA
         BGVg==
X-Received: by 10.112.65.196 with SMTP id z4mr29545532lbs.28.1424190685975;
        Tue, 17 Feb 2015 08:31:25 -0800 (PST)
Received: from [192.168.1.4] ([5.248.107.224])
        by mx.google.com with ESMTPSA id mu9sm3664582lbb.42.2015.02.17.08.31.24
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 17 Feb 2015 08:31:24 -0800 (PST)
Subject: Re: [MLlib] Performance problem in GeneralizedLinearAlgorithm
To: dev@spark.apache.org
references:
 <CAH5MZvM-egTZNRtxquQT=adRM_xOObDXS5D-8rfPKkErXE4+yQ@mail.gmail.com>
 <CAH5MZvMBjqOST-9Nr9k1z1rUODfSiczr_fV9kwqDFqAMNLC2Zw@mail.gmail.com>
 <CABjXkq6WktsYSgMHj3efHy8SWQ0YRt=ehErmTmQ7z5YYOJp9Fg@mail.gmail.com>
From: Peter Rudenko <petro.rudenko@gmail.com>
message-id: <54E36CDB.1060903@gmail.com>
Date: Tue, 17 Feb 2015 18:31:23 +0200
user-agent:
 Mozilla/5.0 (X11; Linux x86_64; rv:37.0) Gecko/20100101 Thunderbird/37.0a2
mime-version: 1.0
in-reply-to:
 <CABjXkq6WktsYSgMHj3efHy8SWQ0YRt=ehErmTmQ7z5YYOJp9Fg@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

It's fixed today: https://github.com/apache/spark/pull/4593

Thanks,
Peter Rudenko
On 2015-02-17 18:25, Evan R. Sparks wrote:
> Josh - thanks for the detailed write up - this seems a little funny to me.
> I agree that with the current code path there is extra work being done than
> needs to be (e.g. the features are re-scaled at every iteration, but the
> relatively costly process of fitting the StandardScaler should not be
> re-done at each iteration. Instead, at each iteration, all points are
> re-scaled according to the pre-computed standard-deviations in the
> StandardScalerModel, and then an intercept is appended.
>
> Just to be clear - you're currently calling .persist() before you pass data
> to LogisticRegressionWithLBFGS?
>
> Also - can you give some parameters about the problem/cluster size you're
> solving this on? How much memory per node? How big are n and d, what is its
> sparsity (if any) and how many iterations are you running for? Is 0:45 the
> per-iteration time or total time for some number of iterations?
>
> A useful test might be to call GeneralizedLinearAlgorithm useFeatureScaling
> set to false (and maybe also addIntercept set to false) on persisted data,
> and see if you see the same performance wins. If that's the case we've
> isolated the issue and can start profiling to see where all the time is
> going.
>
> It would be great if you can open a JIRA.
>
> Thanks!
>
>
>
> On Tue, Feb 17, 2015 at 6:36 AM, Josh Devins <josh@soundcloud.com> wrote:
>
>> Cross-posting as I got no response on the users mailing list last
>> week. Any response would be appreciated :)
>>
>> Josh
>>
>>
>> ---------- Forwarded message ----------
>> From: Josh Devins <josh@soundcloud.com>
>> Date: 9 February 2015 at 15:59
>> Subject: [MLlib] Performance problem in GeneralizedLinearAlgorithm
>> To: "user@spark.apache.org" <user@spark.apache.org>
>>
>>
>> I've been looking into a performance problem when using
>> LogisticRegressionWithLBFGS (and in turn GeneralizedLinearAlgorithm).
>> Here's an outline of what I've figured out so far and it would be
>> great to get some confirmation of the problem, some input on how
>> wide-spread this problem might be and any ideas on a nice way to fix
>> this.
>>
>> Context:
>> - I will reference `branch-1.1` as we are currently on v1.1.1 however
>> this appears to still be a problem on `master`
>> - The cluster is run on YARN, on bare-metal hardware (no VMs)
>> - I've not filed a Jira issue yet but can do so
>> - This problem affects all algorithms based on
>> GeneralizedLinearAlgorithm (GLA) that use feature scaling (and less so
>> when not, but still a problem) (e.g. LogisticRegressionWithLBFGS)
>>
>> Problem Outline:
>> - Starting at GLA line 177
>> (
>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L177
>> ),
>> a feature scaler is created using the `input` RDD
>> - Refer next to line 186 which then maps over the `input` RDD and
>> produces a new `data` RDD
>> (
>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L186
>> )
>> - If you are using feature scaling or adding intercepts, the user
>> `input` RDD has been mapped over *after* the user has persisted it
>> (hopefully) and *before* going into the (iterative) optimizer on line
>> 204 (
>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L204
>> )
>> - Since the RDD `data` that is iterated over in the optimizer is
>> unpersisted, when we are running the cost function in the optimizer
>> (e.g. LBFGS --
>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/optimization/LBFGS.scala#L198
>> ),
>> the map phase will actually first go back and rerun the feature
>> scaling (map tasks on `input`) and then map with the cost function
>> (two maps pipelined into one stage)
>> - As a result, parts of the StandardScaler will actually be run again
>> (perhaps only because the variable is `lazy`?) and this can be costly,
>> see line 84 (
>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/apache/spark/mllib/feature/StandardScaler.scala#L84
>> )
>> - For small datasets and/or few iterations, this is not really a
>> problem, however we found that by adding a `data.persist()` right
>> before running the optimizer, we went from map iterations in the
>> optimizer that went from 5:30 down to 0:45
>>
>> I had a very tough time coming up with a nice way to describe my
>> debugging sessions in an email so I hope this gets the main points
>> across. Happy to clarify anything if necessary (also by live
>> debugging/Skype/phone if that's helpful).
>>
>> Thanks,
>>
>> Josh
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11646-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 16:36:09 2015
Return-Path: <dev-return-11646-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 564081724A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 16:36:09 +0000 (UTC)
Received: (qmail 98872 invoked by uid 500); 17 Feb 2015 16:35:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98785 invoked by uid 500); 17 Feb 2015 16:35:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98774 invoked by uid 99); 17 Feb 2015 16:35:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:35:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 16:35:49 +0000
Received: by lbiz11 with SMTP id z11so5510218lbi.5
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 08:34:22 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=yjantWPLE3e4IXLHj2YLB+blbNYosAJGULT4SzFXw+0=;
        b=NGgoCXiFZOwuu5sD3W2Vx4SBgVXkMibBUHTkepwUsBxq1sOsUMDXAlZDDrlURYciW6
         ThivcrLOXl1EgazW0m7foiObjoQWMFkl9SzypMzLEa9eLKkdj89IkLke6amPaDYQUAmq
         uitwza1G7TNV5QXA7qbiUy+hgKnrg56iSyrFjxR0jfnXGxJWfsX3rXJh+Qv45GDYQBmu
         4qrp7kU5qAjzGzs5oKLETiJAutNunIBD0cOqNF7e9/DYedxhaAVW9OgYlshZpoynUkcv
         ErWih5TTYI76H5roljI2+LNNsS4TiCsZdg9Zi1M2NWD3Su6YEGymlhBv3a8HLPowSHmM
         tXrQ==
X-Gm-Message-State: ALoCoQm+P9UyS1VM/S6w7x+1Dl4HlkLRj9Iq+FJIa4uCjXMitn5yHITPJ4ZEUMcNsZj5J06lIO36
MIME-Version: 1.0
X-Received: by 10.112.64.2 with SMTP id k2mr30088502lbs.54.1424190861962; Tue,
 17 Feb 2015 08:34:21 -0800 (PST)
Received: by 10.25.86.129 with HTTP; Tue, 17 Feb 2015 08:34:21 -0800 (PST)
In-Reply-To: <CABKvOWtKqO2B=+up-n2LdjawTv+yxJTLUYcfRezvSE2Y8i+_sg@mail.gmail.com>
References: <CABKvOWtKqO2B=+up-n2LdjawTv+yxJTLUYcfRezvSE2Y8i+_sg@mail.gmail.com>
Date: Tue, 17 Feb 2015 08:34:21 -0800
Message-ID: <CAHP0waJMMV8LVOBhAVzf_ELhBSAr9s-nyyAmo_QBxYqVoz+tFw@mail.gmail.com>
Subject: Re: org.apache.spark.sql.sources.DDLException: Unsupported dataType:
 [1.1] failure: ``varchar'' expected but identifier char found in spark-sql
From: Yin Huai <yhuai@databricks.com>
To: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3fc3c6b8b31050f4b4679
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3fc3c6b8b31050f4b4679
Content-Type: text/plain; charset=UTF-8

Hi Quizhuang,

Right now, char is not supported in DDL. Can you try varchar or string?

Thanks,

Yin

On Mon, Feb 16, 2015 at 10:39 PM, Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
wrote:

> Hi,
>
> I am not sure this has been reported already or not, I run into this error
> under spark-sql shell as build from newest of spark git trunk,
>
> spark-sql> describe qiuzhuang_hcatlog_import;
> 15/02/17 14:38:36 ERROR SparkSQLDriver: Failed in [describe
> qiuzhuang_hcatlog_import]
> org.apache.spark.sql.sources.DDLException: Unsupported dataType: [1.1]
> failure: ``varchar'' expected but identifier char found
>
> char(32)
> ^
> at org.apache.spark.sql.sources.DDLParser.parseType(ddl.scala:52)
> at
>
> org.apache.spark.sql.hive.MetastoreRelation$SchemaAttribute.toAttribute(HiveMetastoreCatalog.scala:664)
> at
>
> org.apache.spark.sql.hive.MetastoreRelation$$anonfun$23.apply(HiveMetastoreCatalog.scala:674)
> at
>
> org.apache.spark.sql.hive.MetastoreRelation$$anonfun$23.apply(HiveMetastoreCatalog.scala:674)
> at
>
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
> at
>
> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
> at scala.collection.Iterator$class.foreach(Iterator.scala:727)
> at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
> at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
> at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
> at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
> at scala.collection.AbstractTraversable.map(Traversable.scala:105)
> at
>
> org.apache.spark.sql.hive.MetastoreRelation.<init>(HiveMetastoreCatalog.scala:674)
> at
>
> org.apache.spark.sql.hive.HiveMetastoreCatalog.lookupRelation(HiveMetastoreCatalog.scala:185)
> at org.apache.spark.sql.hive.HiveContext$$anon$2.org
>
> $apache$spark$sql$catalyst$analysis$OverrideCatalog$$super$lookupRelation(HiveContext.scala:234)
>
> As in hive 0.131, console, this commands works,
>
> hive> describe qiuzhuang_hcatlog_import;
> OK
> id                      char(32)
> assistant_no            varchar(20)
> assistant_name          varchar(32)
> assistant_type          int
> grade                   int
> shop_no                 varchar(20)
> shop_name               varchar(64)
> organ_no                varchar(20)
> organ_name              varchar(20)
> entry_date              string
> education               int
> commission              decimal(8,2)
> tel                     varchar(20)
> address                 varchar(100)
> identity_card           varchar(25)
> sex                     int
> birthday                string
> employee_type           int
> status                  int
> remark                  varchar(255)
> create_user_no          varchar(20)
> create_user             varchar(32)
> create_time             string
> update_user_no          varchar(20)
> update_user             varchar(32)
> update_time             string
> Time taken: 0.49 seconds, Fetched: 26 row(s)
> hive>
>
>
> Regards,
> Qiuzhuang
>

--001a11c3fc3c6b8b31050f4b4679--

From dev-return-11647-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 23:15:13 2015
Return-Path: <dev-return-11647-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A27B10A29
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 23:15:13 +0000 (UTC)
Received: (qmail 22075 invoked by uid 500); 17 Feb 2015 23:15:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21998 invoked by uid 500); 17 Feb 2015 23:15:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21986 invoked by uid 99); 17 Feb 2015 23:15:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:15:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:14:57 +0000
Received: by mail-wi0-f182.google.com with SMTP id l15so36834920wiw.3
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 15:12:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=DAZbP1ygpNOsmvN3N0VzpfEnY7Vmz2e2Hoc/FYC9VJk=;
        b=UiDFwfdpuPSf2t6X3mXYaQgT6u040iObzJmwvoeqT9lzRunKn2AiRWEmGH83wGmZas
         7Apb1d9ghYpJFfoZxxdsKtjbezExlkJaX0hOR810H1Mtry8a1KbwRUpbx9nuFM5rhSSk
         d81QuNCfdCZyPhqYejyjXjcUDjPgwTIOztLqa3Tq/x9ExuEMxiItg8O1fWwP9pc3+2NU
         cJ1NgDqTDuTK045cyzcDBeqaVphHwvyNGIWzYkT8yc4GklZiWA30LkgnU7kgBYOccSSL
         a0PDAo8tO6TLrYfT8Ma19QgcIXZu/HSWxVvJ2/SmIj8KbuD9WnS+SoefaCN6JdTu+YlK
         4t+Q==
MIME-Version: 1.0
X-Received: by 10.194.20.67 with SMTP id l3mr1423919wje.94.1424214741276; Tue,
 17 Feb 2015 15:12:21 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Tue, 17 Feb 2015 15:12:21 -0800 (PST)
In-Reply-To: <54DBA9BF.5080508@gmail.com>
References: <54DBA9BF.5080508@gmail.com>
Date: Tue, 17 Feb 2015 15:12:21 -0800
Message-ID: <CAJgQjQ9iaw4VjUBZgei3QhA4VSGo2+-J9_yDPPNvbUg3FWgYpQ@mail.gmail.com>
Subject: Re: [ml] Lost persistence for fold in crossvalidation.
From: Xiangrui Meng <mengxr@gmail.com>
To: Peter Rudenko <petro.rudenko@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

There are three different regParams defined in the grid and there are
tree folds. For simplicity, we didn't split the dataset into three and
reuse them, but do the split for each fold. Then we need to cache 3*3
times. Note that the pipeline API is not yet optimized for
performance. It would be nice to optimize its perforamnce in 1.4.
-Xiangrui

On Wed, Feb 11, 2015 at 11:13 AM, Peter Rudenko <petro.rudenko@gmail.com> w=
rote:
> Hi i have a problem. Using spark 1.2 with Pipeline + GridSearch +
> LogisticRegression. I=E2=80=99ve reimplemented LogisticRegression.fit met=
hod and
> comment out instances.unpersist()
>
> |override  def  fit(dataset:SchemaRDD,
> paramMap:ParamMap):LogisticRegressionModel  =3D {
>     println(s"Fitting dataset ${dataset.take(1000).toSeq.hashCode()} with
> ParamMap $paramMap.")
>     transformSchema(dataset.schema, paramMap, logging =3Dtrue)
>     import  dataset.sqlContext._
>     val  map  =3D  this.paramMap ++ paramMap
>     val  instances  =3D  dataset.select(map(labelCol).attr,
> map(featuresCol).attr)
>       .map {
>         case  Row(label:Double, features:Vector) =3D>
>           LabeledPoint(label, features)
>       }
>
>     if  (instances.getStorageLevel =3D=3DStorageLevel.NONE) {
>       println("Instances not persisted")
>       instances.persist(StorageLevel.MEMORY_AND_DISK)
>     }
>
>      val  lr  =3D  (new  LogisticRegressionWithLBFGS)
>       .setValidateData(false)
>       .setIntercept(true)
>     lr.optimizer
>       .setRegParam(map(regParam))
>       .setNumIterations(map(maxIter))
>     val  lrm  =3D  new  LogisticRegressionModel(this, map,
> lr.run(instances).weights)
>     //instances.unpersist()
>     // copy model params
>     Params.inheritValues(map,this, lrm)
>     lrm
>   }
> |
>
> CrossValidator feeds the same SchemaRDD for each parameter (same hash cod=
e),
> but somewhere cache being flushed. The memory is enough. Here=E2=80=99s t=
he output:
>
> |Fitting dataset 2051470010 with ParamMap {
>     DRLogisticRegression-f35ae4d3-regParam: 0.1
> }.
> Instances not persisted
> Fitting dataset 2051470010 with ParamMap {
>     DRLogisticRegression-f35ae4d3-regParam: 0.01
> }.
> Instances not persisted
> Fitting dataset 2051470010 with ParamMap {
>     DRLogisticRegression-f35ae4d3-regParam: 0.001
> }.
> Instances not persisted
> Fitting dataset 802615223 with ParamMap {
>     DRLogisticRegression-f35ae4d3-regParam: 0.1
> }.
> Instances not persisted
> Fitting dataset 802615223 with ParamMap {
>     DRLogisticRegression-f35ae4d3-regParam: 0.01
> }.
> Instances not persisted
> |
>
> I have 3 parameters in GridSearch and 3 folds for CrossValidation:
>
> |
> val  paramGrid  =3D  new  ParamGridBuilder()
>   .addGrid(model.regParam,Array(0.1,0.01,0.001))
>   .build()
>
> crossval.setEstimatorParamMaps(paramGrid)
> crossval.setNumFolds(3)
> |
>
> I assume that the data should be read and cached 3 times (1 to
> numFolds).combinations(2) and be independent from number of parameters. B=
ut
> i have 9 times data being read and cached.
>
> Thanks,
> Peter Rudenko
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11648-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 23:20:26 2015
Return-Path: <dev-return-11648-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CB04710A52
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 23:20:26 +0000 (UTC)
Received: (qmail 34306 invoked by uid 500); 17 Feb 2015 23:20:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34233 invoked by uid 500); 17 Feb 2015 23:20:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34196 invoked by uid 99); 17 Feb 2015 23:20:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:20:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:20:18 +0000
Received: by mail-wi0-f179.google.com with SMTP id hi2so37564899wib.0
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 15:19:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=+NPNTN0bbdehyn2FjeIzAGbIyqJ1o/zgwqrvR9PP0do=;
        b=Iv8AgwGvx7puxv3Zkw2P89NTxhA4Yf3PjFnuMeDK+GA4AZ8H4rCDVG2gg0TNJl9DuE
         dzMxKQTt78++cNcQMk2CAgTYwCVKYXIw7A7Rx01aWQeunOUliixfle6McyuhJhsniBNE
         jgiBmeWLJ5raRt2v2poaHLfe4pPfkImKn+SyAhtQhUhOYr1zm9iSuSKPk2XSAMmsMH85
         8P8llncTc2Cwl+Z1s0InUTHzdMRZdl72MXwCr/xJFL6IByH2qx93ryIB+9kE7gTuDuH+
         tDTldKNmUpDgv4lSeCaKv1slAB3FwVaf2FJA3hWWRbMo0TqFhwlA+u19ITd2q9HqbLe7
         yKYg==
MIME-Version: 1.0
X-Received: by 10.194.20.67 with SMTP id l3mr1469769wje.94.1424215197455; Tue,
 17 Feb 2015 15:19:57 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Tue, 17 Feb 2015 15:19:57 -0800 (PST)
In-Reply-To: <CA+B-+fwL-t9sGDZ7yYfxwXDJUM6bcLiy1UYdP=NRKpfebCaBhA@mail.gmail.com>
References: <CA+B-+fwL-t9sGDZ7yYfxwXDJUM6bcLiy1UYdP=NRKpfebCaBhA@mail.gmail.com>
Date: Tue, 17 Feb 2015 15:19:57 -0800
Message-ID: <CAJgQjQ-oCe+OHqX-4BBy_Le6g61A3nuZJwxLmj21_Ux2f0cH+Q@mail.gmail.com>
Subject: Re: mllib.recommendation Design
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

The current ALS implementation allow pluggable solvers for
NormalEquation, where we put CholeskeySolver and NNLS solver. Please
check the current implementation and let us know how your constraint
solver would fit. For a general matrix factorization package, let's
make a JIRA and move our discussion there. -Xiangrui

On Fri, Feb 13, 2015 at 7:46 AM, Debasish Das <debasish.das83@gmail.com> wrote:
> Hi,
>
> I am bit confused on the mllib design in the master. I thought that core
> algorithms will stay in mllib and ml will define the pipelines over the
> core algorithm but looks like in master ALS is moved from mllib to ml...
>
> I am refactoring my PR to a factorization package and I want to build it on
> top of ml.recommendation.ALS (possibly extend from ml.recommendation.ALS
> since first version will use very similar RDD handling as ALS and a
> proximal solver that's being added to breeze)
>
> https://issues.apache.org/jira/browse/SPARK-2426
> https://github.com/scalanlp/breeze/pull/321
>
> Basically I am not sure if we should merge it with recommendation.ALS since
> this is more generic than recommendation. I am considering calling it
> ConstrainedALS where user can specify different constraint for user and
> product factors (Similar to GraphLab CF structure).
>
> I am also working on ConstrainedALM where the underlying algorithm is no
> longer ALS but nonlinear alternating minimization with constraints.
> https://github.com/scalanlp/breeze/pull/364
> This will let us do large rank matrix completion where there is no need to
> construct gram matrices. I will open up the JIRA soon after getting initial
> results
>
> I am bit confused that where should I add the factorization package. It
> will use the current ALS test-cases and I have to construct more test-cases
> for sparse coding and PLSA formulations.
>
> Thanks.
> Deb

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11649-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 17 23:25:11 2015
Return-Path: <dev-return-11649-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4A1C410A65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 17 Feb 2015 23:25:11 +0000 (UTC)
Received: (qmail 40311 invoked by uid 500); 17 Feb 2015 23:24:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40241 invoked by uid 500); 17 Feb 2015 23:24:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40228 invoked by uid 99); 17 Feb 2015 23:24:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:24:54 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 17 Feb 2015 23:24:50 +0000
Received: by mail-wg0-f52.google.com with SMTP id x12so29164463wgg.11
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 15:22:59 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=PuqTSZJm2PPZbTfT29Fhp4QqP3ZzOtUZNO9Bshf+IB8=;
        b=x/AkOIykBLCzaNOKASm7w3ocZnJayC5dI2Izc/alT6EgbiONIxIRSr3QdVSJ0T2pI1
         9qSPPwWuNVhk9qSVm6h2Qs7qWscWbXOYBKrijo5BdxDEUwkbIzM5trjy9CCjggg8Mu5F
         DiEWWIDLnxrVuizQAw//1UI2Bgv+XwAnjTBI7Mp6GWUH+fMAEOhBzFyKhF2oaCRqvZT4
         y30hwRiuC4UJ+jjxYfRmZ29M71hQFdKaOfnUNMzdPI9Rb3xfBkGcRZKpWQnT8UVwNGmZ
         j4VWgpXfnFc6M4fQDpNYJMoTIY6PaMPblJY26s+dUf6qiAtxYzpAXYd2C0MTW/MYLlqJ
         nffQ==
MIME-Version: 1.0
X-Received: by 10.194.20.67 with SMTP id l3mr1487847wje.94.1424215378957; Tue,
 17 Feb 2015 15:22:58 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Tue, 17 Feb 2015 15:22:58 -0800 (PST)
In-Reply-To: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
References: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
Date: Tue, 17 Feb 2015 15:22:58 -0800
Message-ID: <CAJgQjQ8t=ppgtNR7ydG6+_mMhghqiW5Zk1fk-pCSssYUj8+WGw@mail.gmail.com>
Subject: Re: Batch prediciton for ALS
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

It may be too late to merge it into 1.3. I'm going to make another
pass on your PR today. -Xiangrui

On Tue, Feb 10, 2015 at 8:01 AM, Debasish Das <debasish.das83@gmail.com> wrote:
> Hi,
>
> Will it be possible to merge this PR to 1.3 ?
>
> https://github.com/apache/spark/pull/3098
>
> The batch prediction API in ALS will be useful for us who want to cross
> validate on prec@k and MAP...
>
> Thanks.
> Deb

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11650-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 00:10:29 2015
Return-Path: <dev-return-11650-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EDD1B10BFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 00:10:28 +0000 (UTC)
Received: (qmail 23333 invoked by uid 500); 18 Feb 2015 00:10:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23256 invoked by uid 500); 18 Feb 2015 00:10:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23244 invoked by uid 99); 18 Feb 2015 00:10:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 00:10:27 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 00:10:22 +0000
Received: by lbdu14 with SMTP id u14so7694071lbd.1
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 16:10:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=gJyOXa0OxLTAfgqY4v1jiNpnUGr2dHRD6gzG2J9M6yY=;
        b=qJZzAiIkq36jSoBG7ZncTd+MZlwtzpB6Upwfg9OmrUhpuAPG2BKk3Ngu0U+Lay4Hbk
         XiY1jNWGeC9WMcGzl2DvUHflq/0EEbF9Cm4dwHvJHcdDtBWl1S+3MTh12DCgM7VgkRrO
         dvKOCDZ8peR9g1M4JOKdlDILlXi84kZTyJRDUBUTLSJzMShO/RLa5bs3r35Z3XxEvoOO
         oHlNMKjSehZmqRkFEFkMS0eaytPoUprjqA8j9CPx76HJk7pNAI+FjN4A0z1sSs5w/gVU
         nJzKuEVm55lt48e1a25Of1oHx7ocjzeMqx8kEpi6DR2qIkGqvhfR/FRHaehgnAG2Ehw/
         75Vg==
MIME-Version: 1.0
X-Received: by 10.112.39.69 with SMTP id n5mr28633780lbk.1.1424218201936; Tue,
 17 Feb 2015 16:10:01 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Tue, 17 Feb 2015 16:10:01 -0800 (PST)
In-Reply-To: <CAJgQjQ8t=ppgtNR7ydG6+_mMhghqiW5Zk1fk-pCSssYUj8+WGw@mail.gmail.com>
References: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
	<CAJgQjQ8t=ppgtNR7ydG6+_mMhghqiW5Zk1fk-pCSssYUj8+WGw@mail.gmail.com>
Date: Tue, 17 Feb 2015 16:10:01 -0800
Message-ID: <CA+B-+fxBo=4u4TZSUyxWN0vMDbdHuVQnwst-F=Frmf2qwwf+Jw@mail.gmail.com>
Subject: Re: Batch prediciton for ALS
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11349d20025829050f51a43d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11349d20025829050f51a43d
Content-Type: text/plain; charset=UTF-8

It will be really help us if we merge it but I guess it is already diverged
from the new ALS...I will also take a look at it again and try update with
the new ALS...

On Tue, Feb 17, 2015 at 3:22 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> It may be too late to merge it into 1.3. I'm going to make another
> pass on your PR today. -Xiangrui
>
> On Tue, Feb 10, 2015 at 8:01 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > Will it be possible to merge this PR to 1.3 ?
> >
> > https://github.com/apache/spark/pull/3098
> >
> > The batch prediction API in ALS will be useful for us who want to cross
> > validate on prec@k and MAP...
> >
> > Thanks.
> > Deb
>

--001a11349d20025829050f51a43d--

From dev-return-11651-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 00:43:20 2015
Return-Path: <dev-return-11651-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AEF8210D12
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 00:43:20 +0000 (UTC)
Received: (qmail 82775 invoked by uid 500); 18 Feb 2015 00:43:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82702 invoked by uid 500); 18 Feb 2015 00:43:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82690 invoked by uid 99); 18 Feb 2015 00:43:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 00:43:19 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 00:43:15 +0000
Received: by lbvp9 with SMTP id p9so7848240lbv.3
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 16:40:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=JJf9uRWFz8yRuxfGbr6hppN/ZCjFDI8au7O6w0CUk4I=;
        b=DjbdgbFqeZMCJaBXw1pX5RAfdcQH7lTu9Ybtl8DyXIydonv0MdQZGOpPZbTVho8LkX
         hqp2NtwXklY02P/F7shd667aYz6gm2URyTjrGPuCF7pEXPycEiBsWoSUn3Xzhsdo9U/v
         PwGyMy2aiQHl0vgQAstIzi480ZZBFdw3Xm0ClFf8xwAND7aLhwrcaWPlCn/rjq3Of+jl
         AnyjKwFFy13d01eu3jqqZ5kQGkk6LnQPdQq9RHQVuzsKaANEASXkJvXulyGNKAxllN5/
         nvHrI/OdrkRlIqsZpGhQeZGQxO5dXqqc4bbKHAVz+0SbYnb2a1o7cArNGUfzVNK8V7yA
         rWJA==
MIME-Version: 1.0
X-Received: by 10.152.1.40 with SMTP id 8mr21644590laj.97.1424220039118; Tue,
 17 Feb 2015 16:40:39 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Tue, 17 Feb 2015 16:40:39 -0800 (PST)
In-Reply-To: <CAJgQjQ-oCe+OHqX-4BBy_Le6g61A3nuZJwxLmj21_Ux2f0cH+Q@mail.gmail.com>
References: <CA+B-+fwL-t9sGDZ7yYfxwXDJUM6bcLiy1UYdP=NRKpfebCaBhA@mail.gmail.com>
	<CAJgQjQ-oCe+OHqX-4BBy_Le6g61A3nuZJwxLmj21_Ux2f0cH+Q@mail.gmail.com>
Date: Tue, 17 Feb 2015 16:40:39 -0800
Message-ID: <CA+B-+fx_1tZNoJQ5b1BreQCKGUR9VvBiQU3Q1_iE4iuB9obzmw@mail.gmail.com>
Subject: Re: mllib.recommendation Design
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c6b908384ca050f521127
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6b908384ca050f521127
Content-Type: text/plain; charset=UTF-8

There is a usability difference...I am not sure if recommendation.ALS would
like to add both userConstraint and productConstraint ? GraphLab CF for
example has it and we are ready to support all the features for modest
ranks where gram matrices can be made...

For large ranks I am still working on the code

On Tue, Feb 17, 2015 at 3:19 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> The current ALS implementation allow pluggable solvers for
> NormalEquation, where we put CholeskeySolver and NNLS solver. Please
> check the current implementation and let us know how your constraint
> solver would fit. For a general matrix factorization package, let's
> make a JIRA and move our discussion there. -Xiangrui
>
> On Fri, Feb 13, 2015 at 7:46 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > I am bit confused on the mllib design in the master. I thought that core
> > algorithms will stay in mllib and ml will define the pipelines over the
> > core algorithm but looks like in master ALS is moved from mllib to ml...
> >
> > I am refactoring my PR to a factorization package and I want to build it
> on
> > top of ml.recommendation.ALS (possibly extend from ml.recommendation.ALS
> > since first version will use very similar RDD handling as ALS and a
> > proximal solver that's being added to breeze)
> >
> > https://issues.apache.org/jira/browse/SPARK-2426
> > https://github.com/scalanlp/breeze/pull/321
> >
> > Basically I am not sure if we should merge it with recommendation.ALS
> since
> > this is more generic than recommendation. I am considering calling it
> > ConstrainedALS where user can specify different constraint for user and
> > product factors (Similar to GraphLab CF structure).
> >
> > I am also working on ConstrainedALM where the underlying algorithm is no
> > longer ALS but nonlinear alternating minimization with constraints.
> > https://github.com/scalanlp/breeze/pull/364
> > This will let us do large rank matrix completion where there is no need
> to
> > construct gram matrices. I will open up the JIRA soon after getting
> initial
> > results
> >
> > I am bit confused that where should I add the factorization package. It
> > will use the current ALS test-cases and I have to construct more
> test-cases
> > for sparse coding and PLSA formulations.
> >
> > Thanks.
> > Deb
>

--089e013c6b908384ca050f521127--

From dev-return-11652-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 03:14:41 2015
Return-Path: <dev-return-11652-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 95DDB1739E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 03:14:41 +0000 (UTC)
Received: (qmail 67767 invoked by uid 500); 18 Feb 2015 03:14:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67693 invoked by uid 500); 18 Feb 2015 03:14:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67679 invoked by uid 99); 18 Feb 2015 03:14:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 03:14:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of niranda.perera@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 03:14:10 +0000
Received: by mail-ob0-f175.google.com with SMTP id va2so60925846obc.6
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 19:14:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Ht84tEA5/F2DFJzui52XO1sPHZIUePx2r7nYbIhwTEw=;
        b=dn/078csxQOMUuXoieD6p2veuBGpi7Cp2v+CiD2r+bEdn6XVcu+q7O6YuvR/qXqLW2
         U/JPMwcsChvTawp6Mj1fxDyrx21Txbt1fG+o3rOV9av/D+r7NlszYthBUuIIFG0FlBOV
         ibIxK4CUQ/FUgnCvTUvnVLanKCaHes0E9xIlG+2TGTU2wCVIFyzBWNph2AT62qcqaUU6
         LzeHm5DE+rdC7Gapke08ZcFZ9zAwRMERYsLAnWRZRzZIKCQZVkDglM3GenZqNXmdSvLv
         HOBI9Fesn604p9MJpcFnHA1ivbjZTnjs34ZRnVoutZ1SCJjsmrxCXiHu53VnRiclXmtg
         Wwbw==
MIME-Version: 1.0
X-Received: by 10.202.191.194 with SMTP id p185mr19474734oif.128.1424229248585;
 Tue, 17 Feb 2015 19:14:08 -0800 (PST)
Received: by 10.202.64.6 with HTTP; Tue, 17 Feb 2015 19:14:08 -0800 (PST)
In-Reply-To: <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
	<CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
Date: Wed, 18 Feb 2015 08:44:08 +0530
Message-ID: <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
From: Niranda Perera <niranda.perera@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d6a5270d776050f54367d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d6a5270d776050f54367d
Content-Type: text/plain; charset=UTF-8

Hi Sean,
The main issue we have is, running two web servers in a single product. we
think it would not be an elegant solution.

Could you please point me to the main areas where jetty server is tightly
coupled or extension points where I could plug tomcat instead of jetty?
If successful I could contribute it to the spark project. :-)

cheers



On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:

> There's no particular reason you have to remove the embedded Jetty
> server, right? it doesn't prevent you from using it inside another app
> that happens to run in Tomcat. You won't be able to switch it out
> without rewriting a fair bit of code, no, but you don't need to.
>
> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
> <niranda.perera@gmail.com> wrote:
> > Hi,
> >
> > We are thinking of integrating Spark server inside a product. Our current
> > product uses Tomcat as its webserver.
> >
> > Is it possible to switch the Jetty webserver in Spark to Tomcat
> > off-the-shelf?
> >
> > Cheers
> >
> > --
> > Niranda
>



-- 
Niranda

--001a113d6a5270d776050f54367d--

From dev-return-11653-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 03:24:01 2015
Return-Path: <dev-return-11653-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C0A42173B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 03:24:01 +0000 (UTC)
Received: (qmail 75032 invoked by uid 500); 18 Feb 2015 03:24:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74945 invoked by uid 500); 18 Feb 2015 03:24:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74933 invoked by uid 99); 18 Feb 2015 03:24:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 03:24:00 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 03:23:35 +0000
Received: by mail-ob0-f175.google.com with SMTP id va2so60978609obc.6
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 19:22:49 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=rXs+0wDDeORIhYdQ+5yAVgdBMHJNLQgzxOFX885yFrA=;
        b=mw8Jw547AbyL+Njq5cgtyj04WziNoSkqdeCJXsgxn+DGCkggqASuGtPmmd4Qx7S25i
         HlWbEq4Dm8xphpnTPvlL7PjlyqXHoR61tU4HKpVaBTl3sInsumpsNX0Pw+OwTIj309Xw
         MJFsIWt4ievAQ5m9nm4pWp9OAWw/XvAegzEpt0CodH2nZY7uWsvR7BJR1+S/lyK2iVKn
         paqYrASoyCMbzCdtY6PCxvA8XS4RX5SNsVqHAnKIv/VwprdyegUQacmpMXqKck8a0oTq
         hOhm3MbgokKKoa58UOa80l52hAH4EdG7JIfJU4qgbXWED5ox1GMvKO6luYA3aMbiybK5
         +NjQ==
MIME-Version: 1.0
X-Received: by 10.182.144.229 with SMTP id sp5mr20177560obb.14.1424229768937;
 Tue, 17 Feb 2015 19:22:48 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Tue, 17 Feb 2015 19:22:48 -0800 (PST)
In-Reply-To: <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
	<CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
	<CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
Date: Tue, 17 Feb 2015 19:22:48 -0800
Message-ID: <CABPQxsvdX21C6aCJViGsON90+-Dozwk0YP22NsY1zdUsCJrFqg@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
From: Patrick Wendell <pwendell@gmail.com>
To: Niranda Perera <niranda.perera@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Niranda,

It seems to me a lot of effort to support multiple libraries inside of
Spark like this, so I'm not sure that's a great solution.

If you are building an application that embeds Spark, is it not
possible for you to continue to use Jetty for Spark's internal servers
and use tomcat for your own server's? I would guess that many complex
applications end up embedding multiple server libraries in various
places (Spark itself has different transport mechanisms, etc.)

- Patrick

On Tue, Feb 17, 2015 at 7:14 PM, Niranda Perera
<niranda.perera@gmail.com> wrote:
> Hi Sean,
> The main issue we have is, running two web servers in a single product. we
> think it would not be an elegant solution.
>
> Could you please point me to the main areas where jetty server is tightly
> coupled or extension points where I could plug tomcat instead of jetty?
> If successful I could contribute it to the spark project. :-)
>
> cheers
>
>
>
> On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
>
>> There's no particular reason you have to remove the embedded Jetty
>> server, right? it doesn't prevent you from using it inside another app
>> that happens to run in Tomcat. You won't be able to switch it out
>> without rewriting a fair bit of code, no, but you don't need to.
>>
>> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
>> <niranda.perera@gmail.com> wrote:
>> > Hi,
>> >
>> > We are thinking of integrating Spark server inside a product. Our current
>> > product uses Tomcat as its webserver.
>> >
>> > Is it possible to switch the Jetty webserver in Spark to Tomcat
>> > off-the-shelf?
>> >
>> > Cheers
>> >
>> > --
>> > Niranda
>>
>
>
>
> --
> Niranda

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11654-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 04:31:19 2015
Return-Path: <dev-return-11654-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5398A17561
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 04:31:19 +0000 (UTC)
Received: (qmail 67998 invoked by uid 500); 18 Feb 2015 04:31:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67929 invoked by uid 500); 18 Feb 2015 04:31:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67917 invoked by uid 99); 18 Feb 2015 04:31:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 04:31:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cjnolet@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 04:30:50 +0000
Received: by iecrl12 with SMTP id rl12so43781119iec.2
        for <dev@spark.apache.org>; Tue, 17 Feb 2015 20:30:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=DKuVz/dq7MMS3YU4/SR8JMXW8CFHaXCw7TB3Cwbsv5U=;
        b=ZIy3KQme3cR+ChF8mhQjN8P07LfwKaGOLDHzdcKb97MrBPZhP4eTIMajEbd1T8+ACO
         sF6NjQxIadq2D6wmOd306kiUP32tknTeodevxMbOnjxvysmEwHBdAus7lmGGCM3ZtFXm
         98xs9xzjiMnmB1q62uiI/VQ+5vl76Tj/RTs598+iGHNfqoV7oX3ilpCKL8/b/wsuVb6S
         evxypXTTzRxy5SR+daiPkN0evlMutVWbCR06B4VgxqNx2BqmWgB9uCJsu2HfjuyiBydq
         PJ4//CLRTYEFipFpHrYICa19r6fqkAc15pubYUQ9i3USyhfYldB8miFQqoqJ4INpNR7b
         rZeg==
X-Received: by 10.107.47.22 with SMTP id j22mr3151488ioo.16.1424233803906;
 Tue, 17 Feb 2015 20:30:03 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.18.175 with HTTP; Tue, 17 Feb 2015 20:29:43 -0800 (PST)
In-Reply-To: <CABPQxsvdX21C6aCJViGsON90+-Dozwk0YP22NsY1zdUsCJrFqg@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
 <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
 <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com> <CABPQxsvdX21C6aCJViGsON90+-Dozwk0YP22NsY1zdUsCJrFqg@mail.gmail.com>
From: Corey Nolet <cjnolet@gmail.com>
Date: Tue, 17 Feb 2015 23:29:43 -0500
Message-ID: <CAOHP_tF6GkRoCGguKO-xN18nmbnOf8eQvgW9p1C9qvVxcHW_GQ@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Patrick Wendell <pwendell@gmail.com>
Cc: Niranda Perera <niranda.perera@gmail.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16648f582a4050f5545e1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16648f582a4050f5545e1
Content-Type: text/plain; charset=UTF-8

Niranda,

I'm not sure if I'd say Spark's use of Jetty to expose its UI monitoring
layer constitutes a use of "two web servers in a single product". Hadoop
uses Jetty as well as do many other applications today that need embedded
http layers for serving up their monitoring UI to users. This is completely
aside from any web container an application developer would use to interact
with Spark and Hadoop and service domain-specific content to users. The two
are disjoint.

Many applications use Thrift as a means of establishing socket connections
between clients and across servers. One alternative to Thrift is Protobuf.
You wouldn't say "I want to swap out thrift for protobuf in Cassandra
because I want to use protobuf in my application and there shouldn't be two
different socket layer abstractions on my cluster."

I could understand wanting to do this if you were being forced to deploy a
war file to a web container in order to do the monitoring but Spark's UI is
embedded within the code. If you are worried about having the Jetty
libraries on your classpath, you can exclude the Jetty dependencies from
your servlet code if you want to interact with a SparkContext in Tomcat.



On Tue, Feb 17, 2015 at 10:22 PM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Hey Niranda,
>
> It seems to me a lot of effort to support multiple libraries inside of
> Spark like this, so I'm not sure that's a great solution.
>
> If you are building an application that embeds Spark, is it not
> possible for you to continue to use Jetty for Spark's internal servers
> and use tomcat for your own server's? I would guess that many complex
> applications end up embedding multiple server libraries in various
> places (Spark itself has different transport mechanisms, etc.)
>
> - Patrick
>
> On Tue, Feb 17, 2015 at 7:14 PM, Niranda Perera
> <niranda.perera@gmail.com> wrote:
> > Hi Sean,
> > The main issue we have is, running two web servers in a single product.
> we
> > think it would not be an elegant solution.
> >
> > Could you please point me to the main areas where jetty server is tightly
> > coupled or extension points where I could plug tomcat instead of jetty?
> > If successful I could contribute it to the spark project. :-)
> >
> > cheers
> >
> >
> >
> > On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
> >
> >> There's no particular reason you have to remove the embedded Jetty
> >> server, right? it doesn't prevent you from using it inside another app
> >> that happens to run in Tomcat. You won't be able to switch it out
> >> without rewriting a fair bit of code, no, but you don't need to.
> >>
> >> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
> >> <niranda.perera@gmail.com> wrote:
> >> > Hi,
> >> >
> >> > We are thinking of integrating Spark server inside a product. Our
> current
> >> > product uses Tomcat as its webserver.
> >> >
> >> > Is it possible to switch the Jetty webserver in Spark to Tomcat
> >> > off-the-shelf?
> >> >
> >> > Cheers
> >> >
> >> > --
> >> > Niranda
> >>
> >
> >
> >
> > --
> > Niranda
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c16648f582a4050f5545e1--

From dev-return-11655-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 04:32:21 2015
Return-Path: <dev-return-11655-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 84E531756B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 04:32:21 +0000 (UTC)
Received: (qmail 71495 invoked by uid 500); 18 Feb 2015 04:32:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71410 invoked by uid 500); 18 Feb 2015 04:32:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71395 invoked by uid 99); 18 Feb 2015 04:32:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 04:32:13 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mcheah@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 04:32:08 +0000
Received: from EXDR01-WEST.YOJOE.local (10.160.10.135) by
 EX03-WEST.YOJOE.local (10.160.10.136) with Microsoft SMTP Server (TLS) id
 14.3.195.1; Tue, 17 Feb 2015 20:31:46 -0800
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EXDR01-WEST.YOJOE.local ([169.254.3.4]) with mapi id 14.03.0195.001; Tue, 17
 Feb 2015 20:31:46 -0800
From: Matt Cheah <mcheah@palantir.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
	<mkim@palantir.com>, Andrew Ash <aash@palantir.com>
Subject: JavaRDD Aggregate initial value - Closure-serialized zero value
 reasoning?
Thread-Topic: JavaRDD Aggregate initial value - Closure-serialized zero
 value reasoning?
Thread-Index: AQHQSzPN6LwMFRGQVEeRI4YxS85fiQ==
Date: Wed, 18 Feb 2015 04:31:45 +0000
Message-ID: <D109561E.9161%mcheah@palantir.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.84.245]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507050014_903448"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507050014_903448
Content-type: multipart/alternative;
	boundary="B_3507050014_934996"


--B_3507050014_934996
Content-type: text/plain;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

Hi everyone,

I was using JavaPairRDD=B9s combineByKey() to compute all of my aggregations
before, since I assumed that every aggregation required a key. However, I
realized I could do my analysis using JavaRDD=B9s aggregate() instead and not
use a key.

I have set spark.serializer to use Kryo. As a result, JavaRDD=B9s combineByKe=
y
requires that a =B3createCombiner=B2 function is provided, and the return value
from that function must be serializable using Kryo. When I switched to usin=
g
rdd.aggregate I assumed that the zero value would also be strictly Kryo
serialized, as it is a data item and not part of a closure or the
aggregation functions. However, I got a serialization exception as the
closure serializer (only valid serializer is the Java serializer) was used
instead.

I was wondering the following:
1. What is the rationale for making the zero value be serialized using the
closure serializer? This isn=B9t part of the closure, but is an initial data
item.
2. Would it make sense for us to perhaps write a version of rdd.aggregate()
that takes a function as a parameter, that generates the zero value? This
would be more intuitive to be serialized using the closure serializer.
I believe aggregateByKey is also affected.

Thanks,

-Matt Cheah



--B_3507050014_934996
Content-type: text/html;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

<html><head></head><body style=3D"word-wrap: break-word; -webkit-nbsp-mode: s=
pace; -webkit-line-break: after-white-space; color: rgb(0, 0, 0); font-size:=
 14px; font-family: Calibri, sans-serif;"><div>Hi everyone,</div><div><br></=
div><div>I was using JavaPairRDD&#8217;s combineByKey() to compute all of my=
 aggregations before, since I assumed that every aggregation required a key.=
 However, I realized I could do my analysis using JavaRDD&#8217;s aggregate(=
) instead and not use a key.</div><div><br></div><div>I have set spark.seria=
lizer to use Kryo. As a result, JavaRDD&#8217;s combineByKey requires that a=
 &#8220;createCombiner&#8221; function is provided, and the return value fro=
m that function must be serializable using Kryo. When I switched to using rd=
d.aggregate I assumed that the zero value would also be strictly Kryo serial=
ized, as it is a data item and not part of a closure or the aggregation func=
tions. However, I got a serialization exception as the closure serializer (o=
nly valid serializer is the Java serializer) was used instead.</div><div><br=
></div><div>I was wondering the following:</div><ol><li>What is the rational=
e for making the zero value be serialized using the closure serializer? This=
 isn&#8217;t part of the closure, but is an initial data item.</li><li>Would=
 it make sense for us to perhaps write a version of rdd.aggregate() that tak=
es a function as a parameter, that generates the zero value? This would be m=
ore intuitive to be serialized using the closure serializer.</li></ol><div>I=
 believe aggregateByKey is also affected.</div><div><br></div><div>Thanks,</=
div><div><br></div><div>-Matt Cheah</div></body></html>

--B_3507050014_934996--

--B_3507050014_903448
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507050014_903448--

From dev-return-11656-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 08:14:11 2015
Return-Path: <dev-return-11656-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E2EDF1799D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 08:14:10 +0000 (UTC)
Received: (qmail 27483 invoked by uid 500); 18 Feb 2015 08:14:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27404 invoked by uid 500); 18 Feb 2015 08:14:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27392 invoked by uid 99); 18 Feb 2015 08:14:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 08:14:04 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 08:13:58 +0000
Received: by mail-ob0-f175.google.com with SMTP id va2so62763900obc.6
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 00:12:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=UWy67F5ZNlJVP+HzUZLiW1Q5cT3uNsRVXdFRAiM1kNo=;
        b=gaqm9K8t+VrAr/lxa7K0m7rOMvXWQOxcnPjshxt4aSGCe0PlsS7eDfRBDhPik+u0Pb
         oSdDPD3RyP/zuMLK5vSv7vX8h5qZXHM+lSc55TOciuGHlgb+m3JH2WRxw7M4iInLJb4J
         A7tfcuMy9QGJveW3UL41EmDrfX9FdivlV3hz3n+NYD9R61TH65ZS/GdT4/dQZSAebx4n
         2O9NW/92munZ0BJuucwy2gw0ikNLHWVlYjWl1/CYXxY6iza12iDcz1NUUC5YZuccEbF1
         14J93xIIQYedtew2tYlXRrsjGbFkPOqwZUvfNY2tbfirFx8MIqijkdtAoER/2QQ1YlOK
         7YhA==
MIME-Version: 1.0
X-Received: by 10.60.139.1 with SMTP id qu1mr21156122oeb.83.1424247128385;
 Wed, 18 Feb 2015 00:12:08 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 18 Feb 2015 00:12:08 -0800 (PST)
Date: Wed, 18 Feb 2015 00:12:08 -0800
Message-ID: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
Subject: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Please vote on releasing the following candidate as Apache Spark version 1.3.0!

The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=f97b0d4a6b26504916816d7aefcf3132cd1da6c2

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc1/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1069/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/

Please vote on releasing this package as Apache Spark 1.3.0!

The vote is open until Saturday, February 21, at 08:03 UTC and passes
if a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.3.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

== How can I help test this release? ==
If you are a Spark user, you can help us test this release by
taking a Spark 1.2 workload and running on this release candidate,
then reporting any regressions.

== What justifies a -1 vote for this release? ==
This vote is happening towards the end of the 1.3 QA period,
so -1 votes should only occur for significant regressions from 1.2.1.
Bugs already present in 1.2.X, minor regressions, or bugs related
to new features will not block this release.

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11657-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 08:21:55 2015
Return-Path: <dev-return-11657-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A3813179B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 08:21:55 +0000 (UTC)
Received: (qmail 39282 invoked by uid 500); 18 Feb 2015 08:21:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39204 invoked by uid 500); 18 Feb 2015 08:21:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39192 invoked by uid 99); 18 Feb 2015 08:21:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 08:21:54 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.169 as permitted sender)
Received: from [209.85.214.169] (HELO mail-ob0-f169.google.com) (209.85.214.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 08:21:28 +0000
Received: by mail-ob0-f169.google.com with SMTP id wp4so62749927obc.0
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 00:21:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=R9MNyCxOxnUqseYuQqSufZpMfvJdEy2kpWs5pQ0dyVc=;
        b=QhLgyUahiyLEuZnFSOh+xMTLLEyqpR1853K4/cPA2IjgvYjYsal4UB2Hkrw/7n3EwC
         Q+g1Ebvf8eNHAWGXxHLuVcZChM8YH6CqWgrnXv5d5GSTuhm5c/PoyoWAi6UBQ95D2Wo2
         +h/aO5RqZCesLExMu1ppkSb6zu1HrjZxuYBE1VNB1Vgf4HC4YAYDsznnhLDemag+UiT3
         WOkvToXp3IVP0RaBKBLjLOTbeWj5pGs6XnPzzvUUSdQJrR1G+5aBRBljMSpyGoDUEp1T
         6zdbjYpKp1Z0yiK7qDun9Hk+vE9gGH65UIFpsOfPcTCK/ZuVtIaFZ5r2LDkDRDCwFlqp
         inEA==
MIME-Version: 1.0
X-Received: by 10.182.215.163 with SMTP id oj3mr1909240obc.49.1424247686692;
 Wed, 18 Feb 2015 00:21:26 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 18 Feb 2015 00:21:26 -0800 (PST)
Date: Wed, 18 Feb 2015 00:21:26 -0800
Message-ID: <CABPQxssi9CbBv0WG0btT2MOGT_yWOMHeOLjiNJ=5=Rd=HQttxw@mail.gmail.com>
Subject: Merging code into branch 1.3
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Committers,

Now that Spark 1.3 rc1 is cut, please restrict branch-1.3 merges to
the following:

1. Fixes for issues blocking the 1.3 release (i.e. 1.2.X regressions)
2. Documentation and tests.
3. Fixes for non-blocker issues that are surgical, low-risk, and/or
outside of the core.

If there is a lower priority bug fix (a non-blocker) that requires
nontrivial code changes, do not merge it into 1.3. If something seems
borderline, feel free to reach out to me and we can work through it
together.

This is what we've done for the last few releases to make sure rc's
become progressively more stable, and it is important towards helping
us cut timely releases.

Thanks!

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11658-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 10:04:13 2015
Return-Path: <dev-return-11658-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0F24917CDC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 10:04:13 +0000 (UTC)
Received: (qmail 84602 invoked by uid 500); 18 Feb 2015 10:04:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84521 invoked by uid 500); 18 Feb 2015 10:04:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56383 invoked by uid 99); 18 Feb 2015 09:57:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 09:57:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.170 as permitted sender)
Received: from [74.125.82.170] (HELO mail-we0-f170.google.com) (74.125.82.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 09:57:18 +0000
Received: by wesw55 with SMTP id w55so60907wes.5
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 01:56:12 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=fApfL8ZFxml2mXYKX5edhb4rJ6joL+VokAiazvHeiOE=;
        b=cLyBkakZJqKvIFnlTzGz5DBq2iW4h+NxsSsR/INF23hkp7jO+6KPxDuI0G9wUXgGyr
         XtyV9rOtnJVeQvZ5H8g2TUCcw+yn68JMcYPR8L6ogMqt8dKU25cfCMa0Z7Yp/9SwsLDi
         qbgyi5CCCO8pBAmoMFByvI9ejlwDQ+gdJW19TajLrJw36AgaoFsrokMjLcAljG+idilb
         Cv03CCmS5vj/jsT8qNctpOWHav/3xHfW075s67sB6mvmepG1gcghZvlpA0HyE9n1K3Cy
         wReJB9KHVYpkvfJ5uMHlYnUvHBdyoeaGhAW/2/47UB23S5mYVmE5SKgmPaXRH4lKMnNQ
         Sa7g==
X-Gm-Message-State: ALoCoQmGxsZ6PIYs16KqBVO4cnOXQp8HEzS1cOyRbQ2cR3271G9XsXLETXV8BNjfT2jx3gB5gBJr
X-Received: by 10.194.2.43 with SMTP id 11mr7325295wjr.104.1424253371874; Wed,
 18 Feb 2015 01:56:11 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 18 Feb 2015 01:55:51 -0800 (PST)
In-Reply-To: <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
 <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com> <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 18 Feb 2015 09:55:51 +0000
Message-ID: <CAMAsSdKJKaij3crhRLn_-NZDoTSTu76GsfYvEPBJt93hCVeL-w@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Niranda Perera <niranda.perera@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I do not think it makes sense to make the web server configurable.
Mostly because there's no real problem in running an HTTP service
internally based on Netty while you run your own HTTP service based on
something else like Tomcat. What's the problem?

On Wed, Feb 18, 2015 at 3:14 AM, Niranda Perera
<niranda.perera@gmail.com> wrote:
> Hi Sean,
> The main issue we have is, running two web servers in a single product. we
> think it would not be an elegant solution.
>
> Could you please point me to the main areas where jetty server is tightly
> coupled or extension points where I could plug tomcat instead of jetty?
> If successful I could contribute it to the spark project. :-)
>
> cheers
>
>
>
> On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> There's no particular reason you have to remove the embedded Jetty
>> server, right? it doesn't prevent you from using it inside another app
>> that happens to run in Tomcat. You won't be able to switch it out
>> without rewriting a fair bit of code, no, but you don't need to.
>>
>> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
>> <niranda.perera@gmail.com> wrote:
>> > Hi,
>> >
>> > We are thinking of integrating Spark server inside a product. Our
>> > current
>> > product uses Tomcat as its webserver.
>> >
>> > Is it possible to switch the Jetty webserver in Spark to Tomcat
>> > off-the-shelf?
>> >
>> > Cheers
>> >
>> > --
>> > Niranda
>
>
>
>
> --
> Niranda

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11659-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 10:11:57 2015
Return-Path: <dev-return-11659-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 781F917D57
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 10:11:57 +0000 (UTC)
Received: (qmail 4665 invoked by uid 500); 18 Feb 2015 10:11:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4587 invoked by uid 500); 18 Feb 2015 10:11:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4576 invoked by uid 99); 18 Feb 2015 10:11:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 10:11:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.212.169 as permitted sender)
Received: from [209.85.212.169] (HELO mail-wi0-f169.google.com) (209.85.212.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 10:11:50 +0000
Received: by mail-wi0-f169.google.com with SMTP id em10so37898346wid.0
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 02:09:59 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=M2AN6t2poUffe7W7LZzRMvhfbkIVa+Qju3WpBla1UZs=;
        b=hmucnZAcjtF1yIPfHbTDAYWpay02vCQIJmctkqYkVuP15f2ax2d1t1wwXwS1Lthxdo
         OfRzujp9dz/hu2H/IRyObPYUh2WncbwvtKp/Izne4xjhZ7LgXbEsCudBtOOcFwyF8yPg
         J6WOcMaEUHmnXi2JIimaYSSQCq9GmExmnlrIsgDqSdDZyM/Hj4XIiU6Kh7owTyYG31MT
         I4a4I8id9E8yz0HVS0r+6a0+2Q1nmfPCe6jSeQjhHkTIirLZ4nN7Y9PS9T6a11HeG5Cq
         rFoZ0ZXzyZMjtAoLPGlyCA5V0V88SbURn/BtyTgL27Yd7M0PpxneMy4hEq9xnWkKhBEA
         SwbQ==
X-Gm-Message-State: ALoCoQkiIumGVxJU8/nbHcRd8fhEg1z3xPYQXOiPiIu5eijW6dbMout6PmZsgE04AA6U7Q5QYvaV
X-Received: by 10.180.96.168 with SMTP id dt8mr3407193wib.82.1424254199709;
 Wed, 18 Feb 2015 02:09:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 18 Feb 2015 02:09:39 -0800 (PST)
In-Reply-To: <D109561E.9161%mcheah@palantir.com>
References: <D109561E.9161%mcheah@palantir.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 18 Feb 2015 10:09:39 +0000
Message-ID: <CAMAsSdJZH-4A=c3w9nByBtmtXXePCRJw3uPfbwtaTfN1pbdpOQ@mail.gmail.com>
Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero value reasoning?
To: Matt Cheah <mcheah@palantir.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, 
	Andrew Ash <aash@palantir.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

The serializer is created with

val zeroBuffer =3D SparkEnv.get.serializer.newInstance().serialize(zeroValu=
e)

Which is definitely not the closure serializer and so should respect
what you are setting with spark.serializer.

Maybe you can do a quick bit of debugging to see where that assumption
breaks down? like are you sure spark.serializer is set everywhere?

On Wed, Feb 18, 2015 at 4:31 AM, Matt Cheah <mcheah@palantir.com> wrote:
> Hi everyone,
>
> I was using JavaPairRDD=E2=80=99s combineByKey() to compute all of my agg=
regations
> before, since I assumed that every aggregation required a key. However, I
> realized I could do my analysis using JavaRDD=E2=80=99s aggregate() inste=
ad and not
> use a key.
>
> I have set spark.serializer to use Kryo. As a result, JavaRDD=E2=80=99s c=
ombineByKey
> requires that a =E2=80=9CcreateCombiner=E2=80=9D function is provided, an=
d the return value
> from that function must be serializable using Kryo. When I switched to us=
ing
> rdd.aggregate I assumed that the zero value would also be strictly Kryo
> serialized, as it is a data item and not part of a closure or the
> aggregation functions. However, I got a serialization exception as the
> closure serializer (only valid serializer is the Java serializer) was use=
d
> instead.
>
> I was wondering the following:
>
> What is the rationale for making the zero value be serialized using the
> closure serializer? This isn=E2=80=99t part of the closure, but is an ini=
tial data
> item.
> Would it make sense for us to perhaps write a version of rdd.aggregate()
> that takes a function as a parameter, that generates the zero value? This
> would be more intuitive to be serialized using the closure serializer.
>
> I believe aggregateByKey is also affected.
>
> Thanks,
>
> -Matt Cheah

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11660-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 12:15:10 2015
Return-Path: <dev-return-11660-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9310B17348
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 12:15:10 +0000 (UTC)
Received: (qmail 58293 invoked by uid 500); 18 Feb 2015 12:15:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58216 invoked by uid 500); 18 Feb 2015 12:15:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58205 invoked by uid 99); 18 Feb 2015 12:15:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 12:15:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 12:14:57 +0000
Received: by mail-wi0-f182.google.com with SMTP id l15so1714880wiw.3
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 04:14:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=PwdYnFFRwsIQFePMupC1u45qoPEwhZpePfLmFX5H8rk=;
        b=ED0lzrJa2B91z7UGe7JymOrL3sF5P/FtST1YwStKbB7j2riItTtpt5MgNNQcdMshF9
         cyH6cUl21AdGmRCgiizuGh6QPAwewwyssKSC8NFbEQ96XarfFF2kKh3hk4sGbQdBD7zX
         5rkUffCyvq/cgLxU2eslPWfbFnex4teEQoicdnsHX0Eg7OkppCx+mToJLiUc8EzTX1qZ
         u4MQ8RC55pgQaTGoYHMLTKTACWG5hwOEcguWLPXb3fcdfEZFieiCBGHXow2CA8KFPvEa
         yv7ihAKWyPefie44Yxino2liqirf7XLQkWJl/qAUz55a1wekQOu09FFLvebUvBUGTO8v
         VpcA==
X-Gm-Message-State: ALoCoQkEdPW0j+v62SnCCFNZ4OH/CMW25MiWT1Q0kFvwH51V8brswrJKbCn2b2sTJGUbwcIQJTBj
X-Received: by 10.194.240.164 with SMTP id wb4mr70790951wjc.66.1424261675979;
 Wed, 18 Feb 2015 04:14:35 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 18 Feb 2015 04:14:15 -0800 (PST)
In-Reply-To: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 18 Feb 2015 12:14:15 +0000
Message-ID: <CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On OS X and Ubuntu I see the following test failure in the source
release for 1.3.0-RC1:

UISeleniumSuite:
*** RUN ABORTED ***
  java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal
...


Patrick this link gives a 404:
https://people.apache.org/keys/committer/pwendell.asc


Finally, I already realized I failed to get the fix for
https://issues.apache.org/jira/browse/SPARK-5669 correct, and that has
to be correct for the release. I'll patch that up straight away,
sorry. I believe the result of the intended fix is still as I
described in SPARK-5669, so there is no bad news there. A local test
seems to confirm it and I'm waiting on Jenkins. If it's all good I'll
merge that fix. So, that much will need a new release, I apologize.


Please keep testing anyway!


Otherwise, I verified the signatures are correct, licenses are
correct, compiles on OS X and Ubuntu 14.


On Wed, Feb 18, 2015 at 8:12 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Please vote on releasing the following candidate as Apache Spark version 1.3.0!
>
> The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=f97b0d4a6b26504916816d7aefcf3132cd1da6c2
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1069/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
>
> Please vote on releasing this package as Apache Spark 1.3.0!
>
> The vote is open until Saturday, February 21, at 08:03 UTC and passes
> if a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.3.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == How can I help test this release? ==
> If you are a Spark user, you can help us test this release by
> taking a Spark 1.2 workload and running on this release candidate,
> then reporting any regressions.
>
> == What justifies a -1 vote for this release? ==
> This vote is happening towards the end of the 1.3 QA period,
> so -1 votes should only occur for significant regressions from 1.2.1.
> Bugs already present in 1.2.X, minor regressions, or bugs related
> to new features will not block this release.
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11661-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 14:14:02 2015
Return-Path: <dev-return-11661-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D3BE176EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 14:14:02 +0000 (UTC)
Received: (qmail 86596 invoked by uid 500); 18 Feb 2015 14:13:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86525 invoked by uid 500); 18 Feb 2015 14:13:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86513 invoked by uid 99); 18 Feb 2015 14:13:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 14:13:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.177 as permitted sender)
Received: from [209.85.192.177] (HELO mail-pd0-f177.google.com) (209.85.192.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 14:13:18 +0000
Received: by pdbfp1 with SMTP id fp1so1354935pdb.9
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 06:12:31 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=gYnNjji+AYuQ+JxgkmnMIy2M94Wyf/Fn5FrcgrImlWc=;
        b=tSKMX+/qwbQsJqJJcERlHgFEXt+wP5t05TulzQH4BSs0XurtBUB2GFIIKExAGKjgOt
         Ne60iVPDan7pvFdXgPYSGGJ7TJCawtyxvH7rooodtIQPxdDt1LAZ5RyRdlPiSlykCDY7
         Q9reQ4lBhyIqDBB61/IBzcQvN3sG+7Q7AVBBQ8KxA5aSFWb1yd1STrKwt9owQ51rAWDO
         GI7uP1eV5GIZxkVgA1wr77dQG88LKCPBg5OV8TcW6yOz3bubDXnUsPBmjFhibtLPMW1c
         D/pd17aVYozTycW6zVHiFHM5I7i/yAKODqIWqi5Hh3lHw6Bq03ZdU6dJ2f26/7dLjpqO
         RlXA==
MIME-Version: 1.0
X-Received: by 10.68.241.102 with SMTP id wh6mr57781233pbc.18.1424268751803;
 Wed, 18 Feb 2015 06:12:31 -0800 (PST)
Received: by 10.70.77.33 with HTTP; Wed, 18 Feb 2015 06:12:31 -0800 (PST)
In-Reply-To: <D109561E.9161%mcheah@palantir.com>
References: <D109561E.9161%mcheah@palantir.com>
Date: Wed, 18 Feb 2015 06:12:31 -0800
Message-ID: <CAOEPXP5wDrSROScvTQi3CYdPXRcCioqTe-R6YydbUmy5zcZzKQ@mail.gmail.com>
Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero value reasoning?
From: Josh Rosen <rosenville@gmail.com>
To: Matt Cheah <mcheah@palantir.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, 
	Andrew Ash <aash@palantir.com>
Content-Type: multipart/alternative; boundary=047d7b339d19042247050f5d69c5
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b339d19042247050f5d69c5
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

It looks like this was fixed in
https://issues.apache.org/jira/browse/SPARK-4743 /
https://github.com/apache/spark/pull/3605.  Can you see whether that patch
fixes this issue for you?



On Tue, Feb 17, 2015 at 8:31 PM, Matt Cheah <mcheah@palantir.com> wrote:

> Hi everyone,
>
> I was using JavaPairRDD=E2=80=99s combineByKey() to compute all of my agg=
regations
> before, since I assumed that every aggregation required a key. However, I
> realized I could do my analysis using JavaRDD=E2=80=99s aggregate() inste=
ad and not
> use a key.
>
> I have set spark.serializer to use Kryo. As a result, JavaRDD=E2=80=99s
> combineByKey requires that a =E2=80=9CcreateCombiner=E2=80=9D function is=
 provided, and the
> return value from that function must be serializable using Kryo. When I
> switched to using rdd.aggregate I assumed that the zero value would also =
be
> strictly Kryo serialized, as it is a data item and not part of a closure =
or
> the aggregation functions. However, I got a serialization exception as th=
e
> closure serializer (only valid serializer is the Java serializer) was use=
d
> instead.
>
> I was wondering the following:
>
>    1. What is the rationale for making the zero value be serialized using
>    the closure serializer? This isn=E2=80=99t part of the closure, but is=
 an initial
>    data item.
>    2. Would it make sense for us to perhaps write a version of
>    rdd.aggregate() that takes a function as a parameter, that generates t=
he
>    zero value? This would be more intuitive to be serialized using the cl=
osure
>    serializer.
>
> I believe aggregateByKey is also affected.
>
> Thanks,
>
> -Matt Cheah
>

--047d7b339d19042247050f5d69c5--

From dev-return-11662-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 15:10:51 2015
Return-Path: <dev-return-11662-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 12FBD17941
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 15:10:51 +0000 (UTC)
Received: (qmail 64440 invoked by uid 500); 18 Feb 2015 15:10:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64370 invoked by uid 500); 18 Feb 2015 15:10:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64359 invoked by uid 99); 18 Feb 2015 15:10:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 15:10:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 15:10:42 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so2855669obc.5
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 07:10:02 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=y/Cd7cmrWeWWiEh5rCDmN9ZO/XTsHHQtqXBiC6oL2jc=;
        b=Ae1W/ljxPMujZZs0N4ig9+2bAChNUV36o19/MEuIMkQOMdHid4wNpnrT2HFXNscdQx
         Gb8I9rjVPryIACGyBsrjjJR7NEG8ubMAnP0ZGnjkMyV3Ps8/Y0uUl4Ccuc03AadQL9jw
         i0GYB+m93MeoM09EqRrNCiOq/QBjYx+4C6vhtFIwbD8kb+10uXU5xoBRSk0Jo9in4pr+
         gUFYXWT4iJR9QLOOcVyOPhatxhST32iu11YWkzIjNuWl+4h/zNQbChQceVwneE90Iaaa
         KWEkiNHDoz/lFaytaHfgvCtcRQzRbFbVV3OnTuswGM766+ZvLokN5zMC80xUiuDX/B1X
         Vs2A==
X-Gm-Message-State: ALoCoQnpKHYSucLnbyeUzmbV/hiANYeAZjAcBvzBVKXsO4rkfYquamdJ9tWGH5uBahZV0b41NSMp
X-Received: by 10.182.251.138 with SMTP id zk10mr113025obc.72.1424272201870;
        Wed, 18 Feb 2015 07:10:01 -0800 (PST)
Received: from mail-ob0-f177.google.com (mail-ob0-f177.google.com. [209.85.214.177])
        by mx.google.com with ESMTPSA id ml5sm12935943oeb.6.2015.02.18.07.10.00
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 18 Feb 2015 07:10:00 -0800 (PST)
Received: by mail-ob0-f177.google.com with SMTP id wp18so2751208obc.8
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 07:09:59 -0800 (PST)
X-Received: by 10.202.63.132 with SMTP id m126mr20692111oia.33.1424272199688;
 Wed, 18 Feb 2015 07:09:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.182.182.99 with HTTP; Wed, 18 Feb 2015 07:09:39 -0800 (PST)
From: Andrew Ash <andrew@andrewash.com>
Date: Wed, 18 Feb 2015 07:09:39 -0800
Message-ID: <CA+-p3AHaZ_Q7ZE6vn2YVevQiXQhGn8cYnaM9KjeF7tKeBZk2=w@mail.gmail.com>
Subject: Streaming partitions to driver for use in .toLocalIterator
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d660a86aaad050f5e367c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d660a86aaad050f5e367c
Content-Type: text/plain; charset=UTF-8

Hi Spark devs,

I'm creating a streaming export functionality for RDDs and am having some
trouble with large partitions.  The RDD.toLocalIterator() call pulls over a
partition at a time to the driver, and then streams the RDD out from that
partition before pulling in the next one.  When you have large partitions
though, you can OOM the driver, especially when multiple of these exports
are happening in the same SparkContext.

One idea I had was to repartition the RDD so partitions are smaller, but
it's hard to know a priori what the partition count should be, and I'd like
to avoid paying the shuffle cost if possible -- I think repartition to a
higher partition count forces a shuffle.

Is it feasible to rework this so the executor -> driver transfer in
.toLocalIterator is a steady stream rather than a partition at a time?

Thanks!
Andrew

--001a113d660a86aaad050f5e367c--

From dev-return-11663-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 15:41:20 2015
Return-Path: <dev-return-11663-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D8AA217A4E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 15:41:20 +0000 (UTC)
Received: (qmail 82171 invoked by uid 500); 18 Feb 2015 15:41:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82097 invoked by uid 500); 18 Feb 2015 15:41:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82086 invoked by uid 99); 18 Feb 2015 15:41:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 15:41:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 15:41:10 +0000
Received: by pdbfl12 with SMTP id fl12so1925598pdb.2
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 07:39:45 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=nifUqQXmA3DWv/xGFA8tAJsaqaIKEQG/afoir335BBo=;
        b=gAgF9Xd2Jp94ShLm8DiwhFqPPTHMpi3nd9cl8MMvEr1uzN1Vd+FN34YXW9bZTn7FP9
         QYmv//zszicL4e4CztFfeO1gCukuligjXMtwgRqKeaMdO7ZhA7ej8CIDOC8CgRjgfkJ+
         W/wIi29cQfkIBkOiZwsFyar8LuCw/b+IAbSVsvN7XS/QDMLwdI3KptZ+wyx0U321zahc
         zNVwRCbm9ArhDJUVwb4psKEnhTvcEZXYk5LGQ9UX3Pxw1AlYDTdVHxh1RLNDt7+r+9K7
         JSjHiPYSuEW6tnsIg2wAa+c3rQ8x/kN9bFCdnY7/8r62BilZF1I5gen0+RAKzQf1JUIt
         4cYw==
X-Gm-Message-State: ALoCoQlHt/FIdi1MFwoVvAgiSVb6y31W6KaKgHJzMqF+BTAGJbgY24ifXqksGq+4f94xlYdKhIl9
MIME-Version: 1.0
X-Received: by 10.70.28.130 with SMTP id b2mr6394834pdh.48.1424273985236; Wed,
 18 Feb 2015 07:39:45 -0800 (PST)
Received: by 10.66.236.7 with HTTP; Wed, 18 Feb 2015 07:39:45 -0800 (PST)
Date: Wed, 18 Feb 2015 15:39:45 +0000
Message-ID: <CAM-zAQYBQ=veiy+HMHTaV=Fcfr0H92hs8is-DoHARED-+NkdpQ@mail.gmail.com>
Subject: Issue SPARK-5008 (persistent-hdfs broken)
From: Joe Wass <jwass@crossref.org>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7bf0ecacf4f898050f5ea0eb
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0ecacf4f898050f5ea0eb
Content-Type: text/plain; charset=UTF-8

I've recently run into problems caused by ticket SPARK-5008

https://issues.apache.org/jira/browse/SPARK-5008

This seems like quite a serious regression in 1.2.0, meaning that it's not
really possible to use persistent-hdfs. The config for the persistent-hdfs
points to the wrong part of the filesystem, so it comes up on the wrong
volume (and therefore has the wrong capacity). I'm working around it with
symlinks, but it's not ideal.

It doesn't look like it's scheduled to be fixed in any particular release.
Is there any indication of whether this is on anyone's todo list?

If no-one's looking into it then I could try having a look myself, but I'm
not (yet) familiar with the internals. From the discussion on the ticket it
doesn't look like a huge fix.

Cheers

Joe

--047d7bf0ecacf4f898050f5ea0eb--

From dev-return-11664-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 18:15:25 2015
Return-Path: <dev-return-11664-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 13BC11015A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 18:15:25 +0000 (UTC)
Received: (qmail 99221 invoked by uid 500); 18 Feb 2015 18:15:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99164 invoked by uid 500); 18 Feb 2015 18:15:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99142 invoked by uid 99); 18 Feb 2015 18:15:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 18:15:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 18:14:35 +0000
Received: by mail-ob0-f180.google.com with SMTP id vb8so5063348obc.11
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 10:13:48 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=PvCcY4HOEMnjkW1yG+kGML8+cwpsZRLG6z7hOj9IERY=;
        b=aWTuAxmF1zIR5/GTBSE8smfz2BNjSX3Q/VuYDl00bUhmAP3x91wyoTsPiqCEWJPsLX
         WOaZ/rMukKulVQeFtzKmiJ9SYVNWkhiyVjkSgue4sYn7axEQWq2qNVdWawH1AcHxGav3
         0ycOi62/tLza52f9rbwXdhKt0FQOKKhEoLdAyt2gXRdLXjeB8h05ZoJ9WoViW7juO/sF
         i/v3THk2iNKc1B8PE/UwBQ50EswRHdV8eLgF4bk82BP1cHfvuN+0arChEBkFWBcLHjed
         p/IRMfKEV6onNrNtw/EL3LgM5Sy/mpVk8g4NZZ0OER0c2Oupm1SOEOPkmICULNhOoaig
         MTKA==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr358664oit.100.1424283228852;
 Wed, 18 Feb 2015 10:13:48 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 18 Feb 2015 10:13:48 -0800 (PST)
In-Reply-To: <CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
Date: Wed, 18 Feb 2015 10:13:48 -0800
Message-ID: <CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Patrick Wendell <pwendell@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

> UISeleniumSuite:
> *** RUN ABORTED ***
>   java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal
> ...

This is a newer test suite. There is something flaky about it, we
should definitely fix it, IMO it's not a blocker though.

>
> Patrick this link gives a 404:
> https://people.apache.org/keys/committer/pwendell.asc

Works for me. Maybe it's some ephemeral issue?

> Finally, I already realized I failed to get the fix for
> https://issues.apache.org/jira/browse/SPARK-5669 correct, and that has
> to be correct for the release. I'll patch that up straight away,
> sorry. I believe the result of the intended fix is still as I
> described in SPARK-5669, so there is no bad news there. A local test
> seems to confirm it and I'm waiting on Jenkins. If it's all good I'll
> merge that fix. So, that much will need a new release, I apologize.

Thanks for finding this. I'm going to leave this open for continued testing...

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11665-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 20:56:21 2015
Return-Path: <dev-return-11665-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6175B10A1F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 20:56:21 +0000 (UTC)
Received: (qmail 91787 invoked by uid 500); 18 Feb 2015 20:56:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91711 invoked by uid 500); 18 Feb 2015 20:56:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91699 invoked by uid 99); 18 Feb 2015 20:56:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 20:56:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.48 as permitted sender)
Received: from [209.85.215.48] (HELO mail-la0-f48.google.com) (209.85.215.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 20:56:10 +0000
Received: by labms9 with SMTP id ms9so3769082lab.10
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 12:55:48 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=FTHvkA/yZQ63+a80+jpsI7ffKHMNm3ytv1Gu7xXoM0Y=;
        b=K+NfaY2LLpV0vPtEOQgOn2hHE4wu5TUUbioyc8BGZ6kVDGaJ8gSrFWZheYXrjJMKt+
         +0cK/vc0xrk2VmsUars330F3/iDW7gCXZT26oiffMdA7upehGzADPWy5GAvv+xoEOs3f
         olC5/O0Bf8C8P/m5LdZPqqYwKtGL1OOD/AK3Ofogo1GaZN+UzyLrYLGKZJa6biE+gGAL
         sWphVFfwEhVebdY4giGsLSOMXobQS/0HJ6oGzMByYP5gxoKeYf8UuPUxsCHKyqZ4+TbI
         xTLQnL87vnIlfWiOLJD0QCLsAONN17H600rT+1sc0smx91uLS7ABlk3cAWzEt6g8542a
         9W0A==
X-Gm-Message-State: ALoCoQnCnLAj6VOOFR9NlMiHvrLMsbu/S2rhFMNEVsSS0rNV2aSbiAjf8yADjXg3ixqPCCqaCyx/
X-Received: by 10.112.41.171 with SMTP id g11mr980860lbl.107.1424292948272;
 Wed, 18 Feb 2015 12:55:48 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Wed, 18 Feb 2015 12:55:27 -0800 (PST)
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 18 Feb 2015 12:55:27 -0800
Message-ID: <CACdU-dT=yy0Vfxt=dM6Mj8HKiiFLuHbRM=ZKdigt-2eCEDQDAw@mail.gmail.com>
Subject: quick jenkins restart tomorrow morning, ~7am PST
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11346d9c3cf3be050f630bf5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11346d9c3cf3be050f630bf5
Content-Type: text/plain; charset=UTF-8

i'll be kicking jenkins to up the open file limits on the workers.  it
should be a very short downtime, and i'll post updates on my progress
tomorrow.

shane

--001a11346d9c3cf3be050f630bf5--

From dev-return-11666-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 21:04:09 2015
Return-Path: <dev-return-11666-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BD5A810A93
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 21:04:09 +0000 (UTC)
Received: (qmail 27172 invoked by uid 500); 18 Feb 2015 21:04:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27094 invoked by uid 500); 18 Feb 2015 21:04:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27081 invoked by uid 99); 18 Feb 2015 21:04:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 21:04:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of irashid@cloudera.com designates 74.125.82.53 as permitted sender)
Received: from [74.125.82.53] (HELO mail-wg0-f53.google.com) (74.125.82.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 21:03:40 +0000
Received: by mail-wg0-f53.google.com with SMTP id a1so3499408wgh.12
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 13:01:24 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=NiD7X8ETZ8ez8gaSsKowtoYb02duxKwjhkt4Pf8FvrA=;
        b=LQjNEqN+z84kJpLYuLDcjOx4ftnKTJYuOe/YEMmVxhtJJb484YDOQit+xj93wTaLuj
         rCU2vqOgTbIcmAMdZGwQ3Y6dqRwPiZhwqUPD9VIHe1qadBwhze35WHeSvEBWGo8lcvhR
         LMLrTvk0sCSEsZ7j71AsYvKEqnHkf/7SB99f2XU+7HoDSg/f0wY2ZViHqDh6LSdUkawr
         TpqoUyx+f/1yU7QuhnWeioU5M7rz4TSum8PmWvYZmF2aiGMMt0tUdgb8J7cZr8aumUrq
         wLKnYDeCENV+hgW39y0zDZeicPZL4C08unfJS2prHamAN+zJ6MtbsrCYWV+wd+9K53Ex
         6zdg==
X-Gm-Message-State: ALoCoQlZEas7MFk059toun+R07dOcfMHx3n9+JcLi8iqn5SGOx4kg689MQpt1hmBg2xBgDMm7O6I
X-Received: by 10.194.171.136 with SMTP id au8mr2778267wjc.6.1424293282412;
 Wed, 18 Feb 2015 13:01:22 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.200.134 with HTTP; Wed, 18 Feb 2015 13:01:01 -0800 (PST)
In-Reply-To: <CA+-p3AHaZ_Q7ZE6vn2YVevQiXQhGn8cYnaM9KjeF7tKeBZk2=w@mail.gmail.com>
References: <CA+-p3AHaZ_Q7ZE6vn2YVevQiXQhGn8cYnaM9KjeF7tKeBZk2=w@mail.gmail.com>
From: Imran Rashid <irashid@cloudera.com>
Date: Wed, 18 Feb 2015 15:01:02 -0600
Message-ID: <CA+3qhFQviWYtFceAxZrZpNeWd+RTp=s50dGodWzB71T3Y3ydLw@mail.gmail.com>
Subject: Re: Streaming partitions to driver for use in .toLocalIterator
To: Andrew Ash <andrew@andrewash.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122f58c2794aa050f631f3d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122f58c2794aa050f631f3d
Content-Type: text/plain; charset=UTF-8

This would be pretty tricky to do -- the issue is that right now
sparkContext.runJob has you pass in a function from a partition to *one*
result object that gets serialized and sent back: Iterator[T] => U, and
that idea is baked pretty deep into a lot of the internals, DAGScheduler,
Task, Executors, etc.

Maybe another possibility worth considering: should we make it easy to go
from N partitions to 2N partitions (or any other multiple obviously)
without requiring a shuffle?  for that matter, you should also be able to
go from 2N to N without a shuffle as well.  That change is also somewhat
involved, though.

Both are in theory possible, but I imagine they'd need really compelling
use cases.

An alternative would be to write your RDD to some other data store (eg,
hdfs) which has better support for reading data in a streaming fashion,
though you would probably be unhappy with the overhead.



On Wed, Feb 18, 2015 at 9:09 AM, Andrew Ash <andrew@andrewash.com> wrote:

> Hi Spark devs,
>
> I'm creating a streaming export functionality for RDDs and am having some
> trouble with large partitions.  The RDD.toLocalIterator() call pulls over a
> partition at a time to the driver, and then streams the RDD out from that
> partition before pulling in the next one.  When you have large partitions
> though, you can OOM the driver, especially when multiple of these exports
> are happening in the same SparkContext.
>
> One idea I had was to repartition the RDD so partitions are smaller, but
> it's hard to know a priori what the partition count should be, and I'd like
> to avoid paying the shuffle cost if possible -- I think repartition to a
> higher partition count forces a shuffle.
>
> Is it feasible to rework this so the executor -> driver transfer in
> .toLocalIterator is a steady stream rather than a partition at a time?
>
> Thanks!
> Andrew
>

--089e0122f58c2794aa050f631f3d--

From dev-return-11667-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 22:01:03 2015
Return-Path: <dev-return-11667-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CF69910DF5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 22:01:03 +0000 (UTC)
Received: (qmail 8803 invoked by uid 500); 18 Feb 2015 22:01:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8723 invoked by uid 500); 18 Feb 2015 22:01:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8712 invoked by uid 99); 18 Feb 2015 22:01:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:01:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:00:37 +0000
Received: by labgq15 with SMTP id gq15so4140293lab.3
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 14:00:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=8wqR9HfRrDLyKwQ5S9DsVi/yEUdzpagJJUB0IfJSY0Y=;
        b=KO9HaS0nBRrXCLHAH5CkvGy1BE6HAtNslCcIaH5I5uNBnbmb/wiQpXtqHzEZNik+OZ
         RO3c7A6SAmx+QcvPE8QZn/Es5j79VUOCljp/RXuQvzCiP/c+klZtDiqFZpC+ZhyOdNIb
         +4Iu3aN1mILAuLsZMz5OWFA7RhRKKeaIniCX6YvzIjc+gkSpddn9DF9z2VG8XW5AdsYl
         9cRCUX7LBh89CMu1BwqWhdHpkTxFOStYJwLZwpnLzIN2sddvs0rDSkOqP7huc1FMkn/C
         UhwRiFqunRBRIEi7svuOucaFPuGWEo9ot2UMrXfa+JiOXkOdY9fpcNaWJWApYuZSAzHW
         9Tew==
X-Gm-Message-State: ALoCoQl7x65F3I/tGpaynQZnUVvtCxhCscIaHoyq8uwz7HVPLhmU76LH/qjA7tJI+a//CDHx7Hr1
X-Received: by 10.112.167.4 with SMTP id zk4mr1337998lbb.74.1424296835697;
 Wed, 18 Feb 2015 14:00:35 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Wed, 18 Feb 2015 14:00:15 -0800 (PST)
In-Reply-To: <CACdU-dT=yy0Vfxt=dM6Mj8HKiiFLuHbRM=ZKdigt-2eCEDQDAw@mail.gmail.com>
References: <CACdU-dT=yy0Vfxt=dM6Mj8HKiiFLuHbRM=ZKdigt-2eCEDQDAw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 18 Feb 2015 14:00:15 -0800
Message-ID: <CACdU-dRaG+=XJ-WQvtxjTLyzXvWYkFw+n4LHLwNf5PbG3aER+w@mail.gmail.com>
Subject: Re: quick jenkins restart tomorrow morning, ~7am PST
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c3488cf25cba050f63f2c8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3488cf25cba050f63f2c8
Content-Type: text/plain; charset=UTF-8

i'm actually going to do this now -- it's really quiet today.

there are two spark pull request builds running, which i will kill and
retrigger once jenkins is back up:
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/27689/
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/27690/

On Wed, Feb 18, 2015 at 12:55 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i'll be kicking jenkins to up the open file limits on the workers.  it
> should be a very short downtime, and i'll post updates on my progress
> tomorrow.
>
> shane
>

--001a11c3488cf25cba050f63f2c8--

From dev-return-11668-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 22:09:37 2015
Return-Path: <dev-return-11668-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0866B10EAB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 22:09:37 +0000 (UTC)
Received: (qmail 31198 invoked by uid 500); 18 Feb 2015 22:09:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31123 invoked by uid 500); 18 Feb 2015 22:09:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31107 invoked by uid 99); 18 Feb 2015 22:09:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:09:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:09:31 +0000
Received: by lbdu14 with SMTP id u14so4101667lbd.1
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 14:06:55 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=5jWYVd2zdERPWNLsLP7fegvzhjYKF3gk3zMCL+Xb3vk=;
        b=g/OUKxzYEvRHUaNp0ApZnwoQojiTESllc9kKiZAVHcCxUNzKsWIAGLowfW1OT93ka8
         8PTTHYQXqB32BZ3vYB6CC5zQ5QkzeXC2IGYPjMZtSc32irxgtdXJVBImEIItXEc5KpE0
         ooF0FBpY6vwv+KsoaNcSCCCeXWmLvdQdxuQnLVYVrb07L/o3uCdCd0emBGuYvmDrQvZ+
         RttHis3gzhZEmAIBMFdnYY1on6v49l8qrWCmKLszWnzeJti8XaaC3ulqPfEiqWwTNC1X
         IfvbNDterGPrJf1hNNR4wfJMUwE9UJnk45ZaM9Aqa84G5pbPIFvCNSgeH2l6poL2mfq2
         GBUw==
X-Gm-Message-State: ALoCoQl331ohaC07RE+thfHGyUbFJq1qvoucsKs36BL4HrG7zWsPi5ppguSkRGXGZNXipj/SiURL
X-Received: by 10.113.11.162 with SMTP id ej2mr1431680lbd.30.1424297215331;
 Wed, 18 Feb 2015 14:06:55 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Wed, 18 Feb 2015 14:06:35 -0800 (PST)
In-Reply-To: <CACdU-dRaG+=XJ-WQvtxjTLyzXvWYkFw+n4LHLwNf5PbG3aER+w@mail.gmail.com>
References: <CACdU-dT=yy0Vfxt=dM6Mj8HKiiFLuHbRM=ZKdigt-2eCEDQDAw@mail.gmail.com>
 <CACdU-dRaG+=XJ-WQvtxjTLyzXvWYkFw+n4LHLwNf5PbG3aER+w@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 18 Feb 2015 14:06:35 -0800
Message-ID: <CACdU-dS+BHydNO49i6zqLaDXjyMbQwV2F7Y19HsktTbYPfJL=A@mail.gmail.com>
Subject: Re: quick jenkins restart tomorrow morning, ~7am PST
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a1135e7e69325a7050f6409b9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135e7e69325a7050f6409b9
Content-Type: text/plain; charset=UTF-8

this is done.

On Wed, Feb 18, 2015 at 2:00 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i'm actually going to do this now -- it's really quiet today.
>
> there are two spark pull request builds running, which i will kill and
> retrigger once jenkins is back up:
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/27689/
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/27690/
>
> On Wed, Feb 18, 2015 at 12:55 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i'll be kicking jenkins to up the open file limits on the workers.  it
>> should be a very short downtime, and i'll post updates on my progress
>> tomorrow.
>>
>> shane
>>
>
>

--001a1135e7e69325a7050f6409b9--

From dev-return-11669-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 22:29:28 2015
Return-Path: <dev-return-11669-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AEA0E10FF5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 22:29:28 +0000 (UTC)
Received: (qmail 85717 invoked by uid 500); 18 Feb 2015 22:29:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85639 invoked by uid 500); 18 Feb 2015 22:29:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85624 invoked by uid 99); 18 Feb 2015 22:29:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:29:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mcheah@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:29:02 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Wed, 18
 Feb 2015 14:28:16 -0800
From: Matt Cheah <mcheah@palantir.com>
To: Josh Rosen <rosenville@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
	<mkim@palantir.com>, Andrew Ash <aash@palantir.com>
Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero value
 reasoning?
Thread-Topic: JavaRDD Aggregate initial value - Closure-serialized zero
 value reasoning?
Thread-Index: AQHQSzPN6LwMFRGQVEeRI4YxS85fiZz2+ZKAgAAE6gA=
Date: Wed, 18 Feb 2015 22:28:15 +0000
Message-ID: <D10A5141.9279%mcheah@palantir.com>
References: <D109561E.9161%mcheah@palantir.com>
 <CAOEPXP5wDrSROScvTQi3CYdPXRcCioqTe-R6YydbUmy5zcZzKQ@mail.gmail.com>
In-Reply-To: <CAOEPXP5wDrSROScvTQi3CYdPXRcCioqTe-R6YydbUmy5zcZzKQ@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.84.245]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507114606_947863"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507114606_947863
Content-type: multipart/alternative;
	boundary="B_3507114606_948702"


--B_3507114606_948702
Content-type: text/plain;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

But RDD.aggregate() has this code:

    // Clone the zero value since we will also be serializing it as part of
tasks
    var jobResult =3D Utils.clone(zeroValue,
sc.env.closureSerializer.newInstance())

I do see the SparkEnv.get.serializer used in aggregateByKey however. Perhap=
s
we just missed it and need to apply the change to aggregate()? It seems
appropriate to target a fix for 1.3.0.

-Matt Cheah
From:  Josh Rosen <rosenville@gmail.com>
Date:  Wednesday, February 18, 2015 at 6:12 AM
To:  Matt Cheah <mcheah@palantir.com>
Cc:  "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
<mkim@palantir.com>, Andrew Ash <aash@palantir.com>
Subject:  Re: JavaRDD Aggregate initial value - Closure-serialized zero
value reasoning?

It looks like this was fixed in
https://issues.apache.org/jira/browse/SPARK-4743
<https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__issues.apache.org_jir=
a
_browse_SPARK-2D4743&d=3DAwMFaQ&c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8=
&
r=3DhzwIMNQ9E99EMYGuqHI0kXhVbvX3nU3OSDadUnJxjAs&m=3DHsNLIeID8mKWH68HoNyb_x4jS5D=
3
WSrjQQZX1rW_e9w&s=3DlOqRteYjf7RRl41OfKvkfh7IaSs3wIW643Fz_Iwlekc&e=3D>  /
https://github.com/apache/spark/pull/3605
<https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__github.com_apache_spa=
r
k_pull_3605&d=3DAwMFaQ&c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=3DhzwIMN=
Q
9E99EMYGuqHI0kXhVbvX3nU3OSDadUnJxjAs&m=3DHsNLIeID8mKWH68HoNyb_x4jS5D3WSrjQQZX=
1
rW_e9w&s=3D60tyF-5TbJyVlh7upvFFhNbxKFhh9bUCWJMp5D2wUN8&e=3D> .  Can you see
whether that patch fixes this issue for you?



On Tue, Feb 17, 2015 at 8:31 PM, Matt Cheah <mcheah@palantir.com> wrote:
> Hi everyone,
>=20
> I was using JavaPairRDD=B9s combineByKey() to compute all of my aggregation=
s
> before, since I assumed that every aggregation required a key. However, I
> realized I could do my analysis using JavaRDD=B9s aggregate() instead and n=
ot
> use a key.
>=20
> I have set spark.serializer to use Kryo. As a result, JavaRDD=B9s combineBy=
Key
> requires that a =B3createCombiner=B2 function is provided, and the return val=
ue
> from that function must be serializable using Kryo. When I switched to us=
ing
> rdd.aggregate I assumed that the zero value would also be strictly Kryo
> serialized, as it is a data item and not part of a closure or the aggrega=
tion
> functions. However, I got a serialization exception as the closure serial=
izer
> (only valid serializer is the Java serializer) was used instead.
>=20
> I was wondering the following:
> 1. What is the rationale for making the zero value be serialized using th=
e
> closure serializer? This isn=B9t part of the closure, but is an initial dat=
a
> item.
> 2. Would it make sense for us to perhaps write a version of rdd.aggregate=
()
> that takes a function as a parameter, that generates the zero value? This
> would be more intuitive to be serialized using the closure serializer.
> I believe aggregateByKey is also affected.
>=20
> Thanks,
>=20
> -Matt Cheah




--B_3507114606_948702
Content-type: text/html;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

<html><head></head><body style=3D"word-wrap: break-word; -webkit-nbsp-mode: s=
pace; -webkit-line-break: after-white-space; color: rgb(0, 0, 0); font-size:=
 14px; font-family: Calibri, sans-serif;"><div>But RDD.aggregate() has this =
code:</div><div><br></div><div><div>&nbsp; &nbsp; // Clone the zero value si=
nce we will also be serializing it as part of tasks</div><div>&nbsp; &nbsp; =
var jobResult =3D Utils.clone(zeroValue, sc.env.closureSerializer.newInstance(=
))</div></div><div><br></div><div>I do see the SparkEnv.get.serializer used =
in aggregateByKey however. Perhaps we just missed it and need to apply the c=
hange to aggregate()? It seems appropriate to target a fix for 1.3.0.</div><=
div><br></div><div>-Matt Cheah</div><span id=3D"OLK_SRC_BODY_SECTION"><div sty=
le=3D"font-family:Calibri; font-size:11pt; text-align:left; color:black; BORDE=
R-BOTTOM: medium none; BORDER-LEFT: medium none; PADDING-BOTTOM: 0in; PADDIN=
G-LEFT: 0in; PADDING-RIGHT: 0in; BORDER-TOP: #b5c4df 1pt solid; BORDER-RIGHT=
: medium none; PADDING-TOP: 3pt"><span style=3D"font-weight:bold">From: </span=
> Josh Rosen &lt;<a href=3D"mailto:rosenville@gmail.com">rosenville@gmail.com<=
/a>&gt;<br><span style=3D"font-weight:bold">Date: </span> Wednesday, February =
18, 2015 at 6:12 AM<br><span style=3D"font-weight:bold">To: </span> Matt Cheah=
 &lt;<a href=3D"mailto:mcheah@palantir.com">mcheah@palantir.com</a>&gt;<br><sp=
an style=3D"font-weight:bold">Cc: </span> "<a href=3D"mailto:dev@spark.apache.or=
g">dev@spark.apache.org</a>" &lt;<a href=3D"mailto:dev@spark.apache.org">dev@s=
park.apache.org</a>&gt;, Mingyu Kim &lt;<a href=3D"mailto:mkim@palantir.com">m=
kim@palantir.com</a>&gt;, Andrew Ash &lt;<a href=3D"mailto:aash@palantir.com">=
aash@palantir.com</a>&gt;<br><span style=3D"font-weight:bold">Subject: </span>=
 Re: JavaRDD Aggregate initial value - Closure-serialized zero value reasoni=
ng?<br></div><div><br></div><div><meta http-equiv=3D"Content-Type" content=3D"te=
xt/html; charset=3Dutf-8"><div><div dir=3D"ltr">It looks like this was fixed in =
<a href=3D"https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__issues.apache.=
org_jira_browse_SPARK-2D4743&amp;d=3DAwMFaQ&amp;c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2U=
XBrZ4tFb6oOnmz8&amp;r=3DhzwIMNQ9E99EMYGuqHI0kXhVbvX3nU3OSDadUnJxjAs&amp;m=3DHsNL=
IeID8mKWH68HoNyb_x4jS5D3WSrjQQZX1rW_e9w&amp;s=3DlOqRteYjf7RRl41OfKvkfh7IaSs3wI=
W643Fz_Iwlekc&amp;e=3D">
https://issues.apache.org/jira/browse/SPARK-4743</a> / <a href=3D"https://url=
defense.proofpoint.com/v2/url?u=3Dhttps-3A__github.com_apache_spark_pull_3605&=
amp;d=3DAwMFaQ&amp;c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&amp;r=3DhzwIMNQ=
9E99EMYGuqHI0kXhVbvX3nU3OSDadUnJxjAs&amp;m=3DHsNLIeID8mKWH68HoNyb_x4jS5D3WSrjQ=
QZX1rW_e9w&amp;s=3D60tyF-5TbJyVlh7upvFFhNbxKFhh9bUCWJMp5D2wUN8&amp;e=3D">
https://github.com/apache/spark/pull/3605</a>.&nbsp; Can you see whether th=
at patch fixes this issue for you?
<div><br></div><div><br></div></div><div class=3D"gmail_extra"><br><div class=
=3D"gmail_quote">On Tue, Feb 17, 2015 at 8:31 PM, Matt Cheah <span dir=3D"ltr">
&lt;<a href=3D"mailto:mcheah@palantir.com" target=3D"_blank">mcheah@palantir.co=
m</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0=
 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div style=3D"word-wrap:b=
reak-word;color:rgb(0,0,0);font-size:14px;font-family:Calibri,sans-serif"><d=
iv>Hi everyone,</div><div><br></div><div>I was using JavaPairRDD&#8217;s com=
bineByKey() to compute all of my aggregations before, since I assumed that e=
very aggregation required a key. However, I realized I could do my analysis =
using JavaRDD&#8217;s aggregate() instead and not use a key.</div><div><br><=
/div><div>I have set spark.serializer to use Kryo. As a result, JavaRDD&#821=
7;s combineByKey requires that a &#8220;createCombiner&#8221; function is pr=
ovided, and the return value from that function must be serializable using K=
ryo. When I switched to using rdd.aggregate I assumed
 that the zero value would also be strictly Kryo serialized, as it is a dat=
a item and not part of a closure or the aggregation functions. However, I go=
t a serialization exception as the closure serializer (only valid serializer=
 is the Java serializer) was used
 instead.</div><div><br></div><div>I was wondering the following:</div><ol>=
<li>What is the rationale for making the zero value be serialized using the =
closure serializer? This isn&#8217;t part of the closure, but is an initial =
data item.</li><li>Would it make sense for us to perhaps write a version of =
rdd.aggregate() that takes a function as a parameter, that generates the zer=
o value? This would be more intuitive to be serialized using the closure ser=
ializer.</li></ol><div>I believe aggregateByKey is also affected.</div><div>=
<br></div><div>Thanks,</div><div><br></div><div>-Matt Cheah</div></div></blo=
ckquote></div><br></div></div></div></span></body></html>

--B_3507114606_948702--

--B_3507114606_947863
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507114606_947863--

From dev-return-11670-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 22:54:41 2015
Return-Path: <dev-return-11670-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47E931730F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 22:54:41 +0000 (UTC)
Received: (qmail 47521 invoked by uid 500); 18 Feb 2015 22:54:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47446 invoked by uid 500); 18 Feb 2015 22:54:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47428 invoked by uid 99); 18 Feb 2015 22:54:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:54:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:54:08 +0000
Received: by iecrd18 with SMTP id rd18so5203775iec.8
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 14:53:01 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=epf53aWsOTD/vjHBS+wUx1vRWicC2nQiMWAgCU2LBWQ=;
        b=jdAMicJjkS0m7AQhSt5znB/1PWwgYskpmCQ6vExX/HI9GnW/dg7lvCtYa3phP9z5pr
         yum/krKPbgO8iquqe0NpBCrfVcoPJ0nxXAGGyhHlY3JvoEZpOp8N3qYKg+q9iql/zzSL
         ++AmriOJUtzIoHPoa4p8T/2zrMROIx9p8brfX7cVBtLVPTMMCKZ5vgmFQ7wtcUeW8HXZ
         kc+4iVsZNoP3YOiTgwjVrkQZ+meXEF68h8zxYdPH/IDyYQLwI0QoOImGA8apxeVdhca0
         SfQRBPdK+V2cUg2yhk1W3rmd594wVtoBCFgX088CajnYoHMIvuRePbbphhEZkGtJQcU0
         FgYw==
X-Gm-Message-State: ALoCoQkyyKyD97MrDvchGDElkKmAMbSg4XcQlEsVxIs+OLpfZBBDKmuk4x/ATz+UBEcowCAISJkq
MIME-Version: 1.0
X-Received: by 10.107.170.220 with SMTP id g89mr2292115ioj.31.1424299980461;
 Wed, 18 Feb 2015 14:53:00 -0800 (PST)
Received: by 10.36.66.15 with HTTP; Wed, 18 Feb 2015 14:53:00 -0800 (PST)
In-Reply-To: <CAJgQjQ9iaw4VjUBZgei3QhA4VSGo2+-J9_yDPPNvbUg3FWgYpQ@mail.gmail.com>
References: <54DBA9BF.5080508@gmail.com>
	<CAJgQjQ9iaw4VjUBZgei3QhA4VSGo2+-J9_yDPPNvbUg3FWgYpQ@mail.gmail.com>
Date: Wed, 18 Feb 2015 14:53:00 -0800
Message-ID: <CAF7ADNqbCdZS-K_q+M=PubNvw3XbEVAv07iYooGovi4aqYE=Rg@mail.gmail.com>
Subject: Re: [ml] Lost persistence for fold in crossvalidation.
From: Joseph Bradley <joseph@databricks.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Peter Rudenko <petro.rudenko@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114159b863b75a050f64ae39
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114159b863b75a050f64ae39
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Now in JIRA form: https://issues.apache.org/jira/browse/SPARK-5844

On Tue, Feb 17, 2015 at 3:12 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> There are three different regParams defined in the grid and there are
> tree folds. For simplicity, we didn't split the dataset into three and
> reuse them, but do the split for each fold. Then we need to cache 3*3
> times. Note that the pipeline API is not yet optimized for
> performance. It would be nice to optimize its perforamnce in 1.4.
> -Xiangrui
>
> On Wed, Feb 11, 2015 at 11:13 AM, Peter Rudenko <petro.rudenko@gmail.com>
> wrote:
> > Hi i have a problem. Using spark 1.2 with Pipeline + GridSearch +
> > LogisticRegression. I=E2=80=99ve reimplemented LogisticRegression.fit m=
ethod and
> > comment out instances.unpersist()
> >
> > |override  def  fit(dataset:SchemaRDD,
> > paramMap:ParamMap):LogisticRegressionModel  =3D {
> >     println(s"Fitting dataset ${dataset.take(1000).toSeq.hashCode()} wi=
th
> > ParamMap $paramMap.")
> >     transformSchema(dataset.schema, paramMap, logging =3Dtrue)
> >     import  dataset.sqlContext._
> >     val  map  =3D  this.paramMap ++ paramMap
> >     val  instances  =3D  dataset.select(map(labelCol).attr,
> > map(featuresCol).attr)
> >       .map {
> >         case  Row(label:Double, features:Vector) =3D>
> >           LabeledPoint(label, features)
> >       }
> >
> >     if  (instances.getStorageLevel =3D=3DStorageLevel.NONE) {
> >       println("Instances not persisted")
> >       instances.persist(StorageLevel.MEMORY_AND_DISK)
> >     }
> >
> >      val  lr  =3D  (new  LogisticRegressionWithLBFGS)
> >       .setValidateData(false)
> >       .setIntercept(true)
> >     lr.optimizer
> >       .setRegParam(map(regParam))
> >       .setNumIterations(map(maxIter))
> >     val  lrm  =3D  new  LogisticRegressionModel(this, map,
> > lr.run(instances).weights)
> >     //instances.unpersist()
> >     // copy model params
> >     Params.inheritValues(map,this, lrm)
> >     lrm
> >   }
> > |
> >
> > CrossValidator feeds the same SchemaRDD for each parameter (same hash
> code),
> > but somewhere cache being flushed. The memory is enough. Here=E2=80=99s=
 the
> output:
> >
> > |Fitting dataset 2051470010 with ParamMap {
> >     DRLogisticRegression-f35ae4d3-regParam: 0.1
> > }.
> > Instances not persisted
> > Fitting dataset 2051470010 with ParamMap {
> >     DRLogisticRegression-f35ae4d3-regParam: 0.01
> > }.
> > Instances not persisted
> > Fitting dataset 2051470010 with ParamMap {
> >     DRLogisticRegression-f35ae4d3-regParam: 0.001
> > }.
> > Instances not persisted
> > Fitting dataset 802615223 with ParamMap {
> >     DRLogisticRegression-f35ae4d3-regParam: 0.1
> > }.
> > Instances not persisted
> > Fitting dataset 802615223 with ParamMap {
> >     DRLogisticRegression-f35ae4d3-regParam: 0.01
> > }.
> > Instances not persisted
> > |
> >
> > I have 3 parameters in GridSearch and 3 folds for CrossValidation:
> >
> > |
> > val  paramGrid  =3D  new  ParamGridBuilder()
> >   .addGrid(model.regParam,Array(0.1,0.01,0.001))
> >   .build()
> >
> > crossval.setEstimatorParamMaps(paramGrid)
> > crossval.setNumFolds(3)
> > |
> >
> > I assume that the data should be read and cached 3 times (1 to
> > numFolds).combinations(2) and be independent from number of parameters.
> But
> > i have 9 times data being read and cached.
> >
> > Thanks,
> > Peter Rudenko
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a114159b863b75a050f64ae39--

From dev-return-11671-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 22:59:42 2015
Return-Path: <dev-return-11671-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4840F1733B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 22:59:42 +0000 (UTC)
Received: (qmail 55498 invoked by uid 500); 18 Feb 2015 22:59:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55419 invoked by uid 500); 18 Feb 2015 22:59:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55408 invoked by uid 99); 18 Feb 2015 22:59:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:59:40 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 22:59:16 +0000
Received: by mail-wi0-f180.google.com with SMTP id h11so5575293wiw.1
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 14:59:14 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=iB10eKKQPULIiLMcnImeNyhslvyXWhg60DwScuSfZDE=;
        b=HUgo8sEz3P3bg2KKg8s1m+5IckIov5HNNU/uPmcCJVhchXxSOm/3TCy2NesivdF0T2
         O4I5crATCsvKjeFkPD0FPzyZ1euGd9FVWmTX+lR8i1xoDudKMc8JuBYmx8fEsg6F6bcW
         RwrLL9qR0ra+0buB8F3wlVt0ctDhFIfgM7Yi19CJG06YzNgn7qtQF3YbTAci7Id6V1Jo
         htnTwpuI6dQSw2I0VDlwnUrLLI8kx2PkeGyFyXYpgZEy/c95Y3RkIXkdm6vjiHlShqgy
         i8yY0U6T72LENlpMR4QMzLAb5bL6iQjrTKpqFlV0IYghcyC9dZZ14yU+AR95XBkqR7eb
         TxCw==
X-Gm-Message-State: ALoCoQlb1X9eKEIi1VWmYeGtgwEyEniJY3H/wyH2lYeeuItK6oLgo8U2KSqNF9MXAEXGxiKbfBO+
X-Received: by 10.194.243.1 with SMTP id wu1mr3120106wjc.69.1424300354847;
 Wed, 18 Feb 2015 14:59:14 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 18 Feb 2015 14:58:54 -0800 (PST)
In-Reply-To: <D10A5141.9279%mcheah@palantir.com>
References: <D109561E.9161%mcheah@palantir.com> <CAOEPXP5wDrSROScvTQi3CYdPXRcCioqTe-R6YydbUmy5zcZzKQ@mail.gmail.com>
 <D10A5141.9279%mcheah@palantir.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 18 Feb 2015 22:58:54 +0000
Message-ID: <CAMAsSdLgU3HLHtv6TJMTKv2JHEBAya=PzxxREC1JjxmqJhypcg@mail.gmail.com>
Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero value reasoning?
To: Matt Cheah <mcheah@palantir.com>
Cc: Josh Rosen <rosenville@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Mingyu Kim <mkim@palantir.com>, Andrew Ash <aash@palantir.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

That looks, at the least, inconsistent. As far as I know this should
be changed so that the zero value is always cloned via the non-closure
serializer. Any objection to that?

On Wed, Feb 18, 2015 at 10:28 PM, Matt Cheah <mcheah@palantir.com> wrote:
> But RDD.aggregate() has this code:
>
>     // Clone the zero value since we will also be serializing it as part =
of
> tasks
>     var jobResult =3D Utils.clone(zeroValue,
> sc.env.closureSerializer.newInstance())
>
> I do see the SparkEnv.get.serializer used in aggregateByKey however. Perh=
aps
> we just missed it and need to apply the change to aggregate()? It seems
> appropriate to target a fix for 1.3.0.
>
> -Matt Cheah
> From: Josh Rosen <rosenville@gmail.com>
> Date: Wednesday, February 18, 2015 at 6:12 AM
> To: Matt Cheah <mcheah@palantir.com>
> Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
> <mkim@palantir.com>, Andrew Ash <aash@palantir.com>
> Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero va=
lue
> reasoning?
>
> It looks like this was fixed in
> https://issues.apache.org/jira/browse/SPARK-4743 /
> https://github.com/apache/spark/pull/3605.  Can you see whether that patc=
h
> fixes this issue for you?
>
>
>
> On Tue, Feb 17, 2015 at 8:31 PM, Matt Cheah <mcheah@palantir.com> wrote:
>>
>> Hi everyone,
>>
>> I was using JavaPairRDD=E2=80=99s combineByKey() to compute all of my ag=
gregations
>> before, since I assumed that every aggregation required a key. However, =
I
>> realized I could do my analysis using JavaRDD=E2=80=99s aggregate() inst=
ead and not
>> use a key.
>>
>> I have set spark.serializer to use Kryo. As a result, JavaRDD=E2=80=99s
>> combineByKey requires that a =E2=80=9CcreateCombiner=E2=80=9D function i=
s provided, and the
>> return value from that function must be serializable using Kryo. When I
>> switched to using rdd.aggregate I assumed that the zero value would also=
 be
>> strictly Kryo serialized, as it is a data item and not part of a closure=
 or
>> the aggregation functions. However, I got a serialization exception as t=
he
>> closure serializer (only valid serializer is the Java serializer) was us=
ed
>> instead.
>>
>> I was wondering the following:
>>
>> What is the rationale for making the zero value be serialized using the
>> closure serializer? This isn=E2=80=99t part of the closure, but is an in=
itial data
>> item.
>> Would it make sense for us to perhaps write a version of rdd.aggregate()
>> that takes a function as a parameter, that generates the zero value? Thi=
s
>> would be more intuitive to be serialized using the closure serializer.
>>
>> I believe aggregateByKey is also affected.
>>
>> Thanks,
>>
>> -Matt Cheah
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11672-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 23:05:40 2015
Return-Path: <dev-return-11672-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 652D317378
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 23:05:40 +0000 (UTC)
Received: (qmail 65560 invoked by uid 500); 18 Feb 2015 23:05:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65480 invoked by uid 500); 18 Feb 2015 23:05:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65466 invoked by uid 99); 18 Feb 2015 23:05:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:05:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:05:14 +0000
Received: by mail-qc0-f169.google.com with SMTP id m20so3648466qcx.0
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 15:04:52 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=15kpXnQMIz0XfQ4ChC9dbjEf+djr/pxPGia0Y9aN5/U=;
        b=PEWoVwSjOUNputFlSR/EFXVEDZ+9FgDkM1Xi1jac72d9LB4IqCuSxvyLrWzbDk2D8w
         Xwtr+jrMi1yB+oNEg/wi88htsFcW0M4iZLiMkMCxbdUo94xgK5pItfOi647nHt7V4RS8
         /cHkJhZPv35p0UOza01DD+9MEY5wpioAnzCa2vT1h7bcu8fVXadeytNVMZrMkwfo1JyO
         nA/8xQ+zZrYO419PhwbgERnnjxWRlQ/uEgY2lELFTrwbnjEOkQ2P8s4EK1zPPLsW+WJo
         EcQFWVdUdjhDSp3XikgHrMqqXBvqY8Azzv89e1SodEgQSS4G6cttOG45fWIO6NzdBMKJ
         UbQw==
X-Gm-Message-State: ALoCoQlFHxLeQCtPz4D607goyg4JrkuBdsDTcTE7JZXnJPaOWviZ7/x9qTRLC2v20gPnTvMw/aAi
X-Received: by 10.140.43.199 with SMTP id e65mr5400334qga.34.1424300692282;
 Wed, 18 Feb 2015 15:04:52 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.155.132 with HTTP; Wed, 18 Feb 2015 15:04:32 -0800 (PST)
In-Reply-To: <CAMAsSdLgU3HLHtv6TJMTKv2JHEBAya=PzxxREC1JjxmqJhypcg@mail.gmail.com>
References: <D109561E.9161%mcheah@palantir.com> <CAOEPXP5wDrSROScvTQi3CYdPXRcCioqTe-R6YydbUmy5zcZzKQ@mail.gmail.com>
 <D10A5141.9279%mcheah@palantir.com> <CAMAsSdLgU3HLHtv6TJMTKv2JHEBAya=PzxxREC1JjxmqJhypcg@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 18 Feb 2015 15:04:32 -0800
Message-ID: <CAPh_B=bxL4SN4kz0i1HAv1pptnUXVyfF5Qxgawu3ypwgUEzbbw@mail.gmail.com>
Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero value reasoning?
To: Sean Owen <sowen@cloudera.com>
Cc: Matt Cheah <mcheah@palantir.com>, Josh Rosen <rosenville@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, Andrew Ash <aash@palantir.com>
Content-Type: multipart/alternative; boundary=001a113a9baad13722050f64d8ce
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a9baad13722050f64d8ce
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Yes, that's a bug and should be using the standard serializer.

On Wed, Feb 18, 2015 at 2:58 PM, Sean Owen <sowen@cloudera.com> wrote:

> That looks, at the least, inconsistent. As far as I know this should
> be changed so that the zero value is always cloned via the non-closure
> serializer. Any objection to that?
>
> On Wed, Feb 18, 2015 at 10:28 PM, Matt Cheah <mcheah@palantir.com> wrote:
> > But RDD.aggregate() has this code:
> >
> >     // Clone the zero value since we will also be serializing it as par=
t
> of
> > tasks
> >     var jobResult =3D Utils.clone(zeroValue,
> > sc.env.closureSerializer.newInstance())
> >
> > I do see the SparkEnv.get.serializer used in aggregateByKey however.
> Perhaps
> > we just missed it and need to apply the change to aggregate()? It seems
> > appropriate to target a fix for 1.3.0.
> >
> > -Matt Cheah
> > From: Josh Rosen <rosenville@gmail.com>
> > Date: Wednesday, February 18, 2015 at 6:12 AM
> > To: Matt Cheah <mcheah@palantir.com>
> > Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
> > <mkim@palantir.com>, Andrew Ash <aash@palantir.com>
> > Subject: Re: JavaRDD Aggregate initial value - Closure-serialized zero
> value
> > reasoning?
> >
> > It looks like this was fixed in
> > https://issues.apache.org/jira/browse/SPARK-4743 /
> > https://github.com/apache/spark/pull/3605.  Can you see whether that
> patch
> > fixes this issue for you?
> >
> >
> >
> > On Tue, Feb 17, 2015 at 8:31 PM, Matt Cheah <mcheah@palantir.com> wrote=
:
> >>
> >> Hi everyone,
> >>
> >> I was using JavaPairRDD=E2=80=99s combineByKey() to compute all of my
> aggregations
> >> before, since I assumed that every aggregation required a key. However=
,
> I
> >> realized I could do my analysis using JavaRDD=E2=80=99s aggregate() in=
stead and
> not
> >> use a key.
> >>
> >> I have set spark.serializer to use Kryo. As a result, JavaRDD=E2=80=99=
s
> >> combineByKey requires that a =E2=80=9CcreateCombiner=E2=80=9D function=
 is provided, and
> the
> >> return value from that function must be serializable using Kryo. When =
I
> >> switched to using rdd.aggregate I assumed that the zero value would
> also be
> >> strictly Kryo serialized, as it is a data item and not part of a
> closure or
> >> the aggregation functions. However, I got a serialization exception as
> the
> >> closure serializer (only valid serializer is the Java serializer) was
> used
> >> instead.
> >>
> >> I was wondering the following:
> >>
> >> What is the rationale for making the zero value be serialized using th=
e
> >> closure serializer? This isn=E2=80=99t part of the closure, but is an =
initial
> data
> >> item.
> >> Would it make sense for us to perhaps write a version of rdd.aggregate=
()
> >> that takes a function as a parameter, that generates the zero value?
> This
> >> would be more intuitive to be serialized using the closure serializer.
> >>
> >> I believe aggregateByKey is also affected.
> >>
> >> Thanks,
> >>
> >> -Matt Cheah
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113a9baad13722050f64d8ce--

From dev-return-11673-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 23:10:26 2015
Return-Path: <dev-return-11673-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 369661738D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 23:10:26 +0000 (UTC)
Received: (qmail 73207 invoked by uid 500); 18 Feb 2015 23:10:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73135 invoked by uid 500); 18 Feb 2015 23:10:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73123 invoked by uid 99); 18 Feb 2015 23:10:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:10:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:10:20 +0000
Received: by mail-wg0-f46.google.com with SMTP id a1so4078409wgh.5
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 15:07:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=2r93CVre1gvzgDUH5Wx0t8x836jpXW3Naa34bj4Oc8w=;
        b=0db6Fqs36HBhgvGahJSik8TBOYyanQbBXSQVufTVqDvI+BaPYX5i1/n8yPxCUlPDth
         wzTc8fSEtlxwa63tV1tBDNaxjEw/6RkPwMOYxHvha767062TXfHsH1H0LxiSb05p3pZS
         SYB+FG9VRe0XzlsjXTU+z9dhMbOx2O5lCotdzrEdGFHDnMscfxbCMNl444CfgJMir2u1
         So688eXZMDD0Hoz99qZizYOULRJ4wCkYoUfCR0gkdTHOXzZUmymMR3PMPid9Hd8HRV1s
         gUOtpObes48jvANiUUAOY9hRwJxD6c29DCnCSjkB4RjAQZ2veMuvtbKDLV5mwma5l6ZX
         XGmA==
MIME-Version: 1.0
X-Received: by 10.194.109.36 with SMTP id hp4mr3171971wjb.17.1424300864511;
 Wed, 18 Feb 2015 15:07:44 -0800 (PST)
Received: by 10.194.16.2 with HTTP; Wed, 18 Feb 2015 15:07:44 -0800 (PST)
In-Reply-To: <CA+B-+fxBo=4u4TZSUyxWN0vMDbdHuVQnwst-F=Frmf2qwwf+Jw@mail.gmail.com>
References: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
	<CAJgQjQ8t=ppgtNR7ydG6+_mMhghqiW5Zk1fk-pCSssYUj8+WGw@mail.gmail.com>
	<CA+B-+fxBo=4u4TZSUyxWN0vMDbdHuVQnwst-F=Frmf2qwwf+Jw@mail.gmail.com>
Date: Wed, 18 Feb 2015 15:07:44 -0800
Message-ID: <CAJgQjQ-=Ow2BM+GMjh1DR_FTV512dOrbjtJ=GjqY0u0YtSrCCg@mail.gmail.com>
Subject: Re: Batch prediciton for ALS
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Please create a JIRA for it and we should discuss the APIs first
before updating the code. -Xiangrui

On Tue, Feb 17, 2015 at 4:10 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> It will be really help us if we merge it but I guess it is already diverged
> from the new ALS...I will also take a look at it again and try update with
> the new ALS...
>
> On Tue, Feb 17, 2015 at 3:22 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>>
>> It may be too late to merge it into 1.3. I'm going to make another
>> pass on your PR today. -Xiangrui
>>
>> On Tue, Feb 10, 2015 at 8:01 AM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>> > Hi,
>> >
>> > Will it be possible to merge this PR to 1.3 ?
>> >
>> > https://github.com/apache/spark/pull/3098
>> >
>> > The batch prediction API in ALS will be useful for us who want to cross
>> > validate on prec@k and MAP...
>> >
>> > Thanks.
>> > Deb
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11674-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 23:11:28 2015
Return-Path: <dev-return-11674-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0FB2417395
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 23:11:28 +0000 (UTC)
Received: (qmail 76294 invoked by uid 500); 18 Feb 2015 23:11:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76221 invoked by uid 500); 18 Feb 2015 23:11:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76209 invoked by uid 99); 18 Feb 2015 23:11:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:11:23 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.181 as permitted sender)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:11:19 +0000
Received: by lbvn10 with SMTP id n10so4334215lbv.4
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 15:10:58 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=1S76cysdvv0JPjuKwwLrqs/fPW+LUK4jMT21xCLIv+s=;
        b=jBj4ZY2jpZhwy9kj7pzBqMNf/nWjWWfaE6cyzmAvw54LqFlx6cxGhIyO4Kop7cet9i
         NkdsRWmojwd3+SPWp1BJ/bJGYS4h9RDsgazswr/ZwsZfNSXJxuruNtRjYQoZMSv3g5ia
         Me/DHebCysiSQfDTzvvsaNQm8WE4Z0f+4Y+znCs0bxhziRJ5cmz9MY7hT3O7HyX0FRKu
         Oqa7vkNjw4b0r4xhdP3gMG8v/yCb9jb5phe92vKdNLNRz+PB0ysCX7waTMh/cXUELZNa
         XG8nrsRqQb24rKZER2hqO8ZuHUuQcAqMrsKcI6aEnXqTOq7m0p1eK034j+QhMi7Cvrsj
         81Bg==
MIME-Version: 1.0
X-Received: by 10.112.51.114 with SMTP id j18mr1354815lbo.97.1424301058584;
 Wed, 18 Feb 2015 15:10:58 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Wed, 18 Feb 2015 15:10:58 -0800 (PST)
In-Reply-To: <CAJgQjQ-=Ow2BM+GMjh1DR_FTV512dOrbjtJ=GjqY0u0YtSrCCg@mail.gmail.com>
References: <CA+B-+fz2=vDoiQmdW1S1anWKB0gQxb7_Z290PFfttqy8n9V-GA@mail.gmail.com>
	<CAJgQjQ8t=ppgtNR7ydG6+_mMhghqiW5Zk1fk-pCSssYUj8+WGw@mail.gmail.com>
	<CA+B-+fxBo=4u4TZSUyxWN0vMDbdHuVQnwst-F=Frmf2qwwf+Jw@mail.gmail.com>
	<CAJgQjQ-=Ow2BM+GMjh1DR_FTV512dOrbjtJ=GjqY0u0YtSrCCg@mail.gmail.com>
Date: Wed, 18 Feb 2015 15:10:58 -0800
Message-ID: <CA+B-+fy77RWsrddCJqvHqsJXTZFj+C2Lmmq6W1iKPAhT0mwMmw@mail.gmail.com>
Subject: Re: Batch prediciton for ALS
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113363f4a676da050f64ee7c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113363f4a676da050f64ee7c
Content-Type: text/plain; charset=UTF-8

You have a JIRA for it...

https://issues.apache.org/jira/browse/SPARK-3066

I added the PR on the JIRA...

On Wed, Feb 18, 2015 at 3:07 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Please create a JIRA for it and we should discuss the APIs first
> before updating the code. -Xiangrui
>
> On Tue, Feb 17, 2015 at 4:10 PM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > It will be really help us if we merge it but I guess it is already
> diverged
> > from the new ALS...I will also take a look at it again and try update
> with
> > the new ALS...
> >
> > On Tue, Feb 17, 2015 at 3:22 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
> >>
> >> It may be too late to merge it into 1.3. I'm going to make another
> >> pass on your PR today. -Xiangrui
> >>
> >> On Tue, Feb 10, 2015 at 8:01 AM, Debasish Das <debasish.das83@gmail.com
> >
> >> wrote:
> >> > Hi,
> >> >
> >> > Will it be possible to merge this PR to 1.3 ?
> >> >
> >> > https://github.com/apache/spark/pull/3098
> >> >
> >> > The batch prediction API in ALS will be useful for us who want to
> cross
> >> > validate on prec@k and MAP...
> >> >
> >> > Thanks.
> >> > Deb
> >
> >
>

--001a113363f4a676da050f64ee7c--

From dev-return-11675-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 23:22:50 2015
Return-Path: <dev-return-11675-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 854EC173DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 23:22:50 +0000 (UTC)
Received: (qmail 99481 invoked by uid 500); 18 Feb 2015 23:22:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99408 invoked by uid 500); 18 Feb 2015 23:22:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99392 invoked by uid 99); 18 Feb 2015 23:22:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:22:48 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mkim@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:22:44 +0000
Received: from EXDR01-WEST.YOJOE.local (10.160.10.135) by
 EX03-WEST.YOJOE.local (10.160.10.136) with Microsoft SMTP Server (TLS) id
 14.3.195.1; Wed, 18 Feb 2015 15:21:20 -0800
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EXDR01-WEST.YOJOE.local ([169.254.3.4]) with mapi id 14.03.0195.001; Wed, 18
 Feb 2015 15:21:19 -0800
From: Mingyu Kim <mkim@palantir.com>
To: Imran Rashid <irashid@cloudera.com>, Andrew Ash <andrew@andrewash.com>
CC: dev <dev@spark.apache.org>
Subject: Re: Streaming partitions to driver for use in .toLocalIterator
Thread-Topic: Streaming partitions to driver for use in .toLocalIterator
Thread-Index: AQHQS40W6qUuMOQzZUS9PecZFf6B/Jz3awMA//+hEgA=
Date: Wed, 18 Feb 2015 23:21:18 +0000
Message-ID: <D10A5DB3.1D1C0%mkim@palantir.com>
References: <CA+-p3AHaZ_Q7ZE6vn2YVevQiXQhGn8cYnaM9KjeF7tKeBZk2=w@mail.gmail.com>
 <CA+3qhFQviWYtFceAxZrZpNeWd+RTp=s50dGodWzB71T3Y3ydLw@mail.gmail.com>
In-Reply-To: <CA+3qhFQviWYtFceAxZrZpNeWd+RTp=s50dGodWzB71T3Y3ydLw@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
user-agent: Microsoft-MacOutlook/14.4.1.140326
x-originating-ip: [10.100.91.90]
Content-Type: text/plain; charset="us-ascii"
Content-ID: <81642590C6D4E5418F2FD27266CB9B47@palantir.com>
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Another alternative would be to compress the partition in memory in a
streaming fashion instead of calling .toArray on the iterator. Would it be
an easier mitigation to the problem? Or, is it hard to compress the rows
one by one without materializing the full partition in memory using the
compression algo Spark uses currently?

Mingyu





On 2/18/15, 1:01 PM, "Imran Rashid" <irashid@cloudera.com> wrote:

>This would be pretty tricky to do -- the issue is that right now
>sparkContext.runJob has you pass in a function from a partition to *one*
>result object that gets serialized and sent back: Iterator[T] =3D> U, and
>that idea is baked pretty deep into a lot of the internals, DAGScheduler,
>Task, Executors, etc.
>
>Maybe another possibility worth considering: should we make it easy to go
>from N partitions to 2N partitions (or any other multiple obviously)
>without requiring a shuffle?  for that matter, you should also be able to
>go from 2N to N without a shuffle as well.  That change is also somewhat
>involved, though.
>
>Both are in theory possible, but I imagine they'd need really compelling
>use cases.
>
>An alternative would be to write your RDD to some other data store (eg,
>hdfs) which has better support for reading data in a streaming fashion,
>though you would probably be unhappy with the overhead.
>
>
>
>On Wed, Feb 18, 2015 at 9:09 AM, Andrew Ash <andrew@andrewash.com> wrote:
>
>> Hi Spark devs,
>>
>> I'm creating a streaming export functionality for RDDs and am having
>>some
>> trouble with large partitions.  The RDD.toLocalIterator() call pulls
>>over a
>> partition at a time to the driver, and then streams the RDD out from
>>that
>> partition before pulling in the next one.  When you have large
>>partitions
>> though, you can OOM the driver, especially when multiple of these
>>exports
>> are happening in the same SparkContext.
>>
>> One idea I had was to repartition the RDD so partitions are smaller, but
>> it's hard to know a priori what the partition count should be, and I'd
>>like
>> to avoid paying the shuffle cost if possible -- I think repartition to a
>> higher partition count forces a shuffle.
>>
>> Is it feasible to rework this so the executor -> driver transfer in
>> .toLocalIterator is a steady stream rather than a partition at a time?
>>
>> Thanks!
>> Andrew
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11676-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 18 23:26:49 2015
Return-Path: <dev-return-11676-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C4FF17403
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 18 Feb 2015 23:26:49 +0000 (UTC)
Received: (qmail 9923 invoked by uid 500); 18 Feb 2015 23:26:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9855 invoked by uid 500); 18 Feb 2015 23:26:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9844 invoked by uid 99); 18 Feb 2015 23:26:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:26:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.51 as permitted sender)
Received: from [74.125.82.51] (HELO mail-wg0-f51.google.com) (74.125.82.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 18 Feb 2015 23:26:33 +0000
Received: by mail-wg0-f51.google.com with SMTP id y19so4090688wgg.10
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 15:25:27 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=GtR3rhj2pEIEl488ESe2XLDE7Ryh4zohDiy/NZONN1Q=;
        b=dL9A+vHrLhGYNxJOsMg19ggyrU74Su6hWLLpxPhKvlvbNGmVS8yMqrHd6EkoMPWRFJ
         2yaWdQWqgP7Kyo33t6MSLYBrmwuhz3FGyLTHdRkmH5X09g1Ual0rYgrV5zzPyYT1xk8v
         XyggnM/5JpGjbEY9C9rqg7Qhc6p4aPdkiV4029G6+CCbF456ffjtWAyCz+f7Smu6ReK7
         5zLL7KNqMfCXohpTqXsOr+LjOIirpcZjIZjI9wBQSOMHxPuO5vXz3JFNmRlJ5W3y/5cm
         GXOlbeN13cw0KGqG2ZbMI+zUN4dJ1MEHEHwolCBIDygFxQQSp6PsQGBTTnygCb5y5SqM
         1zwQ==
X-Gm-Message-State: ALoCoQlqgYGMRXMLsF/41Tfd+lo7zieh+cb4gdMc8jX2Wiq2SbSrymcp7OnGFXYnOI1h/p0K0ocp
X-Received: by 10.180.188.41 with SMTP id fx9mr4588664wic.93.1424301927533;
 Wed, 18 Feb 2015 15:25:27 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Wed, 18 Feb 2015 15:25:07 -0800 (PST)
In-Reply-To: <CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com> <CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 18 Feb 2015 23:25:07 +0000
Message-ID: <CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Feb 18, 2015 at 6:13 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>> Patrick this link gives a 404:
>> https://people.apache.org/keys/committer/pwendell.asc
>
> Works for me. Maybe it's some ephemeral issue?

Yes works now; I swear it didn't before! that's all set now. The
signing key is in that file.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11677-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 00:47:40 2015
Return-Path: <dev-return-11677-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DDF3F176A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 00:47:40 +0000 (UTC)
Received: (qmail 88513 invoked by uid 500); 19 Feb 2015 00:47:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88426 invoked by uid 500); 19 Feb 2015 00:47:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88410 invoked by uid 99); 19 Feb 2015 00:47:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 00:47:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mcheah@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 00:47:34 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Wed, 18
 Feb 2015 16:47:12 -0800
From: Matt Cheah <mcheah@palantir.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: Mingyu Kim <mkim@palantir.com>, Sandor Van Wassenhove
	<sandorw@palantir.com>
Subject: [Performance] Possible regression in rdd.take()?
Thread-Topic: [Performance] Possible regression in rdd.take()?
Thread-Index: AQHQS92YJA8Rcu4csUKN2mERdUNl5w==
Date: Thu, 19 Feb 2015 00:47:11 +0000
Message-ID: <D10A72FE.92BA%mcheah@palantir.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.84.245]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507122942_1391097"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507122942_1391097
Content-type: multipart/alternative;
	boundary="B_3507122942_1409469"


--B_3507122942_1409469
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit

Hi everyone,

Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take()
consistently has a slower execution time on the later release. I was
wondering if anyone else has had similar observations.

I have two setups where this reproduces. The first is a local test. I
launched a spark cluster with 4 worker JVMs on my Mac, and launched a
Spark-Shell. I retrieved the text file and immediately called rdd.take(N) on
it, where N varied. The RDD is a plaintext CSV, 4GB in size, split over 8
files, which ends up having 128 partitions, and a total of 80000000 rows.
The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, with all
numbers being in seconds:
10000 items

Spark 1.0.2: 0.069281, 0.012261, 0.011083

Spark 1.1.1: 0.11577, 0.097636, 0.11321



40000 items

Spark 1.0.2: 0.023751, 0.069365, 0.023603

Spark 1.1.1: 0.224287, 0.229651, 0.158431



100000 items

Spark 1.0.2: 0.047019, 0.049056, 0.042568

Spark 1.1.1: 0.353277, 0.288965, 0.281751



400000 items

Spark 1.0.2: 0.216048, 0.198049, 0.796037

Spark 1.1.1: 1.865622, 2.224424, 2.037672

This small test suite indicates a consistently reproducible performance
regression.



I also notice this on a larger scale test. The cluster used is on EC2:

ec2 instance type: m2.4xlarge
10 slaves, 1 master
ephemeral storage
70 cores, 50 GB/box
In this case, I have a 100GB dataset split into 78 files totally 350 million
items, and I take the first 50,000 items from the RDD. In this case, I have
tested this on different formats of the raw data.

With plaintext files:

Spark 1.0.2: 0.422s, 0.363s, 0.382s

Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s



With snappy-compressed Avro files:

Spark 1.0.2: 0.73s, 0.395s, 0.426s

Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s

Again demonstrating a reproducible performance regression.

I was wondering if anyone else observed this regression, and if so, if
anyone would have any idea what could possibly have caused it between Spark
1.0.2 and Spark 1.1.1?

Thanks,

-Matt Cheah



--B_3507122942_1409469
Content-type: text/html;
	charset="US-ASCII"
Content-transfer-encoding: quoted-printable

<html><head></head><body style=3D"word-wrap: break-word; -webkit-nbsp-mode: s=
pace; -webkit-line-break: after-white-space; color: rgb(0, 0, 0); font-size:=
 14px; font-family: Calibri, sans-serif;"><div><div>Hi everyone,</div><div><=
br></div><div>Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.t=
ake() consistently has a slower execution time on the later release. I was w=
ondering if anyone else has had similar observations.</div><div><br></div><d=
iv>I have two setups where this reproduces. The first is a local test. I lau=
nched a s<span style=3D"line-height: 20px; font-size: 15px; background-color: =
rgb(255, 255, 255);">park cluster with 4 worker JVMs on my Mac, and launched=
 a Spark-Shell.&nbsp;I retrieved the text file and immediately called rdd.ta=
ke(N) on it, where N varied. The RDD is a plaintext CSV, 4GB in size, split =
over 8 files, which ends up having&nbsp;</span>128 partitions, and a total o=
f 80000000 rows<span style=3D"font-size: 15px; line-height: 20px; background-c=
olor: rgb(255, 255, 255);">. The numbers&nbsp;I discovered between Spark 1.0=
.2 and Spark 1.1.1 are, with all numbers being in seconds:</span></div><p st=
yle=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; background-color: =
rgb(255, 255, 255);">10000 items</p><p style=3D"font-size: 15px; margin: 10px =
0px 0px; padding: 0px; background-color: rgb(255, 255, 255);">Spark 1.0.2: 0=
.069281, 0.012261, 0.011083</p><p style=3D"font-size: 15px; margin: 10px 0px 0=
px; padding: 0px; background-color: rgb(255, 255, 255);">Spark 1.1.1: 0.1157=
7, 0.097636, 0.11321</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; pad=
ding: 0px; background-color: rgb(255, 255, 255);"><br></p><p style=3D"font-siz=
e: 15px; margin: 10px 0px 0px; padding: 0px; background-color: rgb(255, 255,=
 255);">40000 items</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padd=
ing: 0px; background-color: rgb(255, 255, 255);">Spark 1.0.2: 0.023751, 0.06=
9365, 0.023603</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: =
0px; background-color: rgb(255, 255, 255);">Spark 1.1.1: 0.224287, 0.229651,=
 0.158431</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; =
background-color: rgb(255, 255, 255);"><br></p><p style=3D"font-size: 15px; ma=
rgin: 10px 0px 0px; padding: 0px; background-color: rgb(255, 255, 255);">100=
000 items</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; =
background-color: rgb(255, 255, 255);">Spark 1.0.2: 0.047019, 0.049056, 0.04=
2568</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; backg=
round-color: rgb(255, 255, 255);">Spark 1.1.1: 0.353277, 0.288965, 0.281751<=
/p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; background=
-color: rgb(255, 255, 255);"><br></p><p style=3D"font-size: 15px; margin: 10px=
 0px 0px; padding: 0px; background-color: rgb(255, 255, 255);">400000 items<=
/p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; background=
-color: rgb(255, 255, 255);">Spark 1.0.2: 0.216048, 0.198049, 0.796037</p><p=
 style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px; background-colo=
r: rgb(255, 255, 255);">Spark 1.1.1: 1.865622, 2.224424, 2.037672</p><p styl=
e=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px;"><span style=3D"backgr=
ound-color: rgb(255, 254, 254);">This small test suite indicates a consisten=
tly reproducible performance regression.</span></p><p style=3D"font-size: 15px=
; margin: 10px 0px 0px; padding: 0px;"><span style=3D"background-color: rgb(25=
5, 254, 254);"><br></span></p><p style=3D"font-size: 15px; margin: 10px 0px 0p=
x; padding: 0px;">I also notice this on a larger scale test. The cluster use=
d is on EC2:</p><div>ec2 instance type: m2.4xlarge</div><div>10 slaves, 1 ma=
ster</div><div>ephemeral storage</div><div>70 cores, 50 GB/box</div><p style=
=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px;">In this case, I have=
 a 100GB dataset split into 78 files totally 350 million items, and I take t=
he first 50,000 items from the RDD. In this case, I have tested this on diff=
erent formats of the raw data.</p><p style=3D"font-size: 15px; margin: 10px 0p=
x 0px; padding: 0px;"><span style=3D"color: rgb(51, 51, 51); font-family: Aria=
l, sans-serif; font-size: 14px; line-height: 20px; background-color: rgb(255=
, 255, 255);">With plaintext files:</span></p><p style=3D"font-size: 15px; mar=
gin: 10px 0px 0px; padding: 0px;"><span style=3D"color: rgb(51, 51, 51); font-=
family: Arial, sans-serif; font-size: 14px; line-height: 20px; background-co=
lor: rgb(255, 255, 255);">Spark 1.0.2: 0.422s, 0.363s, 0.382s</span></p><p s=
tyle=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px;"><span style=3D"col=
or: rgb(51, 51, 51); font-family: Arial, sans-serif; font-size: 14px; line-h=
eight: 20px; background-color: rgb(255, 254, 254);">Spark 1.1.1:&nbsp;</span=
><span style=3D"color: rgb(51, 51, 51); font-family: Arial, sans-serif; font-s=
ize: 14px; line-height: 20px; background-color: rgb(255, 255, 255);">4.54s, =
1.28s, 1.221s, 1.13s</span></p><p style=3D"font-size: 15px; margin: 10px 0px 0=
px; padding: 0px;"><span style=3D"color: rgb(51, 51, 51); font-family: Arial, =
sans-serif; font-size: 14px; line-height: 20px; background-color: rgb(255, 2=
55, 255);"><br></span></p><p style=3D"font-size: 15px; margin: 10px 0px 0px; p=
adding: 0px;"><span style=3D"color: rgb(51, 51, 51); font-family: Arial, sans-=
serif; font-size: 14px; line-height: 20px; background-color: rgb(255, 254, 2=
54);">With snappy-compressed Avro files:</span></p><p style=3D"font-size: 15px=
; margin: 10px 0px 0px; padding: 0px;"><span style=3D"color: rgb(51, 51, 51); =
font-family: Arial, sans-serif; font-size: 14px; line-height: 20px; backgrou=
nd-color: rgb(254, 253, 253);">Spark 1.0.2:&nbsp;</span><span style=3D"color: =
rgb(51, 51, 51); font-family: Arial, sans-serif; font-size: 14px; line-heigh=
t: 20px; background-color: rgb(255, 255, 255);">0.73s, 0.395s, 0.426s</span>=
</p><p style=3D"font-size: 15px; margin: 10px 0px 0px; padding: 0px;"><span st=
yle=3D"color: rgb(51, 51, 51); font-family: Arial, sans-serif; font-size: 14px=
; line-height: 20px; background-color: rgb(255, 254, 254);">Spark 1.1.1:&nbs=
p;</span><span style=3D"color: rgb(51, 51, 51); font-family: Arial, sans-serif=
; font-size: 14px; line-height: 20px; background-color: rgb(255, 255, 255);"=
>4.618s, 1.81s, 1.158s, 1.333s</span></p><p style=3D"font-size: 15px; margin: =
10px 0px 0px; padding: 0px;"><span style=3D"color: rgb(51, 51, 51); font-famil=
y: Arial, sans-serif; font-size: 14px; line-height: 20px; background-color: =
rgb(255, 254, 254);">Again demonstrating a reproducible performance regressi=
on.</span></p><p style=3D"margin: 10px 0px 0px; padding: 0px;"><font color=3D"#3=
33333" face=3D"Arial,sans-serif"><span style=3D"line-height: 20px;">I</span></fo=
nt><span style=3D"color: rgb(51, 51, 51); font-family: Arial, sans-serif; line=
-height: 20px; background-color: rgb(255, 255, 255);">&nbsp;was wondering if=
 anyone else observed this regression, and if so, if anyone would have any i=
dea what could possibly have caused it between Spark 1.0.2 and Spark 1.1.1?<=
/span></p><p style=3D"margin: 10px 0px 0px; padding: 0px;"><span style=3D"color:=
 rgb(51, 51, 51); font-family: Arial, sans-serif; line-height: 20px; backgro=
und-color: rgb(255, 254, 254);">Thanks,</span></p><p style=3D"margin: 10px 0px=
 0px; padding: 0px;">-Matt Cheah</p></div></body></html>

--B_3507122942_1409469--

--B_3507122942_1391097
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507122942_1391097--

From dev-return-11678-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 00:55:15 2015
Return-Path: <dev-return-11678-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA585176D7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 00:55:15 +0000 (UTC)
Received: (qmail 13103 invoked by uid 500); 19 Feb 2015 00:55:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13032 invoked by uid 500); 19 Feb 2015 00:55:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13020 invoked by uid 99); 19 Feb 2015 00:55:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 00:55:14 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.170 as permitted sender)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 00:55:10 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so9152606obc.1
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 16:54:49 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=nMpq9ZDgvTKdIsPV0TnExCvJdqyACXRq7AZrDPhH/Us=;
        b=UMUyFHmVNZUIOx7rHRGRUrWLRuQYmRt0NAL97N1CYhMHPqnUvqqLu7BDfsg+E6TOvE
         htZ4FxEOltaEnW+Bw3rnvoiB/tlo/22vOiO0iV5Yea8MvzydibmC6L7ptarm8Kwxmyu/
         p6HPsm7WZO2BHAkIYe6CcoklJGoLgDVtqoNy03KBqFJOEIn+txYH1sPRL/nEmmyPemo/
         bMiLk7pX7iv7lA4YtbiZKDa4J9BlZPAuQhqujmtwMFBYxCKeaE4Z3SMiADwQ52lRcdFJ
         isRoVDLTYI5/KkzYw5NH1EikhtcD2rn7Bodi+OYMz8YMcA2uki1hSoCedfDBy+trWh62
         YdzQ==
MIME-Version: 1.0
X-Received: by 10.202.45.214 with SMTP id t205mr1256572oit.100.1424307289771;
 Wed, 18 Feb 2015 16:54:49 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 18 Feb 2015 16:54:49 -0800 (PST)
In-Reply-To: <D10A72FE.92BA%mcheah@palantir.com>
References: <D10A72FE.92BA%mcheah@palantir.com>
Date: Wed, 18 Feb 2015 16:54:49 -0800
Message-ID: <CABPQxsujs-a0FxHZ7qc+Z2des7sR5vJd1y3NKwd9K-pVC1iGww@mail.gmail.com>
Subject: Re: [Performance] Possible regression in rdd.take()?
From: Patrick Wendell <pwendell@gmail.com>
To: Matt Cheah <mcheah@palantir.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, 
	Sandor Van Wassenhove <sandorw@palantir.com>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I believe the heuristic governing the way that take() decides to fetch
partitions changed between these versions. It could be that in certain
cases the new heuristic is worse, but it might be good to just look at
the source code and see, for your number of elements taken and number
of partitions, if there was any effective change in how aggressively
spark fetched partitions.

This was quite a while ago, but I think the change was made because in
many cases the newer code works more efficiently.

- Patrick

On Wed, Feb 18, 2015 at 4:47 PM, Matt Cheah <mcheah@palantir.com> wrote:
> Hi everyone,
>
> Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take()
> consistently has a slower execution time on the later release. I was
> wondering if anyone else has had similar observations.
>
> I have two setups where this reproduces. The first is a local test. I
> launched a spark cluster with 4 worker JVMs on my Mac, and launched a
> Spark-Shell. I retrieved the text file and immediately called rdd.take(N) on
> it, where N varied. The RDD is a plaintext CSV, 4GB in size, split over 8
> files, which ends up having 128 partitions, and a total of 80000000 rows.
> The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, with all
> numbers being in seconds:
>
> 10000 items
>
> Spark 1.0.2: 0.069281, 0.012261, 0.011083
>
> Spark 1.1.1: 0.11577, 0.097636, 0.11321
>
>
> 40000 items
>
> Spark 1.0.2: 0.023751, 0.069365, 0.023603
>
> Spark 1.1.1: 0.224287, 0.229651, 0.158431
>
>
> 100000 items
>
> Spark 1.0.2: 0.047019, 0.049056, 0.042568
>
> Spark 1.1.1: 0.353277, 0.288965, 0.281751
>
>
> 400000 items
>
> Spark 1.0.2: 0.216048, 0.198049, 0.796037
>
> Spark 1.1.1: 1.865622, 2.224424, 2.037672
>
> This small test suite indicates a consistently reproducible performance
> regression.
>
>
> I also notice this on a larger scale test. The cluster used is on EC2:
>
> ec2 instance type: m2.4xlarge
> 10 slaves, 1 master
> ephemeral storage
> 70 cores, 50 GB/box
>
> In this case, I have a 100GB dataset split into 78 files totally 350 million
> items, and I take the first 50,000 items from the RDD. In this case, I have
> tested this on different formats of the raw data.
>
> With plaintext files:
>
> Spark 1.0.2: 0.422s, 0.363s, 0.382s
>
> Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s
>
>
> With snappy-compressed Avro files:
>
> Spark 1.0.2: 0.73s, 0.395s, 0.426s
>
> Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s
>
> Again demonstrating a reproducible performance regression.
>
> I was wondering if anyone else observed this regression, and if so, if
> anyone would have any idea what could possibly have caused it between Spark
> 1.0.2 and Spark 1.1.1?
>
> Thanks,
>
> -Matt Cheah

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11679-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 01:11:16 2015
Return-Path: <dev-return-11679-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3036E17740
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 01:11:16 +0000 (UTC)
Received: (qmail 37864 invoked by uid 500); 19 Feb 2015 01:11:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37634 invoked by uid 500); 19 Feb 2015 01:11:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37394 invoked by uid 99); 19 Feb 2015 01:11:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:11:01 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mcheah@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:10:36 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Wed, 18
 Feb 2015 17:10:33 -0800
From: Matt Cheah <mcheah@palantir.com>
To: Patrick Wendell <pwendell@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, Mingyu Kim
	<mkim@palantir.com>, Sandor Van Wassenhove <sandorw@palantir.com>
Subject: Re: [Performance] Possible regression in rdd.take()?
Thread-Topic: [Performance] Possible regression in rdd.take()?
Thread-Index: AQHQS92YJA8Rcu4csUKN2mERdUNl55z3q7OA//9+ywA=
Date: Thu, 19 Feb 2015 01:10:32 +0000
Message-ID: <D10A7832.92C3%mcheah@palantir.com>
References: <D10A72FE.92BA%mcheah@palantir.com>
 <CABPQxsujs-a0FxHZ7qc+Z2des7sR5vJd1y3NKwd9K-pVC1iGww@mail.gmail.com>
In-Reply-To: <CABPQxsujs-a0FxHZ7qc+Z2des7sR5vJd1y3NKwd9K-pVC1iGww@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.84.245]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507124343_1417051"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507124343_1417051
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit

I actually tested Spark 1.2.0 with the code in the rdd.take() method
swapped out for what was in Spark 1.0.2. The run time was still slower,
which indicates to me something at work lower in the stack.

-Matt Cheah

On 2/18/15, 4:54 PM, "Patrick Wendell" <pwendell@gmail.com> wrote:

>I believe the heuristic governing the way that take() decides to fetch
>partitions changed between these versions. It could be that in certain
>cases the new heuristic is worse, but it might be good to just look at
>the source code and see, for your number of elements taken and number
>of partitions, if there was any effective change in how aggressively
>spark fetched partitions.
>
>This was quite a while ago, but I think the change was made because in
>many cases the newer code works more efficiently.
>
>- Patrick
>
>On Wed, Feb 18, 2015 at 4:47 PM, Matt Cheah <mcheah@palantir.com> wrote:
>> Hi everyone,
>>
>> Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take()
>> consistently has a slower execution time on the later release. I was
>> wondering if anyone else has had similar observations.
>>
>> I have two setups where this reproduces. The first is a local test. I
>> launched a spark cluster with 4 worker JVMs on my Mac, and launched a
>> Spark-Shell. I retrieved the text file and immediately called
>>rdd.take(N) on
>> it, where N varied. The RDD is a plaintext CSV, 4GB in size, split over
>>8
>> files, which ends up having 128 partitions, and a total of 80000000
>>rows.
>> The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, with
>>all
>> numbers being in seconds:
>>
>> 10000 items
>>
>> Spark 1.0.2: 0.069281, 0.012261, 0.011083
>>
>> Spark 1.1.1: 0.11577, 0.097636, 0.11321
>>
>>
>> 40000 items
>>
>> Spark 1.0.2: 0.023751, 0.069365, 0.023603
>>
>> Spark 1.1.1: 0.224287, 0.229651, 0.158431
>>
>>
>> 100000 items
>>
>> Spark 1.0.2: 0.047019, 0.049056, 0.042568
>>
>> Spark 1.1.1: 0.353277, 0.288965, 0.281751
>>
>>
>> 400000 items
>>
>> Spark 1.0.2: 0.216048, 0.198049, 0.796037
>>
>> Spark 1.1.1: 1.865622, 2.224424, 2.037672
>>
>> This small test suite indicates a consistently reproducible performance
>> regression.
>>
>>
>> I also notice this on a larger scale test. The cluster used is on EC2:
>>
>> ec2 instance type: m2.4xlarge
>> 10 slaves, 1 master
>> ephemeral storage
>> 70 cores, 50 GB/box
>>
>> In this case, I have a 100GB dataset split into 78 files totally 350
>>million
>> items, and I take the first 50,000 items from the RDD. In this case, I
>>have
>> tested this on different formats of the raw data.
>>
>> With plaintext files:
>>
>> Spark 1.0.2: 0.422s, 0.363s, 0.382s
>>
>> Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s
>>
>>
>> With snappy-compressed Avro files:
>>
>> Spark 1.0.2: 0.73s, 0.395s, 0.426s
>>
>> Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s
>>
>> Again demonstrating a reproducible performance regression.
>>
>> I was wondering if anyone else observed this regression, and if so, if
>> anyone would have any idea what could possibly have caused it between
>>Spark
>> 1.0.2 and Spark 1.1.1?
>>
>> Thanks,
>>
>> -Matt Cheah

--B_3507124343_1417051
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507124343_1417051--

From dev-return-11680-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 01:26:16 2015
Return-Path: <dev-return-11680-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 937541779C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 01:26:16 +0000 (UTC)
Received: (qmail 78216 invoked by uid 500); 19 Feb 2015 01:26:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78137 invoked by uid 500); 19 Feb 2015 01:26:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78125 invoked by uid 99); 19 Feb 2015 01:26:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:26:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ilikerps@gmail.com designates 74.125.82.170 as permitted sender)
Received: from [74.125.82.170] (HELO mail-we0-f170.google.com) (74.125.82.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:26:10 +0000
Received: by wevm14 with SMTP id m14so4467624wev.13
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 17:25:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=RM1nk23A+eQw55hdAdaNQNPoUDkWUGorg1yXEbyPors=;
        b=RytSo34P4bmzg59NpiEOhLu49IZueBp2EzwVfYuCv/4u2MTHTOTwljdLavFNFEaUpg
         8mGOzjw7tOidzHoeIMB7Yn4ZoE70ZtHL4UoiHWA16J477RX7XzuPUAASfkOPRSrGoGkT
         oKbilPHxufx/hg3U5Du8xq47i3sKzdwJMELIF3IFY/2AH+qskMpVceXBxJnLhhiyXnOE
         6hwZhJ17KvBso1dRbqIdTL9M2chVR2GOWBdxExvJLBDuZYh6Wnwpn+wCd4GDa3I7Xw9X
         Y9dDnt7Wo39Ys6N8yoKGx+J3WrOyOTGmShIKq4WZdD34NXeSjv0ZqSfMDMT4c1QuZ7yG
         YtZg==
X-Received: by 10.194.59.209 with SMTP id b17mr3763270wjr.67.1424309149977;
 Wed, 18 Feb 2015 17:25:49 -0800 (PST)
MIME-Version: 1.0
Received: by 10.194.44.101 with HTTP; Wed, 18 Feb 2015 17:25:29 -0800 (PST)
In-Reply-To: <D10A7832.92C3%mcheah@palantir.com>
References: <D10A72FE.92BA%mcheah@palantir.com> <CABPQxsujs-a0FxHZ7qc+Z2des7sR5vJd1y3NKwd9K-pVC1iGww@mail.gmail.com>
 <D10A7832.92C3%mcheah@palantir.com>
From: Aaron Davidson <ilikerps@gmail.com>
Date: Wed, 18 Feb 2015 17:25:29 -0800
Message-ID: <CANGvG8p-2tQadJ1Z862hNGV8KDTa5W9z4P42QzPHLE5N_tgQiw@mail.gmail.com>
Subject: Re: [Performance] Possible regression in rdd.take()?
To: Matt Cheah <mcheah@palantir.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Mingyu Kim <mkim@palantir.com>, Sandor Van Wassenhove <sandorw@palantir.com>
Content-Type: multipart/alternative; boundary=047d7b86d7faef5124050f66d04e
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b86d7faef5124050f66d04e
Content-Type: text/plain; charset=UTF-8

You might be seeing the result of this patch:

https://github.com/apache/spark/commit/d069c5d9d2f6ce06389ca2ddf0b3ae4db72c5797

which was introduced in 1.1.1. This patch disabled the ability for take()
to run without launching a Spark job, which means that the latency is
significantly increased for small jobs (but not for large ones). You can
try enabling local execution and seeing if your problem goes away.

On Wed, Feb 18, 2015 at 5:10 PM, Matt Cheah <mcheah@palantir.com> wrote:

> I actually tested Spark 1.2.0 with the code in the rdd.take() method
> swapped out for what was in Spark 1.0.2. The run time was still slower,
> which indicates to me something at work lower in the stack.
>
> -Matt Cheah
>
> On 2/18/15, 4:54 PM, "Patrick Wendell" <pwendell@gmail.com> wrote:
>
> >I believe the heuristic governing the way that take() decides to fetch
> >partitions changed between these versions. It could be that in certain
> >cases the new heuristic is worse, but it might be good to just look at
> >the source code and see, for your number of elements taken and number
> >of partitions, if there was any effective change in how aggressively
> >spark fetched partitions.
> >
> >This was quite a while ago, but I think the change was made because in
> >many cases the newer code works more efficiently.
> >
> >- Patrick
> >
> >On Wed, Feb 18, 2015 at 4:47 PM, Matt Cheah <mcheah@palantir.com> wrote:
> >> Hi everyone,
> >>
> >> Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take()
> >> consistently has a slower execution time on the later release. I was
> >> wondering if anyone else has had similar observations.
> >>
> >> I have two setups where this reproduces. The first is a local test. I
> >> launched a spark cluster with 4 worker JVMs on my Mac, and launched a
> >> Spark-Shell. I retrieved the text file and immediately called
> >>rdd.take(N) on
> >> it, where N varied. The RDD is a plaintext CSV, 4GB in size, split over
> >>8
> >> files, which ends up having 128 partitions, and a total of 80000000
> >>rows.
> >> The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, with
> >>all
> >> numbers being in seconds:
> >>
> >> 10000 items
> >>
> >> Spark 1.0.2: 0.069281, 0.012261, 0.011083
> >>
> >> Spark 1.1.1: 0.11577, 0.097636, 0.11321
> >>
> >>
> >> 40000 items
> >>
> >> Spark 1.0.2: 0.023751, 0.069365, 0.023603
> >>
> >> Spark 1.1.1: 0.224287, 0.229651, 0.158431
> >>
> >>
> >> 100000 items
> >>
> >> Spark 1.0.2: 0.047019, 0.049056, 0.042568
> >>
> >> Spark 1.1.1: 0.353277, 0.288965, 0.281751
> >>
> >>
> >> 400000 items
> >>
> >> Spark 1.0.2: 0.216048, 0.198049, 0.796037
> >>
> >> Spark 1.1.1: 1.865622, 2.224424, 2.037672
> >>
> >> This small test suite indicates a consistently reproducible performance
> >> regression.
> >>
> >>
> >> I also notice this on a larger scale test. The cluster used is on EC2:
> >>
> >> ec2 instance type: m2.4xlarge
> >> 10 slaves, 1 master
> >> ephemeral storage
> >> 70 cores, 50 GB/box
> >>
> >> In this case, I have a 100GB dataset split into 78 files totally 350
> >>million
> >> items, and I take the first 50,000 items from the RDD. In this case, I
> >>have
> >> tested this on different formats of the raw data.
> >>
> >> With plaintext files:
> >>
> >> Spark 1.0.2: 0.422s, 0.363s, 0.382s
> >>
> >> Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s
> >>
> >>
> >> With snappy-compressed Avro files:
> >>
> >> Spark 1.0.2: 0.73s, 0.395s, 0.426s
> >>
> >> Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s
> >>
> >> Again demonstrating a reproducible performance regression.
> >>
> >> I was wondering if anyone else observed this regression, and if so, if
> >> anyone would have any idea what could possibly have caused it between
> >>Spark
> >> 1.0.2 and Spark 1.1.1?
> >>
> >> Thanks,
> >>
> >> -Matt Cheah
>

--047d7b86d7faef5124050f66d04e--

From dev-return-11681-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 01:54:55 2015
Return-Path: <dev-return-11681-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 90B501782F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 01:54:55 +0000 (UTC)
Received: (qmail 48176 invoked by uid 500); 19 Feb 2015 01:54:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48109 invoked by uid 500); 19 Feb 2015 01:54:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48094 invoked by uid 99); 19 Feb 2015 01:54:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:54:51 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mcheah@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 01:54:47 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Wed, 18
 Feb 2015 17:54:25 -0800
From: Matt Cheah <mcheah@palantir.com>
To: Aaron Davidson <ilikerps@gmail.com>
CC: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, Sandor Van Wassenhove
	<sandorw@palantir.com>
Subject: Re: [Performance] Possible regression in rdd.take()?
Thread-Topic: [Performance] Possible regression in rdd.take()?
Thread-Index: AQHQS92YJA8Rcu4csUKN2mERdUNl55z3q7OA//9+ywCAAInHgP//gnsA
Date: Thu, 19 Feb 2015 01:54:23 +0000
Message-ID: <D10A8270.92CD%mcheah@palantir.com>
References: <D10A72FE.92BA%mcheah@palantir.com>
 <CABPQxsujs-a0FxHZ7qc+Z2des7sR5vJd1y3NKwd9K-pVC1iGww@mail.gmail.com>
 <D10A7832.92C3%mcheah@palantir.com>
 <CANGvG8p-2tQadJ1Z862hNGV8KDTa5W9z4P42QzPHLE5N_tgQiw@mail.gmail.com>
In-Reply-To: <CANGvG8p-2tQadJ1Z862hNGV8KDTa5W9z4P42QzPHLE5N_tgQiw@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.84.245]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507126974_1573709"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507126974_1573709
Content-type: multipart/alternative;
	boundary="B_3507126974_1610293"


--B_3507126974_1610293
Content-type: text/plain;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

Ah okay, I turned on spark.localExecution.enabled and the performance
returned to what Spark 1.0.2 had. However I can see how users can
inadvertently incur memory and network strain in fetching the whole
partition to the driver.

I=B9ll evaluate on my side if we want to turn this on or not. Thanks for the
quick and accurate response!

-Matt CHeah

From:  Aaron Davidson <ilikerps@gmail.com>
Date:  Wednesday, February 18, 2015 at 5:25 PM
To:  Matt Cheah <mcheah@palantir.com>
Cc:  Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org"
<dev@spark.apache.org>, Mingyu Kim <mkim@palantir.com>, Sandor Van
Wassenhove <sandorw@palantir.com>
Subject:  Re: [Performance] Possible regression in rdd.take()?

You might be seeing the result of this patch:

https://github.com/apache/spark/commit/d069c5d9d2f6ce06389ca2ddf0b3ae4db72c=
5
797

which was introduced in 1.1.1. This patch disabled the ability for take() t=
o
run without launching a Spark job, which means that the latency is
significantly increased for small jobs (but not for large ones). You can tr=
y
enabling local execution and seeing if your problem goes away.

On Wed, Feb 18, 2015 at 5:10 PM, Matt Cheah <mcheah@palantir.com> wrote:
> I actually tested Spark 1.2.0 with the code in the rdd.take() method
> swapped out for what was in Spark 1.0.2. The run time was still slower,
> which indicates to me something at work lower in the stack.
>=20
> -Matt Cheah
>=20
> On 2/18/15, 4:54 PM, "Patrick Wendell" <pwendell@gmail.com> wrote:
>=20
>> >I believe the heuristic governing the way that take() decides to fetch
>> >partitions changed between these versions. It could be that in certain
>> >cases the new heuristic is worse, but it might be good to just look at
>> >the source code and see, for your number of elements taken and number
>> >of partitions, if there was any effective change in how aggressively
>> >spark fetched partitions.
>> >
>> >This was quite a while ago, but I think the change was made because in
>> >many cases the newer code works more efficiently.
>> >
>> >- Patrick
>> >
>> >On Wed, Feb 18, 2015 at 4:47 PM, Matt Cheah <mcheah@palantir.com> wrote=
:
>>> >> Hi everyone,
>>> >>
>>> >> Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take()
>>> >> consistently has a slower execution time on the later release. I was
>>> >> wondering if anyone else has had similar observations.
>>> >>
>>> >> I have two setups where this reproduces. The first is a local test. =
I
>>> >> launched a spark cluster with 4 worker JVMs on my Mac, and launched =
a
>>> >> Spark-Shell. I retrieved the text file and immediately called
>>> >>rdd.take(N) on
>>> >> it, where N varied. The RDD is a plaintext CSV, 4GB in size, split o=
ver
>>> >>8
>>> >> files, which ends up having 128 partitions, and a total of 80000000
>>> >>rows.
>>> >> The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, wi=
th
>>> >>all
>>> >> numbers being in seconds:
>>> >>
>>> >> 10000 items
>>> >>
>>> >> Spark 1.0.2: 0.069281, 0.012261, 0.011083
>>> >>
>>> >> Spark 1.1.1: 0.11577, 0.097636, 0.11321
>>> >>
>>> >>
>>> >> 40000 items
>>> >>
>>> >> Spark 1.0.2: 0.023751, 0.069365, 0.023603
>>> >>
>>> >> Spark 1.1.1: 0.224287, 0.229651, 0.158431
>>> >>
>>> >>
>>> >> 100000 items
>>> >>
>>> >> Spark 1.0.2: 0.047019, 0.049056, 0.042568
>>> >>
>>> >> Spark 1.1.1: 0.353277, 0.288965, 0.281751
>>> >>
>>> >>
>>> >> 400000 items
>>> >>
>>> >> Spark 1.0.2: 0.216048, 0.198049, 0.796037
>>> >>
>>> >> Spark 1.1.1: 1.865622, 2.224424, 2.037672
>>> >>
>>> >> This small test suite indicates a consistently reproducible performa=
nce
>>> >> regression.
>>> >>
>>> >>
>>> >> I also notice this on a larger scale test. The cluster used is on EC=
2:
>>> >>
>>> >> ec2 instance type: m2.4xlarge
>>> >> 10 slaves, 1 master
>>> >> ephemeral storage
>>> >> 70 cores, 50 GB/box
>>> >>
>>> >> In this case, I have a 100GB dataset split into 78 files totally 350
>>> >>million
>>> >> items, and I take the first 50,000 items from the RDD. In this case,=
 I
>>> >>have
>>> >> tested this on different formats of the raw data.
>>> >>
>>> >> With plaintext files:
>>> >>
>>> >> Spark 1.0.2: 0.422s, 0.363s, 0.382s
>>> >>
>>> >> Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s
>>> >>
>>> >>
>>> >> With snappy-compressed Avro files:
>>> >>
>>> >> Spark 1.0.2: 0.73s, 0.395s, 0.426s
>>> >>
>>> >> Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s
>>> >>
>>> >> Again demonstrating a reproducible performance regression.
>>> >>
>>> >> I was wondering if anyone else observed this regression, and if so, =
if
>>> >> anyone would have any idea what could possibly have caused it betwee=
n
>>> >>Spark
>>> >> 1.0.2 and Spark 1.1.1?
>>> >>
>>> >> Thanks,
>>> >>
>>> >> -Matt Cheah




--B_3507126974_1610293
Content-type: text/html;
	charset="ISO-8859-1"
Content-transfer-encoding: quoted-printable

<html><head></head><body style=3D"word-wrap: break-word; -webkit-nbsp-mode: s=
pace; -webkit-line-break: after-white-space; color: rgb(0, 0, 0); font-size:=
 14px; font-family: Calibri, sans-serif;"><div>Ah okay, I turned on spark.lo=
calExecution.enabled and the performance returned to what Spark 1.0.2 had. H=
owever I can see how users can inadvertently incur memory and network strain=
 in fetching the whole partition to the driver.</div><div><br></div><div>I&#=
8217;ll evaluate on my side if we want to turn this on or not. Thanks for th=
e quick and accurate response!</div><div><br></div><div>-Matt CHeah</div><di=
v><br></div><span id=3D"OLK_SRC_BODY_SECTION"><div style=3D"font-family:Calibri;=
 font-size:11pt; text-align:left; color:black; BORDER-BOTTOM: medium none; B=
ORDER-LEFT: medium none; PADDING-BOTTOM: 0in; PADDING-LEFT: 0in; PADDING-RIG=
HT: 0in; BORDER-TOP: #b5c4df 1pt solid; BORDER-RIGHT: medium none; PADDING-T=
OP: 3pt"><span style=3D"font-weight:bold">From: </span> Aaron Davidson &lt;<a =
href=3D"mailto:ilikerps@gmail.com">ilikerps@gmail.com</a>&gt;<br><span style=3D"=
font-weight:bold">Date: </span> Wednesday, February 18, 2015 at 5:25 PM<br><=
span style=3D"font-weight:bold">To: </span> Matt Cheah &lt;<a href=3D"mailto:mch=
eah@palantir.com">mcheah@palantir.com</a>&gt;<br><span style=3D"font-weight:bo=
ld">Cc: </span> Patrick Wendell &lt;<a href=3D"mailto:pwendell@gmail.com">pwen=
dell@gmail.com</a>&gt;, "<a href=3D"mailto:dev@spark.apache.org">dev@spark.apa=
che.org</a>" &lt;<a href=3D"mailto:dev@spark.apache.org">dev@spark.apache.org<=
/a>&gt;, Mingyu Kim &lt;<a href=3D"mailto:mkim@palantir.com">mkim@palantir.com=
</a>&gt;, Sandor Van Wassenhove &lt;<a href=3D"mailto:sandorw@palantir.com">sa=
ndorw@palantir.com</a>&gt;<br><span style=3D"font-weight:bold">Subject: </span=
> Re: [Performance] Possible regression in rdd.take()?<br></div><div><br></d=
iv><div><meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Dutf-8"><=
div><div dir=3D"ltr">You might be seeing the result of this patch:
<div><br></div><div><a href=3D"https://github.com/apache/spark/commit/d069c5d=
9d2f6ce06389ca2ddf0b3ae4db72c5797">https://github.com/apache/spark/commit/d0=
69c5d9d2f6ce06389ca2ddf0b3ae4db72c5797</a><br></div><div><br></div><div>whic=
h was introduced in 1.1.1. This patch disabled the ability for take() to run=
 without launching a Spark job, which means that the latency is significantl=
y increased for small jobs (but not for large ones). You can try enabling lo=
cal execution and seeing
 if your problem goes away.</div></div><div class=3D"gmail_extra"><br><div cl=
ass=3D"gmail_quote">On Wed, Feb 18, 2015 at 5:10 PM, Matt Cheah <span dir=3D"ltr=
">
&lt;<a href=3D"mailto:mcheah@palantir.com" target=3D"_blank">mcheah@palantir.co=
m</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0=
 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">
I actually tested Spark 1.2.0 with the code in the rdd.take() method<br>
swapped out for what was in Spark 1.0.2. The run time was still slower,<br>=

which indicates to me something at work lower in the stack.<br><span class=3D=
"HOEnZb"><font color=3D"#888888"><br>
-Matt Cheah<br></font></span><div class=3D"HOEnZb"><div class=3D"h5"><br>
On 2/18/15, 4:54 PM, "Patrick Wendell" &lt;<a href=3D"mailto:pwendell@gmail.c=
om">pwendell@gmail.com</a>&gt; wrote:<br><br>
&gt;I believe the heuristic governing the way that take() decides to fetch<=
br>
&gt;partitions changed between these versions. It could be that in certain<=
br>
&gt;cases the new heuristic is worse, but it might be good to just look at<=
br>
&gt;the source code and see, for your number of elements taken and number<b=
r>
&gt;of partitions, if there was any effective change in how aggressively<br=
>
&gt;spark fetched partitions.<br>
&gt;<br>
&gt;This was quite a while ago, but I think the change was made because in<=
br>
&gt;many cases the newer code works more efficiently.<br>
&gt;<br>
&gt;- Patrick<br>
&gt;<br>
&gt;On Wed, Feb 18, 2015 at 4:47 PM, Matt Cheah &lt;<a href=3D"mailto:mcheah@=
palantir.com">mcheah@palantir.com</a>&gt; wrote:<br>
&gt;&gt; Hi everyone,<br>
&gt;&gt;<br>
&gt;&gt; Between Spark 1.0.2 and Spark 1.1.1, I have noticed that rdd.take(=
)<br>
&gt;&gt; consistently has a slower execution time on the later release. I w=
as<br>
&gt;&gt; wondering if anyone else has had similar observations.<br>
&gt;&gt;<br>
&gt;&gt; I have two setups where this reproduces. The first is a local test=
. I<br>
&gt;&gt; launched a spark cluster with 4 worker JVMs on my Mac, and launche=
d a<br>
&gt;&gt; Spark-Shell. I retrieved the text file and immediately called<br>
&gt;&gt;rdd.take(N) on<br>
&gt;&gt; it, where N varied. The RDD is a plaintext CSV, 4GB in size, split=
 over<br>
&gt;&gt;8<br>
&gt;&gt; files, which ends up having 128 partitions, and a total of 8000000=
0<br>
&gt;&gt;rows.<br>
&gt;&gt; The numbers I discovered between Spark 1.0.2 and Spark 1.1.1 are, =
with<br>
&gt;&gt;all<br>
&gt;&gt; numbers being in seconds:<br>
&gt;&gt;<br>
&gt;&gt; 10000 items<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.069281, 0.012261, 0.011083<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 0.11577, 0.097636, 0.11321<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; 40000 items<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.023751, 0.069365, 0.023603<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 0.224287, 0.229651, 0.158431<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; 100000 items<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.047019, 0.049056, 0.042568<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 0.353277, 0.288965, 0.281751<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; 400000 items<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.216048, 0.198049, 0.796037<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 1.865622, 2.224424, 2.037672<br>
&gt;&gt;<br>
&gt;&gt; This small test suite indicates a consistently reproducible perfor=
mance<br>
&gt;&gt; regression.<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; I also notice this on a larger scale test. The cluster used is on =
EC2:<br>
&gt;&gt;<br>
&gt;&gt; ec2 instance type: m2.4xlarge<br>
&gt;&gt; 10 slaves, 1 master<br>
&gt;&gt; ephemeral storage<br>
&gt;&gt; 70 cores, 50 GB/box<br>
&gt;&gt;<br>
&gt;&gt; In this case, I have a 100GB dataset split into 78 files totally 3=
50<br>
&gt;&gt;million<br>
&gt;&gt; items, and I take the first 50,000 items from the RDD. In this cas=
e, I<br>
&gt;&gt;have<br>
&gt;&gt; tested this on different formats of the raw data.<br>
&gt;&gt;<br>
&gt;&gt; With plaintext files:<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.422s, 0.363s, 0.382s<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 4.54s, 1.28s, 1.221s, 1.13s<br>
&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; With snappy-compressed Avro files:<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.0.2: 0.73s, 0.395s, 0.426s<br>
&gt;&gt;<br>
&gt;&gt; Spark 1.1.1: 4.618s, 1.81s, 1.158s, 1.333s<br>
&gt;&gt;<br>
&gt;&gt; Again demonstrating a reproducible performance regression.<br>
&gt;&gt;<br>
&gt;&gt; I was wondering if anyone else observed this regression, and if so=
, if<br>
&gt;&gt; anyone would have any idea what could possibly have caused it betw=
een<br>
&gt;&gt;Spark<br>
&gt;&gt; 1.0.2 and Spark 1.1.1?<br>
&gt;&gt;<br>
&gt;&gt; Thanks,<br>
&gt;&gt;<br>
&gt;&gt; -Matt Cheah<br></div></div></blockquote></div><br></div></div></di=
v></span></body></html>

--B_3507126974_1610293--

--B_3507126974_1573709
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507126974_1573709--

From dev-return-11682-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 02:34:40 2015
Return-Path: <dev-return-11682-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BA1D717900
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 02:34:40 +0000 (UTC)
Received: (qmail 11272 invoked by uid 500); 19 Feb 2015 02:34:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11194 invoked by uid 500); 19 Feb 2015 02:34:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11181 invoked by uid 99); 19 Feb 2015 02:34:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 02:34:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of krajah@maprtech.com designates 209.85.216.171 as permitted sender)
Received: from [209.85.216.171] (HELO mail-qc0-f171.google.com) (209.85.216.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 02:34:08 +0000
Received: by mail-qc0-f171.google.com with SMTP id l6so4294574qcy.2
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 18:33:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=DJ3RM6PgfNr/8eESbk13jySzgxr2Q7/iB5rzLda3vL8=;
        b=a2bgp3ulCcRaa1UDH6XyCCHKDFac8kDYt6te6T+fBDN2AeY4zmNfvaM1IxRmPiW5fX
         D2AvTtMP1pwafzq/Eoon8PBiJP29mgU4LL96iZvzYdn+zvR0uiXBt43iMuwjSpsNWL5I
         rMrZp7SCqgY8yaewbBhJX84GziE4IrknvQEUnHQ9Jyh/O7Kg2/x5gOWBp2/Ceu91Yso6
         gz8PDsJ1hDXY56skHNtZATx4XWtkzsq4scaXEL9S3xqpZTvH+xbMTZVv4YzvXuJYz00+
         d0VUfpUGkM72ushXN4BZiwIWklsUAtZ1hrA5GKxXWWTTWMSniy3T7ALCnP/I9YtDCi7V
         /xoA==
X-Gm-Message-State: ALoCoQkT3ZG/7ujW2LwOiBOWYGb9shdccRmmLJ0y2oxNwstkIYSciFyl3SsgNKBPhPWWNV8el+s2
MIME-Version: 1.0
X-Received: by 10.140.28.166 with SMTP id 35mr7132198qgz.5.1424313201426; Wed,
 18 Feb 2015 18:33:21 -0800 (PST)
Received: by 10.140.93.21 with HTTP; Wed, 18 Feb 2015 18:33:21 -0800 (PST)
Date: Wed, 18 Feb 2015 18:33:21 -0800
Message-ID: <CALH4WSMVhQ1puLg8=0Ti+pY57_6SNE_UiC7eonKEpET3Nfz5Aw@mail.gmail.com>
Subject: Spark-SQL 1.2.0 "sort by" results are not consistent with Hive
From: Kannan Rajah <krajah@maprtech.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1139c05a6b9b57050f67c2e3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1139c05a6b9b57050f67c2e3
Content-Type: text/plain; charset=UTF-8

According to hive documentation, "sort by" is supposed to order the results
for each reducer. So if we set a single reducer, then the results should be
sorted, right? But this is not happening. Any idea why? Looks like the
settings I am using to restrict the number of reducers is not having an
effect.

*Tried the following:*

Set spark.default.parallelism to 1

Set spark.sql.shuffle.partitions to 1

These were set in hive-site.xml and also inside spark shell.


*Spark-SQL*

create table if not exists testSortBy (key int, name string, age int);
LOAD DATA LOCAL INPATH '/home/mapr/sample-name-age.txt' OVERWRITE INTO TABLE
testSortBy;
select * from testSortBY;

1    Aditya    28
2    aash    25
3    prashanth    27
4    bharath    26
5    terry    27
6    nanda    26
7    pradeep    27
8    pratyay    26


set spark.default.parallelism=1;

set spark.sql.shuffle.partitions=1;

select name,age from testSortBy sort by age; aash 25 bharath 26 prashanth
27 Aditya 28 nanda 26 pratyay 26 terry 27 pradeep 27 *HIVE* select name,age
from testSortBy sort by age;

aash    25
bharath    26
nanda    26
pratyay    26
prashanth    27
terry    27
pradeep    27
Aditya    28


--
Kannan

--001a1139c05a6b9b57050f67c2e3--

From dev-return-11683-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 03:52:41 2015
Return-Path: <dev-return-11683-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5B50917A56
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 03:52:41 +0000 (UTC)
Received: (qmail 15044 invoked by uid 500); 19 Feb 2015 03:52:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14962 invoked by uid 500); 19 Feb 2015 03:52:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14948 invoked by uid 99); 19 Feb 2015 03:52:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 03:52:39 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ksankar42@gmail.com designates 209.85.220.49 as permitted sender)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 03:52:35 +0000
Received: by padhz1 with SMTP id hz1so6281794pad.9
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 19:51:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=2S3TwmKd8EuJF9HPqZI/gcxA+0TN2Ii/zudxvVm51yc=;
        b=Xj2XBcMgpTD8RtxJcXndApsGxMBDYDzCa5Az06UAiMnJkLvlfj4gvyQLa5rS4QPMpm
         fWx9BgklNusK543kHFbNlKTzdg+IgVdMf41Hkr7J3zlkUbz93duO6vgmdIdkKD/YTAb+
         i+RNhcQQCvvbeJkFHUOIQ39/YMT+gDBAg9cvA3EM2MiyJBev71bCv+zlu8RjsdguHCKf
         pvwzAspS2sMt8EnnYUYzlmj9FNNKa3EyQe97caT6eo9zEdcaifyELGrbOn/Ub2sg1YJ5
         Jz3Q2wap2ghKtsQjFBT6IuAri9/VXRrHjtzE9tDalZheGc9Bp2a6yVcgXNP5/YcdCfuN
         dVvw==
MIME-Version: 1.0
X-Received: by 10.68.237.131 with SMTP id vc3mr3853983pbc.129.1424317890101;
 Wed, 18 Feb 2015 19:51:30 -0800 (PST)
Received: by 10.70.19.130 with HTTP; Wed, 18 Feb 2015 19:51:30 -0800 (PST)
In-Reply-To: <CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
	<CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
	<CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
Date: Wed, 18 Feb 2015 19:51:30 -0800
Message-ID: <CAOTBr2kuNkJ3XdzRYkWZ-Z7_H1veufz0wT6H3pDGrmY+RUYEhg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Krishna Sankar <ksankar42@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b339029e30a6e050f68d94a
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b339029e30a6e050f68d94a
Content-Type: text/plain; charset=UTF-8

+1 (non-binding, of course)

1. Compiled OSX 10.10 (Yosemite) OK Total time: 14:50 min
     mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
-Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
2. Tested pyspark, mlib - running as well as compare results with 1.1.x &
1.2.x
2.1. statistics (min,max,mean,Pearson,Spearman) OK
2.2. Linear/Ridge/Laso Regression OK

But MSE has increased from 40.81 to 105.86. Has some refactoring happened
on SGD/Linear Models ? Or do we have some extra parameters ? or change
of defaults ?

2.3. Decision Tree, Naive Bayes OK
2.4. KMeans OK
       Center And Scale OK
       WSSSE has come down slightly
2.5. rdd operations OK
      State of the Union Texts - MapReduce, Filter,sortByKey (word count)
2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK
       Model evaluation/optimization (rank, numIter, lmbda) with itertools
OK
3. Scala - MLlib
3.1. statistics (min,max,mean,Pearson,Spearman) OK
3.2. LinearRegressionWIthSGD OK
3.3. Decision Tree OK
3.4. KMeans OK
3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK

Cheers
<k/>
P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "
import sqlContext.implicits._" doesn't do the implicit conversations.
registerTempTable
gives syntax error. I will dig deeper tomorrow. Has anyone seen this ?

On Wed, Feb 18, 2015 at 3:25 PM, Sean Owen <sowen@cloudera.com> wrote:

> On Wed, Feb 18, 2015 at 6:13 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >> Patrick this link gives a 404:
> >> https://people.apache.org/keys/committer/pwendell.asc
> >
> > Works for me. Maybe it's some ephemeral issue?
>
> Yes works now; I swear it didn't before! that's all set now. The
> signing key is in that file.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b339029e30a6e050f68d94a--

From dev-return-11684-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 07:21:22 2015
Return-Path: <dev-return-11684-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DCCB317EAE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 07:21:22 +0000 (UTC)
Received: (qmail 23483 invoked by uid 500); 19 Feb 2015 07:21:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23408 invoked by uid 500); 19 Feb 2015 07:21:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23396 invoked by uid 99); 19 Feb 2015 07:21:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 07:21:21 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.174 as permitted sender)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 07:21:16 +0000
Received: by lbvp9 with SMTP id p9so5886987lbv.3
        for <dev@spark.apache.org>; Wed, 18 Feb 2015 23:20:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=WvT2qXR95OzrcEh8wqCQV5m8qrZrW4VFFFgAAL7TUWk=;
        b=ix8RuAFcXSa4w9k6CzhbdsKn0ElB7WFixoQVky+uaCjtkDnj9Pv13b4bScU0ivDtSi
         gdKvDhlwbEvMiCFQIw3rFYy+F1IoBM5xsHhdCTjo7BArxrOhiJ7B8KoEeQ1NLaZ9G1+S
         Xq2OKaJbuQrpP3hvrpO5OkWZAmpJOOBXU0UQVsiQLJtu7FlUADj1ZQIPYkwcY/rp4N7t
         CiwhY3aotR+2yQ3Qqm5J+IcsegmjIj/IkYCYGNxDwjoymtg93/tk9NfT+WH370WFWiBN
         h+I+jZGOTGfSxGxnLlivE42Pr2nxP+Le2Vv9z7SuwtK4rK/qQYADl4/vhe3O9/lBWKGV
         6D7w==
MIME-Version: 1.0
X-Received: by 10.152.181.196 with SMTP id dy4mr2653154lac.45.1424330455297;
 Wed, 18 Feb 2015 23:20:55 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Wed, 18 Feb 2015 23:20:55 -0800 (PST)
Date: Wed, 18 Feb 2015 23:20:55 -0800
Message-ID: <CA+B-+fwYPjToPp6CQ6e4io7UNfO_ofNu76JbgFSNLhChgzCtPA@mail.gmail.com>
Subject: If job fails shuffle space is not cleaned
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11340efcd4b626050f6bc6ea
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11340efcd4b626050f6bc6ea
Content-Type: text/plain; charset=UTF-8

Hi,

Some of my jobs failed due to no space left on device and on those jobs I
was monitoring the shuffle space...when the job failed shuffle space did
not clean and I had to manually clean it...

Is there a JIRA already tracking this issue ? If no one has been assigned
to it, I can take a look.

Thanks.
Deb

--001a11340efcd4b626050f6bc6ea--

From dev-return-11685-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 08:12:15 2015
Return-Path: <dev-return-11685-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 44E6E17F9F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 08:12:15 +0000 (UTC)
Received: (qmail 89566 invoked by uid 500); 19 Feb 2015 08:12:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89465 invoked by uid 500); 19 Feb 2015 08:12:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89448 invoked by uid 99); 19 Feb 2015 08:12:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 08:12:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of niranda.perera@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 08:11:59 +0000
Received: by mail-ob0-f171.google.com with SMTP id gq1so11835096obb.2
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 00:11:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8lc2FJAKpc1X+Hd2iaWFi89OrB08AD9acdFHdqlkiZI=;
        b=RbbmqEQtBssE2vahbzrAElKCYdHbiBXwtPI/uaQoRdb6W+7jYLxZAzD900MVkD42UG
         0YpIZ+tQ6JnJjwnP0o1fVNJtrGOs8tAT3PGr1ms6D9vEYdN1GFgQIeOk9iVT34k22WMm
         TfjukJ0SohuAUE7tzp2r2w2X6tOvSiE/CVVtx4uQ6NKzYJB0aB3gKqAEBn82RDLtWAiQ
         MIJfTP1g0WxmoB36NOcCjzGTZcBCBedvFXjPr+YlAYOPPkQIoTvH0Uq2zOV0SaDoM8pq
         a0Juu2IR/R6mpqq88L8eW3vVSe4yHiyM2hFQrzSBidU8XICHGki0qfVFF1ePoDQzkqxw
         3+wg==
MIME-Version: 1.0
X-Received: by 10.182.158.195 with SMTP id ww3mr2185147obb.22.1424333499313;
 Thu, 19 Feb 2015 00:11:39 -0800 (PST)
Received: by 10.202.64.6 with HTTP; Thu, 19 Feb 2015 00:11:39 -0800 (PST)
In-Reply-To: <CAMAsSdKJKaij3crhRLn_-NZDoTSTu76GsfYvEPBJt93hCVeL-w@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
	<CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
	<CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
	<CAMAsSdKJKaij3crhRLn_-NZDoTSTu76GsfYvEPBJt93hCVeL-w@mail.gmail.com>
Date: Thu, 19 Feb 2015 13:41:39 +0530
Message-ID: <CANCoaU58fd_quZ4HKEkxrNmSbDiC+zHNs-G15q441kgCgAnXjA@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
From: Niranda Perera <niranda.perera@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01537d1e44b2e7050f6c7c88
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01537d1e44b2e7050f6c7c88
Content-Type: text/plain; charset=UTF-8

Hi Sean,
The issue we have here is that all our products are based on a single
platform and we try to make all our products coherent with our platform as
much as possible. so, having two web services in one instance would not be
a very elegant solution. That is why we were seeking a way to switch it to
Tomcat. But as I understand, it is not readily supported, hence we will
have to accept it as it is.

If we are not using the Spark UIs, is it possible to disable the UIs and
prevent the jetty server from starting, but yet use the core spark
functionality?

Hi Corey,
thank you for your ideas. Our biggest concern here was that it starts a new
webserver inside spark. opening up new ports etc. might be seen as security
threats when it comes to commercial distributions.

cheers



On Wed, Feb 18, 2015 at 3:25 PM, Sean Owen <sowen@cloudera.com> wrote:

> I do not think it makes sense to make the web server configurable.
> Mostly because there's no real problem in running an HTTP service
> internally based on Netty while you run your own HTTP service based on
> something else like Tomcat. What's the problem?
>
> On Wed, Feb 18, 2015 at 3:14 AM, Niranda Perera
> <niranda.perera@gmail.com> wrote:
> > Hi Sean,
> > The main issue we have is, running two web servers in a single product.
> we
> > think it would not be an elegant solution.
> >
> > Could you please point me to the main areas where jetty server is tightly
> > coupled or extension points where I could plug tomcat instead of jetty?
> > If successful I could contribute it to the spark project. :-)
> >
> > cheers
> >
> >
> >
> > On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
> >>
> >> There's no particular reason you have to remove the embedded Jetty
> >> server, right? it doesn't prevent you from using it inside another app
> >> that happens to run in Tomcat. You won't be able to switch it out
> >> without rewriting a fair bit of code, no, but you don't need to.
> >>
> >> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
> >> <niranda.perera@gmail.com> wrote:
> >> > Hi,
> >> >
> >> > We are thinking of integrating Spark server inside a product. Our
> >> > current
> >> > product uses Tomcat as its webserver.
> >> >
> >> > Is it possible to switch the Jetty webserver in Spark to Tomcat
> >> > off-the-shelf?
> >> >
> >> > Cheers
> >> >
> >> > --
> >> > Niranda
> >
> >
> >
> >
> > --
> > Niranda
>



-- 
Niranda

--089e01537d1e44b2e7050f6c7c88--

From dev-return-11686-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 08:27:00 2015
Return-Path: <dev-return-11686-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35CF617FFA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 08:27:00 +0000 (UTC)
Received: (qmail 28115 invoked by uid 500); 19 Feb 2015 08:26:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27946 invoked by uid 500); 19 Feb 2015 08:26:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27351 invoked by uid 99); 19 Feb 2015 08:26:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 08:26:54 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of judynash@exchange.microsoft.com designates 157.55.158.30 as permitted sender)
Received: from [157.55.158.30] (HELO na01-sn2-obe.outbound.o365filtering.com) (157.55.158.30)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 08:26:25 +0000
Received: from CH1SR0101CA0029.namsdf01.sdf.exchangelabs.com (25.160.11.39) by
 SN2SR0101MB0062.namsdf01.sdf.exchangelabs.com (25.160.62.153) with Microsoft
 SMTP Server (TLS) id 15.1.106.2; Thu, 19 Feb 2015 08:26:18 +0000
Received: from SN2FFOFD004.ffo.gbl (2a01:111:f400:7c04::23) by
 CH1SR0101CA0029.outlook.office365.com (2a01:111:e400:1803::39) with Microsoft
 SMTP Server (TLS) id 15.1.106.2 via Frontend Transport; Thu, 19 Feb 2015
 08:26:18 +0000
Received: from hybrid.exchange.microsoft.com (131.107.159.100) by
 SN2FFOFD004.mail.o365filtering.com (10.111.201.41) with Microsoft SMTP Server
 (TLS) id 15.1.99.4 via Frontend Transport; Thu, 19 Feb 2015 08:26:17 +0000
Received: from DFM-TK5MBX15-06.exchange.corp.microsoft.com (157.54.109.45) by
 DFM-TK5EDG15-02.exchange.corp.microsoft.com (157.54.27.97) with Microsoft
 SMTP Server (TLS) id 15.0.1044.22; Thu, 19 Feb 2015 08:26:15 +0000
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DFM-TK5MBX15-06.exchange.corp.microsoft.com (157.54.109.45) with Microsoft
 SMTP Server (TLS) id 15.0.1076.6; Thu, 19 Feb 2015 00:26:14 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) with Microsoft
 SMTP Server (TLS) id 15.0.1076.3; Thu, 19 Feb 2015 00:26:12 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92])
 by DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.92]) with mapi id
 15.00.1076.000; Thu, 19 Feb 2015 00:26:12 -0800
From: Judy Nash <judynash@exchange.microsoft.com>
To: Akhil Das <akhil@sigmoidanalytics.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: RE: spark slave cannot execute without admin permission on windows
Thread-Topic: spark slave cannot execute without admin permission on windows
Thread-Index: AdBMCAvnHuIzNb6pTcGrUb56hu+fJwASfPQAAA4dOWA=
Date: Thu, 19 Feb 2015 08:26:11 +0000
Message-ID: <014bc325f40f43b1937f2f3db4fc6cd3@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
References: <27b07c69a933418f974ddbd7620a757c@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
 <CAHUQ+_bEWyA_a9=QhZdL63rs9e=k5n+cgQ-kz7Hu-B6vNKB69g@mail.gmail.com>
In-Reply-To: <CAHUQ+_bEWyA_a9=QhZdL63rs9e=k5n+cgQ-kz7Hu-B6vNKB69g@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [157.54.51.13]
Content-Type: multipart/related;
	boundary="_005_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_";
	type="multipart/alternative"
MIME-Version: 1.0
X-EOPAttributedMessage: 0
X-Forefront-Antispam-Report:
	CIP:131.107.159.100;CTRY:US;IPV:NLI;EFV:NLI;SFV:NSPM;SFS:(10019020)(377454003)(189002)(199003)(164054003)(24454002)(512874002)(19625215002)(2900100001)(19300405004)(84326002)(18206015028)(87936001)(86362001)(2950100001)(33646002)(2656002)(97736003)(106466001)(19580395003)(19580405001)(66066001)(6806004)(66926002)(2501002)(99936001)(67866002)(92566002)(64706001)(108616004)(16601075003)(16236675004)(92726002)(15975445007)(68736005)(102836002)(46102003)(105596002)(50986999)(76176999)(54356999)(62966003)(77156002)(17760045003)(19627595001)(19617315012)(50919005)(24736002)(562774006);DIR:OUT;SFP:1102;SCL:1;SRVR:SN2SR0101MB0062;H:hybrid.exchange.microsoft.com;FPR:;SPF:SoftFail;PTR:InfoDomainNonexistent;MX:1;A:1;LANG:en;
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:SN2SR0101MB0062;
X-Microsoft-Antispam-PRVS:
	<SN2SR0101MB0062529AF1B383A7478F33EAB02D0@SN2SR0101MB0062.namsdf01.sdf.exchangelabs.com>
X-Exchange-Antispam-Report-Test: UriScan:(193850556364327);
X-Exchange-Antispam-Report-CFA-Test:
	BCL:0;PCL:0;RULEID:(5005002)(2003001);SRVR:SN2SR0101MB0062;BCL:0;PCL:0;RULEID:;SRVR:SN2SR0101MB0062;
X-Forefront-PRVS: 0492FD61DD
Received-SPF: SoftFail (protection.outlook.com: domain of transitioning
 exchange.microsoft.com discourages use of 131.107.159.100 as permitted
 sender)
Authentication-Results: spf=softfail (sender IP is 131.107.159.100)
 smtp.mailfrom=judynash@exchange.microsoft.com; 
X-OriginatorOrg: exchange.microsoft.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Feb 2015 08:26:17.9804
 (UTC)
X-MS-Exchange-CrossTenant-Id: f686d426-8d16-42db-81b7-ab578e110ccd
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f686d426-8d16-42db-81b7-ab578e110ccd;Ip=[131.107.159.100]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: SN2SR0101MB0062
X-Virus-Checked: Checked by ClamAV on apache.org

--_005_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_
Content-Type: multipart/alternative;
	boundary="_000_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_"

--_000_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_
Content-Type: text/html; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_--

--_005_014bc325f40f43b1937f2f3db4fc6cd3DFMDB3MBX1508exchangeco_--

From dev-return-11687-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 09:24:36 2015
Return-Path: <dev-return-11687-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A11781022E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 09:24:36 +0000 (UTC)
Received: (qmail 33361 invoked by uid 500); 19 Feb 2015 09:24:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33289 invoked by uid 500); 19 Feb 2015 09:24:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33275 invoked by uid 99); 19 Feb 2015 09:24:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 09:24:31 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 09:24:27 +0000
Received: by mail-wg0-f50.google.com with SMTP id l2so5967806wgh.9
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 01:24:06 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=aKVUZd7SkbQ/+EMH5L5Lu0QgnCsVsxQzaP7BYb9Wbhg=;
        b=PlUje3rZjGMexmIKLZ0EBFSoWG4XZ9ODY5/3pjEZHvmFzPq0b5orhyoZC+UzUA3fJQ
         dOcWu3ydZU9qjvF8kcVKDfcaS2SFnD0kSCzZvuZNPDcQIwEKQl847PoHlKmkORnRA/LA
         hksOmNS6HhTwbRdW0pcRpJRUMQ5MHp9bd3mpVEBWGPVfVm/C+ISj5tYGidO2V5z7JXqS
         REP7P9yPR9wbkaH1MeqQuSiGndJ0KfKBd72RXZDizW/DVq6bnojxdJ/skOgDjBWao4CK
         z1wOkPOeCMgDklim0Z98p8ZJo+KUbBrB6lK3yy9auNPT0l7FFLqzFjUIk1hE25SjZC45
         1iGw==
X-Gm-Message-State: ALoCoQnYmXZ+U5eVYpWKXyLpBq006/rMYRVbn0s/Wcxa/hmNylPJAPxur6zO1OtTVv87s884FW6i
X-Received: by 10.180.95.162 with SMTP id dl2mr4716842wib.31.1424337846809;
 Thu, 19 Feb 2015 01:24:06 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Thu, 19 Feb 2015 01:23:46 -0800 (PST)
In-Reply-To: <CANCoaU58fd_quZ4HKEkxrNmSbDiC+zHNs-G15q441kgCgAnXjA@mail.gmail.com>
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com>
 <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com>
 <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com>
 <CAMAsSdKJKaij3crhRLn_-NZDoTSTu76GsfYvEPBJt93hCVeL-w@mail.gmail.com> <CANCoaU58fd_quZ4HKEkxrNmSbDiC+zHNs-G15q441kgCgAnXjA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 19 Feb 2015 09:23:46 +0000
Message-ID: <CAMAsSdKuKDg0xCsM+yRtmob=EhccEAB=oyc3SL2VzF6QKhz7hA@mail.gmail.com>
Subject: Re: Replacing Jetty with TomCat
To: Niranda Perera <niranda.perera@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Sure, but you are not using Netty at all. It's invisible to you. It's
not as if you have to set up and maintain a Jetty container. I don't
think your single platform for your apps is relevant.

You can turn off the UI, but as Reynold said, the HTTP servers are
also part of the core data transport functionality and you can't turn
that off. It's not merely unsupported to swap this out with an
arbitrary container, it's not clear it would work with Tomcat without
re-integrating with its behavior and tuning. But it also shouldn't
matter to anyone.

On Thu, Feb 19, 2015 at 8:11 AM, Niranda Perera
<niranda.perera@gmail.com> wrote:
> Hi Sean,
> The issue we have here is that all our products are based on a single
> platform and we try to make all our products coherent with our platform as
> much as possible. so, having two web services in one instance would not be a
> very elegant solution. That is why we were seeking a way to switch it to
> Tomcat. But as I understand, it is not readily supported, hence we will have
> to accept it as it is.
>
> If we are not using the Spark UIs, is it possible to disable the UIs and
> prevent the jetty server from starting, but yet use the core spark
> functionality?
>
> Hi Corey,
> thank you for your ideas. Our biggest concern here was that it starts a new
> webserver inside spark. opening up new ports etc. might be seen as security
> threats when it comes to commercial distributions.
>
> cheers
>
>
>
> On Wed, Feb 18, 2015 at 3:25 PM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> I do not think it makes sense to make the web server configurable.
>> Mostly because there's no real problem in running an HTTP service
>> internally based on Netty while you run your own HTTP service based on
>> something else like Tomcat. What's the problem?
>>
>> On Wed, Feb 18, 2015 at 3:14 AM, Niranda Perera
>> <niranda.perera@gmail.com> wrote:
>> > Hi Sean,
>> > The main issue we have is, running two web servers in a single product.
>> > we
>> > think it would not be an elegant solution.
>> >
>> > Could you please point me to the main areas where jetty server is
>> > tightly
>> > coupled or extension points where I could plug tomcat instead of jetty?
>> > If successful I could contribute it to the spark project. :-)
>> >
>> > cheers
>> >
>> >
>> >
>> > On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
>> >>
>> >> There's no particular reason you have to remove the embedded Jetty
>> >> server, right? it doesn't prevent you from using it inside another app
>> >> that happens to run in Tomcat. You won't be able to switch it out
>> >> without rewriting a fair bit of code, no, but you don't need to.
>> >>
>> >> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
>> >> <niranda.perera@gmail.com> wrote:
>> >> > Hi,
>> >> >
>> >> > We are thinking of integrating Spark server inside a product. Our
>> >> > current
>> >> > product uses Tomcat as its webserver.
>> >> >
>> >> > Is it possible to switch the Jetty webserver in Spark to Tomcat
>> >> > off-the-shelf?
>> >> >
>> >> > Cheers
>> >> >
>> >> > --
>> >> > Niranda
>> >
>> >
>> >
>> >
>> > --
>> > Niranda
>
>
>
>
> --
> Niranda

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11688-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 10:12:04 2015
Return-Path: <dev-return-11688-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 257CB1041F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 10:12:04 +0000 (UTC)
Received: (qmail 59578 invoked by uid 500); 19 Feb 2015 10:11:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59509 invoked by uid 500); 19 Feb 2015 10:11:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59498 invoked by uid 99); 19 Feb 2015 10:11:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 10:11:56 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [157.193.71.182] (HELO smtp1.ugent.be) (157.193.71.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 10:11:50 +0000
Received: from localhost (mcheck3.ugent.be [157.193.71.89])
	by smtp1.ugent.be (Postfix) with ESMTP id 100B78854;
	Thu, 19 Feb 2015 11:11:21 +0100 (CET)
X-Virus-Scanned: by UGent DICT
Received: from smtp1.ugent.be ([IPv6:::ffff:157.193.71.182])
	by localhost (mcheck3.UGent.be [::ffff:157.193.43.11]) (amavisd-new, port 10024)
	with ESMTP id 4SGMoQe6zliD; Thu, 19 Feb 2015 11:11:20 +0100 (CET)
Received: from [157.193.44.242] (gast044b.ugent.be [157.193.44.242])
	(Authenticated sender: ehiggs)
	by smtp1.ugent.be (Postfix) with ESMTPSA id 776778859;
	Thu, 19 Feb 2015 11:11:20 +0100 (CET)
Message-ID: <54E5B6C8.4050006@ugent.be>
Date: Thu, 19 Feb 2015 11:11:20 +0100
From: Ewan Higgs <ewan.higgs@ugent.be>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: Sean Owen <sowen@cloudera.com>, 
 Niranda Perera <niranda.perera@gmail.com>
CC: dev <dev@spark.apache.org>
Subject: Re: Replacing Jetty with TomCat
References: <CANCoaU7bHgRNiJ1kNxiStbrsGm+qYzRt+Vw-saytaa_n9SvDNA@mail.gmail.com> <CAMAsSd+5ZfQBaOAbPBwUwuc1ZJSh3oSPoSqsKpgSTvCxy-sgxA@mail.gmail.com> <CANCoaU6cnFsVBNehySPGZ3ipFR9A90J5xtbmHuY9xCzra6bp1Q@mail.gmail.com> <CAMAsSdKJKaij3crhRLn_-NZDoTSTu76GsfYvEPBJt93hCVeL-w@mail.gmail.com> <CANCoaU58fd_quZ4HKEkxrNmSbDiC+zHNs-G15q441kgCgAnXjA@mail.gmail.com> <CAMAsSdKuKDg0xCsM+yRtmob=EhccEAB=oyc3SL2VzF6QKhz7hA@mail.gmail.com>
In-Reply-To: <CAMAsSdKuKDg0xCsM+yRtmob=EhccEAB=oyc3SL2VzF6QKhz7hA@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Miltered: at jchkm3 with ID 54E5B6C8.002 by Joe's j-chkmail (http://helpdesk.ugent.be/email/)!
X-j-chkmail-Enveloppe: 54E5B6C8.002 from gast044b.ugent.be/gast044b.ugent.be/157.193.44.242/[157.193.44.242]/<ewan.higgs@ugent.be>
X-j-chkmail-Score: MSGID : 54E5B6C8.002 on smtp1.ugent.be : j-chkmail score : . : R=. U=. O=. B=0.000 -> S=0.000
X-j-chkmail-Status: Ham
X-Virus-Checked: Checked by ClamAV on apache.org

To add to Sean and Reynold's point:

Please correct me if I'm wrong, but Spark depends on hadoop-common which 
also uses jetty in the HttpServer2 code. So even if you remove jetty 
from Spark by making it an optional dependency, it will be pulled in by 
Hadoop.

So you'll still see that your program that depends on hypothetical 
Spark-Tomcat will still pull in jetty jars.

-Ewan


On 19/02/15 10:23, Sean Owen wrote:
> Sure, but you are not using Netty at all. It's invisible to you. It's
> not as if you have to set up and maintain a Jetty container. I don't
> think your single platform for your apps is relevant.
>
> You can turn off the UI, but as Reynold said, the HTTP servers are
> also part of the core data transport functionality and you can't turn
> that off. It's not merely unsupported to swap this out with an
> arbitrary container, it's not clear it would work with Tomcat without
> re-integrating with its behavior and tuning. But it also shouldn't
> matter to anyone.
>
> On Thu, Feb 19, 2015 at 8:11 AM, Niranda Perera
> <niranda.perera@gmail.com> wrote:
>> Hi Sean,
>> The issue we have here is that all our products are based on a single
>> platform and we try to make all our products coherent with our platform as
>> much as possible. so, having two web services in one instance would not be a
>> very elegant solution. That is why we were seeking a way to switch it to
>> Tomcat. But as I understand, it is not readily supported, hence we will have
>> to accept it as it is.
>>
>> If we are not using the Spark UIs, is it possible to disable the UIs and
>> prevent the jetty server from starting, but yet use the core spark
>> functionality?
>>
>> Hi Corey,
>> thank you for your ideas. Our biggest concern here was that it starts a new
>> webserver inside spark. opening up new ports etc. might be seen as security
>> threats when it comes to commercial distributions.
>>
>> cheers
>>
>>
>>
>> On Wed, Feb 18, 2015 at 3:25 PM, Sean Owen <sowen@cloudera.com> wrote:
>>> I do not think it makes sense to make the web server configurable.
>>> Mostly because there's no real problem in running an HTTP service
>>> internally based on Netty while you run your own HTTP service based on
>>> something else like Tomcat. What's the problem?
>>>
>>> On Wed, Feb 18, 2015 at 3:14 AM, Niranda Perera
>>> <niranda.perera@gmail.com> wrote:
>>>> Hi Sean,
>>>> The main issue we have is, running two web servers in a single product.
>>>> we
>>>> think it would not be an elegant solution.
>>>>
>>>> Could you please point me to the main areas where jetty server is
>>>> tightly
>>>> coupled or extension points where I could plug tomcat instead of jetty?
>>>> If successful I could contribute it to the spark project. :-)
>>>>
>>>> cheers
>>>>
>>>>
>>>>
>>>> On Mon, Feb 16, 2015 at 4:51 PM, Sean Owen <sowen@cloudera.com> wrote:
>>>>> There's no particular reason you have to remove the embedded Jetty
>>>>> server, right? it doesn't prevent you from using it inside another app
>>>>> that happens to run in Tomcat. You won't be able to switch it out
>>>>> without rewriting a fair bit of code, no, but you don't need to.
>>>>>
>>>>> On Mon, Feb 16, 2015 at 5:08 AM, Niranda Perera
>>>>> <niranda.perera@gmail.com> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> We are thinking of integrating Spark server inside a product. Our
>>>>>> current
>>>>>> product uses Tomcat as its webserver.
>>>>>>
>>>>>> Is it possible to switch the Jetty webserver in Spark to Tomcat
>>>>>> off-the-shelf?
>>>>>>
>>>>>> Cheers
>>>>>>
>>>>>> --
>>>>>> Niranda
>>>>
>>>>
>>>>
>>>> --
>>>> Niranda
>>
>>
>>
>> --
>> Niranda
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11689-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 10:26:50 2015
Return-Path: <dev-return-11689-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D088104A3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 10:26:50 +0000 (UTC)
Received: (qmail 87002 invoked by uid 500); 19 Feb 2015 10:26:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86924 invoked by uid 500); 19 Feb 2015 10:26:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86911 invoked by uid 99); 19 Feb 2015 10:26:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 10:26:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of watcherfr@gmail.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 10:26:43 +0000
Received: by iecar1 with SMTP id ar1so8424609iec.0
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 02:25:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=qPWPXfrVox3eJKRiyV7AfCaSauG1ZG+IDQCpHIK3cf8=;
        b=GZctPFC14Nl7O1a80mvROE2G1hIG8dxab/hnIqsZobgt3qskd5waxYW4WZrm3Mo7Co
         Z2jfa1op2YhnJmasqWrhx9PlfVsvjZL7e7133/Y2nvr5wxUZ+ms1VhbUpkg4WIsU+9Ty
         V+i6ldRvtesV86rp1KxX4EhLLmeTMYkCD0DtCJEqquHQhHhtfPYUXe6RIexEZa+qX+S6
         Ech+66WOA93SM2bM/TuekCULdNx2n0vn6fqzO7Uy5CVmWvOou+u1FiI4ool9pKNY7RRA
         UteW/7fE7/jjmUdECAYhdhvDB5Ckg12OkApkR35HxkAYgBZcztZRLzOpXmsRY7iwMFFK
         40gw==
MIME-Version: 1.0
X-Received: by 10.50.93.70 with SMTP id cs6mr8771842igb.6.1424341538106; Thu,
 19 Feb 2015 02:25:38 -0800 (PST)
Received: by 10.36.16.81 with HTTP; Thu, 19 Feb 2015 02:25:38 -0800 (PST)
Date: Thu, 19 Feb 2015 11:25:38 +0100
Message-ID: <CAHwsXYnvCi1GRu4cGBQ9h2mApLdn9BaqX02SsBhMqo_wTvxMVA@mail.gmail.com>
Subject: Hive SKEWED feature supported in Spark SQL ?
From: The Watcher <watcherfr@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7b41444c6af36e050f6e5b2e
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b41444c6af36e050f6e5b2e
Content-Type: text/plain; charset=UTF-8

I have done some testing of inserting into tables defined in Hive using 1.2
and I can see that the PARTITION clause is honored : data files get created
in multiple subdirectories correctly.

I tried the SKEWED BY ON STORED AS DIRECTORIES clause on the CREATE TABLE
clause but I didn't see subdirectories being created in that case.

1) is SKEWED BY honored ? If so, has anyone run into directories not being
created ?

2) if it is not honored, does it matter ? Hive introduced this feature to
better handle joins where tables had a skewed distribution on keys joined
on so that the single mapper handling one of the keys didn't hold up the
whole process. Could that happen in Spark / Spark SQL ?

Thanks

--047d7b41444c6af36e050f6e5b2e--

From dev-return-11690-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 19:00:07 2015
Return-Path: <dev-return-11690-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 626B310B7F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 19:00:07 +0000 (UTC)
Received: (qmail 49887 invoked by uid 500); 19 Feb 2015 18:59:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49805 invoked by uid 500); 19 Feb 2015 18:59:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49791 invoked by uid 99); 19 Feb 2015 18:59:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 18:59:56 +0000
X-ASF-Spam-Status: No, hits=5.1 required=10.0
	tests=FSL_HELO_BARE_IP_2,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,RCVD_NUMERIC_HELO
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.17.115.42] (HELO atl4mhob04.myregisteredsite.com) (209.17.115.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 18:59:51 +0000
Received: from atl4webmail15 ([10.30.71.172])
	by atl4mhob04.myregisteredsite.com (8.14.4/8.14.4) with ESMTP id t1JIx8bi027561
	for <dev@spark.apache.org>; Thu, 19 Feb 2015 13:59:08 -0500
Received: from 12.250.97.26 (mike@mbowles.com [12.250.97.26])
          by atl4webmail15 (Netsol 11.2.30)
          with WEBMAIL id 20810;
          Thu, 19 Feb 2015 18:59:08 +0000
From: mike@mbowles.com
To: dev@spark.apache.org
Importance: Normal
Sensitivity: Normal
Message-ID: <W7142528733208101424372348@atl4webmail15>
X-Mailer: Network Solutions Webmail, Build 11.2.30
X-Originating-IP: [12.250.97.26]
X-Forwarded-For: [(null)]
X-Authenticated-UID: mike@mbowles.com
Date: Thu, 19 Feb 2015 18:59:08 +0000
Subject: Have Friedman's glmnet algo running in Spark
MIME-Version: 1.0
Content-Type: multipart/alternative;
        boundary="--=_vm_0011_W7142528733_20810_1424372348"
X-Virus-Checked: Checked by ClamAV on apache.org

----=_vm_0011_W7142528733_20810_1424372348
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable

Dev List, 
A couple of colleagues and I have gotten several versions of glmnet algo =
coded and running on Spark RDD. glmnet algo (http://www.jstatsoft.org/v33=
/i01/paper) is a very fast algorithm for generating coefficient paths sol=
ving penalized regression with elastic net penalties. The algorithm runs =
fast by taking an approach that generates solutions for a wide variety of=
 penalty parameter. We're able to integrate into Mllib class structure a =
couple of different ways. The algorithm may fit better into the new pipel=
ine structure since it naturally returns a multitide of models (correspon=
ding to different vales of penalty parameters). That appears to fit bette=
r into pipeline than Mllib linear regression (for example). 

We've got regression running with the speed optimizations that Friedman r=
ecommends. We'll start working on the logistic regression version next. 

We're eager to make the code available as open source and would like to g=
et some feedback about how best to do that. Any thoughts? 
Mike Bowles. 



----=_vm_0011_W7142528733_20810_1424372348--



From dev-return-11691-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 20:00:40 2015
Return-Path: <dev-return-11691-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7E92310E89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 20:00:40 +0000 (UTC)
Received: (qmail 82428 invoked by uid 500); 19 Feb 2015 20:00:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82359 invoked by uid 500); 19 Feb 2015 20:00:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82346 invoked by uid 99); 19 Feb 2015 20:00:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:00:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:00:33 +0000
Received: by labms9 with SMTP id ms9so1862371lab.10
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 11:59:06 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=7PBlG5ApR/1vdL7Yw4jqABUGzsfvB8ATi5o2VzoyN3A=;
        b=A8gDaP5KlPjptcBOu7DnzyjyQTZMyCnQ786jMdeF2Ht2aHl78Upa0llo5yCo/bHJEm
         p0UPq+wYU7Y2deUmLddtQdrfvxbz8pU4aFijYV/e5sbJPaH4x+skay0f9pVkxXjQXxr+
         Zzg7FatjTUjym+JUwCGy3jTOX2wkYH5tqiPZSBBcgFtbqIdnf0yFpi7uioVxs0KWskqs
         Km5cOmy467cg3MRSb144ammE7JmfsvALXB+RM1CB0Yn0ArVPjKAnWhbZ/tCnLqF1Z5bH
         58NISMgfuKQw9lAuwjZgoUmeLN0S5wIOz4kLYvdF6S9dRBzGFyvrlyDBdyc8vNhi+e5Y
         p8/Q==
X-Gm-Message-State: ALoCoQlttxt+WrwD0mpwAaCl8pEgHAbGkOrKwqDGhFazjpugaPn8GxPHTneClD1z/yPJkqSBadfR
X-Received: by 10.112.148.34 with SMTP id tp2mr3829308lbb.94.1424375946486;
 Thu, 19 Feb 2015 11:59:06 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.213.18 with HTTP; Thu, 19 Feb 2015 11:58:44 -0800 (PST)
In-Reply-To: <CAHwsXYnvCi1GRu4cGBQ9h2mApLdn9BaqX02SsBhMqo_wTvxMVA@mail.gmail.com>
References: <CAHwsXYnvCi1GRu4cGBQ9h2mApLdn9BaqX02SsBhMqo_wTvxMVA@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Thu, 19 Feb 2015 11:58:44 -0800
Message-ID: <CAAswR-4oOZM7dPsu+F-W+SNnwD_P9tg18xryJ6syZOVmbnKLvA@mail.gmail.com>
Subject: Re: Hive SKEWED feature supported in Spark SQL ?
To: The Watcher <watcherfr@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a87d251398b050f765e07
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a87d251398b050f765e07
Content-Type: text/plain; charset=UTF-8

>
> 1) is SKEWED BY honored ? If so, has anyone run into directories not being
> created ?
>

It is not.

2) if it is not honored, does it matter ? Hive introduced this feature to
> better handle joins where tables had a skewed distribution on keys joined
> on so that the single mapper handling one of the keys didn't hold up the
> whole process. Could that happen in Spark / Spark SQL?
>

It could matter for very skewed data, though I have not heard many
complaints.  We could consider adding it in the future if people are having
problems with skewed data.

--047d7b3a87d251398b050f765e07--

From dev-return-11692-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 20:05:48 2015
Return-Path: <dev-return-11692-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8C43410F06
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 20:05:48 +0000 (UTC)
Received: (qmail 10421 invoked by uid 500); 19 Feb 2015 20:05:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10350 invoked by uid 500); 19 Feb 2015 20:05:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10334 invoked by uid 99); 19 Feb 2015 20:05:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:05:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.217.173] (HELO mail-lb0-f173.google.com) (209.85.217.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:05:09 +0000
Received: by lbvp9 with SMTP id p9so2187104lbv.0
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 12:03:16 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=xZ4T/eQqZ54guRq6lffSLNpTwwSBpk1oukhfW4ZRDuc=;
        b=AFtgcT1z12cS2dmXt5PJ/24wWyg0OKd/JYRfV5JILfv7LnmPb/7vLlu+JP09xO7dqD
         gmSffVDvXNZBiBrdu3vRXs91aplcWls2vcsQuAKqVe9VRJ69QpQyKBOYaaeZuuWXmbbH
         SunWSuFl7UyuzysKVhNg1/Bf6Eq/0pQaN3UOqn1MupbTt498MXU0RTytZlKsR+V2fM07
         35i0sMQisrOu6EufiFakuhkuEuyJmrAKTPLD1uFQV0kg3B8eJK3112J5pzRA5sg5wqr7
         AMbUCmZ+12byNcb9Clu7vEgcaAlqwj9ap9rQdwCx+qTU3zJaWQjc21924tlPVM62kc2h
         n85Q==
X-Gm-Message-State: ALoCoQmXtYZIhkGIGkxcbJsVGVDqCVdKdc+KvPnWom+qnjzZC1z2Xaf9OkjSnw5++LEFX1u69K6Z
X-Received: by 10.112.13.38 with SMTP id e6mr5522481lbc.31.1424376196726; Thu,
 19 Feb 2015 12:03:16 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.213.18 with HTTP; Thu, 19 Feb 2015 12:02:56 -0800 (PST)
In-Reply-To: <CAOTBr2kuNkJ3XdzRYkWZ-Z7_H1veufz0wT6H3pDGrmY+RUYEhg@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
 <CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
 <CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com> <CAOTBr2kuNkJ3XdzRYkWZ-Z7_H1veufz0wT6H3pDGrmY+RUYEhg@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Thu, 19 Feb 2015 12:02:56 -0800
Message-ID: <CAAswR-6D6B0N-FaR0vE9fRHr0pf5JHUnd4Xp8A-9AWDaV-rFig@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Krishna Sankar <ksankar42@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3f2143b9b0c050f766d32
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f2143b9b0c050f766d32
Content-Type: text/plain; charset=UTF-8

>
> P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "
> import sqlContext.implicits._" doesn't do the implicit conversations.
> registerTempTable
> gives syntax error. I will dig deeper tomorrow. Has anyone seen this ?


We will write up a whole migration guide before the final release, but I
can quickly explain this one.  We made the implicit conversion
significantly less broad to avoid the chance of confusing conflicts.
However, now you have to call .toDF in order to force RDDs to become
DataFrames.

--001a11c3f2143b9b0c050f766d32--

From dev-return-11693-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 20:51:30 2015
Return-Path: <dev-return-11693-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 89AE717336
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 20:51:30 +0000 (UTC)
Received: (qmail 39988 invoked by uid 500); 19 Feb 2015 20:51:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39910 invoked by uid 500); 19 Feb 2015 20:51:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39891 invoked by uid 99); 19 Feb 2015 20:51:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:51:29 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ksankar42@gmail.com designates 209.85.192.175 as permitted sender)
Received: from [209.85.192.175] (HELO mail-pd0-f175.google.com) (209.85.192.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 20:51:24 +0000
Received: by pdjg10 with SMTP id g10so2472660pdj.1
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 12:50:19 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=saw7ewPGIjaIIdO4bnRR1GeAGFjXJ53AYmU6MIqNuus=;
        b=Qpc7Vo6d8uMpcGNuagJsIOKGS5lnq04YIMyme07jSh5bXrc1MHSgS+C02cw0pTjLuU
         /RRQDWyRzVAY3wVhVHDW3qOVCk+F2z97DgRbU1JLT5DefHtMOX+Sh36XeeTQsdP8lWjz
         lfA3T+8RfoemJFkYgL+fZtSPsH5nPjGHv70AgBzTVYo8lslayqAJ9UqPsCCeGPC3VylP
         1A/0yej6hzklHxqffwwT+EVv+Mjrq0Hb1BesN4bV2me6M2izhph/OO/fIFy/VdSYL5Op
         VhyFrMsTKiK2HHsxQ5P2ouS30UiKNUoH49B1u7B/QuCcJ6SgBOAqaKmhazfqYyHMMnun
         nZjg==
MIME-Version: 1.0
X-Received: by 10.68.234.164 with SMTP id uf4mr2342631pbc.37.1424379019465;
 Thu, 19 Feb 2015 12:50:19 -0800 (PST)
Received: by 10.70.19.130 with HTTP; Thu, 19 Feb 2015 12:50:19 -0800 (PST)
In-Reply-To: <CAAswR-6D6B0N-FaR0vE9fRHr0pf5JHUnd4Xp8A-9AWDaV-rFig@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
	<CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
	<CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
	<CAOTBr2kuNkJ3XdzRYkWZ-Z7_H1veufz0wT6H3pDGrmY+RUYEhg@mail.gmail.com>
	<CAAswR-6D6B0N-FaR0vE9fRHr0pf5JHUnd4Xp8A-9AWDaV-rFig@mail.gmail.com>
Date: Thu, 19 Feb 2015 12:50:19 -0800
Message-ID: <CAOTBr2=mKr5Nod=Kqtd3o6xoA8i6VA=cc7WF3OZEMYacxCtY4g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Krishna Sankar <ksankar42@gmail.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Sean Owen <sowen@cloudera.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b33960b7b1bbc050f77157f
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b33960b7b1bbc050f77157f
Content-Type: text/plain; charset=UTF-8

Excellent. Explicit toDF() works.
a) employees.toDF().registerTempTable("Employees") - works
b) Also affects saveAsParquetFile - orders.toDF().saveAsParquetFile

Adding to my earlier tests:
4.0 SQL from Scala and Python
4.1 result = sqlContext.sql("SELECT * from Employees WHERE State = 'WA'") OK
4.2 result = sqlContext.sql("SELECT
OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER
JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK
4.3 result = sqlContext.sql("SELECT ShipCountry, Sum(OrderDetails.UnitPrice
* Qty * Discount) AS ProductSales FROM Orders INNER JOIN OrderDetails ON
Orders.OrderID = OrderDetails.OrderID GROUP BY ShipCountry") OK
4.4 saveAsParquetFile OK
4.5 Read and verify the 4.4 save - sqlContext.parquetFile,
registerTempTable, sql OK

Cheers & thanks Michael
<k/>



On Thu, Feb 19, 2015 at 12:02 PM, Michael Armbrust <michael@databricks.com>
wrote:

> P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "
>> import sqlContext.implicits._" doesn't do the implicit conversations.
>> registerTempTable
>> gives syntax error. I will dig deeper tomorrow. Has anyone seen this ?
>
>
> We will write up a whole migration guide before the final release, but I
> can quickly explain this one.  We made the implicit conversion
> significantly less broad to avoid the chance of confusing conflicts.
> However, now you have to call .toDF in order to force RDDs to become
> DataFrames.
>

--047d7b33960b7b1bbc050f77157f--

From dev-return-11694-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 19 22:53:09 2015
Return-Path: <dev-return-11694-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B9DF01774E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 19 Feb 2015 22:53:09 +0000 (UTC)
Received: (qmail 55903 invoked by uid 500); 19 Feb 2015 22:53:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55821 invoked by uid 500); 19 Feb 2015 22:53:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55809 invoked by uid 99); 19 Feb 2015 22:53:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 22:53:08 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of watcherfr@gmail.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 19 Feb 2015 22:52:43 +0000
Received: by mail-ig0-f170.google.com with SMTP id l13so3662892iga.1
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 14:50:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=54M17hilO59xGn8HS9t4Xo3xOsrQ6NxJgeVvAhEm4O8=;
        b=biFKKWxMFG5CR1n6KdHD3wDoUGWyNQjjHr0rKSpgxmKeR2kSXhJ3mu3Fd6yMN8tUAY
         ZH0tf9Hn4gZk0GCxNOgAFMNNTvtGTI05eAQCes7qUngylnnocwfY4ImHbzuMriqvXmYg
         nKsy+ACQdi8JH5OZOgYzuPXQMnS5yIlkJWIj9K6kNcaYuTc6b/mzSZnLh7A4RNGfted2
         KYqXimlRdqtTo4Fr0QKftn3fkIk/WZN/Ck9OLd7UHVfLNnCBV9Qpkp/2zVoU81chNECy
         2st4aWr9DWZRLsMMPg9Yfs2wohinAEE4fB0OWQsSjtzMsZ4rOe4n19xIclrU5BG2wGcW
         yyBg==
MIME-Version: 1.0
X-Received: by 10.43.160.200 with SMTP id md8mr8860785icc.70.1424386227096;
 Thu, 19 Feb 2015 14:50:27 -0800 (PST)
Received: by 10.36.16.81 with HTTP; Thu, 19 Feb 2015 14:50:27 -0800 (PST)
Date: Thu, 19 Feb 2015 23:50:27 +0100
Message-ID: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
Subject: Spark SQL, Hive & Parquet data types
From: The Watcher <watcherfr@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c32fb016d5a1050f78c3f2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c32fb016d5a1050f78c3f2
Content-Type: text/plain; charset=UTF-8

Still trying to get my head around Spark SQL & Hive.

1) Let's assume I *only* use Spark SQL to create and insert data into HIVE
tables, declared in a Hive meta-store.

Does it matter at all if Hive supports the data types I need with Parquet,
or is all that matters what Catalyst & spark's parquet relation support ?

Case in point : timestamps & Parquet
* Parquet now supports them as per
https://github.com/Parquet/parquet-mr/issues/218
* Hive only supports them in 0.14
So would I be able to read/write timestamps natively in Spark 1.2 ? Spark
1.3 ?

I have found this thread
http://apache-spark-user-list.1001560.n3.nabble.com/timestamp-not-implemented-yet-td15414.html
which seems to indicate that the data types supported by Hive would matter
to Spark SQL.
If so, why is that ? Doesn't the read path go through Spark SQL to read the
parquet file ?

2) Is there planned support for Hive 0.14 ?

Thanks

--001a11c32fb016d5a1050f78c3f2--

From dev-return-11695-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 01:51:33 2015
Return-Path: <dev-return-11695-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7392017C9F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 01:51:33 +0000 (UTC)
Received: (qmail 13922 invoked by uid 500); 20 Feb 2015 01:51:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13844 invoked by uid 500); 20 Feb 2015 01:51:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13624 invoked by uid 99); 20 Feb 2015 01:51:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 01:51:31 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tnachen@gmail.com designates 209.85.218.46 as permitted sender)
Received: from [209.85.218.46] (HELO mail-oi0-f46.google.com) (209.85.218.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 01:51:27 +0000
Received: by mail-oi0-f46.google.com with SMTP id x69so311275oia.5
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 17:50:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ZnDMX5kePy51jOlcN0CxgVlWx8NQQcb+ugHR+JQRHZQ=;
        b=Rd3z+4BrK4jk0mcOsr2z5crhjVbcRhvhcerwxP8cEIWXkNPTZAS/3lqoaBRqmqRLW2
         uC3uPPqbdbgFF6sHrG6qRLdxCOQFwo1GzqBFOr56mp5v/XSliO9uoQgXQApzy0OFtySJ
         5qiINbWD/w5wcqzbLpsrKvY9QNAydvJ1VCinAwjkOcuZyyg4fph3opD9nPi70U/8T+2H
         iNnVYOqsLGwpbNLdv7foEAy2t7NzQSDO3tGnQV4wu86HPgwXFQpSzCbOdt6uASYVRqjd
         WvKIOeyuTFsvy+bUW/V8kd51+KODN9xqMbD9R2OuIXySHS940HDFgMgHpC1yeb41CP2T
         tz7w==
MIME-Version: 1.0
X-Received: by 10.202.71.65 with SMTP id u62mr4809024oia.88.1424397021820;
 Thu, 19 Feb 2015 17:50:21 -0800 (PST)
Received: by 10.60.77.70 with HTTP; Thu, 19 Feb 2015 17:50:21 -0800 (PST)
In-Reply-To: <CAOTBr2=mKr5Nod=Kqtd3o6xoA8i6VA=cc7WF3OZEMYacxCtY4g@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
	<CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com>
	<CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
	<CAOTBr2kuNkJ3XdzRYkWZ-Z7_H1veufz0wT6H3pDGrmY+RUYEhg@mail.gmail.com>
	<CAAswR-6D6B0N-FaR0vE9fRHr0pf5JHUnd4Xp8A-9AWDaV-rFig@mail.gmail.com>
	<CAOTBr2=mKr5Nod=Kqtd3o6xoA8i6VA=cc7WF3OZEMYacxCtY4g@mail.gmail.com>
Date: Thu, 19 Feb 2015 17:50:21 -0800
Message-ID: <CAFx0iW_92+yuc_j0fP0k7q9M7dx3zFx3cCPgO75GKXpz=_Ty-g@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Timothy Chen <tnachen@gmail.com>
To: Krishna Sankar <ksankar42@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, Sean Owen <sowen@cloudera.com>, 
	Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1 (non-binding)

Tested Mesos coarse/fine-grained mode with 4 nodes Mesos cluster with
simple shuffle/map task.

Will be testing with more complete suite (ie: spark-perf) once the
infrastructure is setup to do so.

Tim

On Thu, Feb 19, 2015 at 12:50 PM, Krishna Sankar <ksankar42@gmail.com> wrote:
> Excellent. Explicit toDF() works.
> a) employees.toDF().registerTempTable("Employees") - works
> b) Also affects saveAsParquetFile - orders.toDF().saveAsParquetFile
>
> Adding to my earlier tests:
> 4.0 SQL from Scala and Python
> 4.1 result = sqlContext.sql("SELECT * from Employees WHERE State = 'WA'") OK
> 4.2 result = sqlContext.sql("SELECT
> OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER
> JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK
> 4.3 result = sqlContext.sql("SELECT ShipCountry, Sum(OrderDetails.UnitPrice
> * Qty * Discount) AS ProductSales FROM Orders INNER JOIN OrderDetails ON
> Orders.OrderID = OrderDetails.OrderID GROUP BY ShipCountry") OK
> 4.4 saveAsParquetFile OK
> 4.5 Read and verify the 4.4 save - sqlContext.parquetFile,
> registerTempTable, sql OK
>
> Cheers & thanks Michael
> <k/>
>
>
>
> On Thu, Feb 19, 2015 at 12:02 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "
>>> import sqlContext.implicits._" doesn't do the implicit conversations.
>>> registerTempTable
>>> gives syntax error. I will dig deeper tomorrow. Has anyone seen this ?
>>
>>
>> We will write up a whole migration guide before the final release, but I
>> can quickly explain this one.  We made the implicit conversion
>> significantly less broad to avoid the chance of confusing conflicts.
>> However, now you have to call .toDF in order to force RDDs to become
>> DataFrames.
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11696-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 02:46:32 2015
Return-Path: <dev-return-11696-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9650017D75
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 02:46:32 +0000 (UTC)
Received: (qmail 82234 invoked by uid 500); 20 Feb 2015 02:46:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82153 invoked by uid 500); 20 Feb 2015 02:46:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82136 invoked by uid 99); 20 Feb 2015 02:46:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 02:46:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cjnolet@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 02:46:21 +0000
Received: by iebtr6 with SMTP id tr6so4841640ieb.7
        for <dev@spark.apache.org>; Thu, 19 Feb 2015 18:46:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=MVIHv4FwUMXrFH7ywG40a6y8G1Cfd3q4o2lYFxLQqj0=;
        b=l9O1NbAxRo7ZSA79YNMBT5pHifT2w510g7MKB0VsUU+bkkhbq1gHQLczdu9JsXnD1N
         ywBAueouGpncSrsj9zMCCt9jgGOtwAgsWxFGZl8vjhQy7lJkq8z8jAyJjM4R8ax/9Kze
         CwsfLIH2qC0Y087AxkCA+2UnGsFbuyyhFG1fqrbu3oB37azLBVoXFcq789CrD3snQ+BW
         GzXQOBjcr0C55FYSRAkzoxQSstRF0N5/laDSAAUzG1Y/SH/yMriX2BtgHbsaNJaWFPWJ
         W78hfORHC7z7Qx3WNlpuxEm9SX1QpN1L3xh+4dqjrp8RlQkXlVNgB5DvGZsw+W+W+ZAj
         TvPQ==
X-Received: by 10.107.47.22 with SMTP id j22mr10868145ioo.16.1424400361573;
 Thu, 19 Feb 2015 18:46:01 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.18.175 with HTTP; Thu, 19 Feb 2015 18:45:41 -0800 (PST)
In-Reply-To: <CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAMAsSdJ9fzwa+wySZrYUsvo5FgCpxHqpm=wtr4gJ9fBs-+3cNQ@mail.gmail.com>
 <CABPQxsuR4etEvzUZ6zsVQ_Je_8MYtDg+v7F5WrSCyGSFVMehTA@mail.gmail.com> <CAMAsSdKtHQnX_DtkyYxnZmLR4bEUOr=6gusQZLt0OdPOJqYqQg@mail.gmail.com>
From: Corey Nolet <cjnolet@gmail.com>
Date: Thu, 19 Feb 2015 21:45:41 -0500
Message-ID: <CAOHP_tH8N8NemMgKSyCpV1FVe+oBT6vxdBy9d5kh7Fqj6zzQ5A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1664891f92c050f7c0d17
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1664891f92c050f7c0d17
Content-Type: text/plain; charset=UTF-8

+1 (non-binding)

- Verified signatures using [1]
- Built on MacOSX Yosemite
- Built on Fedora 21

Each build was run with and Hadoop-2.4 version with yarn, hive, and
hive-thriftserver profiles

I am having trouble getting all the tests passing on a single run on both
machines but we have this same problem on other projects as well.

[1] https://github.com/cjnolet/nexus-staging-gpg-verify


On Wed, Feb 18, 2015 at 6:25 PM, Sean Owen <sowen@cloudera.com> wrote:

> On Wed, Feb 18, 2015 at 6:13 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >> Patrick this link gives a 404:
> >> https://people.apache.org/keys/committer/pwendell.asc
> >
> > Works for me. Maybe it's some ephemeral issue?
>
> Yes works now; I swear it didn't before! that's all set now. The
> signing key is in that file.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11c1664891f92c050f7c0d17--

From dev-return-11697-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 08:31:00 2015
Return-Path: <dev-return-11697-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D873E1057B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 08:30:59 +0000 (UTC)
Received: (qmail 35783 invoked by uid 500); 20 Feb 2015 08:30:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35713 invoked by uid 500); 20 Feb 2015 08:30:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35701 invoked by uid 99); 20 Feb 2015 08:30:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 08:30:58 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mkim@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 08:30:29 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Fri, 20
 Feb 2015 00:30:24 -0800
From: Mingyu Kim <mkim@palantir.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: Matt Cheah <mcheah@palantir.com>
Subject: The default CDH4 build uses avro-mapred hadoop1
Thread-Topic: The default CDH4 build uses avro-mapred hadoop1
Thread-Index: AQHQTOd4hIAG25Vv+UGWLpat37wj/w==
Date: Fri, 20 Feb 2015 08:30:23 +0000
Message-ID: <D10C309A.1D70B%mkim@palantir.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
user-agent: Microsoft-MacOutlook/14.4.1.140326
x-originating-ip: [10.160.122.85]
Content-Type: multipart/alternative;
	boundary="_000_D10C309A1D70Bmkimpalantircom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D10C309A1D70Bmkimpalantircom_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

Hi all,

Related to https://issues.apache.org/jira/browse/SPARK-3039, the default CD=
H4 build, which is built with "mvn -Dhadoop.version=3D2.0.0-mr1-cdh4.2.0 -D=
skipTests clean package=94, pulls in avro-mapred hadoop1, as opposed to avr=
o-mapred hadoop2. This ends up in the same error as mentioned in the linked=
 bug. (pasted below).

The right solution would be to create a hadoop-2.0 profile that sets avro.m=
apred.classifier to hadoop2, and to build CDH4 build with =93-Phadoop-2.0=
=94 option.

What do people think?

Mingyu

=97=97=97=97=97=97=97=97=97=97

java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.m=
apreduce.TaskAttemptContext, but class was expected
       at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(A=
vroKeyInputFormat.java:47)
       at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.sca=
la:133)
       at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:107)
       at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69)
       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
       at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
       at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
       at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
       at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
       at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
       at org.apache.spark.rdd.FilteredRDD.compute(FilteredRDD.scala:34)
       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
       at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
       at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61=
)
       at org.apache.spark.scheduler.Task.run(Task.scala:56)
       at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:=
200)
       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecu=
tor.java:1145)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExec=
utor.java:615)
       at java.lang.Thread.run(Thread.java:745)


--_000_D10C309A1D70Bmkimpalantircom_--

From dev-return-11698-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 08:35:52 2015
Return-Path: <dev-return-11698-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D0C0D1058D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 08:35:52 +0000 (UTC)
Received: (qmail 46721 invoked by uid 500); 20 Feb 2015 08:35:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46641 invoked by uid 500); 20 Feb 2015 08:35:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46624 invoked by uid 99); 20 Feb 2015 08:35:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 08:35:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of niranda.perera@gmail.com designates 209.85.214.178 as permitted sender)
Received: from [209.85.214.178] (HELO mail-ob0-f178.google.com) (209.85.214.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 08:35:46 +0000
Received: by mail-ob0-f178.google.com with SMTP id uz6so22762349obc.9
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 00:33:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=fJaIt12fuQnnGQ1WqUMxMI3hM8yWD8ExumdGZdenokQ=;
        b=E1lYqQGSAbIFg4P38i89lgjH1fn/8LN/TDTkzX6EXrqEMG/aQbEqUIhRQHsQUXEpWS
         sA8dXTT6mnwMGi6GldwasGdVL0VKJrXFpmA7lyQVUQ22n6o4v2SylGzCjg6Ecz+DQ78D
         M2+/u2f5og/TWQE+1s/wBZZ6mAKk3WlUl7uotGaewMhnFLONrQr2gQRw5uE/C5d4C1BP
         upI0Sp80QCuaHPfyVXUIDZy0d6Jev9feMKY1OMn/2mAvtqWO8IyJj5LCleaqodfnZhex
         qSA4p2csdzocYx3tPDMzQTE5Hl3Rc5rpEdqej+VpWs84VX4Hk7Qn5WMLrGgDly0tRAqY
         b/jg==
MIME-Version: 1.0
X-Received: by 10.202.176.4 with SMTP id z4mr5355132oie.43.1424421190476; Fri,
 20 Feb 2015 00:33:10 -0800 (PST)
Received: by 10.182.40.166 with HTTP; Fri, 20 Feb 2015 00:33:10 -0800 (PST)
Date: Fri, 20 Feb 2015 14:03:10 +0530
Message-ID: <CANCoaU4fjbDKFrGO+gEWDVy-SmMnKP8w0u7n-cfXwm-iL3_bqg@mail.gmail.com>
Subject: OSGI bundles for spark project..
From: Niranda Perera <niranda.perera@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d3a9211abba050f80e72f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d3a9211abba050f80e72f
Content-Type: text/plain; charset=UTF-8

Hi,

I am interested in a Spark OSGI bundle.

While checking the maven repository I found out that it is still not being
implemented.

Can we see an OSGI bundle being released soon? Is it in the Spark Project
roadmap?

Rgds
-- 
Niranda

--001a113d3a9211abba050f80e72f--

From dev-return-11699-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 10:04:03 2015
Return-Path: <dev-return-11699-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A1F7108A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 10:04:03 +0000 (UTC)
Received: (qmail 98270 invoked by uid 500); 20 Feb 2015 10:04:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98197 invoked by uid 500); 20 Feb 2015 10:04:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98185 invoked by uid 99); 20 Feb 2015 10:04:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:04:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dirceu.semighini@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:03:56 +0000
Received: by mail-ob0-f175.google.com with SMTP id va2so23197049obc.6
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 02:02:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=W668xT+FYq4EjGidZad9JQibSZQizD7G1rHOFouChHE=;
        b=cgitbKPh2An8p6zzsrKm+nTN3xiLOl/XJ7AbExN5cqofBcXpTE86wwxg0zgsCbcQcz
         ebBUWmErQ6PBmvl6NiP7uY+Ov16/NMdptwT0BBTC6V7lrT1BFMybYOSdxpVZ2r4ha4lc
         2la+NFTiMh00PnJDS+AvFaoMgUOhMUpZ9o4cRliGDuoYpdka7Ycwz93CbTR8BJ/ydHLm
         ib+PO8y2wW3ODfr9rAFKVtPCyWM8S3rsb01m5IYHVjHpt6w/uYSsrsN1BXyN2rNVpghy
         KRf5kTvs8EqBqD9jAZfGMWVbriZREoGvexY5Qxnuy/rYdC7WIwXuxWDTUr6BNEHlqGDC
         lt7Q==
X-Received: by 10.202.65.8 with SMTP id o8mr5591354oia.113.1424426525456; Fri,
 20 Feb 2015 02:02:05 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.88.215 with HTTP; Fri, 20 Feb 2015 02:01:25 -0800 (PST)
From: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Date: Fri, 20 Feb 2015 08:01:25 -0200
Message-ID: <CAO4-Pq_Bj31sQq1g9T6WOSFpEkyWdXAYTz=EWL6jHKxpDJxz0A@mail.gmail.com>
Subject: Spark performance on 32 Cpus Server Cluster
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113ddb5e0f23c3050f822566
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ddb5e0f23c3050f822566
Content-Type: text/plain; charset=UTF-8

Hi all,
I'm running Spark 1.2.0, in Stand alone mode, on different cluster and
server sizes. All of my data is cached in memory.
Basically I have a mass of data, about 8gb, with about 37k of columns, and
I'm running different configs of an BinaryLogisticRegressionBFGS.
When I put spark to run on 9 servers (1 master and 8 slaves), with 32 cores
each. I noticed that the cpu usage was varying from 20% to 50% (counting
the cpu usage of 9 servers in the cluster).
First I tried to repartition the Rdds to the same number of total client
cores (256), but that didn't help. After I've tried to change the
property *spark.default.parallelism
* to the same number (256) but that didn't helped to increase the cpu usage.
Looking at the spark monitoring tool, I saw that some stages  took 52s to
be completed.
My last shot was trying to run some tasks in parallel, but when I start
running tasks in parallel (4 tasks) the total cpu time spent to complete
this has increased in about 10%, task parallelism didn't helped.
Looking at the monitoring tool I've noticed that when running tasks in
parallel, the stages complete together, if I have 4 stages running in
parallel (A,B,C and D), if A, B and C finishes, they will wait for D to
mark all this 4 stages as completed, is that right?
Is there any way to improve the cpu usage when running on large servers?
Spending more time when running tasks is an expected behaviour?

Kind Regards,
Dirceu

--001a113ddb5e0f23c3050f822566--

From dev-return-11700-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 10:18:22 2015
Return-Path: <dev-return-11700-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 605C810904
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 10:18:22 +0000 (UTC)
Received: (qmail 17973 invoked by uid 500); 20 Feb 2015 10:18:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17900 invoked by uid 500); 20 Feb 2015 10:18:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17888 invoked by uid 99); 20 Feb 2015 10:18:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:18:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:17:55 +0000
Received: by mail-wi0-f179.google.com with SMTP id hi2so1851097wib.0
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 02:17:54 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=r5DcQ3G1MVTP/US/FwU1JF+YTatwvhwoYMFmWVhe1ec=;
        b=iKisx+CEMj9ACzXQTnYSo3BW9gBYW066PWXq+d20XZywmb5KdVnbgLjudxvd3XdS0K
         6aSEgFzz1wVdtJVt265p2z42hu/rxbRVB2gY+SZNqQwkzLYaw+wUmRUXNPwvCcZZvb4l
         Fqz2jsIyn7+2fBr6zfbk+5zHanoZpvFNGsL8+GTiyv4RJg5mXmQUXxma+2jCAZOt6Yjp
         AmgJyjuMSNN5fjIEyx08g6wU3/VQlRuD+oD3ZBLt7K/0CwbdO68MGAKQow1J53zr7M2/
         D1HxbhzkNDRKoqND5vIHrWooxG2E9dzwmys8dg0p4M40CigKlXotqWzH54+alTYBbSCj
         Fs6Q==
X-Gm-Message-State: ALoCoQnOB2yNDRsG+5H47SZ1Ndy1EyuqLwbEG/HKJtkgIav5vvvYf5WLo0KJePkkeiHCRwxMymNQ
X-Received: by 10.180.74.141 with SMTP id t13mr22900324wiv.45.1424427474113;
 Fri, 20 Feb 2015 02:17:54 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Fri, 20 Feb 2015 02:17:33 -0800 (PST)
In-Reply-To: <CAO4-Pq_Bj31sQq1g9T6WOSFpEkyWdXAYTz=EWL6jHKxpDJxz0A@mail.gmail.com>
References: <CAO4-Pq_Bj31sQq1g9T6WOSFpEkyWdXAYTz=EWL6jHKxpDJxz0A@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 20 Feb 2015 10:17:33 +0000
Message-ID: <CAMAsSdKpdWDbfwaDkkjXzEXTuiDCYnHpgXSbGVcx9PLkpEOfhA@mail.gmail.com>
Subject: Re: Spark performance on 32 Cpus Server Cluster
To: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

It sounds like your computation just isn't CPU bound, right? or maybe
that only some stages are. It's not clear what work you are doing
beyond the core LR.

Stages don't wait on each other unless one depends on the other. You'd
have to clarify what you mean by running stages in parallel, like what
are the interdependencies.

On Fri, Feb 20, 2015 at 10:01 AM, Dirceu Semighini Filho
<dirceu.semighini@gmail.com> wrote:
> Hi all,
> I'm running Spark 1.2.0, in Stand alone mode, on different cluster and
> server sizes. All of my data is cached in memory.
> Basically I have a mass of data, about 8gb, with about 37k of columns, and
> I'm running different configs of an BinaryLogisticRegressionBFGS.
> When I put spark to run on 9 servers (1 master and 8 slaves), with 32 cores
> each. I noticed that the cpu usage was varying from 20% to 50% (counting
> the cpu usage of 9 servers in the cluster).
> First I tried to repartition the Rdds to the same number of total client
> cores (256), but that didn't help. After I've tried to change the
> property *spark.default.parallelism
> * to the same number (256) but that didn't helped to increase the cpu usage.
> Looking at the spark monitoring tool, I saw that some stages  took 52s to
> be completed.
> My last shot was trying to run some tasks in parallel, but when I start
> running tasks in parallel (4 tasks) the total cpu time spent to complete
> this has increased in about 10%, task parallelism didn't helped.
> Looking at the monitoring tool I've noticed that when running tasks in
> parallel, the stages complete together, if I have 4 stages running in
> parallel (A,B,C and D), if A, B and C finishes, they will wait for D to
> mark all this 4 stages as completed, is that right?
> Is there any way to improve the cpu usage when running on large servers?
> Spending more time when running tasks is an expected behaviour?
>
> Kind Regards,
> Dirceu

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11701-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 10:36:07 2015
Return-Path: <dev-return-11701-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 09C8F10983
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 10:36:07 +0000 (UTC)
Received: (qmail 44570 invoked by uid 500); 20 Feb 2015 10:35:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44493 invoked by uid 500); 20 Feb 2015 10:35:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44482 invoked by uid 99); 20 Feb 2015 10:35:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:35:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.171 as permitted sender)
Received: from [74.125.82.171] (HELO mail-we0-f171.google.com) (74.125.82.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 10:35:55 +0000
Received: by wesu56 with SMTP id u56so4759171wes.10
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 02:34:49 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=xKSE+G03HyMPUezTf/H6nj9kR8KNreGGl9Tck8xLnkY=;
        b=mYBLaH/73rMZlB5oAzs5oOTp/55JH13ZKOlfSwZeG96bc2Cf0ualQozBBksPYqAhDB
         LkksSZa036/FFFc1lBi8IYJdArVCU4xEDXsIYGSVHBLntL/hpPCQlW+1xvSKMiBnmcuY
         G3hIh6Dz7LlC4ZZzzwQQ8X2szHFRc2Yg9EL67iSkWaKI6a11+jS5D6HUlDTwLT0ne50+
         M0ORQIgxXB28uqfiM+XcJRNtByMTKUjN/5SpF9hrVMo/ZJUMgpqWZvRl5TVK95Er4//V
         0i+FdyM95YGp0N7zLmnz4NMAAQPS9Xm1np8hgNaDyj2IMkmmuPOJBzsADm8Jg2gO4nmJ
         Eylg==
X-Gm-Message-State: ALoCoQku9DyldFPsXLbSeTxr3tbYJUwEjdWzA5DmuzphNrIAdOP3BwA+TixayJGhDUhYE3kzN5hP
X-Received: by 10.194.60.104 with SMTP id g8mr17280135wjr.96.1424428489414;
 Fri, 20 Feb 2015 02:34:49 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Fri, 20 Feb 2015 02:34:29 -0800 (PST)
In-Reply-To: <D10C309A.1D70B%mkim@palantir.com>
References: <D10C309A.1D70B%mkim@palantir.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 20 Feb 2015 10:34:29 +0000
Message-ID: <CAMAsSdJpRmzVVYXDe64hR5E2VzjSCzTm_sk=t8EfcntEvyNWnw@mail.gmail.com>
Subject: Re: The default CDH4 build uses avro-mapred hadoop1
To: Mingyu Kim <mkim@palantir.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Matt Cheah <mcheah@palantir.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

True, although a number of other little issues make me, personally,
not want to continue down this road:

- There are already a lot of build profiles to try to cover Hadoop versions
- I don't think it's quite right to have vendor-specific builds in
Spark to begin with
- We should be moving to only support Hadoop 2 soon IMHO anyway
- CDH4 is EOL in a few months I think

On Fri, Feb 20, 2015 at 8:30 AM, Mingyu Kim <mkim@palantir.com> wrote:
> Hi all,
>
> Related to https://issues.apache.org/jira/browse/SPARK-3039, the default =
CDH4 build, which is built with "mvn -Dhadoop.version=3D2.0.0-mr1-cdh4.2.0 =
-DskipTests clean package=E2=80=9D, pulls in avro-mapred hadoop1, as oppose=
d to avro-mapred hadoop2. This ends up in the same error as mentioned in th=
e linked bug. (pasted below).
>
> The right solution would be to create a hadoop-2.0 profile that sets avro=
.mapred.classifier to hadoop2, and to build CDH4 build with =E2=80=9C-Phado=
op-2.0=E2=80=9D option.
>
> What do people think?
>
> Mingyu
>
> =E2=80=94=E2=80=94=E2=80=94=E2=80=94=E2=80=94=E2=80=94=E2=80=94=E2=80=94=
=E2=80=94=E2=80=94
>
> java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop=
.mapreduce.TaskAttemptContext, but class was expected
>        at org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader=
(AvroKeyInputFormat.java:47)
>        at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.s=
cala:133)
>        at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:10=
7)
>        at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69=
)
>        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>        at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
>        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>        at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
>        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>        at org.apache.spark.rdd.FilteredRDD.compute(FilteredRDD.scala:34)
>        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:=
61)
>        at org.apache.spark.scheduler.Task.run(Task.scala:56)
>        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scal=
a:200)
>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExe=
cutor.java:1145)
>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolEx=
ecutor.java:615)
>        at java.lang.Thread.run(Thread.java:745)
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11702-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 12:20:23 2015
Return-Path: <dev-return-11702-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 546A010C30
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 12:20:23 +0000 (UTC)
Received: (qmail 99987 invoked by uid 500); 20 Feb 2015 12:20:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99905 invoked by uid 500); 20 Feb 2015 12:20:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99891 invoked by uid 99); 20 Feb 2015 12:20:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 12:20:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of dirceu.semighini@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 12:20:17 +0000
Received: by mail-ob0-f180.google.com with SMTP id vb8so23598518obc.11
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 04:19:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=T6GO/5Fo6MnlaoatkTvPrjclE1cW3e4Ye23pFk9k/5c=;
        b=fExTG6EgI/8Ag6/pfl9fI6lYHW0FEdK8zgqUxZGWFskE5pMwJiPgIV3kIFKBSwFZWG
         f+m5uVC9VRI/sFnnoB+z5sy+iLssSyR1QhzNOEgVTJryhjgvHzv6GAmJ9hClp8hacoeB
         9e4hX1sbtJpE8ck+cPGWqov/pllVoxkIgs/3DAFbUc5OPtHx2Ef1pKOCiH8YGm3V/ygz
         p438rM+JJrrh1WM269pW5cqxSXM9ZhBanMJtYinM3PIbgzril8qdBErGXA6TO4DAt+qB
         w7CkW+uCSDSrH+z4zYMJAQDU0oMO+Ixvu72BtJ+irEW//JpzTcLVTnUa3QicOat+guh9
         SWUA==
X-Received: by 10.182.40.200 with SMTP id z8mr6441280obk.38.1424434752200;
 Fri, 20 Feb 2015 04:19:12 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.88.215 with HTTP; Fri, 20 Feb 2015 04:18:32 -0800 (PST)
In-Reply-To: <CAMAsSdKpdWDbfwaDkkjXzEXTuiDCYnHpgXSbGVcx9PLkpEOfhA@mail.gmail.com>
References: <CAO4-Pq_Bj31sQq1g9T6WOSFpEkyWdXAYTz=EWL6jHKxpDJxz0A@mail.gmail.com>
 <CAMAsSdKpdWDbfwaDkkjXzEXTuiDCYnHpgXSbGVcx9PLkpEOfhA@mail.gmail.com>
From: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Date: Fri, 20 Feb 2015 10:18:32 -0200
Message-ID: <CAO4-Pq8pgNdFr_dftTR8vjWw24fJHRSyEU42Ztd7Y0D0Fi81-Q@mail.gmail.com>
Subject: Re: Spark performance on 32 Cpus Server Cluster
To: Sean Owen <sowen@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c32c20699d13050f840f68
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c32c20699d13050f840f68
Content-Type: text/plain; charset=UTF-8

Hi Sean,
I'm trying to increase the cpu usage by running logistic regression in
different datasets in parallel. They shouldn't depend on each other.
I train several  logistic regression models from different column
combinations of a main dataset. I processed the combinations in a ParArray
in an attempt to increase cpu usage but id did not help.



2015-02-20 8:17 GMT-02:00 Sean Owen <sowen@cloudera.com>:

> It sounds like your computation just isn't CPU bound, right? or maybe
> that only some stages are. It's not clear what work you are doing
> beyond the core LR.
>
> Stages don't wait on each other unless one depends on the other. You'd
> have to clarify what you mean by running stages in parallel, like what
> are the interdependencies.
>
> On Fri, Feb 20, 2015 at 10:01 AM, Dirceu Semighini Filho
> <dirceu.semighini@gmail.com> wrote:
> > Hi all,
> > I'm running Spark 1.2.0, in Stand alone mode, on different cluster and
> > server sizes. All of my data is cached in memory.
> > Basically I have a mass of data, about 8gb, with about 37k of columns,
> and
> > I'm running different configs of an BinaryLogisticRegressionBFGS.
> > When I put spark to run on 9 servers (1 master and 8 slaves), with 32
> cores
> > each. I noticed that the cpu usage was varying from 20% to 50% (counting
> > the cpu usage of 9 servers in the cluster).
> > First I tried to repartition the Rdds to the same number of total client
> > cores (256), but that didn't help. After I've tried to change the
> > property *spark.default.parallelism
> > * to the same number (256) but that didn't helped to increase the cpu
> usage.
> > Looking at the spark monitoring tool, I saw that some stages  took 52s to
> > be completed.
> > My last shot was trying to run some tasks in parallel, but when I start
> > running tasks in parallel (4 tasks) the total cpu time spent to complete
> > this has increased in about 10%, task parallelism didn't helped.
> > Looking at the monitoring tool I've noticed that when running tasks in
> > parallel, the stages complete together, if I have 4 stages running in
> > parallel (A,B,C and D), if A, B and C finishes, they will wait for D to
> > mark all this 4 stages as completed, is that right?
> > Is there any way to improve the cpu usage when running on large servers?
> > Spending more time when running tasks is an expected behaviour?
> >
> > Kind Regards,
> > Dirceu
>

--001a11c32c20699d13050f840f68--

From dev-return-11703-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 12:34:28 2015
Return-Path: <dev-return-11703-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 92DB610C97
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 12:34:28 +0000 (UTC)
Received: (qmail 23143 invoked by uid 500); 20 Feb 2015 12:34:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23069 invoked by uid 500); 20 Feb 2015 12:34:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23058 invoked by uid 99); 20 Feb 2015 12:34:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 12:34:27 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.42 as permitted sender)
Received: from [74.125.82.42] (HELO mail-wg0-f42.google.com) (74.125.82.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 12:34:22 +0000
Received: by mail-wg0-f42.google.com with SMTP id n12so12929261wgh.1
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 04:31:47 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=bAWER7Bq3LgbOBgG3Olvytn3xIa7UZ6clY7rmumo+8U=;
        b=P1D1fCMeuF6ccKxVQ+rbk+SXi9cG08/OCbD7gfUHA2WvYte5ytbQbHMEG3qNYVGkBy
         McsA/E56/k6LeHW3AJfnH/ij+G1z6xeQkQsnpeGN+bz4ZAj2d51L5pWOrvL3EpxFxfHp
         Rk+hesxLeJaofmy1y3kHPWOe6YWb7dF4+c3xsCX6FuD3V5X+ZEip2muDU0+wddhzlFmY
         +hO0zEU/sv0bA1j9XJIvsBl1414/9uK2BeXXHHLyx/r9Cpy/y4wa1JuR9azI+JqCDdMo
         nQFHEPVK6o2lD9fzGDUr1mLiqA+d2o7ioLM1WoVLBPljFVZmzC1MEu7B4sYD488NqVXr
         xdvg==
X-Gm-Message-State: ALoCoQnTawIF1tz0MUYKgWQc68y/qjGHL73PQKEb3TB1cF2J2Fpt9W815gRKGYpWuv4QR1dLvwfb
X-Received: by 10.180.36.174 with SMTP id r14mr15078864wij.93.1424435507056;
 Fri, 20 Feb 2015 04:31:47 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Fri, 20 Feb 2015 04:31:26 -0800 (PST)
In-Reply-To: <CAO4-Pq8pgNdFr_dftTR8vjWw24fJHRSyEU42Ztd7Y0D0Fi81-Q@mail.gmail.com>
References: <CAO4-Pq_Bj31sQq1g9T6WOSFpEkyWdXAYTz=EWL6jHKxpDJxz0A@mail.gmail.com>
 <CAMAsSdKpdWDbfwaDkkjXzEXTuiDCYnHpgXSbGVcx9PLkpEOfhA@mail.gmail.com> <CAO4-Pq8pgNdFr_dftTR8vjWw24fJHRSyEU42Ztd7Y0D0Fi81-Q@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 20 Feb 2015 12:31:26 +0000
Message-ID: <CAMAsSd+cTML5kbujxCgvMYyfV4j-BVDaXzJ+3n=fL-SkvSZL8g@mail.gmail.com>
Subject: Re: Spark performance on 32 Cpus Server Cluster
To: Dirceu Semighini Filho <dirceu.semighini@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Yes that makes sense, but it doesn't make the jobs CPU-bound. What is
the bottleneck? the model building or other stages? I would think you
can get the model building to be CPU bound, unless you have chopped it
up into really small partitions. I think it's best to look further
into what stages are slow, and what it seems to be spending time on --
GC? I/O?

On Fri, Feb 20, 2015 at 12:18 PM, Dirceu Semighini Filho
<dirceu.semighini@gmail.com> wrote:
> Hi Sean,
> I'm trying to increase the cpu usage by running logistic regression in
> different datasets in parallel. They shouldn't depend on each other.
> I train several  logistic regression models from different column
> combinations of a main dataset. I processed the combinations in a ParArray
> in an attempt to increase cpu usage but id did not help.
>
>
>
> 2015-02-20 8:17 GMT-02:00 Sean Owen <sowen@cloudera.com>:
>
>> It sounds like your computation just isn't CPU bound, right? or maybe
>> that only some stages are. It's not clear what work you are doing
>> beyond the core LR.
>>
>> Stages don't wait on each other unless one depends on the other. You'd
>> have to clarify what you mean by running stages in parallel, like what
>> are the interdependencies.
>>
>> On Fri, Feb 20, 2015 at 10:01 AM, Dirceu Semighini Filho
>> <dirceu.semighini@gmail.com> wrote:
>> > Hi all,
>> > I'm running Spark 1.2.0, in Stand alone mode, on different cluster and
>> > server sizes. All of my data is cached in memory.
>> > Basically I have a mass of data, about 8gb, with about 37k of columns,
>> > and
>> > I'm running different configs of an BinaryLogisticRegressionBFGS.
>> > When I put spark to run on 9 servers (1 master and 8 slaves), with 32
>> > cores
>> > each. I noticed that the cpu usage was varying from 20% to 50% (counting
>> > the cpu usage of 9 servers in the cluster).
>> > First I tried to repartition the Rdds to the same number of total client
>> > cores (256), but that didn't help. After I've tried to change the
>> > property *spark.default.parallelism
>> > * to the same number (256) but that didn't helped to increase the cpu
>> > usage.
>> > Looking at the spark monitoring tool, I saw that some stages  took 52s
>> > to
>> > be completed.
>> > My last shot was trying to run some tasks in parallel, but when I start
>> > running tasks in parallel (4 tasks) the total cpu time spent to complete
>> > this has increased in about 10%, task parallelism didn't helped.
>> > Looking at the monitoring tool I've noticed that when running tasks in
>> > parallel, the stages complete together, if I have 4 stages running in
>> > parallel (A,B,C and D), if A, B and C finishes, they will wait for D to
>> > mark all this 4 stages as completed, is that right?
>> > Is there any way to improve the cpu usage when running on large servers?
>> > Spending more time when running tasks is an expected behaviour?
>> >
>> > Kind Regards,
>> > Dirceu
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11704-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 13:45:31 2015
Return-Path: <dev-return-11704-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D3AE10FDC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 13:45:31 +0000 (UTC)
Received: (qmail 82787 invoked by uid 500); 20 Feb 2015 13:45:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82703 invoked by uid 500); 20 Feb 2015 13:45:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82691 invoked by uid 99); 20 Feb 2015 13:45:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 13:45:26 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.53 as permitted sender)
Received: from [209.85.220.53] (HELO mail-pa0-f53.google.com) (209.85.220.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 13:45:21 +0000
Received: by pablf10 with SMTP id lf10so8082635pab.12
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 05:45:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        bh=eZ9cRtnPAFXyX60zMjdnXP+wfOG0CdjbMtkOKBn62TI=;
        b=Mgo90ADqQ6peghu270Pp3wSNs9Fv1xpQhHDmrF4PSSUjFogoOku+QY3bqY8SMNJS4e
         AyWyWf5vqKsIQSOqPH3KLQ8YwJOtt5BAjHlV94RnVXq+NAVKHjL8jzm7jPB+uIm6T+48
         8KJ632zBHu+dwHFCBXez1kf89Saxa+mb8laosaGBg8/Ib7AXw6KmSTMbhaiAOB4vd1HM
         gCaaqxIAO0ldx4DXzNbvbEJxY2IEqbPVLDZ5VtSzg2eCsTFCxXqIHZOQKjk6P1O6JuV0
         d3+MacQPrbBmIsLMK/dg76dgFNLwxhR1elTE7/vq0exco6KZpLR/inr2U9YOQmEZX8sk
         BeFw==
X-Received: by 10.70.21.195 with SMTP id x3mr16662183pde.73.1424439901437;
        Fri, 20 Feb 2015 05:45:01 -0800 (PST)
Received: from [10.10.0.3] ([104.156.239.73])
        by mx.google.com with ESMTPSA id lf13sm27284039pab.2.2015.02.20.05.44.55
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 20 Feb 2015 05:45:00 -0800 (PST)
Message-ID: <54E73A53.2020100@gmail.com>
Date: Fri, 20 Feb 2015 21:44:51 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: The Watcher <watcherfr@gmail.com>, dev@spark.apache.org
Subject: Re: Spark SQL, Hive & Parquet data types
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
In-Reply-To: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------070508080806030502020306"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------070508080806030502020306
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

For the second question, we do plan to support Hive 0.14, possibly in 
Spark 1.4.0.

For the first question:

 1. In Spark 1.2.0, the Parquet support code doesn’t support timestamp
    type, so you can’t.
 2. In Spark 1.3.0, timestamp support was added, also Spark SQL uses its
    own Parquet support to handle both read path and write path when
    dealing with Parquet tables declared in Hive metastore, as long as
    you’re not writing to a partitioned table. So yes, you can.

The Parquet version bundled with Spark 1.3.0 is 1.6.0rc3, which supports 
timestamp type natively. However, the Parquet versions bundled with Hive 
0.13.1 and Hive 0.14.0 are 1.3.2 and 1.5.0 respectively. Neither of them 
supports timestamp type. Hive 0.14.0 “supports” read/write timestamp 
from/to Parquet by converting timestamps from/to Parquet binaries. 
Similarly, Impala converts timestamp into Parquet int96. This can be 
annoying for Spark SQL, because we must interpret Parquet files in 
different ways according to the original writer of the file. As Parquet 
matures, recent Parquet versions support more and more standard data 
types. Mappings from complex nested types to Parquet types are also 
being standardized 1 
<https://github.com/apache/incubator-parquet-mr/pull/83>.

On 2/20/15 6:50 AM, The Watcher wrote:

> Still trying to get my head around Spark SQL & Hive.
>
> 1) Let's assume I *only* use Spark SQL to create and insert data into HIVE
> tables, declared in a Hive meta-store.
>
> Does it matter at all if Hive supports the data types I need with Parquet,
> or is all that matters what Catalyst & spark's parquet relation support ?
>
> Case in point : timestamps & Parquet
> * Parquet now supports them as per
> https://github.com/Parquet/parquet-mr/issues/218
> * Hive only supports them in 0.14
> So would I be able to read/write timestamps natively in Spark 1.2 ? Spark
> 1.3 ?
>
> I have found this thread
> http://apache-spark-user-list.1001560.n3.nabble.com/timestamp-not-implemented-yet-td15414.html
> which seems to indicate that the data types supported by Hive would matter
> to Spark SQL.
> If so, why is that ? Doesn't the read path go through Spark SQL to read the
> parquet file ?
>
> 2) Is there planned support for Hive 0.14 ?
>
> Thanks
>
​

--------------070508080806030502020306--

From dev-return-11705-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 15:00:45 2015
Return-Path: <dev-return-11705-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 32D5F17413
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 15:00:45 +0000 (UTC)
Received: (qmail 27228 invoked by uid 500); 20 Feb 2015 15:00:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27158 invoked by uid 500); 20 Feb 2015 15:00:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27144 invoked by uid 99); 20 Feb 2015 15:00:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 15:00:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of watcherfr@gmail.com designates 209.85.213.170 as permitted sender)
Received: from [209.85.213.170] (HELO mail-ig0-f170.google.com) (209.85.213.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 15:00:10 +0000
Received: by mail-ig0-f170.google.com with SMTP id l13so7512661iga.1
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 06:58:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=Q/L/SmieAuOo6a1oI4ljD7jAsU0O815mLbtfeLPw8dI=;
        b=u6aY1KD2jGvX60ioSKxrozcR5BtI7Yl6GctIsnYJxvtHHPymdwmHggqmwWtCYx12y7
         EB46pD09IJfj/Ov5m+HftBTMJZlGYStHpuK04VaqStBXN61ashg8+IuFIYJkcghhl/+Z
         RHOBi/6gnS5ZVGufgIn/BOI0X0nUFxeOd13oZjeCIG+e4f8Cr70YI53Kgd6kqNN5PJoB
         8ws8ExEg+KYzCOoFHL4U/bpTULsE3slWD457LWEvbD4LfTgnEE0SZbX8BTEAlxkcMSPV
         kp+916qTjSAAIWoVgjqMFV4VPEFGx92BpNFAIPZxC+wa3+oL2HXTd3dI7Ax/xACxzdHA
         dPjQ==
MIME-Version: 1.0
X-Received: by 10.42.207.209 with SMTP id fz17mr10457917icb.43.1424444318255;
 Fri, 20 Feb 2015 06:58:38 -0800 (PST)
Received: by 10.36.16.81 with HTTP; Fri, 20 Feb 2015 06:58:38 -0800 (PST)
In-Reply-To: <54E73A53.2020100@gmail.com>
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
	<54E73A53.2020100@gmail.com>
Date: Fri, 20 Feb 2015 15:58:38 +0100
Message-ID: <CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
Subject: Re: Spark SQL, Hive & Parquet data types
From: The Watcher <watcherfr@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf303ea654978e4d050f86491f
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf303ea654978e4d050f86491f
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

>
>
>    1. In Spark 1.3.0, timestamp support was added, also Spark SQL uses
>    its own Parquet support to handle both read path and write path when
>    dealing with Parquet tables declared in Hive metastore, as long as you=
=E2=80=99re
>    not writing to a partitioned table. So yes, you can.
>
> Ah, I had missed the part about being partitioned or not. Is this related
to the work being done on ParquetRelation2 ?

We will indeed write to a partitioned table : do neither the read nor the
write path go through Spark SQL's parquet support in that case ? Is there a
JIRA/PR I can monitor to see when this would change ?

Thanks

--20cf303ea654978e4d050f86491f--

From dev-return-11706-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 15:52:05 2015
Return-Path: <dev-return-11706-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 67D1917558
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 15:52:05 +0000 (UTC)
Received: (qmail 51159 invoked by uid 500); 20 Feb 2015 15:52:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51080 invoked by uid 500); 20 Feb 2015 15:52:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51067 invoked by uid 99); 20 Feb 2015 15:52:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 15:52:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 15:51:35 +0000
Received: by padet14 with SMTP id et14so8849926pad.11
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 07:51:33 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=9hTatZXV6zjHpHFOveXmhhqVYfDh+2kcnSW7vmMdMPM=;
        b=kIkA8AAoPtQipzNqGBitfJHvd97Dlb4RXQu0p7ihuK30U/dkliRqB0UO34r8r0EqBQ
         DALO4WuxkE14GkEF4OkAygZo7aQnDBh/Bno9D0Q9LiQBgU0nu6S28Dh6X5j1FigCLil0
         GArhaZzuGyQ5xuH2fZclZh+Qm6wlgum340RfNitpFeKlKCvJcGvOy78jtLskB+lFr5kj
         dyhSvRBtYoQluhXEEW2pGxLAAHi8vVqRc++kCjwOmcniu6Fl6VtYmXtAxxl6k4odn4q+
         gThq5+5R6VylfWQ/heixrT1UuA/AuPOYgSZ9g2+IDGiyR4m7bwUDyGIc9T987ttSjK52
         Hewg==
X-Received: by 10.66.163.168 with SMTP id yj8mr17798903pab.132.1424447493848;
 Fri, 20 Feb 2015 07:51:33 -0800 (PST)
MIME-Version: 1.0
From: Denny Lee <denny.g.lee@gmail.com>
Date: Fri, 20 Feb 2015 15:51:32 +0000
Message-ID: <CABjYQ38CC36whH5hiPo-MTdAh4h6OvHSGwGajRy7y+DJKJGXwQ@mail.gmail.com>
Subject: Spark 1.3 RC1 Generate schema based on string of schema
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b86e5a4df44b7050f8706d7
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b86e5a4df44b7050f8706d7
Content-Type: text/plain; charset=UTF-8

In the Spark SQL 1.2 Programmers Guide, we can generate the schema based on
the string of schema via

val schema =
  StructType(
    schemaString.split(" ").map(fieldName => StructField(fieldName,
StringType, true)))

But when running this on Spark 1.3.0 (RC1), I get the error:

val schema =  StructType(schemaString.split(" ").map(fieldName =>
StructField(fieldName, StringType, true)))

<console>:26: error: not found: value StringType

       val schema =  StructType(schemaString.split(" ").map(fieldName =>
StructField(fieldName, StringType, true)))

I'm looking through the various datatypes within
org.apache.spark.sql.types.DataType
but thought I'd ask to see if I was missing something obvious here.

Thanks!
Denny

--047d7b86e5a4df44b7050f8706d7--

From dev-return-11707-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 16:10:31 2015
Return-Path: <dev-return-11707-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7723417619
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 16:10:31 +0000 (UTC)
Received: (qmail 97901 invoked by uid 500); 20 Feb 2015 16:10:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97823 invoked by uid 500); 20 Feb 2015 16:10:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97811 invoked by uid 99); 20 Feb 2015 16:10:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:10:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of saucam@gmail.com designates 209.85.220.45 as permitted sender)
Received: from [209.85.220.45] (HELO mail-pa0-f45.google.com) (209.85.220.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:10:04 +0000
Received: by padbj1 with SMTP id bj1so9012686pad.5
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 08:07:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=BhUyvYpEB9gNDdUfdUvfc46MBGd91v/9EUpUp4AyT0k=;
        b=yIU73p9c/meELuDk3BxOpv+uav/OXONRMVzWeKrJr+LP0IbDzyIQuxdE+NWWZnALmt
         w6SZ07sQvnpwjVy3FvGdcZJdcQV3JG/Hemh4cRswtIV1lkVJIxYYw7JiLj9fT9ZQW5ex
         3Lai7ZUYDenzv2CkgXVHI5WsapM05xvi8/Morr1z/uLJRLJnDvH3J6LPBT03LX7ofkH4
         9UQDBldS0xgEDJpzT9ajRNou04HzfLUMK//TP7sAbY4VcQhqWgz/oNLiHtH3v8ck5X+4
         p9p6RbxBGfrrremSDen1a7fVh6xDIjnZP9LNPefb7MOackHtGe6CcykDZRE0DpkdF74D
         +ApA==
MIME-Version: 1.0
X-Received: by 10.70.140.6 with SMTP id rc6mr17909337pdb.144.1424448467518;
 Fri, 20 Feb 2015 08:07:47 -0800 (PST)
Received: by 10.70.40.204 with HTTP; Fri, 20 Feb 2015 08:07:47 -0800 (PST)
In-Reply-To: <CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
	<54E73A53.2020100@gmail.com>
	<CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
Date: Fri, 20 Feb 2015 21:37:47 +0530
Message-ID: <CAJdVUwWQKJe-8wiAn1YTGMeTc-b4rJAhdMKeVZct-21WqO9Shw@mail.gmail.com>
Subject: Re: Spark SQL, Hive & Parquet data types
From: yash datta <saucam@gmail.com>
To: The Watcher <watcherfr@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1135fe24e84a2b050f8740d1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fe24e84a2b050f8740d1
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

For the old parquet path (available in 1.2.1) , i made a few changes for
being able to read/write to a table partitioned on timestamp type column

https://github.com/apache/spark/pull/4469


On Fri, Feb 20, 2015 at 8:28 PM, The Watcher <watcherfr@gmail.com> wrote:

> >
> >
> >    1. In Spark 1.3.0, timestamp support was added, also Spark SQL uses
> >    its own Parquet support to handle both read path and write path when
> >    dealing with Parquet tables declared in Hive metastore, as long as
> you=E2=80=99re
> >    not writing to a partitioned table. So yes, you can.
> >
> > Ah, I had missed the part about being partitioned or not. Is this relat=
ed
> to the work being done on ParquetRelation2 ?
>
> We will indeed write to a partitioned table : do neither the read nor the
> write path go through Spark SQL's parquet support in that case ? Is there=
 a
> JIRA/PR I can monitor to see when this would change ?
>
> Thanks
>



--=20
When events unfold with calm and ease
When the winds that blow are merely breeze
Learn from nature, from birds and bees
Live your life in love, and let joy not cease.

--001a1135fe24e84a2b050f8740d1--

From dev-return-11708-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 16:24:31 2015
Return-Path: <dev-return-11708-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1FEE7176BC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 16:24:31 +0000 (UTC)
Received: (qmail 45554 invoked by uid 500); 20 Feb 2015 16:24:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45488 invoked by uid 500); 20 Feb 2015 16:24:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45014 invoked by uid 99); 20 Feb 2015 16:24:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:24:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of denny.g.lee@gmail.com designates 209.85.192.174 as permitted sender)
Received: from [209.85.192.174] (HELO mail-pd0-f174.google.com) (209.85.192.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:23:59 +0000
Received: by pdbfl12 with SMTP id fl12so8622862pdb.2
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 08:22:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=5sxaQ6P77q69pK2DO8C5ss4H4yLJCW/I6fjTPGPKT38=;
        b=bjIRnARicLZHioTfIxyX/fOZj5/aJQVWNsx/+X+x1k+0HxVxZByQP1o+nlPsjQNjG3
         EPKk5wfFrVSHSRDXZOMp8k1NBHZ3dCD5x49OE7lfUOujTdXJTR7A0zMEewJzjrBK1frV
         O8njjATmseg06hCUvUESe/zw5aNNjMMiQr2ofiqj0Hm3d391mE61xUFe8yGdk9TqL8Jm
         7VLS6nPLZNlVXFq/6ZQKskZiwiGthA4mN7UxqKbiZu+ZuRxokCPiV+q9mmWyQ24eimnt
         atfpRmFxu4I4vwNDynBOszSIKTslV3zzwy1m6tysSFipLPi+ATYm9+okCboksBWL/QDP
         9cLA==
X-Received: by 10.67.4.70 with SMTP id cc6mr18157499pad.136.1424449347765;
 Fri, 20 Feb 2015 08:22:27 -0800 (PST)
MIME-Version: 1.0
From: Denny Lee <denny.g.lee@gmail.com>
Date: Fri, 20 Feb 2015 16:22:27 +0000
Message-ID: <CABjYQ39CJJRNOTX4sYyEkDvAi4_YF==SxGg-WZT23FqBj2GFpg@mail.gmail.com>
Subject: Re: Spark 1.3 RC1 Generate schema based on string of schema
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11339a1c5fcb9d050f87751e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11339a1c5fcb9d050f87751e
Content-Type: text/plain; charset=UTF-8

Oh, I just realized that I never imported all of sql._ .  My bad!


On Fri Feb 20 2015 at 7:51:32 AM Denny Lee <denny.g.lee@gmail.com> wrote:

> In the Spark SQL 1.2 Programmers Guide, we can generate the schema based
> on the string of schema via
>
> val schema =
>   StructType(
>     schemaString.split(" ").map(fieldName => StructField(fieldName,
> StringType, true)))
>
> But when running this on Spark 1.3.0 (RC1), I get the error:
>
> val schema =  StructType(schemaString.split(" ").map(fieldName =>
> StructField(fieldName, StringType, true)))
>
> <console>:26: error: not found: value StringType
>
>        val schema =  StructType(schemaString.split(" ").map(fieldName =>
> StructField(fieldName, StringType, true)))
>
> I'm looking through the various datatypes within org.apache.spark.sql.types.DataType
> but thought I'd ask to see if I was missing something obvious here.
>
> Thanks!
>
>
> Denny
>

--001a11339a1c5fcb9d050f87751e--

From dev-return-11709-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 16:49:04 2015
Return-Path: <dev-return-11709-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B4ACD17804
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 16:49:04 +0000 (UTC)
Received: (qmail 42508 invoked by uid 500); 20 Feb 2015 16:49:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42430 invoked by uid 500); 20 Feb 2015 16:49:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42418 invoked by uid 99); 20 Feb 2015 16:49:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:49:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of niranda.perera@gmail.com designates 209.85.218.45 as permitted sender)
Received: from [209.85.218.45] (HELO mail-oi0-f45.google.com) (209.85.218.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:48:58 +0000
Received: by mail-oi0-f45.google.com with SMTP id i138so3513933oig.4
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 08:48:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=hC8744f8sCIDfDEfLXP7yBfuhuGo2qfLfNFph14L4So=;
        b=RRyflSx5YiU4n585j0UHbJqwzMpd6wf3Leg8dp+a+R+m6ma8gcvm04ZjajpkP7jZ0o
         TvCKVLMpyj5USHH9bymtCUQSsprbqQAl+VMbG27OVJiuznCBHV8Xdtjks89RUobPsax6
         IwEKxPVMPdTpuGLZ7WxncH1x7v9xTcAw277JW+m9oc3CsYQ0qoSbKwU8i3EpeYTXBBTx
         RBUBuZP4ZorwQzcqXYEY+RzjhBTB42gjRZ+xztxSx9KUaZlyLKRrywf0qOZxrFqcAHnA
         086p++hM5J5v3iHQLFnWUaz4P2AsqQ3DNtnvX/zkfMWMgZTX76vnzaOp5ca89h6j+Jgz
         A9IA==
MIME-Version: 1.0
X-Received: by 10.202.57.195 with SMTP id g186mr6828930oia.86.1424450918336;
 Fri, 20 Feb 2015 08:48:38 -0800 (PST)
Received: by 10.182.40.166 with HTTP; Fri, 20 Feb 2015 08:48:38 -0800 (PST)
In-Reply-To: <CAMAsSd+cbyh9S-D8Nt4U8_TFrxSDp4bj9r-r68BSX9noCCFA6w@mail.gmail.com>
References: <CANCoaU4fjbDKFrGO+gEWDVy-SmMnKP8w0u7n-cfXwm-iL3_bqg@mail.gmail.com>
	<CAMAsSd+cbyh9S-D8Nt4U8_TFrxSDp4bj9r-r68BSX9noCCFA6w@mail.gmail.com>
Date: Fri, 20 Feb 2015 22:18:38 +0530
Message-ID: <CANCoaU4MhnW-S0oM7E8KR6OgnMn6Jqkpo9at7tnjz6PFdq06UA@mail.gmail.com>
Subject: Re: OSGI bundles for spark project..
From: Niranda Perera <niranda.perera@gmail.com>
To: Sean Owen <sowen@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113cfe5cfccebc050f87d2de
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cfe5cfccebc050f87d2de
Content-Type: text/plain; charset=UTF-8

Hi Sean,

does it mean that Spark is not encouraged to be embedded on other products?

On Fri, Feb 20, 2015 at 3:29 PM, Sean Owen <sowen@cloudera.com> wrote:

> I don't think an OSGI bundle makes sense for Spark. It's part JAR,
> part lifecycle manager. Spark has its own lifecycle  management and is
> not generally embeddable. Packaging is generally 'out of scope' for
> the core project beyond the standard Maven and assembly releases.
>
> On Fri, Feb 20, 2015 at 8:33 AM, Niranda Perera
> <niranda.perera@gmail.com> wrote:
> > Hi,
> >
> > I am interested in a Spark OSGI bundle.
> >
> > While checking the maven repository I found out that it is still not
> being
> > implemented.
> >
> > Can we see an OSGI bundle being released soon? Is it in the Spark Project
> > roadmap?
> >
> > Rgds
> > --
> > Niranda
>



-- 
Niranda

--001a113cfe5cfccebc050f87d2de--

From dev-return-11710-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 16:54:51 2015
Return-Path: <dev-return-11710-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AD6D517825
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 16:54:51 +0000 (UTC)
Received: (qmail 61385 invoked by uid 500); 20 Feb 2015 16:54:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61312 invoked by uid 500); 20 Feb 2015 16:54:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61301 invoked by uid 99); 20 Feb 2015 16:54:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:54:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 16:54:22 +0000
Received: by mail-wg0-f41.google.com with SMTP id b13so14290840wgh.0
        for <dev@spark.apache.org>; Fri, 20 Feb 2015 08:54:21 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=q3GxF268QO5ge58uJ+MdMuWrKG2H2h8jcfZjtq4RPe8=;
        b=ew5IjC5sYnbg8dsvm0lcBSJ8uuvhcmW8ZRk76zEbA4ifyc8/GtjL3LeeXUInNWdRYp
         GXHs154T5UL/3C9O4KBI3mam+FqT0AwdvdJiT8snW7TVzIE5hBT4gAhYL83deGLR1TEj
         f8mQ2CnHsv1oB99s5RvGgbmEfJHVPKqUKDOYTlkfKhPnKiG0KyUwJr9N15IBjI2c4IxO
         MiWxaSD0AzdZrvQk5OVix4W/6sc9Hlue9nRFm0Xwgna006LQsVF0U8hQ3D5GY8r5KXYS
         eltdf9HbuUwBmlWZ1Q58zxLG50N5nK48avsYkrvE9KH30BxUmhDsUqsMfV/G5sX3iYCo
         jesg==
X-Gm-Message-State: ALoCoQkHNZ6+TSza2j/wXPVmRwShHpfDEbW2Fv06Fcko+Y+YR+eddQL47cVc0gAwk2Tkdt+2s0z/
X-Received: by 10.194.94.164 with SMTP id dd4mr21452177wjb.56.1424451261247;
 Fri, 20 Feb 2015 08:54:21 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Fri, 20 Feb 2015 08:54:01 -0800 (PST)
In-Reply-To: <CANCoaU4MhnW-S0oM7E8KR6OgnMn6Jqkpo9at7tnjz6PFdq06UA@mail.gmail.com>
References: <CANCoaU4fjbDKFrGO+gEWDVy-SmMnKP8w0u7n-cfXwm-iL3_bqg@mail.gmail.com>
 <CAMAsSd+cbyh9S-D8Nt4U8_TFrxSDp4bj9r-r68BSX9noCCFA6w@mail.gmail.com> <CANCoaU4MhnW-S0oM7E8KR6OgnMn6Jqkpo9at7tnjz6PFdq06UA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 20 Feb 2015 16:54:01 +0000
Message-ID: <CAMAsSdLsUMH3Qe3LaszwMtDxx_Mi5x-oaLE7W-u656iFQRYKsQ@mail.gmail.com>
Subject: Re: OSGI bundles for spark project..
To: Niranda Perera <niranda.perera@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

No, you usually run Spark apps via the spark-submit script, and the
Spark machinery is already deployed on a cluster. Although it's
possible to embed the driver and get it working that way, it's not
supported.

On Fri, Feb 20, 2015 at 4:48 PM, Niranda Perera
<niranda.perera@gmail.com> wrote:
> Hi Sean,
>
> does it mean that Spark is not encouraged to be embedded on other products?
>
> On Fri, Feb 20, 2015 at 3:29 PM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> I don't think an OSGI bundle makes sense for Spark. It's part JAR,
>> part lifecycle manager. Spark has its own lifecycle  management and is
>> not generally embeddable. Packaging is generally 'out of scope' for
>> the core project beyond the standard Maven and assembly releases.
>>
>> On Fri, Feb 20, 2015 at 8:33 AM, Niranda Perera
>> <niranda.perera@gmail.com> wrote:
>> > Hi,
>> >
>> > I am interested in a Spark OSGI bundle.
>> >
>> > While checking the maven repository I found out that it is still not
>> > being
>> > implemented.
>> >
>> > Can we see an OSGI bundle being released soon? Is it in the Spark
>> > Project
>> > roadmap?
>> >
>> > Rgds
>> > --
>> > Niranda
>
>
>
>
> --
> Niranda

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11711-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 19:11:51 2015
Return-Path: <dev-return-11711-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BDFD617CFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 19:11:51 +0000 (UTC)
Received: (qmail 47195 invoked by uid 500); 20 Feb 2015 19:11:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47115 invoked by uid 500); 20 Feb 2015 19:11:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47099 invoked by uid 99); 20 Feb 2015 19:11:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 19:11:50 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mkim@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 19:11:46 +0000
Received: from EXDR01-WEST.YOJOE.local (10.160.10.135) by
 ex02-west.YOJOE.local (10.160.10.131) with Microsoft SMTP Server (TLS) id
 14.3.195.1; Fri, 20 Feb 2015 11:10:42 -0800
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EXDR01-WEST.YOJOE.local ([169.254.3.4]) with mapi id 14.03.0195.001; Fri, 20
 Feb 2015 11:10:42 -0800
From: Mingyu Kim <mkim@palantir.com>
To: Sean Owen <sowen@cloudera.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, Matt Cheah
	<mcheah@palantir.com>
Subject: Re: The default CDH4 build uses avro-mapred hadoop1
Thread-Topic: The default CDH4 build uses avro-mapred hadoop1
Thread-Index: AQHQTOd4hIAG25Vv+UGWLpat37wj/5z53emAgAAKHAA=
Date: Fri, 20 Feb 2015 19:10:41 +0000
Message-ID: <D10CC024.1D797%mkim@palantir.com>
References: <D10C309A.1D70B%mkim@palantir.com>
 <CAMAsSdJpRmzVVYXDe64hR5E2VzjSCzTm_sk=t8EfcntEvyNWnw@mail.gmail.com>
In-Reply-To: <CAMAsSdJpRmzVVYXDe64hR5E2VzjSCzTm_sk=t8EfcntEvyNWnw@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
user-agent: Microsoft-MacOutlook/14.4.1.140326
x-originating-ip: [10.100.91.90]
Content-Type: text/plain; charset="Windows-1252"
Content-ID: <14FF1A946719B749AAD4D8E86630AFAF@palantir.com>
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for the explanation.

To be clear, I meant to speak for any hadoop 2 releases before 2.2, which
have profiles in Spark. I referred to CDH4, since that=B9s the only Hadoop
2.0/2.1 version Spark ships a prebuilt package for.

I understand the hesitation of making a code change if Spark doesn=B9t plan
to support Hadoop 2.0/2.1 in general. (Please note, this is not specific
to CDH4) If so, can I propose alternative options until Spark moves to
only support hadoop2?

- Build the CDH4 package with =B3-Davro.mapred.classifier=3Dhadoop2=B2, and
update http://spark.apache.org/docs/latest/building-spark.html for all
=B32.0.*=B2 examples.
- Build the CDH4 package as is, but note known issues clearly in the
=B3download=B2 page.
- Simply do not ship CDH4 prebuilt package, and let people figure it out
themselves. Preferably, note in documentation that
=B3-Davro.mapred.classifier=3Dhadoop2=B2 should be used for all hadoop =B32=
.0.*=B2
builds.

Please let me know what you think!

Mingyu





On 2/20/15, 2:34 AM, "Sean Owen" <sowen@cloudera.com> wrote:

>True, although a number of other little issues make me, personally,
>not want to continue down this road:
>
>- There are already a lot of build profiles to try to cover Hadoop
>versions
>- I don't think it's quite right to have vendor-specific builds in
>Spark to begin with
>- We should be moving to only support Hadoop 2 soon IMHO anyway
>- CDH4 is EOL in a few months I think
>
>On Fri, Feb 20, 2015 at 8:30 AM, Mingyu Kim <mkim@palantir.com> wrote:
>> Hi all,
>>
>> Related to=20
>>https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__issues.apache.org_=
ji
>>ra_browse_SPARK-2D3039&d=3DAwIFaQ&c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tF=
b6oO
>>nmz8&r=3DennQJq47pNnObsDh-88a9YUrUulcYQoV8giPASqXB84&m=3Ds1MfvBlt11h2xojQ=
Itkw
>>aeh094ttUKTu9K5F-lA6DJY&s=3DSb2SVubKkvdjaLer3K-b_Z0RfeC1fm-CP4A-Uh6nvEQ&e=
=3D
>>, the default CDH4 build, which is built with "mvn
>>-Dhadoop.version=3D2.0.0-mr1-cdh4.2.0 -DskipTests clean package=B2, pulls=
 in
>>avro-mapred hadoop1, as opposed to avro-mapred hadoop2. This ends up in
>>the same error as mentioned in the linked bug. (pasted below).
>>
>> The right solution would be to create a hadoop-2.0 profile that sets
>>avro.mapred.classifier to hadoop2, and to build CDH4 build with
>>=B3-Phadoop-2.0=B2 option.
>>
>> What do people think?
>>
>> Mingyu
>>
>> =8B=8B=8B=8B=8B=8B=8B=8B=8B=8B
>>
>> java.lang.IncompatibleClassChangeError: Found interface
>>org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
>>        at=20
>>org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyIn
>>putFormat.java:47)
>>        at=20
>>org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:133)
>>        at=20
>>org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:107)
>>        at=20
>>org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69)
>>        at=20
>>org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>>        at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
>>        at=20
>>org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>>        at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
>>        at=20
>>org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>>        at org.apache.spark.rdd.FilteredRDD.compute(FilteredRDD.scala:34)
>>        at=20
>>org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
>>        at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
>>        at=20
>>org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
>>        at org.apache.spark.scheduler.Task.run(Task.scala:56)
>>        at=20
>>org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
>>        at=20
>>java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java
>>:1145)
>>        at=20
>>java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.jav
>>a:615)
>>        at java.lang.Thread.run(Thread.java:745)
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11712-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 20 22:59:53 2015
Return-Path: <dev-return-11712-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3F4C9105AD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 20 Feb 2015 22:59:53 +0000 (UTC)
Received: (qmail 28124 invoked by uid 500); 20 Feb 2015 22:59:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28060 invoked by uid 500); 20 Feb 2015 22:59:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28042 invoked by uid 99); 20 Feb 2015 22:59:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 22:59:51 +0000
X-ASF-Spam-Status: No, hits=3.2 required=10.0
	tests=FORGED_YAHOO_RCVD,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tgraves_cs@yahoo.com designates 98.138.121.96 as permitted sender)
Received: from [98.138.121.96] (HELO nm47-vm0.bullet.mail.ne1.yahoo.com) (98.138.121.96)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 20 Feb 2015 22:59:22 +0000
Received: from [127.0.0.1] by nm47.bullet.mail.ne1.yahoo.com with NNFMP; 20 Feb 2015 22:59:20 -0000
Received: from [98.138.100.117] by nm47.bullet.mail.ne1.yahoo.com with NNFMP; 20 Feb 2015 22:56:27 -0000
Received: from [98.139.214.32] by tm108.bullet.mail.ne1.yahoo.com with NNFMP; 20 Feb 2015 22:56:27 -0000
Received: from [98.139.212.251] by tm15.bullet.mail.bf1.yahoo.com with NNFMP; 20 Feb 2015 22:56:27 -0000
Received: from [127.0.0.1] by omp1060.mail.bf1.yahoo.com with NNFMP; 20 Feb 2015 22:56:27 -0000
X-Yahoo-Newman-Property: ymail-4
X-Yahoo-Newman-Id: 412285.96032.bm@omp1060.mail.bf1.yahoo.com
X-YMail-OSG: .i9GR1oVM1nUH0PkICp4SFCx37i1k2cdPsD.L.L18ZnFXc3nUj7AKUD0_q5HR57
 ALGy.SHeM2QaOV7.roaTUyu7IQwejeNNtfXpUJa6Vbg1qMjPwqz6jZ_KRUI0ChlZM8wuE4s0vGpz
 IBa7au4jkYBnQ6QeO9s25GJw8kSmSCMLYzaNCOjlZkukUpr4slDZ95Jfy1v2IWf8_j4QvAbz6Hvw
 .CE7sSVA.UY3mDUcpGjbGbUbMIGvKdT1TZA0N0_OWUq3ZcgGt0F1m42KXKXpEpYi0qIjZY8xWbkt
 pMHbo7QFYiZsSpdV_.L16BwpMVtvRTB4aBifQjfJp75wK1PG2F0cAZ1edL.vGVt_2.ddZYZ3FD.h
 hi3x989VS47_uPyrxAOSEx1TBt__DLwAycomm5r8xYu0TkFt1mBapP_tUZq0rxBoQytTyAvonh7e
 UJ9WLKdZBw82s_1.pMUDitvqeigcqj.x5nAkDaCLmKrmsjkkBFP2laV.Rt80UzgvuZ20ReQHV2Pj
 .PGd5aoiq5v3I9sDbZr_8ytMf0hjDyAAmOsCl_HsWBhFP2X7YkZgFDuYfUfJngWJsQQ3OdD1aamy
 irCkhfUX_.hwC
Received: by 76.13.27.69; Fri, 20 Feb 2015 22:56:26 +0000 
Date: Fri, 20 Feb 2015 22:56:26 +0000 (UTC)
From: Tom Graves <tgraves_cs@yahoo.com.INVALID>
Reply-To: Tom Graves <tgraves_cs@yahoo.com>
To: Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Message-ID: <795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
In-Reply-To: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_5389953_481522663.1424472986316"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_5389953_481522663.1424472986316
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Trying to run pyspark on yarn in client mode with basic wordcount example I=
 see the following error when doing the collect:
Error from python worker:=C2=A0 /usr/bin/python: No module named sqlPYTHONP=
ATH was:=C2=A0 /grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-=
assembly-1.3.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException=C2=A0 =C2=
=A0 =C2=A0 =C2=A0 at java.io.DataInputStream.readInt(DataInputStream.java:3=
92)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.api.python.PythonWorkerF=
actory.startDaemon(PythonWorkerFactory.scala:163)=C2=A0 =C2=A0 =C2=A0 =C2=
=A0 at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(=
PythonWorkerFactory.scala:86)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spar=
k.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)=C2=A0=
 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.SparkEnv.createPythonWorker(Spark=
Env.scala:105)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.api.python.Py=
thonRDD.compute(PythonRDD.scala:69)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apach=
e.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)=C2=A0 =C2=A0 =C2=A0 =
=C2=A0 at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)=C2=A0 =C2=A0 =C2=
=A0 =C2=A0 at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.sca=
la:308)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.rdd.RDD.computeOrRea=
dCheckpoint(RDD.scala:277)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.r=
dd.RDD.iterator(RDD.scala:244)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spa=
rk.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)=C2=A0 =C2=A0 =
=C2=A0 =C2=A0 at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleM=
apTask.scala:41)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.scheduler.T=
ask.run(Task.scala:64)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at org.apache.spark.execu=
tor.Executor$TaskRunner.run(Executor.scala:197)=C2=A0 =C2=A0 =C2=A0 =C2=A0 =
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.jav=
a:1145)=C2=A0 =C2=A0 =C2=A0 =C2=A0 at java.util.concurrent.ThreadPoolExecut=
or$Worker.run(ThreadPoolExecutor.java:615)=C2=A0 =C2=A0 =C2=A0 =C2=A0=C2=A0=
at java.lang.Thread.run(Thread.java:722)
any ideas on this?
Tom=20

     On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <pwendell@gma=
il.com> wrote:
  =20

 Please vote on releasing the following candidate as Apache Spark version 1=
.3.0!

The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Df97b0d=
4a6b26504916816d7aefcf3132cd1da6c2

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc1/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1069/

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/

Please vote on releasing this package as Apache Spark 1.3.0!

The vote is open until Saturday, February 21, at 08:03 UTC and passes
if a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.3.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

=3D=3D How can I help test this release? =3D=3D
If you are a Spark user, you can help us test this release by
taking a Spark 1.2 workload and running on this release candidate,
then reporting any regressions.

=3D=3D What justifies a -1 vote for this release? =3D=3D
This vote is happening towards the end of the 1.3 QA period,
so -1 votes should only occur for significant regressions from 1.2.1.
Bugs already present in 1.2.X, minor regressions, or bugs related
to new features will not block this release.

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org



   
------=_Part_5389953_481522663.1424472986316--

From dev-return-11713-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 21 16:13:41 2015
Return-Path: <dev-return-11713-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F09717DDE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 21 Feb 2015 16:13:41 +0000 (UTC)
Received: (qmail 46948 invoked by uid 500); 21 Feb 2015 16:13:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46869 invoked by uid 500); 21 Feb 2015 16:13:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46857 invoked by uid 99); 21 Feb 2015 16:13:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:13:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of magellanea@gmail.com designates 209.85.213.173 as permitted sender)
Received: from [209.85.213.173] (HELO mail-ig0-f173.google.com) (209.85.213.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:13:14 +0000
Received: by mail-ig0-f173.google.com with SMTP id a13so9653595igq.0
        for <dev@spark.apache.org>; Sat, 21 Feb 2015 08:13:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=D06wUSszdlxCmPEl+vmTVg/wfALDE0hQeGgO2GGZw7g=;
        b=aEg6rK0+WZIk4QM7QaE16hHvTHfegvq6wqikwAWRn1a/B2wiDpue/i9DpCaU4Pw8OQ
         txYEp8EMUB9/deKHhfdBNR7cD4J+dNZWFmc+xivIDyD00DL55KQ2QzJwG8aCOggmn4kM
         nbJh7DNNgwxk8QHo4EQPyYJTejhkaCBVwRLTvZb88aeEtZthOxnAjSGI/yRYJMKjvmof
         tox3LnnVJNt0/3obHA4jh1VbdAfbYySUlefHxyRZpj/t9K5PLYxFboRldazPxN9+7FGR
         7jll+F+P/105BKNxQdyow9WKqw9xACNNeSKurafk1DqtsiZrn0fF3grRvvjTZx3JJ94h
         IJnw==
MIME-Version: 1.0
X-Received: by 10.50.60.72 with SMTP id f8mr3310143igr.31.1424535192602; Sat,
 21 Feb 2015 08:13:12 -0800 (PST)
Received: by 10.64.93.34 with HTTP; Sat, 21 Feb 2015 08:13:12 -0800 (PST)
Date: Sat, 21 Feb 2015 18:13:12 +0200
Message-ID: <CA+scMmua7vPHTU3S-Q7hTDz_Puaoi8zkcGyzPytt02Cw7HqwsQ@mail.gmail.com>
Subject: GSOC2015
From: magellane a <magellanea@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7b10d0e3200e92050f9b7258
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10d0e3200e92050f9b7258
Content-Type: text/plain; charset=UTF-8

Hi
Since we're approaching the GSOC2015 application process I have some
questions:

1) Will your organization be a part of GSOC2015 and what are the projects
that you will be interested in?
2) Since I'm not a contributor to apache spark, what are some starter tasks
I can work on to gain facility with the code base?

Thanks a lot

Regards,

--047d7b10d0e3200e92050f9b7258--

From dev-return-11714-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 21 16:33:15 2015
Return-Path: <dev-return-11714-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4088C17E41
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 21 Feb 2015 16:33:15 +0000 (UTC)
Received: (qmail 79007 invoked by uid 500); 21 Feb 2015 16:33:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78922 invoked by uid 500); 21 Feb 2015 16:33:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78901 invoked by uid 99); 21 Feb 2015 16:33:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:33:13 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:32:49 +0000
Received: by mail-ob0-f179.google.com with SMTP id wp4so29689683obc.10
        for <dev@spark.apache.org>; Sat, 21 Feb 2015 08:32:47 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=musoivYO+cXNP4mz//pmyMEUhABIXtWAvVjK4FANmvQ=;
        b=0wljub/mQFbx5/y71DvaVrjdj0s5Mu9wsmP/YKGD38dX5wLkeFyjy3TCR89o9PhjiW
         3xm61KBAYqdYvmaQMKiLZ8MeuDehqhXwov2b2VkzUh6w3fkWXGU/leuuBIcGAfa6P5rL
         tnLgPvOfQo/pap2XCFGaFLzc2j1hXbzBNfKLrrJkjc0BZb693CkCwNJCTi1QZL/UDApu
         WqXuBXkCDV7qpiSM3Z/t46arIfchSht4pDrQlRQWsmiq1nPiTpTqxXtLwjozp5esBv/L
         JOSS0VCevpeG8/vJgWmlPDQglIw4T3Q3WLsNS2ZLbWuY+uv1YGz3nG2uVjoZMTqLGxmW
         Hf4Q==
MIME-Version: 1.0
X-Received: by 10.202.219.215 with SMTP id s206mr1978940oig.114.1424536367786;
 Sat, 21 Feb 2015 08:32:47 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Sat, 21 Feb 2015 08:32:47 -0800 (PST)
In-Reply-To: <CA+scMmua7vPHTU3S-Q7hTDz_Puaoi8zkcGyzPytt02Cw7HqwsQ@mail.gmail.com>
References: <CA+scMmua7vPHTU3S-Q7hTDz_Puaoi8zkcGyzPytt02Cw7HqwsQ@mail.gmail.com>
Date: Sat, 21 Feb 2015 22:02:47 +0530
Message-ID: <CAFQAd-mWKP32AJZ7eh0Qt3UhfOWmTNWsMRJuxOiwiCxTVeYd4A@mail.gmail.com>
Subject: Re: GSOC2015
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: magellane a <magellanea@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d4a982bf2ca050f9bb85f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d4a982bf2ca050f9bb85f
Content-Type: text/plain; charset=UTF-8

Hi,

For the starters task you can filter by Documentation and "Priority-Minor"
and "Priority-Trivial" over here, since those are most probably the easiest
things to fix, https://issues.apache.org/jira/browse/SPARK/ . You can also
filter based on your expertise, i.e MLlib (for Machine Learning), SparkSQL
or GraphX.

HTH



-- 
Godspeed,
Manoj Kumar,
http://manojbits.wordpress.com
<http://goog_1017110195>
http://github.com/MechCoder

--001a113d4a982bf2ca050f9bb85f--

From dev-return-11715-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 21 16:56:46 2015
Return-Path: <dev-return-11715-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8279B17ECA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 21 Feb 2015 16:56:46 +0000 (UTC)
Received: (qmail 5272 invoked by uid 500); 21 Feb 2015 16:56:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5196 invoked by uid 500); 21 Feb 2015 16:56:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5180 invoked by uid 99); 21 Feb 2015 16:56:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:56:45 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of nitin2goyal@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 16:56:39 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 89D5F149578F
	for <dev@spark.apache.org>; Sat, 21 Feb 2015 08:55:51 -0800 (PST)
Date: Sat, 21 Feb 2015 09:55:49 -0700 (MST)
From: nitin <nitin2goyal@gmail.com>
To: dev@spark.apache.org
Message-ID: <1424537749478-10717.post@n3.nabble.com>
Subject: Spark SQL - Long running job
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi All,

I intend to build a long running spark application which fetches data/tuples
from parquet, does some processing(time consuming) and then cache the
processed table (InMemoryColumnarTableScan). My use case is good retrieval
time for SQL query(benefits of Spark SQL optimizer) and data
compression(in-built in in-memory caching). Now the problem is that if my
driver goes down, I will have to fetch the data again for all the tables and
compute it and cache which is time consuming.

Is it possible to persist processed/cached RDDs on disk such that my system
up time is less when restarted after failure/going down?

On a side note, the data processing contains a shuffle step which creates
huge temporary shuffle files on local disk in temp folder and as per current
logic, shuffle files don't get deleted for running executors. This is
leading to my local disk getting filled up quickly and going out of space as
its a long running spark job. (running spark in yarn-client mode btw).

Thanks
-Nitin 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-Long-running-job-tp10717.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11716-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 21 19:24:57 2015
Return-Path: <dev-return-11716-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F006D101D8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 21 Feb 2015 19:24:56 +0000 (UTC)
Received: (qmail 42671 invoked by uid 500); 21 Feb 2015 19:24:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42596 invoked by uid 500); 21 Feb 2015 19:24:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42574 invoked by uid 99); 21 Feb 2015 19:24:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 19:24:55 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.218.50 as permitted sender)
Received: from [209.85.218.50] (HELO mail-oi0-f50.google.com) (209.85.218.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 21 Feb 2015 19:24:51 +0000
Received: by mail-oi0-f50.google.com with SMTP id v1so7835836oia.9
        for <dev@spark.apache.org>; Sat, 21 Feb 2015 11:24:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=2lgfy+SE6v/VGILNH5tSCp++9T5p96Hks4GI+MEK32c=;
        b=PWDnT9m9B7YH0mJvlTiohu6WgONXs6/+f7JN12hVjQIsGgrGr1Q2d8w1taaCdgEyA6
         kU/gQ+w7ZFpwTdAkL3AeDkqpDn5zFjaMGC2Qi9+n7l5YCcDEl95SMUflkyg7CBvtsvnB
         OTNe5wZ7MSDk1PqF45E1Tbwrt8gEtcjsQZT2VHhmaSN8WbqBl/m6hwXlR/EuYIvxY5DD
         d4IJhzA0GwgL58zJIzEMOfOorDNktw0uy6WqF/JSCslSRsBPR2ZbfdqlXCcaoPRYhZdC
         rZrua+gn6tEo/NrPBzQ7KLJzp0SAjC37TMJeJTmkbT0gqaxnQPW7ffOsaO+lW2SyEV/s
         syJA==
MIME-Version: 1.0
X-Received: by 10.202.108.137 with SMTP id h131mr2377055oic.90.1424546670762;
 Sat, 21 Feb 2015 11:24:30 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Sat, 21 Feb 2015 11:24:30 -0800 (PST)
Date: Sun, 22 Feb 2015 00:54:30 +0530
Message-ID: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
Subject: Google Summer of Code - ideas
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1142d8cc46e030050f9e1e99
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1142d8cc46e030050f9e1e99
Content-Type: text/plain; charset=UTF-8

Hello,

I've been working on the Spark codebase for quite some time right now,
especially on issues related to MLlib and a very small amount of PySpark
and SparkSQL (https://github.com/apache/spark/pulls/MechCoder) .

I would like to extend my work with Spark as a Google Summer of Code
project.
I want to know if there are specific projects related to MLlib that people
would like to see. (I notice, there is no idea page for GSoC yet). There
are a number of issues related to DecisionTrees, Ensembles, LDA (in the
issue tracker) that I find really interesting that could probably club into
a project, but if the spark community has anything else in mind, I could
work on the other issues pre-GSoC and try out something new during GSoC.

Looking forward!
-- 
Godspeed,
Manoj Kumar,
http://manojbits.wordpress.com
<http://goog_1017110195>
http://github.com/MechCoder

--001a1142d8cc46e030050f9e1e99--

From dev-return-11717-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 22 07:55:29 2015
Return-Path: <dev-return-11717-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 05B1310C67
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Feb 2015 07:55:28 +0000 (UTC)
Received: (qmail 71823 invoked by uid 500); 22 Feb 2015 07:55:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71751 invoked by uid 500); 22 Feb 2015 07:55:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71739 invoked by uid 99); 22 Feb 2015 07:55:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 07:55:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 07:55:01 +0000
Received: by mail-ig0-f177.google.com with SMTP id z20so11979958igj.4
        for <dev@spark.apache.org>; Sat, 21 Feb 2015 23:54:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=q9SlhlsMe6KkSYh5PIRfyTK8zu5JPKzUsw7x6iaudv8=;
        b=idj8bSaQIP3x2DFPkdDOSVE8BRnx2UD7uEzWYOulOpeYUDjCmtmPguvcena6yP9DdQ
         4DEgs2Aq+UlGjePP8KxTcglsD7SROY0lqQBvGUrrhzCGAMzHDfAcy55Qw0gYaYzLa38o
         XuPu7N+Zfy4knXZ6xJ6pvkGm/h4ZsKGcgNTmlH17sQc4lwDkMSMAoNrxq3goyhxPdwMP
         ry93uqnLoKHi4xZCsM+52GgtwTnw21hgtUr7s3CNRc7DAjf7p7dzEzMpx4PIuz8f30V8
         H+P5YCuUiOuOI3AdQwLSRt/aOoOJ/JIc+6Vs4yQmH4vWliMcvT2MfXUuFW7bFXuIBILR
         vkEA==
X-Received: by 10.42.44.199 with SMTP id c7mr6188554icf.0.1424591654509; Sat,
 21 Feb 2015 23:54:14 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
 <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
 <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
 <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
 <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
 <CABPQxstsv+3ZjVzx+obeACw5pspwERmzV6RjM1ZsBs-m5g9bBg@mail.gmail.com> <CAOhmDzcVsF4K+V6fs8Z1HcbqbkyNz+6XaEyR8mEOZdDV-P+wEA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 22 Feb 2015 07:54:13 +0000
Message-ID: <CAOhmDzcoMGZ5QEO51=PLUWpaFB8UrYhHwZjMObsotPzimBN2ig@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Patrick Wendell <pwendell@gmail.com>
Cc: Sandy Ryza <sandy.ryza@cloudera.com>, Sean Owen <sowen@cloudera.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec519682d8461da050fa897b1
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec519682d8461da050fa897b1
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

As of right now, there are no more open JIRA issues without an assigned
component
<https://issues.apache.org/jira/issues/?jql=3Dproject%20%3D%20SPARK%20AND%2=
0resolution%20%3D%20Unresolved%20AND%20component%20%3D%20EMPTY%20ORDER%20BY=
%20updated%20DESC>!
Hurray!

[image: yay]

Thanks to Sean and others for the cleanup!

Nick

On Sat Feb 07 2015 at 8:29:42 PM Nicholas Chammas nicholas.chammas@gmail.co=
m
<http://mailto:nicholas.chammas@gmail.com> wrote:

Oh derp, missed the YARN component.
>
> JIRA, does allow admins to make fields mandatory:
> https://confluence.atlassian.com/display/JIRA/Specifying+Field+Behavior#S=
pecifyingFieldBehavior-Makingafieldrequiredoroptional
>
> Nick
>
> On Sat Feb 07 2015 at 5:23:10 PM Patrick Wendell <pwendell@gmail.com>
> wrote:
>
>> I think we already have a YARN component.
>>
>> https://issues.apache.org/jira/issues/?jql=3Dproject%20%3D%
>> 20SPARK%20AND%20component%20%3D%20YARN
>>
>> I don't think JIRA allows it to be mandatory, but if it does, that
>> would be useful.
>>
>> On Sat, Feb 7, 2015 at 5:08 PM, Nicholas Chammas
>> <nicholas.chammas@gmail.com> wrote:
>> > By the way, isn't it possible to make the "Component" field mandatory
>> when
>> > people open new issues? Shouldn't we do that?
>> >
>> > Btw Patrick, don't we need a YARN component? I think our JIRA componen=
ts
>> > should roughly match the components on the PR dashboard.
>> >
>> > Nick
>> >
>> > On Fri Feb 06 2015 at 12:25:52 PM Patrick Wendell <pwendell@gmail.com>
>> > wrote:
>> >>
>> >> Per Nick's suggestion I added two components:
>> >>
>> >> 1. Spark Submit
>> >> 2. Spark Scheduler
>> >>
>> >> I figured I would just add these since if we decide later we don't
>> >> want them, we can simply merge them into Spark Core.
>> >>
>> >> On Fri, Feb 6, 2015 at 11:53 AM, Nicholas Chammas
>> >> <nicholas.chammas@gmail.com> wrote:
>> >> > Do we need some new components to be added to the JIRA project?
>> >> >
>> >> > Like:
>> >> >
>> >> >    -
>> >> >
>> >> >    scheduler
>> >> >     -
>> >> >
>> >> >    YARN
>> >> >     - spark-submit
>> >> >    - ...?
>> >> >
>> >> > Nick
>> >> >
>> >> >
>> >> > On Fri Feb 06 2015 at 10:50:41 AM Nicholas Chammas <
>> >> > nicholas.chammas@gmail.com> wrote:
>> >> >
>> >> >> +9000 on cleaning up JIRA.
>> >> >>
>> >> >> Thank you Sean for laying out some specific things to tackle. I wi=
ll
>> >> >> assist with this.
>> >> >>
>> >> >> Regarding email, I think Sandy is right. I only get JIRA email for
>> >> >> issues
>> >> >> I'm watching.
>> >> >>
>> >> >> Nick
>> >> >>
>> >> >> On Fri Feb 06 2015 at 9:52:58 AM Sandy Ryza <
>> sandy.ryza@cloudera.com>
>> >> >> wrote:
>> >> >>
>> >> >>> JIRA updates don't go to this list, they go to
>> >> >>> issues@spark.apache.org.
>> >> >>> I
>> >> >>> don't think many are signed up for that list, and those that are
>> >> >>> probably
>> >> >>> have a flood of emails anyway.
>> >> >>>
>> >> >>> So I'd definitely be in favor of any JIRA cleanup that you're up
>> for.
>> >> >>>
>> >> >>> -Sandy
>> >> >>>
>> >> >>> On Fri, Feb 6, 2015 at 6:45 AM, Sean Owen <sowen@cloudera.com>
>> wrote:
>> >> >>>
>> >> >>> > I've wasted no time in wielding the commit bit to complete a
>> number
>> >> >>> > of
>> >> >>> > small, uncontroversial changes. I wouldn't commit anything that
>> >> >>> > didn't
>> >> >>> > already appear to have review, consensus and little risk, but
>> please
>> >> >>> > let me know if anything looked a little too bold, so I can
>> >> >>> > calibrate.
>> >> >>> >
>> >> >>> >
>> >> >>> > Anyway, I'd like to continue some small house-cleaning by
>> improving
>> >> >>> > the state of JIRA's metadata, in order to let it give us a litt=
le
>> >> >>> > clearer view on what's happening in the project:
>> >> >>> >
>> >> >>> > a. Add Component to every (open) issue that's missing one
>> >> >>> > b. Review all Critical / Blocker issues to de-escalate ones tha=
t
>> >> >>> > seem
>> >> >>> > obviously neither
>> >> >>> > c. Correct open issues that list a Fix version that has already
>> been
>> >> >>> > released
>> >> >>> > d. Close all issues Resolved for a release that has already bee=
n
>> >> >>> released
>> >> >>> >
>> >> >>> > The problem with doing so is that it will create a tremendous
>> amount
>> >> >>> > of email to the list, like, several hundred. It's possible to
>> make
>> >> >>> > bulk changes and suppress e-mail though, which could be done fo=
r
>> all
>> >> >>> > but b.
>> >> >>> >
>> >> >>> > Better to suppress the emails when making such changes? or just
>> not
>> >> >>> > bother on some of these?
>> >> >>> >
>> >> >>> >
>> >> >>> > ------------------------------------------------------------
>> ---------
>> >> >>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> >>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >> >>> >
>> >> >>> >
>> >> >>>
>> >> >>
>>
> =E2=80=8B

--bcaec519682d8461da050fa897b1--

From dev-return-11718-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 22 08:35:51 2015
Return-Path: <dev-return-11718-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D64CC10CDC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Feb 2015 08:35:51 +0000 (UTC)
Received: (qmail 1319 invoked by uid 500); 22 Feb 2015 08:35:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1232 invoked by uid 500); 22 Feb 2015 08:35:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1220 invoked by uid 99); 22 Feb 2015 08:35:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 08:35:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 08:35:23 +0000
Received: by iecar1 with SMTP id ar1so17155085iec.0
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 00:33:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=ZboLC5pmJr22SOA9UQwQ+RocjJgr12LTlXljSYw3WGk=;
        b=cK0ha5DxpQEPAhyA1Hut4NE2O2T77/0mfIy9UeCQFEyhtH5bx3OZrgKJAXFbHKNMA6
         QL4e2LHYw62Bf8VeKf3mBYOWh4bBc5fGYU2ihSqAaZNDCkNoETQrQ5fJ793tIxY+/MG2
         V5NoVA/T3xA7ba/Ei+3EMIftebvfVcCwvbYzRcIJaE7G26JqsYS9KBmzUP27QeAcGCYG
         vdbP68Zp7AGCdRU6E9O/Md3Ts9vZQxCtAo/xUyo+C3fNX+mwNfat93vIiIE1zoMlshKU
         2oIvFmh+fl53LFWb+MW70IkGLZxzQMRl2zdV2cPOkwYNmchL6WvpCpNhYSB6UtAVi6pi
         Vtug==
X-Received: by 10.43.54.4 with SMTP id vs4mr5894198icb.72.1424594031033; Sun,
 22 Feb 2015 00:33:51 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 22 Feb 2015 08:33:50 +0000
Message-ID: <CAOhmDzew0mbRXD40A0o+iH0TRL7NbZivANXgeRywCAZXqRML+w@mail.gmail.com>
Subject: Git Achievements
To: Spark dev list <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51b1c192b42aa050fa92519
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51b1c192b42aa050fa92519
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

For fun:

http://acha-acha.co/#/repo/https://github.com/apache/spark

I just added Spark to this site. Some of these =E2=80=9Cachievements=E2=80=
=9D are hilarious.

Leo Tolstoy: More than 10 lines in a commit message

Dangerous Game: Commit after 6PM friday

Nick
=E2=80=8B

--bcaec51b1c192b42aa050fa92519--

From dev-return-11719-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 22 14:43:19 2015
Return-Path: <dev-return-11719-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BBC311736E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Feb 2015 14:43:19 +0000 (UTC)
Received: (qmail 47719 invoked by uid 500); 22 Feb 2015 14:43:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47649 invoked by uid 500); 22 Feb 2015 14:43:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47635 invoked by uid 99); 22 Feb 2015 14:43:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 14:43:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 14:43:13 +0000
Received: by wevm14 with SMTP id m14so13586238wev.8
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 06:42:07 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=7rtJanSTOXlKAICXmHdWKg0yH1aHCJ/jOFluwYZ1PwU=;
        b=F6j/mGfkSyO/YuNe6cFV7vI7dut/d9Mud2+lVQLTxnD4Qxsdwxz3D6WBsGQgUIGER7
         k9iGxzlBG/P13g5ymYsBq5iodU5lRlitFSWh+dlmEdPRN2ueH3dp1bhnqo91934bAHY5
         wq7CDXWRosvEdgVNLhRwp3Sqy+e6bqmFFexssAglWUClcj+HrG5Rms7806/eoyGwkvc2
         II3tXIEb18O9h6RYl9TT/zEI8YjcXuB1UPq1sO8boEFwMKYkExL6Y/MR/5fg2ApHp0QF
         0nc2Lg44hjec/O23gLjVXi1xvleXGf29PV00ahlL2LoHlQ1mxiKKJ5R63pdfyPlp//bZ
         coVw==
X-Gm-Message-State: ALoCoQkVeJSoYX+nX5MyEWX7zaAVTXUR43F6upH9GT/1IureLYAUtuaPes+8UtT4yKltL823QwSe
X-Received: by 10.180.36.174 with SMTP id r14mr12121321wij.93.1424616127684;
 Sun, 22 Feb 2015 06:42:07 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Sun, 22 Feb 2015 06:41:47 -0800 (PST)
In-Reply-To: <CAOhmDzcoMGZ5QEO51=PLUWpaFB8UrYhHwZjMObsotPzimBN2ig@mail.gmail.com>
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
 <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
 <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
 <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
 <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
 <CABPQxstsv+3ZjVzx+obeACw5pspwERmzV6RjM1ZsBs-m5g9bBg@mail.gmail.com>
 <CAOhmDzcVsF4K+V6fs8Z1HcbqbkyNz+6XaEyR8mEOZdDV-P+wEA@mail.gmail.com> <CAOhmDzcoMGZ5QEO51=PLUWpaFB8UrYhHwZjMObsotPzimBN2ig@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Sun, 22 Feb 2015 14:41:47 +0000
Message-ID: <CAMAsSdLk_pAbSb+oRPOk-W6SSwVEuyjRYh9Tos2ApfCriOLAXg@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f50350c3b7cf1050fae4a96
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f50350c3b7cf1050fae4a96
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Open pull request count is down to 254 right now from ~325 several weeks
ago.
Open JIRA count is down slightly to 1262 from a peak over ~1320.
Obviously, in the face of an ever faster and larger stream of contributions=
.

There's a real positive impact of JIRA being a little more meaningful, a
little less backlog to keep looking at, getting commits in slightly faster,
slightly happier contributors, etc.


The virtuous circle can keep going. It'd be great if every contributor
could take a moment to look at his or her open PRs and JIRAs. Example
searches (replace with your user name / name):

https://github.com/apache/spark/pulls/srowen
https://issues.apache.org/jira/issues/?jql=3Dproject%20%3D%20SPARK%20AND%20=
reporter%20%3D%20%22Sean%20Owen%22%20or%20assignee%20%3D%20%22Sean%20Owen%2=
2

For PRs:

- if it appears to be waiting on your action or feedback,
  - push more changes and/or reply to comments, or
  - if it isn't work you can pursue in the immediate future, close the PR

- if it appears to be waiting on others,
  - if it's had feedback and it's unclear whether there's support to commit
as-is,
    - break down or reduce the change to something less controversial
    - close the PR as softly rejected
  - if there's no feedback or plainly waiting for action, ping @them

For JIRAs:

- If it's fixed along the way, or obsolete, resolve as Fixed or NotAProblem

- Do a quick search to see if a similar issue has been filed and is
resolved or has more activity; resolve as Duplicate if so

- Check that fields are assigned reasonably:
  - Meaningful title and description
  - Reasonable type and priority. Not everything is a major bug, and few
are blockers
  - 1+ Component
  - 1+ Affects version
  - Avoid setting target version until it looks like there's momentum to
merge a resolution

- If the JIRA has had no activity in a long time (6+ months), but does not
feel obsolete, try to move it to some resolution:
  - Request feedback, from specific people if desired, to feel out if there
is any other support for the change
  - Add more info, like a specific reproduction for bugs
  - Narrow scope of feature requests to something that contains a few
actionable steps, instead of broad open-ended wishes
  - Work on a fix. In an ideal world people are willing to work to resolve
JIRAs they open, and don't fire-and-forget


If everyone did this, not only would it advance the house-cleaning a bit
more, but I'm sure we'd rediscover some important work and issues that need
attention.


On Sun, Feb 22, 2015 at 7:54 AM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> As of right now, there are no more open JIRA issues without an assigned
> component
> <https://issues.apache.org/jira/issues/?jql=3Dproject%20%3D%20SPARK%20AND=
%20resolution%20%3D%20Unresolved%20AND%20component%20%3D%20EMPTY%20ORDER%20=
BY%20updated%20DESC>!
> Hurray!
>
> [image: yay]
>
> Thanks to Sean and others for the cleanup!
>
> Nick
>
> =E2=80=8B
>

--e89a8f50350c3b7cf1050fae4a96--

From dev-return-11720-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Feb 22 17:11:34 2015
Return-Path: <dev-return-11720-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 13D61175CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 22 Feb 2015 17:11:34 +0000 (UTC)
Received: (qmail 95798 invoked by uid 500); 22 Feb 2015 17:11:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95719 invoked by uid 500); 22 Feb 2015 17:11:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95707 invoked by uid 99); 22 Feb 2015 17:11:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 17:11:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.51 as permitted sender)
Received: from [209.85.213.51] (HELO mail-yh0-f51.google.com) (209.85.213.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 22 Feb 2015 17:11:02 +0000
Received: by yhoa41 with SMTP id a41so7948027yho.9
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 09:09:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=db8ICH3FxfVlHScxLGVKR7ALS64n11Ki6s/kDqUHxEo=;
        b=ZbG72re618BsjH9m4J8RIC8/n7eWxFvmosQAp8H2PTo1+HKaUons0i+lJ0OKpdrvC9
         w7V2LwCRR4rycuPP+eRGQZZ8MkStg7vUG4+NayKiCNOM9giCIrq6dtZj9CWYSCfdTT0f
         EUfw9Sya28Aj7FmytWqjLQxo+iKPLVeI6WymEZmLIZuDAVHg/Ke5ZAal6sRUhWxPfCjS
         kYE12OPhUAst2KTim8b1h+nM9U9QI9CkvQHd4Uye7TR2t3ciVu9qK6R6YS0pbu43F8jC
         sW9duukRGtBR47XhI6ng/ldqxBspeytx3ip2iIx/LnCdsLLwK1zNSk5wSQe8AhKdWgBW
         fQGw==
X-Received: by 10.236.208.36 with SMTP id p24mr6236891yho.1.1424624970800;
 Sun, 22 Feb 2015 09:09:30 -0800 (PST)
MIME-Version: 1.0
References: <CAMAsSdLS4eFeXrRuLCs3ihxV7REetyzFS9TBm65eUK9bNcb-6g@mail.gmail.com>
 <CACBYxKKGhmmJ0sqHHMdL6QQ=XyfBvwmYu_bM+kcEqR4SMwc7dg@mail.gmail.com>
 <CAOhmDzeHTBr6_apsBfvBc9LXou5F4m1MjP4LqfmutqJUz1Et4w@mail.gmail.com>
 <CAOhmDzegJzja4=-R7tqmrKDK9vJzh3C4kkdHqGWzFga1omvxog@mail.gmail.com>
 <CABPQxsuXd6-LVkCeFm1HirzyV8Fh9S6wH7K6CHx+014znPvm-A@mail.gmail.com>
 <CAOhmDzeru45tt9Kq_=oJadyHoVcZt-737USdFG_MAkpC16r=KQ@mail.gmail.com>
 <CABPQxstsv+3ZjVzx+obeACw5pspwERmzV6RjM1ZsBs-m5g9bBg@mail.gmail.com>
 <CAOhmDzcVsF4K+V6fs8Z1HcbqbkyNz+6XaEyR8mEOZdDV-P+wEA@mail.gmail.com>
 <CAOhmDzcoMGZ5QEO51=PLUWpaFB8UrYhHwZjMObsotPzimBN2ig@mail.gmail.com> <CAMAsSdLk_pAbSb+oRPOk-W6SSwVEuyjRYh9Tos2ApfCriOLAXg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 22 Feb 2015 17:09:28 +0000
Message-ID: <CAOhmDzc=h=izePCk=bKD1mimZQ581m8h0H5qPXwY6jowMM9m-g@mail.gmail.com>
Subject: Re: Improving metadata in Spark JIRA
To: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1c2ac52bece050fb05969
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1c2ac52bece050fb05969
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Open pull request count is down to 254 right now from ~325 several weeks
ago.

This great. Ideally, we need to get this down to < 50 and keep it there.
Having so many open pull requests is just a bad signal to contributors. But
it will take some time to get there.


   - 1+ Component

 Sean, do you have permission to edit our JIRA settings? It should be
possible to enforce this in JIRA itself.


   - 1+ Affects version

 I don=E2=80=99t think this field makes sense for improvements, right?

Nick
=E2=80=8B

On Sun Feb 22 2015 at 9:43:24 AM Sean Owen <sowen@cloudera.com> wrote:

> Open pull request count is down to 254 right now from ~325 several weeks
> ago.
> Open JIRA count is down slightly to 1262 from a peak over ~1320.
> Obviously, in the face of an ever faster and larger stream of
> contributions.
>
> There's a real positive impact of JIRA being a little more meaningful, a
> little less backlog to keep looking at, getting commits in slightly faste=
r,
> slightly happier contributors, etc.
>
>
> The virtuous circle can keep going. It'd be great if every contributor
> could take a moment to look at his or her open PRs and JIRAs. Example
> searches (replace with your user name / name):
>
> https://github.com/apache/spark/pulls/srowen
> https://issues.apache.org/jira/issues/?jql=3Dproject%20%
> 3D%20SPARK%20AND%20reporter%20%3D%20%22Sean%20Owen%22%
> 20or%20assignee%20%3D%20%22Sean%20Owen%22
>
> For PRs:
>
> - if it appears to be waiting on your action or feedback,
>   - push more changes and/or reply to comments, or
>   - if it isn't work you can pursue in the immediate future, close the PR
>
> - if it appears to be waiting on others,
>   - if it's had feedback and it's unclear whether there's support to comm=
it
> as-is,
>     - break down or reduce the change to something less controversial
>     - close the PR as softly rejected
>   - if there's no feedback or plainly waiting for action, ping @them
>
> For JIRAs:
>
> - If it's fixed along the way, or obsolete, resolve as Fixed or NotAProbl=
em
>
> - Do a quick search to see if a similar issue has been filed and is
> resolved or has more activity; resolve as Duplicate if so
>
> - Check that fields are assigned reasonably:
>   - Meaningful title and description
>   - Reasonable type and priority. Not everything is a major bug, and few
> are blockers
>   - 1+ Component
>   - 1+ Affects version
>   - Avoid setting target version until it looks like there's momentum to
> merge a resolution
>
> - If the JIRA has had no activity in a long time (6+ months), but does no=
t
> feel obsolete, try to move it to some resolution:
>   - Request feedback, from specific people if desired, to feel out if the=
re
> is any other support for the change
>   - Add more info, like a specific reproduction for bugs
>   - Narrow scope of feature requests to something that contains a few
> actionable steps, instead of broad open-ended wishes
>   - Work on a fix. In an ideal world people are willing to work to resolv=
e
> JIRAs they open, and don't fire-and-forget
>
>
> If everyone did this, not only would it advance the house-cleaning a bit
> more, but I'm sure we'd rediscover some important work and issues that ne=
ed
> attention.
>
>
> On Sun, Feb 22, 2015 at 7:54 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
> > As of right now, there are no more open JIRA issues without an assigned
> > component
> > <https://issues.apache.org/jira/issues/?jql=3Dproject%20%
> 3D%20SPARK%20AND%20resolution%20%3D%20Unresolved%20AND%
> 20component%20%3D%20EMPTY%20ORDER%20BY%20updated%20DESC>!
> > Hurray!
> >
> > [image: yay]
> >
> > Thanks to Sean and others for the cleanup!
> >
> > Nick
> >
> > =E2=80=8B
> >
>

--001a11c1c2ac52bece050fb05969--

From dev-return-11721-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 02:09:01 2015
Return-Path: <dev-return-11721-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7C077172DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 02:09:01 +0000 (UTC)
Received: (qmail 44242 invoked by uid 500); 23 Feb 2015 02:09:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44173 invoked by uid 500); 23 Feb 2015 02:09:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44146 invoked by uid 99); 23 Feb 2015 02:09:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:08:59 +0000
X-ASF-Spam-Status: No, hits=1.0 required=10.0
	tests=FORGED_YAHOO_RCVD,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of michaelmalak@yahoo.com designates 98.139.212.154 as permitted sender)
Received: from [98.139.212.154] (HELO nm3-vm0.bullet.mail.bf1.yahoo.com) (98.139.212.154)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:08:52 +0000
Received: from [98.139.215.143] by nm3.bullet.mail.bf1.yahoo.com with NNFMP; 23 Feb 2015 02:05:22 -0000
Received: from [98.139.212.240] by tm14.bullet.mail.bf1.yahoo.com with NNFMP; 23 Feb 2015 02:05:22 -0000
Received: from [127.0.0.1] by omp1049.mail.bf1.yahoo.com with NNFMP; 23 Feb 2015 02:05:21 -0000
X-Yahoo-Newman-Property: ymail-3
X-Yahoo-Newman-Id: 998821.11974.bm@omp1049.mail.bf1.yahoo.com
X-YMail-OSG: nTgWId8VM1m.X9HrUNRexbRywngJ0Gx.CnORxKFTxBBvYgEOKHTpSlSNGsxEZRX
 gfhV6xpPCLvLNXzmgh_53.c7wubGwbhgvUTijiCOhPzHPS6uRJwJtHYVRC4bDMiKMrxSTA2DYfap
 unMEJe0T7o3E9Fj4e3PT5WwoAvmOZZuaD5iKWK59VKMqhqeGdUZUfl_qriHwspy9gD8MS6spQCZ3
 Tb7KcSqoLD5cXJV4wKstYo2PAFEMaxP6tHxctJLQquvNTdVWttTZM1gWiW2d_D1z1Tmh3mLt23X9
 Vaa1.l1lde3KyH5oXM3uNaPhgyhx8k4F9rEPBRVrNXv6sG2aIHi0GzC04ICjpi8YFnXEoDpZzh0B
 8botT54Fp.zcR260BpjQ_8gdB5hyldQ4ssFEj31Gr6Ltq7m0Y3eyp9b5Vtu7hMtXO.XGiyBIYdU4
 ZJJAYKAtkcDsRl3cgpZjopwWl.RKuJXZaLs6TeEAtxucS4DnhgCCAZxkAx8l2U.B2LgijDN3kYwW
 Xkwz94cWehM_Fjwhlpm7mVi98dcv4LBhsN.V8hcFSJCiQS7OK64vyMym6SGMPP2jj2SxFBsB_kHL
 nbkLhMvf3gDd.qCeVlIZdmznyIWZ.ESp8pQ--
Received: by 76.13.26.64; Mon, 23 Feb 2015 02:05:21 +0000 
Date: Mon, 23 Feb 2015 02:04:48 +0000 (UTC)
From: Michael Malak <michaelmalak@yahoo.com.INVALID>
Reply-To: Michael Malak <michaelmalak@yahoo.com>
To: Dev <dev@spark.apache.org>
Message-ID: <1638142323.7230292.1424657088722.JavaMail.yahoo@mail.yahoo.com>
Subject: textFile() ordering and header rows
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Since RDDs are generally unordered, aren't things like textFile().first() not guaranteed to return the first row (such as looking for a header row)? If so, doesn't that make the example in 
http://spark.apache.org/docs/1.2.1/quick-start.html#basics misleading?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11722-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 02:16:03 2015
Return-Path: <dev-return-11722-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AE17B172EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 02:16:03 +0000 (UTC)
Received: (qmail 51726 invoked by uid 500); 23 Feb 2015 02:16:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51641 invoked by uid 500); 23 Feb 2015 02:16:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51629 invoked by uid 99); 23 Feb 2015 02:16:02 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:16:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.42 as permitted sender)
Received: from [209.85.213.42] (HELO mail-yh0-f42.google.com) (209.85.213.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:15:57 +0000
Received: by yhai57 with SMTP id i57so8610412yha.12
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 18:14:07 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=sFAMA3dWJWXR0AUJGDQzOC0MKKSXUgPnalyk8DZO+yY=;
        b=aIBIUAdbiugDXWSgSv2c+m0x4KOwu7ZEMUJpy0o+2JL497m/lvs+xF+RcDRMcAqkun
         UYd+O8BnGQW4+QfAhxeHGewvTFNjkg5k6f08zIRbHQVB+3YEAqqR8lccMLj3g+v8c6qC
         NOP04+ZkU4LEGwz5oXPH3pJvc9RA29b1JxAiKntkepq2tByeER/J06H2d+T3FEBE84t1
         UOicBaBrw2VnyOZzQ2CGvQov9IOmtnUtvf7SJU7ADbo9mv9zw6cAsFynw/vnZwt8KK6w
         Np2hhH5XwKy+bd+4FC6ymOLrW7+tJpcMRO5zTW7E94z6IGk1KenY0Cwk8+iQ/KMwbb+i
         I1wg==
X-Received: by 10.236.53.65 with SMTP id f41mr7664667yhc.182.1424657647183;
 Sun, 22 Feb 2015 18:14:07 -0800 (PST)
MIME-Version: 1.0
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 23 Feb 2015 02:14:06 +0000
Message-ID: <CAOhmDzed_QMbKo8qCX1+5A30h8o+6rUbWhATDpxAAWBxV9mdeg@mail.gmail.com>
Subject: Re: textFile() ordering and header rows
To: Michael Malak <michaelmalak@yahoo.com>, Dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0116057afcac1f050fb7f43f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0116057afcac1f050fb7f43f
Content-Type: text/plain; charset=UTF-8

I guess on a technicality the docs just say "first item in this RDD", not
"first line in the source text file". AFAIK there is no way apart from
filtering to remove header lines
<http://stackoverflow.com/a/24734612/877069>.

As long as first() always returns the same value for a given RDD, I think
it's fine, no?

Nick


On Sun Feb 22 2015 at 9:09:01 PM Michael Malak
<michaelmalak@yahoo.com.invalid> wrote:

> Since RDDs are generally unordered, aren't things like textFile().first()
> not guaranteed to return the first row (such as looking for a header row)?
> If so, doesn't that make the example in
> http://spark.apache.org/docs/1.2.1/quick-start.html#basics misleading?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0116057afcac1f050fb7f43f--

From dev-return-11723-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 02:50:10 2015
Return-Path: <dev-return-11723-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D22F21733E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 02:50:10 +0000 (UTC)
Received: (qmail 74575 invoked by uid 500); 23 Feb 2015 02:50:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74500 invoked by uid 500); 23 Feb 2015 02:50:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74489 invoked by uid 99); 23 Feb 2015 02:50:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:50:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 02:50:05 +0000
Received: by mail-ig0-f180.google.com with SMTP id b16so15255793igk.1
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 18:48:38 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=nnK+FCh99Z2JqqTl7wrRchbmVpSatXTED3pppYpE2K0=;
        b=Q49NkYGGIDENXFekkLNmnYuUYtAyWXerjEeTQ7ddsQNOyileYxQQ9QbPf/MPXLY1aM
         ssJBbsjvZzaR5VVz/VU6GE8PFfHTUT1FcpZF26cjmsTkYcYBIQDCwu5Z542MxAa89caK
         t9mD0lPJnvwQK4g3XH2wa/8R7k8zRnxeNGbtCxDKnXcJAqo3xxsPDMeMdtv41TnRMr5p
         CxRtZokZRRzOV9tVfNIebYA2OwjHRuG06Z6O3prYOnKrcRUZKTHC0W8m+fBsr3FaXV/h
         bHjcSiSGMch0t3b/NF6X2GUXGI1BMxdu0IUKwyzoycTNWgmn50LTTT1tsKx/+yvkHl8/
         wifg==
X-Gm-Message-State: ALoCoQkTruK+SOp8NHp/jVsGM2+XxqfJXnFFr9ZF84v60w40w7ig2Z57LM/Zr/i0uxGYauuaDQGg
MIME-Version: 1.0
X-Received: by 10.107.170.220 with SMTP id g89mr10929156ioj.31.1424659718729;
 Sun, 22 Feb 2015 18:48:38 -0800 (PST)
Received: by 10.36.66.15 with HTTP; Sun, 22 Feb 2015 18:48:38 -0800 (PST)
In-Reply-To: <W7142528733208101424372348@atl4webmail15>
References: <W7142528733208101424372348@atl4webmail15>
Date: Sun, 22 Feb 2015 18:48:38 -0800
Message-ID: <CAF7ADNpTL+YuByg3WnYB8VOCVeVk9CYSLL=4D7v-ib=SMD=hrA@mail.gmail.com>
Subject: Re: Have Friedman's glmnet algo running in Spark
From: Joseph Bradley <joseph@databricks.com>
To: mike@mbowles.com
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a114159b87633d8050fb87024
X-Virus-Checked: Checked by ClamAV on apache.org

--001a114159b87633d8050fb87024
Content-Type: text/plain; charset=UTF-8

Hi Mike,

glmnet has definitely been very successful, and it would be great to see
how we can improve optimization in MLlib!  There is some related work
ongoing; here are the JIRAs:

GLMNET implementation in Spark
<https://issues.apache.org/jira/browse/SPARK-1673>

LinearRegression with L1/L2 (elastic net) using OWLQN in new ML package
<https://issues.apache.org/jira/browse/SPARK-5253>

The GLMNET JIRA has actually been closed in favor of the latter JIRA.
However, if you're getting good results in your experiments, could you
please post them on the GLMNET JIRA and link them from the other JIRA?  If
it's faster and more scalable, that would be great to find out.

As far as where the code should go and the APIs, that can be discussed on
the JIRA.

I hope this helps, and I'll keep an eye out for updates on the JIRAs!

Joseph


On Thu, Feb 19, 2015 at 10:59 AM, <mike@mbowles.com> wrote:

> Dev List,
> A couple of colleagues and I have gotten several versions of glmnet algo
> coded and running on Spark RDD. glmnet algo (
> http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm for
> generating coefficient paths solving penalized regression with elastic net
> penalties. The algorithm runs fast by taking an approach that generates
> solutions for a wide variety of penalty parameter. We're able to integrate
> into Mllib class structure a couple of different ways. The algorithm may
> fit better into the new pipeline structure since it naturally returns a
> multitide of models (corresponding to different vales of penalty
> parameters). That appears to fit better into pipeline than Mllib linear
> regression (for example).
>
> We've got regression running with the speed optimizations that Friedman
> recommends. We'll start working on the logistic regression version next.
>
> We're eager to make the code available as open source and would like to
> get some feedback about how best to do that. Any thoughts?
> Mike Bowles.
>
>
>

--001a114159b87633d8050fb87024--

From dev-return-11724-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 03:43:17 2015
Return-Path: <dev-return-11724-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 66D7A173EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 03:43:17 +0000 (UTC)
Received: (qmail 11014 invoked by uid 500); 23 Feb 2015 03:43:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10910 invoked by uid 500); 23 Feb 2015 03:43:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10891 invoked by uid 99); 23 Feb 2015 03:43:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 03:43:15 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 03:42:50 +0000
Received: by padfb1 with SMTP id fb1so24147535pad.8
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 19:42:03 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=vIXGtyJBT02V0zTc/Ijd1byZYYbn7dMTKBv5X6iEqUg=;
        b=OWGdqzqIEfJYXOv+69njdcpOdkt3KlS5UKOM3xJ1yYEoctn3kAYrUF8U14gPvTzYi+
         TXc/qi+6+OJTBUf80pAVGB+RbwfL0xYsp1BSL8DDLfDAbAMgHH3iExLT5wkfby9A3RWX
         jBcZIHRY554fsA56rQMbux/fo19NKfXTx/xOxLrmygLn/ekgxvEx5kLlPHqbBF2GcB4e
         igU9ZfGWwz6w9ueJL4EgFeWnJdK/Mp92TiqNSO9dE9TyC3WCN5la0dLNW38/VxLCw3fA
         pdB2UI4wTXCmFLkeSPp7rGnMEwOKvQsC5oBiK+J2p4zosZtkM0oIesPYjAhaos1khzbw
         zmEA==
X-Received: by 10.68.57.139 with SMTP id i11mr15564070pbq.59.1424662923051;
        Sun, 22 Feb 2015 19:42:03 -0800 (PST)
Received: from [10.10.0.8] ([104.156.239.73])
        by mx.google.com with ESMTPSA id cf12sm8852922pdb.43.2015.02.22.19.42.00
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Sun, 22 Feb 2015 19:42:01 -0800 (PST)
Message-ID: <54EAA187.2050803@gmail.com>
Date: Mon, 23 Feb 2015 11:41:59 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: nitin <nitin2goyal@gmail.com>, dev@spark.apache.org
Subject: Re: Spark SQL - Long running job
References: <1424537749478-10717.post@n3.nabble.com>
In-Reply-To: <1424537749478-10717.post@n3.nabble.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

How about persisting the computed result table first before caching it? 
So that you only need to cache the result table after restarting your 
service without recomputing it. Somewhat like checkpointing.

Cheng

On 2/22/15 12:55 AM, nitin wrote:
> Hi All,
>
> I intend to build a long running spark application which fetches data/tuples
> from parquet, does some processing(time consuming) and then cache the
> processed table (InMemoryColumnarTableScan). My use case is good retrieval
> time for SQL query(benefits of Spark SQL optimizer) and data
> compression(in-built in in-memory caching). Now the problem is that if my
> driver goes down, I will have to fetch the data again for all the tables and
> compute it and cache which is time consuming.
>
> Is it possible to persist processed/cached RDDs on disk such that my system
> up time is less when restarted after failure/going down?
>
> On a side note, the data processing contains a shuffle step which creates
> huge temporary shuffle files on local disk in temp folder and as per current
> logic, shuffle files don't get deleted for running executors. This is
> leading to my local disk getting filled up quickly and going out of space as
> its a long running spark job. (running spark in yarn-client mode btw).
>
> Thanks
> -Nitin
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-Long-running-job-tp10717.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11725-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 05:39:28 2015
Return-Path: <dev-return-11725-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C9C1B17569
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 05:39:28 +0000 (UTC)
Received: (qmail 8997 invoked by uid 500); 23 Feb 2015 05:39:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8920 invoked by uid 500); 23 Feb 2015 05:39:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8909 invoked by uid 99); 23 Feb 2015 05:39:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 05:39:27 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of nitin2goyal@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 05:39:22 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 0663214B2D89
	for <dev@spark.apache.org>; Sun, 22 Feb 2015 21:38:34 -0800 (PST)
Date: Sun, 22 Feb 2015 22:38:30 -0700 (MST)
From: nitin <nitin2goyal@gmail.com>
To: dev@spark.apache.org
Message-ID: <1424669910830-10727.post@n3.nabble.com>
In-Reply-To: <54EAA187.2050803@gmail.com>
References: <1424537749478-10717.post@n3.nabble.com> <54EAA187.2050803@gmail.com>
Subject: Re: Spark SQL - Long running job
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

I believe calling processedSchemaRdd.persist(DISK) and
processedSchemaRdd.checkpoint() only persists data and I will lose all the
RDD metadata and when I re-start my driver, that data is kind of useless for
me (correct me if I am wrong).

I thought of doing processedSchemaRdd.saveAsParquetFile (hdfs file system)
but I fear that in case my "HDFS block size" > "partition file size", I will
get more partitions when reading instead of original schemaRdd. 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-Long-running-job-tp10717p10727.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11726-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 07:20:59 2015
Return-Path: <dev-return-11726-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0F3D31772C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 07:20:59 +0000 (UTC)
Received: (qmail 35798 invoked by uid 500); 23 Feb 2015 07:20:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35710 invoked by uid 500); 23 Feb 2015 07:20:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35699 invoked by uid 99); 23 Feb 2015 07:20:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 07:20:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 209.85.212.170 as permitted sender)
Received: from [209.85.212.170] (HELO mail-wi0-f170.google.com) (209.85.212.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 07:20:52 +0000
Received: by mail-wi0-f170.google.com with SMTP id hi2so17291924wib.1
        for <dev@spark.apache.org>; Sun, 22 Feb 2015 23:20:30 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=whhASaUh8ykaWPxnJBCY8JcOQY+ykPAYXCWPv1JWYas=;
        b=erznjOAxVuKjjfbopQGabfELYc+YTsMBY+GWpgsX7u48k33Vm0pASfDe0EY8WU7t+1
         +RFz73vq45LAv+BAUJwaDGLzQ2nYVw+OjOJH8D50Nz80yxuZAF2KrHiT6FyjEzAfKzWh
         1xJfc4KH2ylEj1bv0gYTxEW4XrGcMwhf6EtX07nvuAwVYVgBKfHR1EjhUcbCY9RwVMJp
         Q4OE3JjxgBIC/xQiJOsCe5sVqZ+tCeAr5w6XDOCxgOGCH65wUoWyuxQdOk1CfJQXxCY2
         IsVkRvuDnJhI2Fz6toX2fDjtWraic0QWCIsXKnyfyv3GyC1EP8bRW2ESGbojJsA1Jf2K
         EbxA==
X-Gm-Message-State: ALoCoQmBcsmizsbpwWh8igskIepnfnS2XfHtSHNllt5PVvlekkaefF+64SllSII3qr0MjZpyM4lR
MIME-Version: 1.0
X-Received: by 10.180.80.230 with SMTP id u6mr17828179wix.69.1424676030621;
 Sun, 22 Feb 2015 23:20:30 -0800 (PST)
Received: by 10.194.153.202 with HTTP; Sun, 22 Feb 2015 23:20:30 -0800 (PST)
In-Reply-To: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
Date: Sun, 22 Feb 2015 23:20:30 -0800
Message-ID: <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Mark Hamstra <mark@clearstorydata.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d04428aceb9c23b050fbc3c23
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04428aceb9c23b050fbc3c23
Content-Type: text/plain; charset=UTF-8

So what are we expecting of Hive 0.12.0 builds with this RC?  I know not
every combination of Hadoop and Hive versions, etc., can be supported, but
even an example build from the "Building Spark" page isn't looking too good
to me.

Working from f97b0d4, the example build command works: mvn -Pyarn
-Phadoop-2.4 -Dhadoop.version=2.4.0 -Phive -Phive-0.12.0
-Phive-thriftserver -DskipTests clean package
...but then running the tests results in multiple failures in the Hive and
Hive Thrift Server sub-projects.


On Wed, Feb 18, 2015 at 12:12 AM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Please vote on releasing the following candidate as Apache Spark version
> 1.3.0!
>
> The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
>
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=f97b0d4a6b26504916816d7aefcf3132cd1da6c2
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1069/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
>
> Please vote on releasing this package as Apache Spark 1.3.0!
>
> The vote is open until Saturday, February 21, at 08:03 UTC and passes
> if a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.3.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> == How can I help test this release? ==
> If you are a Spark user, you can help us test this release by
> taking a Spark 1.2 workload and running on this release candidate,
> then reporting any regressions.
>
> == What justifies a -1 vote for this release? ==
> This vote is happening towards the end of the 1.3 QA period,
> so -1 votes should only occur for significant regressions from 1.2.1.
> Bugs already present in 1.2.X, minor regressions, or bugs related
> to new features will not block this release.
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--f46d04428aceb9c23b050fbc3c23--

From dev-return-11727-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 11:59:47 2015
Return-Path: <dev-return-11727-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BE39417F97
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 11:59:47 +0000 (UTC)
Received: (qmail 32937 invoked by uid 500); 23 Feb 2015 11:59:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32862 invoked by uid 500); 23 Feb 2015 11:59:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32851 invoked by uid 99); 23 Feb 2015 11:59:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 11:59:46 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [212.124.192.207] (HELO vicki.2020media.net.uk) (212.124.192.207)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 11:59:41 +0000
Received: from [86.7.249.6] (helo=[192.168.0.8])
	by vicki.2020media.net.uk with esmtpsa (TLSv1:AES128-SHA:128)
	(Exim 4.72)
	(envelope-from <robin.east@xense.co.uk>)
	id 1YPrfU-0003T3-3i; Mon, 23 Feb 2015 11:59:20 +0000
Content-Type: multipart/alternative; boundary="Apple-Mail=_AE6561C7-3C0F-42FB-87EE-23C8E9F82890"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Robin East <robin.east@xense.co.uk>
In-Reply-To: <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
Date: Mon, 23 Feb 2015 11:59:17 +0000
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Message-Id: <71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com> <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-2020-Relay: Sent using 2020MEDIA.net.uk relay with auth code: xense
 Send Abuse reports to abuse@2020media.net.uk
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_AE6561C7-3C0F-42FB-87EE-23C8E9F82890
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

Running ec2 launch scripts gives me the following error:

ssl.SSLError: [Errno 1] _ssl.c:504: error:14090086:SSL =
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed

Full stack trace at
https://gist.github.com/insidedctm/4d41600bc22560540a26

I=92m running OSX Mavericks 10.9.5

I=92ll investigate further but wondered if anyone else has run into =
this.

Robin=

--Apple-Mail=_AE6561C7-3C0F-42FB-87EE-23C8E9F82890--

From dev-return-11728-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 12:28:42 2015
Return-Path: <dev-return-11728-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 60B8B10058
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 12:28:42 +0000 (UTC)
Received: (qmail 79776 invoked by uid 500); 23 Feb 2015 12:28:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79685 invoked by uid 500); 23 Feb 2015 12:28:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79071 invoked by uid 99); 23 Feb 2015 12:28:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 12:28:39 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.176 as permitted sender)
Received: from [209.85.192.176] (HELO mail-pd0-f176.google.com) (209.85.192.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 12:28:12 +0000
Received: by pdno5 with SMTP id o5so25083075pdn.8
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 04:25:56 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=RZptnidfMQXVNFeHKAxYs1OMK082SegY4ySkD7jS/Dc=;
        b=YdC5HzNjepdb06N2tp7zsNpVmTigRWNVnLAWhZx0cLFVOrqaCfyXJpWaRI5AqT7r7O
         2MBbaVrYizhWbtIefPSqySpEsPLgJx4zVyQ6CgW8zlrNsEal9016EhAi6uCvYxRmeuWt
         RhiciBgMNm4k4OW2oX/yMSybCBcnnSIAXlmZYdWqVQm6lROVQ7DL9TkoP9SypMoZVnph
         VhXJzNLB6I+crvnMdrKP9lwb9X2QRJ9ue+NvRC44fgulmQEMR46oT/cj1tZInJoNVOWu
         dq+xQYxpDPreWxWaxVZKw293ij300VEbHYvnKcbh/OSF6SaH1sc5fWSS10kD/FUCZaV7
         mc4w==
X-Received: by 10.68.57.139 with SMTP id i11mr18574462pbq.59.1424694355947;
        Mon, 23 Feb 2015 04:25:55 -0800 (PST)
Received: from [10.10.0.10] ([104.156.239.73])
        by mx.google.com with ESMTPSA id jj1sm34858064pac.17.2015.02.23.04.25.53
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 23 Feb 2015 04:25:55 -0800 (PST)
Message-ID: <54EB1C51.4090308@gmail.com>
Date: Mon, 23 Feb 2015 20:25:53 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: The Watcher <watcherfr@gmail.com>, dev@spark.apache.org
Subject: Re: Spark SQL, Hive & Parquet data types
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>	<54E73A53.2020100@gmail.com> <CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
In-Reply-To: <CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, recently we improved ParquetRelation2 quite a bit. Spark SQL uses 
its own Parquet support to read partitioned Parquet tables declared in 
Hive metastore. Only writing to partitioned tables is not covered yet. 
These improvements will be included in Spark 1.3.0.

Just created SPARK-5948 to track writing to partitioned Parquet tables.

Cheng

On 2/20/15 10:58 PM, The Watcher wrote:
>>
>>     1. In Spark 1.3.0, timestamp support was added, also Spark SQL uses
>>     its own Parquet support to handle both read path and write path when
>>     dealing with Parquet tables declared in Hive metastore, as long as you’re
>>     not writing to a partitioned table. So yes, you can.
>>
>> Ah, I had missed the part about being partitioned or not. Is this related
> to the work being done on ParquetRelation2 ?
>
> We will indeed write to a partitioned table : do neither the read nor the
> write path go through Spark SQL's parquet support in that case ? Is there a
> JIRA/PR I can monitor to see when this would change ?
>
> Thanks
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11729-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 13:25:42 2015
Return-Path: <dev-return-11729-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6C3FF101DD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 13:25:42 +0000 (UTC)
Received: (qmail 83793 invoked by uid 500); 23 Feb 2015 13:25:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83719 invoked by uid 500); 23 Feb 2015 13:25:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83705 invoked by uid 99); 23 Feb 2015 13:25:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:25:40 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.175 as permitted sender)
Received: from [209.85.192.175] (HELO mail-pd0-f175.google.com) (209.85.192.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:25:14 +0000
Received: by pdjz10 with SMTP id z10so25469960pdj.0
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 05:24:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        bh=fSJEz9hitSzGLOCCZln+VIJP0Yx5Bjjra6RDOxV3Q7Y=;
        b=epxXPKSXWLXfLozacdJpmo231/Jj03ZfTtFEaqtkhKAmX/iYp65jRkTjrBMAgF0c84
         sWtD7VcFGcaMmC8RIQnidM7G4AAWwC6y5xAb/wnA6FIPx3uB9YZ3WpolfSk+cHESKBgx
         uosfOO+M4tHgM6FTwSSqfdx7p4iXYa6u4qIB2U+TDno47IxK8BOMp2tAMMwqzdzS4n/L
         Gaxt/PPlKL6BjNfhwOwnuw562P1nIlZZeHWU2z8sd4JpctrR5uO9XoegO/wl5CupNvz+
         6HXzZ7ZyHP4lB+ST35XI3Srq+SE9UuqbaaziP3Ywv6IcMu9gBU6PVWkn9yDbAloV5a3C
         fpzA==
X-Received: by 10.66.66.105 with SMTP id e9mr19121009pat.17.1424697867976;
        Mon, 23 Feb 2015 05:24:27 -0800 (PST)
Received: from [10.10.0.2] ([103.6.85.244])
        by mx.google.com with ESMTPSA id fm3sm9264586pab.29.2015.02.23.05.24.21
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 23 Feb 2015 05:24:27 -0800 (PST)
Message-ID: <54EB2A08.5070604@gmail.com>
Date: Mon, 23 Feb 2015 21:24:24 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: nitin <nitin2goyal@gmail.com>, dev@spark.apache.org
Subject: Re: Spark SQL - Long running job
References: <1424537749478-10717.post@n3.nabble.com> <54EAA187.2050803@gmail.com> <1424669910830-10727.post@n3.nabble.com>
In-Reply-To: <1424669910830-10727.post@n3.nabble.com>
Content-Type: multipart/alternative;
 boundary="------------030109080408050609000807"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------030109080408050609000807
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit

I meant using |saveAsParquetFile|. As for partition number, you can 
always control it with |spark.sql.shuffle.partitions| property.

Cheng

On 2/23/15 1:38 PM, nitin wrote:

> I believe calling processedSchemaRdd.persist(DISK) and
> processedSchemaRdd.checkpoint() only persists data and I will lose all the
> RDD metadata and when I re-start my driver, that data is kind of useless for
> me (correct me if I am wrong).
>
> I thought of doing processedSchemaRdd.saveAsParquetFile (hdfs file system)
> but I fear that in case my "HDFS block size" > "partition file size", I will
> get more partitions when reading instead of original schemaRdd.
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Spark-SQL-Long-running-job-tp10717p10727.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>
​

--------------030109080408050609000807--

From dev-return-11730-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 13:37:27 2015
Return-Path: <dev-return-11730-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B9F7910222
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 13:37:27 +0000 (UTC)
Received: (qmail 4809 invoked by uid 500); 23 Feb 2015 13:37:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4725 invoked by uid 500); 23 Feb 2015 13:37:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4714 invoked by uid 99); 23 Feb 2015 13:37:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:37:25 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of josh@soundcloud.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:37:01 +0000
Received: by mail-ob0-f179.google.com with SMTP id wp4so36327087obc.10
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 05:36:59 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=7wAxsQYIWtu8RtuwpRynzxu7C56QOwUS0yJJZf+4qCM=;
        b=JfE59ZPFvAZRp0Sx5NbfsLMNdpRhGQ3IS5AW9E4gmA+/4HZ3nQDwMrW0XFyTn0ffEk
         vlEM+0vmKOZ/CdhXY3yEw7W21PFUI2lQa84g+tzFqHb/9kZxnWMG4r/GnOEovu3EEg+g
         xK3q/nBQfXgwnip6phM2ex39r21TD16koCzUESCA/pomvplPU+JRf09HW4NVfc7Xvpnc
         iPizsjg4k3Z+WsOZ+32Ylz0o860xkinrSMUsZ9lzturAF0LA2q6ExGkxry6EN78XTxyc
         7/FPIZONMl6HiaN4l0KN1fw/s2YoRxCRAOyZElTR2LxWwXZh99PhiQBEARjLgvP/TNR7
         rAmA==
X-Gm-Message-State: ALoCoQlUb8mXV4iVyoXn873Rg14wiRc40fBug6rXfp7QooSjnH2xzZjYcGcxBVrckPg0GZGZnlUK
X-Received: by 10.60.118.202 with SMTP id ko10mr7592600oeb.27.1424698619342;
 Mon, 23 Feb 2015 05:36:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.202.230.200 with HTTP; Mon, 23 Feb 2015 05:36:39 -0800 (PST)
In-Reply-To: <54E36CDB.1060903@gmail.com>
References: <CAH5MZvM-egTZNRtxquQT=adRM_xOObDXS5D-8rfPKkErXE4+yQ@mail.gmail.com>
 <CAH5MZvMBjqOST-9Nr9k1z1rUODfSiczr_fV9kwqDFqAMNLC2Zw@mail.gmail.com>
 <CABjXkq6WktsYSgMHj3efHy8SWQ0YRt=ehErmTmQ7z5YYOJp9Fg@mail.gmail.com> <54E36CDB.1060903@gmail.com>
From: Josh Devins <josh@soundcloud.com>
Date: Mon, 23 Feb 2015 14:36:39 +0100
Message-ID: <CAH5MZvNUAAdGtfjDKuOS+bqzzMpTjM41c6yD-QSYOF_LUjaDew@mail.gmail.com>
Subject: Re: [MLlib] Performance problem in GeneralizedLinearAlgorithm
To: Peter Rudenko <petro.rudenko@gmail.com>, evan.sparks@gmail.com
Cc: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for the pointer Peter, that change will indeed fix this bug and
it looks like it will make it into the upcoming 1.3.0 release.

@Evan, for reference, completeness and posterity:

> Just to be clear - you're currently calling .persist() before you pass da=
ta to LogisticRegressionWithLBFGS?

No. I added persist in GeneralizedLinearAlgorithm right before the
`data` RDD goes into optimizer (LBFGS in our case). See here:
https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/org/ap=
ache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L204

> Also - can you give some parameters about the problem/cluster size you're=
 solving this on? How much memory per node? How big are n and d, what is it=
s sparsity (if any) and how many iterations are you running for? Is 0:45 th=
e per-iteration time or total time for some number of iterations?

The vector is very sparse (few hundred entries) but 2.5M in size. The
dataset is about 30M examples to learn from. 16x machines, 64GB
memory, 32-cores.

Josh


On 17 February 2015 at 17:31, Peter Rudenko <petro.rudenko@gmail.com> wrote=
:
> It's fixed today: https://github.com/apache/spark/pull/4593
>
> Thanks,
> Peter Rudenko
>
> On 2015-02-17 18:25, Evan R. Sparks wrote:
>>
>> Josh - thanks for the detailed write up - this seems a little funny to m=
e.
>> I agree that with the current code path there is extra work being done
>> than
>> needs to be (e.g. the features are re-scaled at every iteration, but the
>> relatively costly process of fitting the StandardScaler should not be
>> re-done at each iteration. Instead, at each iteration, all points are
>> re-scaled according to the pre-computed standard-deviations in the
>> StandardScalerModel, and then an intercept is appended.
>>
>> Just to be clear - you're currently calling .persist() before you pass
>> data
>> to LogisticRegressionWithLBFGS?
>>
>> Also - can you give some parameters about the problem/cluster size you'r=
e
>> solving this on? How much memory per node? How big are n and d, what is
>> its
>> sparsity (if any) and how many iterations are you running for? Is 0:45 t=
he
>> per-iteration time or total time for some number of iterations?
>>
>> A useful test might be to call GeneralizedLinearAlgorithm
>> useFeatureScaling
>> set to false (and maybe also addIntercept set to false) on persisted dat=
a,
>> and see if you see the same performance wins. If that's the case we've
>> isolated the issue and can start profiling to see where all the time is
>> going.
>>
>> It would be great if you can open a JIRA.
>>
>> Thanks!
>>
>>
>>
>> On Tue, Feb 17, 2015 at 6:36 AM, Josh Devins <josh@soundcloud.com> wrote=
:
>>
>>> Cross-posting as I got no response on the users mailing list last
>>> week. Any response would be appreciated :)
>>>
>>> Josh
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Josh Devins <josh@soundcloud.com>
>>> Date: 9 February 2015 at 15:59
>>> Subject: [MLlib] Performance problem in GeneralizedLinearAlgorithm
>>> To: "user@spark.apache.org" <user@spark.apache.org>
>>>
>>>
>>> I've been looking into a performance problem when using
>>> LogisticRegressionWithLBFGS (and in turn GeneralizedLinearAlgorithm).
>>> Here's an outline of what I've figured out so far and it would be
>>> great to get some confirmation of the problem, some input on how
>>> wide-spread this problem might be and any ideas on a nice way to fix
>>> this.
>>>
>>> Context:
>>> - I will reference `branch-1.1` as we are currently on v1.1.1 however
>>> this appears to still be a problem on `master`
>>> - The cluster is run on YARN, on bare-metal hardware (no VMs)
>>> - I've not filed a Jira issue yet but can do so
>>> - This problem affects all algorithms based on
>>> GeneralizedLinearAlgorithm (GLA) that use feature scaling (and less so
>>> when not, but still a problem) (e.g. LogisticRegressionWithLBFGS)
>>>
>>> Problem Outline:
>>> - Starting at GLA line 177
>>> (
>>>
>>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/or=
g/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L177
>>> ),
>>> a feature scaler is created using the `input` RDD
>>> - Refer next to line 186 which then maps over the `input` RDD and
>>> produces a new `data` RDD
>>> (
>>>
>>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/or=
g/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L186
>>> )
>>> - If you are using feature scaling or adding intercepts, the user
>>> `input` RDD has been mapped over *after* the user has persisted it
>>> (hopefully) and *before* going into the (iterative) optimizer on line
>>> 204 (
>>>
>>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/or=
g/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.scala#L204
>>> )
>>> - Since the RDD `data` that is iterated over in the optimizer is
>>> unpersisted, when we are running the cost function in the optimizer
>>> (e.g. LBFGS --
>>>
>>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/or=
g/apache/spark/mllib/optimization/LBFGS.scala#L198
>>> ),
>>> the map phase will actually first go back and rerun the feature
>>> scaling (map tasks on `input`) and then map with the cost function
>>> (two maps pipelined into one stage)
>>> - As a result, parts of the StandardScaler will actually be run again
>>> (perhaps only because the variable is `lazy`?) and this can be costly,
>>> see line 84 (
>>>
>>> https://github.com/apache/spark/blob/branch-1.1/mllib/src/main/scala/or=
g/apache/spark/mllib/feature/StandardScaler.scala#L84
>>> )
>>> - For small datasets and/or few iterations, this is not really a
>>> problem, however we found that by adding a `data.persist()` right
>>> before running the optimizer, we went from map iterations in the
>>> optimizer that went from 5:30 down to 0:45
>>>
>>> I had a very tough time coming up with a nice way to describe my
>>> debugging sessions in an email so I hope this gets the main points
>>> across. Happy to clarify anything if necessary (also by live
>>> debugging/Skype/phone if that's helpful).
>>>
>>> Thanks,
>>>
>>> Josh
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11731-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 13:58:27 2015
Return-Path: <dev-return-11731-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47B85102ED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 13:58:27 +0000 (UTC)
Received: (qmail 51785 invoked by uid 500); 23 Feb 2015 13:58:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51643 invoked by uid 500); 23 Feb 2015 13:58:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51112 invoked by uid 99); 23 Feb 2015 13:58:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:58:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cjnolet@gmail.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 13:58:11 +0000
Received: by iecrd18 with SMTP id rd18so23302125iec.8
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 05:55:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=m6vcN5AT7HHTmexoRlOawTFuIM8AWjLBaWde/Jco/Oc=;
        b=nbBXT3KpghGNMxkaDpe5NXlY7TYPZ4gakdGf6/8XaMeAhNrhyweyZi0b40itYGpOTn
         3SGPfb0PoQMYF4bJZMq6W+7Xfti+0fIl+Lac9rcYoxtxHgSG2BCq8gfYLDd1JWNOXc6n
         kCCttSdFRpA2vxPynbqqnffNdmZdRApzgvFcPj64cQukUgpIIVD4vPthu9U4qwT9yoY8
         CIBbO86VNxhpgbUBSbaF6QXYoVGmKl7eCq1AuZ12AJ0+BnAt017Gt+AqOKoDMujimOvL
         i8DFWcBRc47rfjfOb32ugz1dfqAw20qBxTLx3RZ2LRgY1qF4gsbWP3d31FOx97VmJyAa
         Vv+A==
X-Received: by 10.107.155.131 with SMTP id d125mr14029207ioe.17.1424699735478;
 Mon, 23 Feb 2015 05:55:35 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.18.175 with HTTP; Mon, 23 Feb 2015 05:55:15 -0800 (PST)
In-Reply-To: <71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com> <71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
From: Corey Nolet <cjnolet@gmail.com>
Date: Mon, 23 Feb 2015 08:55:15 -0500
Message-ID: <CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Robin East <robin.east@xense.co.uk>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1140aacea51f5f050fc1c1e2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1140aacea51f5f050fc1c1e2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

This vote was supposed to close on Saturday but it looks like no PMCs voted
(other than the implicit vote from Patrick). Was there a discussion offline
to cut an RC2? Was the vote extended?

On Mon, Feb 23, 2015 at 6:59 AM, Robin East <robin.east@xense.co.uk> wrote:

> Running ec2 launch scripts gives me the following error:
>
> ssl.SSLError: [Errno 1] _ssl.c:504: error:14090086:SSL
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed
>
> Full stack trace at
> https://gist.github.com/insidedctm/4d41600bc22560540a26
>
> I=E2=80=99m running OSX Mavericks 10.9.5
>
> I=E2=80=99ll investigate further but wondered if anyone else has run into=
 this.
>
> Robin

--001a1140aacea51f5f050fc1c1e2--

From dev-return-11732-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 14:06:00 2015
Return-Path: <dev-return-11732-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 80F011032D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 14:06:00 +0000 (UTC)
Received: (qmail 69734 invoked by uid 500); 23 Feb 2015 14:05:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69660 invoked by uid 500); 23 Feb 2015 14:05:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 69648 invoked by uid 99); 23 Feb 2015 14:05:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:05:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of watcherfr@gmail.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:05:36 +0000
Received: by mail-ig0-f174.google.com with SMTP id b16so18295501igk.1
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 06:05:15 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=4jPApYJyum0g73iIxs1HqA7HdDXO15UNZgpOYXCR+ak=;
        b=ZrEIvNhSC6s6mgQO7bsffFig741l3A0E7Aegv2d+FTxOUnkJXelihx1nZLNOPE+kGo
         53SXVSgQacGqUMye5dVB6z9RbHXC3XzXkblB6zegOeEvC87ta/bVGjzc9Z3LuXiBFq/l
         Tc77aGyJ1w8JjByg0NLMegbzbmIQYYII/S/j9rP6O298TEebsA4dGqpLDxH9vxRLOHS5
         RnIOpBEc/KSsH4YRt352SL8P+J2ntrkEb67wodOy7P7AhzWFtpjOn4TbDI3vPzg5eRzH
         FBmUD9gfoaCdSbWMnbgtPeWgZepLGH4JtvrRkecenkU6kqnko3Bg6VQce0WDHpj3wFOO
         1MCQ==
MIME-Version: 1.0
X-Received: by 10.107.168.207 with SMTP id e76mr13513731ioj.60.1424700315456;
 Mon, 23 Feb 2015 06:05:15 -0800 (PST)
Received: by 10.36.113.132 with HTTP; Mon, 23 Feb 2015 06:05:15 -0800 (PST)
In-Reply-To: <54EB1C51.4090308@gmail.com>
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>
	<54E73A53.2020100@gmail.com>
	<CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>
	<54EB1C51.4090308@gmail.com>
Date: Mon, 23 Feb 2015 15:05:15 +0100
Message-ID: <CAHwsXYkWmRsoZShHAe7_K9r1JdujToYrUZ2ZwDiqjrRrcU4dhA@mail.gmail.com>
Subject: Re: Spark SQL, Hive & Parquet data types
From: The Watcher <watcherfr@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1142790036ee92050fc1e4ab
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1142790036ee92050fc1e4ab
Content-Type: text/plain; charset=UTF-8

>
> Yes, recently we improved ParquetRelation2 quite a bit. Spark SQL uses its
> own Parquet support to read partitioned Parquet tables declared in Hive
> metastore. Only writing to partitioned tables is not covered yet. These
> improvements will be included in Spark 1.3.0.
>
> Just created SPARK-5948 to track writing to partitioned Parquet tables.
>
Ok, this is still a little confusing.

Since I am able in 1.2.0 to write to a partitioned Hive by registering my
SchemaRDD and calling INSERT into "the hive partitionned table" SELECT "the
registrered", what is the write-path in this case ? Full Hive with a
SparkSQL<->Hive bridge ?
If that were the case, why wouldn't SKEWED ON be honored (see another
thread I opened).

Thanks

--001a1142790036ee92050fc1e4ab--

From dev-return-11733-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 14:06:01 2015
Return-Path: <dev-return-11733-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 951D21032E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 14:06:01 +0000 (UTC)
Received: (qmail 71581 invoked by uid 500); 23 Feb 2015 14:06:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71514 invoked by uid 500); 23 Feb 2015 14:06:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71503 invoked by uid 99); 23 Feb 2015 14:06:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:06:00 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.176 as permitted sender)
Received: from [74.125.82.176] (HELO mail-we0-f176.google.com) (74.125.82.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:05:55 +0000
Received: by wesq59 with SMTP id q59so18483886wes.1
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 06:05:34 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=nvMeVXMWeFuo9FQ2ZSmap55BssTgYTgFWM0C+DdoqoY=;
        b=kg9YYZkjb1U9tCtoOr2zgyDEbKCM9LDM8Feh/QqQdLHzcLiT8VfSputowYXjlU+Rqk
         m5mG6GZ30IFri/+GEJY2GxfHhmBQaUfWgNxd/XMaQvvovZInCNmr5kyEF/bJWzoOpkIG
         A/FkpPFSl1toh8byH0IF34UrE0KgH/sGoOk4PZb96N6Y6hXMilFuZNKGnJ7q2Q/QdPsT
         JyJYAX6cgzE/L340jQfFt2yO5dRewrqr+orEY78hz4065PzMHzxf2z1g4PuRWzau9FgA
         MvRyqfd0TkSCb10AYRcbhzeLwcnframoFjGgaO33GlqnXuwdrGzv5MeTWkGXSXiSWc9W
         cxiA==
X-Gm-Message-State: ALoCoQlZ1NTn1cHCb93znmYveS497FQg/yfsIdwBdZ7OvT5Wxt9E2Glv6w5jN9xU/BcnNWU+jcYp
X-Received: by 10.180.106.70 with SMTP id gs6mr11623556wib.39.1424700333934;
 Mon, 23 Feb 2015 06:05:33 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Mon, 23 Feb 2015 06:05:13 -0800 (PST)
In-Reply-To: <CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
 <71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk> <CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 23 Feb 2015 14:05:13 +0000
Message-ID: <CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Corey Nolet <cjnolet@gmail.com>
Cc: Robin East <robin.east@xense.co.uk>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Yes my understanding from Patrick's comment is that this RC will not
be released, but, to keep testing. There's an implicit -1 out of the
gates there, I believe, and so the vote won't pass, so perhaps that's
why there weren't further binding votes. I'm sure that will be
formalized shortly.

FWIW here are 10 issues still listed as blockers for 1.3.0:

SPARK-5910 DataFrame.selectExpr("col as newName") does not work
SPARK-5904 SPARK-5166 DataFrame methods with varargs do not work in Java
SPARK-5873 Can't see partially analyzed plans
SPARK-5546 Improve path to Kafka assembly when trying Kafka Python API
SPARK-5517 SPARK-5166 Add input types for Java UDFs
SPARK-5463 Fix Parquet filter push-down
SPARK-5310 SPARK-5166 Update SQL programming guide for 1.3
SPARK-5183 SPARK-5180 Document data source API
SPARK-3650 Triangle Count handles reverse edges incorrectly
SPARK-3511 Create a RELEASE-NOTES.txt file in the repo


On Mon, Feb 23, 2015 at 1:55 PM, Corey Nolet <cjnolet@gmail.com> wrote:
> This vote was supposed to close on Saturday but it looks like no PMCs voted
> (other than the implicit vote from Patrick). Was there a discussion offline
> to cut an RC2? Was the vote extended?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11734-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 14:14:48 2015
Return-Path: <dev-return-11734-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D31C103ED
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 14:14:48 +0000 (UTC)
Received: (qmail 93395 invoked by uid 500); 23 Feb 2015 14:14:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93319 invoked by uid 500); 23 Feb 2015 14:14:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93307 invoked by uid 99); 23 Feb 2015 14:14:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:14:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cjnolet@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 14:14:42 +0000
Received: by mail-ig0-f175.google.com with SMTP id hn18so18287652igb.2
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 06:13:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=zg4kSTw1Z4VjleGMJvNV5bTWHc6A2Iu4jJoyHndsNaI=;
        b=YsllQmPkKDrzOEH4yF9bOFB/g6calVyW3A08RRXsw8xpxzZFrL2lQOIHgsLfBCVRiA
         oHv4OYWM1jzl7qMXni581RxZdvxwLG1DN0BkMwfMhTdBtsWTT4h6mOvOsylXJfBPZoc0
         PY36BcmS+qMUacRwl431Qgco7+3wyMGqPhiSBZzs2FAUR2iI12hIzcSWyOIDJQSW9H2m
         HIJ/NdlZurC52aVuBm5r7QZygZrVNTTISYPp8NmwgU9xsKZC235FBW4QASL0F9DakqY3
         F/w7ch1FqhdNWTEdii+FWJrKWypa1xIOU6/A1L0XQropsgV72LJWAVWGbyAf8Boch/5w
         B2Fg==
X-Received: by 10.50.107.7 with SMTP id gy7mr12982480igb.49.1424700816922;
 Mon, 23 Feb 2015 06:13:36 -0800 (PST)
MIME-Version: 1.0
Received: by 10.64.18.175 with HTTP; Mon, 23 Feb 2015 06:13:15 -0800 (PST)
In-Reply-To: <CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
 <71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk> <CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
 <CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
From: Corey Nolet <cjnolet@gmail.com>
Date: Mon, 23 Feb 2015 09:13:15 -0500
Message-ID: <CAOHP_tFvrWAgi9R7A-mc9YEvRAV=p=Tdhs26v7CLMUjh9ZYN5Q@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Sean Owen <sowen@cloudera.com>
Cc: Robin East <robin.east@xense.co.uk>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8ffbae411a9f62050fc202c2
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8ffbae411a9f62050fc202c2
Content-Type: text/plain; charset=UTF-8

Thanks Sean. I glossed over the comment about SPARK-5669.

On Mon, Feb 23, 2015 at 9:05 AM, Sean Owen <sowen@cloudera.com> wrote:

> Yes my understanding from Patrick's comment is that this RC will not
> be released, but, to keep testing. There's an implicit -1 out of the
> gates there, I believe, and so the vote won't pass, so perhaps that's
> why there weren't further binding votes. I'm sure that will be
> formalized shortly.
>
> FWIW here are 10 issues still listed as blockers for 1.3.0:
>
> SPARK-5910 DataFrame.selectExpr("col as newName") does not work
> SPARK-5904 SPARK-5166 DataFrame methods with varargs do not work in Java
> SPARK-5873 Can't see partially analyzed plans
> SPARK-5546 Improve path to Kafka assembly when trying Kafka Python API
> SPARK-5517 SPARK-5166 Add input types for Java UDFs
> SPARK-5463 Fix Parquet filter push-down
> SPARK-5310 SPARK-5166 Update SQL programming guide for 1.3
> SPARK-5183 SPARK-5180 Document data source API
> SPARK-3650 Triangle Count handles reverse edges incorrectly
> SPARK-3511 Create a RELEASE-NOTES.txt file in the repo
>
>
> On Mon, Feb 23, 2015 at 1:55 PM, Corey Nolet <cjnolet@gmail.com> wrote:
> > This vote was supposed to close on Saturday but it looks like no PMCs
> voted
> > (other than the implicit vote from Patrick). Was there a discussion
> offline
> > to cut an RC2? Was the vote extended?
>

--e89a8ffbae411a9f62050fc202c2--

From dev-return-11735-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 18:20:47 2015
Return-Path: <dev-return-11735-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C344910EC6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 18:20:47 +0000 (UTC)
Received: (qmail 52863 invoked by uid 500); 23 Feb 2015 18:20:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52787 invoked by uid 500); 23 Feb 2015 18:20:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52775 invoked by uid 99); 23 Feb 2015 18:20:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:20:46 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:20:41 +0000
Received: by mail-oi0-f44.google.com with SMTP id a3so14951770oib.3
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 10:18:06 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=FFvNJYB1jdXFS28tTQDBLAbiMGVoSkrQmAfbRxV8nXA=;
        b=p+zlwllFrfNcBOx21E6URd6ydKrrGfNl/zNr3QHeEt2zQYvHwtEN4TNphEEAJCvQUZ
         3In83THyH6Ve8/uXMpdSN1B6RpbT+KKuJc8GpDBMB65t9+fzkeGdEQHeYX0MFvM/FF4F
         3xjROKZLrJx31mpiM7HItOxp2i6JL4u0z3Zlrx0/2RS62+pKm6GpXlalmOWMxZNetZB5
         M0lo64fpkwetXH2ETfaGn0rI6YVpF5UiDt5huWwbj4AOPPTDMgUAxFZPKXX7Jx+5T+oH
         ZFmajtfWIcUhOo931PrsizQTqbKkcb0nrFSgr86EUeWMYVy7QBi47DnJ7PvMYn/1NgD5
         KUjQ==
MIME-Version: 1.0
X-Received: by 10.182.215.163 with SMTP id oj3mr8519953obc.49.1424715486648;
 Mon, 23 Feb 2015 10:18:06 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 23 Feb 2015 10:18:06 -0800 (PST)
In-Reply-To: <CAOHP_tFvrWAgi9R7A-mc9YEvRAV=p=Tdhs26v7CLMUjh9ZYN5Q@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
	<71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
	<CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
	<CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
	<CAOHP_tFvrWAgi9R7A-mc9YEvRAV=p=Tdhs26v7CLMUjh9ZYN5Q@mail.gmail.com>
Date: Mon, 23 Feb 2015 10:18:06 -0800
Message-ID: <CABPQxst4q9=SXaZnB=1sQjow9K6RqHXNi4xbQxHSWDaDNt6G9A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Patrick Wendell <pwendell@gmail.com>
To: Corey Nolet <cjnolet@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, Robin East <robin.east@xense.co.uk>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

So actually, the list of blockers on JIRA is a bit outdated. These
days I won't cut RC1 unless there are no known issues that I'm aware
of that would actually block the release (that's what the snapshot
ones are for). I'm going to clean those up and push others to do so
also.

The main issues I'm aware of that came about post RC1 are:
1. Python submission broken on YARN
2. The license issue in MLlib [now fixed].
3. Varargs broken for Java Dataframes [now fixed]

Re: Corey - yeah, as it stands now I try to wait if there are things
that look like implicit -1 votes.

On Mon, Feb 23, 2015 at 6:13 AM, Corey Nolet <cjnolet@gmail.com> wrote:
> Thanks Sean. I glossed over the comment about SPARK-5669.
>
> On Mon, Feb 23, 2015 at 9:05 AM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> Yes my understanding from Patrick's comment is that this RC will not
>> be released, but, to keep testing. There's an implicit -1 out of the
>> gates there, I believe, and so the vote won't pass, so perhaps that's
>> why there weren't further binding votes. I'm sure that will be
>> formalized shortly.
>>
>> FWIW here are 10 issues still listed as blockers for 1.3.0:
>>
>> SPARK-5910 DataFrame.selectExpr("col as newName") does not work
>> SPARK-5904 SPARK-5166 DataFrame methods with varargs do not work in Java
>> SPARK-5873 Can't see partially analyzed plans
>> SPARK-5546 Improve path to Kafka assembly when trying Kafka Python API
>> SPARK-5517 SPARK-5166 Add input types for Java UDFs
>> SPARK-5463 Fix Parquet filter push-down
>> SPARK-5310 SPARK-5166 Update SQL programming guide for 1.3
>> SPARK-5183 SPARK-5180 Document data source API
>> SPARK-3650 Triangle Count handles reverse edges incorrectly
>> SPARK-3511 Create a RELEASE-NOTES.txt file in the repo
>>
>>
>> On Mon, Feb 23, 2015 at 1:55 PM, Corey Nolet <cjnolet@gmail.com> wrote:
>> > This vote was supposed to close on Saturday but it looks like no PMCs
>> > voted
>> > (other than the implicit vote from Patrick). Was there a discussion
>> > offline
>> > to cut an RC2? Was the vote extended?
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11736-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 18:30:17 2015
Return-Path: <dev-return-11736-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B7E810F5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 18:30:17 +0000 (UTC)
Received: (qmail 97613 invoked by uid 500); 23 Feb 2015 18:30:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97540 invoked by uid 500); 23 Feb 2015 18:30:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97528 invoked by uid 99); 23 Feb 2015 18:30:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:30:16 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.223.182 as permitted sender)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:30:10 +0000
Received: by iebtr6 with SMTP id tr6so25595453ieb.7
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 10:29:50 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=HkDA6KNId4XvWrI3vEMH6ahc8v37FuQDOzVFfmexuZQ=;
        b=NBBckuToNjTEtjdwtRwG2Nm0n3cGwXB3iDa+KM5dufSf8Y7ScOaQIaxOzj2ZiQ2tQR
         k607Yyzfzr1I0SOgQ9A8shd2wBRLT2RKamigYNi1uMXFxOvEWRn33pgrbpdIC4IpJkPp
         H8/iVwYxmwaeBvuVPgo22NmonzHMruLL6bhmxotBa7zo9O1O0owlkkQTA2/16fKreXXm
         ZZHsxy59v6+5cdwyT3b5fz6DhNIezRRJFvndbw79UdVbZJROdcHbvKg0xUsTAPyz2rYS
         jcyDJY7HT8ccRtWTzapXJaZRBiJbBsECx7TAWTu3a1Im1NOwkcLrCg9UaguXmSPQmN3i
         B21A==
X-Gm-Message-State: ALoCoQmwbCamXG4VZbsecuyROgjdXtWOT8uUdtpdSWKWgYP0nyZt8u5Sk/c1PRYamnsdVha7aOa9
MIME-Version: 1.0
X-Received: by 10.42.229.10 with SMTP id jg10mr12979185icb.62.1424716190243;
 Mon, 23 Feb 2015 10:29:50 -0800 (PST)
Received: by 10.36.88.8 with HTTP; Mon, 23 Feb 2015 10:29:50 -0800 (PST)
In-Reply-To: <CABPQxst4q9=SXaZnB=1sQjow9K6RqHXNi4xbQxHSWDaDNt6G9A@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
	<71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
	<CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
	<CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
	<CAOHP_tFvrWAgi9R7A-mc9YEvRAV=p=Tdhs26v7CLMUjh9ZYN5Q@mail.gmail.com>
	<CABPQxst4q9=SXaZnB=1sQjow9K6RqHXNi4xbQxHSWDaDNt6G9A@mail.gmail.com>
Date: Mon, 23 Feb 2015 10:29:50 -0800
Message-ID: <CAAOnQ7u5_vc5Mucm+kntvzjMkUE9cRU74WDxCZg1+ffPR7dQfQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Patrick,

Do you have a link to the bug related to Python and Yarn? I looked at
the blockers in Jira but couldn't find it.

On Mon, Feb 23, 2015 at 10:18 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> So actually, the list of blockers on JIRA is a bit outdated. These
> days I won't cut RC1 unless there are no known issues that I'm aware
> of that would actually block the release (that's what the snapshot
> ones are for). I'm going to clean those up and push others to do so
> also.
>
> The main issues I'm aware of that came about post RC1 are:
> 1. Python submission broken on YARN
> 2. The license issue in MLlib [now fixed].
> 3. Varargs broken for Java Dataframes [now fixed]
>
> Re: Corey - yeah, as it stands now I try to wait if there are things
> that look like implicit -1 votes.

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11737-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 18:31:35 2015
Return-Path: <dev-return-11737-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 830B710F6E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 18:31:35 +0000 (UTC)
Received: (qmail 5848 invoked by uid 500); 23 Feb 2015 18:31:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5768 invoked by uid 500); 23 Feb 2015 18:31:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5752 invoked by uid 99); 23 Feb 2015 18:31:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:31:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:31:29 +0000
Received: by mail-ob0-f181.google.com with SMTP id vb8so38177488obc.12
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 10:31:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=90waubgjfiIwPEv+TfA16FVbPWvZ9Wp5c21oZJ6FMx8=;
        b=PbX1M6RyFNQtx1iy9PzPrRbm6ca90fox3Ax7/7eYqOrJcXrz12e4pu1gjTFIKOGNFu
         wjknmJctsUHmNsD4bJ6mWSKp06Z83hwi8wo+3HGhD1YLFIizM2rwjdmieZYwF3hWf66u
         6RXkXuD+ws7LRdHto3G7Zbd1iOSyOrOl30hXLknH78uBdVZfe7EuzLEAWvhoGdappREK
         6qRrV2/yywUE9KRi8dYVzj7yzILiSAna9hi4bxLOWsoI2GbL76nwDLjZ/VBlYPgbunhF
         kyokUpOzdri63bCinuzBZYjhPsMNPynT2ZLHS7inN5rEfhnhtBpEcjYFfqhOLACsguJ2
         eUtw==
MIME-Version: 1.0
X-Received: by 10.202.185.198 with SMTP id j189mr8132565oif.72.1424716269508;
 Mon, 23 Feb 2015 10:31:09 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Mon, 23 Feb 2015 10:31:09 -0800 (PST)
In-Reply-To: <CAAOnQ7u5_vc5Mucm+kntvzjMkUE9cRU74WDxCZg1+ffPR7dQfQ@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
	<71BB1BD5-CD2C-44BC-A7E6-03B0EE274F94@xense.co.uk>
	<CAOHP_tEs=0t+KncyOmA387av9Udu2v++Z0UXp8_Z5_waKaESdA@mail.gmail.com>
	<CAMAsSdJEQ0erg16afbBojf5p-p=RAPPXCGCwLbO9_q=U2FTjpQ@mail.gmail.com>
	<CAOHP_tFvrWAgi9R7A-mc9YEvRAV=p=Tdhs26v7CLMUjh9ZYN5Q@mail.gmail.com>
	<CABPQxst4q9=SXaZnB=1sQjow9K6RqHXNi4xbQxHSWDaDNt6G9A@mail.gmail.com>
	<CAAOnQ7u5_vc5Mucm+kntvzjMkUE9cRU74WDxCZg1+ffPR7dQfQ@mail.gmail.com>
Date: Mon, 23 Feb 2015 10:31:09 -0800
Message-ID: <CABPQxsvKByPADPq6pMZAdDYW2-kCaV3Q91A0N5HYjmQ8QLaGqw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Patrick Wendell <pwendell@gmail.com>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

It's only been reported on this thread by Tom, so far.

On Mon, Feb 23, 2015 at 10:29 AM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
> Hey Patrick,
>
> Do you have a link to the bug related to Python and Yarn? I looked at
> the blockers in Jira but couldn't find it.
>
> On Mon, Feb 23, 2015 at 10:18 AM, Patrick Wendell <pwendell@gmail.com> wrote:
>> So actually, the list of blockers on JIRA is a bit outdated. These
>> days I won't cut RC1 unless there are no known issues that I'm aware
>> of that would actually block the release (that's what the snapshot
>> ones are for). I'm going to clean those up and push others to do so
>> also.
>>
>> The main issues I'm aware of that came about post RC1 are:
>> 1. Python submission broken on YARN
>> 2. The license issue in MLlib [now fixed].
>> 3. Varargs broken for Java Dataframes [now fixed]
>>
>> Re: Corey - yeah, as it stands now I try to wait if there are things
>> that look like implicit -1 votes.
>
> --
> Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11738-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 18:34:09 2015
Return-Path: <dev-return-11738-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0CA5510F9A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 18:34:09 +0000 (UTC)
Received: (qmail 18495 invoked by uid 500); 23 Feb 2015 18:34:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18427 invoked by uid 500); 23 Feb 2015 18:34:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18416 invoked by uid 99); 23 Feb 2015 18:34:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:34:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:34:02 +0000
Received: by iecar1 with SMTP id ar1so25692544iec.11
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 10:33:42 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=oaNUqjQaGCxYYO8KVLFWurP5JeQP9u7doqkOkRyKaic=;
        b=fnmA/S54euIaZKRXZPvBZ5oZ5oHLUdhVQNavBOTaFW1NvX1hJIZgaAVY1SKfRIf+R+
         k1xJEJ5Ii0y2br61ksay9yTtk6sZKSKIK4wHyCdzMvrwshFdX+60qUPtpV1A4kgrQELI
         xaSa7OgBqWTnJ6z4pjI4OvF5Dl6MezhglaSHuOhxzdXlYGRrhIjH5Vou2EuW33lbXvFS
         LzksAgSvfsgcE3JOEt1/gh6uL3a6xfEpA2HWmtQ0ODeo3lddUAcBHtIp7XQo+TcQMnUv
         ht3Pml4zfDvS1BzmcTpoGQOOH+kRTi4bZDn5o2j00W2KshxflRi1spcr9wpkN9OXkifD
         M7dw==
X-Gm-Message-State: ALoCoQlbhQvUW8CQVHjzabTq/YQFxv+1rUr882pWYrHH9h3ZMKid6NNOcx12kASxVRq9AapTcrkL
MIME-Version: 1.0
X-Received: by 10.42.93.16 with SMTP id v16mr11916003icm.74.1424716421879;
 Mon, 23 Feb 2015 10:33:41 -0800 (PST)
Received: by 10.36.88.8 with HTTP; Mon, 23 Feb 2015 10:33:41 -0800 (PST)
In-Reply-To: <795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
Date: Mon, 23 Feb 2015 10:33:41 -0800
Message-ID: <CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Tom Graves <tgraves_cs@yahoo.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Tom, are you using an sbt-built assembly by any chance? If so, take
a look at SPARK-5808.

I haven't had any problems with the maven-built assembly. Setting
SPARK_HOME on the executors is a workaround if you want to use the sbt
assembly.

On Fri, Feb 20, 2015 at 2:56 PM, Tom Graves
<tgraves_cs@yahoo.com.invalid> wrote:
> Trying to run pyspark on yarn in client mode with basic wordcount example=
 I see the following error when doing the collect:
> Error from python worker:  /usr/bin/python: No module named sqlPYTHONPATH=
 was:  /grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-assembly=
-1.3.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException        at java.io.D=
ataInputStream.readInt(DataInputStream.java:392)        at org.apache.spark=
.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:163) =
       at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaem=
on(PythonWorkerFactory.scala:86)        at org.apache.spark.api.python.Pyth=
onWorkerFactory.create(PythonWorkerFactory.scala:62)        at org.apache.s=
park.SparkEnv.createPythonWorker(SparkEnv.scala:105)        at org.apache.s=
park.api.python.PythonRDD.compute(PythonRDD.scala:69)        at org.apache.=
spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)        at org.apache.s=
park.rdd.RDD.iterator(RDD.scala:244)        at org.apache.spark.api.python.=
PairwiseRDD.compute(PythonRDD.scala:308)        at org.apache.spark.rdd.RDD=
.computeOrReadCheckpoint(RDD.scala:277)        at org.apache.spark.rdd.RDD.=
iterator(RDD.scala:244)        at org.apache.spark.scheduler.ShuffleMapTask=
.runTask(ShuffleMapTask.scala:68)        at org.apache.spark.scheduler.Shuf=
fleMapTask.runTask(ShuffleMapTask.scala:41)        at org.apache.spark.sche=
duler.Task.run(Task.scala:64)        at org.apache.spark.executor.Executor$=
TaskRunner.run(Executor.scala:197)        at java.util.concurrent.ThreadPoo=
lExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concu=
rrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at =
java.lang.Thread.run(Thread.java:722)
> any ideas on this?
> Tom
>
>      On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <pwendell@g=
mail.com> wrote:
>
>
>  Please vote on releasing the following candidate as Apache Spark version=
 1.3.0!
>
> The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Df97b=
0d4a6b26504916816d7aefcf3132cd1da6c2
>
> The release files, including signatures, digests, etc. can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1/
>
> Release artifacts are signed with the following key:
> https://people.apache.org/keys/committer/pwendell.asc
>
> The staging repository for this release can be found at:
> https://repository.apache.org/content/repositories/orgapachespark-1069/
>
> The documentation corresponding to this release can be found at:
> http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
>
> Please vote on releasing this package as Apache Spark 1.3.0!
>
> The vote is open until Saturday, February 21, at 08:03 UTC and passes
> if a majority of at least 3 +1 PMC votes are cast.
>
> [ ] +1 Release this package as Apache Spark 1.3.0
> [ ] -1 Do not release this package because ...
>
> To learn more about Apache Spark, please see
> http://spark.apache.org/
>
> =3D=3D How can I help test this release? =3D=3D
> If you are a Spark user, you can help us test this release by
> taking a Spark 1.2 workload and running on this release candidate,
> then reporting any regressions.
>
> =3D=3D What justifies a -1 vote for this release? =3D=3D
> This vote is happening towards the end of the 1.3 QA period,
> so -1 votes should only occur for significant regressions from 1.2.1.
> Bugs already present in 1.2.X, minor regressions, or bugs related
> to new features will not block this release.
>
> - Patrick
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>
>
>



--=20
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11739-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 18:55:00 2015
Return-Path: <dev-return-11739-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5AAEA1729C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 18:55:00 +0000 (UTC)
Received: (qmail 81386 invoked by uid 500); 23 Feb 2015 18:54:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81301 invoked by uid 500); 23 Feb 2015 18:54:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81290 invoked by uid 99); 23 Feb 2015 18:54:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:54:58 +0000
X-ASF-Spam-Status: No, hits=1.3 required=10.0
	tests=URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: unknown (nike.apache.org: error in processing during lookup of mark.khaitman@chango.com)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 18:54:33 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 9CB8C14C54DD
	for <dev@spark.apache.org>; Mon, 23 Feb 2015 10:53:34 -0800 (PST)
Date: Mon, 23 Feb 2015 11:53:31 -0700 (MST)
From: mkhaitman <mark.khaitman@chango.com>
To: dev@spark.apache.org
Message-ID: <1424717611095-10742.post@n3.nabble.com>
Subject: StreamingContext textFileStream question
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I was interested in creating a StreamingContext textFileStream based job,
which runs for long durations, and can also recover from prolonged driver
failure... It seems like StreamingContext checkpointing is mainly used for
the case when the driver dies during the processing of an RDD, and to
recover that one RDD, but my question specifically relates to whether there
is a way to also recover which files were missed between the timeframe of
the driver dying and being started back up (whether manually or
automatically).

Any assistance/suggestions with this one would be greatly appreciated!

Thanks,
Mark.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/StreamingContext-textFileStream-question-tp10742.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11740-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 19:15:19 2015
Return-Path: <dev-return-11740-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A500C17396
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 19:15:19 +0000 (UTC)
Received: (qmail 28379 invoked by uid 500); 23 Feb 2015 19:15:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28300 invoked by uid 500); 23 Feb 2015 19:15:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28289 invoked by uid 99); 23 Feb 2015 19:15:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:15:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:15:13 +0000
Received: by lbdu14 with SMTP id u14so20521985lbd.1
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 11:13:22 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=UK1r9DgtWw5fEw6aQczogm/G/9urBEuq7x/wKSs3bWg=;
        b=jiMdO9KXnkpcJYMiDgwXB7gvVBFSherzyOprQlPXGtPOnP7RE8xqToU+cct9ziMPSn
         GSTweZ72TEeinvKxK0R9y2wxFXfjsWFfxndBEtZWwOP6Ns20ccBmihOtlRirLThzL8GD
         Ez2pJFhVXZrAts7+l8nQbcfrCTXjpXuAUiMjYBgcve26/RcleviSjrB1vvCu3v8yMIxK
         NPWbNleejIJCyHj+vq6jupiugoqn0f+emrBSHoV3uAZihAP5pWxKrhdQThdm9dOvxSHo
         jh59LszRrqPFChNgi1e54jF8EF96EApwwZEfD7z+XTCnE+UmTwpdREri/9sgKd8e4GuU
         K6mw==
X-Gm-Message-State: ALoCoQnxRiw8QiO9s2jT2/Nv1sHRqEkJNB1kgX6b5tAl3CERkKhGRpxyIOjV04f3z2jHEqyGa4H7
X-Received: by 10.152.116.18 with SMTP id js18mr11239124lab.106.1424718802345;
 Mon, 23 Feb 2015 11:13:22 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Mon, 23 Feb 2015 11:13:02 -0800 (PST)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 23 Feb 2015 11:13:02 -0800
Message-ID: <CACdU-dSmHf6nGH-ovkoG2NZyQOQoKNK_jnY9B9z+McdywsVpbA@mail.gmail.com>
Subject: [jenkins infra -- pls read ] installing anaconda, moving default
 python from 2.6 -> 2.7
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c284e21e7385050fc63230
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c284e21e7385050fc63230
Content-Type: text/plain; charset=UTF-8

good morning, developers!

TL;DR:

i will be installing anaconda and setting it in the system PATH so that
your python will default to 2.7, as well as it taking over management of
all of the sci-py packages.  this is potentially a big change, so i'll be
testing locally on my staging instance before deployment to the wide world.

deployment is *tentatively* next monday, march 2nd.

a little background:

the jenkins test infra is currently (and happily) managed by a set of tools
that allow me to set up and deploy new workers, manage their packages and
make sure that all spark and research projects can happily and successfully
build.

we're currently at the state where ~50 or so packages are installed and
configured on each worker.  this is getting a little cumbersome, as the
package-to-build dep tree is getting pretty large.

the biggest offender is the science-based python infrastructure.
 everything is blindly installed w/yum and pip, so it's hard to control
*exactly* what version of any given library is as compared to what's on a
dev's laptop.

the solution:

anaconda (https://store.continuum.io/cshop/anaconda/)!  everything is
centralized!  i can manage specific versions much easier!

what this means to you:

* python 2.7 will be the default system python.
* 2.6 will still be installed and available (/usr/bin/python or
/usr/bin/python/2.6)

what you need to do:
* install anaconda, have it update your PATH
* build locally and try to fix any bugs (for spark, this "should just work")
* if you have problems, reach out to me and i'll see what i can do to help.
 if we can't get your stuff running under python2.7, we can default to 2.6
via a job config change.

what i will be doing:
* setting up anaconda on my staging instance and spot-testing a lot of
builds before deployment

please let me know if there are any issues/concerns...  i'll be posting
updates this week and will let everyone know if there are any changes to
the Plan[tm].

your friendly devops engineer,

shane

--001a11c284e21e7385050fc63230--

From dev-return-11741-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 19:17:53 2015
Return-Path: <dev-return-11741-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 79FD6173B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 19:17:53 +0000 (UTC)
Received: (qmail 39325 invoked by uid 500); 23 Feb 2015 19:17:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39252 invoked by uid 500); 23 Feb 2015 19:17:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39241 invoked by uid 99); 23 Feb 2015 19:17:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:17:52 +0000
X-ASF-Spam-Status: No, hits=-3.7 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saisai.shao@intel.com designates 192.55.52.115 as permitted sender)
Received: from [192.55.52.115] (HELO mga14.intel.com) (192.55.52.115)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:17:47 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by fmsmga103.fm.intel.com with ESMTP; 23 Feb 2015 11:09:15 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.09,632,1418112000"; 
   d="scan'208";a="670361537"
Received: from pgsmsx104.gar.corp.intel.com ([10.221.44.91])
  by fmsmga001.fm.intel.com with ESMTP; 23 Feb 2015 11:17:07 -0800
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 PGSMSX104.gar.corp.intel.com (10.221.44.91) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Tue, 24 Feb 2015 03:17:07 +0800
Received: from shsmsx104.ccr.corp.intel.com ([169.254.5.161]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.209]) with mapi id 14.03.0195.001;
 Tue, 24 Feb 2015 03:17:05 +0800
From: "Shao, Saisai" <saisai.shao@intel.com>
To: mkhaitman <mark.khaitman@chango.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: StreamingContext textFileStream question
Thread-Topic: StreamingContext textFileStream question
Thread-Index: AQHQT5pAxt+uhbKUY0eOwPNKLxSg1pz+m0XQ
Date: Mon, 23 Feb 2015 19:17:05 +0000
Message-ID: <64474308D680D540A4D8151B0F7C03F70279D949@SHSMSX104.ccr.corp.intel.com>
References: <1424717611095-10742.post@n3.nabble.com>
In-Reply-To: <1424717611095-10742.post@n3.nabble.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Mark,

For input streams like text input stream, only RDDs can be recovered from c=
heckpoint, no missed files, if file is missed, actually an exception will b=
e raised. If you use HDFS, HDFS will guarantee no data loss since it has 3 =
copies.Otherwise user logic has to guarantee no file deleted before recover=
ing.

For input stream which is receiver based, like Kafka input stream or socket=
 input stream, a WAL(write ahead log) mechanism can be enabled to store the=
 received data as well as metadata, so data can be recovered from failure.

Thanks
Jerry

-----Original Message-----
From: mkhaitman [mailto:mark.khaitman@chango.com]=20
Sent: Monday, February 23, 2015 10:54 AM
To: dev@spark.apache.org
Subject: StreamingContext textFileStream question

Hello,

I was interested in creating a StreamingContext textFileStream based job, w=
hich runs for long durations, and can also recover from prolonged driver fa=
ilure... It seems like StreamingContext checkpointing is mainly used for th=
e case when the driver dies during the processing of an RDD, and to recover=
 that one RDD, but my question specifically relates to whether there is a w=
ay to also recover which files were missed between the timeframe of the dri=
ver dying and being started back up (whether manually or automatically).

Any assistance/suggestions with this one would be greatly appreciated!

Thanks,
Mark.



--
View this message in context: http://apache-spark-developers-list.1001551.n=
3.nabble.com/StreamingContext-textFileStream-question-tp10742.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.c=
om.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional com=
mands, e-mail: dev-help@spark.apache.org


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11742-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 19:34:08 2015
Return-Path: <dev-return-11742-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEFEB17439
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 19:34:08 +0000 (UTC)
Received: (qmail 84181 invoked by uid 500); 23 Feb 2015 19:34:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84111 invoked by uid 500); 23 Feb 2015 19:34:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84099 invoked by uid 99); 23 Feb 2015 19:34:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:34:06 +0000
X-ASF-Spam-Status: No, hits=1.3 required=10.0
	tests=URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: unknown (athena.apache.org: error in processing during lookup of mark.khaitman@chango.com)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:34:01 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id 2D37E14C62A0
	for <dev@spark.apache.org>; Mon, 23 Feb 2015 11:32:44 -0800 (PST)
Date: Mon, 23 Feb 2015 12:32:40 -0700 (MST)
From: mkhaitman <mark.khaitman@chango.com>
To: dev@spark.apache.org
Message-ID: <1424719960622-10745.post@n3.nabble.com>
In-Reply-To: <64474308D680D540A4D8151B0F7C03F70279D949@SHSMSX104.ccr.corp.intel.com>
References: <1424717611095-10742.post@n3.nabble.com> <64474308D680D540A4D8151B0F7C03F70279D949@SHSMSX104.ccr.corp.intel.com>
Subject: RE: StreamingContext textFileStream question
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Jerry,

Thanks for the quick response! Looks like I'll need to come up with an
alternative solution in the meantime,  since I'd like to avoid the other
input streams + WAL approach. :)

Thanks again,
Mark.



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/StreamingContext-textFileStream-question-tp10742p10745.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11743-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 19:37:17 2015
Return-Path: <dev-return-11743-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 79154174BA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 19:37:17 +0000 (UTC)
Received: (qmail 37771 invoked by uid 500); 23 Feb 2015 19:37:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37689 invoked by uid 500); 23 Feb 2015 19:37:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37444 invoked by uid 99); 23 Feb 2015 19:37:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:37:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.53 as permitted sender)
Received: from [209.85.213.53] (HELO mail-yh0-f53.google.com) (209.85.213.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:36:47 +0000
Received: by yhoa41 with SMTP id a41so11859233yho.9
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 11:36:45 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=ecVpVIbgniKNQr1joXfi6dtMKcM6jBlMMMYYfQ8CHEM=;
        b=rF1BrEovMA6Sn7Jh8LsAQllZiV0lxbqTT+Hfk58uOS+HNtLGO6MyPyjdGUeNFUl5qJ
         FSovQ+W3mh9SlhoVZ9frYnFdnj8M+dqqd6VU8nFkET+TzdtbfzNWXNoX8EWNvSugWsEs
         lpQRir/32FQdOCntpQZc7sXv6DuMxxyBE37p6YC8HuqLaFiWwAo3iah1bhCh1DTonk8C
         uGJSARP6nGOgRcZNscF7mxkRNEkwbmG07x6GAcZyZdoDfgXAMdIDlqrAzmNIb5b0/VB0
         sTrYJVD+e6TRMY9CZE4LKo6p6e1MlAxjds1eHm5qFf8euRR7tDqHZm4jMna5iQ0KjgsV
         HJZQ==
X-Received: by 10.236.208.36 with SMTP id p24mr11172582yho.1.1424720205375;
 Mon, 23 Feb 2015 11:36:45 -0800 (PST)
MIME-Version: 1.0
References: <CACdU-dSmHf6nGH-ovkoG2NZyQOQoKNK_jnY9B9z+McdywsVpbA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 23 Feb 2015 19:36:44 +0000
Message-ID: <CAOhmDzcPkLfH27-W+aSyHMDYqg+5WmL=XeuNjVgAj37m2Pr7fg@mail.gmail.com>
Subject: Re: [jenkins infra -- pls read ] installing anaconda, moving default
 python from 2.6 -> 2.7
To: shane knapp <sknapp@berkeley.edu>, amp-infra <amp-infra@googlegroups.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1c2acbeed18050fc685fb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1c2acbeed18050fc685fb
Content-Type: text/plain; charset=UTF-8

The first concern for Spark will probably be to ensure that we still build
and test against Python 2.6, since that's the minimum version of Python we
support.

Otherwise this seems OK. We use numpy and other Python packages in PySpark,
but I don't think we're pinned to any particular version of those packages.

Nick

On Mon Feb 23 2015 at 2:15:19 PM shane knapp <sknapp@berkeley.edu> wrote:

> good morning, developers!
>
> TL;DR:
>
> i will be installing anaconda and setting it in the system PATH so that
> your python will default to 2.7, as well as it taking over management of
> all of the sci-py packages.  this is potentially a big change, so i'll be
> testing locally on my staging instance before deployment to the wide world.
>
> deployment is *tentatively* next monday, march 2nd.
>
> a little background:
>
> the jenkins test infra is currently (and happily) managed by a set of tools
> that allow me to set up and deploy new workers, manage their packages and
> make sure that all spark and research projects can happily and successfully
> build.
>
> we're currently at the state where ~50 or so packages are installed and
> configured on each worker.  this is getting a little cumbersome, as the
> package-to-build dep tree is getting pretty large.
>
> the biggest offender is the science-based python infrastructure.
>  everything is blindly installed w/yum and pip, so it's hard to control
> *exactly* what version of any given library is as compared to what's on a
> dev's laptop.
>
> the solution:
>
> anaconda (https://store.continuum.io/cshop/anaconda/)!  everything is
> centralized!  i can manage specific versions much easier!
>
> what this means to you:
>
> * python 2.7 will be the default system python.
> * 2.6 will still be installed and available (/usr/bin/python or
> /usr/bin/python/2.6)
>
> what you need to do:
> * install anaconda, have it update your PATH
> * build locally and try to fix any bugs (for spark, this "should just
> work")
> * if you have problems, reach out to me and i'll see what i can do to help.
>  if we can't get your stuff running under python2.7, we can default to 2.6
> via a job config change.
>
> what i will be doing:
> * setting up anaconda on my staging instance and spot-testing a lot of
> builds before deployment
>
> please let me know if there are any issues/concerns...  i'll be posting
> updates this week and will let everyone know if there are any changes to
> the Plan[tm].
>
> your friendly devops engineer,
>
> shane
>

--001a11c1c2acbeed18050fc685fb--

From dev-return-11744-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 19:52:11 2015
Return-Path: <dev-return-11744-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 96BA917543
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 19:52:11 +0000 (UTC)
Received: (qmail 89631 invoked by uid 500); 23 Feb 2015 19:51:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89548 invoked by uid 500); 23 Feb 2015 19:51:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89537 invoked by uid 99); 23 Feb 2015 19:51:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:51:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 19:51:42 +0000
Received: by lbdu10 with SMTP id u10so20782368lbd.7
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 11:50:36 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ZtHKyZ0xYimUG+id91iIA1ss2Y/r5f4bE0/LuYUuR9o=;
        b=Q/anzgNJOBn+D0wJoyJfM8dh808FnLbUi0D6jQ81g7Iz2JEPd0b3pVu4FsUmcvk2eg
         /sWyYJj8FYKx28Q68/HftVAtOdYiHpCitRlUo5rTNbgXEreyWj8JC0Y5LPHl/zyslL75
         16bFzd60cQFfkv65byu2opBvdPIoIXmrhdhqQQaaCv+QEu42WGYoEfbMwbxaisyFRcgI
         GuGUldZRvL8A0VqQ3emTMfhv+4+VrKgiCDGMDjarWEriNL2Ljf6Np0U7OmWPo6fUnLtF
         t8/OiPlT2N3yUF5U8qnGXS5sFyRXa0AJ6PIYjtSeMeZ7nACYVH1SUueNVq7MoMPkVnCv
         wP2A==
X-Gm-Message-State: ALoCoQlfeVJMb+ppdREhovWGySEpH4AQ8Js/mUL/UKAJ3XVmNjuiIjWK8PC+n35YQQJfsOLuG1Tj
X-Received: by 10.152.5.193 with SMTP id u1mr11088500lau.96.1424721036431;
 Mon, 23 Feb 2015 11:50:36 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Mon, 23 Feb 2015 11:50:04 -0800 (PST)
In-Reply-To: <CAOhmDzcPkLfH27-W+aSyHMDYqg+5WmL=XeuNjVgAj37m2Pr7fg@mail.gmail.com>
References: <CACdU-dSmHf6nGH-ovkoG2NZyQOQoKNK_jnY9B9z+McdywsVpbA@mail.gmail.com>
 <CAOhmDzcPkLfH27-W+aSyHMDYqg+5WmL=XeuNjVgAj37m2Pr7fg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 23 Feb 2015 11:50:04 -0800
Message-ID: <CACdU-dTHQeEe+5FNwx4i7b6yosx9cErG8EtvyucDmon1CunP4A@mail.gmail.com>
Subject: Re: [jenkins infra -- pls read ] installing anaconda, moving default
 python from 2.6 -> 2.7
To: amp-infra <amp-infra@googlegroups.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013d174447e7c7050fc6b7f0
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d174447e7c7050fc6b7f0
Content-Type: text/plain; charset=UTF-8

On Mon, Feb 23, 2015 at 11:36 AM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> The first concern for Spark will probably be to ensure that we still build
> and test against Python 2.6, since that's the minimum version of Python we
> support.
>
> sounds good...  we can set up separate 2.6 builds on specific versions...
 this could allow you to easily differentiate between "baseline" and
"latest and greatest" if you wanted.  it'll have a little bit more
administrative overhead, due to more jobs needing configs, but offers more
flexibility.

let me know what you think.


> Otherwise this seems OK. We use numpy and other Python packages in
> PySpark, but I don't think we're pinned to any particular version of those
> packages.
>
> cool.  i'll start mucking about and let you guys know how it goes.

shane

--089e013d174447e7c7050fc6b7f0--

From dev-return-11745-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 20:20:50 2015
Return-Path: <dev-return-11745-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25D35176B2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 20:20:50 +0000 (UTC)
Received: (qmail 78782 invoked by uid 500); 23 Feb 2015 20:20:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78723 invoked by uid 500); 23 Feb 2015 20:20:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78712 invoked by uid 99); 23 Feb 2015 20:20:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 20:20:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 20:20:42 +0000
Received: by lbvn10 with SMTP id n10so21035870lbv.4
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 12:18:31 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=dOFcldezL97qYarQtrG+HzrEmOLLhqO09nZTKT3g+xQ=;
        b=Nd8P8rU2xSBno1oyXTt1+dlENx8wl7+2wpT0a7+pEtTtnv7F59I4sZQHUPwQSLbvCf
         v2ko0Wdyl8BiKB/+n0HcsPbL6/vnkeVWZ5nBUwTZ9CCbe8ksp5unAXlNTzACDTMUVj/m
         gUoVvu/hdHRvbbQ7iqkmVBt6nivBiEWEntRAnlx1dQXovMf/N+uNCfjNj1rmoSLA237l
         Ah+xlc1pCmJtaidNwE+dCvBfGX/xRTwlip9fQlGt8LRQ7EEsj58V5YZ2SDwZALg3SB/0
         hrtaUgi9BjEQO8RIfTFtM4Mz5LnilCjKkDksuTl3Aq0hXFmbitt23pYSP/CLKCEE6GUi
         ES1w==
X-Gm-Message-State: ALoCoQkiouhsqKSu+3y7SAiOT/qFWdvtP7JOWOSFudUcTlTlwwXwwAov+mpmp3zwzwPG0Io+he4q
X-Received: by 10.112.73.65 with SMTP id j1mr11235283lbv.87.1424722711008;
 Mon, 23 Feb 2015 12:18:31 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.213.18 with HTTP; Mon, 23 Feb 2015 12:18:08 -0800 (PST)
In-Reply-To: <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Mon, 23 Feb 2015 12:18:08 -0800
Message-ID: <CAAswR-40cnNpp=vhA5_Gz0Kx2O7N6r5Nqhp2YLRAUSCS3Qwtqw@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Mark Hamstra <mark@clearstorydata.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c33ea217e12c050fc71bab
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c33ea217e12c050fc71bab
Content-Type: text/plain; charset=UTF-8

On Sun, Feb 22, 2015 at 11:20 PM, Mark Hamstra <mark@clearstorydata.com>
wrote:

> So what are we expecting of Hive 0.12.0 builds with this RC?  I know not
> every combination of Hadoop and Hive versions, etc., can be supported, but
> even an example build from the "Building Spark" page isn't looking too good
> to me.
>

I would definitely expect this to build and we do actually test that for
each PR.  We don't yet run the tests for both versions of Hive and thus
unfortunately these do get out of sync.  Usually these are just problems
diff-ing golden output or cases where we have added a test that uses a
feature not available in hive 12.

Have you seen problems with using Hive 12 outside of these test failures?

--001a11c33ea217e12c050fc71bab--

From dev-return-11746-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Feb 23 20:32:05 2015
Return-Path: <dev-return-11746-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DF12517721
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 23 Feb 2015 20:32:04 +0000 (UTC)
Received: (qmail 9869 invoked by uid 500); 23 Feb 2015 20:32:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9792 invoked by uid 500); 23 Feb 2015 20:32:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9781 invoked by uid 99); 23 Feb 2015 20:32:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 20:32:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 23 Feb 2015 20:31:59 +0000
Received: by mail-wi0-f182.google.com with SMTP id l15so20419100wiw.3
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 12:30:53 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=sxDYiDxV9cKZoLQUTU8BvP+y754oHOxloJIr/8qs/qE=;
        b=i8V1Wp0cu1tHVb6brkDVO+P+a0OJ37d6VhfzNkohS8YE+4EzWo487LXSQAMy4pMpGc
         YWFXPeDjirGGCYgUFvc27K+c1Wy/iNAH4Q6DF1iJqNiKdWISWGK4EUndVhb010S3gmtW
         4YLTMzQkwMcBIu0yHQKMx8GyCd+5IsWLOHt2lSEzp78v5/AtnQI5/ykC/s/NTOPXMfcJ
         hKSlENNO4BlVYFexasvVd99TfOJKHEwuh4vKqXxnHgDzZxGQGWMtYDK9WC+EtNAQ0zsl
         NXcEzneoDzNLpXIYA4M8PKEgqPwDxEqMmTlbQBaUjS1ljpyRl86kLGZwVRVAlaszzgi9
         4NDA==
X-Gm-Message-State: ALoCoQl47iI71fEW3yWzbpG2L4btuNDvWZhM5sb2BiZnO1IjastRNTEJGwsMkwxvlIp8lCTmO+Ua
MIME-Version: 1.0
X-Received: by 10.194.108.162 with SMTP id hl2mr25213250wjb.81.1424723453233;
 Mon, 23 Feb 2015 12:30:53 -0800 (PST)
Received: by 10.194.153.202 with HTTP; Mon, 23 Feb 2015 12:30:53 -0800 (PST)
In-Reply-To: <CAAswR-40cnNpp=vhA5_Gz0Kx2O7N6r5Nqhp2YLRAUSCS3Qwtqw@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com>
	<CAAswR-40cnNpp=vhA5_Gz0Kx2O7N6r5Nqhp2YLRAUSCS3Qwtqw@mail.gmail.com>
Date: Mon, 23 Feb 2015 12:30:53 -0800
Message-ID: <CAAsvFPm=h=za_cXb9=9i5puqXPD8LjQUBvYw08HN5-gUcyYagg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Mark Hamstra <mark@clearstorydata.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0102f212556166050fc747d4
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0102f212556166050fc747d4
Content-Type: text/plain; charset=UTF-8

Nothing that I can point to, so this may only be a problem in test scope.
I am looking at a problem where some UDFs that run with 0.12 fail with
0.13; but that problem is already present in Spark 1.2.x, so it's not a
blocking regression for 1.3.  (Very likely a HiveFunctionWrapper serde
problem, but I haven't run it to ground yet.)

On Mon, Feb 23, 2015 at 12:18 PM, Michael Armbrust <michael@databricks.com>
wrote:

> On Sun, Feb 22, 2015 at 11:20 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
>
>> So what are we expecting of Hive 0.12.0 builds with this RC?  I know not
>> every combination of Hadoop and Hive versions, etc., can be supported, but
>> even an example build from the "Building Spark" page isn't looking too
>> good
>> to me.
>>
>
> I would definitely expect this to build and we do actually test that for
> each PR.  We don't yet run the tests for both versions of Hive and thus
> unfortunately these do get out of sync.  Usually these are just problems
> diff-ing golden output or cases where we have added a test that uses a
> feature not available in hive 12.
>
> Have you seen problems with using Hive 12 outside of these test failures?
>

--089e0102f212556166050fc747d4--

From dev-return-11747-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 02:46:48 2015
Return-Path: <dev-return-11747-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A7C9D1071C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 02:46:48 +0000 (UTC)
Received: (qmail 5299 invoked by uid 500); 24 Feb 2015 02:46:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5226 invoked by uid 500); 24 Feb 2015 02:46:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5213 invoked by uid 99); 24 Feb 2015 02:46:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 02:46:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.52 as permitted sender)
Received: from [209.85.220.52] (HELO mail-pa0-f52.google.com) (209.85.220.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 02:46:37 +0000
Received: by padbj1 with SMTP id bj1so32393466pad.5
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 18:45:32 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=uDHvnzXF60t3zPfPvsVmN0XTolm+LOAz+BynRNzloL4=;
        b=vH8eHQyo6XmL2kBwnhziriYMbZHasv1LofP3+cZKlaYEVukxw2M7AQy6yy9g6khcfH
         E7nnk294p4K1ip9gwCoyc7SSkAE0IAbThSfwuC+HMJnH/m6iVSc+kUM7DO/mDiKQ5v5G
         DSzh5fXulb8YWibpxLst2pkRJzruDPXv3wH9aIsMPkJbrXawgitzfsw3uI24b0kYGPMn
         Pjil8jjEgTOrX2JKPsdakm7ixo8yuM4Rmxu6X7tMnlUORnhv6eLQLWhj8LsHeZR1mJYm
         qt5oPJCF+7lr3hU92ZZQTRGjEPQEpPYqeSl8N0/vpEScAW6t2hxocP+hpP983EBblUwh
         limg==
X-Received: by 10.66.123.73 with SMTP id ly9mr25532377pab.105.1424745931981;
        Mon, 23 Feb 2015 18:45:31 -0800 (PST)
Received: from [10.10.0.4] ([104.156.239.73])
        by mx.google.com with ESMTPSA id ua7sm37566192pab.37.2015.02.23.18.45.29
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 23 Feb 2015 18:45:31 -0800 (PST)
Message-ID: <54EBE5C8.8090907@gmail.com>
Date: Tue, 24 Feb 2015 10:45:28 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: Michael Armbrust <michael@databricks.com>, 
 Mark Hamstra <mark@clearstorydata.com>
CC: Patrick Wendell <pwendell@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com> <CAAsvFP=DQJTvL9zoG3mucEgV-YmXFa5dZXDfX-asg+SRhjEggg@mail.gmail.com> <CAAswR-40cnNpp=vhA5_Gz0Kx2O7N6r5Nqhp2YLRAUSCS3Qwtqw@mail.gmail.com>
In-Reply-To: <CAAswR-40cnNpp=vhA5_Gz0Kx2O7N6r5Nqhp2YLRAUSCS3Qwtqw@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

My bad, had once fixed all Hive 12 test failures in PR #4107, but didn't 
got time to get it merged.

Considering the release is close, I can cherry-pick those Hive 12 fixes 
from #4107 and open a more surgical PR soon.

Cheng

On 2/24/15 4:18 AM, Michael Armbrust wrote:
> On Sun, Feb 22, 2015 at 11:20 PM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
>
>> So what are we expecting of Hive 0.12.0 builds with this RC?  I know not
>> every combination of Hadoop and Hive versions, etc., can be supported, but
>> even an example build from the "Building Spark" page isn't looking too good
>> to me.
>>
> I would definitely expect this to build and we do actually test that for
> each PR.  We don't yet run the tests for both versions of Hive and thus
> unfortunately these do get out of sync.  Usually these are just problems
> diff-ing golden output or cases where we have added a test that uses a
> feature not available in hive 12.
>
> Have you seen problems with using Hive 12 outside of these test failures?
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11748-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 03:10:10 2015
Return-Path: <dev-return-11748-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0CEF3107EC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 03:10:10 +0000 (UTC)
Received: (qmail 25533 invoked by uid 500); 24 Feb 2015 03:10:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25439 invoked by uid 500); 24 Feb 2015 03:10:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25427 invoked by uid 99); 24 Feb 2015 03:10:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 03:10:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.192.171 as permitted sender)
Received: from [209.85.192.171] (HELO mail-pd0-f171.google.com) (209.85.192.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 03:09:37 +0000
Received: by pdev10 with SMTP id v10so30022339pde.10
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 19:08:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type;
        bh=jZNBgmryMNHQ8QX+sA38RoyScO+qB6x98MniGalLPYA=;
        b=F9Zi/wRThexUWaxh6OGro5mqKvL69WpUy1gmab+7AW93XeBKOzAhCW6GsnOrb5hqp/
         Wv7rsRHBDuIIsOicYHtD4RByMJTAxdgzrqkJ2MnXWGe3BsMoEmeL35+KDUhp0I4JzjnO
         BbcJJw5dDEOg6J2TBApcKLCY1MEOVlJu+pxmzZD2J+vnKplnSpXpsgFqBJQ0I+t9IeDE
         FjzOfNKytkOjwXlt9fQNpzhSDS0cEzVkphhvcKkpqJBxDh4otV3VtN0GXDXmA+DLpmkr
         aasTQJZfov0FFgaAR7C/b3v7GNqtlHUq+g8AYv1VIjBFinodHvXqNDtl94vB4uLRPMm+
         oxYw==
X-Received: by 10.66.124.164 with SMTP id mj4mr25690132pab.83.1424747330275;
        Mon, 23 Feb 2015 19:08:50 -0800 (PST)
Received: from [10.10.0.4] ([104.156.239.73])
        by mx.google.com with ESMTPSA id cz1sm37325434pdb.32.2015.02.23.19.08.47
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 23 Feb 2015 19:08:49 -0800 (PST)
Message-ID: <54EBEB3D.4010504@gmail.com>
Date: Tue, 24 Feb 2015 11:08:45 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: The Watcher <watcherfr@gmail.com>, dev@spark.apache.org
Subject: Re: Spark SQL, Hive & Parquet data types
References: <CAHwsXYmmwjWBq2QjdbgHFxk5O9kbFtJiqVwx1MMN39gxV9zh_g@mail.gmail.com>	<54E73A53.2020100@gmail.com>	<CAHwsXYmB8XPL0vMzp6kh9ik-vwDxnz-XS4VbMSfhc7gnzixd3g@mail.gmail.com>	<54EB1C51.4090308@gmail.com> <CAHwsXYkWmRsoZShHAe7_K9r1JdujToYrUZ2ZwDiqjrRrcU4dhA@mail.gmail.com>
In-Reply-To: <CAHwsXYkWmRsoZShHAe7_K9r1JdujToYrUZ2ZwDiqjrRrcU4dhA@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------020105050106050705000005"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------020105050106050705000005
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Ah, sorry for not being clear enough.

So now in Spark 1.3.0, we have two Parquet support implementations, the 
old one is tightly coupled with the Spark SQL framework, while the new 
one is based on data sources API. In both versions, we try to intercept 
operations over Parquet tables registered in metastore when possible for 
better performance (mainly filter push-down optimization and extra 
metadata for more accurate schema inference). The distinctions are:

 1.

    For old version (set |spark.sql.parquet.useDataSourceApi| to |false|)

    When |spark.sql.hive.convertMetastoreParquet| is set to |true|, we
    “hijack” the read path. Namely whenever you query a Parquet table
    registered in metastore, we’re using our own Parquet implementation.

    For write path, we fallback to default Hive SerDe implementation
    (namely Spark SQL’s |InsertIntoHiveTable| operator).

 2.

    For new data source version (set
    |spark.sql.parquet.useDataSourceApi| to |true|, which is the default
    value in master and branch-1.3)

    When |spark.sql.hive.convertMetastoreParquet| is set to |true|, we
    “hijack” both read and write path, but if you’re writing to a
    partitioned table, we still fallback to default Hive SerDe
    implementation.

For Spark 1.2.0, only 1 applies. Spark 1.2.0 also has a Parquet data 
source, but it’s not enabled if you’re not using data sources API 
specific DDL (|CREATE TEMPORARY TABLE <table-name> USING <data-source>|).

Cheng

On 2/23/15 10:05 PM, The Watcher wrote:

>> Yes, recently we improved ParquetRelation2 quite a bit. Spark SQL uses its
>> own Parquet support to read partitioned Parquet tables declared in Hive
>> metastore. Only writing to partitioned tables is not covered yet. These
>> improvements will be included in Spark 1.3.0.
>>
>> Just created SPARK-5948 to track writing to partitioned Parquet tables.
>>
> Ok, this is still a little confusing.
>
> Since I am able in 1.2.0 to write to a partitioned Hive by registering my
> SchemaRDD and calling INSERT into "the hive partitionned table" SELECT "the
> registrered", what is the write-path in this case ? Full Hive with a
> SparkSQL<->Hive bridge ?
> If that were the case, why wouldn't SKEWED ON be honored (see another
> thread I opened).
>
> Thanks
>
​

--------------020105050106050705000005--

From dev-return-11749-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 03:24:52 2015
Return-Path: <dev-return-11749-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 88B4A10A80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 03:24:52 +0000 (UTC)
Received: (qmail 86814 invoked by uid 500); 24 Feb 2015 03:24:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86738 invoked by uid 500); 24 Feb 2015 03:24:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86723 invoked by uid 99); 24 Feb 2015 03:24:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 03:24:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kumar.soumitra@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 03:24:25 +0000
Received: by mail-oi0-f52.google.com with SMTP id u20so17180945oif.11
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 19:23:38 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=W1llWeWV75aDag8MIwUYWaYpop804Q/GmyS0/Airf8c=;
        b=Rjm7YopHsMML+vlDbStFqIh+hhNOvE0UXDMDxxCChm0QFIigtBO4oZilJB/hNqfuB6
         8FORlihPzK/IXrNcKfP4aQHIO7Axb0fBL0Dyemgv9cBfJVbCWtgnJl3NrBkKInnUs9r7
         kKlUTFffWHDBiKMnR4iS5IoAgdUSJdHdrvHWZmy1L5/0XXM2fjccXsntD1BP+EvFk9xl
         eMnR6SBV6D7sQ9nwiBkGQcNMGX+8lQauIA4bsHUnODi1i8j1VQmKmm8afZQbKToFHkel
         yRFuASwWwqHBTiSb8TEI+f7+Pw8U7BNkwnsmfiBluCmEHW+BN7y54n2WMu03TgI8IWh/
         oxlA==
MIME-Version: 1.0
X-Received: by 10.202.67.132 with SMTP id q126mr9109522oia.15.1424748218695;
 Mon, 23 Feb 2015 19:23:38 -0800 (PST)
Received: by 10.202.5.21 with HTTP; Mon, 23 Feb 2015 19:23:38 -0800 (PST)
In-Reply-To: <CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
	<CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com>
Date: Mon, 23 Feb 2015 19:23:38 -0800
Message-ID: <CAMORY85Tzd7b70LdTUixzNghM_8cwmM=Gh3HOq623SnH+q3yhg@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Soumitra Kumar <kumar.soumitra@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113cbcea7846c8050fcd0b0a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cbcea7846c8050fcd0b0a
Content-Type: text/plain; charset=UTF-8

+1 (non-binding)

For: https://issues.apache.org/jira/browse/SPARK-3660

. Docs OK
. Example code is good

-Soumitra.


On Mon, Feb 23, 2015 at 10:33 AM, Marcelo Vanzin <vanzin@cloudera.com>
wrote:

> Hi Tom, are you using an sbt-built assembly by any chance? If so, take
> a look at SPARK-5808.
>
> I haven't had any problems with the maven-built assembly. Setting
> SPARK_HOME on the executors is a workaround if you want to use the sbt
> assembly.
>
> On Fri, Feb 20, 2015 at 2:56 PM, Tom Graves
> <tgraves_cs@yahoo.com.invalid> wrote:
> > Trying to run pyspark on yarn in client mode with basic wordcount
> example I see the following error when doing the collect:
> > Error from python worker:  /usr/bin/python: No module named
> sqlPYTHONPATH was:
> /grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-assembly-1.3.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException
>       at java.io.DataInputStream.readInt(DataInputStream.java:392)
> at
> org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:163)
>       at
> org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:86)
>       at
> org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)
>       at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:105)
>       at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:69)
>       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
>     at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
> org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:308)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
>       at
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
>       at org.apache.spark.scheduler.Task.run(Task.scala:64)        at
> org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:197)
>   at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
>       at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
>       at java.lang.Thread.run(Thread.java:722)
> > any ideas on this?
> > Tom
> >
> >      On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <
> pwendell@gmail.com> wrote:
> >
> >
> >  Please vote on releasing the following candidate as Apache Spark
> version 1.3.0!
> >
> > The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=f97b0d4a6b26504916816d7aefcf3132cd1da6c2
> >
> > The release files, including signatures, digests, etc. can be found at:
> > http://people.apache.org/~pwendell/spark-1.3.0-rc1/
> >
> > Release artifacts are signed with the following key:
> > https://people.apache.org/keys/committer/pwendell.asc
> >
> > The staging repository for this release can be found at:
> > https://repository.apache.org/content/repositories/orgapachespark-1069/
> >
> > The documentation corresponding to this release can be found at:
> > http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
> >
> > Please vote on releasing this package as Apache Spark 1.3.0!
> >
> > The vote is open until Saturday, February 21, at 08:03 UTC and passes
> > if a majority of at least 3 +1 PMC votes are cast.
> >
> > [ ] +1 Release this package as Apache Spark 1.3.0
> > [ ] -1 Do not release this package because ...
> >
> > To learn more about Apache Spark, please see
> > http://spark.apache.org/
> >
> > == How can I help test this release? ==
> > If you are a Spark user, you can help us test this release by
> > taking a Spark 1.2 workload and running on this release candidate,
> > then reporting any regressions.
> >
> > == What justifies a -1 vote for this release? ==
> > This vote is happening towards the end of the 1.3 QA period,
> > so -1 votes should only occur for significant regressions from 1.2.1.
> > Bugs already present in 1.2.X, minor regressions, or bugs related
> > to new features will not block this release.
> >
> > - Patrick
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
> >
> >
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113cbcea7846c8050fcd0b0a--

From dev-return-11750-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 06:54:36 2015
Return-Path: <dev-return-11750-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E85361723E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 06:54:35 +0000 (UTC)
Received: (qmail 37978 invoked by uid 500); 24 Feb 2015 06:54:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37910 invoked by uid 500); 24 Feb 2015 06:54:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37897 invoked by uid 99); 24 Feb 2015 06:54:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 06:54:24 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tathagata.das1565@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 06:54:20 +0000
Received: by iecrl12 with SMTP id rl12so29750773iec.4
        for <dev@spark.apache.org>; Mon, 23 Feb 2015 22:53:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=NK28sI8G83hOqxwgYiBr30dgBP+R6QA5bHY9WVd12fo=;
        b=eH1ePnvSfOgTLqxaFHQ3ghPySUfqyLuQPBviRw1WczcUW9N8Mcj2MY34d/ezz0BUUl
         QAfZaC8omdPKTjzlkgftJ0o5aVEZeZrUSiNsxw/BQ35lNusFrPcIfvQaOmQ4BxI/ihP0
         L6BdpHpdHJJG62Bad8bW/IrGZTNnnWs6MnS0FlBsJycalRdjrPaEaBy16Dnm5VLKeD0y
         HrP/yze/akPX8Eis8uOWQMETEsE3qQh269A8giPzg9FAMj5QwSeC94kLhCbTk7LS6XqC
         CFRCLq1No+RSA1XA+ZV2FzhL77Y0dZhFfzAptBxcxq+QjSYa8/v+sxetYq7ApUnX8V0B
         qgSA==
X-Received: by 10.107.3.161 with SMTP id e33mr19261182ioi.65.1424760794799;
 Mon, 23 Feb 2015 22:53:14 -0800 (PST)
MIME-Version: 1.0
Received: by 10.107.57.66 with HTTP; Mon, 23 Feb 2015 22:52:44 -0800 (PST)
In-Reply-To: <CAMORY85Tzd7b70LdTUixzNghM_8cwmM=Gh3HOq623SnH+q3yhg@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
 <CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com> <CAMORY85Tzd7b70LdTUixzNghM_8cwmM=Gh3HOq623SnH+q3yhg@mail.gmail.com>
From: Tathagata Das <tathagata.das1565@gmail.com>
Date: Mon, 23 Feb 2015 22:52:44 -0800
Message-ID: <CAMwrk0=o9dwFQ7p=VBSK984dtVBaHt2bJOmGk8aGfsL56AB=tA@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
To: Soumitra Kumar <kumar.soumitra@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113ebe5c106764050fcff997
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113ebe5c106764050fcff997
Content-Type: text/plain; charset=UTF-8

Hey all,

I found a major issue where JobProgressListener (a listener used to keep
track of jobs for the web UI) never forgets stages in one of its data
structures. This is a blocker for long running applications.
https://issues.apache.org/jira/browse/SPARK-5967

I am testing a fix for this right now.

TD

On Mon, Feb 23, 2015 at 7:23 PM, Soumitra Kumar <kumar.soumitra@gmail.com>
wrote:

> +1 (non-binding)
>
> For: https://issues.apache.org/jira/browse/SPARK-3660
>
> . Docs OK
> . Example code is good
>
> -Soumitra.
>
>
> On Mon, Feb 23, 2015 at 10:33 AM, Marcelo Vanzin <vanzin@cloudera.com>
> wrote:
>
> > Hi Tom, are you using an sbt-built assembly by any chance? If so, take
> > a look at SPARK-5808.
> >
> > I haven't had any problems with the maven-built assembly. Setting
> > SPARK_HOME on the executors is a workaround if you want to use the sbt
> > assembly.
> >
> > On Fri, Feb 20, 2015 at 2:56 PM, Tom Graves
> > <tgraves_cs@yahoo.com.invalid> wrote:
> > > Trying to run pyspark on yarn in client mode with basic wordcount
> > example I see the following error when doing the collect:
> > > Error from python worker:  /usr/bin/python: No module named
> > sqlPYTHONPATH was:
> >
> /grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-assembly-1.3.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException
> >       at java.io.DataInputStream.readInt(DataInputStream.java:392)
> > at
> >
> org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:163)
> >       at
> >
> org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:86)
> >       at
> >
> org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)
> >       at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:105)
> >       at
> org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:69)
> >       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
> >     at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
> > org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:308)
> > at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
> > at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
> >
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
> >       at
> >
> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
> >       at org.apache.spark.scheduler.Task.run(Task.scala:64)        at
> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:197)
> >   at
> >
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> >       at
> >
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> >       at java.lang.Thread.run(Thread.java:722)
> > > any ideas on this?
> > > Tom
> > >
> > >      On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <
> > pwendell@gmail.com> wrote:
> > >
> > >
> > >  Please vote on releasing the following candidate as Apache Spark
> > version 1.3.0!
> > >
> > > The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
> > >
> >
> https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=f97b0d4a6b26504916816d7aefcf3132cd1da6c2
> > >
> > > The release files, including signatures, digests, etc. can be found at:
> > > http://people.apache.org/~pwendell/spark-1.3.0-rc1/
> > >
> > > Release artifacts are signed with the following key:
> > > https://people.apache.org/keys/committer/pwendell.asc
> > >
> > > The staging repository for this release can be found at:
> > >
> https://repository.apache.org/content/repositories/orgapachespark-1069/
> > >
> > > The documentation corresponding to this release can be found at:
> > > http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
> > >
> > > Please vote on releasing this package as Apache Spark 1.3.0!
> > >
> > > The vote is open until Saturday, February 21, at 08:03 UTC and passes
> > > if a majority of at least 3 +1 PMC votes are cast.
> > >
> > > [ ] +1 Release this package as Apache Spark 1.3.0
> > > [ ] -1 Do not release this package because ...
> > >
> > > To learn more about Apache Spark, please see
> > > http://spark.apache.org/
> > >
> > > == How can I help test this release? ==
> > > If you are a Spark user, you can help us test this release by
> > > taking a Spark 1.2 workload and running on this release candidate,
> > > then reporting any regressions.
> > >
> > > == What justifies a -1 vote for this release? ==
> > > This vote is happening towards the end of the 1.3 QA period,
> > > so -1 votes should only occur for significant regressions from 1.2.1.
> > > Bugs already present in 1.2.X, minor regressions, or bugs related
> > > to new features will not block this release.
> > >
> > > - Patrick
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> > >
> > >
> >
> >
> >
> > --
> > Marcelo
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a113ebe5c106764050fcff997--

From dev-return-11751-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 08:41:45 2015
Return-Path: <dev-return-11751-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D2A7117590
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 08:41:45 +0000 (UTC)
Received: (qmail 54512 invoked by uid 500); 24 Feb 2015 08:41:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54329 invoked by uid 500); 24 Feb 2015 08:41:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53464 invoked by uid 99); 24 Feb 2015 08:41:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 08:41:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of judynash@exchange.microsoft.com designates 157.55.158.29 as permitted sender)
Received: from [157.55.158.29] (HELO na01-sn2-obe.outbound.o365filtering.com) (157.55.158.29)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 08:41:10 +0000
Received: from CH1SR0101CA0027.namsdf01.sdf.exchangelabs.com (25.160.11.37) by
 CH1SR0101MB0026.namsdf01.sdf.exchangelabs.com (25.160.12.16) with Microsoft
 SMTP Server (TLS) id 15.1.112.3; Tue, 24 Feb 2015 08:41:05 +0000
Received: from SN2FFOFD004.ffo.gbl (2a01:111:f400:7c04::23) by
 CH1SR0101CA0027.outlook.office365.com (2a01:111:e400:1803::37) with Microsoft
 SMTP Server (TLS) id 15.1.106.2 via Frontend Transport; Tue, 24 Feb 2015
 08:41:05 +0000
Received: from hybrid.exchange.microsoft.com (131.107.159.99) by
 SN2FFOFD004.mail.o365filtering.com (10.111.201.41) with Microsoft SMTP Server
 (TLS) id 15.1.99.4 via Frontend Transport; Tue, 24 Feb 2015 08:41:05 +0000
Received: from DFM-TK5MBX15-03.exchange.corp.microsoft.com (157.54.110.22) by
 DFM-TK5EDG15-01.exchange.corp.microsoft.com (157.54.27.96) with Microsoft
 SMTP Server (TLS) id 15.0.1044.22; Tue, 24 Feb 2015 08:40:59 +0000
Received: from DFM-DB3MBX15-06.exchange.corp.microsoft.com (10.221.24.76) by
 DFM-TK5MBX15-03.exchange.corp.microsoft.com (157.54.110.22) with Microsoft
 SMTP Server (TLS) id 15.0.1076.7; Tue, 24 Feb 2015 00:40:57 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com (10.221.24.69) by
 DFM-DB3MBX15-06.exchange.corp.microsoft.com (10.221.24.76) with Microsoft
 SMTP Server (TLS) id 15.0.1076.7; Tue, 24 Feb 2015 00:40:49 -0800
Received: from DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.62])
 by DFM-DB3MBX15-08.exchange.corp.microsoft.com ([169.254.12.62]) with mapi id
 15.00.1076.000; Tue, 24 Feb 2015 00:40:49 -0800
From: Judy Nash <judynash@exchange.microsoft.com>
To: Judy Nash <judynash@exchange.microsoft.com>, Akhil Das
	<akhil@sigmoidanalytics.com>, "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: RE: spark slave cannot execute without admin permission on windows
Thread-Topic: spark slave cannot execute without admin permission on windows
Thread-Index: AdBMCAvnHuIzNb6pTcGrUb56hu+fJwASfPQAAA4dOWAA4KZnMA==
Date: Tue, 24 Feb 2015 08:40:48 +0000
Message-ID: <14052b11efca4ffdaeb64e0ed224ac86@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
References: <27b07c69a933418f974ddbd7620a757c@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
 <CAHUQ+_bEWyA_a9=QhZdL63rs9e=k5n+cgQ-kz7Hu-B6vNKB69g@mail.gmail.com>
 <014bc325f40f43b1937f2f3db4fc6cd3@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
In-Reply-To: <014bc325f40f43b1937f2f3db4fc6cd3@DFM-DB3MBX15-08.exchange.corp.microsoft.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [157.59.235.233]
Content-Type: multipart/related;
	boundary="_005_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_";
	type="multipart/alternative"
MIME-Version: 1.0
X-EOPAttributedMessage: 0
X-Forefront-Antispam-Report:
	CIP:131.107.159.99;IPV:NLI;EFV:NLI;SFV:NSPM;SFS:(10019020)(189002)(24454002)(164054003)(69234005)(199003)(377454003)(2900100001)(2950100001)(66926002)(19625215002)(66066001)(64706001)(77156002)(108616004)(62966003)(68736005)(102836002)(18206015028)(92566002)(92726002)(15975445007)(97736003)(19300405004)(2501003)(16601075003)(67866002)(46102003)(86362001)(76176999)(54356999)(50986999)(33646002)(19617315012)(19627595001)(512874002)(105596002)(16236675004)(17760045003)(106466001)(84326002)(575784001)(1511001)(19580395003)(19580405001)(99936001)(6806004)(87936001)(2656002)(50919005)(24736002)(562774006);DIR:OUT;SFP:1102;SCL:1;SRVR:CH1SR0101MB0026;H:hybrid.exchange.microsoft.com;FPR:;SPF:SoftFail;PTR:InfoDomainNonexistent;MX:1;A:1;LANG:en;
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:CH1SR0101MB0026;
X-Microsoft-Antispam-PRVS:
	<CH1SR0101MB00267A5A2363EA284C804FF3B0160@CH1SR0101MB0026.namsdf01.sdf.exchangelabs.com>
X-Exchange-Antispam-Report-Test: UriScan:(193850556364327);
X-Exchange-Antispam-Report-CFA-Test:
	BCL:0;PCL:0;RULEID:(5005002)(2003001);SRVR:CH1SR0101MB0026;BCL:0;PCL:0;RULEID:;SRVR:CH1SR0101MB0026;
X-Forefront-PRVS: 04976078F0
Received-SPF: SoftFail (protection.outlook.com: domain of transitioning
 exchange.microsoft.com discourages use of 131.107.159.99 as permitted sender)
Authentication-Results: spf=softfail (sender IP is 131.107.159.99)
 smtp.mailfrom=judynash@exchange.microsoft.com; 
X-OriginatorOrg: exchange.microsoft.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 24 Feb 2015 08:41:05.1995
 (UTC)
X-MS-Exchange-CrossTenant-Id: f686d426-8d16-42db-81b7-ab578e110ccd
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f686d426-8d16-42db-81b7-ab578e110ccd;Ip=[131.107.159.99]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CH1SR0101MB0026
X-Virus-Checked: Checked by ClamAV on apache.org

--_005_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_
Content-Type: multipart/alternative;
	boundary="_000_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_"

--_000_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_
Content-Type: text/html; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_--

--_005_14052b11efca4ffdaeb64e0ed224ac86DFMDB3MBX1508exchangeco_--

From dev-return-11752-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 15:47:24 2015
Return-Path: <dev-return-11752-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0417B1751B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 15:47:24 +0000 (UTC)
Received: (qmail 2480 invoked by uid 500); 24 Feb 2015 15:47:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2398 invoked by uid 500); 24 Feb 2015 15:47:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2382 invoked by uid 99); 24 Feb 2015 15:47:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 15:47:22 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of nitin2goyal@gmail.com does not designate 162.253.133.43 as permitted sender)
Received: from [162.253.133.43] (HELO mwork.nabble.com) (162.253.133.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 15:46:56 +0000
Received: from mben.nabble.com (unknown [162.253.133.72])
	by mwork.nabble.com (Postfix) with ESMTP id AE23414DE76F
	for <dev@spark.apache.org>; Tue, 24 Feb 2015 07:46:54 -0800 (PST)
Date: Tue, 24 Feb 2015 08:46:54 -0700 (MST)
From: nitin <nitin2goyal@gmail.com>
To: dev@spark.apache.org
Message-ID: <1424792814131-10755.post@n3.nabble.com>
Subject: Does Spark delete shuffle files of lost executor in running
 system(on YARN)?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi All,

I noticed that Spark doesn't delete local shuffle files of a lost executor
in a running system(running in yarn-client mode). For long running system,
this might fill up disk space in case of frequent executor failures. Can we
delete these files when executor loss reported to driver?

Thanks
-Nitin



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Does-Spark-delete-shuffle-files-of-lost-executor-in-running-system-on-YARN-tp10755.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11753-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 21:33:47 2015
Return-Path: <dev-return-11753-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 14E44177A5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 21:33:47 +0000 (UTC)
Received: (qmail 46347 invoked by uid 500); 24 Feb 2015 21:33:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46273 invoked by uid 500); 24 Feb 2015 21:33:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46249 invoked by uid 99); 24 Feb 2015 21:33:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 21:33:45 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.182 as permitted sender)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 21:33:41 +0000
Received: by iecvy18 with SMTP id vy18so35716252iec.13
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 13:33:20 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=GqaGkszHjf2AHq5l9ULW6gMBknxkhCq4b/9iur98MDg=;
        b=NuXLtiW6AK6BQoN6De1IHxo9feBW+dZoq+2RtJmU0eOGQST03LH10p27ALB8jwWfOM
         Qqv72xes6NU8jidQF6bXAzrFAvzmfsjYx64nBpIVKjPoPwSap28Tk+DzcyDP8BUZtRed
         Pyg/K78RTnysj5ln71OIfaYy7HXWiUIU3Uhm+TKBAB3BkNjYSCLN7kStLFknj8qqPhNi
         5ucCWxYG2Idyz4/aGfnS/RJGOaHc8EdMG/2vDrO5Fat0twaEw/P4XyXJuajDAbVIMxfC
         +73x7QHuOG5MiNTvpMJ85Rmu/YElJ3cXfd66kVy3rZfvUIJkKlLHVadnMMKfCEUlfJTI
         Gtwg==
MIME-Version: 1.0
X-Received: by 10.50.25.225 with SMTP id f1mr336477igg.29.1424813600818; Tue,
 24 Feb 2015 13:33:20 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Tue, 24 Feb 2015 13:33:20 -0800 (PST)
In-Reply-To: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
Date: Tue, 24 Feb 2015 13:33:20 -0800
Message-ID: <CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
Subject: Re: Google Summer of Code - ideas
From: Xiangrui Meng <mengxr@gmail.com>
To: Manoj Kumar <manojkumarsivaraj334@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Would you be interested in working on MLlib's Python API during the
summer? We want everything we implemented in Scala can be used in both
Java and Python, but we are not there yet. It would be great if
someone is willing to help. -Xiangrui

On Sat, Feb 21, 2015 at 11:24 AM, Manoj Kumar
<manojkumarsivaraj334@gmail.com> wrote:
> Hello,
>
> I've been working on the Spark codebase for quite some time right now,
> especially on issues related to MLlib and a very small amount of PySpark
> and SparkSQL (https://github.com/apache/spark/pulls/MechCoder) .
>
> I would like to extend my work with Spark as a Google Summer of Code
> project.
> I want to know if there are specific projects related to MLlib that people
> would like to see. (I notice, there is no idea page for GSoC yet). There
> are a number of issues related to DecisionTrees, Ensembles, LDA (in the
> issue tracker) that I find really interesting that could probably club into
> a project, but if the spark community has anything else in mind, I could
> work on the other issues pre-GSoC and try out something new during GSoC.
>
> Looking forward!
> --
> Godspeed,
> Manoj Kumar,
> http://manojbits.wordpress.com
> <http://goog_1017110195>
> http://github.com/MechCoder

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11754-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 21:57:40 2015
Return-Path: <dev-return-11754-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0EA2117896
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 21:57:40 +0000 (UTC)
Received: (qmail 28620 invoked by uid 500); 24 Feb 2015 21:57:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28543 invoked by uid 500); 24 Feb 2015 21:57:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28532 invoked by uid 99); 24 Feb 2015 21:57:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 21:57:38 +0000
X-ASF-Spam-Status: No, hits=5.1 required=10.0
	tests=FSL_HELO_BARE_IP_2,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,RCVD_NUMERIC_HELO
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.17.115.47] (HELO atl4mhob09.myregisteredsite.com) (209.17.115.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 21:57:34 +0000
Received: from atl4webmail17 ([10.30.71.174])
	by atl4mhob09.myregisteredsite.com (8.14.4/8.14.4) with ESMTP id t1OLupQT000459;
	Tue, 24 Feb 2015 16:56:51 -0500
Received: from 12.250.97.26 (mike@mbowles.com [12.250.97.26])
          by atl4webmail17 (Netsol 11.2.30)
          with WEBMAIL id 5577;
          Tue, 24 Feb 2015 21:56:51 +0000
From: mike@mbowles.com
To: "Joseph Bradley" <joseph@databricks.com>
Cc: dev@spark.apache.org
Importance: Normal
Sensitivity: Normal
Message-ID: <W86692564455771424815011@atl4webmail17>
X-Mailer: Network Solutions Webmail, Build 11.2.30
X-Originating-IP: [12.250.97.26]
X-Forwarded-For: [(null)]
X-Authenticated-UID: mike@mbowles.com
Date: Tue, 24 Feb 2015 21:56:51 +0000
Subject: Re:  Have Friedman's glmnet algo running in Spark
MIME-Version: 1.0
Content-Type: multipart/alternative;
        boundary="--=_vm_0011_W866925644_5577_1424815011"
X-Virus-Checked: Checked by ClamAV on apache.org

----=_vm_0011_W866925644_5577_1424815011
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable

 Joseph, 
Thanks for your reply. We'll take the steps you suggest - generate some t=
iming comparisons and post them in the GLMNET JIRA with a link from the O=
WLQN JIRA. 

We've got the regression version of GLMNET programmed. The regression ver=
sion only requires a pass through the data each time the active set of co=
efficients changes. That's usualy less than or equal to the number of dec=
rements in the penalty coefficient (typical default =3D 100). The interme=
diate iterations can be done using results of previous passes through the=
 full data set. We're expecting the number of data passes will be indepen=
dent of either number of rows or columns in the data set. We're eager to =
demonstrate this scaling. Do you have any suggestions regarding data sets=
 for large scale regression problems? It would be nice to demonstrate sca=
ling for both number of rows and number of columns. 

Thanks for your help. 
Mike

-----Original Message-----
From: Joseph Bradley [mailto:joseph@databricks.com]
Sent: Sunday, February 22, 2015 06:48 PM
To: mike@mbowles.com
Cc: dev@spark.apache.org
Subject: Re: Have Friedman's glmnet algo running in Spark

Hi Mike,glmnet has definitely been very successful, and it would be great=
 to seehow we can improve optimization in MLlib! There is some related wo=
rkongoing; here are the JIRAs:GLMNET implementation in SparkLinearRegress=
ion with L1/L2 (elastic net) using OWLQN in new ML packageThe GLMNET JIRA=
 has actually been closed in favor of the latter JIRA.However, if you're =
getting good results in your experiments, could youplease post them on th=
e GLMNET JIRA and link them from the other JIRA? Ifit's faster and more s=
calable, that would be great to find out.As far as where the code should =
go and the APIs, that can be discussed onthe JIRA.I hope this helps, and =
I'll keep an eye out for updates on the JIRAs!JosephOn Thu, Feb 19, 2015 =
at 10:59 AM,  wrote:> Dev List,> A couple of colleagues and I have gotten=
 several versions of glmnet algo> coded and running on Spark RDD. glmnet =
algo (> http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm =
for> generating coefficient paths solving penalized regression with elast=
ic net> penalties. The algorithm runs fast by taking an approach that gen=
erates> solutions for a wide variety of penalty parameter. We're able to =
integrate> into Mllib class structure a couple of different ways. The alg=
orithm may> fit better into the new pipeline structure since it naturally=
 returns a> multitide of models (corresponding to different vales of pena=
lty> parameters). That appears to fit better into pipeline than Mllib lin=
ear> regression (for example).>> We've got regression running with the sp=
eed optimizations that Friedman> recommends. We'll start working on the l=
ogistic regression version next.>> We're eager to make the code available=
 as open source and would like to> get some feedback about how best to do=
 that. Any thoughts?> Mike Bowles.>>>

----=_vm_0011_W866925644_5577_1424815011--



From dev-return-11755-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 22:55:04 2015
Return-Path: <dev-return-11755-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9817B17B06
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 22:55:04 +0000 (UTC)
Received: (qmail 11947 invoked by uid 500); 24 Feb 2015 22:54:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11873 invoked by uid 500); 24 Feb 2015 22:54:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11860 invoked by uid 99); 24 Feb 2015 22:54:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 22:54:52 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mnazario@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 22:54:26 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Tue, 24
 Feb 2015 14:54:24 -0800
From: Michael Nazario <mnazario@palantir.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: PySpark SPARK_CLASSPATH doesn't distribute jars to executors
Thread-Topic: PySpark SPARK_CLASSPATH doesn't distribute jars to executors
Thread-Index: AdBQhNTW9FpX7GMKS9yFXlPyaWXaBg==
Date: Tue, 24 Feb 2015 22:54:23 +0000
Message-ID: <06F190FE1D7B544E8892799F08EA9C503A9CB5@ex02-west.YOJOE.local>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.70.117]
Content-Type: multipart/alternative;
	boundary="_000_06F190FE1D7B544E8892799F08EA9C503A9CB5ex02westYOJOEloca_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_06F190FE1D7B544E8892799F08EA9C503A9CB5ex02westYOJOEloca_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Has anyone experienced a problem with the SPARK_CLASSPATH not distributing =
jars for PySpark? I have a detailed description of what I tried in the tick=
et below, and this seems like a problem that is not a configuration problem=
. The only other case I can think of is that configuration changed between =
Spark 1.1.1 and Spark 1.2.1 about distributing jars for PySpark.

https://issues.apache.org/jira/browse/SPARK-5977

Thanks,
Michael

--_000_06F190FE1D7B544E8892799F08EA9C503A9CB5ex02westYOJOEloca_--

From dev-return-11756-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 23:02:39 2015
Return-Path: <dev-return-11756-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C414817B50
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 23:02:39 +0000 (UTC)
Received: (qmail 30594 invoked by uid 500); 24 Feb 2015 23:02:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30508 invoked by uid 500); 24 Feb 2015 23:02:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30496 invoked by uid 99); 24 Feb 2015 23:02:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:02:38 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of 91mbbh@gmail.com designates 209.85.192.52 as permitted sender)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:02:33 +0000
Received: by mail-qg0-f52.google.com with SMTP id h3so115837qgf.11
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 15:02:12 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=6Pdszr+qh1pKqEA0AuwugcgiFCwlfIqQCejVgV2BuWE=;
        b=Aokcek3JJEkbRh3m8yTcB7p22pCSAjVBTidU93n5blcqlzZPki4ar16mlHYIBxyVh4
         s0BRtIbb7tfy565YTYlvJAbDJEeJx7aoVO3gffaxqzO7AkF3eNKqAlZsuL+SgYpr/LF+
         yKuUvz98SBGYcrH7TzddtsYMqkaJfyg/pBjO0xMyQa+2R1/M9H1KwsRccYv466BsNMOc
         /4coqzYakV4kvEdGLpzCxkcVq2OFa5zg871+hnTDlBZmfXKwrCLMvHTNx/spEPezNUkr
         JgiPiwf5CcHOmuvoH4QI47EsALfoSBg9x0qb0eKE9xdTHdg59Rjt/sKaqLVnEsLctOEw
         N32Q==
MIME-Version: 1.0
X-Received: by 10.140.150.149 with SMTP id 143mr848917qhw.4.1424818932791;
 Tue, 24 Feb 2015 15:02:12 -0800 (PST)
Received: by 10.140.94.81 with HTTP; Tue, 24 Feb 2015 15:02:12 -0800 (PST)
Date: Tue, 24 Feb 2015 18:02:12 -0500
Message-ID: <CABX=+LrVW4nGaX=qDqjEp5bSY9_=s61joKTf5UGsVJZ6fk3M_w@mail.gmail.com>
Subject: [ERROR] bin/compute-classpath.sh: fails with false positive test for
 java 1.7 vs 1.6
From: Mike Hynes <91mbbh@gmail.com>
To: dev@spark.apache.org
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

./bin/compute-classpath.sh fails with error:

$> jar -tf assembly/target/scala-2.10/spark-assembly-1.3.0-SNAPSHOT-hadoop1.0.4.jar
nonexistent/class/path
java.util.zip.ZipException: invalid CEN header (bad signature)
	at java.util.zip.ZipFile.open(Native Method)
	at java.util.zip.ZipFile.<init>(ZipFile.java:132)
	at java.util.zip.ZipFile.<init>(ZipFile.java:93)
	at sun.tools.jar.Main.list(Main.java:997)
	at sun.tools.jar.Main.run(Main.java:242)
	at sun.tools.jar.Main.main(Main.java:1167)

However, I both compiled the distribution and am running spark with Java 1.7;
$ java -version
	java version "1.7.0_75"
	OpenJDK Runtime Environment (IcedTea 2.5.4) (7u75-2.5.4-1~trusty1)
	OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
on a system running Ubuntu:
$ uname -srpov
Linux 3.13.0-44-generic #73-Ubuntu SMP Tue Dec 16 00:22:43 UTC 2014
x86_64 GNU/Linux
$ uname -srpo
Linux 3.13.0-44-generic x86_64 GNU/Linux

This problem was reproduced on Arch Linux:

$ uname -srpo
Linux 3.18.5-1-ARCH x86_64 GNU/Linux
with
$ java -version
java version "1.7.0_75"
OpenJDK Runtime Environment (IcedTea 2.5.4) (Arch Linux build
7.u75_2.5.4-1-x86_64)
OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)

In both of these cases, the problem is not the java versioning;
neither system even has a java 6 installation. This seems like a false
positive to me in compute-classpath.sh.

When I comment out the relevant lines in compute-classpath.sh, the
scripts start-{master,slaves,...}.sh all run fine, and I have no
problem launching applications.

Could someone please offer some insight into this issue?

Thanks,
Mike

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11757-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 23:09:23 2015
Return-Path: <dev-return-11757-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A7EC17B7C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 23:09:23 +0000 (UTC)
Received: (qmail 49088 invoked by uid 500); 24 Feb 2015 23:09:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49010 invoked by uid 500); 24 Feb 2015 23:09:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48999 invoked by uid 99); 24 Feb 2015 23:09:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:09:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:08:56 +0000
Received: by wgha1 with SMTP id a1so124704wgh.12
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 15:08:10 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=tR4xs+mGGY77LYmoDd/X/Z6889SNC2QrvcuE2yOs7Ak=;
        b=KuPS6bSYCUhCM4T8I5XzYhHVemttdpoX0Q8Lpy67Ae1XeR7Iu6z/LzrQFbu4w3h48I
         1k1F8ymwr+E033lslwsuGNiJ0bDfcSkzRvqXDI71nMF1CDbI07/1RJMZDHLcAoFY8st6
         YNIT0VZMo0t+lPcqzybQMLWeAPZhhVwAPpHl8aIzNwgIerXvATlq9mMsWtTEw5sZ5Wet
         TeRVtbzPnVJuyvOE/8Xki4+XZIJ+5HnpheQhjenMovu6SVksOdUsRVtx1uI6kcxcg23j
         lLSmPXRupk8nRwZWnr6gWFU1apM7YJmhnuG37+pPEClGjy1ydLUjO1b/ACVF35Y6JQRT
         yLcg==
X-Gm-Message-State: ALoCoQnj0ll7y+QswxFMf3nmtfInyXNBmELzQ8lYV/xK22eysNZchfod+IMUBvNDSUxcTXAQJBwF
X-Received: by 10.180.108.199 with SMTP id hm7mr34295170wib.5.1424819290109;
 Tue, 24 Feb 2015 15:08:10 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.83.209 with HTTP; Tue, 24 Feb 2015 15:07:49 -0800 (PST)
In-Reply-To: <CABX=+LrVW4nGaX=qDqjEp5bSY9_=s61joKTf5UGsVJZ6fk3M_w@mail.gmail.com>
References: <CABX=+LrVW4nGaX=qDqjEp5bSY9_=s61joKTf5UGsVJZ6fk3M_w@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 24 Feb 2015 23:07:49 +0000
Message-ID: <CAMAsSdJh3RgMbUyCbJj9Uf+dmaRfxuk17zY6pAhrXD7gnaVCdg@mail.gmail.com>
Subject: Re: [ERROR] bin/compute-classpath.sh: fails with false positive test
 for java 1.7 vs 1.6
To: Mike Hynes <91mbbh@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

So you mean that the script is checking for this error, and takes it
as a sign that you compiled with java 6.

Your command seems to confirm that reading the assembly jar does fail
on your system though. What version does the jar command show? are you
sure you don't have JRE 7 but JDK 6 installed?

On Tue, Feb 24, 2015 at 11:02 PM, Mike Hynes <91mbbh@gmail.com> wrote:
> ./bin/compute-classpath.sh fails with error:
>
> $> jar -tf assembly/target/scala-2.10/spark-assembly-1.3.0-SNAPSHOT-hadoop1.0.4.jar
> nonexistent/class/path
> java.util.zip.ZipException: invalid CEN header (bad signature)
>         at java.util.zip.ZipFile.open(Native Method)
>         at java.util.zip.ZipFile.<init>(ZipFile.java:132)
>         at java.util.zip.ZipFile.<init>(ZipFile.java:93)
>         at sun.tools.jar.Main.list(Main.java:997)
>         at sun.tools.jar.Main.run(Main.java:242)
>         at sun.tools.jar.Main.main(Main.java:1167)
>
> However, I both compiled the distribution and am running spark with Java 1.7;
> $ java -version
>         java version "1.7.0_75"
>         OpenJDK Runtime Environment (IcedTea 2.5.4) (7u75-2.5.4-1~trusty1)
>         OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
> on a system running Ubuntu:
> $ uname -srpov
> Linux 3.13.0-44-generic #73-Ubuntu SMP Tue Dec 16 00:22:43 UTC 2014
> x86_64 GNU/Linux
> $ uname -srpo
> Linux 3.13.0-44-generic x86_64 GNU/Linux
>
> This problem was reproduced on Arch Linux:
>
> $ uname -srpo
> Linux 3.18.5-1-ARCH x86_64 GNU/Linux
> with
> $ java -version
> java version "1.7.0_75"
> OpenJDK Runtime Environment (IcedTea 2.5.4) (Arch Linux build
> 7.u75_2.5.4-1-x86_64)
> OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
>
> In both of these cases, the problem is not the java versioning;
> neither system even has a java 6 installation. This seems like a false
> positive to me in compute-classpath.sh.
>
> When I comment out the relevant lines in compute-classpath.sh, the
> scripts start-{master,slaves,...}.sh all run fine, and I have no
> problem launching applications.
>
> Could someone please offer some insight into this issue?
>
> Thanks,
> Mike
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11758-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 23:27:51 2015
Return-Path: <dev-return-11758-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C4A317C04
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 23:27:51 +0000 (UTC)
Received: (qmail 88529 invoked by uid 500); 24 Feb 2015 23:27:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88446 invoked by uid 500); 24 Feb 2015 23:27:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88435 invoked by uid 99); 24 Feb 2015 23:27:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:27:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.213.171] (HELO mail-ig0-f171.google.com) (209.85.213.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:27:25 +0000
Received: by mail-ig0-f171.google.com with SMTP id h15so31101464igd.4
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 15:27:03 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=f5hlWziiPbAfO8Nj3HvDZ9cQXYMF4C8h4NLzr8ujBOQ=;
        b=XQZdBrF+NjkwprtB81cSh0Lh6Shu4TjfUYlcmJ1CQ0HdKJSVlN8q87HLFEBbQyRrxx
         uyoECZNc8wDdIa4p3+8tjfbC635xeSLX/fcJVClaarLg09WM++xxzhr2aKPKezPE+Fdp
         gyqSYbPtSw/t40JvQHdGOA2NyH2vD233UM+Gvoj57DE46+eC5slE8TS+9NANX2iu+dDR
         iBLezi0fObdyMae1BTDw3yHJK5E77DT5vzeoLXKtJIaASMcbU9rQFEvy/LIhZWhaxzP2
         uG5CleBjXrpFlc2mBiA/F7NddRRy90gZpkPYwzyg2cGkxicGwWKfk+i4SkClAHkOWYTa
         UqmA==
X-Gm-Message-State: ALoCoQmryERIHSq4hzUiInB19vdiu9XZuAS1jGUeZZHe5F+zp/SrBPPTj0H5s94pLI+Tr50v9c8v
MIME-Version: 1.0
X-Received: by 10.50.36.103 with SMTP id p7mr23853301igj.20.1424820423087;
 Tue, 24 Feb 2015 15:27:03 -0800 (PST)
Received: by 10.36.118.18 with HTTP; Tue, 24 Feb 2015 15:27:03 -0800 (PST)
In-Reply-To: <W86692564455771424815011@atl4webmail17>
References: <W86692564455771424815011@atl4webmail17>
Date: Tue, 24 Feb 2015 15:27:03 -0800
Message-ID: <CAF7ADNrh-qNEtjVL1efMHXxcgUOOArYLSTO+BKFwAJA_BGssoA@mail.gmail.com>
Subject: Re: Have Friedman's glmnet algo running in Spark
From: Joseph Bradley <joseph@databricks.com>
To: mike@mbowles.com
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01184d5c2ff323050fdddb94
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01184d5c2ff323050fdddb94
Content-Type: text/plain; charset=UTF-8

Hi Mike,

I'm not aware of a "standard" big dataset, but there are a number available:
* The YearPredictionMSD dataset from the LIBSVM datasets is sizeable (in #
instances but not # features):
www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html
* I've used this text dataset from which one can generate lots of n-gram
features (but not many instances): http://www.ark.cs.cmu.edu/10K/
* I've seen some papers use the KDD Cup datasets, which might be the best
option I know of.  The KDD Cup 2012 track 2 one seems promising.

Good luck!
Joseph

On Tue, Feb 24, 2015 at 1:56 PM, <mike@mbowles.com> wrote:

> Joseph,
> Thanks for your reply.  We'll take the steps you suggest - generate some
> timing comparisons and post them in the GLMNET JIRA with a link from the
> OWLQN JIRA.
>
> We've got the regression version of GLMNET programmed.  The regression
> version only requires a pass through the data each time the active set of
> coefficients changes.  That's usualy less than or equal to the number of
> decrements in the penalty coefficient (typical default = 100).  The
> intermediate iterations can be done using results of previous passes
> through the full data set.  We're expecting the number of data passes will
> be independent of either number of rows or columns in the data set.  We're
> eager to demonstrate this scaling.  Do you have any suggestions regarding
> data sets for large scale regression problems?  It would be nice to
> demonstrate scaling for both number of rows and number of columns.
>
> Thanks for your help.
> Mike
>
> -----Original Message-----
> *From:* Joseph Bradley [mailto:joseph@databricks.com]
> *Sent:* Sunday, February 22, 2015 06:48 PM
> *To:* mike@mbowles.com
> *Cc:* dev@spark.apache.org
> *Subject:* Re: Have Friedman's glmnet algo running in Spark
>
> Hi Mike, glmnet has definitely been very successful, and it would be great
> to see how we can improve optimization in MLlib! There is some related work
> ongoing; here are the JIRAs: GLMNET implementation in Spark
> LinearRegression with L1/L2 (elastic net) using OWLQN in new ML package
> The GLMNET JIRA has actually been closed in favor of the latter JIRA.
> However, if you're getting good results in your experiments, could you
> please post them on the GLMNET JIRA and link them from the other JIRA? If
> it's faster and more scalable, that would be great to find out. As far as
> where the code should go and the APIs, that can be discussed on the JIRA. I
> hope this helps, and I'll keep an eye out for updates on the JIRAs! Joseph
> On Thu, Feb 19, 2015 at 10:59 AM,  wrote: > Dev List, > A couple of
> colleagues and I have gotten several versions of glmnet algo > coded and
> running on Spark RDD. glmnet algo ( >
> http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm for >
> generating coefficient paths solving penalized regression with elastic net
> > penalties. The algorithm runs fast by taking an approach that generates >
> solutions for a wide variety of penalty parameter. We're able to integrate
> > into Mllib class structure a couple of different ways. The algorithm may
> > fit better into the new pipeline structure since it naturally returns a >
> multitide of models (corresponding to different vales of penalty >
> parameters). That appears to fit better into pipeline than Mllib linear >
> regression (for example). > > We've got regression running with the speed
> optimizations that Friedman > recommends. We'll start working on the
> logistic regression version next. > > We're eager to make the code
> available as open source and would like to > get some feedback about how
> best to do that. Any thoughts? > Mike Bowles. > > >
>
>

--089e01184d5c2ff323050fdddb94--

From dev-return-11759-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Feb 24 23:34:42 2015
Return-Path: <dev-return-11759-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 37F5817C52
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 24 Feb 2015 23:34:42 +0000 (UTC)
Received: (qmail 20893 invoked by uid 500); 24 Feb 2015 23:34:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20821 invoked by uid 500); 24 Feb 2015 23:34:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20809 invoked by uid 99); 24 Feb 2015 23:34:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:34:33 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of 91mbbh@gmail.com designates 209.85.216.45 as permitted sender)
Received: from [209.85.216.45] (HELO mail-qa0-f45.google.com) (209.85.216.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 24 Feb 2015 23:34:08 +0000
Received: by mail-qa0-f45.google.com with SMTP id j7so255017qaq.4
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 15:32:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=VkA0lNQ9RqswAajMoQcXywknpX9Zwj6iWsqRvSAp594=;
        b=J8g7QqqkBvRqmGzpHtWWES3wd4601xUwDGOGLNk7g4J3P/ChON/n07tgf7L7gBdWrZ
         rcc0wzfzDFBNpGmP0Ay4csf6i+mfJEKmlSC4ybZRfbK84yN/Fx/Akc8aysz+h+ivFlyi
         o/Ufn0zXMZMz48x8Ha4vRXflOD8SrbvCOLw+cmIYxAqT6UaW2IlI5bn5826YAbzQQERy
         2o98Se453ar55mBmiEtdWDwkDWBe6FM9AkKRNIJkJvvRP0gkh/Zkyfv2/CkpJY/m+OFy
         m8Ri0oFQlBL1mQCmciCBBtHy60rL9V2ITHXM3FvpcDIZciEqFvAfCdd645xn0GrMhPD+
         ZKkQ==
MIME-Version: 1.0
X-Received: by 10.140.91.131 with SMTP id z3mr820402qgd.1.1424820757167; Tue,
 24 Feb 2015 15:32:37 -0800 (PST)
Received: by 10.140.94.81 with HTTP; Tue, 24 Feb 2015 15:32:37 -0800 (PST)
In-Reply-To: <CAMAsSdJh3RgMbUyCbJj9Uf+dmaRfxuk17zY6pAhrXD7gnaVCdg@mail.gmail.com>
References: <CABX=+LrVW4nGaX=qDqjEp5bSY9_=s61joKTf5UGsVJZ6fk3M_w@mail.gmail.com>
	<CAMAsSdJh3RgMbUyCbJj9Uf+dmaRfxuk17zY6pAhrXD7gnaVCdg@mail.gmail.com>
Date: Tue, 24 Feb 2015 18:32:37 -0500
Message-ID: <CABX=+LoQJwx6ZDY6R97bdmbAWAop_gLZvR-Y4ViR5qDKLYPHVQ@mail.gmail.com>
Subject: Re: [ERROR] bin/compute-classpath.sh: fails with false positive test
 for java 1.7 vs 1.6
From: Mike Hynes <91mbbh@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I don't see any version flag for /usr/bin/jar, but I think I see the
problem now; the openjdk version is 7, but javac -version gives
1.6.0_34; so spark was compiled with java 6 despite the system using
jre 1.7.
Thanks for the sanity check! Now I just need to find out why javac is
downgraded on the system..

On 2/24/15, Sean Owen <sowen@cloudera.com> wrote:
> So you mean that the script is checking for this error, and takes it
> as a sign that you compiled with java 6.
>
> Your command seems to confirm that reading the assembly jar does fail
> on your system though. What version does the jar command show? are you
> sure you don't have JRE 7 but JDK 6 installed?
>
> On Tue, Feb 24, 2015 at 11:02 PM, Mike Hynes <91mbbh@gmail.com> wrote:
>> ./bin/compute-classpath.sh fails with error:
>>
>> $> jar -tf
>> assembly/target/scala-2.10/spark-assembly-1.3.0-SNAPSHOT-hadoop1.0.4.jar
>> nonexistent/class/path
>> java.util.zip.ZipException: invalid CEN header (bad signature)
>>         at java.util.zip.ZipFile.open(Native Method)
>>         at java.util.zip.ZipFile.<init>(ZipFile.java:132)
>>         at java.util.zip.ZipFile.<init>(ZipFile.java:93)
>>         at sun.tools.jar.Main.list(Main.java:997)
>>         at sun.tools.jar.Main.run(Main.java:242)
>>         at sun.tools.jar.Main.main(Main.java:1167)
>>
>> However, I both compiled the distribution and am running spark with Java
>> 1.7;
>> $ java -version
>>         java version "1.7.0_75"
>>         OpenJDK Runtime Environment (IcedTea 2.5.4)
>> (7u75-2.5.4-1~trusty1)
>>         OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
>> on a system running Ubuntu:
>> $ uname -srpov
>> Linux 3.13.0-44-generic #73-Ubuntu SMP Tue Dec 16 00:22:43 UTC 2014
>> x86_64 GNU/Linux
>> $ uname -srpo
>> Linux 3.13.0-44-generic x86_64 GNU/Linux
>>
>> This problem was reproduced on Arch Linux:
>>
>> $ uname -srpo
>> Linux 3.18.5-1-ARCH x86_64 GNU/Linux
>> with
>> $ java -version
>> java version "1.7.0_75"
>> OpenJDK Runtime Environment (IcedTea 2.5.4) (Arch Linux build
>> 7.u75_2.5.4-1-x86_64)
>> OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
>>
>> In both of these cases, the problem is not the java versioning;
>> neither system even has a java 6 installation. This seems like a false
>> positive to me in compute-classpath.sh.
>>
>> When I comment out the relevant lines in compute-classpath.sh, the
>> scripts start-{master,slaves,...}.sh all run fine, and I have no
>> problem launching applications.
>>
>> Could someone please offer some insight into this issue?
>>
>> Thanks,
>> Mike
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>


-- 
Thanks,
Mike

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11760-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 00:16:26 2015
Return-Path: <dev-return-11760-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2553F17DCB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 00:16:26 +0000 (UTC)
Received: (qmail 28484 invoked by uid 500); 25 Feb 2015 00:16:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28407 invoked by uid 500); 25 Feb 2015 00:16:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28396 invoked by uid 99); 25 Feb 2015 00:16:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 00:16:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.43 as permitted sender)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 00:16:10 +0000
Received: by labgf13 with SMTP id gf13so421522lab.9
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 16:15:49 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=5xS9ObLIjeH8Kbkef3GOykHbc+qHR4CObKcUN4BYGG4=;
        b=G6u2bePC1Lv/xDC4oN9S9Zk0fsI/DuU2F74WcFmWHF3erNXQbLY63l6Mb0jQu52DdR
         lQc6XTD42jyySB+BhGhv5O30YYPjD1Qi3c2x7V/45FpkC0Uzv6k8swvEUgGp2lSu+oCs
         5nX9J5dJW9spsNYnLv3r6IAOkUFzuhOA+esrrKnvoKgfST0S4XqmhCR6MNx0hxkJognZ
         Ze/0u6MTbFtD9IxfA+IL6jEsY35flNCaOCpgpFmYXCl2KEH4Blcu+kcE2xQgcgHE+gNa
         CRfgs1/1IUMjpUgLFLskDh4sYfY2LyrUeyFupWVsHahMNDJeROWfq3iGvq5H4luqby8g
         9ZQA==
X-Gm-Message-State: ALoCoQlpiqo5WE/0/b5nrfJQGLFWNwL+8cLZIALkbcqY6FaGVoLsutvUiETY7X6heGYjW32V1XO5
X-Received: by 10.112.235.10 with SMTP id ui10mr345936lbc.77.1424823349139;
 Tue, 24 Feb 2015 16:15:49 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Tue, 24 Feb 2015 16:15:28 -0800 (PST)
In-Reply-To: <CABX=+LoQJwx6ZDY6R97bdmbAWAop_gLZvR-Y4ViR5qDKLYPHVQ@mail.gmail.com>
References: <CABX=+LrVW4nGaX=qDqjEp5bSY9_=s61joKTf5UGsVJZ6fk3M_w@mail.gmail.com>
 <CAMAsSdJh3RgMbUyCbJj9Uf+dmaRfxuk17zY6pAhrXD7gnaVCdg@mail.gmail.com> <CABX=+LoQJwx6ZDY6R97bdmbAWAop_gLZvR-Y4ViR5qDKLYPHVQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 24 Feb 2015 16:15:28 -0800
Message-ID: <CACdU-dSoXW1C_EePBOmdfMQ3ZNaF=D1q79qG4xrmt4NGgtk-yw@mail.gmail.com>
Subject: Re: [ERROR] bin/compute-classpath.sh: fails with false positive test
 for java 1.7 vs 1.6
To: Mike Hynes <91mbbh@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3d8ca97ea52050fde8996
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3d8ca97ea52050fde8996
Content-Type: text/plain; charset=UTF-8

it's not downgraded, it's your /etc/alternatives setup that's causing this.

you can update all of those entries by executing the following commands (as
root):

update-alternatives --install "/usr/bin/java" "java"
"/usr/java/latest/bin/java" 1
update-alternatives --install "/usr/bin/javah" "javah"
"/usr/java/latest/bin/javah" 1
update-alternatives --install "/usr/bin/javac" "javac"
"/usr/java/latest/bin/javac" 1
update-alternatives --install "/usr/bin/jar" "jar"
"/usr/java/latest/bin/jar" 1

(i have the latest jdk installed in /usr/java/.... with a /usr/java/latest/
symlink pointing to said jdk's dir)

On Tue, Feb 24, 2015 at 3:32 PM, Mike Hynes <91mbbh@gmail.com> wrote:
>
> I don't see any version flag for /usr/bin/jar, but I think I see the
> problem now; the openjdk version is 7, but javac -version gives
> 1.6.0_34; so spark was compiled with java 6 despite the system using
> jre 1.7.
> Thanks for the sanity check! Now I just need to find out why javac is
> downgraded on the system..
>
> On 2/24/15, Sean Owen <sowen@cloudera.com> wrote:
> > So you mean that the script is checking for this error, and takes it
> > as a sign that you compiled with java 6.
> >
> > Your command seems to confirm that reading the assembly jar does fail
> > on your system though. What version does the jar command show? are you
> > sure you don't have JRE 7 but JDK 6 installed?
> >
> > On Tue, Feb 24, 2015 at 11:02 PM, Mike Hynes <91mbbh@gmail.com> wrote:
> >> ./bin/compute-classpath.sh fails with error:
> >>
> >> gt; jar -tf
> >>
assembly/target/scala-2.10/spark-assembly-1.3.0-SNAPSHOT-hadoop1.0.4.jar
> >> nonexistent/class/path
> >> java.util.zip.ZipException: invalid CEN header (bad signature)
> >>         at java.util.zip.ZipFile.open(Native Method)
> >>         at java.util.zip.ZipFile.<init>(ZipFile.java:132)
> >>         at java.util.zip.ZipFile.<init>(ZipFile.java:93)
> >>         at sun.tools.jar.Main.list(Main.java:997)
> >>         at sun.tools.jar.Main.run(Main.java:242)
> >>         at sun.tools.jar.Main.main(Main.java:1167)
> >>
> >> However, I both compiled the distribution and am running spark with
Java
> >> 1.7;
> >> $ java -version
> >>         java version "1.7.0_75"
> >>         OpenJDK Runtime Environment (IcedTea 2.5.4)
> >> (7u75-2.5.4-1~trusty1)
> >>         OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
> >> on a system running Ubuntu:
> >> $ uname -srpov
> >> Linux 3.13.0-44-generic #73-Ubuntu SMP Tue Dec 16 00:22:43 UTC 2014
> >> x86_64 GNU/Linux
> >> $ uname -srpo
> >> Linux 3.13.0-44-generic x86_64 GNU/Linux
> >>
> >> This problem was reproduced on Arch Linux:
> >>
> >> $ uname -srpo
> >> Linux 3.18.5-1-ARCH x86_64 GNU/Linux
> >> with
> >> $ java -version
> >> java version "1.7.0_75"
> >> OpenJDK Runtime Environment (IcedTea 2.5.4) (Arch Linux build
> >> 7.u75_2.5.4-1-x86_64)
> >> OpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)
> >>
> >> In both of these cases, the problem is not the java versioning;
> >> neither system even has a java 6 installation. This seems like a false
> >> positive to me in compute-classpath.sh.
> >>
> >> When I comment out the relevant lines in compute-classpath.sh, the
> >> scripts start-{master,slaves,...}.sh all run fine, and I have no
> >> problem launching applications.
> >>
> >> Could someone please offer some insight into this issue?
> >>
> >> Thanks,
> >> Mike
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >
>
>
> --
> Thanks,
> Mike
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

--001a11c3d8ca97ea52050fde8996--

From dev-return-11761-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 02:00:33 2015
Return-Path: <dev-return-11761-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3B918102E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 02:00:33 +0000 (UTC)
Received: (qmail 39910 invoked by uid 500); 25 Feb 2015 02:00:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39828 invoked by uid 500); 25 Feb 2015 02:00:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39800 invoked by uid 99); 25 Feb 2015 02:00:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 02:00:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 02:00:01 +0000
Received: by mail-oi0-f43.google.com with SMTP id z81so818215oif.2
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 17:58:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=9fkIfLf76y9Wkp4VwCdGTLjKIxpxhKpUujcXrV048MI=;
        b=WCe7rm9zxZOAB1PCr8qBEu6P93KaJKfUSiIOF0K6q9A77taQlZSFCaIdZndD+vZRRJ
         En6i3sn19sK+uyyoEr3Z4o+bm4RdxZLNPZyNMxCc1z/QBjOW+XT3ZFV4Jr95BmCrUYQF
         y1lyTVBJ0c7nZyQhOjgqENgI9WzjY6lD/a2R/4xYXeEF4m7xR8EZZQtxIwBmUKzwNB3R
         4e5UNXfEnB0WQg++lEtRjTaiDojd4XRIHRM9IKAFo0YYZ/Z/RIfIS374MbabkxvuisjK
         CH8idfNZFSqUx3Bej6DRZSu33cRKmzY+aheahdfEi48aGj9PA3z4+JhzlNbhoji5o3YB
         HdnQ==
X-Gm-Message-State: ALoCoQkVfkcQlahtpkDzPuVNZVPJL2mN5cK2vr0G4BgCj026JMfN6gFv47MAkY561r/g1q+W9lj5
X-Received: by 10.182.186.100 with SMTP id fj4mr637266obc.12.1424829489066;
        Tue, 24 Feb 2015 17:58:09 -0800 (PST)
Received: from mail-ob0-f181.google.com (mail-ob0-f181.google.com. [209.85.214.181])
        by mx.google.com with ESMTPSA id h203sm24351697oic.1.2015.02.24.17.58.07
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 24 Feb 2015 17:58:08 -0800 (PST)
Received: by mail-ob0-f181.google.com with SMTP id vb8so874674obc.12
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 17:58:07 -0800 (PST)
X-Received: by 10.60.92.66 with SMTP id ck2mr628641oeb.30.1424829487238; Tue,
 24 Feb 2015 17:58:07 -0800 (PST)
MIME-Version: 1.0
Received: by 10.182.182.99 with HTTP; Tue, 24 Feb 2015 17:57:47 -0800 (PST)
In-Reply-To: <D10A5DB3.1D1C0%mkim@palantir.com>
References: <CA+-p3AHaZ_Q7ZE6vn2YVevQiXQhGn8cYnaM9KjeF7tKeBZk2=w@mail.gmail.com>
 <CA+3qhFQviWYtFceAxZrZpNeWd+RTp=s50dGodWzB71T3Y3ydLw@mail.gmail.com> <D10A5DB3.1D1C0%mkim@palantir.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Tue, 24 Feb 2015 17:57:47 -0800
Message-ID: <CA+-p3AGnbcrvNtq=hwj9Jdj0zwpusZ7VtiJKN0Of+Mv63wEjyQ@mail.gmail.com>
Subject: Re: Streaming partitions to driver for use in .toLocalIterator
To: Mingyu Kim <mkim@palantir.com>
Cc: Imran Rashid <irashid@cloudera.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b33ca0073d710050fdff728
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b33ca0073d710050fdff728
Content-Type: text/plain; charset=UTF-8

I think a cheap way to repartition to a higher partition count without
shuffle would be valuable too.  Right now you can choose whether to execute
a shuffle when going down in partition count, but going up in partition
count always requires a shuffle.  For the need of having a smaller
partitions to make .toLocalIterator more efficient, no shuffle on increase
of partition count is necessary.

Filed as https://issues.apache.org/jira/browse/SPARK-5997

On Wed, Feb 18, 2015 at 3:21 PM, Mingyu Kim <mkim@palantir.com> wrote:

> Another alternative would be to compress the partition in memory in a
> streaming fashion instead of calling .toArray on the iterator. Would it be
> an easier mitigation to the problem? Or, is it hard to compress the rows
> one by one without materializing the full partition in memory using the
> compression algo Spark uses currently?
>
> Mingyu
>
>
>
>
>
> On 2/18/15, 1:01 PM, "Imran Rashid" <irashid@cloudera.com> wrote:
>
> >This would be pretty tricky to do -- the issue is that right now
> >sparkContext.runJob has you pass in a function from a partition to *one*
> >result object that gets serialized and sent back: Iterator[T] => U, and
> >that idea is baked pretty deep into a lot of the internals, DAGScheduler,
> >Task, Executors, etc.
> >
> >Maybe another possibility worth considering: should we make it easy to go
> >from N partitions to 2N partitions (or any other multiple obviously)
> >without requiring a shuffle?  for that matter, you should also be able to
> >go from 2N to N without a shuffle as well.  That change is also somewhat
> >involved, though.
> >
> >Both are in theory possible, but I imagine they'd need really compelling
> >use cases.
> >
> >An alternative would be to write your RDD to some other data store (eg,
> >hdfs) which has better support for reading data in a streaming fashion,
> >though you would probably be unhappy with the overhead.
> >
> >
> >
> >On Wed, Feb 18, 2015 at 9:09 AM, Andrew Ash <andrew@andrewash.com> wrote:
> >
> >> Hi Spark devs,
> >>
> >> I'm creating a streaming export functionality for RDDs and am having
> >>some
> >> trouble with large partitions.  The RDD.toLocalIterator() call pulls
> >>over a
> >> partition at a time to the driver, and then streams the RDD out from
> >>that
> >> partition before pulling in the next one.  When you have large
> >>partitions
> >> though, you can OOM the driver, especially when multiple of these
> >>exports
> >> are happening in the same SparkContext.
> >>
> >> One idea I had was to repartition the RDD so partitions are smaller, but
> >> it's hard to know a priori what the partition count should be, and I'd
> >>like
> >> to avoid paying the shuffle cost if possible -- I think repartition to a
> >> higher partition count forces a shuffle.
> >>
> >> Is it feasible to rework this so the executor -> driver transfer in
> >> .toLocalIterator is a steady stream rather than a partition at a time?
> >>
> >> Thanks!
> >> Andrew
> >>
>
>

--047d7b33ca0073d710050fdff728--

From dev-return-11762-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 03:23:41 2015
Return-Path: <dev-return-11762-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4CFA010698
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 03:23:41 +0000 (UTC)
Received: (qmail 71678 invoked by uid 500); 25 Feb 2015 03:23:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71574 invoked by uid 500); 25 Feb 2015 03:23:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71550 invoked by uid 99); 25 Feb 2015 03:23:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 03:23:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 03:23:34 +0000
Received: by pdjz10 with SMTP id z10so1679902pdj.0
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 19:21:44 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to
         :content-type;
        bh=une6UTytEFrzRo1Ek3QnYxPzh7YDHaY+tIiLC66FCl8=;
        b=vnOntwHyPpkEfir73c0ASF4jeQzKGdSEye99XOy2NXr8xeG8BD02aAtR8H/WPZjDoD
         v9bmlIrI9VLY75q+QfeRi50FBFkuP86b7KJfJnfsM1NlUYR6CSg89/1LtRMxRPAiPq2w
         OMjKma7glrX4qMoiKqWne5LQfxR7/fsgSAyCecBipTpzk5nxiysdSMoNI0OR1EGlv6iV
         NcrKv+sKYtp/stI/IaNkHy5wIH6wgs8rRc3qgSl2gyYqONsdZfzt/YY59DUyjndVMQO0
         aCa4MamrnAiMNurVvFIrId47NXa5WZWEplh5Nc2/VTKlP1FKud9VPZCDhZva1Efu+cdZ
         QM8A==
X-Received: by 10.68.204.73 with SMTP id kw9mr1897197pbc.48.1424834504430;
 Tue, 24 Feb 2015 19:21:44 -0800 (PST)
MIME-Version: 1.0
References: <06F190FE1D7B544E8892799F08EA9C503A9CB5@ex02-west.YOJOE.local>
From: Denny Lee <denny.g.lee@gmail.com>
Date: Wed, 25 Feb 2015 03:21:44 +0000
Message-ID: <CABjYQ3_M6NfDkuzvsccwjqrYidJ-j9bHhgK2RPCAMTykVT0N7A@mail.gmail.com>
Subject: Re: PySpark SPARK_CLASSPATH doesn't distribute jars to executors
To: Michael Nazario <mnazario@palantir.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b10ca17801c2f050fe122d5
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10ca17801c2f050fe122d5
Content-Type: text/plain; charset=UTF-8

Can you try extraClassPath or driver-class-path and see if that helps with
the distribution?
On Tue, Feb 24, 2015 at 14:54 Michael Nazario <mnazario@palantir.com> wrote:

> Has anyone experienced a problem with the SPARK_CLASSPATH not distributing
> jars for PySpark? I have a detailed description of what I tried in the
> ticket below, and this seems like a problem that is not a configuration
> problem. The only other case I can think of is that configuration changed
> between Spark 1.1.1 and Spark 1.2.1 about distributing jars for PySpark.
>
> https://issues.apache.org/jira/browse/SPARK-5977
>
> Thanks,
> Michael
>

--047d7b10ca17801c2f050fe122d5--

From dev-return-11763-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 05:56:32 2015
Return-Path: <dev-return-11763-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8D14110A7D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 05:56:32 +0000 (UTC)
Received: (qmail 25574 invoked by uid 500); 25 Feb 2015 05:56:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25488 invoked by uid 500); 25 Feb 2015 05:56:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25477 invoked by uid 99); 25 Feb 2015 05:56:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 05:56:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.216.54] (HELO mail-qa0-f54.google.com) (209.85.216.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 05:56:06 +0000
Received: by mail-qa0-f54.google.com with SMTP id x12so1249775qac.13
        for <dev@spark.apache.org>; Tue, 24 Feb 2015 21:54:59 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=bFxzIxJ2o7hTC3bjoKAR0+KEuYfY+4/RErmnAarZn/0=;
        b=dxkiaMDnJOQA4UxGKTMAgixKO+4jQS3vrGHqlq8tUZxIJDB48QFGgLPRolatoLxufC
         eEig3vfm0Nv3/EOpqp23I654SromEOF7hq2FadobYaYxZ+XykfpotbS30c3tJHm/8Y7D
         mDbfsArcMny1cunsrZnAppmwV6S0W1uz9Ax4UUjQz1pfnt7Q8i5RIjs7KzukxawUHL34
         GrCU5qZdhbG56h1bA8pr8Kgm358Ryzj3KiRRoXxBCwg3cs9AdPxUfUjaPq1ZNN+wDYr0
         1RSZGHJEyQkWNns72fVCn94ey1jbr8ix2kTnrntve24pff2paRuVYz5hI075ZLPiMhJh
         2Ulw==
X-Gm-Message-State: ALoCoQnCnz8XTRRw942kCKRdtM4449Pe8hZ0ulW8kmD8yLYLHpQCpQ4XieIe3Si4hpqn4C6t3ZvL
X-Received: by 10.140.41.113 with SMTP id y104mr3327818qgy.25.1424843699159;
 Tue, 24 Feb 2015 21:54:59 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.109.9 with HTTP; Tue, 24 Feb 2015 21:54:39 -0800 (PST)
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 24 Feb 2015 21:54:39 -0800
Message-ID: <CAPh_B=bJ8Ed4-noRMrgY2PJxZGHGqPrFWxV+mQ2=0bUmzVgZQA@mail.gmail.com>
Subject: Help vote for Spark talks at the Hadoop Summit
To: "dev@spark.apache.org" <dev@spark.apache.org>, user <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c121b08c9ab8050fe34666
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c121b08c9ab8050fe34666
Content-Type: text/plain; charset=UTF-8

Hi all,

The Hadoop Summit uses community choice voting to decide which talks to
feature. It would be great if the community could help vote for Spark talks
so that Spark has a good showing at this event. You can make three votes on
each track. Below I've listed 3 talks that are important to Spark's
roadmap. Please give 3 votes to each of the following talks.

Committer Track: Lessons from Running Ultra Large Scale Spark Workloads on
Hadoop
https://hadoopsummit.uservoice.com/forums/283260-committer-track/suggestions/7074016

Data Science track: DataFrames: large-scale data science on Hadoop data
with Spark
https://hadoopsummit.uservoice.com/forums/283261-data-science-and-hadoop/suggestions/7074147

Future of Hadoop track: Online Approximate OLAP in SparkSQL
https://hadoopsummit.uservoice.com/forums/283266-the-future-of-apache-hadoop/suggestions/7074424


Thanks!

--001a11c121b08c9ab8050fe34666--

From dev-return-11764-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 15:55:38 2015
Return-Path: <dev-return-11764-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 467A617F14
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 15:55:38 +0000 (UTC)
Received: (qmail 63868 invoked by uid 500); 25 Feb 2015 15:54:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63792 invoked by uid 500); 25 Feb 2015 15:54:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63780 invoked by uid 99); 25 Feb 2015 15:54:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 15:54:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.214.170] (HELO mail-ob0-f170.google.com) (209.85.214.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 15:54:31 +0000
Received: by mail-ob0-f170.google.com with SMTP id va2so4681225obc.1
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 07:53:05 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=1MKZvK1VVvLkpS6NvhL3MVTQJPv9CXkHABgOrUYnwT4=;
        b=cSihgJ6l79aLDgZjcGFH3OZ1xb5u0yXOWkuy6jjhAuUe9RKHpoz4Ypdh1WbkNP1brN
         JdF5PKwPFCf7vopTex9sro/F59dWTbnAQZQk+qn1DCRrUs+GJ9AwO+U/S+vDt02SHwkC
         j3YgMWvA7JSj3lBi2IWzA+rNrTBTGENeMMf+kyYk9KG6gL0mH7ifRehI7hMLO1k1D/z1
         Tbz+TcS4s11chZr20zRUiX5RzO2Ud7sRNBZARV4g3L1m+kpkqMSGYJSjUACCir3cM0YH
         g3w1OZJ43jLlBZB50OW2VYDpVcza6zNwNd40QIAQ4bZ2pTdeCiJJV17ziYHZlGRlMsMs
         AquA==
X-Gm-Message-State: ALoCoQlSuMoF1+sWkR5qNhZFkD+s5gXMIuccS1sl2WYZHYL2M7ZPfd3sO9aI44JH0bYE7GdJ1FPK
MIME-Version: 1.0
X-Received: by 10.183.24.162 with SMTP id ij2mr2754207obd.18.1424879585376;
 Wed, 25 Feb 2015 07:53:05 -0800 (PST)
Received: by 10.76.87.36 with HTTP; Wed, 25 Feb 2015 07:53:05 -0800 (PST)
Date: Wed, 25 Feb 2015 09:53:05 -0600
Message-ID: <CAKWX9VWWtRTJ9FGK+t30pdMcg8jPTPpvgfJyu6LSRmuGqAJ1BA@mail.gmail.com>
Subject: UnusedStubClass in 1.3.0-rc1
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134a7ae88d78d050feba19d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134a7ae88d78d050feba19d
Content-Type: text/plain; charset=UTF-8

So when building 1.3.0-rc1 I see the following warning:

[WARNING] spark-streaming-kafka_2.10-1.3.0.jar, unused-1.0.0.jar define 1
overlappping classes:

[WARNING]   - org.apache.spark.unused.UnusedStubClass


and when trying to build an assembly of a project that was previously using
1.3 snapshots without difficulty, I see the following errors:


[error] (*:assembly) deduplicate: different file contents found in the
following:

[error]
/Users/cody/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.3.0/spark-streaming-kafka_2.10-1.3.0.jar:org/apache/spark/unused/UnusedStubClass.class

[error]
/Users/cody/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:org/apache/spark/unused/UnusedStubClass.class


This persists even after a clean / rebuild of both 1.3.0-rc1 and the
project using it.


I can just exclude that jar in the assembly definition, but is anyone else
seeing similar issues?  If so, might be worth resolving rather than make
users mess with assembly exclusions.

I see that this class was introduced a while ago, related to SPARK-3812 but
the jira issue doesn't have much detail.

--001a1134a7ae88d78d050feba19d--

From dev-return-11765-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 16:52:16 2015
Return-Path: <dev-return-11765-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 70ED217384
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 16:52:16 +0000 (UTC)
Received: (qmail 70671 invoked by uid 500); 25 Feb 2015 16:52:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70593 invoked by uid 500); 25 Feb 2015 16:52:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70581 invoked by uid 99); 25 Feb 2015 16:52:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 16:52:05 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.43 as permitted sender)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 16:52:01 +0000
Received: by labhs14 with SMTP id hs14so5220125lab.4
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 08:50:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=50UI9YEKjhUH1W+tcM1lmSG1h1MzRu2EounkwCjpcys=;
        b=M6HXkvXvsS6aYSLESy4+Nti9og7MJsoNVoZSxr/ShPSXclz8l725aPPIoZwgDOS3hn
         4QlY+xChJhY9xU0BBd6ozIqX9Iu10688kyQvJ++x0yiaXOnAOCcq1bJLz7BFqgmR3pii
         jr4yye7qX4WrHfEU/me5yetSd4zAzhGujUd3YilP3JCwDMjTdoEbjUs2p95KUg5HYEgw
         jR41WNbYlpj5hH/xedRmoCWufeOYc46QoExNZOZEPaJDj/qFCUpKKS1NfcA0yDGJ4A0T
         F5y+Y6FlrP0SbzaLNgnn2euM/JGcSpdTKofXhTYvMUikrd/GYbWkjziDNj2kkjMPhDhx
         Ro2w==
MIME-Version: 1.0
X-Received: by 10.152.7.204 with SMTP id l12mr3653742laa.1.1424883055864; Wed,
 25 Feb 2015 08:50:55 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Wed, 25 Feb 2015 08:50:55 -0800 (PST)
Received: by 10.25.0.6 with HTTP; Wed, 25 Feb 2015 08:50:55 -0800 (PST)
In-Reply-To: <CAF7ADNrh-qNEtjVL1efMHXxcgUOOArYLSTO+BKFwAJA_BGssoA@mail.gmail.com>
References: <W86692564455771424815011@atl4webmail17>
	<CAF7ADNrh-qNEtjVL1efMHXxcgUOOArYLSTO+BKFwAJA_BGssoA@mail.gmail.com>
Date: Wed, 25 Feb 2015 08:50:55 -0800
Message-ID: <CA+B-+fyFmj5TcDdHDwvdz=4u56cfN817fcVABjE+er5yg1L+Mw@mail.gmail.com>
Subject: Re: Have Friedman's glmnet algo running in Spark
From: Debasish Das <debasish.das83@gmail.com>
To: Joseph Bradley <joseph@databricks.com>
Cc: mike@mbowles.com, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c242b0643218050fec70a7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c242b0643218050fec70a7
Content-Type: text/plain; charset=UTF-8

Any reason why the regularization path cannot be implemented using current
owlqn pr ?

We can change owlqn in breeze to fit your needs...
 On Feb 24, 2015 3:27 PM, "Joseph Bradley" <joseph@databricks.com> wrote:

> Hi Mike,
>
> I'm not aware of a "standard" big dataset, but there are a number
> available:
> * The YearPredictionMSD dataset from the LIBSVM datasets is sizeable (in #
> instances but not # features):
> www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html
> * I've used this text dataset from which one can generate lots of n-gram
> features (but not many instances): http://www.ark.cs.cmu.edu/10K/
> * I've seen some papers use the KDD Cup datasets, which might be the best
> option I know of.  The KDD Cup 2012 track 2 one seems promising.
>
> Good luck!
> Joseph
>
> On Tue, Feb 24, 2015 at 1:56 PM, <mike@mbowles.com> wrote:
>
> > Joseph,
> > Thanks for your reply.  We'll take the steps you suggest - generate some
> > timing comparisons and post them in the GLMNET JIRA with a link from the
> > OWLQN JIRA.
> >
> > We've got the regression version of GLMNET programmed.  The regression
> > version only requires a pass through the data each time the active set of
> > coefficients changes.  That's usualy less than or equal to the number of
> > decrements in the penalty coefficient (typical default = 100).  The
> > intermediate iterations can be done using results of previous passes
> > through the full data set.  We're expecting the number of data passes
> will
> > be independent of either number of rows or columns in the data set.
> We're
> > eager to demonstrate this scaling.  Do you have any suggestions regarding
> > data sets for large scale regression problems?  It would be nice to
> > demonstrate scaling for both number of rows and number of columns.
> >
> > Thanks for your help.
> > Mike
> >
> > -----Original Message-----
> > *From:* Joseph Bradley [mailto:joseph@databricks.com]
> > *Sent:* Sunday, February 22, 2015 06:48 PM
> > *To:* mike@mbowles.com
> > *Cc:* dev@spark.apache.org
> > *Subject:* Re: Have Friedman's glmnet algo running in Spark
> >
> > Hi Mike, glmnet has definitely been very successful, and it would be
> great
> > to see how we can improve optimization in MLlib! There is some related
> work
> > ongoing; here are the JIRAs: GLMNET implementation in Spark
> > LinearRegression with L1/L2 (elastic net) using OWLQN in new ML package
> > The GLMNET JIRA has actually been closed in favor of the latter JIRA.
> > However, if you're getting good results in your experiments, could you
> > please post them on the GLMNET JIRA and link them from the other JIRA? If
> > it's faster and more scalable, that would be great to find out. As far as
> > where the code should go and the APIs, that can be discussed on the
> JIRA. I
> > hope this helps, and I'll keep an eye out for updates on the JIRAs!
> Joseph
> > On Thu, Feb 19, 2015 at 10:59 AM,  wrote: > Dev List, > A couple of
> > colleagues and I have gotten several versions of glmnet algo > coded and
> > running on Spark RDD. glmnet algo ( >
> > http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm for >
> > generating coefficient paths solving penalized regression with elastic
> net
> > > penalties. The algorithm runs fast by taking an approach that
> generates >
> > solutions for a wide variety of penalty parameter. We're able to
> integrate
> > > into Mllib class structure a couple of different ways. The algorithm
> may
> > > fit better into the new pipeline structure since it naturally returns
> a >
> > multitide of models (corresponding to different vales of penalty >
> > parameters). That appears to fit better into pipeline than Mllib linear >
> > regression (for example). > > We've got regression running with the speed
> > optimizations that Friedman > recommends. We'll start working on the
> > logistic regression version next. > > We're eager to make the code
> > available as open source and would like to > get some feedback about how
> > best to do that. Any thoughts? > Mike Bowles. > > >
> >
> >
>

--001a11c242b0643218050fec70a7--

From dev-return-11766-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 17:42:44 2015
Return-Path: <dev-return-11766-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 20775175A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 17:42:44 +0000 (UTC)
Received: (qmail 51105 invoked by uid 500); 25 Feb 2015 17:42:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51026 invoked by uid 500); 25 Feb 2015 17:42:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51014 invoked by uid 99); 25 Feb 2015 17:42:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 17:42:39 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.181 as permitted sender)
Received: from [209.85.214.181] (HELO mail-ob0-f181.google.com) (209.85.214.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 17:42:35 +0000
Received: by mail-ob0-f181.google.com with SMTP id vb8so5329777obc.12
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 09:41:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/Q2iWhB+nDNiuu/9lYm7CuWYSwpaPnMGyTmRJQXDZ5c=;
        b=VyQytmhl3FAuNWOH+S0CKl0fZbdht+c0IB6hovMrr/lKlfeIcbcRAIo377OFhjRolq
         R/96w3XM+jfFAH2Pg9iKKBhTZXQtSo29QV6gmh+vBjGqmVAJ/GAwcCfIdU/n1WtvSgaf
         JutIgmS6ZZVTnyu0Ezq+sdxdzMeaW7oSgVe+9rSWiDnbGnRl8hl+BmLMVJ1XjYTrwBBo
         udT1ivFuyPnfbBUZFb9N+BvcCeOMfvkO4xw+8ETyfVl3BIQSJkta4yUCrChwu76zD9+m
         +2UK1HUUWAnBlYeQAGMKbVH6tmh6d4YIX7DDOzjYGcc3VAKWrdQN8D5Qr5eRiSNDkRLD
         Dakg==
MIME-Version: 1.0
X-Received: by 10.182.22.137 with SMTP id d9mr3021849obf.67.1424886089667;
 Wed, 25 Feb 2015 09:41:29 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 25 Feb 2015 09:41:29 -0800 (PST)
In-Reply-To: <CAKWX9VWWtRTJ9FGK+t30pdMcg8jPTPpvgfJyu6LSRmuGqAJ1BA@mail.gmail.com>
References: <CAKWX9VWWtRTJ9FGK+t30pdMcg8jPTPpvgfJyu6LSRmuGqAJ1BA@mail.gmail.com>
Date: Wed, 25 Feb 2015 09:41:29 -0800
Message-ID: <CABPQxsud9gDuAnFn-XaVj_C11gEo70T1L8-uXHXmEcAqRQp8Bg@mail.gmail.com>
Subject: Re: UnusedStubClass in 1.3.0-rc1
From: Patrick Wendell <pwendell@gmail.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Cody,

What build command are you using? In any case, we can actually comment
out the "unused" thing now in the root pom.xml. It existed just to
ensure that at least one dependency was listed in the shade plugin
configuration (otherwise, some work we do that requires the shade
plugin does not happen). However, now there are other things there. If
you just comment out the line in the root pom.xml adding this
dependency, does it work?

- Patrick

On Wed, Feb 25, 2015 at 7:53 AM, Cody Koeninger <cody@koeninger.org> wrote:
> So when building 1.3.0-rc1 I see the following warning:
>
> [WARNING] spark-streaming-kafka_2.10-1.3.0.jar, unused-1.0.0.jar define 1
> overlappping classes:
>
> [WARNING]   - org.apache.spark.unused.UnusedStubClass
>
>
> and when trying to build an assembly of a project that was previously using
> 1.3 snapshots without difficulty, I see the following errors:
>
>
> [error] (*:assembly) deduplicate: different file contents found in the
> following:
>
> [error]
> /Users/cody/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.3.0/spark-streaming-kafka_2.10-1.3.0.jar:org/apache/spark/unused/UnusedStubClass.class
>
> [error]
> /Users/cody/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:org/apache/spark/unused/UnusedStubClass.class
>
>
> This persists even after a clean / rebuild of both 1.3.0-rc1 and the
> project using it.
>
>
> I can just exclude that jar in the assembly definition, but is anyone else
> seeing similar issues?  If so, might be worth resolving rather than make
> users mess with assembly exclusions.
>
> I see that this class was introduced a while ago, related to SPARK-3812 but
> the jira issue doesn't have much detail.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11767-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 17:44:45 2015
Return-Path: <dev-return-11767-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ADA04175BD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 17:44:45 +0000 (UTC)
Received: (qmail 58846 invoked by uid 500); 25 Feb 2015 17:44:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58770 invoked by uid 500); 25 Feb 2015 17:44:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58758 invoked by uid 99); 25 Feb 2015 17:44:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 17:44:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 17:44:19 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so5354979obc.5
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 09:42:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=WXGGH/auA6ggOzAIjRsdRT89854AT9uadmLavFyQbOE=;
        b=i32iy8TMkVtY7rTNqpU7YbymLrochJXpAYVcqsNR59eKoO1n7PsgLdlVwFgNnUCbhc
         bObElVtkv2NRSBbBc83/eVL+I+GmqUlmfxV8gAwyISRpTxM0mQvp+oY+YL1mSnGrpOXA
         nBa5aDlhd+OBxpZ0eF41WN9TwA576IWJsHOZUiDu26GjKQpvq35ecdysqCrU0FDjDmmH
         vL7deJ1q+MGn2OLpQ9MqpWIv4UA/wAlGJfRJDg2lQFdCk6lyUakr0Fm7KddUFDIb+0Hi
         jmlcBeshrSD+dGrA9WhpnYQSGUOnXORWN280CmBW1RUBVzVeKGfu0AY2aAmuorWgq5go
         J7WA==
MIME-Version: 1.0
X-Received: by 10.202.196.137 with SMTP id u131mr2868700oif.78.1424886122909;
 Wed, 25 Feb 2015 09:42:02 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 25 Feb 2015 09:42:02 -0800 (PST)
In-Reply-To: <CABPQxsud9gDuAnFn-XaVj_C11gEo70T1L8-uXHXmEcAqRQp8Bg@mail.gmail.com>
References: <CAKWX9VWWtRTJ9FGK+t30pdMcg8jPTPpvgfJyu6LSRmuGqAJ1BA@mail.gmail.com>
	<CABPQxsud9gDuAnFn-XaVj_C11gEo70T1L8-uXHXmEcAqRQp8Bg@mail.gmail.com>
Date: Wed, 25 Feb 2015 09:42:02 -0800
Message-ID: <CABPQxsuwc02wAK8p40rko8VebJUynVBYOmqOvQP7QaDzYQp5MQ@mail.gmail.com>
Subject: Re: UnusedStubClass in 1.3.0-rc1
From: Patrick Wendell <pwendell@gmail.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

This has been around for multiple versions of Spark, so I am a bit
surprised to see it not working in your build.

- Patrick

On Wed, Feb 25, 2015 at 9:41 AM, Patrick Wendell <pwendell@gmail.com> wrote:
> Hey Cody,
>
> What build command are you using? In any case, we can actually comment
> out the "unused" thing now in the root pom.xml. It existed just to
> ensure that at least one dependency was listed in the shade plugin
> configuration (otherwise, some work we do that requires the shade
> plugin does not happen). However, now there are other things there. If
> you just comment out the line in the root pom.xml adding this
> dependency, does it work?
>
> - Patrick
>
> On Wed, Feb 25, 2015 at 7:53 AM, Cody Koeninger <cody@koeninger.org> wrote:
>> So when building 1.3.0-rc1 I see the following warning:
>>
>> [WARNING] spark-streaming-kafka_2.10-1.3.0.jar, unused-1.0.0.jar define 1
>> overlappping classes:
>>
>> [WARNING]   - org.apache.spark.unused.UnusedStubClass
>>
>>
>> and when trying to build an assembly of a project that was previously using
>> 1.3 snapshots without difficulty, I see the following errors:
>>
>>
>> [error] (*:assembly) deduplicate: different file contents found in the
>> following:
>>
>> [error]
>> /Users/cody/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.3.0/spark-streaming-kafka_2.10-1.3.0.jar:org/apache/spark/unused/UnusedStubClass.class
>>
>> [error]
>> /Users/cody/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:org/apache/spark/unused/UnusedStubClass.class
>>
>>
>> This persists even after a clean / rebuild of both 1.3.0-rc1 and the
>> project using it.
>>
>>
>> I can just exclude that jar in the assembly definition, but is anyone else
>> seeing similar issues?  If so, might be worth resolving rather than make
>> users mess with assembly exclusions.
>>
>> I see that this class was introduced a while ago, related to SPARK-3812 but
>> the jira issue doesn't have much detail.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11768-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 18:31:12 2015
Return-Path: <dev-return-11768-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5E750177F3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 18:31:12 +0000 (UTC)
Received: (qmail 6758 invoked by uid 500); 25 Feb 2015 18:31:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6686 invoked by uid 500); 25 Feb 2015 18:31:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6652 invoked by uid 99); 25 Feb 2015 18:31:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:31:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.218.48] (HELO mail-oi0-f48.google.com) (209.85.218.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:31:01 +0000
Received: by mail-oi0-f48.google.com with SMTP id a3so4875285oib.7
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 10:28:05 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=csao3tx0/7Ew4IA+TYtRO3LtmcGz4TTP85LuoP0xrTE=;
        b=WW+6WwVGgpJQc8lTQITQxEElKvbPUX7GJBj9rbP8dEPBW4CJidzd33+z1covd9SqsB
         NdKh6J/YeoHMnbuFhUBL7Cird+s43FilBfzk/wQT2cALA+f6/AzzuHlkR24JiSGC8r9c
         j4oMn3XtSB6ct5pE1YQnYGd4slLAwEPl+B+5bZ0QB2n844mSB2esarAp9SHZC1a4CLQg
         j5HsrKG9P9uaVxDCJHddQ9bsrLFkNwrlByO1fhOjIXHgNFfReMsax7F/vWC/0nfnwPbP
         NCKfDSCdwscYi3ValvzfLmvJFaDDfJOL3fzD/nYoqoowS7VnmVJtr+vE35ndKWP+SIcM
         1KFg==
X-Gm-Message-State: ALoCoQmHk33Xakq7WT3kXDLSeGfHkrqYWNn5SgtXq/ZlSgJmkzXaLCiwpX4DI6X+iAZ1IbldaM5f
MIME-Version: 1.0
X-Received: by 10.202.85.17 with SMTP id j17mr2968600oib.65.1424888885534;
 Wed, 25 Feb 2015 10:28:05 -0800 (PST)
Received: by 10.76.87.36 with HTTP; Wed, 25 Feb 2015 10:28:05 -0800 (PST)
In-Reply-To: <CABPQxsuwc02wAK8p40rko8VebJUynVBYOmqOvQP7QaDzYQp5MQ@mail.gmail.com>
References: <CAKWX9VWWtRTJ9FGK+t30pdMcg8jPTPpvgfJyu6LSRmuGqAJ1BA@mail.gmail.com>
	<CABPQxsud9gDuAnFn-XaVj_C11gEo70T1L8-uXHXmEcAqRQp8Bg@mail.gmail.com>
	<CABPQxsuwc02wAK8p40rko8VebJUynVBYOmqOvQP7QaDzYQp5MQ@mail.gmail.com>
Date: Wed, 25 Feb 2015 12:28:05 -0600
Message-ID: <CAKWX9VU5yRN6FrDgCpGheHzPGn4qVp1A_M8As_jK2_bznhR1UA@mail.gmail.com>
Subject: Re: UnusedStubClass in 1.3.0-rc1
From: Cody Koeninger <cody@koeninger.org>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d2e2cddf994050fedcb59
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d2e2cddf994050fedcb59
Content-Type: text/plain; charset=UTF-8

I'm building with

mvn -Phadoop-2.4 -DskipTests install


Yeah, commenting out the unused dependency in the root pom.xml resolves
it.  I'm a little surprised that it cropped up now as well, I had built
against multiple different snapshots of 1.3 over the past couple weeks with
no problems.


Is it worth me putting in a PR to remove that class and the dependency
altogether?

On Wed, Feb 25, 2015 at 11:42 AM, Patrick Wendell <pwendell@gmail.com>
wrote:

> This has been around for multiple versions of Spark, so I am a bit
> surprised to see it not working in your build.
>
> - Patrick
>
> On Wed, Feb 25, 2015 at 9:41 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Hey Cody,
> >
> > What build command are you using? In any case, we can actually comment
> > out the "unused" thing now in the root pom.xml. It existed just to
> > ensure that at least one dependency was listed in the shade plugin
> > configuration (otherwise, some work we do that requires the shade
> > plugin does not happen). However, now there are other things there. If
> > you just comment out the line in the root pom.xml adding this
> > dependency, does it work?
> >
> > - Patrick
> >
> > On Wed, Feb 25, 2015 at 7:53 AM, Cody Koeninger <cody@koeninger.org>
> wrote:
> >> So when building 1.3.0-rc1 I see the following warning:
> >>
> >> [WARNING] spark-streaming-kafka_2.10-1.3.0.jar, unused-1.0.0.jar define
> 1
> >> overlappping classes:
> >>
> >> [WARNING]   - org.apache.spark.unused.UnusedStubClass
> >>
> >>
> >> and when trying to build an assembly of a project that was previously
> using
> >> 1.3 snapshots without difficulty, I see the following errors:
> >>
> >>
> >> [error] (*:assembly) deduplicate: different file contents found in the
> >> following:
> >>
> >> [error]
> >>
> /Users/cody/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.3.0/spark-streaming-kafka_2.10-1.3.0.jar:org/apache/spark/unused/UnusedStubClass.class
> >>
> >> [error]
> >>
> /Users/cody/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:org/apache/spark/unused/UnusedStubClass.class
> >>
> >>
> >> This persists even after a clean / rebuild of both 1.3.0-rc1 and the
> >> project using it.
> >>
> >>
> >> I can just exclude that jar in the assembly definition, but is anyone
> else
> >> seeing similar issues?  If so, might be worth resolving rather than make
> >> users mess with assembly exclusions.
> >>
> >> I see that this class was introduced a while ago, related to SPARK-3812
> but
> >> the jira issue doesn't have much detail.
>

--001a113d2e2cddf994050fedcb59--

From dev-return-11769-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 18:33:51 2015
Return-Path: <dev-return-11769-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B8C6217808
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 18:33:51 +0000 (UTC)
Received: (qmail 15723 invoked by uid 500); 25 Feb 2015 18:33:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15577 invoked by uid 500); 25 Feb 2015 18:33:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14859 invoked by uid 99); 25 Feb 2015 18:33:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:33:45 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:33:41 +0000
Received: by iebtr6 with SMTP id tr6so7368281ieb.10;
        Wed, 25 Feb 2015 10:33:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=yV5JKrYLD59/V4JenVb51PVjvnYKbd6x73avAUc/ccw=;
        b=CoXAgu9E3KwbGjqDl6EsKIeZEjsXn30tzeD4Y+2175OV54IhJvXuPyFrSNJYDpRs+H
         LjmDkDPc/xTm3zCZarQm3OLHdWo1gwyX5lK+PrQOkUGcVY84ZiE2Pzjm++OuwhaFhCpz
         V2PVUzwx45NSi3OjRUI/hq2d7iIXDBFAWz/+0nNd242293WV1PlvivTJfbKt3AJza+5A
         VaugeLuAYFfCYfCivCdpKbUFWKZhM3O+hRITz2C19ItguJbsIYZokhke361zFHhUaxNH
         PnJZEvfsTGmUFkozqz5ph71b37HtFmU3bmYdeq6gcwiumTlo6RQ9Yxrzzv4fli40g1A0
         iC8Q==
MIME-Version: 1.0
X-Received: by 10.107.7.154 with SMTP id g26mr6212055ioi.64.1424889201352;
 Wed, 25 Feb 2015 10:33:21 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Wed, 25 Feb 2015 10:33:21 -0800 (PST)
In-Reply-To: <CAPh_B=bJ8Ed4-noRMrgY2PJxZGHGqPrFWxV+mQ2=0bUmzVgZQA@mail.gmail.com>
References: <CAPh_B=bJ8Ed4-noRMrgY2PJxZGHGqPrFWxV+mQ2=0bUmzVgZQA@mail.gmail.com>
Date: Wed, 25 Feb 2015 10:33:21 -0800
Message-ID: <CAJgQjQ8G6O-3=c+TPE+O9iyi5hGz2biXAFDiGNo8mg61hUpJGw@mail.gmail.com>
Subject: Re: Help vote for Spark talks at the Hadoop Summit
From: Xiangrui Meng <mengxr@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, user <user@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Made 3 votes to each of the talks. Looking forward to see them in
Hadoop Summit:) -Xiangrui

On Tue, Feb 24, 2015 at 9:54 PM, Reynold Xin <rxin@databricks.com> wrote:
> Hi all,
>
> The Hadoop Summit uses community choice voting to decide which talks to
> feature. It would be great if the community could help vote for Spark talks
> so that Spark has a good showing at this event. You can make three votes on
> each track. Below I've listed 3 talks that are important to Spark's
> roadmap. Please give 3 votes to each of the following talks.
>
> Committer Track: Lessons from Running Ultra Large Scale Spark Workloads on
> Hadoop
> https://hadoopsummit.uservoice.com/forums/283260-committer-track/suggestions/7074016
>
> Data Science track: DataFrames: large-scale data science on Hadoop data
> with Spark
> https://hadoopsummit.uservoice.com/forums/283261-data-science-and-hadoop/suggestions/7074147
>
> Future of Hadoop track: Online Approximate OLAP in SparkSQL
> https://hadoopsummit.uservoice.com/forums/283266-the-future-of-apache-hadoop/suggestions/7074424
>
>
> Thanks!

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11770-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 18:37:44 2015
Return-Path: <dev-return-11770-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9355D1782F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 18:37:44 +0000 (UTC)
Received: (qmail 32756 invoked by uid 500); 25 Feb 2015 18:37:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32674 invoked by uid 500); 25 Feb 2015 18:37:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32658 invoked by uid 99); 25 Feb 2015 18:37:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:37:36 +0000
X-ASF-Spam-Status: No, hits=5.1 required=10.0
	tests=FSL_HELO_BARE_IP_2,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,RCVD_NUMERIC_HELO
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.17.115.45] (HELO atl4mhob07.myregisteredsite.com) (209.17.115.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:37:11 +0000
Received: from atl4webmail18 ([10.30.71.175])
	by atl4mhob07.myregisteredsite.com (8.14.4/8.14.4) with ESMTP id t1PIZEDN004920;
	Wed, 25 Feb 2015 13:35:14 -0500
Received: from 12.250.97.26 (mike@mbowles.com [12.250.97.26])
          by atl4webmail18 (Netsol 11.2.30)
          with WEBMAIL id 17588;
          Wed, 25 Feb 2015 18:35:14 +0000
From: mike@mbowles.com
To: "Debasish Das" <debasish.das83@gmail.com>,
        "Joseph Bradley" 
    <joseph@databricks.com>
Cc: mike@mbowles.com, "dev" <dev@spark.apache.org>
Importance: Normal
Sensitivity: Normal
Message-ID: <W841642385175881424889314@atl4webmail18>
X-Mailer: Network Solutions Webmail, Build 11.2.30
X-Originating-IP: [12.250.97.26]
X-Forwarded-For: [(null)]
X-Authenticated-UID: mike@mbowles.com
Date: Wed, 25 Feb 2015 18:35:14 +0000
Subject: Re:  Have Friedman's glmnet algo running in Spark
MIME-Version: 1.0
Content-Type: multipart/alternative;
        boundary="--=_vm_0011_W841642385_17588_1424889314"
X-Virus-Checked: Checked by ClamAV on apache.org

----=_vm_0011_W841642385_17588_1424889314
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable

 Hi Debasish, 
Any method that generates point solutions to the minimization problem cou=
ld simply be run a number of times to generate the coefficient paths as a=
 function of the penalty parameter. I think the only issues are how easy =
the method is to use and how much training and developer time is required=
 to produce an answer. 

With regard to training time, Friedman says in his paper that they found =
problems where glmnet would generate the entire coefficient path more rap=
idly than sophisticated single point methods would generate single point =
solutions - not all problems, but some problems. Ryan Tibshirani (Robert'=
s son) who's a professor and researcher at CMU in convex function optimiz=
ation has echoed that assertion for the particular case of the elasticnet=
 penalty function (that's from slides of his that are available online). =
So there's an open question about the training speed that i believe we ca=
n answer in fairly short order. I'm eager to explore that. Does OWLQN do =
a pass through the data for each iteration? The linear version of GLMNET =
does not. On the other hand, OWLQN may be able to take coarser steps thro=
ugh parameter space. 

With regard to developer time, glmnet doesn't require the user to supply =
a starting point for the penalty parameter. It calculates the starting po=
int. That makes it completely automatic. you've probably been through the=
 process of manually searching regularization parameter space with SVM. P=
ick out a set of regularization parameter values like 10 raised to the (-=
2 through +5 in steps of 1). See if there's a minimum in the range and if=
 not shift to the right or left. One of the reasons I pick up glmnet firs=
t for a new problem is that you just drop in the training set and out pop=
 the coefficient curves. Usually the defaults work. One time out of 50 (o=
r so) it doesn't converge. It alerts you that it didn't converge and you =
change one parameter and rerun. If you also drop in a test set then it ev=
en picks the optimum solution andproduces an estimate of out-of-sample er=
ror. 

We're going to make some speed/scaling runs on the synthetic data sets (i=
n a range of sizes) that are used in Spark for testing linear regression.=
 We need some wider data sets. Joseph mentioned some that we'll look at. =
I've got a gene expression data set that's 30k wide by 15k tall. That tak=
es a few hours to train using R version of glmnet. We're also talking to =
some biology friends to find other interesting data sets. 

I really am eager to see the comparisons. And happy to help you tailor OW=
LQN to generate coefficient paths. We might be able to produce a hybrid o=
f Friedman's algorithm using his basic algorithm outline but substituting=
 OWLQN for his round-robin coordinate descent. But i'm a little cocerned =
that it's the round-robin coordinate descent that makes it possible to sk=
ip passing through the full data set for 4 out of 5 iterations. We might =
be able to work a way around that. 

I'm just eager to have parallel versions of the tools available. I'll kee=
p you posted on our results. We should aim for running one another's code=
. I'll check with my colleagues and see when we'll have something we can =
hand out. We've delayed putting together a release version in favor of ge=
nerating some scaling results, as Joseph suggested. Discussions like this=
 may have some impact on what the release code looks like. 
Mike






-----Original Message---
From: Debasish Das [mailto:debasish.das83@gmail.com]
Sent: Wednesday, February 25, 2015 08:50 AM
To: 'Joseph Bradley'
Cc: mike@mbowles.com, 'dev'
Subject: Re: Have Friedman's glmnet algo running in Spark

Any reason why the regularization path cannot be implemented using curren=
t owlqn pr ?
We can change owlqn in breeze to fit your needs...

On Feb 24, 2015 3:27 PM, "Joseph Bradley" <joseph@databricks.com> wrote:
Hi Mike,

I'm not aware of a "standard" big dataset, but there are a number availab=
le:
* The YearPredictionMSD dataset from the LIBSVM datasets is sizeable (in =
#
instances but not # features):
www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html
* I've used this text dataset from which one can generate lots of n-gram
features (but not many instances): http://www.ark.cs.cmu.edu/10K/
* I've seen some papers use the KDD Cup datasets, which might be the best=

option I know of. The KDD Cup 2012 track 2 one seems promising.

Good luck!
Joseph

On Tue, Feb 24, 2015 at 1:56 PM, <mike@mbowles.com> wrote:

> Joseph,
> Thanks for your reply. We'll take the steps you suggest - generate some=

> timing comparisons and post them in the GLMNET JIRA with a link from th=
e
> OWLQN JIRA.
>
> We've got the regression version of GLMNET programmed. The regression
> version only requires a pass through the data each time the active set =
of
> coefficients changes. That's usualy less than or equal to the number of=

> decrements in the penalty coefficient (typical default =3D 100). The
> intermediate iterations can be done using results of previous passes
> through the full data set. We're expecting the number of data passes wi=
ll
> be independent of either number of rows or columns in the data set. We'=
re
> eager to demonstrate this scaling. Do you have any suggestions regardin=
g
> data sets for large scale regression problems? It would be nice to
> demonstrate scaling for both number of rows and number of columns.
>
> Thanks for your help.
> Mike
>
> -----Original Message-----
> *From:* Joseph Bradley [mailto:joseph@databricks.com]
> *Sent:* Sunday, February 22, 2015 06:48 PM
> *To:* mike@mbowles.com
> *Cc:* dev@spark.apache.org
> *Subject:* Re: Have Friedman's glmnet algo running in Spark
>
> Hi Mike, glmnet has definitely been very successful, and it would be gr=
eat
> to see how we can improve optimization in MLlib! There is some related =
work
> ongoing; here are the JIRAs: GLMNET implementation in Spark
> LinearRegression with L1/L2 (elastic net) using OWLQN in new ML package=

> The GLMNET JIRA has actually been closed in favor of the latter JIRA.
> However, if you're getting good results in your experiments, could you
> please post them on the GLMNET JIRA and link them from the other JIRA? =
If
> it's faster and more scalable, that would be great to find out. As far =
as
> where the code should go and the APIs, that can be discussed on the JIR=
A. I
> hope this helps, and I'll keep an eye out for updates on the JIRAs! Jos=
eph
> On Thu, Feb 19, 2015 at 10:59 AM, wrote: > Dev List, > A couple of
> colleagues and I have gotten several versions of glmnet algo > coded an=
d
> running on Spark RDD. glmnet algo ( >
> http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm for >
> generating coefficient paths solving penalized regression with elastic =
net
> > penalties. The algorithm runs fast by taking an approach that generat=
es >
> solutions for a wide variety of penalty parameter. We're able to integr=
ate
> > into Mllib class structure a couple of different ways. The algorithm =
may
> > fit better into the new pipeline structure since it naturally returns=
 a >
> multitide of models (corresponding to different vales of penalty >
> parameters). That appears to fit better into pipeline than Mllib linear=
 >
> regression (for example). > > We've got regression running with the spe=
ed
> optimizations that Friedman > recommends. We'll start working on the
> logistic regression version next. > > We're eager to make the code
> available as open source and would like to > get some feedback about ho=
w
> best to do that. Any thoughts? > Mike Bowles. > > >
>
>



----=_vm_0011_W841642385_17588_1424889314--



From dev-return-11771-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 18:38:35 2015
Return-Path: <dev-return-11771-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 534871783A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 18:38:35 +0000 (UTC)
Received: (qmail 38637 invoked by uid 500); 25 Feb 2015 18:38:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38564 invoked by uid 500); 25 Feb 2015 18:38:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38552 invoked by uid 99); 25 Feb 2015 18:38:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:38:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:38:09 +0000
Received: by lbdu10 with SMTP id u10so5825999lbd.7
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 10:38:06 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=isV29u9TYIBGYzGjctzwRAIporQnAawF9H5BZF5rTrA=;
        b=ks5QowkMGv6qZ0HYWOR0ZUS3GGXMBP8bUL/sOwuio0Fdez2aQQ88p5cjNhKQk6yoLw
         wRGmAoyAFJrTc80rEwF2wHY8RbRj/9lQjFiKfsdQ5PVovZilp/rz0hj0w9ocTunovb+V
         STH+RkTvYYAF+6H2zL27nGM8S7QA56IyigoRgzE8z+/2Hg+8Cggk4i0H1Xhu01NCg/RS
         L8C94hYWl8n5QMXCqOmrVDmiFRB9fb3nQ7vzZtnl34qEtOOG8KwmuoPXoDFRZ5ay8fQx
         mFP6DBEmiRiVomEYSqGSrYdy6pXpAtyHNaw5I3TYqZVwvnUxhvyiBTyfevbSLk/RYQm4
         MMBA==
X-Gm-Message-State: ALoCoQnn6QU1C/SSH9sH9UIxtQnFNMElXaUPRN9Nt4CgC5kIKz4QXQj2j9ts1pHEi7TkmaVz+JY2
X-Received: by 10.112.41.171 with SMTP id g11mr3988362lbl.107.1424889486091;
 Wed, 25 Feb 2015 10:38:06 -0800 (PST)
MIME-Version: 1.0
Received: by 10.114.95.7 with HTTP; Wed, 25 Feb 2015 10:37:45 -0800 (PST)
In-Reply-To: <CACdU-dSmHf6nGH-ovkoG2NZyQOQoKNK_jnY9B9z+McdywsVpbA@mail.gmail.com>
References: <CACdU-dSmHf6nGH-ovkoG2NZyQOQoKNK_jnY9B9z+McdywsVpbA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 25 Feb 2015 10:37:45 -0800
Message-ID: <CACdU-dRkZDr_wq7=TozJcDjYHp-zE_1OQTYR_prUkEVomK7GEw@mail.gmail.com>
Subject: Re: [jenkins infra -- pls read ] installing anaconda, moving default
 python from 2.6 -> 2.7
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11346d9ca9c344050fedef69
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11346d9ca9c344050fedef69
Content-Type: text/plain; charset=UTF-8

i'm going to punt on this until after the next spark 1.3 release (2-3
weeks?).  since i'll be installing a bunch of other packages (including
mongodb), i'd rather wait and be safe.  :)

the full install list is forthcoming, and i'll update the spark infra wiki
w/what's installed on the workers.

shane

On Mon, Feb 23, 2015 at 11:13 AM, shane knapp <sknapp@berkeley.edu> wrote:

> good morning, developers!
>
> TL;DR:
>
> i will be installing anaconda and setting it in the system PATH so that
> your python will default to 2.7, as well as it taking over management of
> all of the sci-py packages.  this is potentially a big change, so i'll be
> testing locally on my staging instance before deployment to the wide world.
>
> deployment is *tentatively* next monday, march 2nd.
>
> a little background:
>
> the jenkins test infra is currently (and happily) managed by a set of
> tools that allow me to set up and deploy new workers, manage their packages
> and make sure that all spark and research projects can happily and
> successfully build.
>
> we're currently at the state where ~50 or so packages are installed and
> configured on each worker.  this is getting a little cumbersome, as the
> package-to-build dep tree is getting pretty large.
>
> the biggest offender is the science-based python infrastructure.
>  everything is blindly installed w/yum and pip, so it's hard to control
> *exactly* what version of any given library is as compared to what's on a
> dev's laptop.
>
> the solution:
>
> anaconda (https://store.continuum.io/cshop/anaconda/)!  everything is
> centralized!  i can manage specific versions much easier!
>
> what this means to you:
>
> * python 2.7 will be the default system python.
> * 2.6 will still be installed and available (/usr/bin/python or
> /usr/bin/python/2.6)
>
> what you need to do:
> * install anaconda, have it update your PATH
> * build locally and try to fix any bugs (for spark, this "should just
> work")
> * if you have problems, reach out to me and i'll see what i can do to
> help.  if we can't get your stuff running under python2.7, we can default
> to 2.6 via a job config change.
>
> what i will be doing:
> * setting up anaconda on my staging instance and spot-testing a lot of
> builds before deployment
>
> please let me know if there are any issues/concerns...  i'll be posting
> updates this week and will let everyone know if there are any changes to
> the Plan[tm].
>
> your friendly devops engineer,
>
> shane
>

--001a11346d9ca9c344050fedef69--

From dev-return-11772-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 18:45:56 2015
Return-Path: <dev-return-11772-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CEF09178BF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 18:45:56 +0000 (UTC)
Received: (qmail 66651 invoked by uid 500); 25 Feb 2015 18:45:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66571 invoked by uid 500); 25 Feb 2015 18:45:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66560 invoked by uid 99); 25 Feb 2015 18:45:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:45:55 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mnazario@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 18:45:50 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Wed, 25
 Feb 2015 10:45:29 -0800
From: Michael Nazario <mnazario@palantir.com>
To: Denny Lee <denny.g.lee@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: PySpark SPARK_CLASSPATH doesn't distribute jars to executors
Thread-Topic: PySpark SPARK_CLASSPATH doesn't distribute jars to executors
Thread-Index: AdBQhNTW9FpX7GMKS9yFXlPyaWXaBgAJVtEIACA7Hm0=
Date: Wed, 25 Feb 2015 18:45:28 +0000
Message-ID: <06F190FE1D7B544E8892799F08EA9C503AC03A@ex02-west.YOJOE.local>
References: <06F190FE1D7B544E8892799F08EA9C503A9CB5@ex02-west.YOJOE.local>,<CABjYQ3_M6NfDkuzvsccwjqrYidJ-j9bHhgK2RPCAMTykVT0N7A@mail.gmail.com>
In-Reply-To: <CABjYQ3_M6NfDkuzvsccwjqrYidJ-j9bHhgK2RPCAMTykVT0N7A@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.100.70.117]
Content-Type: multipart/alternative;
	boundary="_000_06F190FE1D7B544E8892799F08EA9C503AC03Aex02westYOJOEloca_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_06F190FE1D7B544E8892799F08EA9C503AC03Aex02westYOJOEloca_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Neither of those helped. I'm still getting a ClassNotFoundException on the =
workers.
________________________________
From: Denny Lee [denny.g.lee@gmail.com]
Sent: Tuesday, February 24, 2015 7:21 PM
To: Michael Nazario; dev@spark.apache.org
Subject: Re: PySpark SPARK_CLASSPATH doesn't distribute jars to executors

Can you try extraClassPath or driver-class-path and see if that helps with =
the distribution?
On Tue, Feb 24, 2015 at 14:54 Michael Nazario <mnazario@palantir.com<mailto=
:mnazario@palantir.com>> wrote:
Has anyone experienced a problem with the SPARK_CLASSPATH not distributing =
jars for PySpark? I have a detailed description of what I tried in the tick=
et below, and this seems like a problem that is not a configuration problem=
. The only other case I can think of is that configuration changed between =
Spark 1.1.1 and Spark 1.2.1 about distributing jars for PySpark.

https://issues.apache.org/jira/browse/SPARK-5977<https://urldefense.proofpo=
int.com/v2/url?u=3Dhttps-3A__issues.apache.org_jira_browse_SPARK-2D5977&d=
=3DAwMFaQ&c=3Dizlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=3DyN4Yj1JskMkGM=
KoYoLUUIQViRLGShPc1wislP1YdU4g&m=3DREuScW0kzWb6UlI-_aLgZdCGZ62fF2vfW9gRHXsx=
t_g&s=3DZwF_JWb5QHA4P9d9XuZU0u7ZGw-00kOSgfomsg_vREE&e=3D>

Thanks,
Michael

--_000_06F190FE1D7B544E8892799F08EA9C503AC03Aex02westYOJOEloca_--

From dev-return-11773-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 19:15:40 2015
Return-Path: <dev-return-11773-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6068917A57
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 19:15:40 +0000 (UTC)
Received: (qmail 69662 invoked by uid 500); 25 Feb 2015 19:15:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 69591 invoked by uid 500); 25 Feb 2015 19:15:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 69575 invoked by uid 99); 25 Feb 2015 19:15:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 19:15:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 19:15:34 +0000
Received: by iecrp18 with SMTP id rp18so7702724iec.9
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 11:14:54 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=5f8DHyaoyvOZKp1GDO5hPKOpz9x8PnUEFBTWVk/WZxc=;
        b=IUKX1V1cVHMcfC1gBo/6u+eQDKVmYs6fMNhSOII8aoUpM5BVLj4wKcQZzJUV/C+cQ1
         NgcNof6JV3L88Lwa+/KoqmgvH9JJYkWRZgH/yv4c382D3Fz/QJLHw2vtrCNgCDCRTvE9
         Xdpm+XBLK0diWJnYGs4pycBCqPo4MCbJvPCh0uTptLMYj/eoXKHJLgz5bMjpbWfS63G4
         aC1nAiBgeKuqe6cTJQ0LnXPkqD2wTnx2PxgRok1Hc7p6xKOVvLOM7L2ZBxWET8C26TC/
         dyGiGotx8UfUUn3CS6d0AzUJm86CcIa8pqlwsl+Kgicl1n+/l8xwT7NSVyq7nKyueOs3
         RuoQ==
X-Gm-Message-State: ALoCoQn4WxifDz1AWE8nztYrAiqttENtdYhbv0xDyUZM3GmMSnv8q+9SDlfXlRb7qgf9QHMLnfDD
MIME-Version: 1.0
X-Received: by 10.50.61.34 with SMTP id m2mr6870401igr.20.1424891692502; Wed,
 25 Feb 2015 11:14:52 -0800 (PST)
Received: by 10.36.118.18 with HTTP; Wed, 25 Feb 2015 11:14:52 -0800 (PST)
In-Reply-To: <W841642385175881424889314@atl4webmail18>
References: <W841642385175881424889314@atl4webmail18>
Date: Wed, 25 Feb 2015 11:14:52 -0800
Message-ID: <CAF7ADNoUZH3_z=j-8OFCidBAbHw4kNfUGQHxc5qtUqN4pCKf5w@mail.gmail.com>
Subject: Re: Have Friedman's glmnet algo running in Spark
From: Joseph Bradley <joseph@databricks.com>
To: mike@mbowles.com
Cc: Debasish Das <debasish.das83@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1135e0842cfb3f050fee7397
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135e0842cfb3f050fee7397
Content-Type: text/plain; charset=UTF-8

Some of this discussion seems valuable enough to preserve on the JIRA; can
we move it there (and copy any relevant discussions from previous emails as
needed)?

On Wed, Feb 25, 2015 at 10:35 AM, <mike@mbowles.com> wrote:

> Hi Debasish,
> Any method that generates point solutions to the minimization problem
> could simply be run a number of times to generate the coefficient paths as
> a function of the penalty parameter.  I think the only issues are how easy
> the method is to use and how much training and developer time is required
> to produce an answer.
>
> With regard to training time, Friedman says in his paper that they found
> problems where glmnet would generate the entire coefficient path more
> rapidly than sophisticated single point methods would generate single point
> solutions - not all problems, but some problems.  Ryan Tibshirani (Robert's
> son) who's a professor and researcher at CMU in convex function
> optimization has echoed that assertion for the particular case of the
> elasticnet penalty function (that's from slides of his that are available
> online).  So there's an open question about the training speed that i
> believe we can answer in fairly short order.  I'm eager to explore that.
> Does OWLQN do a pass through the data for each iteration?  The linear
> version of GLMNET does not.  On the other hand, OWLQN may be able to take
> coarser steps through parameter space.
>
> With regard to developer time, glmnet doesn't require the user to supply a
> starting point for the penalty parameter.  It calculates the starting
> point.  That makes it completely automatic.  you've probably been through
> the process of manually searching regularization parameter space with SVM.
> Pick out a set of regularization parameter values like 10 raised to the (-2
> through +5 in steps of 1).  See if there's a minimum in the range and if
> not shift to the right or left.  One of the reasons I pick up glmnet first
> for a new problem is that you just drop in the training set and out pop the
> coefficient curves.  Usually the defaults work.  One time out of 50 (or so)
> it doesn't converge.  It alerts you that it didn't converge and you change
> one parameter and rerun.  If you also drop in a test set then it even picks
> the optimum solution andproduces an estimate of out-of-sample error.
>
> We're going to make some speed/scaling runs on the synthetic data sets (in
> a range of sizes) that are used in Spark for testing linear regression.  We
> need some wider data sets.  Joseph mentioned some that we'll look at.  I've
> got a gene expression data set that's 30k wide by 15k tall.  That takes a
> few hours to train using R version of glmnet.  We're also talking to some
> biology friends to find other interesting data sets.
>
> I really am eager to see the comparisons.  And happy to help you tailor
> OWLQN to generate coefficient paths.  We might be able to produce a hybrid
> of Friedman's algorithm using his basic algorithm outline but substituting
> OWLQN for his round-robin coordinate descent.  But i'm a little cocerned
> that it's the round-robin coordinate descent that makes it possible to skip
> passing through the full data set for 4 out of 5 iterations.  We might be
> able to work a way around that.
>
> I'm just eager to have parallel versions of the tools available.  I'll
> keep you posted on our results.  We should aim for running one another's
> code.  I'll check with my colleagues and see when we'll have something we
> can hand out.  We've delayed putting together a release version in favor of
> generating some scaling results, as Joseph suggested.  Discussions like
> this may have some impact on what the release code looks like.
> Mike
>
>
>
>
>
> -----Original Message---
> *From:* Debasish Das [mailto:debasish.das83@gmail.com]
> *Sent:* Wednesday, February 25, 2015 08:50 AM
> *To:* 'Joseph Bradley'
> *Cc:* mike@mbowles.com, 'dev'
> *Subject:* Re: Have Friedman's glmnet algo running in Spark
>
> Any reason why the regularization path cannot be implemented using current
> owlqn pr ?
>
> We can change owlqn in breeze to fit your needs...
>  On Feb 24, 2015 3:27 PM, "Joseph Bradley" <joseph@databricks.com> wrote:
>
>> Hi Mike,
>>
>> I'm not aware of a "standard" big dataset, but there are a number
>> available:
>> * The YearPredictionMSD dataset from the LIBSVM datasets is sizeable (in #
>> instances but not # features):
>> www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html
>> * I've used this text dataset from which one can generate lots of n-gram
>> features (but not many instances): http://www.ark.cs.cmu.edu/10K/
>> * I've seen some papers use the KDD Cup datasets, which might be the best
>> option I know of.  The KDD Cup 2012 track 2 one seems promising.
>>
>> Good luck!
>> Joseph
>>
>> On Tue, Feb 24, 2015 at 1:56 PM, <mike@mbowles.com> wrote:
>>
>> > Joseph,
>> > Thanks for your reply.  We'll take the steps you suggest - generate some
>> > timing comparisons and post them in the GLMNET JIRA with a link from the
>> > OWLQN JIRA.
>> >
>> > We've got the regression version of GLMNET programmed.  The regression
>> > version only requires a pass through the data each time the active set
>> of
>> > coefficients changes.  That's usualy less than or equal to the number of
>> > decrements in the penalty coefficient (typical default = 100).  The
>> > intermediate iterations can be done using results of previous passes
>> > through the full data set.  We're expecting the number of data passes
>> will
>> > be independent of either number of rows or columns in the data set.
>> We're
>> > eager to demonstrate this scaling.  Do you have any suggestions
>> regarding
>> > data sets for large scale regression problems?  It would be nice to
>> > demonstrate scaling for both number of rows and number of columns.
>> >
>> > Thanks for your help.
>> > Mike
>> >
>> > -----Original Message-----
>> > *From:* Joseph Bradley [mailto:joseph@databricks.com]
>> > *Sent:* Sunday, February 22, 2015 06:48 PM
>> > *To:* mike@mbowles.com
>> > *Cc:* dev@spark.apache.org
>> > *Subject:* Re: Have Friedman's glmnet algo running in Spark
>> >
>> > Hi Mike, glmnet has definitely been very successful, and it would be
>> great
>> > to see how we can improve optimization in MLlib! There is some related
>> work
>> > ongoing; here are the JIRAs: GLMNET implementation in Spark
>> > LinearRegression with L1/L2 (elastic net) using OWLQN in new ML package
>> > The GLMNET JIRA has actually been closed in favor of the latter JIRA.
>> > However, if you're getting good results in your experiments, could you
>> > please post them on the GLMNET JIRA and link them from the other JIRA?
>> If
>> > it's faster and more scalable, that would be great to find out. As far
>> as
>> > where the code should go and the APIs, that can be discussed on the
>> JIRA. I
>> > hope this helps, and I'll keep an eye out for updates on the JIRAs!
>> Joseph
>> > On Thu, Feb 19, 2015 at 10:59 AM,  wrote: > Dev List, > A couple of
>> > colleagues and I have gotten several versions of glmnet algo > coded and
>> > running on Spark RDD. glmnet algo ( >
>> > http://www.jstatsoft.org/v33/i01/paper) is a very fast algorithm for >
>> > generating coefficient paths solving penalized regression with elastic
>> net
>> > > penalties. The algorithm runs fast by taking an approach that
>> generates >
>> > solutions for a wide variety of penalty parameter. We're able to
>> integrate
>> > > into Mllib class structure a couple of different ways. The algorithm
>> may
>> > > fit better into the new pipeline structure since it naturally returns
>> a >
>> > multitide of models (corresponding to different vales of penalty >
>> > parameters). That appears to fit better into pipeline than Mllib linear
>> >
>> > regression (for example). > > We've got regression running with the
>> speed
>> > optimizations that Friedman > recommends. We'll start working on the
>> > logistic regression version next. > > We're eager to make the code
>> > available as open source and would like to > get some feedback about how
>> > best to do that. Any thoughts? > Mike Bowles. > > >
>> >
>> >
>>
>

--001a1135e0842cfb3f050fee7397--

From dev-return-11774-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 22:15:11 2015
Return-Path: <dev-return-11774-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 04BAF173F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 22:15:11 +0000 (UTC)
Received: (qmail 80594 invoked by uid 500); 25 Feb 2015 22:15:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80513 invoked by uid 500); 25 Feb 2015 22:15:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80490 invoked by uid 99); 25 Feb 2015 22:15:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:15:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of devl.development@gmail.com designates 209.85.216.176 as permitted sender)
Received: from [209.85.216.176] (HELO mail-qc0-f176.google.com) (209.85.216.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:14:40 +0000
Received: by qcwb13 with SMTP id b13so5501262qcw.7
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 14:13:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=IZJlE41wJ3VzSHtltk656Ku9aNX2awq3yASVpIe1RRs=;
        b=SviFzzc4D0ZEXxcgg+4dUfWXEQH4EzzNHeHQrpbXOVNZ6S8rkd2ftns/Rv7JJmkbGl
         NEUp8N24sO6z0FJ7dB3c/FeZmPkTPebpmNcJQFO4aXCPg8A9cDRdCE4k8jff9otdwT2u
         tGMURrzDk4Oz4Hvu2ZDXqKyPqK/UcRHwT1gwBcjTbYx1wg/eVHu8VlPDnIZtzx0H5vIG
         EuMKUDXVJTAWOiVxpW/sfr1XqHMyoLfvItNswtz26i5Mmml4z6pG586OMuyy21hhK0V+
         pvCf8MfEodAAUAQCViZHubuG+K78R87GloZuYArUl/wUvC5LaNmJS82uq1OQpxgQ+buM
         pHQA==
MIME-Version: 1.0
X-Received: by 10.140.147.147 with SMTP id 141mr11925909qht.57.1424902389153;
 Wed, 25 Feb 2015 14:13:09 -0800 (PST)
Received: by 10.140.23.212 with HTTP; Wed, 25 Feb 2015 14:13:09 -0800 (PST)
Date: Wed, 25 Feb 2015 22:13:09 +0000
Message-ID: <CAMQ+LQPN+KTVz=Rd=qD2MCeoCHRfiTRJ555BKzQPPf2+PN35uQ@mail.gmail.com>
Subject: Some praise and comments on Spark
From: Devl Devel <devl.development@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11376f48bec7c5050ff0f065
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11376f48bec7c5050ff0f065
Content-Type: text/plain; charset=UTF-8

Hi Spark Developers,

First, apologies if this doesn't belong on this list but the
comments/praise are relevant to all developers. This is just a small note
about what we really like about Spark, I/we don't mean to start a whole
long discussion thread in this forum but just share our positive
experiences with Spark thus far.

To start, as you can tell, we think that the Spark project is amazing and
we love it! Having put in nearly half a decade worth of sweat and tears
into production Hadoop, MapReduce clusters and application development it's
so refreshing to see something arguably simpler and more elegant to
supersede it.

These are the things we love about Spark and hope these principles continue:

-the one command build; make-distribution.sh. Simple, clean  and ideal for
deployment and devops and rebuilding on different environments and nodes.
-not having too much runtime and deploy config; as admins and developers we
are sick of setting props like io.sort and mapred.job.shuffle.merge.percent
and dfs file locations and temp directories and so on and on again and
again every time we deploy a job, new cluster, environment or even change
company.
-a fully built-in stack, one global project for SQL, dataframes, MLlib etc,
so there is no need to add on projects to it on as per Hive, Hue, Hbase
etc. This helps life and keeps everything in one place.
-single (global) user based operation - no creation of a hdfs mapred unix
user, makes life much simpler
-single quick-start daemons; master and slaves. Not having to worry about
JT, NN, DN , TT, RM, Hbase master ... and doing netstat and jps on hundreds
of clusters makes life much easier.
-proper code versioning, feature releases and release management.
- good & well organised documentation with good examples.

In addition to the comments above this is where we hope Spark never ends
up:

-tonnes of configuration properties and "go faster" type flags. For example
Hadoop and Hbase users will know that there are a whole catalogue of
properties for regions, caches, network properties, block sizes, etc etc.
Please don't end up here for example:
https://hadoop.apache.org/docs/r1.0.4/mapred-default.html, it is painful
having to configure all of this and then create a set of properties for
each environment and then tie this into CI and deployment tools.
-no more daemons and processes to have to monitor and manipulate and
restart and crash.
-a project that penalises developers (that will ultimately help promote
Spark to their managers and budget holders) with expensive training,
certification, books and accreditation. Ideally this open source should be
free, free training= more users = more commercial uptake.

Anyway, those are our thoughts for what they are worth, keep up the good
work, we just had to mention it. Again sorry if this is not the right place
or if there is another forum for this stuff.

Cheers

--001a11376f48bec7c5050ff0f065--

From dev-return-11775-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 22:38:14 2015
Return-Path: <dev-return-11775-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AF9AD174D1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 22:38:14 +0000 (UTC)
Received: (qmail 67789 invoked by uid 500); 25 Feb 2015 22:38:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67706 invoked by uid 500); 25 Feb 2015 22:38:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67695 invoked by uid 99); 25 Feb 2015 22:38:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:38:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:38:05 +0000
Received: by mail-qg0-f41.google.com with SMTP id i50so5742795qgf.0
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 14:36:39 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=aTy06tBtqz07GDkieg+LNnt0oR4GfAUEPg4XGh62ANc=;
        b=KRp/Usv0h9XKmSx1Bs9W8BUNYvx2xgGfQUNA24Bph0QGOm/n1MnIMdhIzK3vMrXSAl
         KferIDHe8DPdduyz0gPlHCK8gJgRh7pCm+IK3Pn39bXuK2R5JEJw48DE0NVAn0M3+l9S
         8n8+IiuJapLcxDBfwhO2gLVYNGcQ8A5jCLF/6nW+Je3TS/LVhBS8OzdQF+ApecYiMrez
         jDjB7txn8X1HsBcCuE34U9znTPvzBo/6eHId6bZJxB+by00W14PgZxDMFqdc0+3HHeQd
         GYvFetge1ihX28bOjVw91Cz6FBbeMTJGCz0w1sfvbMpXnu2gxz4fZYlkkJkEf6P9rXJT
         d6mQ==
X-Gm-Message-State: ALoCoQlTiiPyCrM7X9xbvxReNj+ttyI9SFMpDTcD9tivnK1OqshUv4CI4PsOiGwR4fSJ+6Yoo6Z8
X-Received: by 10.229.182.9 with SMTP id ca9mr12096360qcb.31.1424903799418;
 Wed, 25 Feb 2015 14:36:39 -0800 (PST)
MIME-Version: 1.0
Received: by 10.96.109.9 with HTTP; Wed, 25 Feb 2015 14:36:19 -0800 (PST)
In-Reply-To: <CAMQ+LQPN+KTVz=Rd=qD2MCeoCHRfiTRJ555BKzQPPf2+PN35uQ@mail.gmail.com>
References: <CAMQ+LQPN+KTVz=Rd=qD2MCeoCHRfiTRJ555BKzQPPf2+PN35uQ@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 25 Feb 2015 14:36:19 -0800
Message-ID: <CAPh_B=b24KUyY=B+eTzmg2K+q4N-35vLEYk-OrVQENdOQaE0hw@mail.gmail.com>
Subject: Re: Some praise and comments on Spark
To: Devl Devel <devl.development@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134546ccdc826050ff14490
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134546ccdc826050ff14490
Content-Type: text/plain; charset=UTF-8

Thanks for the email and encouragement, Devl. Responses to the 3 requests:

-tonnes of configuration properties and "go faster" type flags. For example
Hadoop and Hbase users will know that there are a whole catalogue of
properties for regions, caches, network properties, block sizes, etc etc.
Please don't end up here for example:
https://hadoop.apache.org/docs/r1.0.4/mapred-default.html, it is painful
having to configure all of this and then create a set of properties for
each environment and then tie this into CI and deployment tools.

As the project grows, it is unavoidable to introduce more config options,
in particular, we often use config options to test new modules that are
still experimental before making them the default (e.g. sort-based shuffle).

The philosophy here is to make it a very high bar to introduce new config
options, and make the default values sensible for most deployments, and
then whenever possible, figure out automatically what is the right setting.
Note that this in general is hard, but we expect for 99% of the users they
only need to know a very small number of options (e.g. setting the
serializer).


-no more daemons and processes to have to monitor and manipulate and
restart and crash.

At the very least you'd need the cluster manager itself to be a daemon
process because we can't defy the law of physics. But I don't think we want
to introduce anything beyond that.


-a project that penalises developers (that will ultimately help promote
Spark to their managers and budget holders) with expensive training,
certification, books and accreditation. Ideally this open source should be
free, free training= more users = more commercial uptake.

I definitely agree with you on making it easier to learn Spark. We are
making a lot of materials freely available, including two freely available
MOOCs on edX:
https://databricks.com/blog/2014/12/02/announcing-two-spark-based-moocs.html



On Wed, Feb 25, 2015 at 2:13 PM, Devl Devel <devl.development@gmail.com>
wrote:

> Hi Spark Developers,
>
> First, apologies if this doesn't belong on this list but the
> comments/praise are relevant to all developers. This is just a small note
> about what we really like about Spark, I/we don't mean to start a whole
> long discussion thread in this forum but just share our positive
> experiences with Spark thus far.
>
> To start, as you can tell, we think that the Spark project is amazing and
> we love it! Having put in nearly half a decade worth of sweat and tears
> into production Hadoop, MapReduce clusters and application development it's
> so refreshing to see something arguably simpler and more elegant to
> supersede it.
>
> These are the things we love about Spark and hope these principles
> continue:
>
> -the one command build; make-distribution.sh. Simple, clean  and ideal for
> deployment and devops and rebuilding on different environments and nodes.
> -not having too much runtime and deploy config; as admins and developers we
> are sick of setting props like io.sort and mapred.job.shuffle.merge.percent
> and dfs file locations and temp directories and so on and on again and
> again every time we deploy a job, new cluster, environment or even change
> company.
> -a fully built-in stack, one global project for SQL, dataframes, MLlib etc,
> so there is no need to add on projects to it on as per Hive, Hue, Hbase
> etc. This helps life and keeps everything in one place.
> -single (global) user based operation - no creation of a hdfs mapred unix
> user, makes life much simpler
> -single quick-start daemons; master and slaves. Not having to worry about
> JT, NN, DN , TT, RM, Hbase master ... and doing netstat and jps on hundreds
> of clusters makes life much easier.
> -proper code versioning, feature releases and release management.
> - good & well organised documentation with good examples.
>
> In addition to the comments above this is where we hope Spark never ends
> up:
>
> -tonnes of configuration properties and "go faster" type flags. For example
> Hadoop and Hbase users will know that there are a whole catalogue of
> properties for regions, caches, network properties, block sizes, etc etc.
> Please don't end up here for example:
> https://hadoop.apache.org/docs/r1.0.4/mapred-default.html, it is painful
> having to configure all of this and then create a set of properties for
> each environment and then tie this into CI and deployment tools.
> -no more daemons and processes to have to monitor and manipulate and
> restart and crash.
> -a project that penalises developers (that will ultimately help promote
> Spark to their managers and budget holders) with expensive training,
> certification, books and accreditation. Ideally this open source should be
> free, free training= more users = more commercial uptake.
>
> Anyway, those are our thoughts for what they are worth, keep up the good
> work, we just had to mention it. Again sorry if this is not the right place
> or if there is another forum for this stuff.
>
> Cheers
>

--001a1134546ccdc826050ff14490--

From dev-return-11776-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 22:51:55 2015
Return-Path: <dev-return-11776-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F0A2F1756B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 22:51:55 +0000 (UTC)
Received: (qmail 13228 invoked by uid 500); 25 Feb 2015 22:51:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13153 invoked by uid 500); 25 Feb 2015 22:51:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13141 invoked by uid 99); 25 Feb 2015 22:51:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:51:54 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.42 as permitted sender)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:51:29 +0000
Received: by mail-oi0-f42.google.com with SMTP id h136so6204870oig.1
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 14:51:28 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=uR2JFMoRufbfSxgN0Ed2YUHbTXET6hw8U7s0BKEl5Vk=;
        b=nEjwXHsxwyuXv0ualyOgT+sD1kYgXfclZsd2XIDUJsS5rggns0BWP/lbjubm5VYpxI
         xcoYlXCB57hD5s9FU45O4yi3ALiIq24ARuJIRduEvH+xm06opM/RYvehEivHr2SWh5rL
         ZPp74YnmTU0kh5whFOUK+FRSkhkARuG150s0RF/17aT0FLalclFgYFOXzjMXewTuB5UY
         hCFhKU1x+EY5J8FdFIosa1oMdGX81LstRvrRW0Fbov31tkih0C2hSUmSxbRZE77AZw6Y
         HlRwjkTsKpBgEpCZSS3OlX8H599Lfto5PTNNaS1/p9xp+7DIS8Q9Lc7jKFUaBG/nN/cb
         9krw==
MIME-Version: 1.0
X-Received: by 10.182.129.80 with SMTP id nu16mr3969494obb.15.1424904687938;
 Wed, 25 Feb 2015 14:51:27 -0800 (PST)
Received: by 10.202.226.137 with HTTP; Wed, 25 Feb 2015 14:51:27 -0800 (PST)
In-Reply-To: <CAMwrk0=o9dwFQ7p=VBSK984dtVBaHt2bJOmGk8aGfsL56AB=tA@mail.gmail.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
	<795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
	<CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com>
	<CAMORY85Tzd7b70LdTUixzNghM_8cwmM=Gh3HOq623SnH+q3yhg@mail.gmail.com>
	<CAMwrk0=o9dwFQ7p=VBSK984dtVBaHt2bJOmGk8aGfsL56AB=tA@mail.gmail.com>
Date: Wed, 25 Feb 2015 14:51:27 -0800
Message-ID: <CABPQxss455afCd7m9uVWb610NBv1E5Dwa=w4zL2tpCmiQcnrbQ@mail.gmail.com>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
From: Patrick Wendell <pwendell@gmail.com>
To: Tathagata Das <tathagata.das1565@gmail.com>
Cc: Soumitra Kumar <kumar.soumitra@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

Just a quick updated on this thread. Issues have continued to trickle
in. Not all of them are blocker level but enough to warrant another
RC:

I've been keeping the JIRA dashboard up and running with the latest
status (sorry, long link):
https://issues.apache.org/jira/issues/?jql=3Dproject%20%3D%20SPARK%20AND%20=
%22Target%20Version%2Fs%22%20%3D%201.3.0%20AND%20(fixVersion%20IS%20EMPTY%2=
0OR%20fixVersion%20!%3D%201.3.0)%20AND%20(Resolution%20IS%20EMPTY%20OR%20Re=
solution%20IN%20(Done%2C%20Fixed%2C%20Implemented))%20ORDER%20BY%20priority=
%2C%20component

One these are in I will cut another RC. Thanks everyone for the
continued voting!

- Patrick

On Mon, Feb 23, 2015 at 10:52 PM, Tathagata Das
<tathagata.das1565@gmail.com> wrote:
> Hey all,
>
> I found a major issue where JobProgressListener (a listener used to keep
> track of jobs for the web UI) never forgets stages in one of its data
> structures. This is a blocker for long running applications.
> https://issues.apache.org/jira/browse/SPARK-5967
>
> I am testing a fix for this right now.
>
> TD
>
> On Mon, Feb 23, 2015 at 7:23 PM, Soumitra Kumar <kumar.soumitra@gmail.com=
>
> wrote:
>
>> +1 (non-binding)
>>
>> For: https://issues.apache.org/jira/browse/SPARK-3660
>>
>> . Docs OK
>> . Example code is good
>>
>> -Soumitra.
>>
>>
>> On Mon, Feb 23, 2015 at 10:33 AM, Marcelo Vanzin <vanzin@cloudera.com>
>> wrote:
>>
>> > Hi Tom, are you using an sbt-built assembly by any chance? If so, take
>> > a look at SPARK-5808.
>> >
>> > I haven't had any problems with the maven-built assembly. Setting
>> > SPARK_HOME on the executors is a workaround if you want to use the sbt
>> > assembly.
>> >
>> > On Fri, Feb 20, 2015 at 2:56 PM, Tom Graves
>> > <tgraves_cs@yahoo.com.invalid> wrote:
>> > > Trying to run pyspark on yarn in client mode with basic wordcount
>> > example I see the following error when doing the collect:
>> > > Error from python worker:  /usr/bin/python: No module named
>> > sqlPYTHONPATH was:
>> >
>> /grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-assembly-1.3=
.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException
>> >       at java.io.DataInputStream.readInt(DataInputStream.java:392)
>> > at
>> >
>> org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorker=
Factory.scala:163)
>> >       at
>> >
>> org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(Pyth=
onWorkerFactory.scala:86)
>> >       at
>> >
>> org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFacto=
ry.scala:62)
>> >       at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:1=
05)
>> >       at
>> org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:69)
>> >       at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:27=
7)
>> >     at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
>> > org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:308)
>> > at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
>> > at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
>> >
>> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:6=
8)
>> >       at
>> >
>> org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:4=
1)
>> >       at org.apache.spark.scheduler.Task.run(Task.scala:64)        at
>> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:197)
>> >   at
>> >
>> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.jav=
a:1145)
>> >       at
>> >
>> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.ja=
va:615)
>> >       at java.lang.Thread.run(Thread.java:722)
>> > > any ideas on this?
>> > > Tom
>> > >
>> > >      On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <
>> > pwendell@gmail.com> wrote:
>> > >
>> > >
>> > >  Please vote on releasing the following candidate as Apache Spark
>> > version 1.3.0!
>> > >
>> > > The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
>> > >
>> >
>> https://git-wip-us.apache.org/repos/asf?p=3Dspark.git;a=3Dcommit;h=3Df97=
b0d4a6b26504916816d7aefcf3132cd1da6c2
>> > >
>> > > The release files, including signatures, digests, etc. can be found =
at:
>> > > http://people.apache.org/~pwendell/spark-1.3.0-rc1/
>> > >
>> > > Release artifacts are signed with the following key:
>> > > https://people.apache.org/keys/committer/pwendell.asc
>> > >
>> > > The staging repository for this release can be found at:
>> > >
>> https://repository.apache.org/content/repositories/orgapachespark-1069/
>> > >
>> > > The documentation corresponding to this release can be found at:
>> > > http://people.apache.org/~pwendell/spark-1.3.0-rc1-docs/
>> > >
>> > > Please vote on releasing this package as Apache Spark 1.3.0!
>> > >
>> > > The vote is open until Saturday, February 21, at 08:03 UTC and passe=
s
>> > > if a majority of at least 3 +1 PMC votes are cast.
>> > >
>> > > [ ] +1 Release this package as Apache Spark 1.3.0
>> > > [ ] -1 Do not release this package because ...
>> > >
>> > > To learn more about Apache Spark, please see
>> > > http://spark.apache.org/
>> > >
>> > > =3D=3D How can I help test this release? =3D=3D
>> > > If you are a Spark user, you can help us test this release by
>> > > taking a Spark 1.2 workload and running on this release candidate,
>> > > then reporting any regressions.
>> > >
>> > > =3D=3D What justifies a -1 vote for this release? =3D=3D
>> > > This vote is happening towards the end of the 1.3 QA period,
>> > > so -1 votes should only occur for significant regressions from 1.2.1=
.
>> > > Bugs already present in 1.2.X, minor regressions, or bugs related
>> > > to new features will not block this release.
>> > >
>> > > - Patrick
>> > >
>> > > --------------------------------------------------------------------=
-
>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > For additional commands, e-mail: dev-help@spark.apache.org
>> > >
>> > >
>> > >
>> > >
>> >
>> >
>> >
>> > --
>> > Marcelo
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>> >
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11777-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 22:54:47 2015
Return-Path: <dev-return-11777-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EE25D17582
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 22:54:47 +0000 (UTC)
Received: (qmail 20849 invoked by uid 500); 25 Feb 2015 22:54:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20773 invoked by uid 500); 25 Feb 2015 22:54:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20742 invoked by uid 99); 25 Feb 2015 22:54:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:54:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.176 as permitted sender)
Received: from [209.85.220.176] (HELO mail-vc0-f176.google.com) (209.85.220.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:54:20 +0000
Received: by mail-vc0-f176.google.com with SMTP id la4so2593744vcb.7
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 14:54:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=62R8Htz7/wmB6Z21YxYgIk6rYF1cvmBEeDPcddV1quU=;
        b=sE6DOGwrGET63QrXn4orDPr5gEUW0Q3Ed4+Bda4eH0pB9EuWf/bmE7nIczey7opL1h
         BAiAwM19qKxBFG2bU8oLzoJYjl+ynNgCjSinBNY07fT5yZNL+Kl4AZYPxCqdaEC1aI9t
         m79cTlPa6WamrBaM6AMxb9MeKtAhH7GPSZ2cJEGwGqg2hJpetYrp+2L6ZrdrYwFCzbDI
         yQLD8w/0tPemfm132ev5nEdCpcXh2hDn4p92HyFoAbM9QIY52G+jbiSw0+nLobzrFail
         GETaEYkkFb6jgDf5Zj2HavIu94S0eqGqbKJgFLkfOzxkWq3AmHm33N0l6PAkixOntG0i
         8rTw==
X-Received: by 10.52.81.229 with SMTP id d5mr6225536vdy.54.1424904858207; Wed,
 25 Feb 2015 14:54:18 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Wed, 25 Feb 2015 14:53:58 -0800 (PST)
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
 <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net> <9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Wed, 25 Feb 2015 14:53:58 -0800
Message-ID: <CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: "Ulanov, Alexander" <alexander.ulanov@hp.com>
Cc: Joseph Bradley <joseph@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136779ae98cd5050ff183a6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136779ae98cd5050ff183a6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks for compiling all the data and running these benchmarks, Alex. The
big takeaways here can be seen with this chart:
https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6kmAJ=
eaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive

1) A properly configured GPU matrix multiply implementation (e.g.
BIDMat+GPU) can provide substantial (but less than an order of magnitude)
benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
netlib-java+openblas-compiled).
2) A poorly tuned CPU implementation can be 1-2 orders of magnitude worse
than a well-tuned CPU implementation, particularly for larger matrices.
(netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
basically agrees with the authors own benchmarks (
https://github.com/fommil/netlib-java)

I think that most of our users are in a situation where using GPUs may not
be practical - although we could consider having a good GPU backend
available as an option. However, *ALL* users of MLlib could benefit
(potentially tremendously) from using a well-tuned CPU-based BLAS
implementation. Perhaps we should consider updating the mllib guide with a
more complete section for enabling high performance binaries on OSX and
Linux? Or better, figure out a way for the system to fetch these
automatically.

- Evan



On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <alexander.ulanov@hp.com=
>
wrote:

> Just to summarize this thread, I was finally able to make all performance
> comparisons that we discussed. It turns out that:
> BIDMat-cublas>>BIDMat
> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-rep=
o=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>
> Below is the link to the spreadsheet with full results.
>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J=
5r7kwKSPkY/edit?usp=3Dsharing
>
> One thing still needs exploration: does BIDMat-cublas perform copying
> to/from machine=E2=80=99s RAM?
>
> -----Original Message-----
> From: Ulanov, Alexander
> Sent: Tuesday, February 10, 2015 2:12 PM
> To: Evan R. Sparks
> Cc: Joseph Bradley; dev@spark.apache.org
> Subject: RE: Using CUDA within Spark / boosting linear algebra
>
> Thanks, Evan! It seems that ticket was marked as duplicate though the
> original one discusses slightly different topic. I was able to link netli=
b
> with MKL from BIDMat binaries. Indeed, MKL is statically linked inside a
> 60MB library.
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557 |1,63847545=
9
> |
> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
> 1569,233228 |
>
> It turn out that pre-compiled MKL is faster than precompiled OpenBlas on
> my machine. Probably, I=E2=80=99ll add two more columns with locally comp=
iled
> openblas and cuda.
>
> Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> Sent: Monday, February 09, 2015 6:06 PM
> To: Ulanov, Alexander
> Cc: Joseph Bradley; dev@spark.apache.org
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Great - perhaps we can move this discussion off-list and onto a JIRA
> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705)
>
> It seems like this is going to be somewhat exploratory for a while (and
> there's probably only a handful of us who really care about fast linear
> algebra!)
>
> - Evan
>
> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan,
>
> Thank you for explanation and useful link. I am going to build OpenBLAS,
> link it with Netlib-java and perform benchmark again.
>
> Do I understand correctly that BIDMat binaries contain statically linked
> Intel MKL BLAS? It might be the reason why I am able to run BIDMat not
> having MKL BLAS installed on my server. If it is true, I wonder if it is =
OK
> because Intel sells this library. Nevertheless, it seems that in my case
> precompiled MKL BLAS performs better than precompiled OpenBLAS given that
> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>
> Though, it might be interesting to link Netlib-java with Intel MKL, as yo=
u
> suggested. I wonder, are John Canny (BIDMat) and Sam Halliday (Netlib-jav=
a)
> interested to compare their libraries.
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Friday, February 06, 2015 5:58 PM
>
> To: Ulanov, Alexander
> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I would build OpenBLAS yourself, since good BLAS performance comes from
> getting cache sizes, etc. set up correctly for your particular hardware -
> this is often a very tricky process (see, e.g. ATLAS), but we found that =
on
> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> performance competitive with MKL.
>
> To make sure the right library is getting used, you have to make sure it'=
s
> first on the search path - export LD_LIBRARY_PATH=3D/path/to/blas/library=
.so
> will do the trick here.
>
> For some examples of getting netlib-java setup on an ec2 node and some
> example benchmarking code we ran a while back, see:
> https://github.com/shivaram/matrix-bench
>
> In particular - build-openblas-ec2.sh shows you how to build the library
> and set up symlinks correctly, and scala/run-netlib.sh shows you how to g=
et
> the path setup and get that library picked up by netlib-java.
>
> In this way - you could probably get cuBLAS set up to be used by
> netlib-java as well.
>
> - Evan
>
> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Evan, could you elaborate on how to force BIDMat and netlib-java to force
> loading the right blas? For netlib, I there are few JVM flags, such as
> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so I =
can
> force it to use Java implementation. Not sure I understand how to force u=
se
> a specific blas (not specific wrapper for blas).
>
> Btw. I have installed openblas (yum install openblas), so I suppose that
> netlib is using it.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Friday, February 06, 2015 5:19 PM
> To: Ulanov, Alexander
> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Getting breeze to pick up the right blas library is critical for
> performance. I recommend using OpenBLAS (or MKL, if you already have it).
> It might make sense to force BIDMat to use the same underlying BLAS libra=
ry
> as well.
>
> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Hi Evan, Joseph
>
> I did few matrix multiplication test and BIDMat seems to be ~10x faster
> than netlib-java+breeze (sorry for weird table formatting):
>
> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
> Breeze+Netlib-java f2jblas |
> +-----------------------------------------------------------------------+
> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>
> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
> Linux, Scala 2.11.
>
> Later I will make tests with Cuda. I need to install new Cuda version for
> this purpose.
>
> Do you have any ideas why breeze-netlib with native blas is so much slowe=
r
> than BIDMat MKL?
>
> Best regards, Alexander
>
> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
> joseph@databricks.com>]
> Sent: Thursday, February 05, 2015 5:29 PM
> To: Ulanov, Alexander
> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> Hi Alexander,
>
> Using GPUs with Spark would be very exciting.  Small comment: Concerning
> your question earlier about keeping data stored on the GPU rather than
> having to move it between main memory and GPU memory on each iteration, I
> would guess this would be critical to getting good performance.  If you
> could do multiple local iterations before aggregating results, then the
> cost of data movement to the GPU could be amortized (and I believe that i=
s
> done in practice).  Having Spark be aware of the GPU and using it as
> another part of memory sounds like a much bigger undertaking.
>
> Joseph
>
> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com>> wrote:
> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation =
by John
> Canny and I am really inspired by his talk and comparisons with Spark MLl=
ib.
>
> I am very interested to find out what will be better within Spark: BIDMat
> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
> benchmark them? Currently I do benchmarks on artificial neural networks i=
n
> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear algeb=
ra, it involves
> some other things that are essential to machine learning.
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> Sent: Thursday, February 05, 2015 1:29 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
> layout and fewer levels of indirection - it's definitely a worthwhile
> experiment to run. The main speedups I've seen from using it come from
> highly optimized GPU code for linear algebra. I know that in the past Can=
ny
> has gone as far as to write custom GPU kernels for performance-critical
> regions of code.[1]
>
> BIDMach is highly optimized for single node performance or performance on
> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
> batched in that way) the performance tends to fall off. Canny argues for
> hardware/software codesign and as such prefers machine configurations tha=
t
> are quite different than what we find in most commodity cluster nodes -
> e.g. 10 disk cahnnels and 4 GPUs.
>
> In contrast, MLlib was designed for horizontal scalability on commodity
> clusters and works best on very big datasets - order of terabytes.
>
> For the most part, these projects developed concurrently to address
> slightly different use cases. That said, there may be bits of BIDMach we
> could repurpose for MLlib - keep in mind we need to be careful about
> maintaining cross-language compatibility for our Java and Python-users,
> though.
>
> - Evan
>
> [1] - http://arxiv.org/abs/1409.5402
> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>
> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <alexander.ulanov@hp.co=
m
> <mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:
> alexander.ulanov@hp.com>>> wrote:
> Hi Evan,
>
> Thank you for suggestion! BIDMat seems to have terrific speed. Do you kno=
w
> what makes them faster than netlib-java?
>
> The same group has BIDMach library that implements machine learning. For
> some examples they use Caffe convolutional neural network library owned b=
y
> another group in Berkeley. Could you elaborate on how these all might be
> connected with Spark Mllib? If you take BIDMat for linear algebra why don=
=E2=80=99t
> you take BIDMach for optimization and learning?
>
> Best regards, Alexander
>
> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>>]
> Sent: Thursday, February 05, 2015 12:09 PM
> To: Ulanov, Alexander
> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
> many cases.
>
> You might consider taking a look at the codepaths that BIDMat (
> https://github.com/BIDData/BIDMat) takes and comparing them to
> netlib-java/breeze. John Canny et. al. have done a bunch of work optimizi=
ng
> to make this work really fast from Scala. I've run it on my laptop and
> compared to MKL and in certain cases it's 10x faster at matrix multiply.
> There are a lot of layers of indirection here and you really want to avoi=
d
> data copying as much as possible.
>
> We could also consider swapping out BIDMat for Breeze, but that would be =
a
> big project and if we can figure out how to get breeze+cublas to comparab=
le
> performance that would be a big win.
>
> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> Dear Spark developers,
>
> I am exploring how to make linear algebra operations faster within Spark.
> One way of doing this is to use Scala Breeze library that is bundled with
> Spark. For matrix operations, it employs Netlib-java that has a Java
> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> binaries if they are available on the worker node. It also has its own
> optimized Java implementation of BLAS. It is worth mentioning, that nativ=
e
> binaries provide better performance only for BLAS level 3, i.e.
> matrix-matrix operations or general matrix multiplication (GEMM). This is
> confirmed by GEMM test on Netlib-java page
> https://github.com/fommil/netlib-java. I also confirmed it with my
> experiments with training of artificial neural network
> https://github.com/apache/spark/pull/1290#issuecomment-70313952. However,
> I would like to boost performance more.
>
> GPU is supposed to work fast with linear algebra and there is Nvidia CUDA
> implementation of BLAS, called cublas. I have one Linux server with Nvidi=
a
> GPU and I was able to do the following. I linked cublas (instead of
> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> Breeze/Netlib is using it. Then I did some performance measurements with
> regards to artificial neural network batch learning in Spark MLlib that
> involves matrix-matrix multiplications. It turns out that for matrices of
> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubla=
s
> becomes slower for bigger matrices. It worth mentioning that it is was no=
t
> a test for ONLY multiplication since there are other operations involved.
> One of the reasons for slowdown might be the overhead of copying the
> matrices from computer memory to graphic card memory and back.
>
> So, few questions:
> 1) Do these results with CUDA make sense?
> 2) If the problem is with copy overhead, are there any libraries that
> allow to force intermediate results to stay in graphic card memory thus
> removing the overhead?
> 3) Any other options to speed-up linear algebra in Spark?
>
> Thank you, Alexander
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apache.org
> <mailto:dev-unsubscribe@spark.apache.org>>
> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org>>
>
>
>
>

--001a1136779ae98cd5050ff183a6--

From dev-return-11778-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 22:58:26 2015
Return-Path: <dev-return-11778-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 37342175A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 22:58:26 +0000 (UTC)
Received: (qmail 33460 invoked by uid 500); 25 Feb 2015 22:58:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33387 invoked by uid 500); 25 Feb 2015 22:58:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33375 invoked by uid 99); 25 Feb 2015 22:58:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:58:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.213.51 as permitted sender)
Received: from [209.85.213.51] (HELO mail-yh0-f51.google.com) (209.85.213.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 22:57:59 +0000
Received: by yhoa41 with SMTP id a41so2656448yho.4
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 14:57:57 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=OBJgS80dz1IY3nCq+e5Qb3vmiaARZevz1NJ2oqNR71o=;
        b=IXx6+Jsuoh2wGvzaDqUBkkR9PE1T3D6Kv/w80kExcy/caVyJINBQkcv3JD21dYZ0Qq
         95P8WpiSWKxrt28YUwyvi7ifNUOh4fX1Cq7Uwxg/XcwIJfu7nq3uZNWtYGSUyK5/MszM
         7Hh7Tyid/72OuJd1hWwpS+LuYEHY9G2Iy+SUf5StCdTJp8trVM/awhE1EQ03FJ3sjALU
         nmkWPHlRUMpmqYxOrXzXMCV29Eponi/QR5JyVkwwYMxa4DOSeEo/8TCpy0epKc46SiIn
         nZih+13ZqZ9LzAlYmiV2VaNA7QOSGKPoSAnzNILefl6D9OkSqD1Cyji1vnHw0rqRStRd
         wSxw==
X-Received: by 10.236.62.136 with SMTP id y8mr5356701yhc.13.1424905077784;
 Wed, 25 Feb 2015 14:57:57 -0800 (PST)
MIME-Version: 1.0
References: <CAMQ+LQPN+KTVz=Rd=qD2MCeoCHRfiTRJ555BKzQPPf2+PN35uQ@mail.gmail.com>
 <CAPh_B=b24KUyY=B+eTzmg2K+q4N-35vLEYk-OrVQENdOQaE0hw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 25 Feb 2015 22:57:57 +0000
Message-ID: <CAOhmDzeges6ev1Dwbq4pkzFccy1h8uLbE8wm+8L1KqAM=+8gJA@mail.gmail.com>
Subject: Re: Some praise and comments on Spark
To: Reynold Xin <rxin@databricks.com>, Devl Devel <devl.development@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122ed8a0007da050ff1917c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122ed8a0007da050ff1917c
Content-Type: text/plain; charset=UTF-8

Thanks for sharing the feedback about what works well for you!

It's nice to get that; as we all probably know, people generally reach out
only when they have problems.

On Wed, Feb 25, 2015 at 5:38 PM Reynold Xin <rxin@databricks.com> wrote:

> Thanks for the email and encouragement, Devl. Responses to the 3 requests:
>
> -tonnes of configuration properties and "go faster" type flags. For example
> Hadoop and Hbase users will know that there are a whole catalogue of
> properties for regions, caches, network properties, block sizes, etc etc.
> Please don't end up here for example:
> https://hadoop.apache.org/docs/r1.0.4/mapred-default.html, it is painful
> having to configure all of this and then create a set of properties for
> each environment and then tie this into CI and deployment tools.
>
> As the project grows, it is unavoidable to introduce more config options,
> in particular, we often use config options to test new modules that are
> still experimental before making them the default (e.g. sort-based
> shuffle).
>
> The philosophy here is to make it a very high bar to introduce new config
> options, and make the default values sensible for most deployments, and
> then whenever possible, figure out automatically what is the right setting.
> Note that this in general is hard, but we expect for 99% of the users they
> only need to know a very small number of options (e.g. setting the
> serializer).
>
>
> -no more daemons and processes to have to monitor and manipulate and
> restart and crash.
>
> At the very least you'd need the cluster manager itself to be a daemon
> process because we can't defy the law of physics. But I don't think we want
> to introduce anything beyond that.
>
>
> -a project that penalises developers (that will ultimately help promote
> Spark to their managers and budget holders) with expensive training,
> certification, books and accreditation. Ideally this open source should be
> free, free training= more users = more commercial uptake.
>
> I definitely agree with you on making it easier to learn Spark. We are
> making a lot of materials freely available, including two freely available
> MOOCs on edX:
> https://databricks.com/blog/2014/12/02/announcing-two-
> spark-based-moocs.html
>
>
>
> On Wed, Feb 25, 2015 at 2:13 PM, Devl Devel <devl.development@gmail.com>
> wrote:
>
> > Hi Spark Developers,
> >
> > First, apologies if this doesn't belong on this list but the
> > comments/praise are relevant to all developers. This is just a small note
> > about what we really like about Spark, I/we don't mean to start a whole
> > long discussion thread in this forum but just share our positive
> > experiences with Spark thus far.
> >
> > To start, as you can tell, we think that the Spark project is amazing and
> > we love it! Having put in nearly half a decade worth of sweat and tears
> > into production Hadoop, MapReduce clusters and application development
> it's
> > so refreshing to see something arguably simpler and more elegant to
> > supersede it.
> >
> > These are the things we love about Spark and hope these principles
> > continue:
> >
> > -the one command build; make-distribution.sh. Simple, clean  and ideal
> for
> > deployment and devops and rebuilding on different environments and nodes.
> > -not having too much runtime and deploy config; as admins and developers
> we
> > are sick of setting props like io.sort and mapred.job.shuffle.merge.
> percent
> > and dfs file locations and temp directories and so on and on again and
> > again every time we deploy a job, new cluster, environment or even change
> > company.
> > -a fully built-in stack, one global project for SQL, dataframes, MLlib
> etc,
> > so there is no need to add on projects to it on as per Hive, Hue, Hbase
> > etc. This helps life and keeps everything in one place.
> > -single (global) user based operation - no creation of a hdfs mapred unix
> > user, makes life much simpler
> > -single quick-start daemons; master and slaves. Not having to worry about
> > JT, NN, DN , TT, RM, Hbase master ... and doing netstat and jps on
> hundreds
> > of clusters makes life much easier.
> > -proper code versioning, feature releases and release management.
> > - good & well organised documentation with good examples.
> >
> > In addition to the comments above this is where we hope Spark never ends
> > up:
> >
> > -tonnes of configuration properties and "go faster" type flags. For
> example
> > Hadoop and Hbase users will know that there are a whole catalogue of
> > properties for regions, caches, network properties, block sizes, etc etc.
> > Please don't end up here for example:
> > https://hadoop.apache.org/docs/r1.0.4/mapred-default.html, it is painful
> > having to configure all of this and then create a set of properties for
> > each environment and then tie this into CI and deployment tools.
> > -no more daemons and processes to have to monitor and manipulate and
> > restart and crash.
> > -a project that penalises developers (that will ultimately help promote
> > Spark to their managers and budget holders) with expensive training,
> > certification, books and accreditation. Ideally this open source should
> be
> > free, free training= more users = more commercial uptake.
> >
> > Anyway, those are our thoughts for what they are worth, keep up the good
> > work, we just had to mention it. Again sorry if this is not the right
> place
> > or if there is another forum for this stuff.
> >
> > Cheers
> >
>

--089e0122ed8a0007da050ff1917c--

From dev-return-11779-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Feb 25 23:38:52 2015
Return-Path: <dev-return-11779-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31F6517836
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 25 Feb 2015 23:38:52 +0000 (UTC)
Received: (qmail 99208 invoked by uid 500); 25 Feb 2015 23:38:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99133 invoked by uid 500); 25 Feb 2015 23:38:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99121 invoked by uid 99); 25 Feb 2015 23:38:45 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 23:38:45 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.213.178] (HELO mail-ig0-f178.google.com) (209.85.213.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 25 Feb 2015 23:38:19 +0000
Received: by mail-ig0-f178.google.com with SMTP id hl2so10315807igb.5
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 15:36:27 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=fYJZoIlxHOEhQaWfWtw87g8AIzcQVqvCLLDnKP3to1g=;
        b=eldM8ii3ZS4DoN0+rderKa9zTWF9/gVrnLrO+vPnlqf8MS4CehcdHKo2IFd5Oa38/6
         7ZDvSD6F8uzdihh+l9ty/Bt4CdzsPFUPlfGuz5iGDj5ayHCiJkB+IcLUv/VOQtWWLuqy
         N+4SSJIymOJ/7D631se/7beAKaeHbuU5dQxcHs3ANBxp0QjDLmEdDS71I7fkNxhIEsci
         +1AElrh1yK/7L1MX/gB54BIPzi1S1YyuzOQi+QPI71h4WbTkFYcrmHSn2b9px5Lr9TY6
         nrsR6uGFypNt2n8JGT5E03FqzzxCtUuCDVavZY5706mC8RSwFLQd+nszsFucXKsU71q3
         mOLQ==
X-Gm-Message-State: ALoCoQkuqKRxE4bG01kHbX8MDT/vApgmfNzlgJJBBMUbL9e4O4X67lcQmoxGkaWze1TV8Q4Buo+x
MIME-Version: 1.0
X-Received: by 10.50.114.33 with SMTP id jd1mr8238684igb.31.1424907386865;
 Wed, 25 Feb 2015 15:36:26 -0800 (PST)
Received: by 10.36.118.18 with HTTP; Wed, 25 Feb 2015 15:36:26 -0800 (PST)
In-Reply-To: <CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
Date: Wed, 25 Feb 2015 15:36:26 -0800
Message-ID: <CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Joseph Bradley <joseph@databricks.com>
To: "Evan R. Sparks" <evan.sparks@gmail.com>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b41418ea1e481050ff21a79
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b41418ea1e481050ff21a79
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Better documentation for linking would be very helpful!  Here's a JIRA:
https://issues.apache.org/jira/browse/SPARK-6019


On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com>
wrote:

> Thanks for compiling all the data and running these benchmarks, Alex. The
> big takeaways here can be seen with this chart:
>
> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6km=
AJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>
> 1) A properly configured GPU matrix multiply implementation (e.g.
> BIDMat+GPU) can provide substantial (but less than an order of magnitude)
> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> netlib-java+openblas-compiled).
> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude worse
> than a well-tuned CPU implementation, particularly for larger matrices.
> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
> basically agrees with the authors own benchmarks (
> https://github.com/fommil/netlib-java)
>
> I think that most of our users are in a situation where using GPUs may no=
t
> be practical - although we could consider having a good GPU backend
> available as an option. However, *ALL* users of MLlib could benefit
> (potentially tremendously) from using a well-tuned CPU-based BLAS
> implementation. Perhaps we should consider updating the mllib guide with =
a
> more complete section for enabling high performance binaries on OSX and
> Linux? Or better, figure out a way for the system to fetch these
> automatically.
>
> - Evan
>
>
>
> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
> alexander.ulanov@hp.com> wrote:
>
>> Just to summarize this thread, I was finally able to make all performanc=
e
>> comparisons that we discussed. It turns out that:
>> BIDMat-cublas>>BIDMat
>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-re=
po=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>>
>> Below is the link to the spreadsheet with full results.
>>
>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9=
J5r7kwKSPkY/edit?usp=3Dsharing
>>
>> One thing still needs exploration: does BIDMat-cublas perform copying
>> to/from machine=E2=80=99s RAM?
>>
>> -----Original Message-----
>> From: Ulanov, Alexander
>> Sent: Tuesday, February 10, 2015 2:12 PM
>> To: Evan R. Sparks
>> Cc: Joseph Bradley; dev@spark.apache.org
>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>
>> Thanks, Evan! It seems that ticket was marked as duplicate though the
>> original one discusses slightly different topic. I was able to link netl=
ib
>> with MKL from BIDMat binaries. Indeed, MKL is statically linked inside a
>> 60MB library.
>>
>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>> +-----------------------------------------------------------------------=
+
>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>> |1,638475459 |
>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>> 1569,233228 |
>>
>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas on
>> my machine. Probably, I=E2=80=99ll add two more columns with locally com=
piled
>> openblas and cuda.
>>
>> Alexander
>>
>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
>> Sent: Monday, February 09, 2015 6:06 PM
>> To: Ulanov, Alexander
>> Cc: Joseph Bradley; dev@spark.apache.org
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> Great - perhaps we can move this discussion off-list and onto a JIRA
>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705)
>>
>> It seems like this is going to be somewhat exploratory for a while (and
>> there's probably only a handful of us who really care about fast linear
>> algebra!)
>>
>> - Evan
>>
>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> Hi Evan,
>>
>> Thank you for explanation and useful link. I am going to build OpenBLAS,
>> link it with Netlib-java and perform benchmark again.
>>
>> Do I understand correctly that BIDMat binaries contain statically linked
>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat not
>> having MKL BLAS installed on my server. If it is true, I wonder if it is=
 OK
>> because Intel sells this library. Nevertheless, it seems that in my case
>> precompiled MKL BLAS performs better than precompiled OpenBLAS given tha=
t
>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>
>> Though, it might be interesting to link Netlib-java with Intel MKL, as
>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>> (Netlib-java) interested to compare their libraries.
>>
>> Best regards, Alexander
>>
>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com>]
>> Sent: Friday, February 06, 2015 5:58 PM
>>
>> To: Ulanov, Alexander
>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> I would build OpenBLAS yourself, since good BLAS performance comes from
>> getting cache sizes, etc. set up correctly for your particular hardware =
-
>> this is often a very tricky process (see, e.g. ATLAS), but we found that=
 on
>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>> performance competitive with MKL.
>>
>> To make sure the right library is getting used, you have to make sure
>> it's first on the search path - export
>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>>
>> For some examples of getting netlib-java setup on an ec2 node and some
>> example benchmarking code we ran a while back, see:
>> https://github.com/shivaram/matrix-bench
>>
>> In particular - build-openblas-ec2.sh shows you how to build the library
>> and set up symlinks correctly, and scala/run-netlib.sh shows you how to =
get
>> the path setup and get that library picked up by netlib-java.
>>
>> In this way - you could probably get cuBLAS set up to be used by
>> netlib-java as well.
>>
>> - Evan
>>
>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> Evan, could you elaborate on how to force BIDMat and netlib-java to forc=
e
>> loading the right blas? For netlib, I there are few JVM flags, such as
>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so I=
 can
>> force it to use Java implementation. Not sure I understand how to force =
use
>> a specific blas (not specific wrapper for blas).
>>
>> Btw. I have installed openblas (yum install openblas), so I suppose that
>> netlib is using it.
>>
>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com>]
>> Sent: Friday, February 06, 2015 5:19 PM
>> To: Ulanov, Alexander
>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> Getting breeze to pick up the right blas library is critical for
>> performance. I recommend using OpenBLAS (or MKL, if you already have it)=
.
>> It might make sense to force BIDMat to use the same underlying BLAS libr=
ary
>> as well.
>>
>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> Hi Evan, Joseph
>>
>> I did few matrix multiplication test and BIDMat seems to be ~10x faster
>> than netlib-java+breeze (sorry for weird table formatting):
>>
>> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64|
>> Breeze+Netlib-java f2jblas |
>> +-----------------------------------------------------------------------=
+
>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>>
>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
>> Linux, Scala 2.11.
>>
>> Later I will make tests with Cuda. I need to install new Cuda version fo=
r
>> this purpose.
>>
>> Do you have any ideas why breeze-netlib with native blas is so much
>> slower than BIDMat MKL?
>>
>> Best regards, Alexander
>>
>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
>> joseph@databricks.com>]
>> Sent: Thursday, February 05, 2015 5:29 PM
>> To: Ulanov, Alexander
>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> Hi Alexander,
>>
>> Using GPUs with Spark would be very exciting.  Small comment: Concerning
>> your question earlier about keeping data stored on the GPU rather than
>> having to move it between main memory and GPU memory on each iteration, =
I
>> would guess this would be critical to getting good performance.  If you
>> could do multiple local iterations before aggregating results, then the
>> cost of data movement to the GPU could be amortized (and I believe that =
is
>> done in practice).  Having Spark be aware of the GPU and using it as
>> another part of memory sounds like a much bigger undertaking.
>>
>> Joseph
>>
>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentation=
 by John
>> Canny and I am really inspired by his talk and comparisons with Spark ML=
lib.
>>
>> I am very interested to find out what will be better within Spark: BIDMa=
t
>> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
>> benchmark them? Currently I do benchmarks on artificial neural networks =
in
>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear alge=
bra, it involves
>> some other things that are essential to machine learning.
>>
>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com>]
>> Sent: Thursday, February 05, 2015 1:29 PM
>> To: Ulanov, Alexander
>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>> netlib-java+OpenBLAS, but if it is much faster it's probably due to data
>> layout and fewer levels of indirection - it's definitely a worthwhile
>> experiment to run. The main speedups I've seen from using it come from
>> highly optimized GPU code for linear algebra. I know that in the past Ca=
nny
>> has gone as far as to write custom GPU kernels for performance-critical
>> regions of code.[1]
>>
>> BIDMach is highly optimized for single node performance or performance o=
n
>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can be
>> batched in that way) the performance tends to fall off. Canny argues for
>> hardware/software codesign and as such prefers machine configurations th=
at
>> are quite different than what we find in most commodity cluster nodes -
>> e.g. 10 disk cahnnels and 4 GPUs.
>>
>> In contrast, MLlib was designed for horizontal scalability on commodity
>> clusters and works best on very big datasets - order of terabytes.
>>
>> For the most part, these projects developed concurrently to address
>> slightly different use cases. That said, there may be bits of BIDMach we
>> could repurpose for MLlib - keep in mind we need to be careful about
>> maintaining cross-language compatibility for our Java and Python-users,
>> though.
>>
>> - Evan
>>
>> [1] - http://arxiv.org/abs/1409.5402
>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>
>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> Hi Evan,
>>
>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
>> know what makes them faster than netlib-java?
>>
>> The same group has BIDMach library that implements machine learning. For
>> some examples they use Caffe convolutional neural network library owned =
by
>> another group in Berkeley. Could you elaborate on how these all might be
>> connected with Spark Mllib? If you take BIDMat for linear algebra why do=
n=E2=80=99t
>> you take BIDMach for optimization and learning?
>>
>> Best regards, Alexander
>>
>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com>>]
>> Sent: Thursday, February 05, 2015 12:09 PM
>> To: Ulanov, Alexander
>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas in
>> many cases.
>>
>> You might consider taking a look at the codepaths that BIDMat (
>> https://github.com/BIDData/BIDMat) takes and comparing them to
>> netlib-java/breeze. John Canny et. al. have done a bunch of work optimiz=
ing
>> to make this work really fast from Scala. I've run it on my laptop and
>> compared to MKL and in certain cases it's 10x faster at matrix multiply.
>> There are a lot of layers of indirection here and you really want to avo=
id
>> data copying as much as possible.
>>
>> We could also consider swapping out BIDMat for Breeze, but that would be
>> a big project and if we can figure out how to get breeze+cublas to
>> comparable performance that would be a big win.
>>
>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> Dear Spark developers,
>>
>> I am exploring how to make linear algebra operations faster within Spark=
.
>> One way of doing this is to use Scala Breeze library that is bundled wit=
h
>> Spark. For matrix operations, it employs Netlib-java that has a Java
>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
>> binaries if they are available on the worker node. It also has its own
>> optimized Java implementation of BLAS. It is worth mentioning, that nati=
ve
>> binaries provide better performance only for BLAS level 3, i.e.
>> matrix-matrix operations or general matrix multiplication (GEMM). This i=
s
>> confirmed by GEMM test on Netlib-java page
>> https://github.com/fommil/netlib-java. I also confirmed it with my
>> experiments with training of artificial neural network
>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>> However, I would like to boost performance more.
>>
>> GPU is supposed to work fast with linear algebra and there is Nvidia CUD=
A
>> implementation of BLAS, called cublas. I have one Linux server with Nvid=
ia
>> GPU and I was able to do the following. I linked cublas (instead of
>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>> Breeze/Netlib is using it. Then I did some performance measurements with
>> regards to artificial neural network batch learning in Spark MLlib that
>> involves matrix-matrix multiplications. It turns out that for matrices o=
f
>> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cubl=
as
>> becomes slower for bigger matrices. It worth mentioning that it is was n=
ot
>> a test for ONLY multiplication since there are other operations involved=
.
>> One of the reasons for slowdown might be the overhead of copying the
>> matrices from computer memory to graphic card memory and back.
>>
>> So, few questions:
>> 1) Do these results with CUDA make sense?
>> 2) If the problem is with copy overhead, are there any libraries that
>> allow to force intermediate results to stay in graphic card memory thus
>> removing the overhead?
>> 3) Any other options to speed-up linear algebra in Spark?
>>
>> Thank you, Alexander
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
>> dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apache.or=
g
>> <mailto:dev-unsubscribe@spark.apache.org>>
>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
>> dev-help@spark.apache.org>>
>>
>>
>>
>>
>

--047d7b41418ea1e481050ff21a79--

From dev-return-11780-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 03:38:28 2015
Return-Path: <dev-return-11780-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 663491003E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 03:38:28 +0000 (UTC)
Received: (qmail 74528 invoked by uid 500); 26 Feb 2015 03:38:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74435 invoked by uid 500); 26 Feb 2015 03:38:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74423 invoked by uid 99); 26 Feb 2015 03:38:26 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 03:38:26 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 03:38:00 +0000
Received: by mail-oi0-f44.google.com with SMTP id a3so7131787oib.3
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 19:37:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=CdGfJs0yfgZp/kfjYWguZa6hLdOaLUlI5cbT/r64GqQ=;
        b=i14aFxWhX+Qen71bTnUidmbZvTna4/98hB3B/yLO/sprDwnP/BaI/XA0Y+bzZGpU8u
         DZWXn0OkanMQBPqr9lim6dcTf5n2TgyUTFN8zDdBL9+fUlZTZX42+6/rZWmGwcqcGqPa
         IHYbSZN4wqApiWp95f6OzP4YGrttFejPXrgNo6cB1niPFm5dzIvkphaAINZ/Xr56ZUwC
         VI2nGGaM/pDDzO4KyrWuFfJzFRuDIY17l8MuqUz+FlxVvVL56CCD3RwbWAVDOR965CAE
         Qh/jhkxN/AwVdV62ssQjz616ze9YUQjMHvEDe85DuibFWOu40mKrP/380PbIvxvMAkAK
         vjyQ==
MIME-Version: 1.0
X-Received: by 10.60.16.202 with SMTP id i10mr4641327oed.16.1424921833893;
 Wed, 25 Feb 2015 19:37:13 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Wed, 25 Feb 2015 19:37:13 -0800 (PST)
In-Reply-To: <CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
	<CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
Date: Thu, 26 Feb 2015 09:07:13 +0530
Message-ID: <CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
Subject: Re: Google Summer of Code - ideas
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122a3ecbdf698050ff577e5
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a3ecbdf698050ff577e5
Content-Type: text/plain; charset=UTF-8

Hi,

I think that would be really good. Are there any specific issues that are
to be implemented as per priority?

--089e0122a3ecbdf698050ff577e5--

From dev-return-11781-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 07:59:15 2015
Return-Path: <dev-return-11781-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A33A510743
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 07:59:15 +0000 (UTC)
Received: (qmail 89734 invoked by uid 500); 26 Feb 2015 07:59:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89633 invoked by uid 500); 26 Feb 2015 07:59:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89620 invoked by uid 99); 26 Feb 2015 07:59:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 07:59:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vikramkone@gmail.com designates 209.85.214.178 as permitted sender)
Received: from [209.85.214.178] (HELO mail-ob0-f178.google.com) (209.85.214.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 07:58:48 +0000
Received: by mail-ob0-f178.google.com with SMTP id uz6so9236289obc.9
        for <dev@spark.apache.org>; Wed, 25 Feb 2015 23:56:31 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=U+j4XSxaKhDoxkC5/TjgOYWT8/Eh3eK7ubXQi7Q34ik=;
        b=aL1S1TfDYcSHborR6uPFbp1GhhJRzvwoETGMq91U/vdvOaeuhkhDYQzNBMRJiwCvn+
         ho5vULy7Z56kAgpi3fEjX1zRLVXoE7AyBgKVTV7VJcvSe074OWFawIge3QIxnf4AG5If
         zo0wdIJ5PLY2fpYK2c4EKcMQBCc40Z9rQZq7FzZt7xBeqwK9nCdPXqZ0quAb8rVzEVoq
         aA82UnsK77C42F/5F8T8gEu4CnByZAj3hFKRcSNSyLf1LZzOF1ATh81YE/Bwu9FDUTqc
         Ga5MPXp7143/g26zGcEWuJJ/Glg5nNd00Yj6RVHFEYq86VDNqzCZYfs5KrlI8YhRg6jn
         yaqg==
MIME-Version: 1.0
X-Received: by 10.202.229.141 with SMTP id c135mr4867718oih.44.1424937391057;
 Wed, 25 Feb 2015 23:56:31 -0800 (PST)
Received: by 10.182.193.8 with HTTP; Wed, 25 Feb 2015 23:56:31 -0800 (PST)
Date: Wed, 25 Feb 2015 23:56:31 -0800
Message-ID: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
Subject: Need advice for Spark newbie
From: Vikram Kone <vikramkone@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1140744005710c050ff91799
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1140744005710c050ff91799
Content-Type: text/plain; charset=UTF-8

Hi,
I'm a newbie when it comes to Spark and Hadoop eco system in general. Our
team has been predominantly a Microsoft shop that uses MS stack for most of
their BI needs. So we are talking SQL server  for storing relational data
and SQL Server Analysis services for building MOLAP cubes for sub-second
query analysis.
Lately, we have been hitting degradation in our cube query response times
as our data sizes grew considerably the past year. We are talking fact
tables which are in 1o-100 billions of rows range and a few dimensions in
the 10-100's of millions of rows. We tried vertically scaling up our SSAS
server but queries are still taking few minutes. In light of this, I was
entrusted with task of figuring out an open source solution that would
scale to our current and future needs for data analysis.
I looked at a bunch of open source tools like Apache Drill, Druid, AtScale,
Spark, Storm, Kylin etc and settled on exploring Spark as the first step
given it's recent rise in popularity and growing eco-system around it.
Since we are also interested in doing deep data analysis like machine
learning and graph algorithms on top our data, spark seems to be a good
solution.
I would like to build out a POC for our MOLAP cubes using spark with
HDFS/Hive as the datasource and see how it scales for our queries/measures
in real time with real data.
Roughly, these are the requirements for our team
1. Should be able to create facts, dimensions and measures from our data
sets in an easier way.
2. Cubes should be query able from Excel and Tableau.
3. Easily scale out by adding new nodes when data grows
4. Very less maintenance and highly stable for production level workloads
5. Sub second query latencies for COUNT DISTINCT measures (since majority
of our expensive measures are of this type) . Are ok with Approx Distinct
counts for better perf.

So given these requirements, is Spark the right solution to replace our
on-premise MOLAP cubes?
Are there any tutorials or documentation on how to build cubes using Spark?
Is that even possible? or even necessary? As long as our users can
pivot/slice & dice the measures quickly from client tools by dragging
dropping dimensions into rows/columns w/o the need to join to fact table,
we are ok with however the data is laid out. Doesn't have to be a cube. It
can be a flat file in hdfs for all we care. I would love to chat with some
one who has successfully done this kind of migration from OLAP cubes to
Spark in their team or company .

This is it for now. Looking forward to a great discussion.

P.S. We have decided on using Azure HDInsight as our managed hadoop system
in the cloud.

--001a1140744005710c050ff91799--

From dev-return-11782-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 09:33:43 2015
Return-Path: <dev-return-11782-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 93B5810AFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 09:33:43 +0000 (UTC)
Received: (qmail 97518 invoked by uid 500); 26 Feb 2015 09:33:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97432 invoked by uid 500); 26 Feb 2015 09:33:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97420 invoked by uid 99); 26 Feb 2015 09:33:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 09:33:42 +0000
X-ASF-Spam-Status: No, hits=-0.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rikima3132@gmail.com designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 09:33:16 +0000
Received: by labgf13 with SMTP id gf13so9650085lab.9
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 01:31:45 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=xQoutfTttv/MJOa+I/3nQrQJtwF4yVTgYcunqxkkCqw=;
        b=o+WDjIHvPG8/AUk9iwl1iGmV7lY3OYS588meDqLgO16ZUSU5mmlJXcKMirOn425Al6
         xZvNECvJJcdAZHLIMeVdiTRqvP3ULMZ1xvm6RTnXV3EeApvs/yKz56jDZFumm0MtgiSa
         7Zz7kcCxIokcPaJN0UBUAg6Wv2o1NdbHutUqBm1lEu0j4aayBwI8nRdB2ZN969NC5F/O
         8FMmHgsGhJdK+U/iQ2H89/rDtqD2uq3eyoheTSauw/zbSpcENdYuKnstw1opqWzkxHjZ
         AvQcR0xFBa95FUdE/Jo1PJrBE5+TmSJLgFBURp3zVNxH6s9ky8tPr+BhWczq4bAW+AC4
         WeUQ==
MIME-Version: 1.0
X-Received: by 10.152.183.165 with SMTP id en5mr6788085lac.0.1424943105010;
 Thu, 26 Feb 2015 01:31:45 -0800 (PST)
Received: by 10.114.68.16 with HTTP; Thu, 26 Feb 2015 01:31:44 -0800 (PST)
Date: Thu, 26 Feb 2015 18:31:44 +0900
Message-ID: <CAPa0eF7-YY5fsE2F0qX7gJ1NSuWrV3ExHURzQ3rVp1gOtSNDPQ@mail.gmail.com>
Subject: number of partitions for hive schemaRDD
From: masaki rikitoku <rikima3132@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all

now, I'm trying the SparkSQL with hivecontext.

when I execute the hql like the following.

---

val ctx = new org.apache.spark.sql.hive.HiveContext(sc)
import ctx._

val queries = ctx.hql("select keyword from queries where dt =
'2015-02-01' limit 10000000")

---

It seem that the number of the partitions ot the queries is set by 1.

Is this the specifications for schemaRDD, SparkSQL, HiveContext ?

Are there any means to set the number of partitions arbitrary value
except for explicit repartition


Masaki Rikitoku

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11783-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 10:14:23 2015
Return-Path: <dev-return-11783-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 68EB010BF1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 10:14:23 +0000 (UTC)
Received: (qmail 88203 invoked by uid 500); 26 Feb 2015 10:14:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88112 invoked by uid 500); 26 Feb 2015 10:14:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88089 invoked by uid 99); 26 Feb 2015 10:14:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 10:14:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 10:14:15 +0000
Received: by padet14 with SMTP id et14so12828067pad.11
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 02:13:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=VO5gn0V+x8AXAYPw11Hz5YTbQ6EsY1G6b9Hewav2ZJ4=;
        b=L/WcGK4oHZT5kDMjhQLzOk1ceME0R8iWhXLabjHBeBfxm/vKMBu38MY0Lpdi8deT/J
         s+0BqK/04jBKJ31KsmuE8B1GsU4CqnkmYstrpOcAfyRIZYVWSSK4JUkxrk/8ky6UVv6s
         LxCWX5YdeE2BwrkRSl3ba7tR8tGV9mzwLMHI48OatboV1Xix82+bBEhpw48yH1zx0eV5
         RiJZ6TzoPAqkpPpO6mf/STaOMUQes9H0Ei5UQcPGLnxnk1wM8UD5LLzt6MzZUWdII6pb
         dNtGD1fAd+iWX1ShXM6eGWoZslGPXjrujtU1liCTe7p6jzYyCuePOhYmrQiL1N/vFAEr
         9HVg==
X-Received: by 10.70.132.71 with SMTP id os7mr13765293pdb.94.1424945634951;
        Thu, 26 Feb 2015 02:13:54 -0800 (PST)
Received: from [10.10.0.2] (ec2-54-65-203-163.ap-northeast-1.compute.amazonaws.com. [54.65.203.163])
        by mx.google.com with ESMTPSA id d9sm582862pdk.3.2015.02.26.02.13.52
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 26 Feb 2015 02:13:54 -0800 (PST)
Message-ID: <54EEF1E0.10308@gmail.com>
Date: Thu, 26 Feb 2015 18:13:52 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.4.0
MIME-Version: 1.0
To: masaki rikitoku <rikima3132@gmail.com>, dev <dev@spark.apache.org>
Subject: Re: number of partitions for hive schemaRDD
References: <CAPa0eF7-YY5fsE2F0qX7gJ1NSuWrV3ExHURzQ3rVp1gOtSNDPQ@mail.gmail.com>
In-Reply-To: <CAPa0eF7-YY5fsE2F0qX7gJ1NSuWrV3ExHURzQ3rVp1gOtSNDPQ@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Masaki,

I guess what you saw is the partition number of the last stage, which 
must be 1 to perform the global phase of LIMIT. To tune partition number 
of normal shuffles like joins, you may resort to 
spark.sql.shuffle.partitions.

Cheng

On 2/26/15 5:31 PM, masaki rikitoku wrote:
> Hi all
>
> now, I'm trying the SparkSQL with hivecontext.
>
> when I execute the hql like the following.
>
> ---
>
> val ctx = new org.apache.spark.sql.hive.HiveContext(sc)
> import ctx._
>
> val queries = ctx.hql("select keyword from queries where dt =
> '2015-02-01' limit 10000000")
>
> ---
>
> It seem that the number of the partitions ot the queries is set by 1.
>
> Is this the specifications for schemaRDD, SparkSQL, HiveContext ?
>
> Are there any means to set the number of partitions arbitrary value
> except for explicit repartition
>
>
> Masaki Rikitoku
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11784-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 12:38:53 2015
Return-Path: <dev-return-11784-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9C8A9172F7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 12:38:53 +0000 (UTC)
Received: (qmail 31427 invoked by uid 500); 26 Feb 2015 12:38:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31353 invoked by uid 500); 26 Feb 2015 12:38:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31341 invoked by uid 99); 26 Feb 2015 12:38:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 12:38:51 +0000
X-ASF-Spam-Status: No, hits=3.4 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_IMAGE_ONLY_12,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,T_REMOTE_IMAGE
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of alcaid1801@gmail.com designates 74.125.82.172 as permitted sender)
Received: from [74.125.82.172] (HELO mail-we0-f172.google.com) (74.125.82.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 12:38:47 +0000
Received: by wesw55 with SMTP id w55so10264492wes.4
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 04:38:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=WW9f8b1jqH3CKBEkomoxqCVSiifStHIgxcoYznTP/jE=;
        b=xHy6MoIghWJLn1wUtuSJFAd5Kvao/BPMg29jT5hqwrbH1m1BEzC51MIsVSG/aHWqfJ
         5yZcRFyVo6gunfJXQoRDXTUNHGgRzwCXF2jeG7SLUNssaKeRDeIr5kA5Z4tgZnTgGcSa
         43iAPusTQPubyP6kWOMIYE5/o98n0rfP/Vfqr98oYpT0dTF7hCIX3F6VjZd/CSJacS5c
         O4+59NwNuFDtyLXeUYtq0JkqfQfERZI3l9wrUV6weeMPBf+kN26+QyZbsAB3UjHjvhyY
         ibr8nwe/9+uUffl0qK0rudfKJIbMu5U9DrHDkR6xUbpEonA+wQkiuotk8BDw0mGFCOFx
         vjkQ==
MIME-Version: 1.0
X-Received: by 10.180.87.33 with SMTP id u1mr15986808wiz.20.1424954306735;
 Thu, 26 Feb 2015 04:38:26 -0800 (PST)
Received: by 10.27.64.134 with HTTP; Thu, 26 Feb 2015 04:38:26 -0800 (PST)
Date: Thu, 26 Feb 2015 20:38:26 +0800
Message-ID: <CACdk1M6z2LJJmPj3GHCu6bkC9+wu2U1iXYYMNzkQ5LfERfQquQ@mail.gmail.com>
Subject: graph.mapVertices() function obtain edge triplets with null attribute
From: James <alcaid1801@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d044402b0463a40050ffd077f
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d044402b0463a40050ffd077f
Content-Type: text/plain; charset=UTF-8

My code

```
// Initial the graph, assign a counter to each vertex that contains the
vertex id only
var anfGraph = graph.mapVertices { case (vid, _) =>
  val counter = new HyperLogLog(5)
  counter.offer(vid)
  counter
}

val nullVertex = anfGraph.triplets.filter(edge => edge.srcAttr ==
null).first
// There is an edge whose src attr is null

anfGraph.vertices.filter(_._1 == nullVertex).first
// I could see that the vertex has a not null attribute

// messages = anfGraph.aggregateMessages(msgFun, mergeMessage)   // <-
NullPointerException

```

My spark version:1.2.0

Alcaid

--f46d044402b0463a40050ffd077f--

From dev-return-11785-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 16:54:43 2015
Return-Path: <dev-return-11785-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 002D317D37
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 16:54:42 +0000 (UTC)
Received: (qmail 22169 invoked by uid 500); 26 Feb 2015 16:54:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22090 invoked by uid 500); 26 Feb 2015 16:54:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22076 invoked by uid 99); 26 Feb 2015 16:54:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 16:54:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of deanwampler@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 16:54:09 +0000
Received: by iecrp18 with SMTP id rp18so17697595iec.9
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 08:54:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=lWmxxV/y0/3WQpmgSwpzDbh8vgO2hFCgY0euWvXedyU=;
        b=QK8tQraFa7urpker/hVkRfbaFc1qXUEFqQDxXrREQJodccVRBnNAxbqKUW80VKLjxe
         G763Z747kItf66ft8255tpVHKYROvZEk33NJR0/JXIgRyCWdA6l6hEsHBXMmAITlxAFY
         5sNs7zX0DdMGHvi0Noy1a8XtWxDPjejBm10EGsGLgEgOX2tol7KOfe+4qkEaM+sm3YC8
         Oux4wkDUFuU9LFO/Pp6ERuKAH+4XD1Kn4bzAZs8XAkzoWLMLnjo8ZANvkPWJsGsIV7dd
         2Lc13kcjdKBPDaX/dnhKYetBcVEpxA9K3HVueHQjptC80WZi1jUGbcpe/kwNwwH2Ci5I
         NPDg==
X-Received: by 10.50.78.232 with SMTP id e8mr12745548igx.5.1424969648206; Thu,
 26 Feb 2015 08:54:08 -0800 (PST)
MIME-Version: 1.0
Received: by 10.36.113.76 with HTTP; Thu, 26 Feb 2015 08:53:48 -0800 (PST)
In-Reply-To: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
References: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
From: Dean Wampler <deanwampler@gmail.com>
Date: Thu, 26 Feb 2015 10:53:48 -0600
Message-ID: <CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
Subject: Re: Need advice for Spark newbie
To: Vikram Kone <vikramkone@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e013c6a20b27b4a05100099cc
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c6a20b27b4a05100099cc
Content-Type: text/plain; charset=UTF-8

Historically, many orgs. have replaced data warehouses with Hadoop clusters
and used Hive along with Impala (on Cloudera deployments) or Drill (on MapR
deployments) for SQL. Hive is older and slower, while Impala and Drill are
newer and faster, but you typically need both for their complementary
features, at least today.

Spark and Spark SQL are not yet complete replacements for them, but they'll
get there over time. The good news is, you can mix and match these tools,
as appropriate, because they can all work with the same datasets.

The challenge is all the tribal knowledge required to setup and manage
Hadoop clusters, to properly organize your data for best performance for
your needs, to use all these tools effectively, along with additional
Hadoop ETL tools, etc. Fortunately, tools like Tableau are already
integrated here.

However, none of this will be as polished and integrated as what you're
used to. You're trading that polish for greater scalability and flexibility.

HTH.


Dean Wampler, Ph.D.
Author: Programming Scala, 2nd Edition
<http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
Typesafe <http://typesafe.com>
@deanwampler <http://twitter.com/deanwampler>
http://polyglotprogramming.com

On Thu, Feb 26, 2015 at 1:56 AM, Vikram Kone <vikramkone@gmail.com> wrote:

> Hi,
> I'm a newbie when it comes to Spark and Hadoop eco system in general. Our
> team has been predominantly a Microsoft shop that uses MS stack for most of
> their BI needs. So we are talking SQL server  for storing relational data
> and SQL Server Analysis services for building MOLAP cubes for sub-second
> query analysis.
> Lately, we have been hitting degradation in our cube query response times
> as our data sizes grew considerably the past year. We are talking fact
> tables which are in 1o-100 billions of rows range and a few dimensions in
> the 10-100's of millions of rows. We tried vertically scaling up our SSAS
> server but queries are still taking few minutes. In light of this, I was
> entrusted with task of figuring out an open source solution that would
> scale to our current and future needs for data analysis.
> I looked at a bunch of open source tools like Apache Drill, Druid, AtScale,
> Spark, Storm, Kylin etc and settled on exploring Spark as the first step
> given it's recent rise in popularity and growing eco-system around it.
> Since we are also interested in doing deep data analysis like machine
> learning and graph algorithms on top our data, spark seems to be a good
> solution.
> I would like to build out a POC for our MOLAP cubes using spark with
> HDFS/Hive as the datasource and see how it scales for our queries/measures
> in real time with real data.
> Roughly, these are the requirements for our team
> 1. Should be able to create facts, dimensions and measures from our data
> sets in an easier way.
> 2. Cubes should be query able from Excel and Tableau.
> 3. Easily scale out by adding new nodes when data grows
> 4. Very less maintenance and highly stable for production level workloads
> 5. Sub second query latencies for COUNT DISTINCT measures (since majority
> of our expensive measures are of this type) . Are ok with Approx Distinct
> counts for better perf.
>
> So given these requirements, is Spark the right solution to replace our
> on-premise MOLAP cubes?
> Are there any tutorials or documentation on how to build cubes using Spark?
> Is that even possible? or even necessary? As long as our users can
> pivot/slice & dice the measures quickly from client tools by dragging
> dropping dimensions into rows/columns w/o the need to join to fact table,
> we are ok with however the data is laid out. Doesn't have to be a cube. It
> can be a flat file in hdfs for all we care. I would love to chat with some
> one who has successfully done this kind of migration from OLAP cubes to
> Spark in their team or company .
>
> This is it for now. Looking forward to a great discussion.
>
> P.S. We have decided on using Azure HDInsight as our managed hadoop system
> in the cloud.
>

--089e013c6a20b27b4a05100099cc--

From dev-return-11786-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 17:38:24 2015
Return-Path: <dev-return-11786-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D59DB17F8D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 17:38:24 +0000 (UTC)
Received: (qmail 96556 invoked by uid 500); 26 Feb 2015 17:38:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96468 invoked by uid 500); 26 Feb 2015 17:38:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96457 invoked by uid 99); 26 Feb 2015 17:38:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 17:38:23 +0000
X-ASF-Spam-Status: No, hits=4.2 required=10.0
	tests=FSL_HELO_BARE_IP_2,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of snunez@hortonworks.com designates 64.78.52.184 as permitted sender)
Received: from [64.78.52.184] (HELO relayvx11b.securemail.intermedia.net) (64.78.52.184)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 17:38:19 +0000
Received: from securemail.intermedia.net (localhost [127.0.0.1])
	by emg-ca-1-1.localdomain (Postfix) with ESMTP id B04E053EC7;
	Thu, 26 Feb 2015 09:37:37 -0800 (PST)
Subject: RE: Need advice for Spark newbie
MIME-Version: 1.0
x-echoworx-emg-received: Thu, 26 Feb 2015 09:37:37.710 -0800
x-echoworx-msg-id: a9def4bb-d79c-4d4a-a6de-fc587c010a30
x-echoworx-action: delivered
Received: from 10.254.155.14 ([10.254.155.14])
          by emg-ca-1-1 (JAMES SMTP Server 2.3.2) with SMTP ID 927;
          Thu, 26 Feb 2015 09:37:37 -0800 (PST)
Received: from MBX080-W4-CO-1.exch080.serverpod.net (unknown [10.224.117.101])
	by emg-ca-1-1.localdomain (Postfix) with ESMTP id 6C7C153EC7;
	Thu, 26 Feb 2015 09:37:37 -0800 (PST)
Received: from MBX080-W4-CO-1.exch080.serverpod.net (10.224.117.101) by
 MBX080-W4-CO-1.exch080.serverpod.net (10.224.117.101) with Microsoft SMTP
 Server (TLS) id 15.0.1044.25; Thu, 26 Feb 2015 09:37:36 -0800
Received: from MBX080-W4-CO-1.exch080.serverpod.net ([10.224.117.101]) by
 mbx080-w4-co-1.exch080.serverpod.net ([10.224.117.101]) with mapi id
 15.00.1044.021; Thu, 26 Feb 2015 09:37:36 -0800
From: Steve Nunez <snunez@hortonworks.com>
To: Vikram Kone <vikramkone@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Thread-Topic: Need advice for Spark newbie
Thread-Index: AQHQUZodM7Y9un9IpUaru6WFZPgZJ50DrHwA//984IA=
Date: Thu, 26 Feb 2015 17:37:36 +0000
Message-ID: <7bfd6a10399a436f815c65872b88f8ba@mbx080-w4-co-1.exch080.serverpod.net>
References: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
 <CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
In-Reply-To: <CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [192.175.27.13]
x-source-routing-agent: Processed
Content-Type: multipart/alternative;
	boundary="_000_7bfd6a10399a436f815c65872b88f8bambx080w4co1exch080serve_"
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_7bfd6a10399a436f815c65872b88f8bambx080w4co1exch080serve_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_7bfd6a10399a436f815c65872b88f8bambx080w4co1exch080serve_--

From dev-return-11787-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 17:51:22 2015
Return-Path: <dev-return-11787-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D2BF10008
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 17:51:22 +0000 (UTC)
Received: (qmail 26010 invoked by uid 500); 26 Feb 2015 17:51:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25942 invoked by uid 500); 26 Feb 2015 17:51:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25914 invoked by uid 99); 26 Feb 2015 17:51:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 17:51:04 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sandorw@palantir.com designates 66.70.54.21 as permitted sender)
Received: from [66.70.54.21] (HELO mxw1.palantir.com) (66.70.54.21)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 17:51:00 +0000
Received: from EX02-WEST.YOJOE.local ([169.254.1.145]) by
 EX03-WEST.YOJOE.local ([169.254.2.196]) with mapi id 14.03.0195.001; Thu, 26
 Feb 2015 09:50:16 -0800
From: Sandor Van Wassenhove <sandorw@palantir.com>
To: Patrick Wendell <pwendell@gmail.com>, Tathagata Das
	<tathagata.das1565@gmail.com>
CC: Soumitra Kumar <kumar.soumitra@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: Re: [VOTE] Release Apache Spark 1.3.0 (RC1)
Thread-Topic: [VOTE] Release Apache Spark 1.3.0 (RC1)
Thread-Index: AQHQS1Ld2Phit4sTxUWY9BZ3w4WICZz6sF8AgARtlYCAAJQRAIAAOmwAgAKeMoCAAOpaAA==
Date: Thu, 26 Feb 2015 17:50:15 +0000
Message-ID: <D114C624.21E15%sandorw@palantir.com>
References: <CABPQxss4pYSJeuUxZUOn7-K0_EhG+Vc_A9qUrvjcztLBdy83hA@mail.gmail.com>
 <795701600.5389956.1424472986327.JavaMail.yahoo@mail.yahoo.com>
 <CAAOnQ7spJD8SPykn2DS=b5PoOSMM=5e3exgWX-y+gOrbVYjX3A@mail.gmail.com>
 <CAMORY85Tzd7b70LdTUixzNghM_8cwmM=Gh3HOq623SnH+q3yhg@mail.gmail.com>
 <CAMwrk0=o9dwFQ7p=VBSK984dtVBaHt2bJOmGk8aGfsL56AB=tA@mail.gmail.com>
 <CABPQxss455afCd7m9uVWb610NBv1E5Dwa=w4zL2tpCmiQcnrbQ@mail.gmail.com>
In-Reply-To: <CABPQxss455afCd7m9uVWb610NBv1E5Dwa=w4zL2tpCmiQcnrbQ@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: yes
X-MS-TNEF-Correlator:
x-originating-ip: [10.201.66.200]
Content-Type: multipart/signed; protocol="application/pkcs7-signature";
	micalg=sha1; boundary="B_3507799814_51468762"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3507799814_51468762
Content-type: text/plain;
	charset="US-ASCII"
Content-transfer-encoding: 7bit

FWIW, I tested the first rc and saw no regressions. I ran our benchmarks
built against spark 1.3 and saw results consistent with spark 1.2/1.2.1.

On 2/25/15, 5:51 PM, "Patrick Wendell" <pwendell@gmail.com> wrote:

>Hey All,
>
>Just a quick updated on this thread. Issues have continued to trickle
>in. Not all of them are blocker level but enough to warrant another
>RC:
>
>I've been keeping the JIRA dashboard up and running with the latest
>status (sorry, long link):
>https://urldefense.proofpoint.com/v2/url?u=https-3A__issues.apache.org_jir
>a_issues_-3Fjql-3Dproject-2520-253D-2520SPARK-2520AND-2520-2522Target-2520
>Version-252Fs-2522-2520-253D-25201.3.0-2520AND-2520-28fixVersion-2520IS-25
>20EMPTY-2520OR-2520fixVersion-2520-21-253D-25201.3.0-29-2520AND-2520-28Res
>olution-2520IS-2520EMPTY-2520OR-2520Resolution-2520IN-2520-28Done-252C-252
>0Fixed-252C-2520Implemented-29-29-2520ORDER-2520BY-2520priority-252C-2520c
>omponent&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=cyguR-hd
>uPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2udAW6MBS4NWwKmHCBBpCG9
>zeuaRhA&s=SEjc91m9Dpx8QLLWlMK_5G0ORYtTHlLR2r3091n9qU0&e=
>
>One these are in I will cut another RC. Thanks everyone for the
>continued voting!
>
>- Patrick
>
>On Mon, Feb 23, 2015 at 10:52 PM, Tathagata Das
><tathagata.das1565@gmail.com> wrote:
>> Hey all,
>>
>> I found a major issue where JobProgressListener (a listener used to keep
>> track of jobs for the web UI) never forgets stages in one of its data
>> structures. This is a blocker for long running applications.
>> 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__issues.apache.org_ji
>>ra_browse_SPARK-2D5967&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oO
>>nmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2udAW6M
>>BS4NWwKmHCBBpCG9zeuaRhA&s=06QttEOx2YqhPQ2sWdQmOElwog_cJ5iT2Mqa1_5jnl4&e=
>>
>> I am testing a fix for this right now.
>>
>> TD
>>
>> On Mon, Feb 23, 2015 at 7:23 PM, Soumitra Kumar
>><kumar.soumitra@gmail.com>
>> wrote:
>>
>>> +1 (non-binding)
>>>
>>> For: 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__issues.apache.org_j
>>>ira_browse_SPARK-2D3660&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6
>>>oOnmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2udA
>>>W6MBS4NWwKmHCBBpCG9zeuaRhA&s=0sBvf0vWgAski9HweupKdPZwWdYH0Mimda14oHnNVDA
>>>&e= 
>>>
>>> . Docs OK
>>> . Example code is good
>>>
>>> -Soumitra.
>>>
>>>
>>> On Mon, Feb 23, 2015 at 10:33 AM, Marcelo Vanzin <vanzin@cloudera.com>
>>> wrote:
>>>
>>> > Hi Tom, are you using an sbt-built assembly by any chance? If so,
>>>take
>>> > a look at SPARK-5808.
>>> >
>>> > I haven't had any problems with the maven-built assembly. Setting
>>> > SPARK_HOME on the executors is a workaround if you want to use the
>>>sbt
>>> > assembly.
>>> >
>>> > On Fri, Feb 20, 2015 at 2:56 PM, Tom Graves
>>> > <tgraves_cs@yahoo.com.invalid> wrote:
>>> > > Trying to run pyspark on yarn in client mode with basic wordcount
>>> > example I see the following error when doing the collect:
>>> > > Error from python worker:  /usr/bin/python: No module named
>>> > sqlPYTHONPATH was:
>>> >
>>> 
>>>/grid/3/tmp/yarn-local/usercache/tgraves/filecache/20/spark-assembly-1.3
>>>.0-hadoop2.6.0.1.1411101121.jarjava.io.EOFException
>>> >       at java.io.DataInputStream.readInt(DataInputStream.java:392)
>>> > at
>>> >
>>> 
>>>org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorker
>>>Factory.scala:163)
>>> >       at
>>> >
>>> 
>>>org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(Pyth
>>>onWorkerFactory.scala:86)
>>> >       at
>>> >
>>> 
>>>org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFacto
>>>ry.scala:62)
>>> >       at 
>>>org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:105)
>>> >       at
>>> org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:69)
>>> >       at 
>>>org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
>>> >     at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
>>> > org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:308)
>>> > at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
>>> > at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)        at
>>> >
>>> 
>>>org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:6
>>>8)
>>> >       at
>>> >
>>> 
>>>org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:4
>>>1)
>>> >       at org.apache.spark.scheduler.Task.run(Task.scala:64)        at
>>> > org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:197)
>>> >   at
>>> >
>>> 
>>>java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.jav
>>>a:1145)
>>> >       at
>>> >
>>> 
>>>java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.ja
>>>va:615)
>>> >       at java.lang.Thread.run(Thread.java:722)
>>> > > any ideas on this?
>>> > > Tom
>>> > >
>>> > >      On Wednesday, February 18, 2015 2:14 AM, Patrick Wendell <
>>> > pwendell@gmail.com> wrote:
>>> > >
>>> > >
>>> > >  Please vote on releasing the following candidate as Apache Spark
>>> > version 1.3.0!
>>> > >
>>> > > The tag to be voted on is v1.3.0-rc1 (commit f97b0d4a):
>>> > >
>>> >
>>> 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__git-2Dwip-2Dus.apac
>>>he.org_repos_asf-3Fp-3Dspark.git-3Ba-3Dcommit-3Bh-3Df97b0d4a6b2650491681
>>>6d7aefcf3132cd1da6c2&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOn
>>>mz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2udAW6M
>>>BS4NWwKmHCBBpCG9zeuaRhA&s=DF8Cc8QmI354neHBHJ0HGyQtKL4yOIX2SDDwc0-hshw&e=
>>> 
>>> > >
>>> > > The release files, including signatures, digests, etc. can be
>>>found at:
>>> > > 
>>>https://urldefense.proofpoint.com/v2/url?u=http-3A__people.apache.org_-7
>>>Epwendell_spark-2D1.3.0-2Drc1_&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXB
>>>rZ4tFb6oOnmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJ
>>>cMu2udAW6MBS4NWwKmHCBBpCG9zeuaRhA&s=SHWRgoK3UcmmnWVXU0LWjArD2PdG9RYWnO2f
>>>lVC8nMQ&e= 
>>> > >
>>> > > Release artifacts are signed with the following key:
>>> > > 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__people.apache.org_k
>>>eys_committer_pwendell.asc&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4t
>>>Fb6oOnmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2
>>>udAW6MBS4NWwKmHCBBpCG9zeuaRhA&s=lAnGa6hXGkJQp14UV7lB1zQqOcCeMS3hYG0scwXh
>>>OFw&e= 
>>> > >
>>> > > The staging repository for this release can be found at:
>>> > >
>>> 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__repository.apache.o
>>>rg_content_repositories_orgapachespark-2D1069_&d=AwIFAw&c=izlc9mHr637UR4
>>>lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2
>>>JUA&m=frmHzwi9qJcMu2udAW6MBS4NWwKmHCBBpCG9zeuaRhA&s=TOEI0htKa2cktRFNdRiM
>>>owZerFsTz44EPFC3qpzDzs8&e=
>>> > >
>>> > > The documentation corresponding to this release can be found at:
>>> > > 
>>>https://urldefense.proofpoint.com/v2/url?u=http-3A__people.apache.org_-7
>>>Epwendell_spark-2D1.3.0-2Drc1-2Ddocs_&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS
>>>3Vn2UXBrZ4tFb6oOnmz8&r=cyguR-hduPXP87jeUDbz1NGOZ18iIQjDTb_C1-_2JUA&m=frm
>>>Hzwi9qJcMu2udAW6MBS4NWwKmHCBBpCG9zeuaRhA&s=iduBlV7hay0TwWj6-Gwto3ZBElN4k
>>>0frDTIn0Ce8B8E&e=
>>> > >
>>> > > Please vote on releasing this package as Apache Spark 1.3.0!
>>> > >
>>> > > The vote is open until Saturday, February 21, at 08:03 UTC and
>>>passes
>>> > > if a majority of at least 3 +1 PMC votes are cast.
>>> > >
>>> > > [ ] +1 Release this package as Apache Spark 1.3.0
>>> > > [ ] -1 Do not release this package because ...
>>> > >
>>> > > To learn more about Apache Spark, please see
>>> > > 
>>>https://urldefense.proofpoint.com/v2/url?u=http-3A__spark.apache.org_&d=
>>>AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=cyguR-hduPXP87jeU
>>>Dbz1NGOZ18iIQjDTb_C1-_2JUA&m=frmHzwi9qJcMu2udAW6MBS4NWwKmHCBBpCG9zeuaRhA
>>>&s=UPGEOKzVMEZ-8CqDq6dkvwzKpkF6fmBgy9ZVXanQOcE&e=
>>> > >
>>> > > == How can I help test this release? ==
>>> > > If you are a Spark user, you can help us test this release by
>>> > > taking a Spark 1.2 workload and running on this release candidate,
>>> > > then reporting any regressions.
>>> > >
>>> > > == What justifies a -1 vote for this release? ==
>>> > > This vote is happening towards the end of the 1.3 QA period,
>>> > > so -1 votes should only occur for significant regressions from
>>>1.2.1.
>>> > > Bugs already present in 1.2.X, minor regressions, or bugs related
>>> > > to new features will not block this release.
>>> > >
>>> > > - Patrick
>>> > >
>>> > > 
>>>---------------------------------------------------------------------
>>> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > > For additional commands, e-mail: dev-help@spark.apache.org
>>> > >
>>> > >
>>> > >
>>> > >
>>> >
>>> >
>>> >
>>> > --
>>> > Marcelo
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>> >
>>>
>
>---------------------------------------------------------------------
>To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>For additional commands, e-mail: dev-help@spark.apache.org
>

--B_3507799814_51468762
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
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--B_3507799814_51468762--

From dev-return-11788-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:17:24 2015
Return-Path: <dev-return-11788-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5BEE110B14
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:17:24 +0000 (UTC)
Received: (qmail 68996 invoked by uid 500); 26 Feb 2015 21:17:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68914 invoked by uid 500); 26 Feb 2015 21:17:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68902 invoked by uid 99); 26 Feb 2015 21:17:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:17:22 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:17:18 +0000
Received: by ierx19 with SMTP id x19so21403601ier.3
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:16:13 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=RbVcE/ey4hXVZAQXsK6TooyeH2KqEoTVhWHXw+PYrJE=;
        b=gh5l/WYhvV25OP+h54FGXROzZvV5ZyFuWBQEtrE/BpdBMFlEBm5RwndrGfP7Xdftwe
         Hlzy95XK76/AL1iDXr5yqAW5ThOzlAhT94r4EfbcL7lnVDswIeQ4jYh+JnFGriuarN9M
         uo97Qj2rFhvwti6rsGFhANbabv+7Z+okVFwcNxVjkXCbbsjApT0V9iFxuM+QDjeq8Grv
         xyoNZ8MxfObF9xPP4pO6reLywfKG4H5xAB5rOhnbxjx6WseVvjrjTMej2m2s+hetHqat
         uu/qLPMnajI32nd48xqMKjtj+RoaUTE2SI8v2BioviZq0Vu+adnLrjZ0oPof+x1mD1d2
         imrg==
MIME-Version: 1.0
X-Received: by 10.43.10.138 with SMTP id pa10mr8828926icb.94.1424985373197;
 Thu, 26 Feb 2015 13:16:13 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Thu, 26 Feb 2015 13:16:13 -0800 (PST)
In-Reply-To: <CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
Date: Thu, 26 Feb 2015 13:16:13 -0800
Message-ID: <CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Xiangrui Meng <mengxr@gmail.com>
To: Joseph Bradley <joseph@databricks.com>
Cc: "Evan R. Sparks" <evan.sparks@gmail.com>, "Ulanov, Alexander" <alexander.ulanov@hp.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, sam.halliday@gmail.com
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Alexander,

I don't quite understand the part where netlib-cublas is about 20x
slower than netlib-openblas. What is the overhead of using a GPU BLAS
with netlib-java?

CC'ed Sam, the author of netlib-java.

Best,
Xiangrui

On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com> wro=
te:
> Better documentation for linking would be very helpful!  Here's a JIRA:
> https://issues.apache.org/jira/browse/SPARK-6019
>
>
> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com>
> wrote:
>
>> Thanks for compiling all the data and running these benchmarks, Alex. Th=
e
>> big takeaways here can be seen with this chart:
>>
>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6k=
mAJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>>
>> 1) A properly configured GPU matrix multiply implementation (e.g.
>> BIDMat+GPU) can provide substantial (but less than an order of magnitude=
)
>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>> netlib-java+openblas-compiled).
>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude wors=
e
>> than a well-tuned CPU implementation, particularly for larger matrices.
>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>> basically agrees with the authors own benchmarks (
>> https://github.com/fommil/netlib-java)
>>
>> I think that most of our users are in a situation where using GPUs may n=
ot
>> be practical - although we could consider having a good GPU backend
>> available as an option. However, *ALL* users of MLlib could benefit
>> (potentially tremendously) from using a well-tuned CPU-based BLAS
>> implementation. Perhaps we should consider updating the mllib guide with=
 a
>> more complete section for enabling high performance binaries on OSX and
>> Linux? Or better, figure out a way for the system to fetch these
>> automatically.
>>
>> - Evan
>>
>>
>>
>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>> alexander.ulanov@hp.com> wrote:
>>
>>> Just to summarize this thread, I was finally able to make all performan=
ce
>>> comparisons that we discussed. It turns out that:
>>> BIDMat-cublas>>BIDMat
>>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-r=
epo=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>>>
>>> Below is the link to the spreadsheet with full results.
>>>
>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T=
9J5r7kwKSPkY/edit?usp=3Dsharing
>>>
>>> One thing still needs exploration: does BIDMat-cublas perform copying
>>> to/from machine=E2=80=99s RAM?
>>>
>>> -----Original Message-----
>>> From: Ulanov, Alexander
>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>> To: Evan R. Sparks
>>> Cc: Joseph Bradley; dev@spark.apache.org
>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>
>>> Thanks, Evan! It seems that ticket was marked as duplicate though the
>>> original one discusses slightly different topic. I was able to link net=
lib
>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked inside =
a
>>> 60MB library.
>>>
>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>> +----------------------------------------------------------------------=
-+
>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>> |1,638475459 |
>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>> 1569,233228 |
>>>
>>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas o=
n
>>> my machine. Probably, I=E2=80=99ll add two more columns with locally co=
mpiled
>>> openblas and cuda.
>>>
>>> Alexander
>>>
>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
>>> Sent: Monday, February 09, 2015 6:06 PM
>>> To: Ulanov, Alexander
>>> Cc: Joseph Bradley; dev@spark.apache.org
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> Great - perhaps we can move this discussion off-list and onto a JIRA
>>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705)
>>>
>>> It seems like this is going to be somewhat exploratory for a while (and
>>> there's probably only a handful of us who really care about fast linear
>>> algebra!)
>>>
>>> - Evan
>>>
>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>> Hi Evan,
>>>
>>> Thank you for explanation and useful link. I am going to build OpenBLAS=
,
>>> link it with Netlib-java and perform benchmark again.
>>>
>>> Do I understand correctly that BIDMat binaries contain statically linke=
d
>>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat not
>>> having MKL BLAS installed on my server. If it is true, I wonder if it i=
s OK
>>> because Intel sells this library. Nevertheless, it seems that in my cas=
e
>>> precompiled MKL BLAS performs better than precompiled OpenBLAS given th=
at
>>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>
>>> Though, it might be interesting to link Netlib-java with Intel MKL, as
>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>>> (Netlib-java) interested to compare their libraries.
>>>
>>> Best regards, Alexander
>>>
>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>> evan.sparks@gmail.com>]
>>> Sent: Friday, February 06, 2015 5:58 PM
>>>
>>> To: Ulanov, Alexander
>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> I would build OpenBLAS yourself, since good BLAS performance comes from
>>> getting cache sizes, etc. set up correctly for your particular hardware=
 -
>>> this is often a very tricky process (see, e.g. ATLAS), but we found tha=
t on
>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>>> performance competitive with MKL.
>>>
>>> To make sure the right library is getting used, you have to make sure
>>> it's first on the search path - export
>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>>>
>>> For some examples of getting netlib-java setup on an ec2 node and some
>>> example benchmarking code we ran a while back, see:
>>> https://github.com/shivaram/matrix-bench
>>>
>>> In particular - build-openblas-ec2.sh shows you how to build the librar=
y
>>> and set up symlinks correctly, and scala/run-netlib.sh shows you how to=
 get
>>> the path setup and get that library picked up by netlib-java.
>>>
>>> In this way - you could probably get cuBLAS set up to be used by
>>> netlib-java as well.
>>>
>>> - Evan
>>>
>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>> Evan, could you elaborate on how to force BIDMat and netlib-java to for=
ce
>>> loading the right blas? For netlib, I there are few JVM flags, such as
>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so =
I can
>>> force it to use Java implementation. Not sure I understand how to force=
 use
>>> a specific blas (not specific wrapper for blas).
>>>
>>> Btw. I have installed openblas (yum install openblas), so I suppose tha=
t
>>> netlib is using it.
>>>
>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>> evan.sparks@gmail.com>]
>>> Sent: Friday, February 06, 2015 5:19 PM
>>> To: Ulanov, Alexander
>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> Getting breeze to pick up the right blas library is critical for
>>> performance. I recommend using OpenBLAS (or MKL, if you already have it=
).
>>> It might make sense to force BIDMat to use the same underlying BLAS lib=
rary
>>> as well.
>>>
>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>> Hi Evan, Joseph
>>>
>>> I did few matrix multiplication test and BIDMat seems to be ~10x faster
>>> than netlib-java+breeze (sorry for weird table formatting):
>>>
>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-64=
|
>>> Breeze+Netlib-java f2jblas |
>>> +----------------------------------------------------------------------=
-+
>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>>>
>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
>>> Linux, Scala 2.11.
>>>
>>> Later I will make tests with Cuda. I need to install new Cuda version f=
or
>>> this purpose.
>>>
>>> Do you have any ideas why breeze-netlib with native blas is so much
>>> slower than BIDMat MKL?
>>>
>>> Best regards, Alexander
>>>
>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
>>> joseph@databricks.com>]
>>> Sent: Thursday, February 05, 2015 5:29 PM
>>> To: Ulanov, Alexander
>>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> Hi Alexander,
>>>
>>> Using GPUs with Spark would be very exciting.  Small comment: Concernin=
g
>>> your question earlier about keeping data stored on the GPU rather than
>>> having to move it between main memory and GPU memory on each iteration,=
 I
>>> would guess this would be critical to getting good performance.  If you
>>> could do multiple local iterations before aggregating results, then the
>>> cost of data movement to the GPU could be amortized (and I believe that=
 is
>>> done in practice).  Having Spark be aware of the GPU and using it as
>>> another part of memory sounds like a much bigger undertaking.
>>>
>>> Joseph
>>>
>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentatio=
n by John
>>> Canny and I am really inspired by his talk and comparisons with Spark M=
Llib.
>>>
>>> I am very interested to find out what will be better within Spark: BIDM=
at
>>> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
>>> benchmark them? Currently I do benchmarks on artificial neural networks=
 in
>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear alg=
ebra, it involves
>>> some other things that are essential to machine learning.
>>>
>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>> evan.sparks@gmail.com>]
>>> Sent: Thursday, February 05, 2015 1:29 PM
>>> To: Ulanov, Alexander
>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to dat=
a
>>> layout and fewer levels of indirection - it's definitely a worthwhile
>>> experiment to run. The main speedups I've seen from using it come from
>>> highly optimized GPU code for linear algebra. I know that in the past C=
anny
>>> has gone as far as to write custom GPU kernels for performance-critical
>>> regions of code.[1]
>>>
>>> BIDMach is highly optimized for single node performance or performance =
on
>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can b=
e
>>> batched in that way) the performance tends to fall off. Canny argues fo=
r
>>> hardware/software codesign and as such prefers machine configurations t=
hat
>>> are quite different than what we find in most commodity cluster nodes -
>>> e.g. 10 disk cahnnels and 4 GPUs.
>>>
>>> In contrast, MLlib was designed for horizontal scalability on commodity
>>> clusters and works best on very big datasets - order of terabytes.
>>>
>>> For the most part, these projects developed concurrently to address
>>> slightly different use cases. That said, there may be bits of BIDMach w=
e
>>> could repurpose for MLlib - keep in mind we need to be careful about
>>> maintaining cross-language compatibility for our Java and Python-users,
>>> though.
>>>
>>> - Evan
>>>
>>> [1] - http://arxiv.org/abs/1409.5402
>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>
>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>> Hi Evan,
>>>
>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
>>> know what makes them faster than netlib-java?
>>>
>>> The same group has BIDMach library that implements machine learning. Fo=
r
>>> some examples they use Caffe convolutional neural network library owned=
 by
>>> another group in Berkeley. Could you elaborate on how these all might b=
e
>>> connected with Spark Mllib? If you take BIDMat for linear algebra why d=
on=E2=80=99t
>>> you take BIDMach for optimization and learning?
>>>
>>> Best regards, Alexander
>>>
>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
>>> evan.sparks@gmail.com>>]
>>> Sent: Thursday, February 05, 2015 12:09 PM
>>> To: Ulanov, Alexander
>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
>>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>
>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas i=
n
>>> many cases.
>>>
>>> You might consider taking a look at the codepaths that BIDMat (
>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>> netlib-java/breeze. John Canny et. al. have done a bunch of work optimi=
zing
>>> to make this work really fast from Scala. I've run it on my laptop and
>>> compared to MKL and in certain cases it's 10x faster at matrix multiply=
.
>>> There are a lot of layers of indirection here and you really want to av=
oid
>>> data copying as much as possible.
>>>
>>> We could also consider swapping out BIDMat for Breeze, but that would b=
e
>>> a big project and if we can figure out how to get breeze+cublas to
>>> comparable performance that would be a big win.
>>>
>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>> Dear Spark developers,
>>>
>>> I am exploring how to make linear algebra operations faster within Spar=
k.
>>> One way of doing this is to use Scala Breeze library that is bundled wi=
th
>>> Spark. For matrix operations, it employs Netlib-java that has a Java
>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
>>> binaries if they are available on the worker node. It also has its own
>>> optimized Java implementation of BLAS. It is worth mentioning, that nat=
ive
>>> binaries provide better performance only for BLAS level 3, i.e.
>>> matrix-matrix operations or general matrix multiplication (GEMM). This =
is
>>> confirmed by GEMM test on Netlib-java page
>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>> experiments with training of artificial neural network
>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>> However, I would like to boost performance more.
>>>
>>> GPU is supposed to work fast with linear algebra and there is Nvidia CU=
DA
>>> implementation of BLAS, called cublas. I have one Linux server with Nvi=
dia
>>> GPU and I was able to do the following. I linked cublas (instead of
>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>>> Breeze/Netlib is using it. Then I did some performance measurements wit=
h
>>> regards to artificial neural network batch learning in Spark MLlib that
>>> involves matrix-matrix multiplications. It turns out that for matrices =
of
>>> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cub=
las
>>> becomes slower for bigger matrices. It worth mentioning that it is was =
not
>>> a test for ONLY multiplication since there are other operations involve=
d.
>>> One of the reasons for slowdown might be the overhead of copying the
>>> matrices from computer memory to graphic card memory and back.
>>>
>>> So, few questions:
>>> 1) Do these results with CUDA make sense?
>>> 2) If the problem is with copy overhead, are there any libraries that
>>> allow to force intermediate results to stay in graphic card memory thus
>>> removing the overhead?
>>> 3) Any other options to speed-up linear algebra in Spark?
>>>
>>> Thank you, Alexander
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
>>> dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apache.o=
rg
>>> <mailto:dev-unsubscribe@spark.apache.org>>
>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
>>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
>>> dev-help@spark.apache.org>>
>>>
>>>
>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11789-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:22:57 2015
Return-Path: <dev-return-11789-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 51C5310B53
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:22:57 +0000 (UTC)
Received: (qmail 79905 invoked by uid 500); 26 Feb 2015 21:22:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79831 invoked by uid 500); 26 Feb 2015 21:22:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79819 invoked by uid 99); 26 Feb 2015 21:22:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:22:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.181 as permitted sender)
Received: from [209.85.223.181] (HELO mail-ie0-f181.google.com) (209.85.223.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:22:50 +0000
Received: by iebtr6 with SMTP id tr6so21341946ieb.10
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:20:14 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=FcyIRTwVGvmXO4IaQyOQtG2oLVZ9EztX0pegps0pVtc=;
        b=BTLHkNTWZivjK1uVFkdsMaALs6nBSA/j6M9vWgYhhq0xAc3BNLn/JUVlPl+e8lUaw8
         4WQuzREU76l07LlP6ly+FxRwB/agCVy0eHA1p5/QIGD6wEF8FhJtoERktCvsFYCsCK56
         WP9klDwmOl8GGlPlX9bKs3FMUimYSmXMQqNUdxFDsFXENtFRLUaEL920IiY0xGBTYF65
         AUUMaM0g1+xA82x44Yc/Jujkn2/GzzougfsELVXekVXH/6zUvKzorE0b4G4HaH1svYyc
         AihLfmyBDtt1RJO6rkvQz2bOKUZEToSV/SzIcPqz6N/3BSUAJhY1fk66tu7jFT1AS/Cp
         bGsg==
MIME-Version: 1.0
X-Received: by 10.50.25.225 with SMTP id f1mr14237136igg.29.1424985614763;
 Thu, 26 Feb 2015 13:20:14 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Thu, 26 Feb 2015 13:20:14 -0800 (PST)
In-Reply-To: <CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
	<CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
	<CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
Date: Thu, 26 Feb 2015 13:20:14 -0800
Message-ID: <CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com>
Subject: Re: Google Summer of Code - ideas
From: Xiangrui Meng <mengxr@gmail.com>
To: Manoj Kumar <manojkumarsivaraj334@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

There are couple things in Scala/Java but missing in Python API:

1. model import/export
2. evaluation metrics
3. distributed linear algebra
4. streaming algorithms

If you are interested, we can list/create target JIRAs and hunt them
down one by one.

Best,
Xiangrui

On Wed, Feb 25, 2015 at 7:37 PM, Manoj Kumar
<manojkumarsivaraj334@gmail.com> wrote:
> Hi,
>
> I think that would be really good. Are there any specific issues that are to
> be implemented as per priority?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11790-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:23:31 2015
Return-Path: <dev-return-11790-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8928010B65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:23:31 +0000 (UTC)
Received: (qmail 84082 invoked by uid 500); 26 Feb 2015 21:23:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84003 invoked by uid 500); 26 Feb 2015 21:23:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83991 invoked by uid 99); 26 Feb 2015 21:23:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:23:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:22:58 +0000
Received: by iecvy18 with SMTP id vy18so21377271iec.6
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:21:26 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=FcyIRTwVGvmXO4IaQyOQtG2oLVZ9EztX0pegps0pVtc=;
        b=BTLHkNTWZivjK1uVFkdsMaALs6nBSA/j6M9vWgYhhq0xAc3BNLn/JUVlPl+e8lUaw8
         4WQuzREU76l07LlP6ly+FxRwB/agCVy0eHA1p5/QIGD6wEF8FhJtoERktCvsFYCsCK56
         WP9klDwmOl8GGlPlX9bKs3FMUimYSmXMQqNUdxFDsFXENtFRLUaEL920IiY0xGBTYF65
         AUUMaM0g1+xA82x44Yc/Jujkn2/GzzougfsELVXekVXH/6zUvKzorE0b4G4HaH1svYyc
         AihLfmyBDtt1RJO6rkvQz2bOKUZEToSV/SzIcPqz6N/3BSUAJhY1fk66tu7jFT1AS/Cp
         bGsg==
MIME-Version: 1.0
X-Received: by 10.50.25.225 with SMTP id f1mr14237136igg.29.1424985614763;
 Thu, 26 Feb 2015 13:20:14 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Thu, 26 Feb 2015 13:20:14 -0800 (PST)
In-Reply-To: <CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
	<CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
	<CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
Date: Thu, 26 Feb 2015 13:20:14 -0800
Message-ID: <CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com>
Subject: Re: Google Summer of Code - ideas
From: Xiangrui Meng <mengxr@gmail.com>
To: Manoj Kumar <manojkumarsivaraj334@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

There are couple things in Scala/Java but missing in Python API:

1. model import/export
2. evaluation metrics
3. distributed linear algebra
4. streaming algorithms

If you are interested, we can list/create target JIRAs and hunt them
down one by one.

Best,
Xiangrui

On Wed, Feb 25, 2015 at 7:37 PM, Manoj Kumar
<manojkumarsivaraj334@gmail.com> wrote:
> Hi,
>
> I think that would be really good. Are there any specific issues that are to
> be implemented as per priority?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11791-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:23:56 2015
Return-Path: <dev-return-11791-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 87BC610B6A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:23:56 +0000 (UTC)
Received: (qmail 86048 invoked by uid 500); 26 Feb 2015 21:23:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85977 invoked by uid 500); 26 Feb 2015 21:23:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85705 invoked by uid 99); 26 Feb 2015 21:23:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:23:54 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vikramkone@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:23:51 +0000
Received: by mail-ob0-f174.google.com with SMTP id wo20so14209655obc.5
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:23:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SxyAUi6WZTOKh5Y3OwMTfiBgyCjbpiV9xxgVQ6xbupM=;
        b=LmaJKutWqJUGGBZjKpgIVtZNwc4yw1GN5XZY+doNpLKgcArbEGH9c0RrGiFfytODn1
         LHNHVCA10xsi1Wim5HdCqt714GjJyRTwsWS6EMUIJ6giNS0jZAV7D/IBzlTcifDzJO8s
         sMPI+U39tR0hafrrNE3F9DaI0Fj30VdueP62fE4r1+RloV9IIqbta0VkzbAPNJcQP2zE
         Igsz+bEnDHQk80YDqiE3oLXGcKjBLv1AOAoDf3YsdNHaS5pBSDTUj9s8oaENY88am6o0
         SbeJ3ty67PXkdqPo+GqW9fNd5sZS1UII+DQX08nI8gjtIL2fIvr9mz0oiOinucbnd4NN
         b5Lw==
MIME-Version: 1.0
X-Received: by 10.202.211.130 with SMTP id k124mr7286892oig.124.1424985810472;
 Thu, 26 Feb 2015 13:23:30 -0800 (PST)
Received: by 10.182.193.8 with HTTP; Thu, 26 Feb 2015 13:23:30 -0800 (PST)
In-Reply-To: <CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
References: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
	<CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
Date: Thu, 26 Feb 2015 13:23:30 -0800
Message-ID: <CAG9PkLLv-viZbXCFVwQYjWe9J6Hg3j5Ng-pt-kZrzDod=hhwsw@mail.gmail.com>
Subject: Re: Need advice for Spark newbie
From: Vikram Kone <vikramkone@gmail.com>
To: Dean Wampler <deanwampler@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113de5a00b15320510045db7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113de5a00b15320510045db7
Content-Type: text/plain; charset=UTF-8

Dean
Thanks for the info. Are you saying that we can create star/snowflake data
models using spark so they can be queried from tableau ?

On Thursday, February 26, 2015, Dean Wampler <deanwampler@gmail.com> wrote:

> Historically, many orgs. have replaced data warehouses with Hadoop
> clusters and used Hive along with Impala (on Cloudera deployments) or Drill
> (on MapR deployments) for SQL. Hive is older and slower, while Impala and
> Drill are newer and faster, but you typically need both for their
> complementary features, at least today.
>
> Spark and Spark SQL are not yet complete replacements for them, but
> they'll get there over time. The good news is, you can mix and match these
> tools, as appropriate, because they can all work with the same datasets.
>
> The challenge is all the tribal knowledge required to setup and manage
> Hadoop clusters, to properly organize your data for best performance for
> your needs, to use all these tools effectively, along with additional
> Hadoop ETL tools, etc. Fortunately, tools like Tableau are already
> integrated here.
>
> However, none of this will be as polished and integrated as what you're
> used to. You're trading that polish for greater scalability and flexibility.
>
> HTH.
>
>
> Dean Wampler, Ph.D.
> Author: Programming Scala, 2nd Edition
> <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
> Typesafe <http://typesafe.com>
> @deanwampler <http://twitter.com/deanwampler>
> http://polyglotprogramming.com
>
> On Thu, Feb 26, 2015 at 1:56 AM, Vikram Kone <vikramkone@gmail.com
> <javascript:_e(%7B%7D,'cvml','vikramkone@gmail.com');>> wrote:
>
>> Hi,
>> I'm a newbie when it comes to Spark and Hadoop eco system in general. Our
>> team has been predominantly a Microsoft shop that uses MS stack for most
>> of
>> their BI needs. So we are talking SQL server  for storing relational data
>> and SQL Server Analysis services for building MOLAP cubes for sub-second
>> query analysis.
>> Lately, we have been hitting degradation in our cube query response times
>> as our data sizes grew considerably the past year. We are talking fact
>> tables which are in 1o-100 billions of rows range and a few dimensions in
>> the 10-100's of millions of rows. We tried vertically scaling up our SSAS
>> server but queries are still taking few minutes. In light of this, I was
>> entrusted with task of figuring out an open source solution that would
>> scale to our current and future needs for data analysis.
>> I looked at a bunch of open source tools like Apache Drill, Druid,
>> AtScale,
>> Spark, Storm, Kylin etc and settled on exploring Spark as the first step
>> given it's recent rise in popularity and growing eco-system around it.
>> Since we are also interested in doing deep data analysis like machine
>> learning and graph algorithms on top our data, spark seems to be a good
>> solution.
>> I would like to build out a POC for our MOLAP cubes using spark with
>> HDFS/Hive as the datasource and see how it scales for our queries/measures
>> in real time with real data.
>> Roughly, these are the requirements for our team
>> 1. Should be able to create facts, dimensions and measures from our data
>> sets in an easier way.
>> 2. Cubes should be query able from Excel and Tableau.
>> 3. Easily scale out by adding new nodes when data grows
>> 4. Very less maintenance and highly stable for production level workloads
>> 5. Sub second query latencies for COUNT DISTINCT measures (since majority
>> of our expensive measures are of this type) . Are ok with Approx Distinct
>> counts for better perf.
>>
>> So given these requirements, is Spark the right solution to replace our
>> on-premise MOLAP cubes?
>> Are there any tutorials or documentation on how to build cubes using
>> Spark?
>> Is that even possible? or even necessary? As long as our users can
>> pivot/slice & dice the measures quickly from client tools by dragging
>> dropping dimensions into rows/columns w/o the need to join to fact table,
>> we are ok with however the data is laid out. Doesn't have to be a cube. It
>> can be a flat file in hdfs for all we care. I would love to chat with some
>> one who has successfully done this kind of migration from OLAP cubes to
>> Spark in their team or company .
>>
>> This is it for now. Looking forward to a great discussion.
>>
>> P.S. We have decided on using Azure HDInsight as our managed hadoop system
>> in the cloud.
>>
>
>

--001a113de5a00b15320510045db7--

From dev-return-11792-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:34:34 2015
Return-Path: <dev-return-11792-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 875CC10C06
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:34:34 +0000 (UTC)
Received: (qmail 27082 invoked by uid 500); 26 Feb 2015 21:34:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27001 invoked by uid 500); 26 Feb 2015 21:34:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26987 invoked by uid 99); 26 Feb 2015 21:34:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:34:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vikramkone@gmail.com designates 209.85.214.177 as permitted sender)
Received: from [209.85.214.177] (HELO mail-ob0-f177.google.com) (209.85.214.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:34:08 +0000
Received: by mail-ob0-f177.google.com with SMTP id wp18so13885682obc.8
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:32:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=GPz3PvdmMVmlPIePz73cL1ffTYIAC+yg9FkW4Z8/Pb4=;
        b=gwW2aKErR7ebQPKoIv03fNAnpje20WDvsRvDjCWzQO9Je7qbtJBcfzz9ZD/MFvxYzK
         yJeorBqKsN1JDMP48hkE/xUt8jJfHdK0b0ceIH1RsfY1EUMNXv9VEZKXDq/PPCwCu7bJ
         Mw/Tg2WZZz0k1Qny/DoBG80PCirMMmYlFgpnrt2AktlSeuMduq/n4TpXGS1fbq0Pct4m
         +/shkg/wiXYQpz4GfBmgC5Gy85VvQ8q2anDtJkGEgVj/uoepB+yXlLg1XNH32Q9Zl18P
         c1jUqNteKqIyyXIslkA/zLcnIWd+LtliriRv4Nh0cBf7N8MZDuOo/hP3ZyX90JK1f/Xz
         G4UQ==
MIME-Version: 1.0
X-Received: by 10.202.211.130 with SMTP id k124mr7312733oig.124.1424986356131;
 Thu, 26 Feb 2015 13:32:36 -0800 (PST)
Received: by 10.182.193.8 with HTTP; Thu, 26 Feb 2015 13:32:36 -0800 (PST)
In-Reply-To: <7bfd6a10399a436f815c65872b88f8ba@mbx080-w4-co-1.exch080.serverpod.net>
References: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
	<CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com>
	<7bfd6a10399a436f815c65872b88f8ba@mbx080-w4-co-1.exch080.serverpod.net>
Date: Thu, 26 Feb 2015 13:32:36 -0800
Message-ID: <CAG9PkLK0Yuq6tgRw7zT3S=iOLa=3_MwWPwP++zjzKYYNmq=PTQ@mail.gmail.com>
Subject: Re: Need advice for Spark newbie
From: Vikram Kone <vikramkone@gmail.com>
To: Steve Nunez <snunez@hortonworks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113de5a0912d5f0510047dfd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113de5a0912d5f0510047dfd
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Steve
Thanks for the info. I will look into hivemail. Are you saying that we can
create star/snowflake data models using spark so they can be queried from
tableau ?

On Thursday, February 26, 2015, Steve Nunez <snunez@hortonworks.com> wrote:

>  Hi Vikram,
>
>
>
> There was a recent presentation at Strata that you might find useful: Hiv=
e
> on Spark is Blazing Fast .. Or Is It?
> <http://www.slideshare.net/hortonworks/hive-on-spark-is-blazing-fast-or-i=
s-it-final>
>
>
>
> Generally those conclusions mirror my own observations: on large data
> sets, Hive still gives the best SQL performance and the curve drops off a=
s
> the data sets get smaller. Of course if you also want to build models fro=
m
> the data than Spark is an attractive option with its unified programming
> model. HiveMall <https://github.com/myui/hivemall> might also be
> applicable in your case; I=E2=80=99ve seen increasing adoption of it with=
in certain
> industries.
>
>
>
> If you are going cloud, HDInsights is a good choice. You can run both Spa=
rk
> and R on HDInsights
> <http://azure.microsoft.com/blog/2014/11/17/azure-hdinsight-clusters-can-=
now-be-customized-to-run-a-variety-of-hadoop-projects-including-spark-and-r=
/>,
> as well as get the newest version of Hive (0.14, with Stinger
> enhancements from Microsoft
> <http://www.slideshare.net/hugfrance/recent-enhancements-to-apache-hive-q=
uery-performance>)
> for =E2=80=98free=E2=80=99, so once you get your data into a wasb you can=
 try all three
> methods and see which one works best for you. HDInsights works well for
> mixing & matching tools.
>
>
>
> HTH,
>
> -          SteveN
>
>
>
> -----Original Message-----
> From: Dean Wampler [mailto:deanwampler@gmail.com
> <javascript:_e(%7B%7D,'cvml','deanwampler@gmail.com');>]
> Sent: Thursday, 26 February, 2015 8:54
> To: Vikram Kone
> Cc: dev@spark.apache.org
> <javascript:_e(%7B%7D,'cvml','dev@spark.apache.org');>
> Subject: Re: Need advice for Spark newbie
>
>
>
> Historically, many orgs. have replaced data warehouses with Hadoop
> clusters and used Hive along with Impala (on Cloudera deployments) or Dri=
ll
> (on MapR
>
> deployments) for SQL. Hive is older and slower, while Impala and Drill ar=
e
> newer and faster, but you typically need both for their complementary
> features, at least today.
>
>
>
> Spark and Spark SQL are not yet complete replacements for them, but
> they'll get there over time. The good news is, you can mix and match thes=
e
> tools, as appropriate, because they can all work with the same datasets.
>
>
>
> The challenge is all the tribal knowledge required to setup and manage
> Hadoop clusters, to properly organize your data for best performance for
> your needs, to use all these tools effectively, along with additional
> Hadoop ETL tools, etc. Fortunately, tools like Tableau are already
> integrated here.
>
>
>
> However, none of this will be as polished and integrated as what you're
> used to. You're trading that polish for greater scalability and flexibili=
ty.
>
>
>
> HTH.
>
>
>
>
>
> Dean Wampler, Ph.D.
>
> Author: Programming Scala, 2nd Edition
>
> <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly) Typesafe <
> http://typesafe.com> @deanwampler <http://twitter.com/deanwampler>
> http://polyglotprogramming.com
>
>
>
> On Thu, Feb 26, 2015 at 1:56 AM, Vikram Kone <vikramkone@gmail.com
> <javascript:_e(%7B%7D,'cvml','vikramkone@gmail.com');>> wrote:
>
>
>
> > Hi,
>
> > I'm a newbie when it comes to Spark and Hadoop eco system in general.
>
> > Our team has been predominantly a Microsoft shop that uses MS stack
>
> > for most of their BI needs. So we are talking SQL server  for storing
>
> > relational data and SQL Server Analysis services for building MOLAP
>
> > cubes for sub-second query analysis.
>
> > Lately, we have been hitting degradation in our cube query response
>
> > times as our data sizes grew considerably the past year. We are
>
> > talking fact tables which are in 1o-100 billions of rows range and a
>
> > few dimensions in the 10-100's of millions of rows. We tried
>
> > vertically scaling up our SSAS server but queries are still taking few
>
> > minutes. In light of this, I was entrusted with task of figuring out
>
> > an open source solution that would scale to our current and future need=
s
> for data analysis.
>
> > I looked at a bunch of open source tools like Apache Drill, Druid,
>
> > AtScale, Spark, Storm, Kylin etc and settled on exploring Spark as the
>
> > first step given it's recent rise in popularity and growing eco-system
> around it.
>
> > Since we are also interested in doing deep data analysis like machine
>
> > learning and graph algorithms on top our data, spark seems to be a
>
> > good solution.
>
> > I would like to build out a POC for our MOLAP cubes using spark with
>
> > HDFS/Hive as the datasource and see how it scales for our
>
> > queries/measures in real time with real data.
>
> > Roughly, these are the requirements for our team 1. Should be able to
>
> > create facts, dimensions and measures from our data sets in an easier
>
> > way.
>
> > 2. Cubes should be query able from Excel and Tableau.
>
> > 3. Easily scale out by adding new nodes when data grows 4. Very less
>
> > maintenance and highly stable for production level workloads 5. Sub
>
> > second query latencies for COUNT DISTINCT measures (since majority of
>
> > our expensive measures are of this type) . Are ok with Approx Distinct
>
> > counts for better perf.
>
> >
>
> > So given these requirements, is Spark the right solution to replace
>
> > our on-premise MOLAP cubes?
>
> > Are there any tutorials or documentation on how to build cubes using
> Spark?
>
> > Is that even possible? or even necessary? As long as our users can
>
> > pivot/slice & dice the measures quickly from client tools by dragging
>
> > dropping dimensions into rows/columns w/o the need to join to fact
>
> > table, we are ok with however the data is laid out. Doesn't have to be
>
> > a cube. It can be a flat file in hdfs for all we care. I would love to
>
> > chat with some one who has successfully done this kind of migration
>
> > from OLAP cubes to Spark in their team or company .
>
> >
>
> > This is it for now. Looking forward to a great discussion.
>
> >
>
> > P.S. We have decided on using Azure HDInsight as our managed hadoop
>
> > system in the cloud.
>
> >
>

--001a113de5a0912d5f0510047dfd--

From dev-return-11793-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:39:12 2015
Return-Path: <dev-return-11793-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35A3510C28
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:39:12 +0000 (UTC)
Received: (qmail 33099 invoked by uid 500); 26 Feb 2015 21:39:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33020 invoked by uid 500); 26 Feb 2015 21:39:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33000 invoked by uid 99); 26 Feb 2015 21:39:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:39:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:38:39 +0000
Received: by mail-ob0-f172.google.com with SMTP id nt9so14425601obb.3
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:37:31 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=5lsdeEMyKAyGyNj53/K/az8lW8cb70eI6QLdG+lvCKA=;
        b=MR9hM9AE4Fe4IuV51dvjrldlc/k/225jdTVliAzW0u2Pu3wcKU7/JJqAkCXRDBKxn3
         AdiybDEtIG7+UvXY9ExlEBk0rdOQ2LOC146GZ2WcaBw4IbUlfG9Pse3Ouu1wquDUnaYU
         H/16YIJTvMUfDDRNxtFASvXV+al810g9HOWirlrCbgvi2xD7i0JncrlePIDNgIO3Poy1
         OYT+AVxBWezZZXHxxRhr1vQcNCsB6poA5KEcVjNgrEj0plraJn9iJNpcJof/woMLhSl+
         QnWH0G3obSxVs7JCNZAzPYQdVJgpqhxWXzBLd9tZ+4x69uWwYDkibgk3ws6FNSKnn2kh
         5Iog==
X-Gm-Message-State: ALoCoQlOPr+r2vG7f4NNu+uQxta/bp+5QViiKUzwGHQYRX+1Gg++8/HWC0c+RzwSG+mWutFZQqrs
X-Received: by 10.60.165.68 with SMTP id yw4mr7562703oeb.76.1424986651596;
 Thu, 26 Feb 2015 13:37:31 -0800 (PST)
MIME-Version: 1.0
Received: by 10.76.116.33 with HTTP; Thu, 26 Feb 2015 13:37:11 -0800 (PST)
In-Reply-To: <CAO4jRXYn5N_d0W2yteGtNzMTDbbupoM48kbEmovUhtHhnstZOw@mail.gmail.com>
References: <CAO4jRXZAX0=LThkdjeU5d_p0_esK8gg1BUwyzZSrenEMMht-9g@mail.gmail.com>
 <CAHUQ+_YhbdP3CGVg697amartG+AS=Sk0zM4ZK=ADyCTb-PCZ5g@mail.gmail.com>
 <CAO4jRXatHK=V8i=AxtRSze5YhuKqk8_RAvA_dsBkTXw3qJwBKA@mail.gmail.com>
 <CAO4jRXZovRqkyCNiD8qqin05ccvRxUY2+-M8-8gCnYd3Tp8zkg@mail.gmail.com>
 <CAHUQ+_Y1Hg0Gg1xi2e5EuLVkux1-4ufzXwVNAbeVmpTQf0xu7w@mail.gmail.com> <CAO4jRXYn5N_d0W2yteGtNzMTDbbupoM48kbEmovUhtHhnstZOw@mail.gmail.com>
From: Victor Tso-Guillen <vtso@paxata.com>
Date: Thu, 26 Feb 2015 13:37:11 -0800
Message-ID: <CAO4jRXa0BjguKhO3379Y-XZx0KosNj+EoBEFBDSOT80nfy07xw@mail.gmail.com>
Subject: Re: Scheduler hang?
To: dev@spark.apache.org
Cc: "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/related; boundary=047d7b4508622e129a0510048fcc
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b4508622e129a0510048fcc
Content-Type: multipart/alternative; boundary=047d7b4508622e12950510048fcb

--047d7b4508622e12950510048fcb
Content-Type: text/plain; charset=UTF-8

Okay I confirmed my suspicions of a hang. I made a request that stopped
progressing, though the already-scheduled tasks had finished. I made a
separate request that was small enough not to hang, and it kicked the hung
job enough to finish. I think what's happening is that the scheduler or the
local backend is not kicking the revive offers messaging at the right time,
but I have to dig into the code some more to nail the culprit. Anyone on
these list have experience in those code areas that could help?

On Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <vtso@paxata.com> wrote:

> Thanks for the link. Unfortunately, I turned on rdd compression and
> nothing changed. I tried moving netty -> nio and no change :(
>
> On Thu, Feb 26, 2015 at 2:01 AM, Akhil Das <akhil@sigmoidanalytics.com>
> wrote:
>
>> Not many that i know of, but i bumped into this one
>> https://issues.apache.org/jira/browse/SPARK-4516
>>
>> Thanks
>> Best Regards
>>
>> On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-Guillen <vtso@paxata.com>
>> wrote:
>>
>>> Is there any potential problem from 1.1.1 to 1.2.1 with shuffle
>>> dependencies that produce no data?
>>>
>>> On Thu, Feb 26, 2015 at 1:56 AM, Victor Tso-Guillen <vtso@paxata.com>
>>> wrote:
>>>
>>>> The data is small. The job is composed of many small stages.
>>>>
>>>> * I found that with fewer than 222 the problem exhibits. What will be
>>>> gained by going higher?
>>>> * Pushing up the parallelism only pushes up the boundary at which the
>>>> system appears to hang. I'm worried about some sort of message loss or
>>>> inconsistency.
>>>> * Yes, we are using Kryo.
>>>> * I'll try that, but I'm again a little confused why you're
>>>> recommending this. I'm stumped so might as well?
>>>>
>>>> On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <akhil@sigmoidanalytics.com
>>>> > wrote:
>>>>
>>>>> What operation are you trying to do and how big is the data that you
>>>>> are operating on?
>>>>>
>>>>> Here's a few things which you can try:
>>>>>
>>>>> - Repartition the RDD to a higher number than 222
>>>>> - Specify the master as local[*] or local[10]
>>>>> - Use Kryo Serializer (.set("spark.serializer",
>>>>> "org.apache.spark.serializer.KryoSerializer"))
>>>>> - Enable RDD Compression (.set("spark.rdd.compress","true") )
>>>>>
>>>>>
>>>>> Thanks
>>>>> Best Regards
>>>>>
>>>>> On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso-Guillen <vtso@paxata.com>
>>>>> wrote:
>>>>>
>>>>>> I'm getting this really reliably on Spark 1.2.1. Basically I'm in
>>>>>> local mode with parallelism at 8. I have 222 tasks and I never seem to get
>>>>>> far past 40. Usually in the 20s to 30s it will just hang. The last logging
>>>>>> is below, and a screenshot of the UI.
>>>>>>
>>>>>> 2015-02-25 20:39:55.779 GMT-0800 INFO  [task-result-getter-3]
>>>>>> TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms on
>>>>>> localhost (1/5)
>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>> worker-10] Executor - Finished task 1.0 in stage 16.0 (TID 20). 2492 bytes
>>>>>> result sent to driver
>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>> worker-8] Executor - Finished task 2.0 in stage 16.0 (TID 21). 2492 bytes
>>>>>> result sent to driver
>>>>>> 2015-02-25 20:39:55.831 GMT-0800 INFO  [task-result-getter-0]
>>>>>> TaskSetManager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on
>>>>>> localhost (2/5)
>>>>>> 2015-02-25 20:39:55.836 GMT-0800 INFO  [task-result-getter-1]
>>>>>> TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on
>>>>>> localhost (3/5)
>>>>>> 2015-02-25 20:39:55.891 GMT-0800 INFO  [Executor task launch
>>>>>> worker-9] Executor - Finished task 0.0 in stage 16.0 (TID 19). 2492 bytes
>>>>>> result sent to driver
>>>>>> 2015-02-25 20:39:55.896 GMT-0800 INFO  [task-result-getter-2]
>>>>>> TaskSetManager - Finished task 0.0 in stage 16.0 (TID 19) in 740 ms on
>>>>>> localhost (4/5)
>>>>>>
>>>>>> [image: Inline image 1]
>>>>>> What should I make of this? Where do I start?
>>>>>>
>>>>>> Thanks,
>>>>>> Victor
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

--047d7b4508622e12950510048fcb
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Okay I confirmed my suspicions of a hang. I made a request=
 that stopped progressing, though the already-scheduled tasks had finished.=
 I made a separate request that was small enough not to hang, and it kicked=
 the hung job enough to finish. I think what&#39;s happening is that the sc=
heduler or the local backend is not kicking the revive offers messaging at =
the right time, but I have to dig into the code some more to nail the culpr=
it. Anyone on these list have experience in those code areas that could hel=
p?</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, F=
eb 26, 2015 at 2:27 AM, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D=
"mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com</a>&gt;</span> w=
rote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;borde=
r-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Thanks for the lin=
k. Unfortunately, I turned on rdd compression and nothing changed. I tried =
moving netty -&gt; nio and no change :(</div><div class=3D"HOEnZb"><div cla=
ss=3D"h5"><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu,=
 Feb 26, 2015 at 2:01 AM, Akhil Das <span dir=3D"ltr">&lt;<a href=3D"mailto=
:akhil@sigmoidanalytics.com" target=3D"_blank">akhil@sigmoidanalytics.com</=
a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0=
 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><di=
v class=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monosp=
ace;color:rgb(0,0,0)">Not many that i know of, but i bumped into this one=
=C2=A0<a href=3D"https://issues.apache.org/jira/browse/SPARK-4516" target=
=3D"_blank">https://issues.apache.org/jira/browse/SPARK-4516</a></div></div=
><div class=3D"gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Th=
anks<div>Best Regards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-=
Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"=
_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail=
_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:=
1ex"><div dir=3D"ltr">Is there any potential problem from 1.1.1 to 1.2.1 wi=
th shuffle dependencies that produce no data?</div><div><div><div class=3D"=
gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 1:56 AM=
, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.co=
m" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr">The data is small. The job is composed o=
f many small stages.<div><br></div><div>* I found that with fewer than 222 =
the problem exhibits. What will be gained by going higher?</div><div>* Push=
ing up the parallelism only pushes up the boundary at which the system appe=
ars to hang. I&#39;m worried about some sort of message loss or inconsisten=
cy.</div><div>* Yes, we are using Kryo.</div><div>* I&#39;ll try that, but =
I&#39;m again a little confused why you&#39;re recommending this. I&#39;m s=
tumped so might as well?</div></div><div><div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <s=
pan dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.com" target=3D=
"_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br><blockquote cl=
ass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;p=
adding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">What operation a=
re you trying to do and how big is the data that you are operating on?</div=
><div class=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,mo=
nospace;color:rgb(0,0,0)"><br></div><div class=3D"gmail_default" style=3D"f=
ont-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">Here&#39;s a f=
ew things which you can try:</div><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)"><br></div><block=
quote style=3D"margin:0 0 0 40px;border:none;padding:0px"><div class=3D"gma=
il_default" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(=
0,0,0)">- Repartition the RDD to a higher number than 222</div><div class=
=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;col=
or:rgb(0,0,0)">- Specify the master as local[*] or local[10]</div><div clas=
s=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;co=
lor:rgb(0,0,0)">- Use Kryo Serializer (<span style=3D"color:rgb(51,51,51);f=
ont-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-=
size:12px;line-height:1.4;font-weight:bold">.</span><span style=3D"color:rg=
b(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,mo=
nospace;font-size:12px;line-height:1.4;background-color:rgb(255,255,255)">s=
et</span><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39=
;Liberation Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font=
-weight:bold">(</span><span style=3D"font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;color:rgb(1=
87,136,68)">&quot;spark.serializer&quot;</span><span style=3D"color:rgb(51,=
51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospa=
ce;font-size:12px;line-height:1.4;font-weight:bold">,</span><span style=3D"=
color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Co=
urier,monospace;font-size:12px;line-height:1.4"> </span><span style=3D"font=
-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-siz=
e:12px;line-height:1.4;color:rgb(187,136,68)">&quot;org.apache.spark.serial=
izer.KryoSerializer&quot;</span><span style=3D"color:rgb(51,51,51);font-fam=
ily:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-size:12=
px;line-height:1.4;font-weight:bold">))</span></div><div class=3D"gmail_def=
ault" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)=
"><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font-weight=
:bold"><span style=3D"color:rgb(0,0,0);font-family:&#39;courier new&#39;,mo=
nospace;font-size:small;font-weight:normal;line-height:normal">- Enable RDD=
 Compression (</span><span style=3D"line-height:1.4">.</span><span style=3D=
"line-height:1.4;font-weight:normal;background-color:rgb(255,255,255)">set<=
/span><span style=3D"line-height:1.4">(</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;spark.rdd.compress&quot;<=
/span><span style=3D"line-height:1.4">,</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;true&quot;</span><span st=
yle=3D"line-height:1.4">) )</span></span></div></blockquote></div><div clas=
s=3D"gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>B=
est Regards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso=
-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D=
"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div>I&#39;m getting this really reliably on Spark 1=
.2.1. Basically I&#39;m in local mode with parallelism at 8. I have 222 tas=
ks and I never seem to get far past 40. Usually in the 20s to 30s it will j=
ust hang. The last logging is below, and a screenshot of the UI.</div><div>=
<br></div><div>2015-02-25 20:39:55.779 GMT-0800 INFO =C2=A0[task-result-get=
ter-3] TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms =
on localhost (1/5)</div><div>2015-02-25 20:39:55.825 GMT-0800 INFO =C2=A0[E=
xecutor task launch worker-10] Executor - Finished task 1.0 in stage 16.0 (=
TID 20). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.825=
 GMT-0800 INFO =C2=A0[Executor task launch worker-8] Executor - Finished ta=
sk 2.0 in stage 16.0 (TID 21). 2492 bytes result sent to driver</div><div>2=
015-02-25 20:39:55.831 GMT-0800 INFO =C2=A0[task-result-getter-0] TaskSetMa=
nager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on localhost (2/=
5)</div><div>2015-02-25 20:39:55.836 GMT-0800 INFO =C2=A0[task-result-gette=
r-1] TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on=
 localhost (3/5)</div><div>2015-02-25 20:39:55.891 GMT-0800 INFO =C2=A0[Exe=
cutor task launch worker-9] Executor - Finished task 0.0 in stage 16.0 (TID=
 19). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.896 GM=
T-0800 INFO =C2=A0[task-result-getter-2] TaskSetManager - Finished task 0.0=
 in stage 16.0 (TID 19) in 740 ms on localhost (4/5)</div><div><br></div><d=
iv><img src=3D"cid:ii_14bc43449dfc51e7" alt=3D"Inline image 1" width=3D"544=
" height=3D"124"><br></div><div>What should I make of this? Where do I star=
t?</div><div><br></div><div>Thanks,</div><div>Victor</div></div>
</blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>

--047d7b4508622e12950510048fcb--
--047d7b4508622e129a0510048fcc--

From dev-return-11794-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:47:48 2015
Return-Path: <dev-return-11794-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2298E10C8F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:47:48 +0000 (UTC)
Received: (qmail 63628 invoked by uid 500); 26 Feb 2015 21:47:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63555 invoked by uid 500); 26 Feb 2015 21:47:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63539 invoked by uid 99); 26 Feb 2015 21:47:37 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:47:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of deanwampler@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:47:12 +0000
Received: by iecrd18 with SMTP id rd18so21730425iec.5
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:46:25 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=loB0aRxjJ7swp9d8gGCeZPESyyQYUPi6MOzRWfD7nPA=;
        b=CcDQXvxSUFDINQ9hFgjmr6nmShiFdrazOpfLh1N575Mha6nU4VLefIVf19Mn4eszJz
         vcJirhHy77H+0Zd0o4K3IG6PZ/eCwF4wGMDrzTjaoqL5ioeG3rTtrDEPBjbs9cZ+XvVC
         ExfMpOkl4eEs2It9b/9Q2rcc5sYD1Lqs5OzfFM0qNkJ/gJBld3sZ6OsjjOcONEw+J/Bu
         fsV/L28mKfoHtMR/XkbsqLZHmj1w3/IrP4mkiOgpvf/q39rx+gg1K5gf04+dnAUHmiyX
         bduOFAQrCxu5j+qqB3/gGXct1MQq1qC2WalUXD82hjlHJoixnDUiUKi9Tph1HWkm0f1o
         fsvw==
X-Received: by 10.107.169.233 with SMTP id f102mr14863256ioj.6.1424987185249;
 Thu, 26 Feb 2015 13:46:25 -0800 (PST)
MIME-Version: 1.0
Received: by 10.36.113.76 with HTTP; Thu, 26 Feb 2015 13:46:05 -0800 (PST)
In-Reply-To: <CAG9PkLLv-viZbXCFVwQYjWe9J6Hg3j5Ng-pt-kZrzDod=hhwsw@mail.gmail.com>
References: <CAG9PkLJcoE7vVUZpotHXCXQoMic18RSP9ixxxm3SRgUJLsP2dw@mail.gmail.com>
 <CAKW0i0xWXEq_OZ8=_FE_mgFjY7poyU4V+aJd2mxKsger7BjbGg@mail.gmail.com> <CAG9PkLLv-viZbXCFVwQYjWe9J6Hg3j5Ng-pt-kZrzDod=hhwsw@mail.gmail.com>
From: Dean Wampler <deanwampler@gmail.com>
Date: Thu, 26 Feb 2015 15:46:05 -0600
Message-ID: <CAKW0i0wzycWDrZUfeiqp+Ryb6bsqiJY0fpNOTEFcpeJfGqvJLA@mail.gmail.com>
Subject: Re: Need advice for Spark newbie
To: Vikram Kone <vikramkone@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11425954fc8595051004ae52
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11425954fc8595051004ae52
Content-Type: text/plain; charset=UTF-8

There's no support for star or snowflake models, per se. What you get with
Hadoop is access to all your data and the processing power to build the ad
hoc queries you want, when you need them, rather than having to figure out
a schema/model in advance.

I recommend that you also ask your questions on one of the Hadoop or Hive
user mailing lists, where you'll find people who have moved data warehouses
to Hadoop. Then you can use Spark for some of the tasks you'll do. This
"dev" (developer) mailing list isn't really the place to discuss this
anyway. (The user list would be slightly better.)

dean

Dean Wampler, Ph.D.
Author: Programming Scala, 2nd Edition
<http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
Typesafe <http://typesafe.com>
@deanwampler <http://twitter.com/deanwampler>
http://polyglotprogramming.com

On Thu, Feb 26, 2015 at 3:23 PM, Vikram Kone <vikramkone@gmail.com> wrote:

> Dean
> Thanks for the info. Are you saying that we can create star/snowflake data
> models using spark so they can be queried from tableau ?
>
>
> On Thursday, February 26, 2015, Dean Wampler <deanwampler@gmail.com>
> wrote:
>
>> Historically, many orgs. have replaced data warehouses with Hadoop
>> clusters and used Hive along with Impala (on Cloudera deployments) or Drill
>> (on MapR deployments) for SQL. Hive is older and slower, while Impala and
>> Drill are newer and faster, but you typically need both for their
>> complementary features, at least today.
>>
>> Spark and Spark SQL are not yet complete replacements for them, but
>> they'll get there over time. The good news is, you can mix and match these
>> tools, as appropriate, because they can all work with the same datasets.
>>
>> The challenge is all the tribal knowledge required to setup and manage
>> Hadoop clusters, to properly organize your data for best performance for
>> your needs, to use all these tools effectively, along with additional
>> Hadoop ETL tools, etc. Fortunately, tools like Tableau are already
>> integrated here.
>>
>> However, none of this will be as polished and integrated as what you're
>> used to. You're trading that polish for greater scalability and flexibility.
>>
>> HTH.
>>
>>
>> Dean Wampler, Ph.D.
>> Author: Programming Scala, 2nd Edition
>> <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
>> Typesafe <http://typesafe.com>
>> @deanwampler <http://twitter.com/deanwampler>
>> http://polyglotprogramming.com
>>
>> On Thu, Feb 26, 2015 at 1:56 AM, Vikram Kone <vikramkone@gmail.com>
>> wrote:
>>
>>> Hi,
>>> I'm a newbie when it comes to Spark and Hadoop eco system in general. Our
>>> team has been predominantly a Microsoft shop that uses MS stack for most
>>> of
>>> their BI needs. So we are talking SQL server  for storing relational data
>>> and SQL Server Analysis services for building MOLAP cubes for sub-second
>>> query analysis.
>>> Lately, we have been hitting degradation in our cube query response times
>>> as our data sizes grew considerably the past year. We are talking fact
>>> tables which are in 1o-100 billions of rows range and a few dimensions in
>>> the 10-100's of millions of rows. We tried vertically scaling up our SSAS
>>> server but queries are still taking few minutes. In light of this, I was
>>> entrusted with task of figuring out an open source solution that would
>>> scale to our current and future needs for data analysis.
>>> I looked at a bunch of open source tools like Apache Drill, Druid,
>>> AtScale,
>>> Spark, Storm, Kylin etc and settled on exploring Spark as the first step
>>> given it's recent rise in popularity and growing eco-system around it.
>>> Since we are also interested in doing deep data analysis like machine
>>> learning and graph algorithms on top our data, spark seems to be a good
>>> solution.
>>> I would like to build out a POC for our MOLAP cubes using spark with
>>> HDFS/Hive as the datasource and see how it scales for our
>>> queries/measures
>>> in real time with real data.
>>> Roughly, these are the requirements for our team
>>> 1. Should be able to create facts, dimensions and measures from our data
>>> sets in an easier way.
>>> 2. Cubes should be query able from Excel and Tableau.
>>> 3. Easily scale out by adding new nodes when data grows
>>> 4. Very less maintenance and highly stable for production level workloads
>>> 5. Sub second query latencies for COUNT DISTINCT measures (since majority
>>> of our expensive measures are of this type) . Are ok with Approx Distinct
>>> counts for better perf.
>>>
>>> So given these requirements, is Spark the right solution to replace our
>>> on-premise MOLAP cubes?
>>> Are there any tutorials or documentation on how to build cubes using
>>> Spark?
>>> Is that even possible? or even necessary? As long as our users can
>>> pivot/slice & dice the measures quickly from client tools by dragging
>>> dropping dimensions into rows/columns w/o the need to join to fact table,
>>> we are ok with however the data is laid out. Doesn't have to be a cube.
>>> It
>>> can be a flat file in hdfs for all we care. I would love to chat with
>>> some
>>> one who has successfully done this kind of migration from OLAP cubes to
>>> Spark in their team or company .
>>>
>>> This is it for now. Looking forward to a great discussion.
>>>
>>> P.S. We have decided on using Azure HDInsight as our managed hadoop
>>> system
>>> in the cloud.
>>>
>>
>>

--001a11425954fc8595051004ae52--

From dev-return-11795-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:50:51 2015
Return-Path: <dev-return-11795-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CD37A10CB5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:50:51 +0000 (UTC)
Received: (qmail 76273 invoked by uid 500); 26 Feb 2015 21:50:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76181 invoked by uid 500); 26 Feb 2015 21:50:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75885 invoked by uid 99); 26 Feb 2015 21:50:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:50:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sam.halliday@gmail.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:50:16 +0000
Received: by iecrd18 with SMTP id rd18so21768938iec.5
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:49:29 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=xYzEQ2J82UKPpLg5zb4daeqwN0Vhjp1t00DEciEZII4=;
        b=aw3TDNNEflzR7JAERNpa2qn9p/wP4iLYGVp1DEf0nLWhUYMBy21GWzt68/KYqEefQT
         /NUlfiV275zAZRL+gU/beEFiNxYAEFPLVP2SVYQvNPbVOa86tBB7ReAi25d8gLfWeGip
         t2VoDT5wBn3BRqFcTVEByQk1LoIFqc/El7VjukxZbWD9YMBJPRBno0ldvhuJ77PACalU
         ya9TdqZwRiBLfPctUB+V6iI002BpH5thqK8k9v+j4xxFW8gTKFC0QLoWpq50stw0ynhO
         6UbkdorrT+Ev3A1zZdTYJCWai1jsUCrNCAS68asVX9tZyxu1zruyOUV4Ubix3jcra3/u
         DddA==
MIME-Version: 1.0
X-Received: by 10.50.49.43 with SMTP id r11mr227383ign.18.1424987368902; Thu,
 26 Feb 2015 13:49:28 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 13:49:28 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 13:49:28 -0800 (PST)
In-Reply-To: <CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
Date: Thu, 26 Feb 2015 21:49:28 +0000
Message-ID: <CALR_T9AWgLcops_cgXSrUfQsh23riXDOrog7uwM2=Ge1uBkHFw@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Sam Halliday <sam.halliday@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, Joseph Bradley <joseph@databricks.com>, 
	"Ulanov, Alexander" <alexander.ulanov@hp.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: multipart/alternative; boundary=047d7bdca5b6eed7eb051004b966
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdca5b6eed7eb051004b966
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi all,

I'm not surprised if the GPU is slow. It's about the bottleneck copying the
memory. Watch my talk, linked from the netlib-java github page, to
understand further. The only way to currently make use of a GPU is to do
all the operations using the GPU's kernel. You can find some prepackaged
high level algorithms than do this, but it's extremely limiting.

I believe hardware will fix this problem eventually, so I still advocate
using the netlib primitives. I'm particularly interested in APU approaches
and I'm very interested in finding somebody to fund me to look into it.
It's too much work for a side project.

Look on the last few slides of my talk to see the potential performance
gains.

Best regards, Sam
On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com> wrote:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com>
> wrote:
> > Better documentation for linking would be very helpful!  Here's a JIRA:
> > https://issues.apache.org/jira/browse/SPARK-6019
> >
> >
> > On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com>
> > wrote:
> >
> >> Thanks for compiling all the data and running these benchmarks, Alex.
> The
> >> big takeaways here can be seen with this chart:
> >>
> >>
> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6km=
AJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
> >>
> >> 1) A properly configured GPU matrix multiply implementation (e.g.
> >> BIDMat+GPU) can provide substantial (but less than an order of
> magnitude)
> >> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> >> netlib-java+openblas-compiled).
> >> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
> worse
> >> than a well-tuned CPU implementation, particularly for larger matrices=
.
> >> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
> >> basically agrees with the authors own benchmarks (
> >> https://github.com/fommil/netlib-java)
> >>
> >> I think that most of our users are in a situation where using GPUs may
> not
> >> be practical - although we could consider having a good GPU backend
> >> available as an option. However, *ALL* users of MLlib could benefit
> >> (potentially tremendously) from using a well-tuned CPU-based BLAS
> >> implementation. Perhaps we should consider updating the mllib guide
> with a
> >> more complete section for enabling high performance binaries on OSX an=
d
> >> Linux? Or better, figure out a way for the system to fetch these
> >> automatically.
> >>
> >> - Evan
> >>
> >>
> >>
> >> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
> >> alexander.ulanov@hp.com> wrote:
> >>
> >>> Just to summarize this thread, I was finally able to make all
> performance
> >>> comparisons that we discussed. It turns out that:
> >>> BIDMat-cublas>>BIDMat
> >>>
> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-rep=
o=3D=3Dnetlib-cublas>netlib-blas>f2jblas
> >>>
> >>> Below is the link to the spreadsheet with full results.
> >>>
> >>>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J=
5r7kwKSPkY/edit?usp=3Dsharing
> >>>
> >>> One thing still needs exploration: does BIDMat-cublas perform copying
> >>> to/from machine=E2=80=99s RAM?
> >>>
> >>> -----Original Message-----
> >>> From: Ulanov, Alexander
> >>> Sent: Tuesday, February 10, 2015 2:12 PM
> >>> To: Evan R. Sparks
> >>> Cc: Joseph Bradley; dev@spark.apache.org
> >>> Subject: RE: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Thanks, Evan! It seems that ticket was marked as duplicate though the
> >>> original one discusses slightly different topic. I was able to link
> netlib
> >>> with MKL from BIDMat binaries. Indeed, MKL is statically linked insid=
e
> a
> >>> 60MB library.
> >>>
> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> >>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> >>>
> +-----------------------------------------------------------------------+
> >>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
> >>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
> >>> |1,638475459 |
> >>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
> >>> 1569,233228 |
> >>>
> >>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas
> on
> >>> my machine. Probably, I=E2=80=99ll add two more columns with locally =
compiled
> >>> openblas and cuda.
> >>>
> >>> Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> >>> Sent: Monday, February 09, 2015 6:06 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Great - perhaps we can move this discussion off-list and onto a JIRA
> >>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705=
)
> >>>
> >>> It seems like this is going to be somewhat exploratory for a while (a=
nd
> >>> there's probably only a handful of us who really care about fast line=
ar
> >>> algebra!)
> >>>
> >>> - Evan
> >>>
> >>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Hi Evan,
> >>>
> >>> Thank you for explanation and useful link. I am going to build
> OpenBLAS,
> >>> link it with Netlib-java and perform benchmark again.
> >>>
> >>> Do I understand correctly that BIDMat binaries contain statically
> linked
> >>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat no=
t
> >>> having MKL BLAS installed on my server. If it is true, I wonder if it
> is OK
> >>> because Intel sells this library. Nevertheless, it seems that in my
> case
> >>> precompiled MKL BLAS performs better than precompiled OpenBLAS given
> that
> >>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
> >>>
> >>> Though, it might be interesting to link Netlib-java with Intel MKL, a=
s
> >>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
> >>> (Netlib-java) interested to compare their libraries.
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Friday, February 06, 2015 5:58 PM
> >>>
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I would build OpenBLAS yourself, since good BLAS performance comes fr=
om
> >>> getting cache sizes, etc. set up correctly for your particular
> hardware -
> >>> this is often a very tricky process (see, e.g. ATLAS), but we found
> that on
> >>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> >>> performance competitive with MKL.
> >>>
> >>> To make sure the right library is getting used, you have to make sure
> >>> it's first on the search path - export
> >>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
> >>>
> >>> For some examples of getting netlib-java setup on an ec2 node and som=
e
> >>> example benchmarking code we ran a while back, see:
> >>> https://github.com/shivaram/matrix-bench
> >>>
> >>> In particular - build-openblas-ec2.sh shows you how to build the
> library
> >>> and set up symlinks correctly, and scala/run-netlib.sh shows you how
> to get
> >>> the path setup and get that library picked up by netlib-java.
> >>>
> >>> In this way - you could probably get cuBLAS set up to be used by
> >>> netlib-java as well.
> >>>
> >>> - Evan
> >>>
> >>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Evan, could you elaborate on how to force BIDMat and netlib-java to
> force
> >>> loading the right blas? For netlib, I there are few JVM flags, such a=
s
> >>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, s=
o I
> can
> >>> force it to use Java implementation. Not sure I understand how to
> force use
> >>> a specific blas (not specific wrapper for blas).
> >>>
> >>> Btw. I have installed openblas (yum install openblas), so I suppose
> that
> >>> netlib is using it.
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Friday, February 06, 2015 5:19 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Getting breeze to pick up the right blas library is critical for
> >>> performance. I recommend using OpenBLAS (or MKL, if you already have
> it).
> >>> It might make sense to force BIDMat to use the same underlying BLAS
> library
> >>> as well.
> >>>
> >>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Hi Evan, Joseph
> >>>
> >>> I did few matrix multiplication test and BIDMat seems to be ~10x fast=
er
> >>> than netlib-java+breeze (sorry for weird table formatting):
> >>>
> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
> native_system_linux_x86-64|
> >>> Breeze+Netlib-java f2jblas |
> >>>
> +-----------------------------------------------------------------------+
> >>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> >>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> >>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
> >>>
> >>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 1=
9
> >>> Linux, Scala 2.11.
> >>>
> >>> Later I will make tests with Cuda. I need to install new Cuda version
> for
> >>> this purpose.
> >>>
> >>> Do you have any ideas why breeze-netlib with native blas is so much
> >>> slower than BIDMat MKL?
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
> >>> joseph@databricks.com>]
> >>> Sent: Thursday, February 05, 2015 5:29 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Hi Alexander,
> >>>
> >>> Using GPUs with Spark would be very exciting.  Small comment:
> Concerning
> >>> your question earlier about keeping data stored on the GPU rather tha=
n
> >>> having to move it between main memory and GPU memory on each
> iteration, I
> >>> would guess this would be critical to getting good performance.  If y=
ou
> >>> could do multiple local iterations before aggregating results, then t=
he
> >>> cost of data movement to the GPU could be amortized (and I believe
> that is
> >>> done in practice).  Having Spark be aware of the GPU and using it as
> >>> another part of memory sounds like a much bigger undertaking.
> >>>
> >>> Joseph
> >>>
> >>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentat=
ion by
> John
> >>> Canny and I am really inspired by his talk and comparisons with Spark
> MLlib.
> >>>
> >>> I am very interested to find out what will be better within Spark:
> BIDMat
> >>> or netlib-java with CPU or GPU natives. Could you suggest a fair way =
to
> >>> benchmark them? Currently I do benchmarks on artificial neural
> networks in
> >>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear a=
lgebra, it
> involves
> >>> some other things that are essential to machine learning.
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Thursday, February 05, 2015 1:29 PM
> >>> To: Ulanov, Alexander
> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> >>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
> data
> >>> layout and fewer levels of indirection - it's definitely a worthwhile
> >>> experiment to run. The main speedups I've seen from using it come fro=
m
> >>> highly optimized GPU code for linear algebra. I know that in the past
> Canny
> >>> has gone as far as to write custom GPU kernels for performance-critic=
al
> >>> regions of code.[1]
> >>>
> >>> BIDMach is highly optimized for single node performance or performanc=
e
> on
> >>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can
> be
> >>> batched in that way) the performance tends to fall off. Canny argues
> for
> >>> hardware/software codesign and as such prefers machine configurations
> that
> >>> are quite different than what we find in most commodity cluster nodes=
 -
> >>> e.g. 10 disk cahnnels and 4 GPUs.
> >>>
> >>> In contrast, MLlib was designed for horizontal scalability on commodi=
ty
> >>> clusters and works best on very big datasets - order of terabytes.
> >>>
> >>> For the most part, these projects developed concurrently to address
> >>> slightly different use cases. That said, there may be bits of BIDMach
> we
> >>> could repurpose for MLlib - keep in mind we need to be careful about
> >>> maintaining cross-language compatibility for our Java and Python-user=
s,
> >>> though.
> >>>
> >>> - Evan
> >>>
> >>> [1] - http://arxiv.org/abs/1409.5402
> >>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
> >>>
> >>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>> Hi Evan,
> >>>
> >>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
> >>> know what makes them faster than netlib-java?
> >>>
> >>> The same group has BIDMach library that implements machine learning.
> For
> >>> some examples they use Caffe convolutional neural network library
> owned by
> >>> another group in Berkeley. Could you elaborate on how these all might
> be
> >>> connected with Spark Mllib? If you take BIDMat for linear algebra why
> don=E2=80=99t
> >>> you take BIDMach for optimization and learning?
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>>]
> >>> Sent: Thursday, February 05, 2015 12:09 PM
> >>> To: Ulanov, Alexander
> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> >>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas
> in
> >>> many cases.
> >>>
> >>> You might consider taking a look at the codepaths that BIDMat (
> >>> https://github.com/BIDData/BIDMat) takes and comparing them to
> >>> netlib-java/breeze. John Canny et. al. have done a bunch of work
> optimizing
> >>> to make this work really fast from Scala. I've run it on my laptop an=
d
> >>> compared to MKL and in certain cases it's 10x faster at matrix
> multiply.
> >>> There are a lot of layers of indirection here and you really want to
> avoid
> >>> data copying as much as possible.
> >>>
> >>> We could also consider swapping out BIDMat for Breeze, but that would
> be
> >>> a big project and if we can figure out how to get breeze+cublas to
> >>> comparable performance that would be a big win.
> >>>
> >>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>> Dear Spark developers,
> >>>
> >>> I am exploring how to make linear algebra operations faster within
> Spark.
> >>> One way of doing this is to use Scala Breeze library that is bundled
> with
> >>> Spark. For matrix operations, it employs Netlib-java that has a Java
> >>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> >>> binaries if they are available on the worker node. It also has its ow=
n
> >>> optimized Java implementation of BLAS. It is worth mentioning, that
> native
> >>> binaries provide better performance only for BLAS level 3, i.e.
> >>> matrix-matrix operations or general matrix multiplication (GEMM). Thi=
s
> is
> >>> confirmed by GEMM test on Netlib-java page
> >>> https://github.com/fommil/netlib-java. I also confirmed it with my
> >>> experiments with training of artificial neural network
> >>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
> >>> However, I would like to boost performance more.
> >>>
> >>> GPU is supposed to work fast with linear algebra and there is Nvidia
> CUDA
> >>> implementation of BLAS, called cublas. I have one Linux server with
> Nvidia
> >>> GPU and I was able to do the following. I linked cublas (instead of
> >>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> >>> Breeze/Netlib is using it. Then I did some performance measurements
> with
> >>> regards to artificial neural network batch learning in Spark MLlib th=
at
> >>> involves matrix-matrix multiplications. It turns out that for matrice=
s
> of
> >>> size less than ~1000x780 GPU cublas has the same speed as CPU blas.
> Cublas
> >>> becomes slower for bigger matrices. It worth mentioning that it is wa=
s
> not
> >>> a test for ONLY multiplication since there are other operations
> involved.
> >>> One of the reasons for slowdown might be the overhead of copying the
> >>> matrices from computer memory to graphic card memory and back.
> >>>
> >>> So, few questions:
> >>> 1) Do these results with CUDA make sense?
> >>> 2) If the problem is with copy overhead, are there any libraries that
> >>> allow to force intermediate results to stay in graphic card memory th=
us
> >>> removing the overhead?
> >>> 3) Any other options to speed-up linear algebra in Spark?
> >>>
> >>> Thank you, Alexander
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> >>> dev-unsubscribe@spark.apache.org><mailto:
> dev-unsubscribe@spark.apache.org
> >>> <mailto:dev-unsubscribe@spark.apache.org>>
> >>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> >>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
> >>> dev-help@spark.apache.org>>
> >>>
> >>>
> >>>
> >>>
> >>
>

--047d7bdca5b6eed7eb051004b966--

From dev-return-11796-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 21:56:50 2015
Return-Path: <dev-return-11796-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A26810D11
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 21:56:50 +0000 (UTC)
Received: (qmail 99244 invoked by uid 500); 26 Feb 2015 21:56:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99172 invoked by uid 500); 26 Feb 2015 21:56:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99160 invoked by uid 99); 26 Feb 2015 21:56:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:56:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sam.halliday@gmail.com designates 209.85.223.170 as permitted sender)
Received: from [209.85.223.170] (HELO mail-ie0-f170.google.com) (209.85.223.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 21:56:22 +0000
Received: by iecrl12 with SMTP id rl12so21843622iec.4
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 13:55:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=yDQ7qmsz9k+jJvjlZQjpL4Sgj3PcGQfPAEsLPPx/oQg=;
        b=mhm0/K5T3N9LyHohdX/cLqTIg/AbJyOkjZzAHf6nK0gWnQfDusO6sIielnUAEtQsle
         I8Fgy/lFrHmXsecWjI1m6R/FryxjrvAW77OvWRicNKV4GU/rSHfihkkxCwXYj4+JnmL/
         bX/KZpbP+bVMo00lcaoH1tBSJN292566jTYoNdjSMW7JnfJcjNiT8IreTizX/jK7e5bo
         sqpRJw8iEj8HjvGJrTn/g8d80JoKEnCWUsPySwYwWDz0u2iBR25owKtqFE8LYYD3XkR9
         71CnBI2YRrgQDSE1YlSgRqibfqAR/Jxb7S5sTAvvFCIV2KlRF6ujFa+7bZokCrMi43ad
         NIxw==
MIME-Version: 1.0
X-Received: by 10.50.124.73 with SMTP id mg9mr232175igb.38.1424987735002; Thu,
 26 Feb 2015 13:55:35 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 13:55:34 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 13:55:34 -0800 (PST)
In-Reply-To: <CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
Date: Thu, 26 Feb 2015 21:55:34 +0000
Message-ID: <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Sam Halliday <sam.halliday@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev@spark.apache.org, Joseph Bradley <joseph@databricks.com>, 
	"Ulanov, Alexander" <alexander.ulanov@hp.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: multipart/alternative; boundary=089e010d9532c1172a051004cf7d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d9532c1172a051004cf7d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Btw, I wish people would stop cheating when comparing CPU and GPU timings
for things like matrix multiply :-P

Please always compare apples with apples and include the time it takes to
set up the matrices, send it to the processing unit, doing the calculation
AND copying it back to where you need to see the results.

Ignoring this method will make you believe that your GPU is thousands of
times faster than it really is. Again, jump to the end of my talk for
graphs and more discussion....  especially the bit about me being keen on
funding to investigate APU hardware further ;-) (I believe it will solve
the problem)
On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com> wrote:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com>
> wrote:
> > Better documentation for linking would be very helpful!  Here's a JIRA:
> > https://issues.apache.org/jira/browse/SPARK-6019
> >
> >
> > On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com>
> > wrote:
> >
> >> Thanks for compiling all the data and running these benchmarks, Alex.
> The
> >> big takeaways here can be seen with this chart:
> >>
> >>
> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6km=
AJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
> >>
> >> 1) A properly configured GPU matrix multiply implementation (e.g.
> >> BIDMat+GPU) can provide substantial (but less than an order of
> magnitude)
> >> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> >> netlib-java+openblas-compiled).
> >> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
> worse
> >> than a well-tuned CPU implementation, particularly for larger matrices=
.
> >> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
> >> basically agrees with the authors own benchmarks (
> >> https://github.com/fommil/netlib-java)
> >>
> >> I think that most of our users are in a situation where using GPUs may
> not
> >> be practical - although we could consider having a good GPU backend
> >> available as an option. However, *ALL* users of MLlib could benefit
> >> (potentially tremendously) from using a well-tuned CPU-based BLAS
> >> implementation. Perhaps we should consider updating the mllib guide
> with a
> >> more complete section for enabling high performance binaries on OSX an=
d
> >> Linux? Or better, figure out a way for the system to fetch these
> >> automatically.
> >>
> >> - Evan
> >>
> >>
> >>
> >> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
> >> alexander.ulanov@hp.com> wrote:
> >>
> >>> Just to summarize this thread, I was finally able to make all
> performance
> >>> comparisons that we discussed. It turns out that:
> >>> BIDMat-cublas>>BIDMat
> >>>
> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-rep=
o=3D=3Dnetlib-cublas>netlib-blas>f2jblas
> >>>
> >>> Below is the link to the spreadsheet with full results.
> >>>
> >>>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J=
5r7kwKSPkY/edit?usp=3Dsharing
> >>>
> >>> One thing still needs exploration: does BIDMat-cublas perform copying
> >>> to/from machine=E2=80=99s RAM?
> >>>
> >>> -----Original Message-----
> >>> From: Ulanov, Alexander
> >>> Sent: Tuesday, February 10, 2015 2:12 PM
> >>> To: Evan R. Sparks
> >>> Cc: Joseph Bradley; dev@spark.apache.org
> >>> Subject: RE: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Thanks, Evan! It seems that ticket was marked as duplicate though the
> >>> original one discusses slightly different topic. I was able to link
> netlib
> >>> with MKL from BIDMat binaries. Indeed, MKL is statically linked insid=
e
> a
> >>> 60MB library.
> >>>
> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> >>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> >>>
> +-----------------------------------------------------------------------+
> >>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
> >>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
> >>> |1,638475459 |
> >>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
> >>> 1569,233228 |
> >>>
> >>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas
> on
> >>> my machine. Probably, I=E2=80=99ll add two more columns with locally =
compiled
> >>> openblas and cuda.
> >>>
> >>> Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
> >>> Sent: Monday, February 09, 2015 6:06 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Great - perhaps we can move this discussion off-list and onto a JIRA
> >>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705=
)
> >>>
> >>> It seems like this is going to be somewhat exploratory for a while (a=
nd
> >>> there's probably only a handful of us who really care about fast line=
ar
> >>> algebra!)
> >>>
> >>> - Evan
> >>>
> >>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Hi Evan,
> >>>
> >>> Thank you for explanation and useful link. I am going to build
> OpenBLAS,
> >>> link it with Netlib-java and perform benchmark again.
> >>>
> >>> Do I understand correctly that BIDMat binaries contain statically
> linked
> >>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat no=
t
> >>> having MKL BLAS installed on my server. If it is true, I wonder if it
> is OK
> >>> because Intel sells this library. Nevertheless, it seems that in my
> case
> >>> precompiled MKL BLAS performs better than precompiled OpenBLAS given
> that
> >>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
> >>>
> >>> Though, it might be interesting to link Netlib-java with Intel MKL, a=
s
> >>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
> >>> (Netlib-java) interested to compare their libraries.
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Friday, February 06, 2015 5:58 PM
> >>>
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I would build OpenBLAS yourself, since good BLAS performance comes fr=
om
> >>> getting cache sizes, etc. set up correctly for your particular
> hardware -
> >>> this is often a very tricky process (see, e.g. ATLAS), but we found
> that on
> >>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> >>> performance competitive with MKL.
> >>>
> >>> To make sure the right library is getting used, you have to make sure
> >>> it's first on the search path - export
> >>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
> >>>
> >>> For some examples of getting netlib-java setup on an ec2 node and som=
e
> >>> example benchmarking code we ran a while back, see:
> >>> https://github.com/shivaram/matrix-bench
> >>>
> >>> In particular - build-openblas-ec2.sh shows you how to build the
> library
> >>> and set up symlinks correctly, and scala/run-netlib.sh shows you how
> to get
> >>> the path setup and get that library picked up by netlib-java.
> >>>
> >>> In this way - you could probably get cuBLAS set up to be used by
> >>> netlib-java as well.
> >>>
> >>> - Evan
> >>>
> >>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Evan, could you elaborate on how to force BIDMat and netlib-java to
> force
> >>> loading the right blas? For netlib, I there are few JVM flags, such a=
s
> >>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, s=
o I
> can
> >>> force it to use Java implementation. Not sure I understand how to
> force use
> >>> a specific blas (not specific wrapper for blas).
> >>>
> >>> Btw. I have installed openblas (yum install openblas), so I suppose
> that
> >>> netlib is using it.
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Friday, February 06, 2015 5:19 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Getting breeze to pick up the right blas library is critical for
> >>> performance. I recommend using OpenBLAS (or MKL, if you already have
> it).
> >>> It might make sense to force BIDMat to use the same underlying BLAS
> library
> >>> as well.
> >>>
> >>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Hi Evan, Joseph
> >>>
> >>> I did few matrix multiplication test and BIDMat seems to be ~10x fast=
er
> >>> than netlib-java+breeze (sorry for weird table formatting):
> >>>
> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
> native_system_linux_x86-64|
> >>> Breeze+Netlib-java f2jblas |
> >>>
> +-----------------------------------------------------------------------+
> >>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> >>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> >>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
> >>>
> >>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 1=
9
> >>> Linux, Scala 2.11.
> >>>
> >>> Later I will make tests with Cuda. I need to install new Cuda version
> for
> >>> this purpose.
> >>>
> >>> Do you have any ideas why breeze-netlib with native blas is so much
> >>> slower than BIDMat MKL?
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
> >>> joseph@databricks.com>]
> >>> Sent: Thursday, February 05, 2015 5:29 PM
> >>> To: Ulanov, Alexander
> >>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> Hi Alexander,
> >>>
> >>> Using GPUs with Spark would be very exciting.  Small comment:
> Concerning
> >>> your question earlier about keeping data stored on the GPU rather tha=
n
> >>> having to move it between main memory and GPU memory on each
> iteration, I
> >>> would guess this would be critical to getting good performance.  If y=
ou
> >>> could do multiple local iterations before aggregating results, then t=
he
> >>> cost of data movement to the GPU could be amortized (and I believe
> that is
> >>> done in practice).  Having Spark be aware of the GPU and using it as
> >>> another part of memory sounds like a much bigger undertaking.
> >>>
> >>> Joseph
> >>>
> >>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentat=
ion by
> John
> >>> Canny and I am really inspired by his talk and comparisons with Spark
> MLlib.
> >>>
> >>> I am very interested to find out what will be better within Spark:
> BIDMat
> >>> or netlib-java with CPU or GPU natives. Could you suggest a fair way =
to
> >>> benchmark them? Currently I do benchmarks on artificial neural
> networks in
> >>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear a=
lgebra, it
> involves
> >>> some other things that are essential to machine learning.
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>]
> >>> Sent: Thursday, February 05, 2015 1:29 PM
> >>> To: Ulanov, Alexander
> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> >>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
> data
> >>> layout and fewer levels of indirection - it's definitely a worthwhile
> >>> experiment to run. The main speedups I've seen from using it come fro=
m
> >>> highly optimized GPU code for linear algebra. I know that in the past
> Canny
> >>> has gone as far as to write custom GPU kernels for performance-critic=
al
> >>> regions of code.[1]
> >>>
> >>> BIDMach is highly optimized for single node performance or performanc=
e
> on
> >>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can
> be
> >>> batched in that way) the performance tends to fall off. Canny argues
> for
> >>> hardware/software codesign and as such prefers machine configurations
> that
> >>> are quite different than what we find in most commodity cluster nodes=
 -
> >>> e.g. 10 disk cahnnels and 4 GPUs.
> >>>
> >>> In contrast, MLlib was designed for horizontal scalability on commodi=
ty
> >>> clusters and works best on very big datasets - order of terabytes.
> >>>
> >>> For the most part, these projects developed concurrently to address
> >>> slightly different use cases. That said, there may be bits of BIDMach
> we
> >>> could repurpose for MLlib - keep in mind we need to be careful about
> >>> maintaining cross-language compatibility for our Java and Python-user=
s,
> >>> though.
> >>>
> >>> - Evan
> >>>
> >>> [1] - http://arxiv.org/abs/1409.5402
> >>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
> >>>
> >>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>> Hi Evan,
> >>>
> >>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
> >>> know what makes them faster than netlib-java?
> >>>
> >>> The same group has BIDMach library that implements machine learning.
> For
> >>> some examples they use Caffe convolutional neural network library
> owned by
> >>> another group in Berkeley. Could you elaborate on how these all might
> be
> >>> connected with Spark Mllib? If you take BIDMat for linear algebra why
> don=E2=80=99t
> >>> you take BIDMach for optimization and learning?
> >>>
> >>> Best regards, Alexander
> >>>
> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
> >>> evan.sparks@gmail.com>>]
> >>> Sent: Thursday, February 05, 2015 12:09 PM
> >>> To: Ulanov, Alexander
> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> >>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>
> >>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas
> in
> >>> many cases.
> >>>
> >>> You might consider taking a look at the codepaths that BIDMat (
> >>> https://github.com/BIDData/BIDMat) takes and comparing them to
> >>> netlib-java/breeze. John Canny et. al. have done a bunch of work
> optimizing
> >>> to make this work really fast from Scala. I've run it on my laptop an=
d
> >>> compared to MKL and in certain cases it's 10x faster at matrix
> multiply.
> >>> There are a lot of layers of indirection here and you really want to
> avoid
> >>> data copying as much as possible.
> >>>
> >>> We could also consider swapping out BIDMat for Breeze, but that would
> be
> >>> a big project and if we can figure out how to get breeze+cublas to
> >>> comparable performance that would be a big win.
> >>>
> >>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>> Dear Spark developers,
> >>>
> >>> I am exploring how to make linear algebra operations faster within
> Spark.
> >>> One way of doing this is to use Scala Breeze library that is bundled
> with
> >>> Spark. For matrix operations, it employs Netlib-java that has a Java
> >>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
> >>> binaries if they are available on the worker node. It also has its ow=
n
> >>> optimized Java implementation of BLAS. It is worth mentioning, that
> native
> >>> binaries provide better performance only for BLAS level 3, i.e.
> >>> matrix-matrix operations or general matrix multiplication (GEMM). Thi=
s
> is
> >>> confirmed by GEMM test on Netlib-java page
> >>> https://github.com/fommil/netlib-java. I also confirmed it with my
> >>> experiments with training of artificial neural network
> >>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
> >>> However, I would like to boost performance more.
> >>>
> >>> GPU is supposed to work fast with linear algebra and there is Nvidia
> CUDA
> >>> implementation of BLAS, called cublas. I have one Linux server with
> Nvidia
> >>> GPU and I was able to do the following. I linked cublas (instead of
> >>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> >>> Breeze/Netlib is using it. Then I did some performance measurements
> with
> >>> regards to artificial neural network batch learning in Spark MLlib th=
at
> >>> involves matrix-matrix multiplications. It turns out that for matrice=
s
> of
> >>> size less than ~1000x780 GPU cublas has the same speed as CPU blas.
> Cublas
> >>> becomes slower for bigger matrices. It worth mentioning that it is wa=
s
> not
> >>> a test for ONLY multiplication since there are other operations
> involved.
> >>> One of the reasons for slowdown might be the overhead of copying the
> >>> matrices from computer memory to graphic card memory and back.
> >>>
> >>> So, few questions:
> >>> 1) Do these results with CUDA make sense?
> >>> 2) If the problem is with copy overhead, are there any libraries that
> >>> allow to force intermediate results to stay in graphic card memory th=
us
> >>> removing the overhead?
> >>> 3) Any other options to speed-up linear algebra in Spark?
> >>>
> >>> Thank you, Alexander
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> >>> dev-unsubscribe@spark.apache.org><mailto:
> dev-unsubscribe@spark.apache.org
> >>> <mailto:dev-unsubscribe@spark.apache.org>>
> >>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> >>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
> >>> dev-help@spark.apache.org>>
> >>>
> >>>
> >>>
> >>>
> >>
>

--089e010d9532c1172a051004cf7d--

From dev-return-11797-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 22:03:05 2015
Return-Path: <dev-return-11797-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2664B10D83
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 22:03:05 +0000 (UTC)
Received: (qmail 28427 invoked by uid 500); 26 Feb 2015 22:02:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28356 invoked by uid 500); 26 Feb 2015 22:02:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28343 invoked by uid 99); 26 Feb 2015 22:02:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:02:56 +0000
X-ASF-Spam-Status: No, hits=-0.1 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:02:24 +0000
Received: from G4W6310.americas.hpqcorp.net (g4w6310.houston.hp.com [16.210.26.217])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id E338E24A;
	Thu, 26 Feb 2015 22:02:20 +0000 (UTC)
Received: from G4W6302.americas.hpqcorp.net (16.210.26.227) by
 G4W6310.americas.hpqcorp.net (16.210.26.217) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Thu, 26 Feb 2015 22:01:10 +0000
Received: from G9W0737.americas.hpqcorp.net ([169.254.9.160]) by
 G4W6302.americas.hpqcorp.net ([16.210.26.227]) with mapi id 14.03.0169.001;
 Thu, 26 Feb 2015 22:01:10 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: Sam Halliday <sam.halliday@gmail.com>, Xiangrui Meng <mengxr@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, Joseph Bradley
	<joseph@databricks.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0AAAKwxgACUAsfwAAMhugAAKb0RoABpRQ1wAorxuwAAAXuuAAAtZPiAAAFf0QAAAAlNIA==
Date: Thu, 26 Feb 2015 22:01:09 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
 <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
In-Reply-To: <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: multipart/alternative;
	boundary="_000_9D5B00849D2CDA4386BDA89E83F69E6C0FE0314CG9W0737americas_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FE0314CG9W0737americas_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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--_000_9D5B00849D2CDA4386BDA89E83F69E6C0FE0314CG9W0737americas_--

From dev-return-11798-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 22:07:04 2015
Return-Path: <dev-return-11798-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEEF910DC6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 22:07:04 +0000 (UTC)
Received: (qmail 45004 invoked by uid 500); 26 Feb 2015 22:07:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44925 invoked by uid 500); 26 Feb 2015 22:07:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44913 invoked by uid 99); 26 Feb 2015 22:07:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:07:03 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [15.201.208.53] (HELO g4t3425.houston.hp.com) (15.201.208.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:06:59 +0000
Received: from G4W6310.americas.hpqcorp.net (g4w6310.houston.hp.com [16.210.26.217])
	(using TLSv1 with cipher AES128-SHA (128/128 bits))
	(No client certificate requested)
	by g4t3425.houston.hp.com (Postfix) with ESMTPS id E74C72E0;
	Thu, 26 Feb 2015 22:05:37 +0000 (UTC)
Received: from G4W6304.americas.hpqcorp.net (16.210.26.229) by
 G4W6310.americas.hpqcorp.net (16.210.26.217) with Microsoft SMTP Server (TLS)
 id 14.3.169.1; Thu, 26 Feb 2015 22:04:30 +0000
Received: from G9W0737.americas.hpqcorp.net ([169.254.9.160]) by
 G4W6304.americas.hpqcorp.net ([16.210.26.229]) with mapi id 14.03.0169.001;
 Thu, 26 Feb 2015 22:04:30 +0000
From: "Ulanov, Alexander" <alexander.ulanov@hp.com>
To: Sam Halliday <sam.halliday@gmail.com>, Xiangrui Meng <mengxr@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>, Joseph Bradley
	<joseph@databricks.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Subject: RE: Using CUDA within Spark / boosting linear algebra
Thread-Topic: Using CUDA within Spark / boosting linear algebra
Thread-Index: AdBBfWhuKPqoaEklS3C36BE9QomgGQAAhtEAAAGfVLAAASz4gAAHItZAAAFGYoAAMDL08AABuXqAAAC0q0AAAKwxgACUAsfwAAMhugAAKb0RoABpRQ1wAorxuwAAAXuuAAAtZPiAAAFf0QAAAAlNIAAAPxuA
Date: Thu, 26 Feb 2015 22:04:29 +0000
Message-ID: <9D5B00849D2CDA4386BDA89E83F69E6C0FE03178@G9W0737.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
 <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [16.210.48.17]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org
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DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-11799-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 22:09:10 2015
Return-Path: <dev-return-11799-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2BFEC10E07
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 22:09:10 +0000 (UTC)
Received: (qmail 53354 invoked by uid 500); 26 Feb 2015 22:08:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53269 invoked by uid 500); 26 Feb 2015 22:08:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53257 invoked by uid 99); 26 Feb 2015 22:08:56 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:08:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of evan.sparks@gmail.com designates 209.85.220.178 as permitted sender)
Received: from [209.85.220.178] (HELO mail-vc0-f178.google.com) (209.85.220.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:08:52 +0000
Received: by mail-vc0-f178.google.com with SMTP id hq11so5019908vcb.9
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 14:07:01 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=B6aSbk2dXx8aIEyz9kUO2unC6bPmqVyinwaNbTdq4e0=;
        b=Z8zCOvcDcUoaGaCMcVjMJyk7K3oOdCAxwZrue34RGZvmNzNlAu1cGxLueDIAUqd624
         OG/QHNBP7ueQmTkkOLye6CO5QU4apGTZ3UJdQI6LM8OsaMzud5RZvvUpmVZptUL9fpen
         kBsD2FJJKQhrW7H3lS4jloHYub4nSO0fa2I/U414cZXa81HvcCKAEa2cZJnMAf4P45ym
         uKr6polQoKz/LDSAurFwzxl5jCO25WrZMPguJ41RoqlcUCUqpO7SgSDbKL60E8665T2+
         sC2i5cT5kYGg3B80dfKXo0mYtJtjvC40yXj/MR3kRsblGOHVvmK6JWPGsuOXsn0eQuBX
         erng==
X-Received: by 10.52.53.102 with SMTP id a6mr10671166vdp.50.1424988421340;
 Thu, 26 Feb 2015 14:07:01 -0800 (PST)
MIME-Version: 1.0
Received: by 10.52.243.107 with HTTP; Thu, 26 Feb 2015 14:06:41 -0800 (PST)
In-Reply-To: <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
 <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
 <CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
 <CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
 <CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com> <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
From: "Evan R. Sparks" <evan.sparks@gmail.com>
Date: Thu, 26 Feb 2015 14:06:41 -0800
Message-ID: <CABjXkq65qJ0c+8+ue6qCf8OHG7sCwj9=H_rZx8ndGeXD7qMr9w@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
To: Sam Halliday <sam.halliday@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Joseph Bradley <joseph@databricks.com>, "Ulanov, Alexander" <alexander.ulanov@hp.com>
Content-Type: multipart/alternative; boundary=089e01184ac4a9c642051004f89b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01184ac4a9c642051004f89b
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I couldn't agree with you more, Sam. The GPU/Matrix guys typically don't
count their copy times, but claim that you should be doing *as much as
possible* on the GPU - so, maybe for some applications where you can
generate the data on the GPU this makes sense. But, in the context of Spark
we should be *very* careful about enumerating the applications we want GPU
support for and deciding whether it's appropriate to measure the overheads
of getting the data to the GPU.

On Thu, Feb 26, 2015 at 1:55 PM, Sam Halliday <sam.halliday@gmail.com>
wrote:

> Btw, I wish people would stop cheating when comparing CPU and GPU timings
> for things like matrix multiply :-P
>
> Please always compare apples with apples and include the time it takes to
> set up the matrices, send it to the processing unit, doing the calculatio=
n
> AND copying it back to where you need to see the results.
>
> Ignoring this method will make you believe that your GPU is thousands of
> times faster than it really is. Again, jump to the end of my talk for
> graphs and more discussion....  especially the bit about me being keen on
> funding to investigate APU hardware further ;-) (I believe it will solve
> the problem)
> On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com> wrote:
>
>> Hey Alexander,
>>
>> I don't quite understand the part where netlib-cublas is about 20x
>> slower than netlib-openblas. What is the overhead of using a GPU BLAS
>> with netlib-java?
>>
>> CC'ed Sam, the author of netlib-java.
>>
>> Best,
>> Xiangrui
>>
>> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com>
>> wrote:
>> > Better documentation for linking would be very helpful!  Here's a JIRA=
:
>> > https://issues.apache.org/jira/browse/SPARK-6019
>> >
>> >
>> > On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com=
>
>> > wrote:
>> >
>> >> Thanks for compiling all the data and running these benchmarks, Alex.
>> The
>> >> big takeaways here can be seen with this chart:
>> >>
>> >>
>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6k=
mAJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>> >>
>> >> 1) A properly configured GPU matrix multiply implementation (e.g.
>> >> BIDMat+GPU) can provide substantial (but less than an order of
>> magnitude)
>> >> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>> >> netlib-java+openblas-compiled).
>> >> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
>> worse
>> >> than a well-tuned CPU implementation, particularly for larger matrice=
s.
>> >> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>> >> basically agrees with the authors own benchmarks (
>> >> https://github.com/fommil/netlib-java)
>> >>
>> >> I think that most of our users are in a situation where using GPUs ma=
y
>> not
>> >> be practical - although we could consider having a good GPU backend
>> >> available as an option. However, *ALL* users of MLlib could benefit
>> >> (potentially tremendously) from using a well-tuned CPU-based BLAS
>> >> implementation. Perhaps we should consider updating the mllib guide
>> with a
>> >> more complete section for enabling high performance binaries on OSX a=
nd
>> >> Linux? Or better, figure out a way for the system to fetch these
>> >> automatically.
>> >>
>> >> - Evan
>> >>
>> >>
>> >>
>> >> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>> >> alexander.ulanov@hp.com> wrote:
>> >>
>> >>> Just to summarize this thread, I was finally able to make all
>> performance
>> >>> comparisons that we discussed. It turns out that:
>> >>> BIDMat-cublas>>BIDMat
>> >>>
>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-re=
po=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>> >>>
>> >>> Below is the link to the spreadsheet with full results.
>> >>>
>> >>>
>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9=
J5r7kwKSPkY/edit?usp=3Dsharing
>> >>>
>> >>> One thing still needs exploration: does BIDMat-cublas perform copyin=
g
>> >>> to/from machine=E2=80=99s RAM?
>> >>>
>> >>> -----Original Message-----
>> >>> From: Ulanov, Alexander
>> >>> Sent: Tuesday, February 10, 2015 2:12 PM
>> >>> To: Evan R. Sparks
>> >>> Cc: Joseph Bradley; dev@spark.apache.org
>> >>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> Thanks, Evan! It seems that ticket was marked as duplicate though th=
e
>> >>> original one discusses slightly different topic. I was able to link
>> netlib
>> >>> with MKL from BIDMat binaries. Indeed, MKL is statically linked
>> inside a
>> >>> 60MB library.
>> >>>
>> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>> >>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>> >>>
>> +-----------------------------------------------------------------------=
+
>> >>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>> >>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>> >>> |1,638475459 |
>> >>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>> >>> 1569,233228 |
>> >>>
>> >>> It turn out that pre-compiled MKL is faster than precompiled OpenBla=
s
>> on
>> >>> my machine. Probably, I=E2=80=99ll add two more columns with locally=
 compiled
>> >>> openblas and cuda.
>> >>>
>> >>> Alexander
>> >>>
>> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
>> >>> Sent: Monday, February 09, 2015 6:06 PM
>> >>> To: Ulanov, Alexander
>> >>> Cc: Joseph Bradley; dev@spark.apache.org
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> Great - perhaps we can move this discussion off-list and onto a JIRA
>> >>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-570=
5
>> )
>> >>>
>> >>> It seems like this is going to be somewhat exploratory for a while
>> (and
>> >>> there's probably only a handful of us who really care about fast
>> linear
>> >>> algebra!)
>> >>>
>> >>> - Evan
>> >>>
>> >>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>> Hi Evan,
>> >>>
>> >>> Thank you for explanation and useful link. I am going to build
>> OpenBLAS,
>> >>> link it with Netlib-java and perform benchmark again.
>> >>>
>> >>> Do I understand correctly that BIDMat binaries contain statically
>> linked
>> >>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat n=
ot
>> >>> having MKL BLAS installed on my server. If it is true, I wonder if i=
t
>> is OK
>> >>> because Intel sells this library. Nevertheless, it seems that in my
>> case
>> >>> precompiled MKL BLAS performs better than precompiled OpenBLAS given
>> that
>> >>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>> >>>
>> >>> Though, it might be interesting to link Netlib-java with Intel MKL, =
as
>> >>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>> >>> (Netlib-java) interested to compare their libraries.
>> >>>
>> >>> Best regards, Alexander
>> >>>
>> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> >>> evan.sparks@gmail.com>]
>> >>> Sent: Friday, February 06, 2015 5:58 PM
>> >>>
>> >>> To: Ulanov, Alexander
>> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org=
>
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> I would build OpenBLAS yourself, since good BLAS performance comes
>> from
>> >>> getting cache sizes, etc. set up correctly for your particular
>> hardware -
>> >>> this is often a very tricky process (see, e.g. ATLAS), but we found
>> that on
>> >>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>> >>> performance competitive with MKL.
>> >>>
>> >>> To make sure the right library is getting used, you have to make sur=
e
>> >>> it's first on the search path - export
>> >>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>> >>>
>> >>> For some examples of getting netlib-java setup on an ec2 node and so=
me
>> >>> example benchmarking code we ran a while back, see:
>> >>> https://github.com/shivaram/matrix-bench
>> >>>
>> >>> In particular - build-openblas-ec2.sh shows you how to build the
>> library
>> >>> and set up symlinks correctly, and scala/run-netlib.sh shows you how
>> to get
>> >>> the path setup and get that library picked up by netlib-java.
>> >>>
>> >>> In this way - you could probably get cuBLAS set up to be used by
>> >>> netlib-java as well.
>> >>>
>> >>> - Evan
>> >>>
>> >>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>> Evan, could you elaborate on how to force BIDMat and netlib-java to
>> force
>> >>> loading the right blas? For netlib, I there are few JVM flags, such =
as
>> >>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, =
so
>> I can
>> >>> force it to use Java implementation. Not sure I understand how to
>> force use
>> >>> a specific blas (not specific wrapper for blas).
>> >>>
>> >>> Btw. I have installed openblas (yum install openblas), so I suppose
>> that
>> >>> netlib is using it.
>> >>>
>> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> >>> evan.sparks@gmail.com>]
>> >>> Sent: Friday, February 06, 2015 5:19 PM
>> >>> To: Ulanov, Alexander
>> >>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org=
>
>> >>>
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> Getting breeze to pick up the right blas library is critical for
>> >>> performance. I recommend using OpenBLAS (or MKL, if you already have
>> it).
>> >>> It might make sense to force BIDMat to use the same underlying BLAS
>> library
>> >>> as well.
>> >>>
>> >>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>> Hi Evan, Joseph
>> >>>
>> >>> I did few matrix multiplication test and BIDMat seems to be ~10x
>> faster
>> >>> than netlib-java+breeze (sorry for weird table formatting):
>> >>>
>> >>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>> native_system_linux_x86-64|
>> >>> Breeze+Netlib-java f2jblas |
>> >>>
>> +-----------------------------------------------------------------------=
+
>> >>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>> >>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>> >>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>> >>>
>> >>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora =
19
>> >>> Linux, Scala 2.11.
>> >>>
>> >>> Later I will make tests with Cuda. I need to install new Cuda versio=
n
>> for
>> >>> this purpose.
>> >>>
>> >>> Do you have any ideas why breeze-netlib with native blas is so much
>> >>> slower than BIDMat MKL?
>> >>>
>> >>> Best regards, Alexander
>> >>>
>> >>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
>> >>> joseph@databricks.com>]
>> >>> Sent: Thursday, February 05, 2015 5:29 PM
>> >>> To: Ulanov, Alexander
>> >>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org=
>
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> Hi Alexander,
>> >>>
>> >>> Using GPUs with Spark would be very exciting.  Small comment:
>> Concerning
>> >>> your question earlier about keeping data stored on the GPU rather th=
an
>> >>> having to move it between main memory and GPU memory on each
>> iteration, I
>> >>> would guess this would be critical to getting good performance.  If
>> you
>> >>> could do multiple local iterations before aggregating results, then
>> the
>> >>> cost of data movement to the GPU could be amortized (and I believe
>> that is
>> >>> done in practice).  Having Spark be aware of the GPU and using it as
>> >>> another part of memory sounds like a much bigger undertaking.
>> >>>
>> >>> Joseph
>> >>>
>> >>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presenta=
tion by
>> John
>> >>> Canny and I am really inspired by his talk and comparisons with Spar=
k
>> MLlib.
>> >>>
>> >>> I am very interested to find out what will be better within Spark:
>> BIDMat
>> >>> or netlib-java with CPU or GPU natives. Could you suggest a fair way
>> to
>> >>> benchmark them? Currently I do benchmarks on artificial neural
>> networks in
>> >>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear =
algebra, it
>> involves
>> >>> some other things that are essential to machine learning.
>> >>>
>> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> >>> evan.sparks@gmail.com>]
>> >>> Sent: Thursday, February 05, 2015 1:29 PM
>> >>> To: Ulanov, Alexander
>> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>> >>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
>> data
>> >>> layout and fewer levels of indirection - it's definitely a worthwhil=
e
>> >>> experiment to run. The main speedups I've seen from using it come fr=
om
>> >>> highly optimized GPU code for linear algebra. I know that in the pas=
t
>> Canny
>> >>> has gone as far as to write custom GPU kernels for
>> performance-critical
>> >>> regions of code.[1]
>> >>>
>> >>> BIDMach is highly optimized for single node performance or
>> performance on
>> >>> small clusters.[2] Once data doesn't fit easily in GPU memory (or ca=
n
>> be
>> >>> batched in that way) the performance tends to fall off. Canny argues
>> for
>> >>> hardware/software codesign and as such prefers machine configuration=
s
>> that
>> >>> are quite different than what we find in most commodity cluster node=
s
>> -
>> >>> e.g. 10 disk cahnnels and 4 GPUs.
>> >>>
>> >>> In contrast, MLlib was designed for horizontal scalability on
>> commodity
>> >>> clusters and works best on very big datasets - order of terabytes.
>> >>>
>> >>> For the most part, these projects developed concurrently to address
>> >>> slightly different use cases. That said, there may be bits of BIDMac=
h
>> we
>> >>> could repurpose for MLlib - keep in mind we need to be careful about
>> >>> maintaining cross-language compatibility for our Java and
>> Python-users,
>> >>> though.
>> >>>
>> >>> - Evan
>> >>>
>> >>> [1] - http://arxiv.org/abs/1409.5402
>> >>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>> >>>
>> >>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>> Hi Evan,
>> >>>
>> >>> Thank you for suggestion! BIDMat seems to have terrific speed. Do yo=
u
>> >>> know what makes them faster than netlib-java?
>> >>>
>> >>> The same group has BIDMach library that implements machine learning.
>> For
>> >>> some examples they use Caffe convolutional neural network library
>> owned by
>> >>> another group in Berkeley. Could you elaborate on how these all migh=
t
>> be
>> >>> connected with Spark Mllib? If you take BIDMat for linear algebra wh=
y
>> don=E2=80=99t
>> >>> you take BIDMach for optimization and learning?
>> >>>
>> >>> Best regards, Alexander
>> >>>
>> >>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> >>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
>> >>> evan.sparks@gmail.com>>]
>> >>> Sent: Thursday, February 05, 2015 12:09 PM
>> >>> To: Ulanov, Alexander
>> >>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
>> >>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> >>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>
>> >>> I'd expect that we can make GPU-accelerated BLAS faster than CPU bla=
s
>> in
>> >>> many cases.
>> >>>
>> >>> You might consider taking a look at the codepaths that BIDMat (
>> >>> https://github.com/BIDData/BIDMat) takes and comparing them to
>> >>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>> optimizing
>> >>> to make this work really fast from Scala. I've run it on my laptop a=
nd
>> >>> compared to MKL and in certain cases it's 10x faster at matrix
>> multiply.
>> >>> There are a lot of layers of indirection here and you really want to
>> avoid
>> >>> data copying as much as possible.
>> >>>
>> >>> We could also consider swapping out BIDMat for Breeze, but that woul=
d
>> be
>> >>> a big project and if we can figure out how to get breeze+cublas to
>> >>> comparable performance that would be a big win.
>> >>>
>> >>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>> Dear Spark developers,
>> >>>
>> >>> I am exploring how to make linear algebra operations faster within
>> Spark.
>> >>> One way of doing this is to use Scala Breeze library that is bundled
>> with
>> >>> Spark. For matrix operations, it employs Netlib-java that has a Java
>> >>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK nativ=
e
>> >>> binaries if they are available on the worker node. It also has its o=
wn
>> >>> optimized Java implementation of BLAS. It is worth mentioning, that
>> native
>> >>> binaries provide better performance only for BLAS level 3, i.e.
>> >>> matrix-matrix operations or general matrix multiplication (GEMM).
>> This is
>> >>> confirmed by GEMM test on Netlib-java page
>> >>> https://github.com/fommil/netlib-java. I also confirmed it with my
>> >>> experiments with training of artificial neural network
>> >>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>> >>> However, I would like to boost performance more.
>> >>>
>> >>> GPU is supposed to work fast with linear algebra and there is Nvidia
>> CUDA
>> >>> implementation of BLAS, called cublas. I have one Linux server with
>> Nvidia
>> >>> GPU and I was able to do the following. I linked cublas (instead of
>> >>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>> >>> Breeze/Netlib is using it. Then I did some performance measurements
>> with
>> >>> regards to artificial neural network batch learning in Spark MLlib
>> that
>> >>> involves matrix-matrix multiplications. It turns out that for
>> matrices of
>> >>> size less than ~1000x780 GPU cublas has the same speed as CPU blas.
>> Cublas
>> >>> becomes slower for bigger matrices. It worth mentioning that it is
>> was not
>> >>> a test for ONLY multiplication since there are other operations
>> involved.
>> >>> One of the reasons for slowdown might be the overhead of copying the
>> >>> matrices from computer memory to graphic card memory and back.
>> >>>
>> >>> So, few questions:
>> >>> 1) Do these results with CUDA make sense?
>> >>> 2) If the problem is with copy overhead, are there any libraries tha=
t
>> >>> allow to force intermediate results to stay in graphic card memory
>> thus
>> >>> removing the overhead?
>> >>> 3) Any other options to speed-up linear algebra in Spark?
>> >>>
>> >>> Thank you, Alexander
>> >>>
>> >>> --------------------------------------------------------------------=
-
>> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
>> >>> dev-unsubscribe@spark.apache.org><mailto:
>> dev-unsubscribe@spark.apache.org
>> >>> <mailto:dev-unsubscribe@spark.apache.org>>
>> >>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
>> >>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
>> >>> dev-help@spark.apache.org>>
>> >>>
>> >>>
>> >>>
>> >>>
>> >>
>>
>

--089e01184ac4a9c642051004f89b--

From dev-return-11800-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Feb 26 22:22:04 2015
Return-Path: <dev-return-11800-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 20F6210E98
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 26 Feb 2015 22:22:04 +0000 (UTC)
Received: (qmail 84219 invoked by uid 500); 26 Feb 2015 22:22:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84140 invoked by uid 500); 26 Feb 2015 22:22:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84128 invoked by uid 99); 26 Feb 2015 22:22:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:22:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sam.halliday@gmail.com designates 74.125.82.43 as permitted sender)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 26 Feb 2015 22:21:37 +0000
Received: by wggz12 with SMTP id z12so15404848wgg.2
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 14:21:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:to:cc:subject:in-reply-to:references:user-agent:date
         :message-id:mime-version:content-type;
        bh=Kgg5UeENroS0b2PMU4ikfStMyZsiN3x3WyNe3mkL0fU=;
        b=StdUNtjch2YcvGlcZEEKLfpKsBpEXbw8zEvobriHLW+25ovoK3QBhgXsGExQLSUh5F
         9UaU0LJMk4zgnCC7HmyhXuUpx61fWLBM7mIfg2Wox1U8g/EgO+KF3dY0v0cLMo/aFfIJ
         JNCZdB0WUIiWRHwDv5Dje8OyfMLfQu9d9zKjzA1vI2v90o6EcfO4TG/Q/y1qTVNUElHK
         q8yrTd1ZlJtxUrfh8ebClYkmNrmVrMddAC1BMht5nQgDimA9GXyp4JfpF8X5lk8hhGgW
         Z0ZYI3/nFFDb0QDB6/lZtFGfkSbt7A3nJ4j9cx0ZWSL1XEmq1ADR2xFpii7M9m6CHjiU
         WyIA==
X-Received: by 10.180.79.1 with SMTP id f1mr514273wix.24.1424989296077;
        Thu, 26 Feb 2015 14:21:36 -0800 (PST)
Received: from Sampo (host86-176-86-184.range86-176.btcentralplus.com. [86.176.86.184])
        by mx.google.com with ESMTPSA id ev7sm3235122wjb.47.2015.02.26.14.21.33
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 26 Feb 2015 14:21:34 -0800 (PST)
From: Sam Halliday <sam.halliday@gmail.com>
To: "Ulanov\, Alexander" <alexander.ulanov@hp.com>, Xiangrui Meng <mengxr@gmail.com>
Cc: "dev\@spark.apache.org" <dev@spark.apache.org>, Joseph Bradley <joseph@databricks.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Subject: RE: Using CUDA within Spark / boosting linear algebra
In-Reply-To: <9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
 <CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
 <CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
 <CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
 <CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
 <CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
 <9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
 <CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
 <CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
 <CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
 <CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com> <9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
User-Agent: Notmuch/0.18.2 (http://notmuchmail.org) Emacs/24.4.1 (x86_64-pc-linux-gnu)
Date: Thu, 26 Feb 2015 22:21:29 +0000
Message-ID: <87ioeo5n6e.fsf@gmail.com>
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="=-=-="
X-Virus-Checked: Checked by ClamAV on apache.org

--=-=-=
Content-Type: text/plain

I've had some email exchanges with the author of BIDMat: it does exactly
what you need to get the GPU benefit and writes higher level algorithms
entirely in the GPU kernels so that the memory stays there as long as
possible. The restriction with this approach is that it is only offering
high-level algorithms so is not a toolkit for applied mathematics
research and development --- but it works well as a toolkit for higher
level analysis (e.g. for analysts and practitioners).

I believe BIDMat's approach is the best way to get performance out of
GPU hardware at the moment but I also have strong evidence to suggest
that the hardware will catch up and the memory transfer costs between
CPU/GPU will disappear meaning that there will be no need for custom GPU
kernel implementations. i.e. please continue to use BLAS primitives when
writing new algorithms and only go to the GPU for an alternative
optimised implementation.

Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, and offer
an API that looks like BLAS but takes pointers to special regions in the
GPU memory region. Somebody has written a wrapper around CUDA to create
a proper BLAS library but it only gives marginal performance over the
CPU because of the memory transfer overhead.

This slide from my talk

  http://fommil.github.io/scalax14/#/11/2

says it all. X axis is matrix size, Y axis is logarithmic time to do
DGEMM. Black line is the "cheating" time for the GPU and the green line
is after copying the memory to/from the GPU memory. APUs have the
potential to eliminate the green line.

Best regards,
Sam



--=-=-=
Content-Type: multipart/signed; boundary="==-=-=";
	micalg=pgp-sha1; protocol="application/pgp-signature"

--==-=-=
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

"Ulanov, Alexander" <alexander.ulanov@hp.com> writes:

> Evan, thank you for the summary. I would like to add some more observatio=
ns. The GPU that I used is 2.5 times cheaper than the CPU ($250 vs $100). T=
hey both are 3 years old. I've also did a small test with modern hardware, =
and the new GPU nVidia Titan was slightly more than 1 order of magnitude fa=
ster than Intel E5-2650 v2 for the same tests. However, it costs as much as=
 CPU ($1200). My takeaway is that GPU is making a better price/value progre=
ss.
>
>
>
> Xiangrui, I was also surprised that BIDMat-cuda was faster than netlib-cu=
da and the most reasonable explanation is that it holds the result in GPU m=
emory, as Sam suggested. At the same time, it is OK because you can copy th=
e result back from GPU only when needed. However, to be sure, I am going to=
 ask the developer of BIDMat on his upcoming talk.
>
>
>
> Best regards, Alexander
>
>
> From: Sam Halliday [mailto:sam.halliday@gmail.com]
> Sent: Thursday, February 26, 2015 1:56 PM
> To: Xiangrui Meng
> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R. Spar=
ks
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
>
> Btw, I wish people would stop cheating when comparing CPU and GPU timings=
 for things like matrix multiply :-P
>
> Please always compare apples with apples and include the time it takes to=
 set up the matrices, send it to the processing unit, doing the calculation=
 AND copying it back to where you need to see the results.
>
> Ignoring this method will make you believe that your GPU is thousands of =
times faster than it really is. Again, jump to the end of my talk for graph=
s and more discussion....  especially the bit about me being keen on fundin=
g to investigate APU hardware further ;-) (I believe it will solve the prob=
lem)
> On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com<mailto:mengxr@gma=
il.com>> wrote:
> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<ma=
ilto:joseph@databricks.com>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com<m=
ailto:evan.sparks@gmail.com>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks, Alex. T=
he
>>> big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6=
kmAJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of magnitud=
e)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude wor=
se
>>> than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs may =
not
>>> be practical - although we could consider having a good GPU backend
>>> available as an option. However, *ALL* users of MLlib could benefit
>>> (potentially tremendously) from using a well-tuned CPU-based BLAS
>>> implementation. Perhaps we should consider updating the mllib guide wit=
h a
>>> more complete section for enabling high performance binaries on OSX and
>>> Linux? Or better, figure out a way for the system to fetch these
>>> automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all performa=
nce
>>>> comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-=
repo=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378=
T9J5r7kwKSPkY/edit?usp=3Dsharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform copying
>>>> to/from machine=E2=80=99s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though the
>>>> original one discusses slightly different topic. I was able to link ne=
tlib
>>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked inside=
 a
>>>> 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +---------------------------------------------------------------------=
--+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas =
on
>>>> my machine. Probably, I=E2=80=99ll add two more columns with locally c=
ompiled
>>>> openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@=
gmail.com>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a JIRA
>>>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while (and
>>>> there's probably only a handful of us who really care about fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build OpenBLA=
S,
>>>> link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically link=
ed
>>>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat not
>>>> having MKL BLAS installed on my server. If it is true, I wonder if it =
is OK
>>>> because Intel sells this library. Nevertheless, it seems that in my ca=
se
>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS given t=
hat
>>>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL, as
>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@=
gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org><=
mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes from
>>>> getting cache sizes, etc. set up correctly for your particular hardwar=
e -
>>>> this is often a very tricky process (see, e.g. ATLAS), but we found th=
at on
>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>>>> performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make sure
>>>> it's first on the search path - export
>>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and some
>>>> example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the libra=
ry
>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you how t=
o get
>>>> the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to fo=
rce
>>>> loading the right blas? For netlib, I there are few JVM flags, such as
>>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, so=
 I can
>>>> force it to use Java implementation. Not sure I understand how to forc=
e use
>>>> a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose th=
at
>>>> netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@=
gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org><=
mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have i=
t).
>>>> It might make sense to force BIDMat to use the same underlying BLAS li=
brary
>>>> as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x faster
>>>> than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-6=
4|
>>>> Breeze+Netlib-java f2jblas |
>>>> +---------------------------------------------------------------------=
--+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 19
>>>> Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda version =
for
>>>> this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@datab=
ricks.com><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org><=
mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment: Concerni=
ng
>>>> your question earlier about keeping data stored on the GPU rather than
>>>> having to move it between main memory and GPU memory on each iteration=
, I
>>>> would guess this would be critical to getting good performance.  If you
>>>> could do multiple local iterations before aggregating results, then the
>>>> cost of data movement to the GPU could be amortized (and I believe tha=
t is
>>>> done in practice).  Having Spark be aware of the GPU and using it as
>>>> another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentati=
on by John
>>>> Canny and I am really inspired by his talk and comparisons with Spark =
MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark: BID=
Mat
>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair way to
>>>> benchmark them? Currently I do benchmarks on artificial neural network=
s in
>>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear al=
gebra, it involves
>>>> some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@=
gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to da=
ta
>>>> layout and fewer levels of indirection - it's definitely a worthwhile
>>>> experiment to run. The main speedups I've seen from using it come from
>>>> highly optimized GPU code for linear algebra. I know that in the past =
Canny
>>>> has gone as far as to write custom GPU kernels for performance-critical
>>>> regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or performance=
 on
>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can =
be
>>>> batched in that way) the performance tends to fall off. Canny argues f=
or
>>>> hardware/software codesign and as such prefers machine configurations =
that
>>>> are quite different than what we find in most commodity cluster nodes -
>>>> e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on commodity
>>>> clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address
>>>> slightly different use cases. That said, there may be bits of BIDMach =
we
>>>> could repurpose for MLlib - keep in mind we need to be careful about
>>>> maintaining cross-language compatibility for our Java and Python-users,
>>>> though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402
>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
>>>> know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine learning. F=
or
>>>> some examples they use Caffe convolutional neural network library owne=
d by
>>>> another group in Berkeley. Could you elaborate on how these all might =
be
>>>> connected with Spark Mllib? If you take BIDMat for linear algebra why =
don=E2=80=99t
>>>> you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@=
gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.spark=
s@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apa=
che.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas =
in
>>>> many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work optim=
izing
>>>> to make this work really fast from Scala. I've run it on my laptop and
>>>> compared to MKL and in certain cases it's 10x faster at matrix multipl=
y.
>>>> There are a lot of layers of indirection here and you really want to a=
void
>>>> data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that would =
be
>>>> a big project and if we can figure out how to get breeze+cublas to
>>>> comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexand=
er.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spa=
rk.
>>>> One way of doing this is to use Scala Breeze library that is bundled w=
ith
>>>> Spark. For matrix operations, it employs Netlib-java that has a Java
>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
>>>> binaries if they are available on the worker node. It also has its own
>>>> optimized Java implementation of BLAS. It is worth mentioning, that na=
tive
>>>> binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM). This=
 is
>>>> confirmed by GEMM test on Netlib-java page
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>>> experiments with training of artificial neural network
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is Nvidia C=
UDA
>>>> implementation of BLAS, called cublas. I have one Linux server with Nv=
idia
>>>> GPU and I was able to do the following. I linked cublas (instead of
>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>>>> Breeze/Netlib is using it. Then I did some performance measurements wi=
th
>>>> regards to artificial neural network batch learning in Spark MLlib that
>>>> involves matrix-matrix multiplications. It turns out that for matrices=
 of
>>>> size less than ~1000x780 GPU cublas has the same speed as CPU blas. Cu=
blas
>>>> becomes slower for bigger matrices. It worth mentioning that it is was=
 not
>>>> a test for ONLY multiplication since there are other operations involv=
ed.
>>>> One of the reasons for slowdown might be the overhead of copying the
>>>> matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries that
>>>> allow to force intermediate results to stay in graphic card memory thus
>>>> removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-un=
subscribe@spark.apache.org><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.o=
rg>><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.a=
pache.org>
>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.=
apache.org>>>
>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev-=
help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:de=
v-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>
>>>>
>>>>
>>>>
>>>

=2D-=20
Best regards,
Sam

--==-=-=
Content-Type: application/pgp-signature; name="signature.asc"

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iEYEARECAAYFAlTvnGoACgkQh5Q4qVL9G8mQWACfQmsyAsNNhUZFSOfzYs5Ea/sI
YeUAnRQudAG5Ip/UO85Zkcf57wwPSN3Y
=9iAl
-----END PGP SIGNATURE-----
--==-=-=--


--=-=-=
Content-Type: text/plain; charset=us-ascii


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
--=-=-=--

From dev-return-11801-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 01:42:33 2015
Return-Path: <dev-return-11801-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B31251783B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 01:42:33 +0000 (UTC)
Received: (qmail 33602 invoked by uid 500); 27 Feb 2015 01:42:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33521 invoked by uid 500); 27 Feb 2015 01:42:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33509 invoked by uid 99); 27 Feb 2015 01:42:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 01:42:32 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.223.170 as permitted sender)
Received: from [209.85.223.170] (HELO mail-ie0-f170.google.com) (209.85.223.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 01:42:07 +0000
Received: by iecar1 with SMTP id ar1so24204914iec.0
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 17:42:05 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=Vx/WoK8RRtPKU4t9/Rke+tHmRn+GaFEHyqzSVJbNMYE=;
        b=vfs8zfOq0xkuP0jsK23kNGeBWotszc+UhltItww5UHKZ1DOTF0/VIqTbSd7zcCVKZ1
         c1WT+0Gjs7/T0zcOfa5Z6ClTORjXN6TZDZsimWzo7Fh/+JbD63oBq0TDKlYitxDWPU0W
         YyQ8ym/u2NRA4WMIugQGZnXIFgbHwz2MkSw1foq029Jt+7kJHn8KhTGTo8gEo8f0HIra
         +rK2qcPuKgj2o23zgQ9N6+FOfhGY1t4vWg9fN8+wQZpXgX4BBkVEtXpJWYMavjyq0L5U
         /V12zqmIkRBaadNFQi08v4LyXiui+hUdd6YFAei+VrhRiGjcuN0FjzjUDqszzm/PrBbw
         EeJQ==
MIME-Version: 1.0
X-Received: by 10.107.9.26 with SMTP id j26mr15255940ioi.91.1425001325493;
 Thu, 26 Feb 2015 17:42:05 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Thu, 26 Feb 2015 17:42:05 -0800 (PST)
In-Reply-To: <87ioeo5n6e.fsf@gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
	<CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
	<87ioeo5n6e.fsf@gmail.com>
Date: Thu, 26 Feb 2015 17:42:05 -0800
Message-ID: <CAJgQjQ9q2wEu-URc6OkNf+rVriX+FDcViSBM-die2HyCpRC=-A@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Xiangrui Meng <mengxr@gmail.com>
To: Sam Halliday <sam.halliday@gmail.com>
Cc: "Ulanov, Alexander" <alexander.ulanov@hp.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Joseph Bradley <joseph@databricks.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

The copying overhead should be quadratic on n, while the computation
cost is cubic on n. I can understand that netlib-cublas is slower than
netlib-openblas on small problems. But I'm surprised to see that it is
still 20x slower on 10000x10000. I did the following on a g2.2xlarge
instance with BIDMat:

val n =3D 10000

val f =3D rand(n, n)
flip; f*f; val rf =3D flop

flip; val g =3D GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val rg =3D f=
lop

flip; g*g; val rgg =3D flop

The CPU version finished in 12 seconds.
The CPU->GPU->CPU version finished in 2.2 seconds.
The GPU version finished in 1.7 seconds.

I'm not sure whether my CPU->GPU->CPU code simulates the netlib-cublas
path. But based on the result, the data copying overhead is definitely
not as big as 20x at n =3D 10000.

Best,
Xiangrui


On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday <sam.halliday@gmail.com> wrot=
e:
> I've had some email exchanges with the author of BIDMat: it does exactly
> what you need to get the GPU benefit and writes higher level algorithms
> entirely in the GPU kernels so that the memory stays there as long as
> possible. The restriction with this approach is that it is only offering
> high-level algorithms so is not a toolkit for applied mathematics
> research and development --- but it works well as a toolkit for higher
> level analysis (e.g. for analysts and practitioners).
>
> I believe BIDMat's approach is the best way to get performance out of
> GPU hardware at the moment but I also have strong evidence to suggest
> that the hardware will catch up and the memory transfer costs between
> CPU/GPU will disappear meaning that there will be no need for custom GPU
> kernel implementations. i.e. please continue to use BLAS primitives when
> writing new algorithms and only go to the GPU for an alternative
> optimised implementation.
>
> Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, and offer
> an API that looks like BLAS but takes pointers to special regions in the
> GPU memory region. Somebody has written a wrapper around CUDA to create
> a proper BLAS library but it only gives marginal performance over the
> CPU because of the memory transfer overhead.
>
> This slide from my talk
>
>   http://fommil.github.io/scalax14/#/11/2
>
> says it all. X axis is matrix size, Y axis is logarithmic time to do
> DGEMM. Black line is the "cheating" time for the GPU and the green line
> is after copying the memory to/from the GPU memory. APUs have the
> potential to eliminate the green line.
>
> Best regards,
> Sam
>
>
>
> "Ulanov, Alexander" <alexander.ulanov@hp.com> writes:
>
>> Evan, thank you for the summary. I would like to add some more observati=
ons. The GPU that I used is 2.5 times cheaper than the CPU ($250 vs $100). =
They both are 3 years old. I've also did a small test with modern hardware,=
 and the new GPU nVidia Titan was slightly more than 1 order of magnitude f=
aster than Intel E5-2650 v2 for the same tests. However, it costs as much a=
s CPU ($1200). My takeaway is that GPU is making a better price/value progr=
ess.
>>
>>
>>
>> Xiangrui, I was also surprised that BIDMat-cuda was faster than netlib-c=
uda and the most reasonable explanation is that it holds the result in GPU =
memory, as Sam suggested. At the same time, it is OK because you can copy t=
he result back from GPU only when needed. However, to be sure, I am going t=
o ask the developer of BIDMat on his upcoming talk.
>>
>>
>>
>> Best regards, Alexander
>>
>>
>> From: Sam Halliday [mailto:sam.halliday@gmail.com]
>> Sent: Thursday, February 26, 2015 1:56 PM
>> To: Xiangrui Meng
>> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R. Spa=
rks
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>>
>> Btw, I wish people would stop cheating when comparing CPU and GPU timing=
s for things like matrix multiply :-P
>>
>> Please always compare apples with apples and include the time it takes t=
o set up the matrices, send it to the processing unit, doing the calculatio=
n AND copying it back to where you need to see the results.
>>
>> Ignoring this method will make you believe that your GPU is thousands of=
 times faster than it really is. Again, jump to the end of my talk for grap=
hs and more discussion....  especially the bit about me being keen on fundi=
ng to investigate APU hardware further ;-) (I believe it will solve the pro=
blem)
>> On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com<mailto:mengxr@gm=
ail.com>> wrote:
>> Hey Alexander,
>>
>> I don't quite understand the part where netlib-cublas is about 20x
>> slower than netlib-openblas. What is the overhead of using a GPU BLAS
>> with netlib-java?
>>
>> CC'ed Sam, the author of netlib-java.
>>
>> Best,
>> Xiangrui
>>
>> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<m=
ailto:joseph@databricks.com>> wrote:
>>> Better documentation for linking would be very helpful!  Here's a JIRA:
>>> https://issues.apache.org/jira/browse/SPARK-6019
>>>
>>>
>>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.com<=
mailto:evan.sparks@gmail.com>>
>>> wrote:
>>>
>>>> Thanks for compiling all the data and running these benchmarks, Alex. =
The
>>>> big takeaways here can be seen with this chart:
>>>>
>>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl=
6kmAJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>>>>
>>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>>> BIDMat+GPU) can provide substantial (but less than an order of magnitu=
de)
>>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>>> netlib-java+openblas-compiled).
>>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude wo=
rse
>>>> than a well-tuned CPU implementation, particularly for larger matrices=
.
>>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>>>> basically agrees with the authors own benchmarks (
>>>> https://github.com/fommil/netlib-java)
>>>>
>>>> I think that most of our users are in a situation where using GPUs may=
 not
>>>> be practical - although we could consider having a good GPU backend
>>>> available as an option. However, *ALL* users of MLlib could benefit
>>>> (potentially tremendously) from using a well-tuned CPU-based BLAS
>>>> implementation. Perhaps we should consider updating the mllib guide wi=
th a
>>>> more complete section for enabling high performance binaries on OSX an=
d
>>>> Linux? Or better, figure out a way for the system to fetch these
>>>> automatically.
>>>>
>>>> - Evan
>>>>
>>>>
>>>>
>>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>>
>>>>> Just to summarize this thread, I was finally able to make all perform=
ance
>>>>> comparisons that we discussed. It turns out that:
>>>>> BIDMat-cublas>>BIDMat
>>>>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum=
-repo=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>>>>>
>>>>> Below is the link to the spreadsheet with full results.
>>>>>
>>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx37=
8T9J5r7kwKSPkY/edit?usp=3Dsharing
>>>>>
>>>>> One thing still needs exploration: does BIDMat-cublas perform copying
>>>>> to/from machine=E2=80=99s RAM?
>>>>>
>>>>> -----Original Message-----
>>>>> From: Ulanov, Alexander
>>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>>> To: Evan R. Sparks
>>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> Thanks, Evan! It seems that ticket was marked as duplicate though the
>>>>> original one discusses slightly different topic. I was able to link n=
etlib
>>>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked insid=
e a
>>>>> 60MB library.
>>>>>
>>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>>> +--------------------------------------------------------------------=
---+
>>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>>> |1,638475459 |
>>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>>> 1569,233228 |
>>>>>
>>>>> It turn out that pre-compiled MKL is faster than precompiled OpenBlas=
 on
>>>>> my machine. Probably, I=E2=80=99ll add two more columns with locally =
compiled
>>>>> openblas and cuda.
>>>>>
>>>>> Alexander
>>>>>
>>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks=
@gmail.com>]
>>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>>> To: Ulanov, Alexander
>>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> Great - perhaps we can move this discussion off-list and onto a JIRA
>>>>> ticket? (Here's one: https://issues.apache.org/jira/browse/SPARK-5705=
)
>>>>>
>>>>> It seems like this is going to be somewhat exploratory for a while (a=
nd
>>>>> there's probably only a handful of us who really care about fast line=
ar
>>>>> algebra!)
>>>>>
>>>>> - Evan
>>>>>
>>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>>> Hi Evan,
>>>>>
>>>>> Thank you for explanation and useful link. I am going to build OpenBL=
AS,
>>>>> link it with Netlib-java and perform benchmark again.
>>>>>
>>>>> Do I understand correctly that BIDMat binaries contain statically lin=
ked
>>>>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat no=
t
>>>>> having MKL BLAS installed on my server. If it is true, I wonder if it=
 is OK
>>>>> because Intel sells this library. Nevertheless, it seems that in my c=
ase
>>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS given =
that
>>>>> BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>>
>>>>> Though, it might be interesting to link Netlib-java with Intel MKL, a=
s
>>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>>>>> (Netlib-java) interested to compare their libraries.
>>>>>
>>>>> Best regards, Alexander
>>>>>
>>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks=
@gmail.com><mailto:
>>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>>
>>>>> To: Ulanov, Alexander
>>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>=
<mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> I would build OpenBLAS yourself, since good BLAS performance comes fr=
om
>>>>> getting cache sizes, etc. set up correctly for your particular hardwa=
re -
>>>>> this is often a very tricky process (see, e.g. ATLAS), but we found t=
hat on
>>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>>>>> performance competitive with MKL.
>>>>>
>>>>> To make sure the right library is getting used, you have to make sure
>>>>> it's first on the search path - export
>>>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>>>>>
>>>>> For some examples of getting netlib-java setup on an ec2 node and som=
e
>>>>> example benchmarking code we ran a while back, see:
>>>>> https://github.com/shivaram/matrix-bench
>>>>>
>>>>> In particular - build-openblas-ec2.sh shows you how to build the libr=
ary
>>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you how =
to get
>>>>> the path setup and get that library picked up by netlib-java.
>>>>>
>>>>> In this way - you could probably get cuBLAS set up to be used by
>>>>> netlib-java as well.
>>>>>
>>>>> - Evan
>>>>>
>>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to f=
orce
>>>>> loading the right blas? For netlib, I there are few JVM flags, such a=
s
>>>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS, s=
o I can
>>>>> force it to use Java implementation. Not sure I understand how to for=
ce use
>>>>> a specific blas (not specific wrapper for blas).
>>>>>
>>>>> Btw. I have installed openblas (yum install openblas), so I suppose t=
hat
>>>>> netlib is using it.
>>>>>
>>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks=
@gmail.com><mailto:
>>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>>> To: Ulanov, Alexander
>>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>=
<mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> Getting breeze to pick up the right blas library is critical for
>>>>> performance. I recommend using OpenBLAS (or MKL, if you already have =
it).
>>>>> It might make sense to force BIDMat to use the same underlying BLAS l=
ibrary
>>>>> as well.
>>>>>
>>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>>> Hi Evan, Joseph
>>>>>
>>>>> I did few matrix multiplication test and BIDMat seems to be ~10x fast=
er
>>>>> than netlib-java+breeze (sorry for weird table formatting):
>>>>>
>>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java native_system_linux_x86-=
64|
>>>>> Breeze+Netlib-java f2jblas |
>>>>> +--------------------------------------------------------------------=
---+
>>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 |
>>>>>
>>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 1=
9
>>>>> Linux, Scala 2.11.
>>>>>
>>>>> Later I will make tests with Cuda. I need to install new Cuda version=
 for
>>>>> this purpose.
>>>>>
>>>>> Do you have any ideas why breeze-netlib with native blas is so much
>>>>> slower than BIDMat MKL?
>>>>>
>>>>> Best regards, Alexander
>>>>>
>>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@data=
bricks.com><mailto:
>>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>>> To: Ulanov, Alexander
>>>>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.org>=
<mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> Hi Alexander,
>>>>>
>>>>> Using GPUs with Spark would be very exciting.  Small comment: Concern=
ing
>>>>> your question earlier about keeping data stored on the GPU rather tha=
n
>>>>> having to move it between main memory and GPU memory on each iteratio=
n, I
>>>>> would guess this would be critical to getting good performance.  If y=
ou
>>>>> could do multiple local iterations before aggregating results, then t=
he
>>>>> cost of data movement to the GPU could be amortized (and I believe th=
at is
>>>>> done in practice).  Having Spark be aware of the GPU and using it as
>>>>> another part of memory sounds like a much bigger undertaking.
>>>>>
>>>>> Joseph
>>>>>
>>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presentat=
ion by John
>>>>> Canny and I am really inspired by his talk and comparisons with Spark=
 MLlib.
>>>>>
>>>>> I am very interested to find out what will be better within Spark: BI=
DMat
>>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair way =
to
>>>>> benchmark them? Currently I do benchmarks on artificial neural networ=
ks in
>>>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear a=
lgebra, it involves
>>>>> some other things that are essential to machine learning.
>>>>>
>>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks=
@gmail.com><mailto:
>>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>>> To: Ulanov, Alexander
>>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spar=
k.apache.org<mailto:dev@spark.apache.org>>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to d=
ata
>>>>> layout and fewer levels of indirection - it's definitely a worthwhile
>>>>> experiment to run. The main speedups I've seen from using it come fro=
m
>>>>> highly optimized GPU code for linear algebra. I know that in the past=
 Canny
>>>>> has gone as far as to write custom GPU kernels for performance-critic=
al
>>>>> regions of code.[1]
>>>>>
>>>>> BIDMach is highly optimized for single node performance or performanc=
e on
>>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or can=
 be
>>>>> batched in that way) the performance tends to fall off. Canny argues =
for
>>>>> hardware/software codesign and as such prefers machine configurations=
 that
>>>>> are quite different than what we find in most commodity cluster nodes=
 -
>>>>> e.g. 10 disk cahnnels and 4 GPUs.
>>>>>
>>>>> In contrast, MLlib was designed for horizontal scalability on commodi=
ty
>>>>> clusters and works best on very big datasets - order of terabytes.
>>>>>
>>>>> For the most part, these projects developed concurrently to address
>>>>> slightly different use cases. That said, there may be bits of BIDMach=
 we
>>>>> could repurpose for MLlib - keep in mind we need to be careful about
>>>>> maintaining cross-language compatibility for our Java and Python-user=
s,
>>>>> though.
>>>>>
>>>>> - Evan
>>>>>
>>>>> [1] - http://arxiv.org/abs/1409.5402
>>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>>
>>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>>> Hi Evan,
>>>>>
>>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do you
>>>>> know what makes them faster than netlib-java?
>>>>>
>>>>> The same group has BIDMach library that implements machine learning. =
For
>>>>> some examples they use Caffe convolutional neural network library own=
ed by
>>>>> another group in Berkeley. Could you elaborate on how these all might=
 be
>>>>> connected with Spark Mllib? If you take BIDMat for linear algebra why=
 don=E2=80=99t
>>>>> you take BIDMach for optimization and learning?
>>>>>
>>>>> Best regards, Alexander
>>>>>
>>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks=
@gmail.com><mailto:
>>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.spar=
ks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>>> To: Ulanov, Alexander
>>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spar=
k.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.ap=
ache.org<mailto:dev@spark.apache.org>>>
>>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>>
>>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU blas=
 in
>>>>> many cases.
>>>>>
>>>>> You might consider taking a look at the codepaths that BIDMat (
>>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work opti=
mizing
>>>>> to make this work really fast from Scala. I've run it on my laptop an=
d
>>>>> compared to MKL and in certain cases it's 10x faster at matrix multip=
ly.
>>>>> There are a lot of layers of indirection here and you really want to =
avoid
>>>>> data copying as much as possible.
>>>>>
>>>>> We could also consider swapping out BIDMat for Breeze, but that would=
 be
>>>>> a big project and if we can figure out how to get breeze+cublas to
>>>>> comparable performance that would be a big win.
>>>>>
>>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexan=
der.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>>> Dear Spark developers,
>>>>>
>>>>> I am exploring how to make linear algebra operations faster within Sp=
ark.
>>>>> One way of doing this is to use Scala Breeze library that is bundled =
with
>>>>> Spark. For matrix operations, it employs Netlib-java that has a Java
>>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK native
>>>>> binaries if they are available on the worker node. It also has its ow=
n
>>>>> optimized Java implementation of BLAS. It is worth mentioning, that n=
ative
>>>>> binaries provide better performance only for BLAS level 3, i.e.
>>>>> matrix-matrix operations or general matrix multiplication (GEMM). Thi=
s is
>>>>> confirmed by GEMM test on Netlib-java page
>>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>>>> experiments with training of artificial neural network
>>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>>> However, I would like to boost performance more.
>>>>>
>>>>> GPU is supposed to work fast with linear algebra and there is Nvidia =
CUDA
>>>>> implementation of BLAS, called cublas. I have one Linux server with N=
vidia
>>>>> GPU and I was able to do the following. I linked cublas (instead of
>>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>>>>> Breeze/Netlib is using it. Then I did some performance measurements w=
ith
>>>>> regards to artificial neural network batch learning in Spark MLlib th=
at
>>>>> involves matrix-matrix multiplications. It turns out that for matrice=
s of
>>>>> size less than ~1000x780 GPU cublas has the same speed as CPU blas. C=
ublas
>>>>> becomes slower for bigger matrices. It worth mentioning that it is wa=
s not
>>>>> a test for ONLY multiplication since there are other operations invol=
ved.
>>>>> One of the reasons for slowdown might be the overhead of copying the
>>>>> matrices from computer memory to graphic card memory and back.
>>>>>
>>>>> So, few questions:
>>>>> 1) Do these results with CUDA make sense?
>>>>> 2) If the problem is with copy overhead, are there any libraries that
>>>>> allow to force intermediate results to stay in graphic card memory th=
us
>>>>> removing the overhead?
>>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>>
>>>>> Thank you, Alexander
>>>>>
>>>>> ---------------------------------------------------------------------
>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-u=
nsubscribe@spark.apache.org><mailto:
>>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.=
org>><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.=
apache.org>
>>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark=
.apache.org>>>
>>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev=
-help@spark.apache.org><mailto:
>>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:d=
ev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>
> --
> Best regards,
> Sam
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11802-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 02:11:27 2015
Return-Path: <dev-return-11802-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE921178F0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 02:11:27 +0000 (UTC)
Received: (qmail 99918 invoked by uid 500); 27 Feb 2015 02:11:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99791 invoked by uid 500); 27 Feb 2015 02:11:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99134 invoked by uid 99); 27 Feb 2015 02:11:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 02:11:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nobigdealstyle@gmail.com designates 209.85.213.48 as permitted sender)
Received: from [209.85.213.48] (HELO mail-yh0-f48.google.com) (209.85.213.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 02:11:20 +0000
Received: by yhaf73 with SMTP id f73so6623013yha.11;
        Thu, 26 Feb 2015 18:11:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=8D4IQFYr7QoI+JHQM5/9jPZGOOUqZPH2oeIsFOJVBCI=;
        b=JFxEsLbT9aGRmJBC8XblzNaZP9UU1pbH3IJRnonjYeXX2UdyndxX1wy/Qo2B+1TRO5
         XPEkmPcLVp+Eun2BsRqxDI6mQ5aie67oA6ULDaUagWLs3vvClm68pkPi65Wtlgb6DIi8
         eQHiimfaFqP0+tVL8XWUeN/ThwQ7Z9T8SfRVBsHDrNZ52Ats/iU6zO1ioQUqZILim3YE
         0jt+WBaUCadv4qJLheazkkncL+v1TXe1QbefMVE0juXbRrEugtTVYYuL60wnpsbl+rKP
         miV1Avx+oLXITVefnxcMiXhmUK8Ai+iJ6LZqlAmkC4F7YAaTIGsnlM0I34zf8d5ugxzt
         CyeQ==
X-Received: by 10.170.72.70 with SMTP id o67mr11175538yko.3.1425003060245;
 Thu, 26 Feb 2015 18:11:00 -0800 (PST)
MIME-Version: 1.0
From: Ryan Williams <ryan.blake.williams@gmail.com>
Date: Fri, 27 Feb 2015 02:10:58 +0000
Message-ID: <CANeJXFP2JZ97qFx=gh7UXmXoS5ODTH8deF2XhT1nwd2_tD16EA@mail.gmail.com>
Subject: Monitoring Spark with Graphite and Grafana
To: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a973e35bd480510086133
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a973e35bd480510086133
Content-Type: text/plain; charset=UTF-8

If anyone is curious to try exporting Spark metrics to Graphite, I just
published a post about my experience doing that, building dashboards in
Grafana <http://grafana.org/>, and using them to monitor Spark jobs:
http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/

Code for generating Grafana dashboards tailored to the metrics emitted by
Spark is here: https://github.com/hammerlab/grafana-spark-dashboards.

If anyone else is interested in working on expanding MetricsSystem to make
this sort of thing more useful, let me know, I've been working on it a fair
amount and have a bunch of ideas about where it should go.

Thanks,

-Ryan

--001a113a973e35bd480510086133--

From dev-return-11803-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 02:27:09 2015
Return-Path: <dev-return-11803-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D70C71795A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 02:27:09 +0000 (UTC)
Received: (qmail 18626 invoked by uid 500); 27 Feb 2015 02:27:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18497 invoked by uid 500); 27 Feb 2015 02:27:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17907 invoked by uid 99); 27 Feb 2015 02:27:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 02:27:04 +0000
X-ASF-Spam-Status: No, hits=-2.8 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of saisai.shao@intel.com designates 134.134.136.20 as permitted sender)
Received: from [134.134.136.20] (HELO mga02.intel.com) (134.134.136.20)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 02:27:01 +0000
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
  by orsmga101.jf.intel.com with ESMTP; 26 Feb 2015 18:25:39 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.09,656,1418112000"; 
   d="scan'208,217";a="672427710"
Received: from pgsmsx101.gar.corp.intel.com ([10.221.44.78])
  by fmsmga001.fm.intel.com with ESMTP; 26 Feb 2015 18:25:38 -0800
Received: from shsmsx152.ccr.corp.intel.com (10.239.6.52) by
 PGSMSX101.gar.corp.intel.com (10.221.44.78) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Fri, 27 Feb 2015 10:25:37 +0800
Received: from shsmsx104.ccr.corp.intel.com ([169.254.5.161]) by
 SHSMSX152.ccr.corp.intel.com ([169.254.6.46]) with mapi id 14.03.0195.001;
 Fri, 27 Feb 2015 10:25:35 +0800
From: "Shao, Saisai" <saisai.shao@intel.com>
To: Ryan Williams <ryan.blake.williams@gmail.com>, user
	<user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Subject: RE: Monitoring Spark with Graphite and Grafana
Thread-Topic: Monitoring Spark with Graphite and Grafana
Thread-Index: AQHQUjKxuhAXwZqP9k28rchU3+amM50DxLLA
Date: Fri, 27 Feb 2015 02:25:35 +0000
Message-ID: <64474308D680D540A4D8151B0F7C03F70279E9EF@SHSMSX104.ccr.corp.intel.com>
References: <CANeJXFP2JZ97qFx=gh7UXmXoS5ODTH8deF2XhT1nwd2_tD16EA@mail.gmail.com>
In-Reply-To: <CANeJXFP2JZ97qFx=gh7UXmXoS5ODTH8deF2XhT1nwd2_tD16EA@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: multipart/alternative;
	boundary="_000_64474308D680D540A4D8151B0F7C03F70279E9EFSHSMSX104ccrcor_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_64474308D680D540A4D8151B0F7C03F70279E9EFSHSMSX104ccrcor_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64

Q29vbCwgZ3JlYXQgam9i4pi6Lg0KDQpUaGFua3MNCkplcnJ5DQoNCkZyb206IFJ5YW4gV2lsbGlh
bXMgW21haWx0bzpyeWFuLmJsYWtlLndpbGxpYW1zQGdtYWlsLmNvbV0NClNlbnQ6IFRodXJzZGF5
LCBGZWJydWFyeSAyNiwgMjAxNSA2OjExIFBNDQpUbzogdXNlcjsgZGV2QHNwYXJrLmFwYWNoZS5v
cmcNClN1YmplY3Q6IE1vbml0b3JpbmcgU3Bhcmsgd2l0aCBHcmFwaGl0ZSBhbmQgR3JhZmFuYQ0K
DQpJZiBhbnlvbmUgaXMgY3VyaW91cyB0byB0cnkgZXhwb3J0aW5nIFNwYXJrIG1ldHJpY3MgdG8g
R3JhcGhpdGUsIEkganVzdCBwdWJsaXNoZWQgYSBwb3N0IGFib3V0IG15IGV4cGVyaWVuY2UgZG9p
bmcgdGhhdCwgYnVpbGRpbmcgZGFzaGJvYXJkcyBpbiBHcmFmYW5hPGh0dHA6Ly9ncmFmYW5hLm9y
Zy8+LCBhbmQgdXNpbmcgdGhlbSB0byBtb25pdG9yIFNwYXJrIGpvYnM6IGh0dHA6Ly93d3cuaGFt
bWVybGFiLm9yZy8yMDE1LzAyLzI3L21vbml0b3Jpbmctc3Bhcmstd2l0aC1ncmFwaGl0ZS1hbmQt
Z3JhZmFuYS8NCg0KQ29kZSBmb3IgZ2VuZXJhdGluZyBHcmFmYW5hIGRhc2hib2FyZHMgdGFpbG9y
ZWQgdG8gdGhlIG1ldHJpY3MgZW1pdHRlZCBieSBTcGFyayBpcyBoZXJlOiBodHRwczovL2dpdGh1
Yi5jb20vaGFtbWVybGFiL2dyYWZhbmEtc3BhcmstZGFzaGJvYXJkcy4NCg0KSWYgYW55b25lIGVs
c2UgaXMgaW50ZXJlc3RlZCBpbiB3b3JraW5nIG9uIGV4cGFuZGluZyBNZXRyaWNzU3lzdGVtIHRv
IG1ha2UgdGhpcyBzb3J0IG9mIHRoaW5nIG1vcmUgdXNlZnVsLCBsZXQgbWUga25vdywgSSd2ZSBi
ZWVuIHdvcmtpbmcgb24gaXQgYSBmYWlyIGFtb3VudCBhbmQgaGF2ZSBhIGJ1bmNoIG9mIGlkZWFz
IGFib3V0IHdoZXJlIGl0IHNob3VsZCBnby4NCg0KVGhhbmtzLA0KDQotUnlhbg0KDQoNCg==

--_000_64474308D680D540A4D8151B0F7C03F70279E9EFSHSMSX104ccrcor_--

From dev-return-11804-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 03:56:12 2015
Return-Path: <dev-return-11804-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8221417B51
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 03:56:12 +0000 (UTC)
Received: (qmail 26875 invoked by uid 500); 27 Feb 2015 03:56:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26790 invoked by uid 500); 27 Feb 2015 03:56:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26779 invoked by uid 99); 27 Feb 2015 03:56:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 03:56:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 03:56:06 +0000
Received: by lbvp9 with SMTP id p9so14881977lbv.3
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 19:55:24 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=bSeWnWo0Rtk0ZuPqqo+AiADSKBsMkZc7ocEk5rTbl9Y=;
        b=cJUa9/aABc+GzzZfSRS/XmgIkJN/vGW06QdFW1UYWXokH5nM76bhNK0+IQsLJWPERk
         yQZG/AUiZH2rPwBYHtXb0O82EQzXMjRrBA0YhDZarR1qjWNy+aJWdw/MVOloG4jnV6vh
         uVuSTB8BEKIvDBE6y/SjGvD6Hf7eOfviCigv3nDeSJmxNp119zFlQm7lH848coTOFqzH
         /2nY6/lxqxLq/V8u4nUuhL0KNNHMCA4bxa5apmvK7JDNZ8C1P0w8hn9CE5o767ElnzxR
         /zyezoS/ZLxrIilhvbNTPWWlvBsnX5JV9f34dlix31/2Sx5kwq4CDuknEZdaKnW25xAn
         +ENA==
X-Gm-Message-State: ALoCoQnAButLeqsO1s4dpDyMCJ1WnFTsyQz53HlBfQrQ/yhR0HCnCvnldsnpyn13Uq+cgOgYJues
X-Received: by 10.112.62.135 with SMTP id y7mr10591817lbr.50.1425009324588;
 Thu, 26 Feb 2015 19:55:24 -0800 (PST)
MIME-Version: 1.0
Received: by 10.25.39.8 with HTTP; Thu, 26 Feb 2015 19:55:04 -0800 (PST)
In-Reply-To: <CAO4jRXa0BjguKhO3379Y-XZx0KosNj+EoBEFBDSOT80nfy07xw@mail.gmail.com>
References: <CAO4jRXZAX0=LThkdjeU5d_p0_esK8gg1BUwyzZSrenEMMht-9g@mail.gmail.com>
 <CAHUQ+_YhbdP3CGVg697amartG+AS=Sk0zM4ZK=ADyCTb-PCZ5g@mail.gmail.com>
 <CAO4jRXatHK=V8i=AxtRSze5YhuKqk8_RAvA_dsBkTXw3qJwBKA@mail.gmail.com>
 <CAO4jRXZovRqkyCNiD8qqin05ccvRxUY2+-M8-8gCnYd3Tp8zkg@mail.gmail.com>
 <CAHUQ+_Y1Hg0Gg1xi2e5EuLVkux1-4ufzXwVNAbeVmpTQf0xu7w@mail.gmail.com>
 <CAO4jRXYn5N_d0W2yteGtNzMTDbbupoM48kbEmovUhtHhnstZOw@mail.gmail.com> <CAO4jRXa0BjguKhO3379Y-XZx0KosNj+EoBEFBDSOT80nfy07xw@mail.gmail.com>
From: Victor Tso-Guillen <vtso@paxata.com>
Date: Thu, 26 Feb 2015 19:55:04 -0800
Message-ID: <CAO4jRXZRnuMd9xRS4hF1_L9fiCn9-vyLTrnU-fUsm7on-JRPRw@mail.gmail.com>
Subject: Re: Scheduler hang?
To: dev@spark.apache.org
Cc: "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/related; boundary=001a11c3f7ce983036051009d607
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f7ce983036051009d607
Content-Type: multipart/alternative; boundary=001a11c3f7ce98302f051009d606

--001a11c3f7ce98302f051009d606
Content-Type: text/plain; charset=UTF-8

Love to hear some input on this. I did get a standalone cluster up on my
local machine and the problem didn't present itself. I'm pretty confident
that means the problem is in the LocalBackend or something near it.

On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <vtso@paxata.com> wrote:

> Okay I confirmed my suspicions of a hang. I made a request that stopped
> progressing, though the already-scheduled tasks had finished. I made a
> separate request that was small enough not to hang, and it kicked the hung
> job enough to finish. I think what's happening is that the scheduler or the
> local backend is not kicking the revive offers messaging at the right time,
> but I have to dig into the code some more to nail the culprit. Anyone on
> these list have experience in those code areas that could help?
>
> On Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <vtso@paxata.com>
> wrote:
>
>> Thanks for the link. Unfortunately, I turned on rdd compression and
>> nothing changed. I tried moving netty -> nio and no change :(
>>
>> On Thu, Feb 26, 2015 at 2:01 AM, Akhil Das <akhil@sigmoidanalytics.com>
>> wrote:
>>
>>> Not many that i know of, but i bumped into this one
>>> https://issues.apache.org/jira/browse/SPARK-4516
>>>
>>> Thanks
>>> Best Regards
>>>
>>> On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-Guillen <vtso@paxata.com>
>>> wrote:
>>>
>>>> Is there any potential problem from 1.1.1 to 1.2.1 with shuffle
>>>> dependencies that produce no data?
>>>>
>>>> On Thu, Feb 26, 2015 at 1:56 AM, Victor Tso-Guillen <vtso@paxata.com>
>>>> wrote:
>>>>
>>>>> The data is small. The job is composed of many small stages.
>>>>>
>>>>> * I found that with fewer than 222 the problem exhibits. What will be
>>>>> gained by going higher?
>>>>> * Pushing up the parallelism only pushes up the boundary at which the
>>>>> system appears to hang. I'm worried about some sort of message loss or
>>>>> inconsistency.
>>>>> * Yes, we are using Kryo.
>>>>> * I'll try that, but I'm again a little confused why you're
>>>>> recommending this. I'm stumped so might as well?
>>>>>
>>>>> On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <
>>>>> akhil@sigmoidanalytics.com> wrote:
>>>>>
>>>>>> What operation are you trying to do and how big is the data that you
>>>>>> are operating on?
>>>>>>
>>>>>> Here's a few things which you can try:
>>>>>>
>>>>>> - Repartition the RDD to a higher number than 222
>>>>>> - Specify the master as local[*] or local[10]
>>>>>> - Use Kryo Serializer (.set("spark.serializer",
>>>>>> "org.apache.spark.serializer.KryoSerializer"))
>>>>>> - Enable RDD Compression (.set("spark.rdd.compress","true") )
>>>>>>
>>>>>>
>>>>>> Thanks
>>>>>> Best Regards
>>>>>>
>>>>>> On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso-Guillen <vtso@paxata.com
>>>>>> > wrote:
>>>>>>
>>>>>>> I'm getting this really reliably on Spark 1.2.1. Basically I'm in
>>>>>>> local mode with parallelism at 8. I have 222 tasks and I never seem to get
>>>>>>> far past 40. Usually in the 20s to 30s it will just hang. The last logging
>>>>>>> is below, and a screenshot of the UI.
>>>>>>>
>>>>>>> 2015-02-25 20:39:55.779 GMT-0800 INFO  [task-result-getter-3]
>>>>>>> TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms on
>>>>>>> localhost (1/5)
>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>> worker-10] Executor - Finished task 1.0 in stage 16.0 (TID 20). 2492 bytes
>>>>>>> result sent to driver
>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>> worker-8] Executor - Finished task 2.0 in stage 16.0 (TID 21). 2492 bytes
>>>>>>> result sent to driver
>>>>>>> 2015-02-25 20:39:55.831 GMT-0800 INFO  [task-result-getter-0]
>>>>>>> TaskSetManager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on
>>>>>>> localhost (2/5)
>>>>>>> 2015-02-25 20:39:55.836 GMT-0800 INFO  [task-result-getter-1]
>>>>>>> TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on
>>>>>>> localhost (3/5)
>>>>>>> 2015-02-25 20:39:55.891 GMT-0800 INFO  [Executor task launch
>>>>>>> worker-9] Executor - Finished task 0.0 in stage 16.0 (TID 19). 2492 bytes
>>>>>>> result sent to driver
>>>>>>> 2015-02-25 20:39:55.896 GMT-0800 INFO  [task-result-getter-2]
>>>>>>> TaskSetManager - Finished task 0.0 in stage 16.0 (TID 19) in 740 ms on
>>>>>>> localhost (4/5)
>>>>>>>
>>>>>>> [image: Inline image 1]
>>>>>>> What should I make of this? Where do I start?
>>>>>>>
>>>>>>> Thanks,
>>>>>>> Victor
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a11c3f7ce98302f051009d606
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Love to hear some input on this. I did get a standalone cl=
uster up on my local machine and the problem didn&#39;t present itself. I&#=
39;m pretty confident that means the problem is in the LocalBackend or some=
thing near it.</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quot=
e">On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <span dir=3D"ltr">&l=
t;<a href=3D"mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com</a>&=
gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 =
0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Okay I=
 confirmed my suspicions of a hang. I made a request that stopped progressi=
ng, though the already-scheduled tasks had finished. I made a separate requ=
est that was small enough not to hang, and it kicked the hung job enough to=
 finish. I think what&#39;s happening is that the scheduler or the local ba=
ckend is not kicking the revive offers messaging at the right time, but I h=
ave to dig into the code some more to nail the culprit. Anyone on these lis=
t have experience in those code areas that could help?</div><div class=3D"H=
OEnZb"><div class=3D"h5"><div class=3D"gmail_extra"><br><div class=3D"gmail=
_quote">On Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <span dir=3D"lt=
r">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com=
</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin=
:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">T=
hanks for the link. Unfortunately, I turned on rdd compression and nothing =
changed. I tried moving netty -&gt; nio and no change :(</div><div><div><di=
v class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015=
 at 2:01 AM, Akhil Das <span dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoi=
danalytics.com" target=3D"_blank">akhil@sigmoidanalytics.com</a>&gt;</span>=
 wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bor=
der-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><div class=3D"gm=
ail_default" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb=
(0,0,0)">Not many that i know of, but i bumped into this one=C2=A0<a href=
=3D"https://issues.apache.org/jira/browse/SPARK-4516" target=3D"_blank">htt=
ps://issues.apache.org/jira/browse/SPARK-4516</a></div></div><div class=3D"=
gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>Best R=
egards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-=
Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"=
_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail=
_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:=
1ex"><div dir=3D"ltr">Is there any potential problem from 1.1.1 to 1.2.1 wi=
th shuffle dependencies that produce no data?</div><div><div><div class=3D"=
gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 1:56 AM=
, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.co=
m" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr">The data is small. The job is composed o=
f many small stages.<div><br></div><div>* I found that with fewer than 222 =
the problem exhibits. What will be gained by going higher?</div><div>* Push=
ing up the parallelism only pushes up the boundary at which the system appe=
ars to hang. I&#39;m worried about some sort of message loss or inconsisten=
cy.</div><div>* Yes, we are using Kryo.</div><div>* I&#39;ll try that, but =
I&#39;m again a little confused why you&#39;re recommending this. I&#39;m s=
tumped so might as well?</div></div><div><div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <s=
pan dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.com" target=3D=
"_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br><blockquote cl=
ass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;p=
adding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">What operation a=
re you trying to do and how big is the data that you are operating on?</div=
><div class=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,mo=
nospace;color:rgb(0,0,0)"><br></div><div class=3D"gmail_default" style=3D"f=
ont-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">Here&#39;s a f=
ew things which you can try:</div><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)"><br></div><block=
quote style=3D"margin:0 0 0 40px;border:none;padding:0px"><div class=3D"gma=
il_default" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(=
0,0,0)">- Repartition the RDD to a higher number than 222</div><div class=
=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;col=
or:rgb(0,0,0)">- Specify the master as local[*] or local[10]</div><div clas=
s=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;co=
lor:rgb(0,0,0)">- Use Kryo Serializer (<span style=3D"color:rgb(51,51,51);f=
ont-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-=
size:12px;line-height:1.4;font-weight:bold">.</span><span style=3D"color:rg=
b(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,mo=
nospace;font-size:12px;line-height:1.4;background-color:rgb(255,255,255)">s=
et</span><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39=
;Liberation Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font=
-weight:bold">(</span><span style=3D"font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;color:rgb(1=
87,136,68)">&quot;spark.serializer&quot;</span><span style=3D"color:rgb(51,=
51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospa=
ce;font-size:12px;line-height:1.4;font-weight:bold">,</span><span style=3D"=
color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Co=
urier,monospace;font-size:12px;line-height:1.4"> </span><span style=3D"font=
-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-siz=
e:12px;line-height:1.4;color:rgb(187,136,68)">&quot;org.apache.spark.serial=
izer.KryoSerializer&quot;</span><span style=3D"color:rgb(51,51,51);font-fam=
ily:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-size:12=
px;line-height:1.4;font-weight:bold">))</span></div><div class=3D"gmail_def=
ault" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)=
"><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font-weight=
:bold"><span style=3D"color:rgb(0,0,0);font-family:&#39;courier new&#39;,mo=
nospace;font-size:small;font-weight:normal;line-height:normal">- Enable RDD=
 Compression (</span><span style=3D"line-height:1.4">.</span><span style=3D=
"line-height:1.4;font-weight:normal;background-color:rgb(255,255,255)">set<=
/span><span style=3D"line-height:1.4">(</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;spark.rdd.compress&quot;<=
/span><span style=3D"line-height:1.4">,</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;true&quot;</span><span st=
yle=3D"line-height:1.4">) )</span></span></div></blockquote></div><div clas=
s=3D"gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>B=
est Regards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso=
-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D=
"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div>I&#39;m getting this really reliably on Spark 1=
.2.1. Basically I&#39;m in local mode with parallelism at 8. I have 222 tas=
ks and I never seem to get far past 40. Usually in the 20s to 30s it will j=
ust hang. The last logging is below, and a screenshot of the UI.</div><div>=
<br></div><div>2015-02-25 20:39:55.779 GMT-0800 INFO =C2=A0[task-result-get=
ter-3] TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms =
on localhost (1/5)</div><div>2015-02-25 20:39:55.825 GMT-0800 INFO =C2=A0[E=
xecutor task launch worker-10] Executor - Finished task 1.0 in stage 16.0 (=
TID 20). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.825=
 GMT-0800 INFO =C2=A0[Executor task launch worker-8] Executor - Finished ta=
sk 2.0 in stage 16.0 (TID 21). 2492 bytes result sent to driver</div><div>2=
015-02-25 20:39:55.831 GMT-0800 INFO =C2=A0[task-result-getter-0] TaskSetMa=
nager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on localhost (2/=
5)</div><div>2015-02-25 20:39:55.836 GMT-0800 INFO =C2=A0[task-result-gette=
r-1] TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on=
 localhost (3/5)</div><div>2015-02-25 20:39:55.891 GMT-0800 INFO =C2=A0[Exe=
cutor task launch worker-9] Executor - Finished task 0.0 in stage 16.0 (TID=
 19). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.896 GM=
T-0800 INFO =C2=A0[task-result-getter-2] TaskSetManager - Finished task 0.0=
 in stage 16.0 (TID 19) in 740 ms on localhost (4/5)</div><div><br></div><d=
iv><img src=3D"cid:ii_14bc43449dfc51e7" alt=3D"Inline image 1" width=3D"544=
" height=3D"124"><br></div><div>What should I make of this? Where do I star=
t?</div><div><br></div><div>Thanks,</div><div>Victor</div></div>
</blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

--001a11c3f7ce98302f051009d606--
--001a11c3f7ce983036051009d607--

From dev-return-11805-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 04:35:16 2015
Return-Path: <dev-return-11805-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2EC0217CE2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 04:35:16 +0000 (UTC)
Received: (qmail 99261 invoked by uid 500); 27 Feb 2015 04:34:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99181 invoked by uid 500); 27 Feb 2015 04:34:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99169 invoked by uid 99); 27 Feb 2015 04:34:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 04:34:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (athena.apache.org: local policy)
Received: from [209.85.218.45] (HELO mail-oi0-f45.google.com) (209.85.218.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 04:34:36 +0000
Received: by mail-oi0-f45.google.com with SMTP id i138so13695089oig.4
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 20:33:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=t+xBb5G5MYVmoNp9uJ6MWhtczZ2uNL7MGlVtpmrKn6A=;
        b=TFgL0V5NnJ0UnxMC2vJX/SnaDKRhc8mvQ1IawVF2CRhG/1080DgJ1LBvGNyIqlm9Iq
         uMRBwFdmBT+CtNXXEO0LDyTWCyMyR+SNVxqmc0xGJKSPWG+388yGJfIvFmCsjESOI8ok
         YHJ4LyUfQVw+Mh+FMR+c7Q6rniO0NNsqoF8nt9nOU2Q9C+C8EOAAkFTc/ghh9XG84Hvc
         YhcpirRW9ITO/6iDVVMQaaiNVkgqsXKd3/kD79dmKMydDtWsRvJXADhN/h6XK0Uu4Xof
         EpXfYtqNbkkkSgD1Cj0D66Nst53L06AVSw/BHJlVa+bh/QqAXkJZXiJu4bZGrPlJCC4u
         QhSQ==
X-Gm-Message-State: ALoCoQkCAKcS2WIQSEpsk/+IqqpX15Q0Ryq8RWenGlt6go2Xl21mmX4EED66SLif4sr+fhNLvXKd
X-Received: by 10.202.85.17 with SMTP id j17mr8148590oib.65.1425011589704;
 Thu, 26 Feb 2015 20:33:09 -0800 (PST)
MIME-Version: 1.0
Received: by 10.76.116.33 with HTTP; Thu, 26 Feb 2015 20:32:47 -0800 (PST)
In-Reply-To: <CAO4jRXZRnuMd9xRS4hF1_L9fiCn9-vyLTrnU-fUsm7on-JRPRw@mail.gmail.com>
References: <CAO4jRXZAX0=LThkdjeU5d_p0_esK8gg1BUwyzZSrenEMMht-9g@mail.gmail.com>
 <CAHUQ+_YhbdP3CGVg697amartG+AS=Sk0zM4ZK=ADyCTb-PCZ5g@mail.gmail.com>
 <CAO4jRXatHK=V8i=AxtRSze5YhuKqk8_RAvA_dsBkTXw3qJwBKA@mail.gmail.com>
 <CAO4jRXZovRqkyCNiD8qqin05ccvRxUY2+-M8-8gCnYd3Tp8zkg@mail.gmail.com>
 <CAHUQ+_Y1Hg0Gg1xi2e5EuLVkux1-4ufzXwVNAbeVmpTQf0xu7w@mail.gmail.com>
 <CAO4jRXYn5N_d0W2yteGtNzMTDbbupoM48kbEmovUhtHhnstZOw@mail.gmail.com>
 <CAO4jRXa0BjguKhO3379Y-XZx0KosNj+EoBEFBDSOT80nfy07xw@mail.gmail.com> <CAO4jRXZRnuMd9xRS4hF1_L9fiCn9-vyLTrnU-fUsm7on-JRPRw@mail.gmail.com>
From: Victor Tso-Guillen <vtso@paxata.com>
Date: Thu, 26 Feb 2015 20:32:47 -0800
Message-ID: <CAO4jRXYdhr8oso8d-u_JG2uBH+CLEFr_ocTobRJG_U=sB1bMhw@mail.gmail.com>
Subject: Re: Scheduler hang?
To: dev@spark.apache.org
Cc: "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/related; boundary=001a113d2e2c9ba23505100a5dd4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d2e2c9ba23505100a5dd4
Content-Type: multipart/alternative; boundary=001a113d2e2c9ba23005100a5dd3

--001a113d2e2c9ba23005100a5dd3
Content-Type: text/plain; charset=UTF-8

Of course, breakpointing on every status update and revive offers
invocation kept the problem from happening. Where could the race be?

On Thu, Feb 26, 2015 at 7:55 PM, Victor Tso-Guillen <vtso@paxata.com> wrote:

> Love to hear some input on this. I did get a standalone cluster up on my
> local machine and the problem didn't present itself. I'm pretty confident
> that means the problem is in the LocalBackend or something near it.
>
> On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <vtso@paxata.com>
> wrote:
>
>> Okay I confirmed my suspicions of a hang. I made a request that stopped
>> progressing, though the already-scheduled tasks had finished. I made a
>> separate request that was small enough not to hang, and it kicked the hung
>> job enough to finish. I think what's happening is that the scheduler or the
>> local backend is not kicking the revive offers messaging at the right time,
>> but I have to dig into the code some more to nail the culprit. Anyone on
>> these list have experience in those code areas that could help?
>>
>> On Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <vtso@paxata.com>
>> wrote:
>>
>>> Thanks for the link. Unfortunately, I turned on rdd compression and
>>> nothing changed. I tried moving netty -> nio and no change :(
>>>
>>> On Thu, Feb 26, 2015 at 2:01 AM, Akhil Das <akhil@sigmoidanalytics.com>
>>> wrote:
>>>
>>>> Not many that i know of, but i bumped into this one
>>>> https://issues.apache.org/jira/browse/SPARK-4516
>>>>
>>>> Thanks
>>>> Best Regards
>>>>
>>>> On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-Guillen <vtso@paxata.com>
>>>> wrote:
>>>>
>>>>> Is there any potential problem from 1.1.1 to 1.2.1 with shuffle
>>>>> dependencies that produce no data?
>>>>>
>>>>> On Thu, Feb 26, 2015 at 1:56 AM, Victor Tso-Guillen <vtso@paxata.com>
>>>>> wrote:
>>>>>
>>>>>> The data is small. The job is composed of many small stages.
>>>>>>
>>>>>> * I found that with fewer than 222 the problem exhibits. What will be
>>>>>> gained by going higher?
>>>>>> * Pushing up the parallelism only pushes up the boundary at which the
>>>>>> system appears to hang. I'm worried about some sort of message loss or
>>>>>> inconsistency.
>>>>>> * Yes, we are using Kryo.
>>>>>> * I'll try that, but I'm again a little confused why you're
>>>>>> recommending this. I'm stumped so might as well?
>>>>>>
>>>>>> On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <
>>>>>> akhil@sigmoidanalytics.com> wrote:
>>>>>>
>>>>>>> What operation are you trying to do and how big is the data that you
>>>>>>> are operating on?
>>>>>>>
>>>>>>> Here's a few things which you can try:
>>>>>>>
>>>>>>> - Repartition the RDD to a higher number than 222
>>>>>>> - Specify the master as local[*] or local[10]
>>>>>>> - Use Kryo Serializer (.set("spark.serializer",
>>>>>>> "org.apache.spark.serializer.KryoSerializer"))
>>>>>>> - Enable RDD Compression (.set("spark.rdd.compress","true") )
>>>>>>>
>>>>>>>
>>>>>>> Thanks
>>>>>>> Best Regards
>>>>>>>
>>>>>>> On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso-Guillen <
>>>>>>> vtso@paxata.com> wrote:
>>>>>>>
>>>>>>>> I'm getting this really reliably on Spark 1.2.1. Basically I'm in
>>>>>>>> local mode with parallelism at 8. I have 222 tasks and I never seem to get
>>>>>>>> far past 40. Usually in the 20s to 30s it will just hang. The last logging
>>>>>>>> is below, and a screenshot of the UI.
>>>>>>>>
>>>>>>>> 2015-02-25 20:39:55.779 GMT-0800 INFO  [task-result-getter-3]
>>>>>>>> TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms on
>>>>>>>> localhost (1/5)
>>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>>> worker-10] Executor - Finished task 1.0 in stage 16.0 (TID 20). 2492 bytes
>>>>>>>> result sent to driver
>>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>>> worker-8] Executor - Finished task 2.0 in stage 16.0 (TID 21). 2492 bytes
>>>>>>>> result sent to driver
>>>>>>>> 2015-02-25 20:39:55.831 GMT-0800 INFO  [task-result-getter-0]
>>>>>>>> TaskSetManager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on
>>>>>>>> localhost (2/5)
>>>>>>>> 2015-02-25 20:39:55.836 GMT-0800 INFO  [task-result-getter-1]
>>>>>>>> TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on
>>>>>>>> localhost (3/5)
>>>>>>>> 2015-02-25 20:39:55.891 GMT-0800 INFO  [Executor task launch
>>>>>>>> worker-9] Executor - Finished task 0.0 in stage 16.0 (TID 19). 2492 bytes
>>>>>>>> result sent to driver
>>>>>>>> 2015-02-25 20:39:55.896 GMT-0800 INFO  [task-result-getter-2]
>>>>>>>> TaskSetManager - Finished task 0.0 in stage 16.0 (TID 19) in 740 ms on
>>>>>>>> localhost (4/5)
>>>>>>>>
>>>>>>>> [image: Inline image 1]
>>>>>>>> What should I make of this? Where do I start?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Victor
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a113d2e2c9ba23005100a5dd3
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Of course, breakpointing on every status update and revive=
 offers invocation kept the problem from happening. Where could the race be=
?</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Fe=
b 26, 2015 at 7:55 PM, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"=
mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wr=
ote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border=
-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Love to hear some i=
nput on this. I did get a standalone cluster up on my local machine and the=
 problem didn&#39;t present itself. I&#39;m pretty confident that means the=
 problem is in the LocalBackend or something near it.</div><div class=3D"HO=
EnZb"><div class=3D"h5"><div class=3D"gmail_extra"><br><div class=3D"gmail_=
quote">On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <span dir=3D"ltr=
">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com<=
/a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:=
0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Ok=
ay I confirmed my suspicions of a hang. I made a request that stopped progr=
essing, though the already-scheduled tasks had finished. I made a separate =
request that was small enough not to hang, and it kicked the hung job enoug=
h to finish. I think what&#39;s happening is that the scheduler or the loca=
l backend is not kicking the revive offers messaging at the right time, but=
 I have to dig into the code some more to nail the culprit. Anyone on these=
 list have experience in those code areas that could help?</div><div><div><=
div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 20=
15 at 2:27 AM, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:v=
tso@paxata.com" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br>=
<blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1p=
x #ccc solid;padding-left:1ex"><div dir=3D"ltr">Thanks for the link. Unfort=
unately, I turned on rdd compression and nothing changed. I tried moving ne=
tty -&gt; nio and no change :(</div><div><div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 2:01 AM, Akhil Das <sp=
an dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.com" target=3D"=
_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br><blockquote cla=
ss=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;pa=
dding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default" style=3D"font=
-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">Not many that i k=
now of, but i bumped into this one=C2=A0<a href=3D"https://issues.apache.or=
g/jira/browse/SPARK-4516" target=3D"_blank">https://issues.apache.org/jira/=
browse/SPARK-4516</a></div></div><div class=3D"gmail_extra"><br clear=3D"al=
l"><div><div><div dir=3D"ltr">Thanks<div>Best Regards</div></div></div></di=
v><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-=
Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"=
_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail=
_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:=
1ex"><div dir=3D"ltr">Is there any potential problem from 1.1.1 to 1.2.1 wi=
th shuffle dependencies that produce no data?</div><div><div><div class=3D"=
gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 1:56 AM=
, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.co=
m" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr">The data is small. The job is composed o=
f many small stages.<div><br></div><div>* I found that with fewer than 222 =
the problem exhibits. What will be gained by going higher?</div><div>* Push=
ing up the parallelism only pushes up the boundary at which the system appe=
ars to hang. I&#39;m worried about some sort of message loss or inconsisten=
cy.</div><div>* Yes, we are using Kryo.</div><div>* I&#39;ll try that, but =
I&#39;m again a little confused why you&#39;re recommending this. I&#39;m s=
tumped so might as well?</div></div><div><div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <s=
pan dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.com" target=3D=
"_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br><blockquote cl=
ass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;p=
adding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">What operation a=
re you trying to do and how big is the data that you are operating on?</div=
><div class=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,mo=
nospace;color:rgb(0,0,0)"><br></div><div class=3D"gmail_default" style=3D"f=
ont-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">Here&#39;s a f=
ew things which you can try:</div><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)"><br></div><block=
quote style=3D"margin:0 0 0 40px;border:none;padding:0px"><div class=3D"gma=
il_default" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(=
0,0,0)">- Repartition the RDD to a higher number than 222</div><div class=
=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;col=
or:rgb(0,0,0)">- Specify the master as local[*] or local[10]</div><div clas=
s=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;co=
lor:rgb(0,0,0)">- Use Kryo Serializer (<span style=3D"color:rgb(51,51,51);f=
ont-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-=
size:12px;line-height:1.4;font-weight:bold">.</span><span style=3D"color:rg=
b(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,mo=
nospace;font-size:12px;line-height:1.4;background-color:rgb(255,255,255)">s=
et</span><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39=
;Liberation Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font=
-weight:bold">(</span><span style=3D"font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;color:rgb(1=
87,136,68)">&quot;spark.serializer&quot;</span><span style=3D"color:rgb(51,=
51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospa=
ce;font-size:12px;line-height:1.4;font-weight:bold">,</span><span style=3D"=
color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Co=
urier,monospace;font-size:12px;line-height:1.4"> </span><span style=3D"font=
-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-siz=
e:12px;line-height:1.4;color:rgb(187,136,68)">&quot;org.apache.spark.serial=
izer.KryoSerializer&quot;</span><span style=3D"color:rgb(51,51,51);font-fam=
ily:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-size:12=
px;line-height:1.4;font-weight:bold">))</span></div><div class=3D"gmail_def=
ault" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)=
"><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font-weight=
:bold"><span style=3D"color:rgb(0,0,0);font-family:&#39;courier new&#39;,mo=
nospace;font-size:small;font-weight:normal;line-height:normal">- Enable RDD=
 Compression (</span><span style=3D"line-height:1.4">.</span><span style=3D=
"line-height:1.4;font-weight:normal;background-color:rgb(255,255,255)">set<=
/span><span style=3D"line-height:1.4">(</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;spark.rdd.compress&quot;<=
/span><span style=3D"line-height:1.4">,</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;true&quot;</span><span st=
yle=3D"line-height:1.4">) )</span></span></div></blockquote></div><div clas=
s=3D"gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>B=
est Regards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso=
-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D=
"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div>I&#39;m getting this really reliably on Spark 1=
.2.1. Basically I&#39;m in local mode with parallelism at 8. I have 222 tas=
ks and I never seem to get far past 40. Usually in the 20s to 30s it will j=
ust hang. The last logging is below, and a screenshot of the UI.</div><div>=
<br></div><div>2015-02-25 20:39:55.779 GMT-0800 INFO =C2=A0[task-result-get=
ter-3] TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms =
on localhost (1/5)</div><div>2015-02-25 20:39:55.825 GMT-0800 INFO =C2=A0[E=
xecutor task launch worker-10] Executor - Finished task 1.0 in stage 16.0 (=
TID 20). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.825=
 GMT-0800 INFO =C2=A0[Executor task launch worker-8] Executor - Finished ta=
sk 2.0 in stage 16.0 (TID 21). 2492 bytes result sent to driver</div><div>2=
015-02-25 20:39:55.831 GMT-0800 INFO =C2=A0[task-result-getter-0] TaskSetMa=
nager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on localhost (2/=
5)</div><div>2015-02-25 20:39:55.836 GMT-0800 INFO =C2=A0[task-result-gette=
r-1] TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on=
 localhost (3/5)</div><div>2015-02-25 20:39:55.891 GMT-0800 INFO =C2=A0[Exe=
cutor task launch worker-9] Executor - Finished task 0.0 in stage 16.0 (TID=
 19). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.896 GM=
T-0800 INFO =C2=A0[task-result-getter-2] TaskSetManager - Finished task 0.0=
 in stage 16.0 (TID 19) in 740 ms on localhost (4/5)</div><div><br></div><d=
iv><img src=3D"cid:ii_14bc43449dfc51e7" alt=3D"Inline image 1" width=3D"544=
" height=3D"124"><br></div><div>What should I make of this? Where do I star=
t?</div><div><br></div><div>Thanks,</div><div>Victor</div></div>
</blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

--001a113d2e2c9ba23005100a5dd3--
--001a113d2e2c9ba23505100a5dd4--

From dev-return-11806-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 06:47:59 2015
Return-Path: <dev-return-11806-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5E9C310090
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 06:47:59 +0000 (UTC)
Received: (qmail 51930 invoked by uid 500); 27 Feb 2015 06:47:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51842 invoked by uid 500); 27 Feb 2015 06:47:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51829 invoked by uid 99); 27 Feb 2015 06:47:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 06:47:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sam.halliday@gmail.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 06:47:29 +0000
Received: by ierx19 with SMTP id x19so26835493ier.3
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 22:47:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eJEYZmLjdBmuJuOk4txPQ+S/Zc9I7VTDgv0wTkLAnT8=;
        b=Ei5P/nxoNEEW54D+xh2LUVWbz6KHn3hxR5jgUxqyeD/EVjLpNxEL/Jh+9HD8zQukt/
         9beRA3kWBfHCchYg0csQGw1IhUS7gv3ZjBrW302g6lsJrUCXSUluLW3tzcBJzo2QMbM5
         eeOuYz9VERb2V+Fn0PRcwoy4L4mvsBr/XyJX6kjpz8Dw3i/kJ5WQ3+x6ematoc9lWdby
         3N1mh+5hWvRl9irIYAW15P53KXjuOLLW2nNn55UQZ84tYdQmpCP5XofMo+EkvQZ6tjmA
         lYXpfBhx2vv84LPO+0Pp4R4Yo2nV2QfSgi9qgP39sHRVSXsN7Pep0XZWUtiLsq8Ws7lB
         +AXw==
MIME-Version: 1.0
X-Received: by 10.50.49.43 with SMTP id r11mr1057426ign.18.1425019647369; Thu,
 26 Feb 2015 22:47:27 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 22:47:27 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Thu, 26 Feb 2015 22:47:27 -0800 (PST)
In-Reply-To: <CAJgQjQ9q2wEu-URc6OkNf+rVriX+FDcViSBM-die2HyCpRC=-A@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
	<CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
	<87ioeo5n6e.fsf@gmail.com>
	<CAJgQjQ9q2wEu-URc6OkNf+rVriX+FDcViSBM-die2HyCpRC=-A@mail.gmail.com>
Date: Fri, 27 Feb 2015 06:47:27 +0000
Message-ID: <CALR_T9BsNT9SBAveH7z+Aw-CYB+NFPxGH0Rm_JNsjHu+RhMqsQ@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Sam Halliday <sam.halliday@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev@spark.apache.org, Joseph Bradley <joseph@databricks.com>, 
	"Ulanov, Alexander" <alexander.ulanov@hp.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: multipart/alternative; boundary=047d7bdca5b6e12a6d05100c3d07
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bdca5b6e12a6d05100c3d07
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Don't use "big O" estimates, always measure. It used to work back in the
days when double multiplication was a bottleneck. The computation cost is
effectively free on both the CPU and GPU and you're seeing pure copying
costs. Also, I'm dubious that cublas is doing what you think it is. Can you
link me to the source code for DGEMM?

I show all of this in my talk, with explanations, I can't stress enough how
much I recommend that you watch it if you want to understand high
performance hardware acceleration for linear algebra :-)
On 27 Feb 2015 01:42, "Xiangrui Meng" <mengxr@gmail.com> wrote:

> The copying overhead should be quadratic on n, while the computation
> cost is cubic on n. I can understand that netlib-cublas is slower than
> netlib-openblas on small problems. But I'm surprised to see that it is
> still 20x slower on 10000x10000. I did the following on a g2.2xlarge
> instance with BIDMat:
>
> val n =3D 10000
>
> val f =3D rand(n, n)
> flip; f*f; val rf =3D flop
>
> flip; val g =3D GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val rg =3D=
 flop
>
> flip; g*g; val rgg =3D flop
>
> The CPU version finished in 12 seconds.
> The CPU->GPU->CPU version finished in 2.2 seconds.
> The GPU version finished in 1.7 seconds.
>
> I'm not sure whether my CPU->GPU->CPU code simulates the netlib-cublas
> path. But based on the result, the data copying overhead is definitely
> not as big as 20x at n =3D 10000.
>
> Best,
> Xiangrui
>
>
> On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday <sam.halliday@gmail.com>
> wrote:
> > I've had some email exchanges with the author of BIDMat: it does exactl=
y
> > what you need to get the GPU benefit and writes higher level algorithms
> > entirely in the GPU kernels so that the memory stays there as long as
> > possible. The restriction with this approach is that it is only offerin=
g
> > high-level algorithms so is not a toolkit for applied mathematics
> > research and development --- but it works well as a toolkit for higher
> > level analysis (e.g. for analysts and practitioners).
> >
> > I believe BIDMat's approach is the best way to get performance out of
> > GPU hardware at the moment but I also have strong evidence to suggest
> > that the hardware will catch up and the memory transfer costs between
> > CPU/GPU will disappear meaning that there will be no need for custom GP=
U
> > kernel implementations. i.e. please continue to use BLAS primitives whe=
n
> > writing new algorithms and only go to the GPU for an alternative
> > optimised implementation.
> >
> > Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, and offer
> > an API that looks like BLAS but takes pointers to special regions in th=
e
> > GPU memory region. Somebody has written a wrapper around CUDA to create
> > a proper BLAS library but it only gives marginal performance over the
> > CPU because of the memory transfer overhead.
> >
> > This slide from my talk
> >
> >   http://fommil.github.io/scalax14/#/11/2
> >
> > says it all. X axis is matrix size, Y axis is logarithmic time to do
> > DGEMM. Black line is the "cheating" time for the GPU and the green line
> > is after copying the memory to/from the GPU memory. APUs have the
> > potential to eliminate the green line.
> >
> > Best regards,
> > Sam
> >
> >
> >
> > "Ulanov, Alexander" <alexander.ulanov@hp.com> writes:
> >
> >> Evan, thank you for the summary. I would like to add some more
> observations. The GPU that I used is 2.5 times cheaper than the CPU ($250
> vs $100). They both are 3 years old. I've also did a small test with mode=
rn
> hardware, and the new GPU nVidia Titan was slightly more than 1 order of
> magnitude faster than Intel E5-2650 v2 for the same tests. However, it
> costs as much as CPU ($1200). My takeaway is that GPU is making a better
> price/value progress.
> >>
> >>
> >>
> >> Xiangrui, I was also surprised that BIDMat-cuda was faster than
> netlib-cuda and the most reasonable explanation is that it holds the resu=
lt
> in GPU memory, as Sam suggested. At the same time, it is OK because you c=
an
> copy the result back from GPU only when needed. However, to be sure, I am
> going to ask the developer of BIDMat on his upcoming talk.
> >>
> >>
> >>
> >> Best regards, Alexander
> >>
> >>
> >> From: Sam Halliday [mailto:sam.halliday@gmail.com]
> >> Sent: Thursday, February 26, 2015 1:56 PM
> >> To: Xiangrui Meng
> >> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R.
> Sparks
> >> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>
> >>
> >> Btw, I wish people would stop cheating when comparing CPU and GPU
> timings for things like matrix multiply :-P
> >>
> >> Please always compare apples with apples and include the time it takes
> to set up the matrices, send it to the processing unit, doing the
> calculation AND copying it back to where you need to see the results.
> >>
> >> Ignoring this method will make you believe that your GPU is thousands
> of times faster than it really is. Again, jump to the end of my talk for
> graphs and more discussion....  especially the bit about me being keen on
> funding to investigate APU hardware further ;-) (I believe it will solve
> the problem)
> >> On 26 Feb 2015 21:16, "Xiangrui Meng" <mengxr@gmail.com<mailto:
> mengxr@gmail.com>> wrote:
> >> Hey Alexander,
> >>
> >> I don't quite understand the part where netlib-cublas is about 20x
> >> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> >> with netlib-java?
> >>
> >> CC'ed Sam, the author of netlib-java.
> >>
> >> Best,
> >> Xiangrui
> >>
> >> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com
> <mailto:joseph@databricks.com>> wrote:
> >>> Better documentation for linking would be very helpful!  Here's a JIR=
A:
> >>> https://issues.apache.org/jira/browse/SPARK-6019
> >>>
> >>>
> >>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <evan.sparks@gmail.co=
m
> <mailto:evan.sparks@gmail.com>>
> >>> wrote:
> >>>
> >>>> Thanks for compiling all the data and running these benchmarks, Alex=
.
> The
> >>>> big takeaways here can be seen with this chart:
> >>>>
> >>>>
> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6km=
AJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
> >>>>
> >>>> 1) A properly configured GPU matrix multiply implementation (e.g.
> >>>> BIDMat+GPU) can provide substantial (but less than an order of
> magnitude)
> >>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> >>>> netlib-java+openblas-compiled).
> >>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
> worse
> >>>> than a well-tuned CPU implementation, particularly for larger
> matrices.
> >>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
> >>>> basically agrees with the authors own benchmarks (
> >>>> https://github.com/fommil/netlib-java)
> >>>>
> >>>> I think that most of our users are in a situation where using GPUs
> may not
> >>>> be practical - although we could consider having a good GPU backend
> >>>> available as an option. However, *ALL* users of MLlib could benefit
> >>>> (potentially tremendously) from using a well-tuned CPU-based BLAS
> >>>> implementation. Perhaps we should consider updating the mllib guide
> with a
> >>>> more complete section for enabling high performance binaries on OSX
> and
> >>>> Linux? Or better, figure out a way for the system to fetch these
> >>>> automatically.
> >>>>
> >>>> - Evan
> >>>>
> >>>>
> >>>>
> >>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >>>>
> >>>>> Just to summarize this thread, I was finally able to make all
> performance
> >>>>> comparisons that we discussed. It turns out that:
> >>>>> BIDMat-cublas>>BIDMat
> >>>>>
> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-rep=
o=3D=3Dnetlib-cublas>netlib-blas>f2jblas
> >>>>>
> >>>>> Below is the link to the spreadsheet with full results.
> >>>>>
> >>>>>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J=
5r7kwKSPkY/edit?usp=3Dsharing
> >>>>>
> >>>>> One thing still needs exploration: does BIDMat-cublas perform copyi=
ng
> >>>>> to/from machine=E2=80=99s RAM?
> >>>>>
> >>>>> -----Original Message-----
> >>>>> From: Ulanov, Alexander
> >>>>> Sent: Tuesday, February 10, 2015 2:12 PM
> >>>>> To: Evan R. Sparks
> >>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.or=
g
> >
> >>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> Thanks, Evan! It seems that ticket was marked as duplicate though t=
he
> >>>>> original one discusses slightly different topic. I was able to link
> netlib
> >>>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked
> inside a
> >>>>> 60MB library.
> >>>>>
> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> >>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> >>>>>
> +-----------------------------------------------------------------------+
> >>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
> >>>>> |1,638475459 |
> >>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
> >>>>> 1569,233228 |
> >>>>>
> >>>>> It turn out that pre-compiled MKL is faster than precompiled
> OpenBlas on
> >>>>> my machine. Probably, I=E2=80=99ll add two more columns with locall=
y compiled
> >>>>> openblas and cuda.
> >>>>>
> >>>>> Alexander
> >>>>>
> >>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com>]
> >>>>> Sent: Monday, February 09, 2015 6:06 PM
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.or=
g
> >
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> Great - perhaps we can move this discussion off-list and onto a JIR=
A
> >>>>> ticket? (Here's one:
> https://issues.apache.org/jira/browse/SPARK-5705)
> >>>>>
> >>>>> It seems like this is going to be somewhat exploratory for a while
> (and
> >>>>> there's probably only a handful of us who really care about fast
> linear
> >>>>> algebra!)
> >>>>>
> >>>>> - Evan
> >>>>>
> >>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>>>> Hi Evan,
> >>>>>
> >>>>> Thank you for explanation and useful link. I am going to build
> OpenBLAS,
> >>>>> link it with Netlib-java and perform benchmark again.
> >>>>>
> >>>>> Do I understand correctly that BIDMat binaries contain statically
> linked
> >>>>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat
> not
> >>>>> having MKL BLAS installed on my server. If it is true, I wonder if
> it is OK
> >>>>> because Intel sells this library. Nevertheless, it seems that in my
> case
> >>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS give=
n
> that
> >>>>> BIDMat and Netlib-java are supposed to be on par with JNI overheads=
.
> >>>>>
> >>>>> Though, it might be interesting to link Netlib-java with Intel MKL,
> as
> >>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
> >>>>> (Netlib-java) interested to compare their libraries.
> >>>>>
> >>>>> Best regards, Alexander
> >>>>>
> >>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com><mailto:
> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >>>>> Sent: Friday, February 06, 2015 5:58 PM
> >>>>>
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.or=
g
> ><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> I would build OpenBLAS yourself, since good BLAS performance comes
> from
> >>>>> getting cache sizes, etc. set up correctly for your particular
> hardware -
> >>>>> this is often a very tricky process (see, e.g. ATLAS), but we found
> that on
> >>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> >>>>> performance competitive with MKL.
> >>>>>
> >>>>> To make sure the right library is getting used, you have to make su=
re
> >>>>> it's first on the search path - export
> >>>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
> >>>>>
> >>>>> For some examples of getting netlib-java setup on an ec2 node and
> some
> >>>>> example benchmarking code we ran a while back, see:
> >>>>> https://github.com/shivaram/matrix-bench
> >>>>>
> >>>>> In particular - build-openblas-ec2.sh shows you how to build the
> library
> >>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you ho=
w
> to get
> >>>>> the path setup and get that library picked up by netlib-java.
> >>>>>
> >>>>> In this way - you could probably get cuBLAS set up to be used by
> >>>>> netlib-java as well.
> >>>>>
> >>>>> - Evan
> >>>>>
> >>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to
> force
> >>>>> loading the right blas? For netlib, I there are few JVM flags, such
> as
> >>>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS,=
 so
> I can
> >>>>> force it to use Java implementation. Not sure I understand how to
> force use
> >>>>> a specific blas (not specific wrapper for blas).
> >>>>>
> >>>>> Btw. I have installed openblas (yum install openblas), so I suppose
> that
> >>>>> netlib is using it.
> >>>>>
> >>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com><mailto:
> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >>>>> Sent: Friday, February 06, 2015 5:19 PM
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.or=
g
> ><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>>>>
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> Getting breeze to pick up the right blas library is critical for
> >>>>> performance. I recommend using OpenBLAS (or MKL, if you already hav=
e
> it).
> >>>>> It might make sense to force BIDMat to use the same underlying BLAS
> library
> >>>>> as well.
> >>>>>
> >>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>>>> Hi Evan, Joseph
> >>>>>
> >>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
> faster
> >>>>> than netlib-java+breeze (sorry for weird table formatting):
> >>>>>
> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
> native_system_linux_x86-64|
> >>>>> Breeze+Netlib-java f2jblas |
> >>>>>
> +-----------------------------------------------------------------------+
> >>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> >>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 =
|
> >>>>>
> >>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
> 19
> >>>>> Linux, Scala 2.11.
> >>>>>
> >>>>> Later I will make tests with Cuda. I need to install new Cuda
> version for
> >>>>> this purpose.
> >>>>>
> >>>>> Do you have any ideas why breeze-netlib with native blas is so much
> >>>>> slower than BIDMat MKL?
> >>>>>
> >>>>> Best regards, Alexander
> >>>>>
> >>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
> joseph@databricks.com><mailto:
> >>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
> >>>>> Sent: Thursday, February 05, 2015 5:29 PM
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: Evan R. Sparks; dev@spark.apache.org<mailto:dev@spark.apache.or=
g
> ><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> Hi Alexander,
> >>>>>
> >>>>> Using GPUs with Spark would be very exciting.  Small comment:
> Concerning
> >>>>> your question earlier about keeping data stored on the GPU rather
> than
> >>>>> having to move it between main memory and GPU memory on each
> iteration, I
> >>>>> would guess this would be critical to getting good performance.  If
> you
> >>>>> could do multiple local iterations before aggregating results, then
> the
> >>>>> cost of data movement to the GPU could be amortized (and I believe
> that is
> >>>>> done in practice).  Having Spark be aware of the GPU and using it a=
s
> >>>>> another part of memory sounds like a much bigger undertaking.
> >>>>>
> >>>>> Joseph
> >>>>>
> >>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
> >>>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach present=
ation by
> John
> >>>>> Canny and I am really inspired by his talk and comparisons with
> Spark MLlib.
> >>>>>
> >>>>> I am very interested to find out what will be better within Spark:
> BIDMat
> >>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair wa=
y
> to
> >>>>> benchmark them? Currently I do benchmarks on artificial neural
> networks in
> >>>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linear=
 algebra, it
> involves
> >>>>> some other things that are essential to machine learning.
> >>>>>
> >>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com><mailto:
> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >>>>> Sent: Thursday, February 05, 2015 1:29 PM
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> >>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
> data
> >>>>> layout and fewer levels of indirection - it's definitely a worthwhi=
le
> >>>>> experiment to run. The main speedups I've seen from using it come
> from
> >>>>> highly optimized GPU code for linear algebra. I know that in the
> past Canny
> >>>>> has gone as far as to write custom GPU kernels for
> performance-critical
> >>>>> regions of code.[1]
> >>>>>
> >>>>> BIDMach is highly optimized for single node performance or
> performance on
> >>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or
> can be
> >>>>> batched in that way) the performance tends to fall off. Canny argue=
s
> for
> >>>>> hardware/software codesign and as such prefers machine
> configurations that
> >>>>> are quite different than what we find in most commodity cluster
> nodes -
> >>>>> e.g. 10 disk cahnnels and 4 GPUs.
> >>>>>
> >>>>> In contrast, MLlib was designed for horizontal scalability on
> commodity
> >>>>> clusters and works best on very big datasets - order of terabytes.
> >>>>>
> >>>>> For the most part, these projects developed concurrently to address
> >>>>> slightly different use cases. That said, there may be bits of
> BIDMach we
> >>>>> could repurpose for MLlib - keep in mind we need to be careful abou=
t
> >>>>> maintaining cross-language compatibility for our Java and
> Python-users,
> >>>>> though.
> >>>>>
> >>>>> - Evan
> >>>>>
> >>>>> [1] - http://arxiv.org/abs/1409.5402
> >>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
> >>>>>
> >>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
> >>>>> Hi Evan,
> >>>>>
> >>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do y=
ou
> >>>>> know what makes them faster than netlib-java?
> >>>>>
> >>>>> The same group has BIDMach library that implements machine learning=
.
> For
> >>>>> some examples they use Caffe convolutional neural network library
> owned by
> >>>>> another group in Berkeley. Could you elaborate on how these all
> might be
> >>>>> connected with Spark Mllib? If you take BIDMat for linear algebra
> why don=E2=80=99t
> >>>>> you take BIDMach for optimization and learning?
> >>>>>
> >>>>> Best regards, Alexander
> >>>>>
> >>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
> evan.sparks@gmail.com><mailto:
> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
> >>>>> Sent: Thursday, February 05, 2015 12:09 PM
> >>>>> To: Ulanov, Alexander
> >>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>>
> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>>
> >>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
> blas in
> >>>>> many cases.
> >>>>>
> >>>>> You might consider taking a look at the codepaths that BIDMat (
> >>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
> >>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
> optimizing
> >>>>> to make this work really fast from Scala. I've run it on my laptop
> and
> >>>>> compared to MKL and in certain cases it's 10x faster at matrix
> multiply.
> >>>>> There are a lot of layers of indirection here and you really want t=
o
> avoid
> >>>>> data copying as much as possible.
> >>>>>
> >>>>> We could also consider swapping out BIDMat for Breeze, but that
> would be
> >>>>> a big project and if we can figure out how to get breeze+cublas to
> >>>>> comparable performance that would be a big win.
> >>>>>
> >>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
> >>>>> Dear Spark developers,
> >>>>>
> >>>>> I am exploring how to make linear algebra operations faster within
> Spark.
> >>>>> One way of doing this is to use Scala Breeze library that is bundle=
d
> with
> >>>>> Spark. For matrix operations, it employs Netlib-java that has a Jav=
a
> >>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK nati=
ve
> >>>>> binaries if they are available on the worker node. It also has its
> own
> >>>>> optimized Java implementation of BLAS. It is worth mentioning, that
> native
> >>>>> binaries provide better performance only for BLAS level 3, i.e.
> >>>>> matrix-matrix operations or general matrix multiplication (GEMM).
> This is
> >>>>> confirmed by GEMM test on Netlib-java page
> >>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
> >>>>> experiments with training of artificial neural network
> >>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
> >>>>> However, I would like to boost performance more.
> >>>>>
> >>>>> GPU is supposed to work fast with linear algebra and there is Nvidi=
a
> CUDA
> >>>>> implementation of BLAS, called cublas. I have one Linux server with
> Nvidia
> >>>>> GPU and I was able to do the following. I linked cublas (instead of
> >>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
> >>>>> Breeze/Netlib is using it. Then I did some performance measurements
> with
> >>>>> regards to artificial neural network batch learning in Spark MLlib
> that
> >>>>> involves matrix-matrix multiplications. It turns out that for
> matrices of
> >>>>> size less than ~1000x780 GPU cublas has the same speed as CPU blas.
> Cublas
> >>>>> becomes slower for bigger matrices. It worth mentioning that it is
> was not
> >>>>> a test for ONLY multiplication since there are other operations
> involved.
> >>>>> One of the reasons for slowdown might be the overhead of copying th=
e
> >>>>> matrices from computer memory to graphic card memory and back.
> >>>>>
> >>>>> So, few questions:
> >>>>> 1) Do these results with CUDA make sense?
> >>>>> 2) If the problem is with copy overhead, are there any libraries th=
at
> >>>>> allow to force intermediate results to stay in graphic card memory
> thus
> >>>>> removing the overhead?
> >>>>> 3) Any other options to speed-up linear algebra in Spark?
> >>>>>
> >>>>> Thank you, Alexander
> >>>>>
> >>>>> -------------------------------------------------------------------=
--
> >>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org><mailto:
> >>>>> dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>><mailto:dev-unsubscribe@spark.apache.or=
g
> <mailto:dev-unsubscribe@spark.apache.org>
> >>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>>>
> >>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
> dev-help@spark.apache.org><mailto:
> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto=
:
> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>
> >
> > --
> > Best regards,
> > Sam
> >
>

--047d7bdca5b6e12a6d05100c3d07--

From dev-return-11807-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 07:12:30 2015
Return-Path: <dev-return-11807-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4FBE8101A3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 07:12:30 +0000 (UTC)
Received: (qmail 4594 invoked by uid 500); 27 Feb 2015 07:12:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4508 invoked by uid 500); 27 Feb 2015 07:12:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4409 invoked by uid 99); 27 Feb 2015 07:12:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 07:12:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of freeman.jeremy@gmail.com designates 209.85.192.46 as permitted sender)
Received: from [209.85.192.46] (HELO mail-qg0-f46.google.com) (209.85.192.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 07:12:02 +0000
Received: by mail-qg0-f46.google.com with SMTP id z107so12731710qgd.5
        for <dev@spark.apache.org>; Thu, 26 Feb 2015 23:11:16 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=ec53W5TUU/IlImiiLucE6mTr6CAfHmk5NQs0jju42ak=;
        b=HFegzWH1pF6FC8hVzwL8kuroSQ4GvFkNhVB+fu/IJi0cgkiods+xX0rBhQgJcervWb
         RNo8h9VSfOIqiQKCY0oPL6RaZ0aoFU65al4Vhxm3KbTD1eKH86qlgxJxBmdLsSpAQwKM
         UxEksNzmsQJcWc4mVj7XIHWGXCd4wyBd95VbSSVtEeeaGWw7UG3E8e0SW7oeOcfQGUnF
         Hm4uYwrImKPGyezzkjZHY1weJxcrBvkP9v4JHQgfas58M8OblNDNUHP4YvkpIhPaIm6n
         cNkDpqEIemN+qdp7OLqRmmgv/BgGAnsjHjKPx1hJzVG9cPnCr5ILS/70BwWO3ujARcAk
         KjMA==
X-Received: by 10.140.29.4 with SMTP id a4mr22753618qga.106.1425021076139;
        Thu, 26 Feb 2015 23:11:16 -0800 (PST)
Received: from solaire.home (pool-173-72-150-2.clppva.fios.verizon.net. [173.72.150.2])
        by mx.google.com with ESMTPSA id g51sm2145333qgg.23.2015.02.26.23.11.14
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 26 Feb 2015 23:11:15 -0800 (PST)
Content-Type: multipart/alternative; boundary="Apple-Mail=_12E4666A-BBC9-46EF-ABCB-ABAACB090EDC"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Google Summer of Code - ideas
From: Jeremy Freeman <freeman.jeremy@gmail.com>
In-Reply-To: <CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com>
Date: Fri, 27 Feb 2015 02:11:13 -0500
Cc: Manoj Kumar <manojkumarsivaraj334@gmail.com>,
 dev <dev@spark.apache.org>
Message-Id: <BC0324FE-7612-42B6-82DB-38CD30E48A75@gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com> <CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com> <CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com> <CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_12E4666A-BBC9-46EF-ABCB-ABAACB090EDC
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

For topic #4 (streaming ML in Python), there=92s an existing JIRA, but =
progress seems to have stalled. I=92d be happy to help if you want to =
pick it up!

https://issues.apache.org/jira/browse/SPARK-4127

-------------------------
jeremyfreeman.net
@thefreemanlab

On Feb 26, 2015, at 4:20 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> There are couple things in Scala/Java but missing in Python API:
>=20
> 1. model import/export
> 2. evaluation metrics
> 3. distributed linear algebra
> 4. streaming algorithms
>=20
> If you are interested, we can list/create target JIRAs and hunt them
> down one by one.
>=20
> Best,
> Xiangrui
>=20
> On Wed, Feb 25, 2015 at 7:37 PM, Manoj Kumar
> <manojkumarsivaraj334@gmail.com> wrote:
>> Hi,
>>=20
>> I think that would be really good. Are there any specific issues that =
are to
>> be implemented as per priority?
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


--Apple-Mail=_12E4666A-BBC9-46EF-ABCB-ABAACB090EDC--

From dev-return-11808-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 19:10:48 2015
Return-Path: <dev-return-11808-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4FBE610148
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 19:10:48 +0000 (UTC)
Received: (qmail 36826 invoked by uid 500); 27 Feb 2015 19:10:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36756 invoked by uid 500); 27 Feb 2015 19:10:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36745 invoked by uid 99); 27 Feb 2015 19:10:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:10:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of irashid@cloudera.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:10:41 +0000
Received: by wgha1 with SMTP id a1so22272272wgh.5
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 11:10:20 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=hSLFIMxODlb3Kfoxdi7gCaXx5sAZDE9xmvKk1BT8Yjk=;
        b=aTt3yldR3M6F/F+qwgkSu8379PHK4v7gTPrwPz+Au5z1+0So1nALxbcr5dkXYt6HK/
         e6FaEjAH1Dr6QKSBaxrQbR5pGTvYeIoPjzw25ygiIxFEhK9yS/NqiXJmDPliT+zutBzt
         ZFZNW+ASIGVMJPW/VrXV2h1/V4K65S1P9/7GxtF60ZBX4z5irb2PzAcesDqVD7RsKBZx
         kwFcN4aweAEwk/m18WftaojgjrGIh3UjrsEzfDm+wl3+WB9KsKjB568XpJhGz40KGTjI
         6KCfWn4/d6+MUi0vytEgOiXKWr0Q8Kc/Nsz5OqBjjunuUW+BLH5ZpBpP/kfouW2xZR5V
         JdWg==
X-Gm-Message-State: ALoCoQnk0IXpOJkBrabwFJD0UiMUiU5xftiXjRbRw7XRsCOa1aKkz2bh8v1E0BzKswyeaF1cgHTP
X-Received: by 10.194.234.40 with SMTP id ub8mr31463733wjc.100.1425064220205;
 Fri, 27 Feb 2015 11:10:20 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.200.134 with HTTP; Fri, 27 Feb 2015 11:10:00 -0800 (PST)
From: Imran Rashid <irashid@cloudera.com>
Date: Fri, 27 Feb 2015 13:10:00 -0600
Message-ID: <CA+3qhFQ6kB6FwVB2UA7RLBHx3Nvv5QLB92+y5uWT3bCv_src2g@mail.gmail.com>
Subject: trouble with sbt building network-* projects?
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493c7ca0bee80510169e37
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493c7ca0bee80510169e37
Content-Type: text/plain; charset=UTF-8

Has anyone else noticed very strange build behavior in the network-*
projects?

maven seems to the doing the right, but sbt is very inconsistent.
Sometimes when it builds network-shuffle it doesn't know about any of the
code in network-common.  Sometimes it will completely skip the java unit
tests.  And then some time later, it'll suddenly decide it knows about some
more of the java unit tests.  Its not from a simple change, like touching a
test file, or a file the test depends on -- nor a restart of sbt.  I am
pretty confused.


maven had issues when I tried to add scala code to network-common, it would
compile the scala code but not make it available to java.  I'm working
around that by just coding in java anyhow.  I'd really like to be able to
run my tests in sbt, though, it makes the development iterations much
faster.

thanks,
Imran

--089e01493c7ca0bee80510169e37--

From dev-return-11809-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 19:15:37 2015
Return-Path: <dev-return-11809-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 77F2F10180
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 19:15:37 +0000 (UTC)
Received: (qmail 48571 invoked by uid 500); 27 Feb 2015 19:15:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48513 invoked by uid 500); 27 Feb 2015 19:15:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48500 invoked by uid 99); 27 Feb 2015 19:15:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:15:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:15:08 +0000
Received: by igbhl2 with SMTP id hl2so2955631igb.5
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 11:14:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=mgl10Jjt/ii04hgnwPCCCCcMimbUsA4IN8SjOZJpyYw=;
        b=vL04t/wMIK5nlmS5m2Fn4jSDvhS2U4+ks/d06At2mbmCXo2alIqIghcoJ/FjQw8clC
         oQ67pueXzdQOVkZ3azp0vZnHEOdK0XlaipuY/d7WszNyvblYLelcQBg5Jz39qeV6gm85
         0GCQqHtANBfN+77/vBiLhaEUwgN0D4IlbhXJh643DT/79ZGcxpFMJCww6q1qcEuJHsLE
         AG5bLjVDDqbAQAoKqUt6e72NcOWWtTkX7VHt9DFa2xHb0wadF2hUKHooXNV30PnnL9j5
         MX7wuM+wWS/io730PiRhDa/a3L9+PoWQlnYNSVsCx612lvqOcQeTO2LXzjpXkPDjmwfu
         lYyQ==
MIME-Version: 1.0
X-Received: by 10.42.210.20 with SMTP id gi20mr17434417icb.34.1425064460979;
 Fri, 27 Feb 2015 11:14:20 -0800 (PST)
Received: by 10.36.53.82 with HTTP; Fri, 27 Feb 2015 11:14:20 -0800 (PST)
In-Reply-To: <CA+3qhFQ6kB6FwVB2UA7RLBHx3Nvv5QLB92+y5uWT3bCv_src2g@mail.gmail.com>
References: <CA+3qhFQ6kB6FwVB2UA7RLBHx3Nvv5QLB92+y5uWT3bCv_src2g@mail.gmail.com>
Date: Fri, 27 Feb 2015 11:14:20 -0800
Message-ID: <CALte62wKU=FuH+MWHA5UkNi-FA+uqnECuJ7VwmHtiac5sjNagA@mail.gmail.com>
Subject: Re: trouble with sbt building network-* projects?
From: Ted Yu <yuzhihong@gmail.com>
To: Imran Rashid <irashid@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf30434da0fa965e051016ac53
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf30434da0fa965e051016ac53
Content-Type: text/plain; charset=UTF-8

bq. to be able to run my tests in sbt, though, it makes the development
iterations much faster.

Was the preference for sbt due to long maven build time ?
Have you started Zinc on your machine ?

Cheers

On Fri, Feb 27, 2015 at 11:10 AM, Imran Rashid <irashid@cloudera.com> wrote:

> Has anyone else noticed very strange build behavior in the network-*
> projects?
>
> maven seems to the doing the right, but sbt is very inconsistent.
> Sometimes when it builds network-shuffle it doesn't know about any of the
> code in network-common.  Sometimes it will completely skip the java unit
> tests.  And then some time later, it'll suddenly decide it knows about some
> more of the java unit tests.  Its not from a simple change, like touching a
> test file, or a file the test depends on -- nor a restart of sbt.  I am
> pretty confused.
>
>
> maven had issues when I tried to add scala code to network-common, it would
> compile the scala code but not make it available to java.  I'm working
> around that by just coding in java anyhow.  I'd really like to be able to
> run my tests in sbt, though, it makes the development iterations much
> faster.
>
> thanks,
> Imran
>

--20cf30434da0fa965e051016ac53--

From dev-return-11810-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 19:33:18 2015
Return-Path: <dev-return-11810-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A08D1027A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 19:33:18 +0000 (UTC)
Received: (qmail 7227 invoked by uid 500); 27 Feb 2015 19:32:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7146 invoked by uid 500); 27 Feb 2015 19:32:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7134 invoked by uid 99); 27 Feb 2015 19:32:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:32:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of irashid@cloudera.com designates 209.85.212.172 as permitted sender)
Received: from [209.85.212.172] (HELO mail-wi0-f172.google.com) (209.85.212.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 19:32:30 +0000
Received: by wiwl15 with SMTP id l15so2566610wiw.5
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 11:31:43 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=E/NfmvP1X/vPHdBNj+SxbWQkn412mQcmRJYVZZSq+MA=;
        b=kiUEmhqqSFAI5bSySN6F1W7uk2vOq/dZNXOi2alDh1DbX181kK1totZ+QvdrVupZxn
         D/gvkPKD5XHJlgiOVx57zZmtAIi/rdMFwkPXcxTKAN8ianLsXfU7JtUTdiRg00+Nd87z
         IKKisqCA0zxCKsX2VYN4fraoToHhHO6H69GVYtIUnVMxeakeiRFwwbL7TcRnCfB5XTBV
         r0d51j6jHDkpGgp9+g4Oh2SoBscTZxyd86gx+ZxdtUBRTdmFof6YVOoz34poi385e2Zf
         kLwOQfORpqdK7irjLi6qqN0/iOKWLGts6AFXN5ySRKsdJnb2+Qx28a3lSu7+XPjgxhjn
         84cw==
X-Gm-Message-State: ALoCoQkxMktWVfThGTXjDCjCBIzD6DXoilC1Y/Ms7zMwJ7qO3oTtG53jqzFwNYsSddCGhA6hi2s3
X-Received: by 10.180.106.225 with SMTP id gx1mr9693058wib.53.1425065503641;
 Fri, 27 Feb 2015 11:31:43 -0800 (PST)
MIME-Version: 1.0
Received: by 10.27.200.134 with HTTP; Fri, 27 Feb 2015 11:31:23 -0800 (PST)
In-Reply-To: <CALte62wKU=FuH+MWHA5UkNi-FA+uqnECuJ7VwmHtiac5sjNagA@mail.gmail.com>
References: <CA+3qhFQ6kB6FwVB2UA7RLBHx3Nvv5QLB92+y5uWT3bCv_src2g@mail.gmail.com>
 <CALte62wKU=FuH+MWHA5UkNi-FA+uqnECuJ7VwmHtiac5sjNagA@mail.gmail.com>
From: Imran Rashid <irashid@cloudera.com>
Date: Fri, 27 Feb 2015 13:31:23 -0600
Message-ID: <CA+3qhFT8mNQsstNRyRoXJ+D2S2YL7ZPRi52ruRrBmgOStQb8Wg@mail.gmail.com>
Subject: Re: trouble with sbt building network-* projects?
To: Ted Yu <yuzhihong@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f3ba6392069b3051016eb50
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f3ba6392069b3051016eb50
Content-Type: text/plain; charset=UTF-8

well, perhaps I just need to learn to use maven better, but currently I
find sbt much more convenient for continuously running my tests.  I do use
zinc, but I'm looking for continuous testing.  This makes me think I need
sbt for that:
http://stackoverflow.com/questions/11347633/is-there-a-java-continuous-testing-plugin-for-maven

1) I really like that in sbt I can run "~test-only
com.foo.bar.SomeTestSuite" (or whatever other pattern) and just leave that
running as I code, without having to go and explicitly trigger "mvn test"
and wait for the result.

2) I find sbt's handling of sub-projects much simpler (when it works).  I'm
trying to make changes to network/common & network/shuffle, which means I
have to keep cd'ing into network/common, run mvn install, then go back to
network/shuffle and run some other mvn command over there.  I don't want to
run mvn at the root project level, b/c I don't want to wait for it to
compile all the other projects when I just want to run tests in
network/common.  Even with incremental compiling, in my day-to-day coding I
want to entirely skip compiling sql, graphx, mllib etc. -- I have to switch
branches often enough that i end up triggering a full rebuild of those
projects even when I haven't touched them.





On Fri, Feb 27, 2015 at 1:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> bq. to be able to run my tests in sbt, though, it makes the development
> iterations much faster.
>
> Was the preference for sbt due to long maven build time ?
> Have you started Zinc on your machine ?
>
> Cheers
>
> On Fri, Feb 27, 2015 at 11:10 AM, Imran Rashid <irashid@cloudera.com>
> wrote:
>
>> Has anyone else noticed very strange build behavior in the network-*
>> projects?
>>
>> maven seems to the doing the right, but sbt is very inconsistent.
>> Sometimes when it builds network-shuffle it doesn't know about any of the
>> code in network-common.  Sometimes it will completely skip the java unit
>> tests.  And then some time later, it'll suddenly decide it knows about
>> some
>> more of the java unit tests.  Its not from a simple change, like touching
>> a
>> test file, or a file the test depends on -- nor a restart of sbt.  I am
>> pretty confused.
>>
>>
>> maven had issues when I tried to add scala code to network-common, it
>> would
>> compile the scala code but not make it available to java.  I'm working
>> around that by just coding in java anyhow.  I'd really like to be able to
>> run my tests in sbt, though, it makes the development iterations much
>> faster.
>>
>> thanks,
>> Imran
>>
>
>

--e89a8f3ba6392069b3051016eb50--

From dev-return-11811-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 20:27:01 2015
Return-Path: <dev-return-11811-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E54B01052F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 20:27:01 +0000 (UTC)
Received: (qmail 58721 invoked by uid 500); 27 Feb 2015 20:26:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58630 invoked by uid 500); 27 Feb 2015 20:26:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58614 invoked by uid 99); 27 Feb 2015 20:26:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 20:26:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 20:26:43 +0000
Received: by igjz20 with SMTP id z20so3506107igj.4
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 12:26:23 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=KLjlyw6ybolqe04mUGm8qmnsaTKTUD2QXOCtbG9VOs4=;
        b=g8dzPTNZ4tYGKkZqvhjT2wEI8FnU6AKtX+iA2KQLU+u9W+DhuETxV9Tmy6/1izXiI1
         obXuNVBAu6t5J1J2tzNO25BumhdqSP2232f6jWKgDrpom90B785KSjyC7vn1JyJHS3/5
         G28dE8/cMMchxsqkqn0fZHFUbX8x/P3qE4zsGQDEnNml7JnDVcms0VwEwJZKmlR9RtMm
         s/Hi6t07KRLwQjDzVf6whdlMNs/wHKmcEkWGdCmzlN2iLe8/QRGOTYcWEtn+nwyM+Xvo
         E+fIhPwVi7yoeiZMqG3Rh568LFr14nCDqWK7QCLDyX5N3KB54x4zUkiW2xFwxf0tn4TV
         RqxQ==
MIME-Version: 1.0
X-Received: by 10.50.137.99 with SMTP id qh3mr572729igb.9.1425068783083; Fri,
 27 Feb 2015 12:26:23 -0800 (PST)
Received: by 10.36.69.31 with HTTP; Fri, 27 Feb 2015 12:26:22 -0800 (PST)
In-Reply-To: <CALR_T9BsNT9SBAveH7z+Aw-CYB+NFPxGH0Rm_JNsjHu+RhMqsQ@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
	<CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
	<87ioeo5n6e.fsf@gmail.com>
	<CAJgQjQ9q2wEu-URc6OkNf+rVriX+FDcViSBM-die2HyCpRC=-A@mail.gmail.com>
	<CALR_T9BsNT9SBAveH7z+Aw-CYB+NFPxGH0Rm_JNsjHu+RhMqsQ@mail.gmail.com>
Date: Fri, 27 Feb 2015 12:26:22 -0800
Message-ID: <CAJgQjQ8e8S4sdbZ+bPnDS7TsOthX2zv89707W2r7FVDsf4n9ZQ@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Xiangrui Meng <mengxr@gmail.com>
To: Sam Halliday <sam.halliday@gmail.com>
Cc: dev <dev@spark.apache.org>, Joseph Bradley <joseph@databricks.com>, 
	"Ulanov, Alexander" <alexander.ulanov@hp.com>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Sam,

The running times are not "big O" estimates:

> The CPU version finished in 12 seconds.
> The CPU->GPU->CPU version finished in 2.2 seconds.
> The GPU version finished in 1.7 seconds.

I think there is something wrong with the netlib/cublas combination.
Sam already mentioned that cuBLAS doesn't implement the CPU BLAS
interfaces. I checked the CUDA doc and it seems that to use GPU BLAS
through the CPU BLAS interface we need to use NVBLAS, which intercepts
some Level 3 CPU BLAS calls (including GEMM). So we need to load
nvblas.so first and then some CPU BLAS library in JNI. I wonder
whether the setup was correct.

Alexander, could you check whether GPU is used in the netlib-cublas
experiments? You can tell it by watching CPU/GPU usage.

Best,
Xiangrui

On Thu, Feb 26, 2015 at 10:47 PM, Sam Halliday <sam.halliday@gmail.com> wro=
te:
> Don't use "big O" estimates, always measure. It used to work back in the
> days when double multiplication was a bottleneck. The computation cost is
> effectively free on both the CPU and GPU and you're seeing pure copying
> costs. Also, I'm dubious that cublas is doing what you think it is. Can y=
ou
> link me to the source code for DGEMM?
>
> I show all of this in my talk, with explanations, I can't stress enough h=
ow
> much I recommend that you watch it if you want to understand high
> performance hardware acceleration for linear algebra :-)
>
> On 27 Feb 2015 01:42, "Xiangrui Meng" <mengxr@gmail.com> wrote:
>>
>> The copying overhead should be quadratic on n, while the computation
>> cost is cubic on n. I can understand that netlib-cublas is slower than
>> netlib-openblas on small problems. But I'm surprised to see that it is
>> still 20x slower on 10000x10000. I did the following on a g2.2xlarge
>> instance with BIDMat:
>>
>> val n =3D 10000
>>
>> val f =3D rand(n, n)
>> flip; f*f; val rf =3D flop
>>
>> flip; val g =3D GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val rg =
=3D flop
>>
>> flip; g*g; val rgg =3D flop
>>
>> The CPU version finished in 12 seconds.
>> The CPU->GPU->CPU version finished in 2.2 seconds.
>> The GPU version finished in 1.7 seconds.
>>
>> I'm not sure whether my CPU->GPU->CPU code simulates the netlib-cublas
>> path. But based on the result, the data copying overhead is definitely
>> not as big as 20x at n =3D 10000.
>>
>> Best,
>> Xiangrui
>>
>>
>> On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday <sam.halliday@gmail.com>
>> wrote:
>> > I've had some email exchanges with the author of BIDMat: it does exact=
ly
>> > what you need to get the GPU benefit and writes higher level algorithm=
s
>> > entirely in the GPU kernels so that the memory stays there as long as
>> > possible. The restriction with this approach is that it is only offeri=
ng
>> > high-level algorithms so is not a toolkit for applied mathematics
>> > research and development --- but it works well as a toolkit for higher
>> > level analysis (e.g. for analysts and practitioners).
>> >
>> > I believe BIDMat's approach is the best way to get performance out of
>> > GPU hardware at the moment but I also have strong evidence to suggest
>> > that the hardware will catch up and the memory transfer costs between
>> > CPU/GPU will disappear meaning that there will be no need for custom G=
PU
>> > kernel implementations. i.e. please continue to use BLAS primitives wh=
en
>> > writing new algorithms and only go to the GPU for an alternative
>> > optimised implementation.
>> >
>> > Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, and offe=
r
>> > an API that looks like BLAS but takes pointers to special regions in t=
he
>> > GPU memory region. Somebody has written a wrapper around CUDA to creat=
e
>> > a proper BLAS library but it only gives marginal performance over the
>> > CPU because of the memory transfer overhead.
>> >
>> > This slide from my talk
>> >
>> >   http://fommil.github.io/scalax14/#/11/2
>> >
>> > says it all. X axis is matrix size, Y axis is logarithmic time to do
>> > DGEMM. Black line is the "cheating" time for the GPU and the green lin=
e
>> > is after copying the memory to/from the GPU memory. APUs have the
>> > potential to eliminate the green line.
>> >
>> > Best regards,
>> > Sam
>> >
>> >
>> >
>> > "Ulanov, Alexander" <alexander.ulanov@hp.com> writes:
>> >
>> >> Evan, thank you for the summary. I would like to add some more
>> >> observations. The GPU that I used is 2.5 times cheaper than the CPU (=
$250 vs
>> >> $100). They both are 3 years old. I've also did a small test with mod=
ern
>> >> hardware, and the new GPU nVidia Titan was slightly more than 1 order=
 of
>> >> magnitude faster than Intel E5-2650 v2 for the same tests. However, i=
t costs
>> >> as much as CPU ($1200). My takeaway is that GPU is making a better
>> >> price/value progress.
>> >>
>> >>
>> >>
>> >> Xiangrui, I was also surprised that BIDMat-cuda was faster than
>> >> netlib-cuda and the most reasonable explanation is that it holds the =
result
>> >> in GPU memory, as Sam suggested. At the same time, it is OK because y=
ou can
>> >> copy the result back from GPU only when needed. However, to be sure, =
I am
>> >> going to ask the developer of BIDMat on his upcoming talk.
>> >>
>> >>
>> >>
>> >> Best regards, Alexander
>> >>
>> >>
>> >> From: Sam Halliday [mailto:sam.halliday@gmail.com]
>> >> Sent: Thursday, February 26, 2015 1:56 PM
>> >> To: Xiangrui Meng
>> >> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R.
>> >> Sparks
>> >> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>
>> >>
>> >> Btw, I wish people would stop cheating when comparing CPU and GPU
>> >> timings for things like matrix multiply :-P
>> >>
>> >> Please always compare apples with apples and include the time it take=
s
>> >> to set up the matrices, send it to the processing unit, doing the
>> >> calculation AND copying it back to where you need to see the results.
>> >>
>> >> Ignoring this method will make you believe that your GPU is thousands
>> >> of times faster than it really is. Again, jump to the end of my talk =
for
>> >> graphs and more discussion....  especially the bit about me being kee=
n on
>> >> funding to investigate APU hardware further ;-) (I believe it will so=
lve the
>> >> problem)
>> >> On 26 Feb 2015 21:16, "Xiangrui Meng"
>> >> <mengxr@gmail.com<mailto:mengxr@gmail.com>> wrote:
>> >> Hey Alexander,
>> >>
>> >> I don't quite understand the part where netlib-cublas is about 20x
>> >> slower than netlib-openblas. What is the overhead of using a GPU BLAS
>> >> with netlib-java?
>> >>
>> >> CC'ed Sam, the author of netlib-java.
>> >>
>> >> Best,
>> >> Xiangrui
>> >>
>> >> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley
>> >> <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> >>> Better documentation for linking would be very helpful!  Here's a
>> >>> JIRA:
>> >>> https://issues.apache.org/jira/browse/SPARK-6019
>> >>>
>> >>>
>> >>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks
>> >>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> >>> wrote:
>> >>>
>> >>>> Thanks for compiling all the data and running these benchmarks, Ale=
x.
>> >>>> The
>> >>>> big takeaways here can be seen with this chart:
>> >>>>
>> >>>>
>> >>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50u=
ZHl6kmAJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
>> >>>>
>> >>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>> >>>> BIDMat+GPU) can provide substantial (but less than an order of
>> >>>> magnitude)
>> >>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>> >>>> netlib-java+openblas-compiled).
>> >>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
>> >>>> worse
>> >>>> than a well-tuned CPU implementation, particularly for larger
>> >>>> matrices.
>> >>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>> >>>> basically agrees with the authors own benchmarks (
>> >>>> https://github.com/fommil/netlib-java)
>> >>>>
>> >>>> I think that most of our users are in a situation where using GPUs
>> >>>> may not
>> >>>> be practical - although we could consider having a good GPU backend
>> >>>> available as an option. However, *ALL* users of MLlib could benefit
>> >>>> (potentially tremendously) from using a well-tuned CPU-based BLAS
>> >>>> implementation. Perhaps we should consider updating the mllib guide
>> >>>> with a
>> >>>> more complete section for enabling high performance binaries on OSX
>> >>>> and
>> >>>> Linux? Or better, figure out a way for the system to fetch these
>> >>>> automatically.
>> >>>>
>> >>>> - Evan
>> >>>>
>> >>>>
>> >>>>
>> >>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>>>
>> >>>>> Just to summarize this thread, I was finally able to make all
>> >>>>> performance
>> >>>>> comparisons that we discussed. It turns out that:
>> >>>>> BIDMat-cublas>>BIDMat
>> >>>>>
>> >>>>> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-=
yum-repo=3D=3Dnetlib-cublas>netlib-blas>f2jblas
>> >>>>>
>> >>>>> Below is the link to the spreadsheet with full results.
>> >>>>>
>> >>>>>
>> >>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUM=
x378T9J5r7kwKSPkY/edit?usp=3Dsharing
>> >>>>>
>> >>>>> One thing still needs exploration: does BIDMat-cublas perform
>> >>>>> copying
>> >>>>> to/from machine=E2=80=99s RAM?
>> >>>>>
>> >>>>> -----Original Message-----
>> >>>>> From: Ulanov, Alexander
>> >>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>> >>>>> To: Evan R. Sparks
>> >>>>> Cc: Joseph Bradley;
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> Thanks, Evan! It seems that ticket was marked as duplicate though
>> >>>>> the
>> >>>>> original one discusses slightly different topic. I was able to lin=
k
>> >>>>> netlib
>> >>>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked
>> >>>>> inside a
>> >>>>> 60MB library.
>> >>>>>
>> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>> >>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>> >>>>>
>> >>>>> +-----------------------------------------------------------------=
------+
>> >>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>> >>>>> |1,638475459 |
>> >>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 =
|
>> >>>>> 1569,233228 |
>> >>>>>
>> >>>>> It turn out that pre-compiled MKL is faster than precompiled
>> >>>>> OpenBlas on
>> >>>>> my machine. Probably, I=E2=80=99ll add two more columns with local=
ly
>> >>>>> compiled
>> >>>>> openblas and cuda.
>> >>>>>
>> >>>>> Alexander
>> >>>>>
>> >>>>> From: Evan R. Sparks
>> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>> >>>>> Sent: Monday, February 09, 2015 6:06 PM
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc: Joseph Bradley;
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> Great - perhaps we can move this discussion off-list and onto a JI=
RA
>> >>>>> ticket? (Here's one:
>> >>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>> >>>>>
>> >>>>> It seems like this is going to be somewhat exploratory for a while
>> >>>>> (and
>> >>>>> there's probably only a handful of us who really care about fast
>> >>>>> linear
>> >>>>> algebra!)
>> >>>>>
>> >>>>> - Evan
>> >>>>>
>> >>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >>>>> wrote:
>> >>>>> Hi Evan,
>> >>>>>
>> >>>>> Thank you for explanation and useful link. I am going to build
>> >>>>> OpenBLAS,
>> >>>>> link it with Netlib-java and perform benchmark again.
>> >>>>>
>> >>>>> Do I understand correctly that BIDMat binaries contain statically
>> >>>>> linked
>> >>>>> Intel MKL BLAS? It might be the reason why I am able to run BIDMat
>> >>>>> not
>> >>>>> having MKL BLAS installed on my server. If it is true, I wonder if
>> >>>>> it is OK
>> >>>>> because Intel sells this library. Nevertheless, it seems that in m=
y
>> >>>>> case
>> >>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS giv=
en
>> >>>>> that
>> >>>>> BIDMat and Netlib-java are supposed to be on par with JNI overhead=
s.
>> >>>>>
>> >>>>> Though, it might be interesting to link Netlib-java with Intel MKL=
,
>> >>>>> as
>> >>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>> >>>>> (Netlib-java) interested to compare their libraries.
>> >>>>>
>> >>>>> Best regards, Alexander
>> >>>>>
>> >>>>> From: Evan R. Sparks
>> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto=
:
>> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>>> Sent: Friday, February 06, 2015 5:58 PM
>> >>>>>
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc: Joseph Bradley;
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> I would build OpenBLAS yourself, since good BLAS performance comes
>> >>>>> from
>> >>>>> getting cache sizes, etc. set up correctly for your particular
>> >>>>> hardware -
>> >>>>> this is often a very tricky process (see, e.g. ATLAS), but we foun=
d
>> >>>>> that on
>> >>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>> >>>>> performance competitive with MKL.
>> >>>>>
>> >>>>> To make sure the right library is getting used, you have to make
>> >>>>> sure
>> >>>>> it's first on the search path - export
>> >>>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick here.
>> >>>>>
>> >>>>> For some examples of getting netlib-java setup on an ec2 node and
>> >>>>> some
>> >>>>> example benchmarking code we ran a while back, see:
>> >>>>> https://github.com/shivaram/matrix-bench
>> >>>>>
>> >>>>> In particular - build-openblas-ec2.sh shows you how to build the
>> >>>>> library
>> >>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you h=
ow
>> >>>>> to get
>> >>>>> the path setup and get that library picked up by netlib-java.
>> >>>>>
>> >>>>> In this way - you could probably get cuBLAS set up to be used by
>> >>>>> netlib-java as well.
>> >>>>>
>> >>>>> - Evan
>> >>>>>
>> >>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >>>>> wrote:
>> >>>>> Evan, could you elaborate on how to force BIDMat and netlib-java t=
o
>> >>>>> force
>> >>>>> loading the right blas? For netlib, I there are few JVM flags, suc=
h
>> >>>>> as
>> >>>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBLAS=
, so
>> >>>>> I can
>> >>>>> force it to use Java implementation. Not sure I understand how to
>> >>>>> force use
>> >>>>> a specific blas (not specific wrapper for blas).
>> >>>>>
>> >>>>> Btw. I have installed openblas (yum install openblas), so I suppos=
e
>> >>>>> that
>> >>>>> netlib is using it.
>> >>>>>
>> >>>>> From: Evan R. Sparks
>> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto=
:
>> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>>> Sent: Friday, February 06, 2015 5:19 PM
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc: Joseph Bradley;
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>
>> >>>>>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> Getting breeze to pick up the right blas library is critical for
>> >>>>> performance. I recommend using OpenBLAS (or MKL, if you already ha=
ve
>> >>>>> it).
>> >>>>> It might make sense to force BIDMat to use the same underlying BLA=
S
>> >>>>> library
>> >>>>> as well.
>> >>>>>
>> >>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >>>>> wrote:
>> >>>>> Hi Evan, Joseph
>> >>>>>
>> >>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
>> >>>>> faster
>> >>>>> than netlib-java+breeze (sorry for weird table formatting):
>> >>>>>
>> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>> >>>>> native_system_linux_x86-64|
>> >>>>> Breeze+Netlib-java f2jblas |
>> >>>>>
>> >>>>> +-----------------------------------------------------------------=
------+
>> >>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>> >>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228=
 |
>> >>>>>
>> >>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedor=
a
>> >>>>> 19
>> >>>>> Linux, Scala 2.11.
>> >>>>>
>> >>>>> Later I will make tests with Cuda. I need to install new Cuda
>> >>>>> version for
>> >>>>> this purpose.
>> >>>>>
>> >>>>> Do you have any ideas why breeze-netlib with native blas is so muc=
h
>> >>>>> slower than BIDMat MKL?
>> >>>>>
>> >>>>> Best regards, Alexander
>> >>>>>
>> >>>>> From: Joseph Bradley
>> >>>>> [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto=
:
>> >>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>> >>>>> Sent: Thursday, February 05, 2015 5:29 PM
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc: Evan R. Sparks;
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> Hi Alexander,
>> >>>>>
>> >>>>> Using GPUs with Spark would be very exciting.  Small comment:
>> >>>>> Concerning
>> >>>>> your question earlier about keeping data stored on the GPU rather
>> >>>>> than
>> >>>>> having to move it between main memory and GPU memory on each
>> >>>>> iteration, I
>> >>>>> would guess this would be critical to getting good performance.  I=
f
>> >>>>> you
>> >>>>> could do multiple local iterations before aggregating results, the=
n
>> >>>>> the
>> >>>>> cost of data movement to the GPU could be amortized (and I believe
>> >>>>> that is
>> >>>>> done in practice).  Having Spark be aware of the GPU and using it =
as
>> >>>>> another part of memory sounds like a much bigger undertaking.
>> >>>>>
>> >>>>> Joseph
>> >>>>>
>> >>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >>>>> wrote:
>> >>>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach presen=
tation by
>> >>>>> John
>> >>>>> Canny and I am really inspired by his talk and comparisons with
>> >>>>> Spark MLlib.
>> >>>>>
>> >>>>> I am very interested to find out what will be better within Spark:
>> >>>>> BIDMat
>> >>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair w=
ay
>> >>>>> to
>> >>>>> benchmark them? Currently I do benchmarks on artificial neural
>> >>>>> networks in
>> >>>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of linea=
r algebra, it
>> >>>>> involves
>> >>>>> some other things that are essential to machine learning.
>> >>>>>
>> >>>>> From: Evan R. Sparks
>> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto=
:
>> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>>> Sent: Thursday, February 05, 2015 1:29 PM
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc:
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>> >>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due t=
o
>> >>>>> data
>> >>>>> layout and fewer levels of indirection - it's definitely a
>> >>>>> worthwhile
>> >>>>> experiment to run. The main speedups I've seen from using it come
>> >>>>> from
>> >>>>> highly optimized GPU code for linear algebra. I know that in the
>> >>>>> past Canny
>> >>>>> has gone as far as to write custom GPU kernels for
>> >>>>> performance-critical
>> >>>>> regions of code.[1]
>> >>>>>
>> >>>>> BIDMach is highly optimized for single node performance or
>> >>>>> performance on
>> >>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or
>> >>>>> can be
>> >>>>> batched in that way) the performance tends to fall off. Canny argu=
es
>> >>>>> for
>> >>>>> hardware/software codesign and as such prefers machine
>> >>>>> configurations that
>> >>>>> are quite different than what we find in most commodity cluster
>> >>>>> nodes -
>> >>>>> e.g. 10 disk cahnnels and 4 GPUs.
>> >>>>>
>> >>>>> In contrast, MLlib was designed for horizontal scalability on
>> >>>>> commodity
>> >>>>> clusters and works best on very big datasets - order of terabytes.
>> >>>>>
>> >>>>> For the most part, these projects developed concurrently to addres=
s
>> >>>>> slightly different use cases. That said, there may be bits of
>> >>>>> BIDMach we
>> >>>>> could repurpose for MLlib - keep in mind we need to be careful abo=
ut
>> >>>>> maintaining cross-language compatibility for our Java and
>> >>>>> Python-users,
>> >>>>> though.
>> >>>>>
>> >>>>> - Evan
>> >>>>>
>> >>>>> [1] - http://arxiv.org/abs/1409.5402
>> >>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>> >>>>>
>> >>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
>> >>>>> wrote:
>> >>>>> Hi Evan,
>> >>>>>
>> >>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do
>> >>>>> you
>> >>>>> know what makes them faster than netlib-java?
>> >>>>>
>> >>>>> The same group has BIDMach library that implements machine learnin=
g.
>> >>>>> For
>> >>>>> some examples they use Caffe convolutional neural network library
>> >>>>> owned by
>> >>>>> another group in Berkeley. Could you elaborate on how these all
>> >>>>> might be
>> >>>>> connected with Spark Mllib? If you take BIDMat for linear algebra
>> >>>>> why don=E2=80=99t
>> >>>>> you take BIDMach for optimization and learning?
>> >>>>>
>> >>>>> Best regards, Alexander
>> >>>>>
>> >>>>> From: Evan R. Sparks
>> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto=
:
>> >>>>>
>> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.s=
parks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>> >>>>> Sent: Thursday, February 05, 2015 12:09 PM
>> >>>>> To: Ulanov, Alexander
>> >>>>> Cc:
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>><mailto:
>> >>>>>
>> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark=
.apache.org<mailto:dev@spark.apache.org>>>
>> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>>
>> >>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
>> >>>>> blas in
>> >>>>> many cases.
>> >>>>>
>> >>>>> You might consider taking a look at the codepaths that BIDMat (
>> >>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>> >>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>> >>>>> optimizing
>> >>>>> to make this work really fast from Scala. I've run it on my laptop
>> >>>>> and
>> >>>>> compared to MKL and in certain cases it's 10x faster at matrix
>> >>>>> multiply.
>> >>>>> There are a lot of layers of indirection here and you really want =
to
>> >>>>> avoid
>> >>>>> data copying as much as possible.
>> >>>>>
>> >>>>> We could also consider swapping out BIDMat for Breeze, but that
>> >>>>> would be
>> >>>>> a big project and if we can figure out how to get breeze+cublas to
>> >>>>> comparable performance that would be a big win.
>> >>>>>
>> >>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >>>>>
>> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:ale=
xander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
>> >>>>> wrote:
>> >>>>> Dear Spark developers,
>> >>>>>
>> >>>>> I am exploring how to make linear algebra operations faster within
>> >>>>> Spark.
>> >>>>> One way of doing this is to use Scala Breeze library that is bundl=
ed
>> >>>>> with
>> >>>>> Spark. For matrix operations, it employs Netlib-java that has a Ja=
va
>> >>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK
>> >>>>> native
>> >>>>> binaries if they are available on the worker node. It also has its
>> >>>>> own
>> >>>>> optimized Java implementation of BLAS. It is worth mentioning, tha=
t
>> >>>>> native
>> >>>>> binaries provide better performance only for BLAS level 3, i.e.
>> >>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>> >>>>> This is
>> >>>>> confirmed by GEMM test on Netlib-java page
>> >>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>> >>>>> experiments with training of artificial neural network
>> >>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>> >>>>> However, I would like to boost performance more.
>> >>>>>
>> >>>>> GPU is supposed to work fast with linear algebra and there is Nvid=
ia
>> >>>>> CUDA
>> >>>>> implementation of BLAS, called cublas. I have one Linux server wit=
h
>> >>>>> Nvidia
>> >>>>> GPU and I was able to do the following. I linked cublas (instead o=
f
>> >>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, so
>> >>>>> Breeze/Netlib is using it. Then I did some performance measurement=
s
>> >>>>> with
>> >>>>> regards to artificial neural network batch learning in Spark MLlib
>> >>>>> that
>> >>>>> involves matrix-matrix multiplications. It turns out that for
>> >>>>> matrices of
>> >>>>> size less than ~1000x780 GPU cublas has the same speed as CPU blas=
.
>> >>>>> Cublas
>> >>>>> becomes slower for bigger matrices. It worth mentioning that it is
>> >>>>> was not
>> >>>>> a test for ONLY multiplication since there are other operations
>> >>>>> involved.
>> >>>>> One of the reasons for slowdown might be the overhead of copying t=
he
>> >>>>> matrices from computer memory to graphic card memory and back.
>> >>>>>
>> >>>>> So, few questions:
>> >>>>> 1) Do these results with CUDA make sense?
>> >>>>> 2) If the problem is with copy overhead, are there any libraries
>> >>>>> that
>> >>>>> allow to force intermediate results to stay in graphic card memory
>> >>>>> thus
>> >>>>> removing the overhead?
>> >>>>> 3) Any other options to speed-up linear algebra in Spark?
>> >>>>>
>> >>>>> Thank you, Alexander
>> >>>>>
>> >>>>>
>> >>>>> ------------------------------------------------------------------=
---
>> >>>>> To unsubscribe, e-mail:
>> >>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apac=
he.org><mailto:
>> >>>>>
>> >>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apac=
he.org>><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spa=
rk.apache.org>
>> >>>>>
>> >>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@sp=
ark.apache.org>>>
>> >>>>> For additional commands, e-mail:
>> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto=
:
>> >>>>>
>> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailt=
o:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>
>> >
>> > --
>> > Best regards,
>> > Sam
>> >

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-11812-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 20:33:27 2015
Return-Path: <dev-return-11812-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 978AD10571
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 20:33:27 +0000 (UTC)
Received: (qmail 81844 invoked by uid 500); 27 Feb 2015 20:33:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81768 invoked by uid 500); 27 Feb 2015 20:33:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81756 invoked by uid 99); 27 Feb 2015 20:33:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 20:33:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sam.halliday@gmail.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 20:33:21 +0000
Received: by iecrd18 with SMTP id rd18so33968231iec.5
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 12:33:00 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=kRjbwgKyx4K67zcSrToOjWieh15puOIZQK6fZnzO/Jw=;
        b=fRbqbjeDy6lG5EVLDZLirDzAqmIGG7TS7a3mIfXNC6+TiABxKOiqobzvKXzP1mb8x8
         w5bU0jvxO4JZl2qpZcYrSEQ1fV1pZGCLTupP+tlZtdKiehvPrdwt2BvnxM7PPOWfsxiP
         DrWAgFDGyRyMCTrXHKNA8L5TEgLHhleTQUZnvoqZfLp8E6omYUwkIj6mPz5uS+dj0SwQ
         EaK/hbUVqaDqd61MVQIJmp1LX/wQF6SdVGxSy3zpsZZYVGyzFBoxIkpIQZL5lXtneE9+
         sYT4GStDa1yflxkZcSRwSmAjhQwh0jqhsd74GG3UCB0FEl/sm4+3IcaJXC1ggacavPWM
         1VIA==
MIME-Version: 1.0
X-Received: by 10.50.124.73 with SMTP id mg9mr6736383igb.38.1425069180541;
 Fri, 27 Feb 2015 12:33:00 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Fri, 27 Feb 2015 12:33:00 -0800 (PST)
Received: by 10.36.39.70 with HTTP; Fri, 27 Feb 2015 12:33:00 -0800 (PST)
In-Reply-To: <CAJgQjQ8e8S4sdbZ+bPnDS7TsOthX2zv89707W2r7FVDsf4n9ZQ@mail.gmail.com>
References: <9D5B00849D2CDA4386BDA89E83F69E6C0FDEFB6F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6CWqUJkfrxmymVFzdsyrJTdHnnuFMka0dUYnaDaLvirg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFC2D@G4W3292.americas.hpqcorp.net>
	<CABjXkq61RorkGRJQMhnfHsAvQTOnBn6eGyiG=XsdX=q8uhVL9Q@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDEFDE2@G4W3292.americas.hpqcorp.net>
	<CAF7ADNq=LdkP14EjJNgYx=eWWwcpALw+B47WfEqV9PdYfNRgfg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF039F@G4W3292.americas.hpqcorp.net>
	<CABjXkq6eKSkb7iHV5Z7v=GMhMCJB_bwjyKFFHc-Y0i_5QTzeWg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF0451@G4W3292.americas.hpqcorp.net>
	<CABjXkq5oXFus=wYRQyA42UM2XUC8FVV1iLpTiOnbrtwUGO2RFA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF16BF@G4W3292.americas.hpqcorp.net>
	<CABjXkq47H8+4NqweLvq95hr0-CNZ74tM7TAkqwfH_phTMg7HOg@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF1D26@G4W3292.americas.hpqcorp.net>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FDF2B99@G4W3292.americas.hpqcorp.net>
	<CABjXkq5wrLT1Z-aT3mwsU9qpcHVw2fKq5XvUaXVJbJZpHHMg1g@mail.gmail.com>
	<CAF7ADNoG3R_G5Y3ESy6=L2Ck_b+KwKD1P08OUHEYRbjNiZUJPA@mail.gmail.com>
	<CAJgQjQ_AwWRWgy_nPs1+Z4MqB=HHwTGmFw7_2S+GvQw3n7SzJg@mail.gmail.com>
	<CALR_T9BJQZTP1jo98BrS3MicX+hXXmvUvDNhNUefO=AMXyALLA@mail.gmail.com>
	<9D5B00849D2CDA4386BDA89E83F69E6C0FE0314C@G9W0737.americas.hpqcorp.net>
	<87ioeo5n6e.fsf@gmail.com>
	<CAJgQjQ9q2wEu-URc6OkNf+rVriX+FDcViSBM-die2HyCpRC=-A@mail.gmail.com>
	<CALR_T9BsNT9SBAveH7z+Aw-CYB+NFPxGH0Rm_JNsjHu+RhMqsQ@mail.gmail.com>
	<CAJgQjQ8e8S4sdbZ+bPnDS7TsOthX2zv89707W2r7FVDsf4n9ZQ@mail.gmail.com>
Date: Fri, 27 Feb 2015 20:33:00 +0000
Message-ID: <CALR_T9A8ukiDZ4K+uaMvSSR+wFL9a5yHwEe4AV1JCG6GEG7qmQ@mail.gmail.com>
Subject: Re: Using CUDA within Spark / boosting linear algebra
From: Sam Halliday <sam.halliday@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Joseph Bradley <joseph@databricks.com>, Alexander Ulanov <alexander.ulanov@hp.com>, 
	dev <dev@spark.apache.org>, "Evan R. Sparks" <evan.sparks@gmail.com>
Content-Type: multipart/alternative; boundary=089e010d953249629b051017c626
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d953249629b051017c626
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Also, check the JNILoader output.

Remember, for netlib-java to use your system libblas all you need to do is
setup libblas.so.3 like any native application would expect.

I haven't ever used the cublas "real BLAS"  implementation, so I'd be
interested to hear about this. Do an 'ldd /usr/lib/libblas.so.3' to check
that all the runtime links are in order.

Btw, I have some DGEMM wrappers in my netlib-java performance module... and
I also planned to write more in MultiBLAS (until I mothballed the project
for the hardware to catch up, which is probably has and now I just need a
reason to look at it)
 On 27 Feb 2015 20:26, "Xiangrui Meng" <mengxr@gmail.com> wrote:

> Hey Sam,
>
> The running times are not "big O" estimates:
>
> > The CPU version finished in 12 seconds.
> > The CPU->GPU->CPU version finished in 2.2 seconds.
> > The GPU version finished in 1.7 seconds.
>
> I think there is something wrong with the netlib/cublas combination.
> Sam already mentioned that cuBLAS doesn't implement the CPU BLAS
> interfaces. I checked the CUDA doc and it seems that to use GPU BLAS
> through the CPU BLAS interface we need to use NVBLAS, which intercepts
> some Level 3 CPU BLAS calls (including GEMM). So we need to load
> nvblas.so first and then some CPU BLAS library in JNI. I wonder
> whether the setup was correct.
>
> Alexander, could you check whether GPU is used in the netlib-cublas
> experiments? You can tell it by watching CPU/GPU usage.
>
> Best,
> Xiangrui
>
> On Thu, Feb 26, 2015 at 10:47 PM, Sam Halliday <sam.halliday@gmail.com>
> wrote:
> > Don't use "big O" estimates, always measure. It used to work back in th=
e
> > days when double multiplication was a bottleneck. The computation cost =
is
> > effectively free on both the CPU and GPU and you're seeing pure copying
> > costs. Also, I'm dubious that cublas is doing what you think it is. Can
> you
> > link me to the source code for DGEMM?
> >
> > I show all of this in my talk, with explanations, I can't stress enough
> how
> > much I recommend that you watch it if you want to understand high
> > performance hardware acceleration for linear algebra :-)
> >
> > On 27 Feb 2015 01:42, "Xiangrui Meng" <mengxr@gmail.com> wrote:
> >>
> >> The copying overhead should be quadratic on n, while the computation
> >> cost is cubic on n. I can understand that netlib-cublas is slower than
> >> netlib-openblas on small problems. But I'm surprised to see that it is
> >> still 20x slower on 10000x10000. I did the following on a g2.2xlarge
> >> instance with BIDMat:
> >>
> >> val n =3D 10000
> >>
> >> val f =3D rand(n, n)
> >> flip; f*f; val rf =3D flop
> >>
> >> flip; val g =3D GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val rg =
=3D
> flop
> >>
> >> flip; g*g; val rgg =3D flop
> >>
> >> The CPU version finished in 12 seconds.
> >> The CPU->GPU->CPU version finished in 2.2 seconds.
> >> The GPU version finished in 1.7 seconds.
> >>
> >> I'm not sure whether my CPU->GPU->CPU code simulates the netlib-cublas
> >> path. But based on the result, the data copying overhead is definitely
> >> not as big as 20x at n =3D 10000.
> >>
> >> Best,
> >> Xiangrui
> >>
> >>
> >> On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday <sam.halliday@gmail.com>
> >> wrote:
> >> > I've had some email exchanges with the author of BIDMat: it does
> exactly
> >> > what you need to get the GPU benefit and writes higher level
> algorithms
> >> > entirely in the GPU kernels so that the memory stays there as long a=
s
> >> > possible. The restriction with this approach is that it is only
> offering
> >> > high-level algorithms so is not a toolkit for applied mathematics
> >> > research and development --- but it works well as a toolkit for high=
er
> >> > level analysis (e.g. for analysts and practitioners).
> >> >
> >> > I believe BIDMat's approach is the best way to get performance out o=
f
> >> > GPU hardware at the moment but I also have strong evidence to sugges=
t
> >> > that the hardware will catch up and the memory transfer costs betwee=
n
> >> > CPU/GPU will disappear meaning that there will be no need for custom
> GPU
> >> > kernel implementations. i.e. please continue to use BLAS primitives
> when
> >> > writing new algorithms and only go to the GPU for an alternative
> >> > optimised implementation.
> >> >
> >> > Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, and
> offer
> >> > an API that looks like BLAS but takes pointers to special regions in
> the
> >> > GPU memory region. Somebody has written a wrapper around CUDA to
> create
> >> > a proper BLAS library but it only gives marginal performance over th=
e
> >> > CPU because of the memory transfer overhead.
> >> >
> >> > This slide from my talk
> >> >
> >> >   http://fommil.github.io/scalax14/#/11/2
> >> >
> >> > says it all. X axis is matrix size, Y axis is logarithmic time to do
> >> > DGEMM. Black line is the "cheating" time for the GPU and the green
> line
> >> > is after copying the memory to/from the GPU memory. APUs have the
> >> > potential to eliminate the green line.
> >> >
> >> > Best regards,
> >> > Sam
> >> >
> >> >
> >> >
> >> > "Ulanov, Alexander" <alexander.ulanov@hp.com> writes:
> >> >
> >> >> Evan, thank you for the summary. I would like to add some more
> >> >> observations. The GPU that I used is 2.5 times cheaper than the CPU
> ($250 vs
> >> >> $100). They both are 3 years old. I've also did a small test with
> modern
> >> >> hardware, and the new GPU nVidia Titan was slightly more than 1
> order of
> >> >> magnitude faster than Intel E5-2650 v2 for the same tests. However,
> it costs
> >> >> as much as CPU ($1200). My takeaway is that GPU is making a better
> >> >> price/value progress.
> >> >>
> >> >>
> >> >>
> >> >> Xiangrui, I was also surprised that BIDMat-cuda was faster than
> >> >> netlib-cuda and the most reasonable explanation is that it holds th=
e
> result
> >> >> in GPU memory, as Sam suggested. At the same time, it is OK because
> you can
> >> >> copy the result back from GPU only when needed. However, to be sure=
,
> I am
> >> >> going to ask the developer of BIDMat on his upcoming talk.
> >> >>
> >> >>
> >> >>
> >> >> Best regards, Alexander
> >> >>
> >> >>
> >> >> From: Sam Halliday [mailto:sam.halliday@gmail.com]
> >> >> Sent: Thursday, February 26, 2015 1:56 PM
> >> >> To: Xiangrui Meng
> >> >> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R=
.
> >> >> Sparks
> >> >> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>
> >> >>
> >> >> Btw, I wish people would stop cheating when comparing CPU and GPU
> >> >> timings for things like matrix multiply :-P
> >> >>
> >> >> Please always compare apples with apples and include the time it
> takes
> >> >> to set up the matrices, send it to the processing unit, doing the
> >> >> calculation AND copying it back to where you need to see the result=
s.
> >> >>
> >> >> Ignoring this method will make you believe that your GPU is thousan=
ds
> >> >> of times faster than it really is. Again, jump to the end of my tal=
k
> for
> >> >> graphs and more discussion....  especially the bit about me being
> keen on
> >> >> funding to investigate APU hardware further ;-) (I believe it will
> solve the
> >> >> problem)
> >> >> On 26 Feb 2015 21:16, "Xiangrui Meng"
> >> >> <mengxr@gmail.com<mailto:mengxr@gmail.com>> wrote:
> >> >> Hey Alexander,
> >> >>
> >> >> I don't quite understand the part where netlib-cublas is about 20x
> >> >> slower than netlib-openblas. What is the overhead of using a GPU BL=
AS
> >> >> with netlib-java?
> >> >>
> >> >> CC'ed Sam, the author of netlib-java.
> >> >>
> >> >> Best,
> >> >> Xiangrui
> >> >>
> >> >> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley
> >> >> <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
> >> >>> Better documentation for linking would be very helpful!  Here's a
> >> >>> JIRA:
> >> >>> https://issues.apache.org/jira/browse/SPARK-6019
> >> >>>
> >> >>>
> >> >>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks
> >> >>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
> >> >>> wrote:
> >> >>>
> >> >>>> Thanks for compiling all the data and running these benchmarks,
> Alex.
> >> >>>> The
> >> >>>> big takeaways here can be seen with this chart:
> >> >>>>
> >> >>>>
> >> >>>>
> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZHl6km=
AJeaZZggr0/pubchart?oid=3D1899767119&format=3Dinteractive
> >> >>>>
> >> >>>> 1) A properly configured GPU matrix multiply implementation (e.g.
> >> >>>> BIDMat+GPU) can provide substantial (but less than an order of
> >> >>>> magnitude)
> >> >>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> >> >>>> netlib-java+openblas-compiled).
> >> >>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitu=
de
> >> >>>> worse
> >> >>>> than a well-tuned CPU implementation, particularly for larger
> >> >>>> matrices.
> >> >>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - th=
is
> >> >>>> basically agrees with the authors own benchmarks (
> >> >>>> https://github.com/fommil/netlib-java)
> >> >>>>
> >> >>>> I think that most of our users are in a situation where using GPU=
s
> >> >>>> may not
> >> >>>> be practical - although we could consider having a good GPU backe=
nd
> >> >>>> available as an option. However, *ALL* users of MLlib could benef=
it
> >> >>>> (potentially tremendously) from using a well-tuned CPU-based BLAS
> >> >>>> implementation. Perhaps we should consider updating the mllib gui=
de
> >> >>>> with a
> >> >>>> more complete section for enabling high performance binaries on O=
SX
> >> >>>> and
> >> >>>> Linux? Or better, figure out a way for the system to fetch these
> >> >>>> automatically.
> >> >>>>
> >> >>>> - Evan
> >> >>>>
> >> >>>>
> >> >>>>
> >> >>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
> >> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> >> >>>>
> >> >>>>> Just to summarize this thread, I was finally able to make all
> >> >>>>> performance
> >> >>>>> comparisons that we discussed. It turns out that:
> >> >>>>> BIDMat-cublas>>BIDMat
> >> >>>>>
> >> >>>>>
> MKL=3D=3Dnetlib-mkl=3D=3Dnetlib-openblas-compiled>netlib-openblas-yum-rep=
o=3D=3Dnetlib-cublas>netlib-blas>f2jblas
> >> >>>>>
> >> >>>>> Below is the link to the spreadsheet with full results.
> >> >>>>>
> >> >>>>>
> >> >>>>>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J=
5r7kwKSPkY/edit?usp=3Dsharing
> >> >>>>>
> >> >>>>> One thing still needs exploration: does BIDMat-cublas perform
> >> >>>>> copying
> >> >>>>> to/from machine=E2=80=99s RAM?
> >> >>>>>
> >> >>>>> -----Original Message-----
> >> >>>>> From: Ulanov, Alexander
> >> >>>>> Sent: Tuesday, February 10, 2015 2:12 PM
> >> >>>>> To: Evan R. Sparks
> >> >>>>> Cc: Joseph Bradley;
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
> >> >>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> Thanks, Evan! It seems that ticket was marked as duplicate thoug=
h
> >> >>>>> the
> >> >>>>> original one discusses slightly different topic. I was able to
> link
> >> >>>>> netlib
> >> >>>>> with MKL from BIDMat binaries. Indeed, MKL is statically linked
> >> >>>>> inside a
> >> >>>>> 60MB library.
> >> >>>>>
> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> >> >>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> >> >>>>>
> >> >>>>>
> +-----------------------------------------------------------------------+
> >> >>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556=
 |
> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
> >> >>>>> |1,638475459 |
> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,093521=
1
> |
> >> >>>>> 1569,233228 |
> >> >>>>>
> >> >>>>> It turn out that pre-compiled MKL is faster than precompiled
> >> >>>>> OpenBlas on
> >> >>>>> my machine. Probably, I=E2=80=99ll add two more columns with loc=
ally
> >> >>>>> compiled
> >> >>>>> openblas and cuda.
> >> >>>>>
> >> >>>>> Alexander
> >> >>>>>
> >> >>>>> From: Evan R. Sparks
> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
> >> >>>>> Sent: Monday, February 09, 2015 6:06 PM
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc: Joseph Bradley;
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> Great - perhaps we can move this discussion off-list and onto a
> JIRA
> >> >>>>> ticket? (Here's one:
> >> >>>>> https://issues.apache.org/jira/browse/SPARK-5705)
> >> >>>>>
> >> >>>>> It seems like this is going to be somewhat exploratory for a whi=
le
> >> >>>>> (and
> >> >>>>> there's probably only a handful of us who really care about fast
> >> >>>>> linear
> >> >>>>> algebra!)
> >> >>>>>
> >> >>>>> - Evan
> >> >>>>>
> >> >>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
> >> >>>>> wrote:
> >> >>>>> Hi Evan,
> >> >>>>>
> >> >>>>> Thank you for explanation and useful link. I am going to build
> >> >>>>> OpenBLAS,
> >> >>>>> link it with Netlib-java and perform benchmark again.
> >> >>>>>
> >> >>>>> Do I understand correctly that BIDMat binaries contain staticall=
y
> >> >>>>> linked
> >> >>>>> Intel MKL BLAS? It might be the reason why I am able to run BIDM=
at
> >> >>>>> not
> >> >>>>> having MKL BLAS installed on my server. If it is true, I wonder =
if
> >> >>>>> it is OK
> >> >>>>> because Intel sells this library. Nevertheless, it seems that in
> my
> >> >>>>> case
> >> >>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS
> given
> >> >>>>> that
> >> >>>>> BIDMat and Netlib-java are supposed to be on par with JNI
> overheads.
> >> >>>>>
> >> >>>>> Though, it might be interesting to link Netlib-java with Intel
> MKL,
> >> >>>>> as
> >> >>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Hallida=
y
> >> >>>>> (Netlib-java) interested to compare their libraries.
> >> >>>>>
> >> >>>>> Best regards, Alexander
> >> >>>>>
> >> >>>>> From: Evan R. Sparks
> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com
> ><mailto:
> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >> >>>>> Sent: Friday, February 06, 2015 5:58 PM
> >> >>>>>
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc: Joseph Bradley;
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> I would build OpenBLAS yourself, since good BLAS performance com=
es
> >> >>>>> from
> >> >>>>> getting cache sizes, etc. set up correctly for your particular
> >> >>>>> hardware -
> >> >>>>> this is often a very tricky process (see, e.g. ATLAS), but we
> found
> >> >>>>> that on
> >> >>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
> >> >>>>> performance competitive with MKL.
> >> >>>>>
> >> >>>>> To make sure the right library is getting used, you have to make
> >> >>>>> sure
> >> >>>>> it's first on the search path - export
> >> >>>>> LD_LIBRARY_PATH=3D/path/to/blas/library.so will do the trick her=
e.
> >> >>>>>
> >> >>>>> For some examples of getting netlib-java setup on an ec2 node an=
d
> >> >>>>> some
> >> >>>>> example benchmarking code we ran a while back, see:
> >> >>>>> https://github.com/shivaram/matrix-bench
> >> >>>>>
> >> >>>>> In particular - build-openblas-ec2.sh shows you how to build the
> >> >>>>> library
> >> >>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you
> how
> >> >>>>> to get
> >> >>>>> the path setup and get that library picked up by netlib-java.
> >> >>>>>
> >> >>>>> In this way - you could probably get cuBLAS set up to be used by
> >> >>>>> netlib-java as well.
> >> >>>>>
> >> >>>>> - Evan
> >> >>>>>
> >> >>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
> >> >>>>> wrote:
> >> >>>>> Evan, could you elaborate on how to force BIDMat and netlib-java
> to
> >> >>>>> force
> >> >>>>> loading the right blas? For netlib, I there are few JVM flags,
> such
> >> >>>>> as
> >> >>>>> -Dcom.github.fommil.netlib.BLAS=3Dcom.github.fommil.netlib.F2jBL=
AS,
> so
> >> >>>>> I can
> >> >>>>> force it to use Java implementation. Not sure I understand how t=
o
> >> >>>>> force use
> >> >>>>> a specific blas (not specific wrapper for blas).
> >> >>>>>
> >> >>>>> Btw. I have installed openblas (yum install openblas), so I
> suppose
> >> >>>>> that
> >> >>>>> netlib is using it.
> >> >>>>>
> >> >>>>> From: Evan R. Sparks
> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com
> ><mailto:
> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >> >>>>> Sent: Friday, February 06, 2015 5:19 PM
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc: Joseph Bradley;
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >> >>>>>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> Getting breeze to pick up the right blas library is critical for
> >> >>>>> performance. I recommend using OpenBLAS (or MKL, if you already
> have
> >> >>>>> it).
> >> >>>>> It might make sense to force BIDMat to use the same underlying
> BLAS
> >> >>>>> library
> >> >>>>> as well.
> >> >>>>>
> >> >>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
> >> >>>>> wrote:
> >> >>>>> Hi Evan, Joseph
> >> >>>>>
> >> >>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
> >> >>>>> faster
> >> >>>>> than netlib-java+breeze (sorry for weird table formatting):
> >> >>>>>
> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
> >> >>>>> native_system_linux_x86-64|
> >> >>>>> Breeze+Netlib-java f2jblas |
> >> >>>>>
> >> >>>>>
> +-----------------------------------------------------------------------+
> >> >>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 |
> 1569,233228 |
> >> >>>>>
> >> >>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM,
> Fedora
> >> >>>>> 19
> >> >>>>> Linux, Scala 2.11.
> >> >>>>>
> >> >>>>> Later I will make tests with Cuda. I need to install new Cuda
> >> >>>>> version for
> >> >>>>> this purpose.
> >> >>>>>
> >> >>>>> Do you have any ideas why breeze-netlib with native blas is so
> much
> >> >>>>> slower than BIDMat MKL?
> >> >>>>>
> >> >>>>> Best regards, Alexander
> >> >>>>>
> >> >>>>> From: Joseph Bradley
> >> >>>>> [mailto:joseph@databricks.com<mailto:joseph@databricks.com
> ><mailto:
> >> >>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
> >> >>>>> Sent: Thursday, February 05, 2015 5:29 PM
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc: Evan R. Sparks;
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> Hi Alexander,
> >> >>>>>
> >> >>>>> Using GPUs with Spark would be very exciting.  Small comment:
> >> >>>>> Concerning
> >> >>>>> your question earlier about keeping data stored on the GPU rathe=
r
> >> >>>>> than
> >> >>>>> having to move it between main memory and GPU memory on each
> >> >>>>> iteration, I
> >> >>>>> would guess this would be critical to getting good performance.
> If
> >> >>>>> you
> >> >>>>> could do multiple local iterations before aggregating results,
> then
> >> >>>>> the
> >> >>>>> cost of data movement to the GPU could be amortized (and I belie=
ve
> >> >>>>> that is
> >> >>>>> done in practice).  Having Spark be aware of the GPU and using i=
t
> as
> >> >>>>> another part of memory sounds like a much bigger undertaking.
> >> >>>>>
> >> >>>>> Joseph
> >> >>>>>
> >> >>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
> >> >>>>> wrote:
> >> >>>>> Thank you for explanation! I=E2=80=99ve watched the BIDMach pres=
entation
> by
> >> >>>>> John
> >> >>>>> Canny and I am really inspired by his talk and comparisons with
> >> >>>>> Spark MLlib.
> >> >>>>>
> >> >>>>> I am very interested to find out what will be better within Spar=
k:
> >> >>>>> BIDMat
> >> >>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair
> way
> >> >>>>> to
> >> >>>>> benchmark them? Currently I do benchmarks on artificial neural
> >> >>>>> networks in
> >> >>>>> batch mode. While it is not a =E2=80=9Cpure=E2=80=9D test of lin=
ear algebra, it
> >> >>>>> involves
> >> >>>>> some other things that are essential to machine learning.
> >> >>>>>
> >> >>>>> From: Evan R. Sparks
> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com
> ><mailto:
> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
> >> >>>>> Sent: Thursday, February 05, 2015 1:29 PM
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc:
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster tha=
n
> >> >>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due
> to
> >> >>>>> data
> >> >>>>> layout and fewer levels of indirection - it's definitely a
> >> >>>>> worthwhile
> >> >>>>> experiment to run. The main speedups I've seen from using it com=
e
> >> >>>>> from
> >> >>>>> highly optimized GPU code for linear algebra. I know that in the
> >> >>>>> past Canny
> >> >>>>> has gone as far as to write custom GPU kernels for
> >> >>>>> performance-critical
> >> >>>>> regions of code.[1]
> >> >>>>>
> >> >>>>> BIDMach is highly optimized for single node performance or
> >> >>>>> performance on
> >> >>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (o=
r
> >> >>>>> can be
> >> >>>>> batched in that way) the performance tends to fall off. Canny
> argues
> >> >>>>> for
> >> >>>>> hardware/software codesign and as such prefers machine
> >> >>>>> configurations that
> >> >>>>> are quite different than what we find in most commodity cluster
> >> >>>>> nodes -
> >> >>>>> e.g. 10 disk cahnnels and 4 GPUs.
> >> >>>>>
> >> >>>>> In contrast, MLlib was designed for horizontal scalability on
> >> >>>>> commodity
> >> >>>>> clusters and works best on very big datasets - order of terabyte=
s.
> >> >>>>>
> >> >>>>> For the most part, these projects developed concurrently to
> address
> >> >>>>> slightly different use cases. That said, there may be bits of
> >> >>>>> BIDMach we
> >> >>>>> could repurpose for MLlib - keep in mind we need to be careful
> about
> >> >>>>> maintaining cross-language compatibility for our Java and
> >> >>>>> Python-users,
> >> >>>>> though.
> >> >>>>>
> >> >>>>> - Evan
> >> >>>>>
> >> >>>>> [1] - http://arxiv.org/abs/1409.5402
> >> >>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
> >> >>>>>
> >> >>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
> >> >>>>> wrote:
> >> >>>>> Hi Evan,
> >> >>>>>
> >> >>>>> Thank you for suggestion! BIDMat seems to have terrific speed. D=
o
> >> >>>>> you
> >> >>>>> know what makes them faster than netlib-java?
> >> >>>>>
> >> >>>>> The same group has BIDMach library that implements machine
> learning.
> >> >>>>> For
> >> >>>>> some examples they use Caffe convolutional neural network librar=
y
> >> >>>>> owned by
> >> >>>>> another group in Berkeley. Could you elaborate on how these all
> >> >>>>> might be
> >> >>>>> connected with Spark Mllib? If you take BIDMat for linear algebr=
a
> >> >>>>> why don=E2=80=99t
> >> >>>>> you take BIDMach for optimization and learning?
> >> >>>>>
> >> >>>>> Best regards, Alexander
> >> >>>>>
> >> >>>>> From: Evan R. Sparks
> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com
> ><mailto:
> >> >>>>>
> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
> >> >>>>> Sent: Thursday, February 05, 2015 12:09 PM
> >> >>>>> To: Ulanov, Alexander
> >> >>>>> Cc:
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
> >> >>>>>
> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
> dev@spark.apache.org<mailto:dev@spark.apache.org>>>
> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >> >>>>>
> >> >>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
> >> >>>>> blas in
> >> >>>>> many cases.
> >> >>>>>
> >> >>>>> You might consider taking a look at the codepaths that BIDMat (
> >> >>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
> >> >>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
> >> >>>>> optimizing
> >> >>>>> to make this work really fast from Scala. I've run it on my lapt=
op
> >> >>>>> and
> >> >>>>> compared to MKL and in certain cases it's 10x faster at matrix
> >> >>>>> multiply.
> >> >>>>> There are a lot of layers of indirection here and you really wan=
t
> to
> >> >>>>> avoid
> >> >>>>> data copying as much as possible.
> >> >>>>>
> >> >>>>> We could also consider swapping out BIDMat for Breeze, but that
> >> >>>>> would be
> >> >>>>> a big project and if we can figure out how to get breeze+cublas =
to
> >> >>>>> comparable performance that would be a big win.
> >> >>>>>
> >> >>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
> >> >>>>>
> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
> >> >>>>> wrote:
> >> >>>>> Dear Spark developers,
> >> >>>>>
> >> >>>>> I am exploring how to make linear algebra operations faster with=
in
> >> >>>>> Spark.
> >> >>>>> One way of doing this is to use Scala Breeze library that is
> bundled
> >> >>>>> with
> >> >>>>> Spark. For matrix operations, it employs Netlib-java that has a
> Java
> >> >>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK
> >> >>>>> native
> >> >>>>> binaries if they are available on the worker node. It also has i=
ts
> >> >>>>> own
> >> >>>>> optimized Java implementation of BLAS. It is worth mentioning,
> that
> >> >>>>> native
> >> >>>>> binaries provide better performance only for BLAS level 3, i.e.
> >> >>>>> matrix-matrix operations or general matrix multiplication (GEMM)=
.
> >> >>>>> This is
> >> >>>>> confirmed by GEMM test on Netlib-java page
> >> >>>>> https://github.com/fommil/netlib-java. I also confirmed it with
> my
> >> >>>>> experiments with training of artificial neural network
> >> >>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
> >> >>>>> However, I would like to boost performance more.
> >> >>>>>
> >> >>>>> GPU is supposed to work fast with linear algebra and there is
> Nvidia
> >> >>>>> CUDA
> >> >>>>> implementation of BLAS, called cublas. I have one Linux server
> with
> >> >>>>> Nvidia
> >> >>>>> GPU and I was able to do the following. I linked cublas (instead
> of
> >> >>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark, =
so
> >> >>>>> Breeze/Netlib is using it. Then I did some performance
> measurements
> >> >>>>> with
> >> >>>>> regards to artificial neural network batch learning in Spark MLl=
ib
> >> >>>>> that
> >> >>>>> involves matrix-matrix multiplications. It turns out that for
> >> >>>>> matrices of
> >> >>>>> size less than ~1000x780 GPU cublas has the same speed as CPU
> blas.
> >> >>>>> Cublas
> >> >>>>> becomes slower for bigger matrices. It worth mentioning that it =
is
> >> >>>>> was not
> >> >>>>> a test for ONLY multiplication since there are other operations
> >> >>>>> involved.
> >> >>>>> One of the reasons for slowdown might be the overhead of copying
> the
> >> >>>>> matrices from computer memory to graphic card memory and back.
> >> >>>>>
> >> >>>>> So, few questions:
> >> >>>>> 1) Do these results with CUDA make sense?
> >> >>>>> 2) If the problem is with copy overhead, are there any libraries
> >> >>>>> that
> >> >>>>> allow to force intermediate results to stay in graphic card memo=
ry
> >> >>>>> thus
> >> >>>>> removing the overhead?
> >> >>>>> 3) Any other options to speed-up linear algebra in Spark?
> >> >>>>>
> >> >>>>> Thank you, Alexander
> >> >>>>>
> >> >>>>>
> >> >>>>>
> ---------------------------------------------------------------------
> >> >>>>> To unsubscribe, e-mail:
> >> >>>>> dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org><mailto:
> >> >>>>>
> >> >>>>> dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>><mailto:dev-unsubscribe@spark.apache.or=
g
> <mailto:dev-unsubscribe@spark.apache.org>
> >> >>>>>
> >> >>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:
> dev-unsubscribe@spark.apache.org>>>
> >> >>>>> For additional commands, e-mail:
> >> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org
> ><mailto:
> >> >>>>>
> >> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org
> >><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org
> ><mailto:
> >> >>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>
> >> >
> >> > --
> >> > Best regards,
> >> > Sam
> >> >
>

--089e010d953249629b051017c626--

From dev-return-11813-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Feb 27 21:56:56 2015
Return-Path: <dev-return-11813-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 009EC109A0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 27 Feb 2015 21:56:56 +0000 (UTC)
Received: (qmail 21243 invoked by uid 500); 27 Feb 2015 21:56:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21162 invoked by uid 500); 27 Feb 2015 21:56:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21144 invoked by uid 99); 27 Feb 2015 21:56:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 21:56:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 27 Feb 2015 21:56:26 +0000
Received: by igbhl2 with SMTP id hl2so3691705igb.0
        for <dev@spark.apache.org>; Fri, 27 Feb 2015 13:54:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=G697TERrYueBQV6vXTNJDIL06pcoJGq2FvUQSKRlrHs=;
        b=lkXpO7WJxVxt+AjNkplQNR4Yl1jHas7DmorI0QKdKvMukzi1ZCHetbiW1TZXACDHpI
         vgrdSEMaTDUqw0JWn3VpxNhkWeeLqSgODZPRMsge/wUtMlCx1cjN4SQD1pzyNERMmDym
         YMX7XTG5X5uqAOOVhzjn+HiWFoPKZBIE17Z0OYUaFdQ0jb1Eonr/GMPeA9gmMyZutPIz
         cMqfHrKHdbvJ4s+mr64CAf+Q+Gmv7U8a0SfvnoDq/xmUOyrk1Q2c+V14euax8+2pJj7O
         aI+76VZXwVHHlPtF3kFDFjSknqEAxGT/QPeUwe/W1pA8YPegPX7qeAnKY862JSHsQTk0
         xXYA==
MIME-Version: 1.0
X-Received: by 10.42.28.199 with SMTP id o7mr18147097icc.23.1425074094676;
 Fri, 27 Feb 2015 13:54:54 -0800 (PST)
Received: by 10.36.53.82 with HTTP; Fri, 27 Feb 2015 13:54:54 -0800 (PST)
In-Reply-To: <CA+3qhFT8mNQsstNRyRoXJ+D2S2YL7ZPRi52ruRrBmgOStQb8Wg@mail.gmail.com>
References: <CA+3qhFQ6kB6FwVB2UA7RLBHx3Nvv5QLB92+y5uWT3bCv_src2g@mail.gmail.com>
	<CALte62wKU=FuH+MWHA5UkNi-FA+uqnECuJ7VwmHtiac5sjNagA@mail.gmail.com>
	<CA+3qhFT8mNQsstNRyRoXJ+D2S2YL7ZPRi52ruRrBmgOStQb8Wg@mail.gmail.com>
Date: Fri, 27 Feb 2015 13:54:54 -0800
Message-ID: <CALte62zdXMCrrdxc8gWb96fphdJBnL6By8mDp+FpUuUQJm7otA@mail.gmail.com>
Subject: Re: trouble with sbt building network-* projects?
From: Ted Yu <yuzhihong@gmail.com>
To: Imran Rashid <irashid@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf304271b231238a051018eb9d
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf304271b231238a051018eb9d
Content-Type: text/plain; charset=UTF-8

bq. I have to keep cd'ing into network/common, run mvn install, then go
back to network/shuffle and run some other mvn command over there.

Yeah - been through this.

Having continuous testing for maven would be nice.

On Fri, Feb 27, 2015 at 11:31 AM, Imran Rashid <irashid@cloudera.com> wrote:

> well, perhaps I just need to learn to use maven better, but currently I
> find sbt much more convenient for continuously running my tests.  I do use
> zinc, but I'm looking for continuous testing.  This makes me think I need
> sbt for that:
> http://stackoverflow.com/questions/11347633/is-there-a-java-continuous-testing-plugin-for-maven
>
> 1) I really like that in sbt I can run "~test-only
> com.foo.bar.SomeTestSuite" (or whatever other pattern) and just leave that
> running as I code, without having to go and explicitly trigger "mvn test"
> and wait for the result.
>
> 2) I find sbt's handling of sub-projects much simpler (when it works).
> I'm trying to make changes to network/common & network/shuffle, which means
> I have to keep cd'ing into network/common, run mvn install, then go back to
> network/shuffle and run some other mvn command over there.  I don't want to
> run mvn at the root project level, b/c I don't want to wait for it to
> compile all the other projects when I just want to run tests in
> network/common.  Even with incremental compiling, in my day-to-day coding I
> want to entirely skip compiling sql, graphx, mllib etc. -- I have to switch
> branches often enough that i end up triggering a full rebuild of those
> projects even when I haven't touched them.
>
>
>
>
>
> On Fri, Feb 27, 2015 at 1:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>
>> bq. to be able to run my tests in sbt, though, it makes the development
>> iterations much faster.
>>
>> Was the preference for sbt due to long maven build time ?
>> Have you started Zinc on your machine ?
>>
>> Cheers
>>
>> On Fri, Feb 27, 2015 at 11:10 AM, Imran Rashid <irashid@cloudera.com>
>> wrote:
>>
>>> Has anyone else noticed very strange build behavior in the network-*
>>> projects?
>>>
>>> maven seems to the doing the right, but sbt is very inconsistent.
>>> Sometimes when it builds network-shuffle it doesn't know about any of the
>>> code in network-common.  Sometimes it will completely skip the java unit
>>> tests.  And then some time later, it'll suddenly decide it knows about
>>> some
>>> more of the java unit tests.  Its not from a simple change, like
>>> touching a
>>> test file, or a file the test depends on -- nor a restart of sbt.  I am
>>> pretty confused.
>>>
>>>
>>> maven had issues when I tried to add scala code to network-common, it
>>> would
>>> compile the scala code but not make it available to java.  I'm working
>>> around that by just coding in java anyhow.  I'd really like to be able to
>>> run my tests in sbt, though, it makes the development iterations much
>>> faster.
>>>
>>> thanks,
>>> Imran
>>>
>>
>>
>

--20cf304271b231238a051018eb9d--

From dev-return-11814-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 28 08:01:15 2015
Return-Path: <dev-return-11814-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C0F217E97
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Feb 2015 08:01:15 +0000 (UTC)
Received: (qmail 92521 invoked by uid 500); 28 Feb 2015 08:01:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92439 invoked by uid 500); 28 Feb 2015 08:01:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92427 invoked by uid 99); 28 Feb 2015 08:01:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 08:01:12 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,MIME_BASE64_TEXT,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of r7raul1984@163.com designates 220.181.12.12 as permitted sender)
Received: from [220.181.12.12] (HELO m12-12.163.com) (220.181.12.12)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 08:00:46 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=163.com;
	s=s110527; h=Date:From:Subject:Mime-Version:Message-ID; bh=7JhlK
	IsUiKtBu5HM7W7y1tGR3iMhK7Ooh+tzhp1tD9I=; b=B03TOThwFkqnDhJ0R+TO/
	o9/b66rZPw7yWRZybn9NLNmKn7t+olJeYl71ZpprdQGWtFw76Z52HtDf6LcWFciL
	OcjViYUZNy9Qd3kmltpFCqMcWq8v7pu7IjhfIdEGM0wpfKHLpzOekdXHTu85rxy9
	TfYBomzPBckzCDxXpssr3c=
Received: from NHSH1MNB72514 (unknown [203.110.175.179])
	by smtp8 (Coremail) with SMTP id DMCowEBpuXdEdfFUtSPsAg--.1840S2;
	Sat, 28 Feb 2015 15:59:01 +0800 (CST)
Date: Sat, 28 Feb 2015 15:58:43 +0800
From: "r7raul1984@163.com" <r7raul1984@163.com>
To: dev <dev@spark.apache.org>
Subject: How to create a Row from a List or Array in Spark using Scala
X-Priority: 3
X-Has-Attach: no
X-Mailer: Foxmail 7, 2, 5, 136[cn]
Mime-Version: 1.0
Message-ID: <201502281558413298157@163.com>
Content-Type: multipart/alternative;
	boundary="----=_001_NextPart338322541085_=----"
X-CM-TRANSID:DMCowEBpuXdEdfFUtSPsAg--.1840S2
X-Coremail-Antispam: 1Uf129KBjDUn29KB7ZKAUJUUUUU529EdanIXcx71UUUUU7v73
	VFW2AGmfu7bjvjm3AaLaJ3UbIYCTnIWIevJa73UjIFyTuYvjxUzmRUDUUUU
X-Originating-IP: [203.110.175.179]
X-CM-SenderInfo: 3uxut3borzmki6rwjhhfrp/1tbiVAWuzlEAMgwysQAAsd
X-Virus-Checked: Checked by ClamAV on apache.org

------=_001_NextPart338322541085_=----
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: base64

aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLmNhdGFseXN0LmV4cHJlc3Npb25zLl8NCg0KdmFs
IHZhbHVlczogSmF2YUFycmF5TGlzdFtBbnldID0gbmV3IEphdmFBcnJheUxpc3QoKQ0KY29tcHV0
ZWRWYWx1ZXMgPSBSb3codmFsdWVzLmdldCgwKSx2YWx1ZXMuZ2V0KDEpKSAvL0l0IGlzIG5vdCBn
b29kIGJ5IHVzZSBnZXQoaW5kZXgpLiAgSG93IHRvIGNyZWF0ZSBhIFJvdyBmcm9tIGEgTGlzdCBv
ciBBcnJheSBpbiBTcGFyayB1c2luZyBTY2FsYSAuDQoNCg0KDQpyN3JhdWwxOTg0QDE2My5jb20N
Cg==

------=_001_NextPart338322541085_=------



From dev-return-11815-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 28 08:38:07 2015
Return-Path: <dev-return-11815-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 385D417EF1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Feb 2015 08:38:07 +0000 (UTC)
Received: (qmail 22084 invoked by uid 500); 28 Feb 2015 08:38:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22001 invoked by uid 500); 28 Feb 2015 08:38:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21971 invoked by uid 99); 28 Feb 2015 08:38:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 08:38:05 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of msdevanms@gmail.com designates 209.85.192.47 as permitted sender)
Received: from [209.85.192.47] (HELO mail-qg0-f47.google.com) (209.85.192.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 08:37:39 +0000
Received: by mail-qg0-f47.google.com with SMTP id f51so10205770qge.6
        for <dev@spark.apache.org>; Sat, 28 Feb 2015 00:37:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/xt5N81SNG5GTnUa5K7Cz6CMReafE+xe3PHOFNX9tX8=;
        b=RpM249wizh4ag6AhL60XIuCp8qm8+bCNw/c4Izg1vjM5XlRPrFB6tlMrF/q1fnafds
         vxMyT+4UCdlB+sl3e1Y41/+rcsmVqeUaAr0t97Nk4voKzPmgp4DuwQY8EAE/Y8jLSxHf
         YUX9sv6IJI1jShvY3DMNtBT1dDpTYxBvtdHgg0Xh0SBXdWm2dJgiMHLfNMKd1SrGb9an
         QMKdP3miOfjIWjrA9kmo0hugW/arkG99NZfNjBgTz71nKj1t1vaBfjTA8fYIpFJ97nm1
         erPcGcaEjJgJTGCBACnQ8iTStpL5cVVpY9fd8pNNzWpYgns1atKtvIyrNF2m3V4EBJLP
         bIPg==
MIME-Version: 1.0
X-Received: by 10.140.31.116 with SMTP id e107mr8804867qge.36.1425112657640;
 Sat, 28 Feb 2015 00:37:37 -0800 (PST)
Received: by 10.229.165.7 with HTTP; Sat, 28 Feb 2015 00:37:37 -0800 (PST)
In-Reply-To: <201502281558413298157@163.com>
References: <201502281558413298157@163.com>
Date: Sat, 28 Feb 2015 14:07:37 +0530
Message-ID: <CADkoF-qJLKGYRnRvTSei8O7q1re6YVeQmEjq6wmVfqmpbgVOwg@mail.gmail.com>
Subject: Re: How to create a Row from a List or Array in Spark using Scala
From: "DEVAN M.S." <msdevanms@gmail.com>
To: "r7raul1984@163.com" <r7raul1984@163.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a9544b944fe051021e5eb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a9544b944fe051021e5eb
Content-Type: text/plain; charset=UTF-8

  In scala API its there, Row.fromSeq(ARRAY), I dnt know much more
about java api



Devan M.S. | Research Associate | Cyber Security | AMRITA VISHWA
VIDYAPEETHAM | Amritapuri | Cell +919946535290 |


On Sat, Feb 28, 2015 at 1:28 PM, r7raul1984@163.com <r7raul1984@163.com>
wrote:

> import org.apache.spark.sql.catalyst.expressions._
>
> val values: JavaArrayList[Any] = new JavaArrayList()
> computedValues = Row(values.get(0),values.get(1)) //It is not good by use
> get(index).  How to create a Row from a List or Array in Spark using Scala .
>
>
>
> r7raul1984@163.com
>

--001a113a9544b944fe051021e5eb--

From dev-return-11816-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 28 19:35:20 2015
Return-Path: <dev-return-11816-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEE6F10ABD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Feb 2015 19:35:20 +0000 (UTC)
Received: (qmail 82656 invoked by uid 500); 28 Feb 2015 19:35:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82573 invoked by uid 500); 28 Feb 2015 19:35:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82561 invoked by uid 99); 28 Feb 2015 19:35:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 19:35:19 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of manojkumarsivaraj334@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 19:35:15 +0000
Received: by mail-ob0-f175.google.com with SMTP id va2so24601229obc.6
        for <dev@spark.apache.org>; Sat, 28 Feb 2015 11:34:09 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=adG13Wup63/2CLk5WOEdagRNgZB0Zy7x3AOUIPQMllQ=;
        b=zFmtZFjKvT18LULeJBBkDLxjHIf92Od/Ke/pqrHMCX/B50UOcDZcLNJ+5TVAN2FnJs
         kE2lwvztmGlESMShHzraO87D8hgUkT13nIbK8VpZ2KrUiyIZ3fDtTefFb3K3jEnK2Jjy
         A/FNO24s6dFDlAl1CyNs02QXiSvuc8ScbRcRjtrE+lJqU5Z07yqD5BK7GPIONAIwwW/q
         FZQ/ZHXtGlfQutSz2uQ3OmA/QWmEo6FTYYrlqLndYlUwTM0HfEYJMVqldT58v2Wu3WT3
         Ey1XUiyNnmuWoX0CAfAy5bq15Xd0fhjbhubMoGUChMVDdUjMFdRnJhBAIDmEn501tGUI
         iWrw==
MIME-Version: 1.0
X-Received: by 10.202.219.215 with SMTP id s206mr13333716oig.114.1425152049708;
 Sat, 28 Feb 2015 11:34:09 -0800 (PST)
Received: by 10.202.108.14 with HTTP; Sat, 28 Feb 2015 11:34:09 -0800 (PST)
In-Reply-To: <BC0324FE-7612-42B6-82DB-38CD30E48A75@gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com>
	<CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com>
	<CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com>
	<CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com>
	<BC0324FE-7612-42B6-82DB-38CD30E48A75@gmail.com>
Date: Sun, 1 Mar 2015 01:04:09 +0530
Message-ID: <CAFQAd-nNmFK9rFQeNQGqZz6HtegiYk_Hkt7iJ5+BXobTudFGiQ@mail.gmail.com>
Subject: Re: Google Summer of Code - ideas
From: Manoj Kumar <manojkumarsivaraj334@gmail.com>
To: Jeremy Freeman <freeman.jeremy@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d4a98ac83dc05102b111d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d4a98ac83dc05102b111d
Content-Type: text/plain; charset=UTF-8

Hi,

Thanks a lot.
Yes indeed, I am interested. I shall start looking at all the related
JIRA's in a while.



-- 
Godspeed,
Manoj Kumar,
http://manojbits.wordpress.com
<http://goog_1017110195>
http://github.com/MechCoder

--001a113d4a98ac83dc05102b111d--

From dev-return-11817-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 28 19:54:37 2015
Return-Path: <dev-return-11817-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 067A410B21
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Feb 2015 19:54:37 +0000 (UTC)
Received: (qmail 9461 invoked by uid 500); 28 Feb 2015 19:54:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9379 invoked by uid 500); 28 Feb 2015 19:54:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9368 invoked by uid 99); 28 Feb 2015 19:54:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 19:54:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW
X-Spam-Check-By: apache.org
Received-SPF: error (nike.apache.org: local policy)
Received: from [209.85.218.51] (HELO mail-oi0-f51.google.com) (209.85.218.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 19:54:04 +0000
Received: by mail-oi0-f51.google.com with SMTP id g201so21019662oib.10
        for <dev@spark.apache.org>; Sat, 28 Feb 2015 11:51:27 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=bRy1vgQgtRMLppnXnHqIsYA8Jcp4IKrxwk13oFzXiHY=;
        b=fREvnn6QuGwpiJwzWU2dctldfzW3jc/T4qwPVHvJUbMQbGRIYx593ZWkWCEs7agbHp
         +PEf8Zcjh8nWBTRYbwG1Bh28PpI/quKkLOndZ/4S5eFPl9LVWTdzKFSqeLiM80iXy5vP
         Z7DY6/5tElah1dCPIjhhxHL70vG051+/PZglb5wayOX6j+msXcMIEnbB/NOlKfjURj8P
         6DUWzRvPGgyzWDQseYJevw40kqc61gNSgSrcMGc1jusXL0vWucsEr9CYnS2CD8vDWf1S
         aav2yaW3FnRV4E3qw2Prm9sYDiJBwB52zjXRNw/NtM6QmyAKTRKEfr4Z//kGdwAo/lof
         2PUg==
X-Gm-Message-State: ALoCoQlMkkOBHjLeYJmSOObCPBnlA1WnontSmMLT1O2NMAgh+3pw/eIwcesruLEpsNEqtTQwNB4w
X-Received: by 10.202.56.133 with SMTP id f127mr13295426oia.101.1425153087194;
 Sat, 28 Feb 2015 11:51:27 -0800 (PST)
MIME-Version: 1.0
Received: by 10.76.116.33 with HTTP; Sat, 28 Feb 2015 11:51:06 -0800 (PST)
In-Reply-To: <CAO4jRXYdhr8oso8d-u_JG2uBH+CLEFr_ocTobRJG_U=sB1bMhw@mail.gmail.com>
References: <CAO4jRXZAX0=LThkdjeU5d_p0_esK8gg1BUwyzZSrenEMMht-9g@mail.gmail.com>
 <CAHUQ+_YhbdP3CGVg697amartG+AS=Sk0zM4ZK=ADyCTb-PCZ5g@mail.gmail.com>
 <CAO4jRXatHK=V8i=AxtRSze5YhuKqk8_RAvA_dsBkTXw3qJwBKA@mail.gmail.com>
 <CAO4jRXZovRqkyCNiD8qqin05ccvRxUY2+-M8-8gCnYd3Tp8zkg@mail.gmail.com>
 <CAHUQ+_Y1Hg0Gg1xi2e5EuLVkux1-4ufzXwVNAbeVmpTQf0xu7w@mail.gmail.com>
 <CAO4jRXYn5N_d0W2yteGtNzMTDbbupoM48kbEmovUhtHhnstZOw@mail.gmail.com>
 <CAO4jRXa0BjguKhO3379Y-XZx0KosNj+EoBEFBDSOT80nfy07xw@mail.gmail.com>
 <CAO4jRXZRnuMd9xRS4hF1_L9fiCn9-vyLTrnU-fUsm7on-JRPRw@mail.gmail.com> <CAO4jRXYdhr8oso8d-u_JG2uBH+CLEFr_ocTobRJG_U=sB1bMhw@mail.gmail.com>
From: Victor Tso-Guillen <vtso@paxata.com>
Date: Sat, 28 Feb 2015 11:51:06 -0800
Message-ID: <CAO4jRXZCxb5hYdmE-SzncoXknSqamL=PJNMFSD7r5NJXTRLjnQ@mail.gmail.com>
Subject: Re: Scheduler hang?
To: dev@spark.apache.org
Content-Type: multipart/related; boundary=001a113cd7be8407eb05102b4f2e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cd7be8407eb05102b4f2e
Content-Type: multipart/alternative; boundary=001a113cd7be8407e605102b4f2d

--001a113cd7be8407e605102b4f2d
Content-Type: text/plain; charset=UTF-8

Moving user to bcc.

What I found was that the TaskSetManager for my task set that had 5 tasks
had preferred locations set for 4 of the 5. Three had localhost/<driver>
and had completed. The one that had nothing had also completed. The last
one was set by our code to be my IP address. Local mode can hang on this
because of https://issues.apache.org/jira/browse/SPARK-4939 addressed by
https://github.com/apache/spark/pull/4147, which is obviously not an
optimal solution but since it's only local mode, it's very good enough. I'm
not going to wait for those seconds to tick by to complete the task, so
I'll fix the IP address reporting side for local mode in my code.

On Thu, Feb 26, 2015 at 8:32 PM, Victor Tso-Guillen <vtso@paxata.com> wrote:

> Of course, breakpointing on every status update and revive offers
> invocation kept the problem from happening. Where could the race be?
>
> On Thu, Feb 26, 2015 at 7:55 PM, Victor Tso-Guillen <vtso@paxata.com>
> wrote:
>
>> Love to hear some input on this. I did get a standalone cluster up on my
>> local machine and the problem didn't present itself. I'm pretty confident
>> that means the problem is in the LocalBackend or something near it.
>>
>> On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <vtso@paxata.com>
>> wrote:
>>
>>> Okay I confirmed my suspicions of a hang. I made a request that stopped
>>> progressing, though the already-scheduled tasks had finished. I made a
>>> separate request that was small enough not to hang, and it kicked the hung
>>> job enough to finish. I think what's happening is that the scheduler or the
>>> local backend is not kicking the revive offers messaging at the right time,
>>> but I have to dig into the code some more to nail the culprit. Anyone on
>>> these list have experience in those code areas that could help?
>>>
>>> On Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <vtso@paxata.com>
>>> wrote:
>>>
>>>> Thanks for the link. Unfortunately, I turned on rdd compression and
>>>> nothing changed. I tried moving netty -> nio and no change :(
>>>>
>>>> On Thu, Feb 26, 2015 at 2:01 AM, Akhil Das <akhil@sigmoidanalytics.com>
>>>> wrote:
>>>>
>>>>> Not many that i know of, but i bumped into this one
>>>>> https://issues.apache.org/jira/browse/SPARK-4516
>>>>>
>>>>> Thanks
>>>>> Best Regards
>>>>>
>>>>> On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-Guillen <vtso@paxata.com>
>>>>> wrote:
>>>>>
>>>>>> Is there any potential problem from 1.1.1 to 1.2.1 with shuffle
>>>>>> dependencies that produce no data?
>>>>>>
>>>>>> On Thu, Feb 26, 2015 at 1:56 AM, Victor Tso-Guillen <vtso@paxata.com>
>>>>>> wrote:
>>>>>>
>>>>>>> The data is small. The job is composed of many small stages.
>>>>>>>
>>>>>>> * I found that with fewer than 222 the problem exhibits. What will
>>>>>>> be gained by going higher?
>>>>>>> * Pushing up the parallelism only pushes up the boundary at which
>>>>>>> the system appears to hang. I'm worried about some sort of message loss or
>>>>>>> inconsistency.
>>>>>>> * Yes, we are using Kryo.
>>>>>>> * I'll try that, but I'm again a little confused why you're
>>>>>>> recommending this. I'm stumped so might as well?
>>>>>>>
>>>>>>> On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <
>>>>>>> akhil@sigmoidanalytics.com> wrote:
>>>>>>>
>>>>>>>> What operation are you trying to do and how big is the data that
>>>>>>>> you are operating on?
>>>>>>>>
>>>>>>>> Here's a few things which you can try:
>>>>>>>>
>>>>>>>> - Repartition the RDD to a higher number than 222
>>>>>>>> - Specify the master as local[*] or local[10]
>>>>>>>> - Use Kryo Serializer (.set("spark.serializer",
>>>>>>>> "org.apache.spark.serializer.KryoSerializer"))
>>>>>>>> - Enable RDD Compression (.set("spark.rdd.compress","true") )
>>>>>>>>
>>>>>>>>
>>>>>>>> Thanks
>>>>>>>> Best Regards
>>>>>>>>
>>>>>>>> On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso-Guillen <
>>>>>>>> vtso@paxata.com> wrote:
>>>>>>>>
>>>>>>>>> I'm getting this really reliably on Spark 1.2.1. Basically I'm in
>>>>>>>>> local mode with parallelism at 8. I have 222 tasks and I never seem to get
>>>>>>>>> far past 40. Usually in the 20s to 30s it will just hang. The last logging
>>>>>>>>> is below, and a screenshot of the UI.
>>>>>>>>>
>>>>>>>>> 2015-02-25 20:39:55.779 GMT-0800 INFO  [task-result-getter-3]
>>>>>>>>> TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms on
>>>>>>>>> localhost (1/5)
>>>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>>>> worker-10] Executor - Finished task 1.0 in stage 16.0 (TID 20). 2492 bytes
>>>>>>>>> result sent to driver
>>>>>>>>> 2015-02-25 20:39:55.825 GMT-0800 INFO  [Executor task launch
>>>>>>>>> worker-8] Executor - Finished task 2.0 in stage 16.0 (TID 21). 2492 bytes
>>>>>>>>> result sent to driver
>>>>>>>>> 2015-02-25 20:39:55.831 GMT-0800 INFO  [task-result-getter-0]
>>>>>>>>> TaskSetManager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on
>>>>>>>>> localhost (2/5)
>>>>>>>>> 2015-02-25 20:39:55.836 GMT-0800 INFO  [task-result-getter-1]
>>>>>>>>> TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on
>>>>>>>>> localhost (3/5)
>>>>>>>>> 2015-02-25 20:39:55.891 GMT-0800 INFO  [Executor task launch
>>>>>>>>> worker-9] Executor - Finished task 0.0 in stage 16.0 (TID 19). 2492 bytes
>>>>>>>>> result sent to driver
>>>>>>>>> 2015-02-25 20:39:55.896 GMT-0800 INFO  [task-result-getter-2]
>>>>>>>>> TaskSetManager - Finished task 0.0 in stage 16.0 (TID 19) in 740 ms on
>>>>>>>>> localhost (4/5)
>>>>>>>>>
>>>>>>>>> [image: Inline image 1]
>>>>>>>>> What should I make of this? Where do I start?
>>>>>>>>>
>>>>>>>>> Thanks,
>>>>>>>>> Victor
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--001a113cd7be8407e605102b4f2d
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Moving user to bcc.<div><br></div><div>What I found was th=
at the TaskSetManager for my task set that had 5 tasks had preferred locati=
ons set for 4 of the 5. Three had localhost/&lt;driver&gt; and had complete=
d. The one that had nothing had also completed. The last one was set by our=
 code to be my IP address. Local mode can hang on this because of=C2=A0<a h=
ref=3D"https://issues.apache.org/jira/browse/SPARK-4939">https://issues.apa=
che.org/jira/browse/SPARK-4939</a> addressed by=C2=A0<a href=3D"https://git=
hub.com/apache/spark/pull/4147">https://github.com/apache/spark/pull/4147</=
a>, which is obviously not an optimal solution but since it&#39;s only loca=
l mode, it&#39;s very good enough. I&#39;m not going to wait for those seco=
nds to tick by to complete the task, so I&#39;ll fix the IP address reporti=
ng side for local mode in my code.</div></div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 8:32 PM, Victor Tso-Gu=
illen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"_b=
lank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_q=
uote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1e=
x"><div dir=3D"ltr">Of course, breakpointing on every status update and rev=
ive offers invocation kept the problem from happening. Where could the race=
 be?</div><div class=3D"HOEnZb"><div class=3D"h5"><div class=3D"gmail_extra=
"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 7:55 PM, Victor Ts=
o-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=
=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"g=
mail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-l=
eft:1ex"><div dir=3D"ltr">Love to hear some input on this. I did get a stan=
dalone cluster up on my local machine and the problem didn&#39;t present it=
self. I&#39;m pretty confident that means the problem is in the LocalBacken=
d or something near it.</div><div><div><div class=3D"gmail_extra"><br><div =
class=3D"gmail_quote">On Thu, Feb 26, 2015 at 1:37 PM, Victor Tso-Guillen <=
span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"_blank">v=
tso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" s=
tyle=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div=
 dir=3D"ltr">Okay I confirmed my suspicions of a hang. I made a request tha=
t stopped progressing, though the already-scheduled tasks had finished. I m=
ade a separate request that was small enough not to hang, and it kicked the=
 hung job enough to finish. I think what&#39;s happening is that the schedu=
ler or the local backend is not kicking the revive offers messaging at the =
right time, but I have to dig into the code some more to nail the culprit. =
Anyone on these list have experience in those code areas that could help?</=
div><div><div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On =
Thu, Feb 26, 2015 at 2:27 AM, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a h=
ref=3D"mailto:vtso@paxata.com" target=3D"_blank">vtso@paxata.com</a>&gt;</s=
pan> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex=
;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Thanks for t=
he link. Unfortunately, I turned on rdd compression and nothing changed. I =
tried moving netty -&gt; nio and no change :(</div><div><div><div class=3D"=
gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 2:01 AM=
, Akhil Das <span dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.=
com" target=3D"_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br>=
<blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1p=
x #ccc solid;padding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default=
" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">No=
t many that i know of, but i bumped into this one=C2=A0<a href=3D"https://i=
ssues.apache.org/jira/browse/SPARK-4516" target=3D"_blank">https://issues.a=
pache.org/jira/browse/SPARK-4516</a></div></div><div class=3D"gmail_extra">=
<br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>Best Regards</div><=
/div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 3:26 PM, Victor Tso-=
Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D"=
_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail=
_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:=
1ex"><div dir=3D"ltr">Is there any potential problem from 1.1.1 to 1.2.1 wi=
th shuffle dependencies that produce no data?</div><div><div><div class=3D"=
gmail_extra"><br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 1:56 AM=
, Victor Tso-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.co=
m" target=3D"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr">The data is small. The job is composed o=
f many small stages.<div><br></div><div>* I found that with fewer than 222 =
the problem exhibits. What will be gained by going higher?</div><div>* Push=
ing up the parallelism only pushes up the boundary at which the system appe=
ars to hang. I&#39;m worried about some sort of message loss or inconsisten=
cy.</div><div>* Yes, we are using Kryo.</div><div>* I&#39;ll try that, but =
I&#39;m again a little confused why you&#39;re recommending this. I&#39;m s=
tumped so might as well?</div></div><div><div><div class=3D"gmail_extra"><b=
r><div class=3D"gmail_quote">On Wed, Feb 25, 2015 at 11:13 PM, Akhil Das <s=
pan dir=3D"ltr">&lt;<a href=3D"mailto:akhil@sigmoidanalytics.com" target=3D=
"_blank">akhil@sigmoidanalytics.com</a>&gt;</span> wrote:<br><blockquote cl=
ass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;p=
adding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">What operation a=
re you trying to do and how big is the data that you are operating on?</div=
><div class=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,mo=
nospace;color:rgb(0,0,0)"><br></div><div class=3D"gmail_default" style=3D"f=
ont-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)">Here&#39;s a f=
ew things which you can try:</div><div class=3D"gmail_default" style=3D"fon=
t-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)"><br></div><block=
quote style=3D"margin:0 0 0 40px;border:none;padding:0px"><div class=3D"gma=
il_default" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(=
0,0,0)">- Repartition the RDD to a higher number than 222</div><div class=
=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;col=
or:rgb(0,0,0)">- Specify the master as local[*] or local[10]</div><div clas=
s=3D"gmail_default" style=3D"font-family:&#39;courier new&#39;,monospace;co=
lor:rgb(0,0,0)">- Use Kryo Serializer (<span style=3D"color:rgb(51,51,51);f=
ont-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-=
size:12px;line-height:1.4;font-weight:bold">.</span><span style=3D"color:rg=
b(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,mo=
nospace;font-size:12px;line-height:1.4;background-color:rgb(255,255,255)">s=
et</span><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39=
;Liberation Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font=
-weight:bold">(</span><span style=3D"font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;color:rgb(1=
87,136,68)">&quot;spark.serializer&quot;</span><span style=3D"color:rgb(51,=
51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospa=
ce;font-size:12px;line-height:1.4;font-weight:bold">,</span><span style=3D"=
color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Co=
urier,monospace;font-size:12px;line-height:1.4"> </span><span style=3D"font=
-family:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-siz=
e:12px;line-height:1.4;color:rgb(187,136,68)">&quot;org.apache.spark.serial=
izer.KryoSerializer&quot;</span><span style=3D"color:rgb(51,51,51);font-fam=
ily:Consolas,Menlo,&#39;Liberation Mono&#39;,Courier,monospace;font-size:12=
px;line-height:1.4;font-weight:bold">))</span></div><div class=3D"gmail_def=
ault" style=3D"font-family:&#39;courier new&#39;,monospace;color:rgb(0,0,0)=
"><span style=3D"color:rgb(51,51,51);font-family:Consolas,Menlo,&#39;Libera=
tion Mono&#39;,Courier,monospace;font-size:12px;line-height:1.4;font-weight=
:bold"><span style=3D"color:rgb(0,0,0);font-family:&#39;courier new&#39;,mo=
nospace;font-size:small;font-weight:normal;line-height:normal">- Enable RDD=
 Compression (</span><span style=3D"line-height:1.4">.</span><span style=3D=
"line-height:1.4;font-weight:normal;background-color:rgb(255,255,255)">set<=
/span><span style=3D"line-height:1.4">(</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;spark.rdd.compress&quot;<=
/span><span style=3D"line-height:1.4">,</span><span style=3D"line-height:1.=
4;font-weight:normal;color:rgb(187,136,68)">&quot;true&quot;</span><span st=
yle=3D"line-height:1.4">) )</span></span></div></blockquote></div><div clas=
s=3D"gmail_extra"><br clear=3D"all"><div><div><div dir=3D"ltr">Thanks<div>B=
est Regards</div></div></div></div><div><div>
<br><div class=3D"gmail_quote">On Thu, Feb 26, 2015 at 10:15 AM, Victor Tso=
-Guillen <span dir=3D"ltr">&lt;<a href=3D"mailto:vtso@paxata.com" target=3D=
"_blank">vtso@paxata.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div>I&#39;m getting this really reliably on Spark 1=
.2.1. Basically I&#39;m in local mode with parallelism at 8. I have 222 tas=
ks and I never seem to get far past 40. Usually in the 20s to 30s it will j=
ust hang. The last logging is below, and a screenshot of the UI.</div><div>=
<br></div><div>2015-02-25 20:39:55.779 GMT-0800 INFO =C2=A0[task-result-get=
ter-3] TaskSetManager - Finished task 3.0 in stage 16.0 (TID 22) in 612 ms =
on localhost (1/5)</div><div>2015-02-25 20:39:55.825 GMT-0800 INFO =C2=A0[E=
xecutor task launch worker-10] Executor - Finished task 1.0 in stage 16.0 (=
TID 20). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.825=
 GMT-0800 INFO =C2=A0[Executor task launch worker-8] Executor - Finished ta=
sk 2.0 in stage 16.0 (TID 21). 2492 bytes result sent to driver</div><div>2=
015-02-25 20:39:55.831 GMT-0800 INFO =C2=A0[task-result-getter-0] TaskSetMa=
nager - Finished task 1.0 in stage 16.0 (TID 20) in 670 ms on localhost (2/=
5)</div><div>2015-02-25 20:39:55.836 GMT-0800 INFO =C2=A0[task-result-gette=
r-1] TaskSetManager - Finished task 2.0 in stage 16.0 (TID 21) in 674 ms on=
 localhost (3/5)</div><div>2015-02-25 20:39:55.891 GMT-0800 INFO =C2=A0[Exe=
cutor task launch worker-9] Executor - Finished task 0.0 in stage 16.0 (TID=
 19). 2492 bytes result sent to driver</div><div>2015-02-25 20:39:55.896 GM=
T-0800 INFO =C2=A0[task-result-getter-2] TaskSetManager - Finished task 0.0=
 in stage 16.0 (TID 19) in 740 ms on localhost (4/5)</div><div><br></div><d=
iv><img src=3D"cid:ii_14bc43449dfc51e7" alt=3D"Inline image 1" width=3D"544=
" height=3D"124"><br></div><div>What should I make of this? Where do I star=
t?</div><div><br></div><div>Thanks,</div><div>Victor</div></div>
</blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div></div></div>
</blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

--001a113cd7be8407e605102b4f2d--
--001a113cd7be8407eb05102b4f2e--

From dev-return-11818-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Feb 28 20:27:02 2015
Return-Path: <dev-return-11818-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F05C10BE7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 28 Feb 2015 20:27:02 +0000 (UTC)
Received: (qmail 50785 invoked by uid 500); 28 Feb 2015 20:27:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50710 invoked by uid 500); 28 Feb 2015 20:27:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50698 invoked by uid 99); 28 Feb 2015 20:27:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 20:27:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of neiodavince@gmail.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 28 Feb 2015 20:26:36 +0000
Received: by pdbft15 with SMTP id ft15so6925497pdb.11
        for <dev@spark.apache.org>; Sat, 28 Feb 2015 12:26:34 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=x2v4S84w0UiU5IkM8XQKMlt3cYyVZ1NEj2ADST2WzEE=;
        b=JvKMInejTGEG4dRMWQ5i7iuF0fYIlze+5Mse567olqpMVMT2RpmsKqYjrnBsV3XUTP
         cgzTQK8/QXvSdPZOH5cZKIjuu21+s2mR8D+lYP9AZbn7UZKWESIj9FMTmHk5zrAN7kxn
         562wIvH31loS6S60fxj68tUmNKzj1Bs9Dxr00gWlF/bg99dqqJaMdTnfrrWYJYN1BGJm
         XaWGRXwKObbL3pzNxIkuPWn7+/i7y3U1kPfXJobetbI3Tl+J7dxS6Dy6tjCLkBxcwJqd
         +ouyMqMgWYbBLbK/6R1VZfycWUKk8b2m8j+sMyABcEzAQuAA31+stByEXkf7RFSzTX+F
         GN6A==
X-Received: by 10.66.159.167 with SMTP id xd7mr35025467pab.54.1425155194100;
        Sat, 28 Feb 2015 12:26:34 -0800 (PST)
Received: from [22.3.9.161] ([172.56.17.45])
        by mx.google.com with ESMTPSA id hx2sm7529319pbc.68.2015.02.28.12.26.32
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 28 Feb 2015 12:26:33 -0800 (PST)
Content-Type: text/plain;
	charset=us-ascii
Mime-Version: 1.0 (1.0)
Subject: Re: Google Summer of Code - ideas
From: Sath <neiodavince@gmail.com>
X-Mailer: iPhone Mail (12B466)
In-Reply-To: <CAFQAd-nNmFK9rFQeNQGqZz6HtegiYk_Hkt7iJ5+BXobTudFGiQ@mail.gmail.com>
Date: Sat, 28 Feb 2015 12:26:31 -0800
Cc: Jeremy Freeman <freeman.jeremy@gmail.com>,
 Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <8FDD3B4D-3DC6-4594-B1C2-D8245BEEA895@gmail.com>
References: <CAFQAd-n5q8zOraAEUh7rQzTH-QhuADZHebiZ6=CzQ7c12Roz+A@mail.gmail.com> <CAJgQjQ_EG+9xL7nu7RytH9UbEqL9aoBbF5Me_01bPqjQ-jfCmA@mail.gmail.com> <CAFQAd-nV0xQ_5DS4u+JznuGt+LgkfLCNB7AhiCmX6i9T8WiRuw@mail.gmail.com> <CAJgQjQ_fFXjos2x_QE=RwkRRB8XqQxUu00Ro5c3cAun3iYKrXg@mail.gmail.com> <BC0324FE-7612-42B6-82DB-38CD30E48A75@gmail.com> <CAFQAd-nNmFK9rFQeNQGqZz6HtegiYk_Hkt7iJ5+BXobTudFGiQ@mail.gmail.com>
To: Manoj Kumar <manojkumarsivaraj334@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

All=20

  I would like to contribute for the google summer of code projects. Please g=
uide me to start the process=20


Sath=20


> On Feb 28, 2015, at 11:34 AM, Manoj Kumar <manojkumarsivaraj334@gmail.com>=
 wrote:
>=20
> Hi,
>=20
> Thanks a lot.
> Yes indeed, I am interested. I shall start looking at all the related
> JIRA's in a while.
>=20
>=20
>=20
> --=20
> Godspeed,
> Manoj Kumar,
> http://manojbits.wordpress.com
> <http://goog_1017110195>
> http://github.com/MechCoder

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


